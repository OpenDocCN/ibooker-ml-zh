<html><head></head><body><section data-pdf-bookmark="Chapter 12. Training for Ranking" data-type="chapter" epub:type="chapter"><div class="chapter" id="LossFunctions">&#13;
<h1><span class="label">Chapter 12. </span>Training for Ranking</h1>&#13;
&#13;
&#13;
<p>Typical<a data-primary="ranking metrics" data-secondary="ordering of recommendations" data-type="indexterm" id="id1019"/> ML tasks usually predict a single outcome, such as the probability of being in a positive class for classification tasks, or an expected value for regression tasks. Ranking, on the other hand, provides a relative ordering of sets of items. This kind of task is typical of search results or recommendations, where the order of items presented is important. In these kinds of problems, the score of an item usually isn’t shown to the user directly but rather is presented—maybe implicitly—with the ordinal rank of the item: the item at the top of the list is numbered lower than the next item.</p>&#13;
&#13;
<p>This chapter presents various kinds of loss functions that ML algorithms can use during training. These scores should estimate list orderings such that when compared to one another, they result in sets that are ordered more closely to the relevance ordering observed in a training dataset. Here we will focus on introducing the concepts and computations, which you’ll put to work in the next chapter.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Where Does Ranking Fit in Recommender Systems?" data-type="sect1"><div class="sect1" id="id222">&#13;
<h1>Where Does Ranking Fit in Recommender Systems?</h1>&#13;
&#13;
<p>Before<a data-primary="ranking training" data-secondary="role of ranking in recommender systems" data-type="indexterm" id="id1020"/><a data-primary="recommendation systems" data-secondary="role of ranking in" data-type="indexterm" id="id1021"/> we dive into the details of loss functions for ranking, we should talk about where ranking fits into the larger scheme of recommender systems as a whole. Typical large-scale recommenders have a retrieval phase, in which a cheap function is used to gather a decent number of candidate items into a candidate set. Usually, this retrieval phase is only item based. For example, the candidate set might include items related to recently consumed or liked items by a user. Or if freshness is important, such as for news data, the set might include the newest popular and relevant items for the user. After items are gathered into a candidate set, we apply ranking to its items.</p>&#13;
&#13;
<p>Also, since the candidate set is usually much smaller than the entire corpus of items, we can use more expensive models and auxiliary features to help the ranking. These features could be user features or context features. User features could help in determining the items’ usefulness to the user, such as the average embedding of recently consumed items. Context features could indicate details about the current session, such as time of day or recent queries that a user has typed—a feature that differentiates the current session from others and helps in determining relevant items. Finally, we have the representation of the items themselves, which can be anything from content features to learned embeddings that represent the item.</p>&#13;
&#13;
<p>The user, context, and item features are then concatenated into one feature vector that we will use to represent the item; we then score all the candidates at once and order them. The rank ordered set might then have extra filtering applied to it for business logic, such as removing near duplicates or making the ranked set more diverse in the kinds of items displayed.</p>&#13;
&#13;
<p>In the following examples, we will assume that the items can all be represented by a concatenated feature vector of user, context, and item features and that the model could be as simple as a linear model with a weight vector <code>W</code> that is dotted with the item vector to obtain a score for sorting the items. These models can be generalized to deep neural networks, but the final layer output is still going to be a scalar used to sort the items.</p>&#13;
&#13;
<p>Now that we have set the context for ranking, let’s consider ways we might rank a set of items represented by vectors.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Learning to Rank" data-type="sect1"><div class="sect1" id="id140">&#13;
<h1>Learning to Rank</h1>&#13;
&#13;
<p><em>Learning to rank</em> (LTR) is<a data-primary="LTR (learning to rank) models" data-type="indexterm" id="id1022"/><a data-primary="ranking training" data-secondary="learning to rank (LTR) models" data-type="indexterm" id="id1023"/><a data-primary="learning to rank (LTR) models" data-type="indexterm" id="id1024"/><a data-primary="models" data-secondary="learning to rank (LTR) models" data-type="indexterm" id="id1025"/> the name for the kind of models that score an ordered list of items according to their relevancy or importance. This technique is how we go from the potentially raw output of retrieval to a sorted list of items based on their relevance.</p>&#13;
&#13;
<p>LTR problems have three main types:</p>&#13;
<dl>&#13;
<dt>Pointwise</dt>&#13;
<dd>&#13;
<p>The<a data-primary="pointwise LTR models" data-type="indexterm" id="id1026"/> model treats individual documents in isolation and assigns them a score or rank. The task becomes a regression or classification problem.</p>&#13;
</dd>&#13;
<dt>Pairwise</dt>&#13;
<dd>&#13;
<p>The<a data-primary="pairwise LTR models" data-type="indexterm" id="id1027"/> model considers pairs of documents simultaneously in the loss function. The goal is to minimize the number of incorrectly ordered pairs.</p>&#13;
</dd>&#13;
<dt>Listwise</dt>&#13;
<dd>&#13;
<p>The<a data-primary="listwise LTR models" data-type="indexterm" id="id1028"/> model considers the entire list of documents in the loss function. The goal is to find the optimal ordering of the entire list.</p>&#13;
</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Training an LTR Model" data-type="sect1"><div class="sect1" id="id223">&#13;
<h1>Training an LTR Model</h1>&#13;
&#13;
<p>The<a data-primary="ranking training" data-secondary="training LTR models" data-type="indexterm" id="id1029"/> training data for an LTR model typically consists of a list of items, and each item has a set of features and a label (or ground truth). The features might include information about the item itself, and the label typically represents its relevance or importance. For instance, in our recommender systems, we have item features, and in the training dataset, the labels will show if the item is relevant to the user. Additionally, LTR models sometimes make use of the query or user features.</p>&#13;
&#13;
<p>The training process is about learning a ranking function by using these features and labels. These ranking functions are then applied to the retrieved items before serving.</p>&#13;
&#13;
<p>Let’s see some examples of how these models are trained.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Classification for Ranking" data-type="sect2"><div class="sect2" id="id141">&#13;
<h2>Classification for Ranking</h2>&#13;
&#13;
<p>One<a data-primary="classification, for ranking" data-type="indexterm" id="id1030"/> way to pose the ranking problem is as a<a data-primary="multilabel tasks" data-type="indexterm" id="id1031"/> multilabel task. Every item appearing in the training set that is associated to the user is a positive example, while those outside would be negative. This is, in effect, a multilabel approach at the scale of the set of items. The network could have an architecture with each item’s features as input nodes, and then some user features as well. The output nodes would be in correspondence with the items you wish to label.</p>&#13;
&#13;
<p>With<a data-primary="binary cross-entropy loss" data-type="indexterm" id="id1032"/><a data-primary="loss functions" data-secondary="binary cross-entropy loss" data-type="indexterm" id="id1033"/><a data-primary="cross-entropy loss" data-type="indexterm" id="id1034"/> a linear model, if <math alttext="upper X">&#13;
  <mi>X</mi>&#13;
</math> is the item vector and <math alttext="upper Y">&#13;
  <mi>Y</mi>&#13;
</math> is the output, we learn <math alttext="upper W">&#13;
  <mi>W</mi>&#13;
</math>, where <math alttext="s i g m o i d left-parenthesis upper W upper X right-parenthesis equals 1">&#13;
  <mrow>&#13;
    <mi>s</mi>&#13;
    <mi>i</mi>&#13;
    <mi>g</mi>&#13;
    <mi>m</mi>&#13;
    <mi>o</mi>&#13;
    <mi>i</mi>&#13;
    <mi>d</mi>&#13;
    <mo>(</mo>&#13;
    <mi>W</mi>&#13;
    <mi>X</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
  </mrow>&#13;
</math> if <math alttext="upper X">&#13;
  <mi>X</mi>&#13;
</math> is an item in the positive set; otherwise, <math alttext="s i g m o i d left-parenthesis upper W upper X right-parenthesis equals 0">&#13;
  <mrow>&#13;
    <mi>s</mi>&#13;
    <mi>i</mi>&#13;
    <mi>g</mi>&#13;
    <mi>m</mi>&#13;
    <mi>o</mi>&#13;
    <mi>i</mi>&#13;
    <mi>d</mi>&#13;
    <mo>(</mo>&#13;
    <mi>W</mi>&#13;
    <mi>X</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mn>0</mn>&#13;
  </mrow>&#13;
</math>. This corresponds to the <a href="https://oreil.ly/5Rd14">binary cross-entropy loss</a> in Optax.</p>&#13;
&#13;
<p>Unfortunately, the relative ordering of items isn’t taken into account in this setup, so this loss function consisting of<a data-primary="sigmoid activation functions" data-type="indexterm" id="id1035"/> sigmoid activation functions for each item won’t optimize ranking metrics very well. Effectively, this ranking is merely a downstream<a data-primary="relevance models" data-type="indexterm" id="id1036"/><a data-primary="models" data-secondary="relevance models" data-type="indexterm" id="id1037"/> <em>relevance model</em> that only helps to filter those options retrieved in a previous step.</p>&#13;
&#13;
<p>Another problem with this approach is that we have labeled everything outside of the training set to be negative, but the user might never have seen a new item that could be relevant to a query—so it would be incorrect to label this new item as a negative when it is simply unobserved.</p>&#13;
&#13;
<p>You may have realized that the ranking needs to consider the relative positions in the list. Let’s consider this next.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Regression for Ranking" data-type="sect2"><div class="sect2" id="id142">&#13;
<h2>Regression for Ranking</h2>&#13;
&#13;
<p>The<a data-primary="regression, for ranking" data-type="indexterm" id="id1038"/> most naive way to rank a set of items is simply to regress to the rank of a similar number like NDCG or our other personalization metrics that are rank respective.</p>&#13;
&#13;
<p>In practice, this is achieved by conditioning the set of items against a query. For example, we could pose the problem as regression to the NDCG, given the query as the context of the ranking. Furthermore, we can supply the query as an embedding context vector to a feed-forward network that is concatenated with the features of the items in the set and regress toward the NDCG value.</p>&#13;
&#13;
<p>The query is needed as a context because a set of item’s ordering might be dependent upon the query. Consider, for example, typing into a search bar the query <strong><code>flowers</code></strong>. We would then expect a set of items most representative of flowers to be in the top results. This demonstrates that the query is an important consideration of the scoring function.</p>&#13;
&#13;
<p>With a linear model, if <math alttext="upper X">&#13;
  <mi>X</mi>&#13;
</math> is the item vector and <math alttext="upper Y">&#13;
  <mi>Y</mi>&#13;
</math> is the output, then we learn <math alttext="upper W">&#13;
  <mi>W</mi>&#13;
</math>, where <math alttext="upper W upper X left-parenthesis i right-parenthesis equals upper N upper D upper C upper G left-parenthesis i right-parenthesis">&#13;
  <mrow>&#13;
    <mi>W</mi>&#13;
    <mi>X</mi>&#13;
    <mo>(</mo>&#13;
    <mi>i</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>N</mi>&#13;
    <mi>D</mi>&#13;
    <mi>C</mi>&#13;
    <mi>G</mi>&#13;
    <mo>(</mo>&#13;
    <mi>i</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> and <math alttext="upper N upper D upper C upper G left-parenthesis i right-parenthesis">&#13;
  <mrow>&#13;
    <mi>N</mi>&#13;
    <mi>D</mi>&#13;
    <mi>C</mi>&#13;
    <mi>G</mi>&#13;
    <mo>(</mo>&#13;
    <mi>i</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> is the NDCG for item <math alttext="i">&#13;
  <mi>i</mi>&#13;
</math>. Regression can be learned using the<a data-primary="L2 loss function" data-type="indexterm" id="id1039"/><a data-primary="loss functions" data-secondary="L2 loss function" data-type="indexterm" id="id1040"/> <a href="https://oreil.ly/IHw-Z">L2 loss</a> in Optax.</p>&#13;
&#13;
<p>Ultimately, this approach is about attempting to learn the underlying features of items that lead to higher-rank scores in your personalization metric. Unfortunately, this also fails to explicitly consider the relative ordering of items. This is a pretty serious limitation, which we’ll consider shortly.</p>&#13;
&#13;
<p>Another consideration: what do we do for items that aren’t ranked outside of the top-<em>k</em> training items? The rank we would assign them would be essentially random, as we do not know what number to assign them. Therefore, this method needs improvement, which we’ll explore in the next section.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Classification and Regression for Ranking" data-type="sect2"><div class="sect2" id="id316">&#13;
<h2>Classification and Regression for Ranking</h2>&#13;
&#13;
<p>Suppose we have a web page such as an online bookstore, and users have to browse through and click items in order to purchase them. For such a funnel, we could break the ranking into two parts. The first model could predict the probability of a click on an item, given a set of items on display. The second model could be conditioned on a click-through and  could be a regression model estimating the purchase price of the item.</p>&#13;
&#13;
<p>Then, a full ranking model could be the product of two models. The first one computes the probability of clicking through an item, given a set of competing items. And the second one computes the expected value of a purchase, given that it had been clicked. Notice that the first and second model could have different features, depending on the stage of the funnel a user is in. The first model has access to features of competing items, while the second model might take into account shipping costs and discounts applied that might change the value of an item. Thus, in this setting, it would be advantageous to model both stages of the funnel with different models so as to make use of the most amount of information present at each stage of the funnel.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="WARP" data-type="sect1"><div class="sect1" id="warp">&#13;
<h1>WARP</h1>&#13;
&#13;
<p>One<a data-primary="ranking training" data-secondary="weighted approximate rank pairwise (WARP)" data-type="indexterm" id="id1041"/><a data-primary="weighted approximate rank pairwise (WARP)" data-type="indexterm" id="id1042"/><a data-primary="WARP (weighted approximate rank pairwise)" data-type="indexterm" id="id1043"/><a data-primary="loss functions" data-secondary="weighted approximate rank pairwise (WARP)" data-type="indexterm" id="id1044"/> possible way to generate a ranking loss stochastically is introduced in <a href="https://oreil.ly/bagf-">“WSABIE: Scaling Up to Large Vocabulary Image Annotation”</a> by Jason Weston et al. The loss is called <em>weighted approximate rank pairwise</em> (WARP). In this scheme, the loss function is broken into what looks like a pairwise loss. More precisely, if a higher-ranked item doesn’t have a score that is greater than the margin (which is arbitrarily picked to be 1) for a lower-rank item, we apply the<a data-primary="hinge loss" data-type="indexterm" id="id1045"/> <em>hinge loss</em> to the pair of items. This looks like the following:</p>&#13;
<div data-type="equation">&#13;
<math alttext="m a x left-parenthesis 0 comma 1 minus s c o r e left-parenthesis p o s right-parenthesis plus s c o r e left-parenthesis n e g right-parenthesis right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>m</mi>&#13;
    <mi>a</mi>&#13;
    <mi>x</mi>&#13;
    <mo>(</mo>&#13;
    <mn>0</mn>&#13;
    <mo>,</mo>&#13;
    <mn>1</mn>&#13;
    <mo>-</mo>&#13;
    <mi>s</mi>&#13;
    <mi>c</mi>&#13;
    <mi>o</mi>&#13;
    <mi>r</mi>&#13;
    <mi>e</mi>&#13;
    <mo>(</mo>&#13;
    <mi>p</mi>&#13;
    <mi>o</mi>&#13;
    <mi>s</mi>&#13;
    <mo>)</mo>&#13;
    <mo>+</mo>&#13;
    <mi>s</mi>&#13;
    <mi>c</mi>&#13;
    <mi>o</mi>&#13;
    <mi>r</mi>&#13;
    <mi>e</mi>&#13;
    <mo>(</mo>&#13;
    <mi>n</mi>&#13;
    <mi>e</mi>&#13;
    <mi>g</mi>&#13;
    <mo>)</mo>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>With a linear model, if <math alttext="upper X Subscript p Baseline o s">&#13;
  <mrow>&#13;
    <msub><mi>X</mi> <mi>p</mi> </msub>&#13;
    <mi>o</mi>&#13;
    <mi>s</mi>&#13;
  </mrow>&#13;
</math> is the positive item vector, and <math alttext="upper X Subscript n Baseline e g">&#13;
  <mrow>&#13;
    <msub><mi>X</mi> <mi>n</mi> </msub>&#13;
    <mi>e</mi>&#13;
    <mi>g</mi>&#13;
  </mrow>&#13;
</math> is the negative item vector, then we learn <math alttext="upper W">&#13;
  <mi>W</mi>&#13;
</math>, where <math alttext="upper W upper X Subscript p Baseline o s minus upper W upper X Subscript n Baseline e g greater-than 1">&#13;
  <mrow>&#13;
    <mi>W</mi>&#13;
    <msub><mi>X</mi> <mi>p</mi> </msub>&#13;
    <mi>o</mi>&#13;
    <mi>s</mi>&#13;
    <mo>-</mo>&#13;
    <mi>W</mi>&#13;
    <msub><mi>X</mi> <mi>n</mi> </msub>&#13;
    <mi>e</mi>&#13;
    <mi>g</mi>&#13;
    <mo>&gt;</mo>&#13;
    <mn>1</mn>&#13;
  </mrow>&#13;
</math>. The loss for this is <a href="https://oreil.ly/88zk3">hinge loss</a>, where the predictor output is <math alttext="upper W upper X Subscript p Baseline o s minus upper W upper X Subscript n Baseline e g">&#13;
  <mrow>&#13;
    <mi>W</mi>&#13;
    <msub><mi>X</mi> <mi>p</mi> </msub>&#13;
    <mi>o</mi>&#13;
    <mi>s</mi>&#13;
    <mo>-</mo>&#13;
    <mi>W</mi>&#13;
    <msub><mi>X</mi> <mi>n</mi> </msub>&#13;
    <mi>e</mi>&#13;
    <mi>g</mi>&#13;
  </mrow>&#13;
</math> and the target is 1.</p>&#13;
&#13;
<p>However, to compensate for the fact that an unobserved item might not be a true negative, just something unobserved, we count the number of times we had to sample from the negative set to find something that violates the ordering of the chosen pair. That is, we count the number of times we had to look for something where:</p>&#13;
<div data-type="equation">&#13;
<math alttext="s c o r e left-parenthesis n e g right-parenthesis greater-than s c o r e left-parenthesis p o s right-parenthesis minus 1" display="block">&#13;
  <mrow>&#13;
    <mi>s</mi>&#13;
    <mi>c</mi>&#13;
    <mi>o</mi>&#13;
    <mi>r</mi>&#13;
    <mi>e</mi>&#13;
    <mo>(</mo>&#13;
    <mi>n</mi>&#13;
    <mi>e</mi>&#13;
    <mi>g</mi>&#13;
    <mo>)</mo>&#13;
    <mo>&gt;</mo>&#13;
    <mi>s</mi>&#13;
    <mi>c</mi>&#13;
    <mi>o</mi>&#13;
    <mi>r</mi>&#13;
    <mi>e</mi>&#13;
    <mo>(</mo>&#13;
    <mi>p</mi>&#13;
    <mi>o</mi>&#13;
    <mi>s</mi>&#13;
    <mo>)</mo>&#13;
    <mo>-</mo>&#13;
    <mn>1</mn>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>We then construct a monotonically decreasing function of the number of times we sample the universe of items (less the positives) for a violating negative and look up the weight for this number and multiply the loss with it. If it’s very hard to find a violating negative, the gradient should therefore be lower because either we are close to a good solution already or the item was never seen before, so we should not be so confident as to assign it a low score just because it was never shown to the user as a result for a query.</p>&#13;
&#13;
<p>Note that WARP loss was developed when CPUs were the dominant form of computation to train ML models. As such, an approximation to ranking was used to obtain the rank of a negative item. The<a data-primary="approximate rank" data-type="indexterm" id="id1046"/> <em>approximate rank</em> is defined as the number of samples with replacement in the universe of items (less the positive example) before we find a negative item whose score is larger than the positive by an arbitrary constant, called a <em>margin</em>, of 1.0.</p>&#13;
&#13;
<p>To construct the WARP weight for the pairwise loss, we need a function to go from the approximate rank of the negative item to the WARP weight. A relatively simple bit of code to compute this is as follows:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">get_warp_weights</code><code class="p">(</code><code class="n">n</code><code class="p">:</code> <code class="nb">int</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">np</code><code class="o">.</code><code class="n">ndarray</code><code class="p">:</code>&#13;
  <code class="sd">"""Returns N weights to convert a rank to a loss weight."""</code>&#13;
&#13;
  <code class="c1"># The alphas are defined as values that are monotonically decreasing.</code>&#13;
  <code class="c1"># We take the reciprocal of the natural numbers for the alphas.</code>&#13;
  <code class="n">rank</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="mf">1.0</code><code class="p">,</code> <code class="n">n</code> <code class="o">+</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>&#13;
  <code class="n">alpha</code> <code class="o">=</code> <code class="mf">1.0</code> <code class="o">/</code> <code class="n">rank</code>&#13;
  <code class="n">weights</code> <code class="o">=</code> <code class="n">alpha</code>&#13;
&#13;
  <code class="c1"># This is the L in the paper, defined as the sum of all previous alphas.</code>&#13;
  <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="n">n</code><code class="p">):</code>&#13;
    <code class="n">weights</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">weights</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">+</code> <code class="n">weights</code><code class="p">[</code><code class="n">i</code> <code class="o">-</code><code class="mi">1</code><code class="p">]</code>&#13;
&#13;
  <code class="c1"># Divide by the rank.</code>&#13;
  <code class="n">weights</code> <code class="o">=</code> <code class="n">weights</code> <code class="o">/</code> <code class="n">rank</code>&#13;
  <code class="k">return</code> <code class="n">weights</code>&#13;
&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">get_warp_weights</code><code class="p">(</code><code class="mi">5</code><code class="p">))</code>&#13;
<code class="p">[</code><code class="mf">1.</code>         <code class="mf">0.75</code>       <code class="mf">0.61111111</code> <code class="mf">0.52083333</code> <code class="mf">0.45666667</code><code class="p">]</code></pre>&#13;
&#13;
<p>As you can see, if we find a negative immediately, the WARP weight is 1.0, but if it is very difficult to find a negative that violates the margin, the WARP weight will be small.</p>&#13;
&#13;
<p>This loss function is approximately optimizing precision@<em>k</em>, and thus a good step toward improving rank estimates in the retrieved set. Even better, WARP is computationally efficient via sampling and thus more memory efficient.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="k-order Statistic" data-type="sect1"><div class="sect1" id="id144">&#13;
<h1>k-order Statistic</h1>&#13;
&#13;
<p>Is<a data-primary="k-order statistic loss" data-type="indexterm" id="id1047"/><a data-primary="loss functions" data-secondary="k-order statistic loss" data-type="indexterm" id="id1048"/><a data-primary="ranking training" data-secondary="k-order statistic loss" data-type="indexterm" id="id1049"/> there a way to improve upon the WARP loss and straight-up pairwise hinge loss? Turns out there are a whole spectrum of ways. In <a href="https://oreil.ly/afphG">“Learning to Rank Recommendations with the k-order Statistic Loss”</a>, Jason Weston et al. (including one of this book’s coauthors) show how this can be done by exploring the variants of losses between hinge loss and WARP loss. The authors of the paper conducted experiments on various corpora and show how the trade-off between optimizing for a single pairwise versus selecting a harder negative like WARP affects metrics including mean rank and precision and recall at <em>k</em>.</p>&#13;
&#13;
<p>The key generalization is that instead of a single positive item considered during the gradient step, the model uses all of them.</p>&#13;
&#13;
<p>Recall again that picking a random positive and a random negative pair optimizes for the ROC, or AUC. This isn’t great for ranking because it doesn’t optimize for the top of the list. WARP loss, on the other hand, optimizes for the top of the ranking list for a single positive item but does not specify how to pick the positive item.</p>&#13;
&#13;
<p>Several alternate strategies can be used for ordering the top of the list, including optimizing for mean maximum rank, which tries to group the positive items such that the lowest-scoring positive item is as near the top of the list as possible. To allow this ordering, we provide a probability distribution function over how we pick the positive sample. If the probability is skewed toward the top of the positive item list, we get a loss more like WARP loss. If the probability is uniform, we get AUC loss. If the probability is skewed toward the end of the positive item list, we then optimize for the worst case, like mean maximum rank. The NumPy function <code>np.random.choice</code> provides a mechanism from sampling from a distribution <math alttext="upper P">&#13;
  <mi>P</mi>&#13;
</math>.</p>&#13;
&#13;
<p>We have one more optimization to consider: <math alttext="upper K">&#13;
  <mi>K</mi>&#13;
</math>, the number of positive samples to use to construct the positive set. If <math alttext="upper K equals 1">&#13;
  <mrow>&#13;
    <mi>K</mi>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
  </mrow>&#13;
</math>, we pick only a positive random item from the positive set; otherwise, we construct the positive set, order the samples by score, and sample from the positive list of size <math alttext="upper K">&#13;
  <mi>K</mi>&#13;
</math> by using the probability distribution <math alttext="upper P">&#13;
  <mi>P</mi>&#13;
</math>. This optimization made sense in the era of CPUs when compute was expensive but might not make that much sense these days in the era of GPUs and TPUs, which we will talk about in the following warning.</p>&#13;
<div data-type="warning" epub:type="warning"><h1>Stochastic Losses and GPUs</h1>&#13;
<p>A<a data-primary="ranking training" data-secondary="stochastic losses" data-type="indexterm" id="id1050"/><a data-primary="stochastic loss functions" data-type="indexterm" id="id1051"/><a data-primary="loss functions" data-secondary="stochastic losses" data-type="indexterm" id="id1052"/> word of caution about the preceding stochastic losses. They were developed for an earlier era of CPUs when it was cheap and easy to sample and exit if a negative sample was found. These days, with modern GPUs, making branching decisions like this is harder because all the threads on the GPU core have to run the same code over different data in parallel. That usually means both sides of a branch are taken in a batch, so less computational savings occur from these early exits. Consequently, branching code that approximates stochastic losses like WARP and <em>k</em>-order statistic loss appear less efficient.</p>&#13;
&#13;
<p>What are we to do? We will show in <a data-type="xref" href="ch13.html#ch:spotify">Chapter 13</a> how to approximate these losses in code. Long story short, because of the way vector processors like GPUs tend to work by processing lots of data in parallel uniformly, we have to find a GPU-friendly way to compute these losses. In the next chapter, we approximate the negative sampling by generating a large batch of negatives and either scoring them all lower than the negative or looking for the most egregious violating negative or both together as a blend of loss functions.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="BM25" data-type="sect1"><div class="sect1" id="id145">&#13;
<h1>BM25</h1>&#13;
&#13;
<p>While<a data-primary="best matching 25 (BM25) algorithm" data-type="indexterm" id="id1053"/><a data-primary="BM25 (best matching 25) algorithm" data-type="indexterm" id="id1054"/><a data-primary="ranking training" data-secondary="best matching 25 (BM25) algorithm" data-type="indexterm" id="id1055"/> much of this book is targeted at recommending items to users, search ranking is a close sister study. In the space of information retrieval, or search ranking for documents, <em>best matching 25</em> (BM25) is an essential tool.</p>&#13;
&#13;
<p>BM25 is an algorithm used in information-retrieval systems to rank documents based on their relevance to a given query. This relevance is determined by considering factors like TF-IDF. It’s a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document. It’s also a part of the probabilistic relevance framework and is derived from the probabilistic retrieval model.</p>&#13;
&#13;
<p>The BM25 ranking function calculates a score for each document based on the query. The document with the highest score is considered the most relevant to the query.</p>&#13;
&#13;
<p>Here is a simplified version of the BM25 formula:</p>&#13;
<div data-type="equation">&#13;
<math alttext="left-brace score right-brace left-parenthesis upper D comma upper Q right-parenthesis equals sigma-summation Underscript i equals 1 Overscript n Endscripts left-brace IDF right-brace left-parenthesis q Subscript i Baseline right-parenthesis asterisk StartStartFraction f left-parenthesis q Subscript i Baseline comma upper D right-parenthesis asterisk left-parenthesis k Baseline 1 plus 1 right-parenthesis OverOver f left-parenthesis q Subscript i Baseline comma upper D right-parenthesis plus k 1 asterisk left-parenthesis 1 minus b plus b asterisk StartFraction StartAbsoluteValue upper D EndAbsoluteValue Over left-brace avgdl right-brace EndFraction right-parenthesis EndEndFraction" display="block">&#13;
  <mrow>&#13;
    <mtext>score</mtext>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>D</mi>&#13;
      <mo>,</mo>&#13;
      <mi>Q</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi> </munderover>&#13;
    <mtext>IDF</mtext>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>q</mi> <mi>i</mi> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>*</mo>&#13;
    <mfrac><mrow><mi>f</mi><mrow><mo>(</mo><msub><mi>q</mi> <mi>i</mi> </msub><mo>,</mo><mi>D</mi><mo>)</mo></mrow><mo>*</mo><mrow><mo>(</mo><mi>k</mi><mn>1</mn><mo>+</mo><mn>1</mn><mo>)</mo></mrow></mrow> <mrow><mi>f</mi><mrow><mo>(</mo><msub><mi>q</mi> <mi>i</mi> </msub><mo>,</mo><mi>D</mi><mo>)</mo></mrow><mo>+</mo><mi>k</mi><mn>1</mn><mo>*</mo><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mi>b</mi><mo>+</mo><mi>b</mi><mo>*</mo><mfrac><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow> <mtext>avgdl</mtext></mfrac><mo>)</mo></mrow></mrow></mfrac>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>The elements of this formula are as follows:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><math alttext="upper D">&#13;
  <mi>D</mi>&#13;
</math> represents a document.</p>&#13;
</li>&#13;
<li>&#13;
<p><math alttext="upper Q">&#13;
  <mi>Q</mi>&#13;
</math> is the query that consists of words <math alttext="StartSet q 1 comma q 2 comma period period period comma q Subscript n Baseline EndSet">&#13;
  <mfenced close="}" open="{" separators="">&#13;
    <msub><mi>q</mi> <mn>1</mn> </msub>&#13;
    <mo>,</mo>&#13;
    <msub><mi>q</mi> <mn>2</mn> </msub>&#13;
    <mo>,</mo>&#13;
    <mo>.</mo>&#13;
    <mo>.</mo>&#13;
    <mo>.</mo>&#13;
    <mo>,</mo>&#13;
    <msub><mi>q</mi> <mi>n</mi> </msub>&#13;
  </mfenced>&#13;
</math>.</p>&#13;
</li>&#13;
<li>&#13;
<p><math alttext="f left-parenthesis q i comma upper D right-parenthesis">&#13;
  <mrow>&#13;
    <mi>f</mi>&#13;
    <mo>(</mo>&#13;
    <mi>q</mi>&#13;
    <mi>i</mi>&#13;
    <mo>,</mo>&#13;
    <mi>D</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> is the frequency of query term <math alttext="q Subscript i">&#13;
  <msub><mi>q</mi> <mi>i</mi> </msub>&#13;
</math> in document <math alttext="upper D">&#13;
  <mi>D</mi>&#13;
</math>.</p>&#13;
</li>&#13;
<li>&#13;
<p><math alttext="StartAbsoluteValue upper D EndAbsoluteValue">&#13;
  <mrow>&#13;
    <mo>|</mo>&#13;
    <mi>D</mi>&#13;
    <mo>|</mo>&#13;
  </mrow>&#13;
</math> is the length of (the number of words in) the document <math alttext="upper D">&#13;
  <mi>D</mi>&#13;
</math>.</p>&#13;
</li>&#13;
<li>&#13;
<p><math alttext="a v g Subscript d Baseline l">&#13;
  <mrow>&#13;
    <mi>a</mi>&#13;
    <mi>v</mi>&#13;
    <msub><mi>g</mi> <mi>d</mi> </msub>&#13;
    <mi>l</mi>&#13;
  </mrow>&#13;
</math> is the average document length in the collection.</p>&#13;
</li>&#13;
<li>&#13;
<p><math alttext="k 1">&#13;
  <msub><mi>k</mi> <mn>1</mn> </msub>&#13;
</math> and <math alttext="b">&#13;
  <mi>b</mi>&#13;
</math> are hyperparameters. <math alttext="k 1">&#13;
  <msub><mi>k</mi> <mn>1</mn> </msub>&#13;
</math> is a positive tuning parameter that calibrates the document term frequency scaling. <math alttext="b">&#13;
  <mi>b</mi>&#13;
</math> is a parameter that determines the scaling by document length: <math alttext="b equals 1">&#13;
  <mrow>&#13;
    <mi>b</mi>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
  </mrow>&#13;
</math> corresponds to fully scaling the term weight by the document length, while <math alttext="b equals 0">&#13;
  <mrow>&#13;
    <mi>b</mi>&#13;
    <mo>=</mo>&#13;
    <mn>0</mn>&#13;
  </mrow>&#13;
</math> corresponds to no length normalization.</p>&#13;
</li>&#13;
<li>&#13;
<p><math alttext="upper I upper D upper F left-parenthesis q Subscript i Baseline right-parenthesis">&#13;
  <mrow>&#13;
    <mi>I</mi>&#13;
    <mi>D</mi>&#13;
    <mi>F</mi>&#13;
    <mo>(</mo>&#13;
    <msub><mi>q</mi> <mi>i</mi> </msub>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> is the inverse document frequency of query term <math alttext="q Subscript i">&#13;
  <msub><mi>q</mi> <mi>i</mi> </msub>&#13;
</math>, which measures the amount of information the word provides (whether it’s common or rare across all documents). BM25 applies a variant of IDF that can be computed as follows:</p>&#13;
<div data-type="equation">&#13;
<math alttext="left-brace IDF right-brace left-parenthesis q Subscript i Baseline right-parenthesis equals log left-parenthesis StartFraction upper N minus n left-parenthesis q Subscript i Baseline right-parenthesis plus 0.5 Over n left-parenthesis q Subscript i Baseline right-parenthesis plus 0.5 EndFraction right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mtext>IDF</mtext>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>q</mi> <mi>i</mi> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <mo form="prefix">log</mo>&#13;
    <mfenced close=")" open="(" separators="">&#13;
      <mfrac><mrow><mi>N</mi><mo>-</mo><mi>n</mi><mo>(</mo><msub><mi>q</mi> <mi>i</mi> </msub><mo>)</mo><mo>+</mo><mn>0</mn><mo>.</mo><mn>5</mn></mrow> <mrow><mi>n</mi><mo>(</mo><msub><mi>q</mi> <mi>i</mi> </msub><mo>)</mo><mo>+</mo><mn>0</mn><mo>.</mo><mn>5</mn></mrow></mfrac>&#13;
    </mfenced>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>Here, <math alttext="upper N">&#13;
  <mi>N</mi>&#13;
</math> is the total number of documents in the collection, and <math alttext="n left-parenthesis q Subscript i Baseline right-parenthesis">&#13;
  <mrow>&#13;
    <mi>n</mi>&#13;
    <mo>(</mo>&#13;
    <msub><mi>q</mi> <mi>i</mi> </msub>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> is the number of documents containing <math alttext="q Subscript i">&#13;
  <msub><mi>q</mi> <mi>i</mi> </msub>&#13;
</math>.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Simply, BM25 combines both term frequency (how often a term appears in a document) and inverse document frequency (how much unique information a term provides) to calculate the relevance score. It also introduces the concept of document length normalization, penalizing too-long documents  and preventing them from dominating shorter ones, which is a common issue in simple TF-IDF models. The free parameters <math alttext="k 1">&#13;
  <msub><mi>k</mi> <mn>1</mn> </msub>&#13;
</math> and <math alttext="b">&#13;
  <mi>b</mi>&#13;
</math> allow the model to be tuned based on the specific characteristics of the document set.</p>&#13;
&#13;
<p>In practice, BM25 provides a robust baseline for most<a data-primary="retrieval" data-secondary="information-retrieval tasks" data-type="indexterm" id="id1056"/><a data-primary="information-retrieval tasks" data-type="indexterm" id="id1057"/> information-retrieval tasks, including ad hoc keyword search and document similarity. BM25 is used in many open source search engines, such as Lucene and Elasticsearch, and is the de facto standard for what is often called<a data-primary="full-text search" data-type="indexterm" id="id1058"/> <em>full-text search</em>.</p>&#13;
&#13;
<p>So how might we integrate BM25 into the problems we discuss in this book? The output from BM25 is a list of documents ranked by relevance to the given query, and then LTR comes into play. You can use the BM25 score as one of the features in an LTR model, along with other features that you believe might influence the relevance of a document to a query.</p>&#13;
&#13;
<p>The general steps to combine BM25 with LTR for ranking are as follows:</p>&#13;
<ol>&#13;
<li>&#13;
<p><em>Retrieve a list of candidate documents</em>. Given a query, use BM25 to retrieve a list of candidate documents.</p>&#13;
</li>&#13;
<li>&#13;
<p><em>Compute features for each document</em>. Compute the BM25 score as one of the features, along with other potential features. This could include various document-specific features, query-document match features, user interaction features, etc.</p>&#13;
</li>&#13;
<li>&#13;
<p><em>Train/evaluate the LTR model</em>. Use these feature vectors and their corresponding labels (relevance judgments) to train your LTR model. Or, if you already have a trained model, use it to evaluate and rank the retrieved documents.</p>&#13;
</li>&#13;
<li>&#13;
<p><em>Rank</em>. The LTR model generates a score for each document. Rank the documents based on these scores.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>This combination of retrieval (with BM25) and ranking (with LTR) allows you to first narrow the potential candidate documents from a possibly very large collection (where BM25 shines) and then fine-tune the ranking of these candidates with a model that can consider more complex features and interactions (where LTR shines).</p>&#13;
&#13;
<p class="less_space pagebreak-before">It is worth mentioning that the BM25 score can provide a strong baseline in text document retrieval, and depending on the complexity of the problem and the amount of training data you have, LTR may or may not provide significant improvements.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Multimodal Retrieval" data-type="sect1"><div class="sect1" id="id146">&#13;
<h1>Multimodal Retrieval</h1>&#13;
&#13;
<p>Let’s<a data-primary="multimodal retrieval" data-type="indexterm" id="id1059"/><a data-primary="retrieval" data-secondary="multimodal retrieval" data-type="indexterm" id="id1060"/><a data-primary="ranking training" data-secondary="multimodal retrieval" data-type="indexterm" id="id1061"/> take another look at this retrieval method, as we can find some powerful leverage. Think back to <a data-type="xref" href="ch08.html#ch:wikipedia-e2e">Chapter 8</a>: we built a co-occurrence model, which illustrated how articles referenced jointly in other articles share meaning and mutual relevance. But how would you integrate search into this?</p>&#13;
&#13;
<p>You may think, “Oh, I can search the names of the articles.” But that doesn’t quite utilize our co-occurrence model; it underleverages that joint meaning we discovered. A classic approach may be to use something like BM25 on article titles or articles. More modern approaches may do a vector embedding of the query and article titles (using something like BERT or other transformer models). However, neither of these really capture both sides of what we’re looking for.</p>&#13;
&#13;
<p>Consider instead the following approach:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Search with the initial query via BM25 to get an initial set of “anchors.”</p>&#13;
</li>&#13;
<li>&#13;
<p>Search with each anchor as a query via your latent model(s).</p>&#13;
</li>&#13;
<li>&#13;
<p>Train an LTR model to aggregate and rank the union of the searches.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>Now we’re using a true multimodal retrieval, leveraging multiple latent spaces! One additional highlight in this approach is that queries are often out of distribution from documents with respect to encoder-based latent spaces. This means that when you type <strong><code>Who’s the leader of Mozambique?</code></strong>, this question looks fairly dissimilar to the article title (Mozambique) or the relevant sentence as of summer 2023 (“The new government under President Samora Machel established a one-party state based on Marxist principles.”)</p>&#13;
&#13;
<p>When the embeddings are not text at all, this method becomes even more powerful: consider typing text to search for an item of clothing and hoping to see an entire outfit that goes with it.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="id317">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>Getting things in the right order is an important aspect of recommendation systems. By now, you know that ordering is not the whole story, but it’s an essential step in the pipeline. We’ve collected our items and put them in the right order, and all that’s left to do is send them off to the user.</p>&#13;
&#13;
<p class="less_space pagebreak-before">We started with the most fundamental concept, learning to rank, and compared it with some traditional methods. We then got a big upgrade with WARP and WSABIE. That led us to the <em>k</em>-order statistic, which involves utilizing more careful probabilistic sampling. We finally wrapped up with BM25 as a powerful baseline in text settings.</p>&#13;
&#13;
<p>Before we conquer serving, let’s put these pieces together. In the next chapter, we’re going to turn up the volume and build some playlists. This will be the most intensive chapter yet, so go grab a beverage and a stretch. We’ve got some work to do.</p>&#13;
</div></section>&#13;
</div></section></body></html>