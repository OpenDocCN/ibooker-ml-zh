["```py\n# Import libraries\n'''Main'''\nimport numpy as np\nimport pandas as pd\nimport os, time, re\nimport pickle, gzip\n\n'''Data Viz'''\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nimport matplotlib as mpl\n\n%matplotlib inline\n\n'''Data Prep and Model Evaluation'''\nfrom sklearn import preprocessing as pp\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve, average_precision_score\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\n'''Algorithms'''\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport fastcluster\nfrom scipy.cluster.hierarchy import dendrogram, cophenet, fcluster\nfrom scipy.spatial.distance import pdist\n```", "```py\n# Load the data\ncurrent_path = os.getcwd()\nfile = '\\\\datasets\\\\lending_club_data\\\\LoanStats3a.csv'\ndata = pd.read_csv(current_path + file)\n\n# Select columns to keep\ncolumnsToKeep = ['loan_amnt','funded_amnt','funded_amnt_inv','term', \\\n                 'int_rate','installment','grade','sub_grade', \\\n                 'emp_length','home_ownership','annual_inc', \\\n                 'verification_status','pymnt_plan','purpose', \\\n                 'addr_state','dti','delinq_2yrs','earliest_cr_line', \\\n                 'mths_since_last_delinq','mths_since_last_record', \\\n                 'open_acc','pub_rec','revol_bal','revol_util', \\\n                 'total_acc','initial_list_status','out_prncp', \\\n                 'out_prncp_inv','total_pymnt','total_pymnt_inv', \\\n                 'total_rec_prncp','total_rec_int','total_rec_late_fee', \\\n                 'recoveries','collection_recovery_fee','last_pymnt_d', \\\n                 'last_pymnt_amnt']\n\ndata = data.loc[:,columnsToKeep]\n\ndata.shape\n\ndata.head()\n```", "```py\n# Transform features from string to numeric\nfor i in [\"term\",\"int_rate\",\"emp_length\",\"revol_util\"]:\n    data.loc[:,i] = \\\n        data.loc[:,i].apply(lambda x: re.sub(\"[^0-9]\", \"\", str(x)))\n    data.loc[:,i] = pd.to_numeric(data.loc[:,i])\n```", "```py\n# Determine which features are numerical\nnumericalFeats = [x for x in data.columns if data[x].dtype != 'object']\n\n# Display NaNs by feature\nnanCounter = np.isnan(data.loc[:,numericalFeats]).sum()\nnanCounter\n```", "```py\nloan_amnt               7\nfunded_amnt             7\nfunded_amnt_inv         7\nterm                    7\nint_rate                7\ninstallment             7\nemp_length              1119\nannual_inc              11\ndti                     7\ndelinq_2yrs             36\nmths_since_last_delinq  26933\nmths_since_last_record  38891\nopen_acc                36\npub_rec                 36\nrevol_bal               7\nrevol_util              97\ntotal_acc               36\nout_prncp               7\nout_prncp_inv           7\ntotal_pymnt             7\ntotal_pymnt_inv         7\ntotal_rec_prncp         7\ntotal_rec_int           7\ntotal_rec_late_fee      7\nrecoveries              7\ncollection_recovery_fee 7\nlast_pymnt_amnt         7\ndtype: int64\n```", "```py\n# Impute NaNs with mean\nfillWithMean = ['loan_amnt','funded_amnt','funded_amnt_inv','term', \\\n                'int_rate','installment','emp_length','annual_inc',\\\n                'dti','open_acc','revol_bal','revol_util','total_acc',\\\n                'out_prncp','out_prncp_inv','total_pymnt', \\\n                'total_pymnt_inv','total_rec_prncp','total_rec_int', \\\n                'last_pymnt_amnt']\n\n# Impute NaNs with zero\nfillWithZero = ['delinq_2yrs','mths_since_last_delinq', \\\n                'mths_since_last_record','pub_rec','total_rec_late_fee', \\\n                'recoveries','collection_recovery_fee']\n\n# Perform imputation\nim = pp.Imputer(strategy='mean')\ndata.loc[:,fillWithMean] = im.fit_transform(data[fillWithMean])\n\ndata.loc[:,fillWithZero] = data.loc[:,fillWithZero].fillna(value=0,axis=1)\n```", "```py\nnumericalFeats = [x for x in data.columns if data[x].dtype != 'object']\n\nnanCounter = np.isnan(data.loc[:,numericalFeats]).sum()\nnanCounter\n```", "```py\nloan_amnt               0\nfunded_amnt             0\nfunded_amnt_inv         0\nterm                    0\nint_rate                0\ninstallment             0\nemp_length              0\nannual_inc              0\ndti                     0\ndelinq_2yrs             0\nmths_since_last_delinq  0\nmths_since_last_record  0\nopen_acc                0\npub_rec                 0\nrevol_bal               0\nrevol_util              0\ntotal_acc               0\nout_prncp               0\nout_prncp_inv           0\ntotal_pymnt             0\ntotal_pymnt_inv         0\ntotal_rec_prncp         0\ntotal_rec_int           0\ntotal_rec_late_fee      0\nrecoveries              0\ncollection_recovery_fee 0\nlast_pymnt_amnt         0\ndtype: int64\n```", "```py\n# Feature engineering\ndata['installmentOverLoanAmnt'] = data.installment/data.loan_amnt\ndata['loanAmntOverIncome'] = data.loan_amnt/data.annual_inc\ndata['revol_balOverIncome'] = data.revol_bal/data.annual_inc\ndata['totalPymntOverIncome'] = data.total_pymnt/data.annual_inc\ndata['totalPymntInvOverIncome'] = data.total_pymnt_inv/data.annual_inc\ndata['totalRecPrncpOverIncome'] = data.total_rec_prncp/data.annual_inc\ndata['totalRecIncOverIncome'] = data.total_rec_int/data.annual_inc\n\nnewFeats = ['installmentOverLoanAmnt','loanAmntOverIncome', \\\n            'revol_balOverIncome','totalPymntOverIncome', \\\n           'totalPymntInvOverIncome','totalRecPrncpOverIncome', \\\n            'totalRecIncOverIncome']\n```", "```py\n# Select features for training\nnumericalPlusNewFeats = numericalFeats+newFeats\nX_train = data.loc[:,numericalPlusNewFeats]\n\n# Scale data\nsX = pp.StandardScaler()\nX_train.loc[:,:] = sX.fit_transform(X_train)\n```", "```py\nlabels = data.grade\nlabels.unique()\n```", "```py\narray(['B', 'C', 'A', 'E', 'F', 'D', 'G', nan], dtype=object)\n```", "```py\n# Fill missing labels\nlabels = labels.fillna(value=\"Z\")\n\n# Convert labels to numerical values\nlbl = pp.LabelEncoder()\nlbl.fit(list(labels.values))\nlabels = pd.Series(data=lbl.transform(labels.values), name=\"grade\")\n\n# Store as y_train\ny_train = labels\n\nlabelsOriginalVSNew = pd.concat([labels, data.grade],axis=1)\nlabelsOriginalVSNew\n```", "```py\n# Compare loan grades with interest rates\ninterestAndGrade = pd.DataFrame(data=[data.int_rate,labels])\ninterestAndGrade = interestAndGrade.T\n\ninterestAndGrade.groupby(\"grade\").mean()\n```", "```py\ndef analyzeCluster(clusterDF, labelsDF):\n    countByCluster = \\\n        pd.DataFrame(data=clusterDF['cluster'].value_counts())\n    countByCluster.reset_index(inplace=True,drop=False)\n    countByCluster.columns = ['cluster','clusterCount']\n\n    preds = pd.concat([labelsDF,clusterDF], axis=1)\n    preds.columns = ['trueLabel','cluster']\n\n    countByLabel = pd.DataFrame(data=preds.groupby('trueLabel').count())\n\n    countMostFreq = pd.DataFrame(data=preds.groupby('cluster').agg( \\\n        lambda x:x.value_counts().iloc[0]))\n    countMostFreq.reset_index(inplace=True,drop=False)\n    countMostFreq.columns = ['cluster','countMostFrequent']\n\n    accuracyDF = countMostFreq.merge(countByCluster, \\\n        left_on=\"cluster\",right_on=\"cluster\")\n\n    overallAccuracy = accuracyDF.countMostFrequent.sum()/ \\\n        accuracyDF.clusterCount.sum()\n\n    accuracyByLabel = accuracyDF.countMostFrequent/ \\\n        accuracyDF.clusterCount\n\n    return countByCluster, countByLabel, countMostFreq, \\\n        accuracyDF, overallAccuracy, accuracyByLabel\n```", "```py\nfrom sklearn.cluster import KMeans\n\nn_clusters = 10\nn_init = 10\nmax_iter = 300\ntol = 0.0001\nrandom_state = 2018\nn_jobs = 2\n\nkmeans = KMeans(n_clusters=n_clusters, n_init=n_init, \\\n                max_iter=max_iter, tol=tol, \\\n                random_state=random_state, n_jobs=n_jobs)\n\nkMeans_inertia = pd.DataFrame(data=[],index=range(10,31), \\\n                              columns=['inertia'])\n\noverallAccuracy_kMeansDF = pd.DataFrame(data=[], \\\n    index=range(10,31),columns=['overallAccuracy'])\n\nfor n_clusters in range(10,31):\n    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, \\\n                    max_iter=max_iter, tol=tol, \\\n                    random_state=random_state, n_jobs=n_jobs)\n\n    kmeans.fit(X_train)\n    kMeans_inertia.loc[n_clusters] = kmeans.inertia_\n    X_train_kmeansClustered = kmeans.predict(X_train)\n    X_train_kmeansClustered = pd.DataFrame(data= \\\n        X_train_kmeansClustered, index=X_train.index, \\\n        columns=['cluster'])\n\n    countByCluster_kMeans, countByLabel_kMeans, \\\n    countMostFreq_kMeans, accuracyDF_kMeans, \\\n    overallAccuracy_kMeans, accuracyByLabel_kMeans = \\\n    analyzeCluster(X_train_kmeansClustered, y_train)\n\n    overallAccuracy_kMeansDF.loc[n_clusters] = \\\n        overallAccuracy_kMeans\n\noverallAccuracy_kMeansDF.plot()\n```", "```py\n0      0.326633\n1      0.258993\n2      0.292240\n3      0.234242\n4      0.388794\n5      0.325654\n6      0.303797\n7      0.762116\n8      0.222222\n9      0.391381\n10     0.292910\n11     0.317533\n12     0.206897\n13     0.312709\n14     0.345233\n15     0.682208\n16     0.327250\n17     0.366605\n18     0.234783\n19     0.288757\n20     0.500000\n21     0.375466\n22     0.332203\n23     0.252252\n24     0.338509\n25     0.232000\n26     0.464418\n27     0.261583\n28     0.376327\n29     0.269129\ndtype: float64\n```", "```py\nimport fastcluster\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cophenet\nfrom scipy.spatial.distance import pdist\n\nZ = fastcluster.linkage_vector(X_train, method='ward', \\\n                               metric='euclidean')\n\nZ_dataFrame = pd.DataFrame(data=Z,columns=['clusterOne', \\\n                'clusterTwo','distance','newClusterSize'])\n```", "```py\nfrom scipy.cluster.hierarchy import fcluster\ndistance_threshold = 100\nclusters = fcluster(Z, distance_threshold, criterion='distance')\nX_train_hierClustered = pd.DataFrame(data=clusters,\n index=X_train_PCA.index,columns=['cluster'])\n\nprint(\"Number of distinct clusters: \",\n len(X_train_hierClustered['cluster'].unique()))\n```", "```py\ncountByCluster_hierClust, countByLabel_hierClust, countMostFreq_hierClust,\n accuracyDF_hierClust, overallAccuracy_hierClust, accuracyByLabel_hierClust =\n analyzeCluster(X_train_hierClustered, y_train)\nprint(\"Overall accuracy from hierarchical clustering: \",\n overallAccuracy_hierClust)\n```", "```py\nOverall accuracy from hierarchical clustering: 0.3651685393258427\n```", "```py\nAccuracy by cluster for hierarchical clustering\n\n0      0.304124\n1      0.219001\n2      0.228311\n3      0.379722\n4      0.240064\n5      0.272011\n6      0.314560\n7      0.263930\n8      0.246138\n9      0.318942\n10     0.302752\n11     0.269772\n12     0.335717\n13     0.330403\n14     0.346320\n15     0.440141\n16     0.744155\n17     0.502227\n18     0.294118\n19     0.236111\n20     0.254727\n21     0.241042\n22     0.317979\n23     0.308771\n24     0.284314\n25     0.243243\n26     0.500000\n27     0.289157\n28     0.365283\n29     0.479693\n30     0.393559\n31     0.340875\n```", "```py\nimport hdbscan\n\nmin_cluster_size = 20\nmin_samples = 20\nalpha = 1.0\ncluster_selection_method = 'leaf'\n\nhdb = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, \\\n    min_samples=min_samples, alpha=alpha, \\\n    cluster_selection_method=cluster_selection_method)\n\nX_train_hdbscanClustered = hdb.fit_predict(X_train)\nX_train_hdbscanClustered = pd.DataFrame(data= \\\n    X_train_hdbscanClustered, index=X_train.index, \\\n    columns=['cluster'])\n\ncountByCluster_hdbscan, countByLabel_hdbscan, \\\n    countMostFreq_hdbscan, accuracyDF_hdbscan, \\\n    overallAccuracy_hdbscan, accuracyByLabel_hdbscan = \\\n    analyzeCluster(X_train_hdbscanClustered, y_train)\n```", "```py\nOverall accuracy from HDBSCAN: 0.3246203751586667\n```", "```py\n0       0.284487\n1       0.341667\n2       0.414234\n3       0.332061\n4       0.552632\n5       0.438551\n6       0.400000\n7       0.408163\n8       0.590663\n```"]