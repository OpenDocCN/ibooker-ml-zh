<html><head></head><body><section data-pdf-bookmark="Chapter 18. What&#x2019;s Next for Recs?" data-type="chapter" epub:type="chapter"><div class="chapter" id="FinalComments">&#13;
<h1><span class="label">Chapter 18. </span>What’s Next for Recs?</h1>&#13;
&#13;
&#13;
<p>We find ourselves in a transitionary time for recommendation systems. However, this is quite normal for this field, as it is in many segments of the tech industry. One of the realities of a field that is so closely aligned with business objectives and with such strong capabilities for business value is that the field tends to be constantly searching for any and all opportunities to advance.</p>&#13;
&#13;
<p>In this chapter, we’ll briefly introduce some of the modern views of where recommendation systems are going. An important point to consider is that recommendation systems as a science spread both depth first and breadth first simultaneously. Looking at the most cutting-edge research in the field means that you’re seeing deep optimization in areas that have been under study for decades or areas that seem like pure fantasy for now.<a data-primary="CF" data-see="collaborative filtering" data-type="indexterm" id="id1227"/><a data-primary="logging" data-see="also data collection and user logging" data-type="indexterm" id="id1228"/><a data-primary="collection" data-see="data collection and user logging" data-type="indexterm" id="id1229"/><a data-primary="recommendation systems" data-secondary="content based" data-see="content-based recommender" data-type="indexterm" id="id1230"/><a data-primary="MF" data-see="matrix factorization" data-type="indexterm" id="id1231"/><a data-primary="monitoring" data-see="alerting and monitoring" data-type="indexterm" id="id1232"/><a data-primary="big data frameworks" data-see="also PySpark" data-type="indexterm" id="id1233"/><a data-primary="recommendation systems" data-secondary="feature-based" data-see="feature-based recommendations" data-type="indexterm" id="id1234"/><a data-primary="SVD" data-see="singular value decomposition" data-type="indexterm" id="id1235"/><a data-primary="metrics" data-see="also ranking metrics" data-type="indexterm" id="id1236"/><a data-primary="training" data-see="also continuous training and deployment; ranking training" data-type="indexterm" id="id1237"/><a data-primary="development environment" data-see="environments" data-type="indexterm" id="id1238"/><a data-primary="ratings" data-see="also user-item ratings" data-type="indexterm" id="id1239"/><a data-primary="rank reduction" data-see="dimensionality reduction" data-type="indexterm" id="id1240"/></p>&#13;
&#13;
<p>We’ve chosen three areas to focus on in this final chapter. The first you’ve seen a bit of throughout this text: multimodal recommendations. This area is increasingly important as users turn to platforms to do more things. Recall that multimodal recommendations occur when a user is represented by several latent vectors simultaneously.</p>&#13;
&#13;
<p>Next up is graph-based recommenders. We’ve discussed co-occurrence models, which are the simplest such models for graph-based recommendation systems. They go much deeper! GNNs are becoming an incredibly powerful mechanism for encoding relations between entities and utilizing these representations, making them useful for recommendations.</p>&#13;
&#13;
<p>Finally, we’ll turn our attention to large language models and generative AI. During the writing of this book, LLMs have gone from something that a small subset of ML experts understood to something mentioned on HBO comedy broadcasts. While a rush is occurring to find relevant applications of LLMs to recommendation systems, the industry already has confidence in applying these tools in certain ways. Also exciting, however, is the application of recommendation systems to LLM apps.</p>&#13;
&#13;
<p>Let’s see what’s coming next!</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Multimodal Recommendations" data-type="sect1"><div class="sect1" id="id183">&#13;
<h1>Multimodal Recommendations</h1>&#13;
&#13;
<p><em>Multimodal recommenders</em> allow<a data-primary="multimodal recommendations" data-type="indexterm" id="id1241"/><a data-primary="recommendation systems" data-secondary="multimodal recommendations" data-type="indexterm" id="id1242"/> for the concession that <em>users contain multitudes</em>: a single representation for a user’s preferences may not capture the entire story. Someone shopping on a large everything-ecommerce website, for example, may be all of the following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>A dog owner who frequently needs items for their dog</p>&#13;
</li>&#13;
<li>&#13;
<p>A parent who is always updating the closet for the growing baby</p>&#13;
</li>&#13;
<li>&#13;
<p>A hobbyist race-car driver who buys the pieces necessary to drive their car on a track</p>&#13;
</li>&#13;
<li>&#13;
<p>A LEGO investor who keeps hundreds of sealed boxes of Star Wars sets hidden away in the closet</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The methods you’ve learned throughout this book should do well at providing recommendations for all of these users. However, you may notice in this list a few areas that are conflicting:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>If your child is very young, why do you buy LEGO sets already? Also, doesn’t your dog chew on them?</p>&#13;
</li>&#13;
<li>&#13;
<p>If your garage is full of LEGO sets, where do you keep all these car parts?</p>&#13;
</li>&#13;
<li>&#13;
<p>Where do you put your dog in that two-seater Mazdaspeed MX-5 Miata?</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>You can probably think of other cases where some aspects of what you buy just don’t match up well with others. This leads to a problem of multimodality: several places in the latent space of your interests coalesce into modes or medoids, but not only one.</p>&#13;
&#13;
<p>Let’s return to some of our geometric discussions from before: if you are using nearest neighbors to a user vector, then which of the medoids will take on the most importance?</p>&#13;
&#13;
<p>The way we approach this problem is by multimodality, or providing several vectors associated to a single user. While a naive approach to scaling to consider all the modes for a user would be to simply increase the dimensionality of the model on the item side (to create more areas in which different types of items can be embedded disjointly), this presents serious challenges at scale in terms of training and memory concerns.</p>&#13;
&#13;
<p>One of the first significant works in this area is coauthored by one of this book’s authors and introduces an extension to MF to deal with this; see <a href="https://oreil.ly/OkzmZ">“Nonlinear Latent Factorization by Embedding Multiple User Interests”</a>  by Jason Weston et al. The goal is to build multiple latent factors simultaneously as we did in our other matrix factorization methods, each factor hopefully taking on representation for one of the user’s interests.</p>&#13;
&#13;
<p>This is achieved by constructing a tensor that has its third tensor dimension represent each of the latent factors for distinct interests rather than encoding a user item factorization matrix. The factorization is generalized to the tensor case, and the WSABIE loss you saw earlier is used to train.</p>&#13;
&#13;
<p>Building on this work, several years later Pinterest released<a data-primary="PinnerSage paper" data-type="indexterm" id="id1243"/> PinnerSage, as we mentioned in <a data-type="xref" href="ch15.html#Diversity">Chapter 15</a>. This modifies some of the assumptions of the Weston et al. paper, by not assuming a known number of representations for each user. Additionally, this approach uses graph-based feature representations, which we’ll talk more about in the next section. Finally, the last important modification that this method uses is clustering: it attempts to build the modes via clustering in item space.</p>&#13;
&#13;
<p>The basic PinnerSage approach is to do the following:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Fix item embeddings (they call these <em>pins</em>).</p>&#13;
</li>&#13;
<li>&#13;
<p>Cluster user interactions (unsupervised and unspecified in cardinality).</p>&#13;
</li>&#13;
<li>&#13;
<p>Build cluster representations as the medoid of the cluster embeddings.</p>&#13;
</li>&#13;
<li>&#13;
<p>Retrieve using medoid-anchored ANN search.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>PinnerSage is still considered to be near state of the art for large-scale multimodal recommenders. Some systems take another approach to allow users to more directly modify their “mode” by selecting the theme of what they’re looking for, while others hope to learn it from a sequence of interactions.</p>&#13;
&#13;
<p>Next up, we’ll look at how higher-order relationships between items or users can be explicitly specified.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Graph-Based Recommenders" data-type="sect1"><div class="sect1" id="id184">&#13;
<h1>Graph-Based Recommenders</h1>&#13;
&#13;
<p><em>Graph neural networks</em> (GNNs) are<a data-primary="graph neural networks (GNNs)" data-type="indexterm" id="gnn18"/><a data-primary="recommendation systems" data-secondary="graph-based recommenders" data-type="indexterm" id="RSgraph18"/> a class of neural networks that use the structural information of data to build deeper representations of your data. They’ve proven especially useful when dealing with relational or networked data, both of which have utility.</p>&#13;
&#13;
<p class="less_space pagebreak-before">One moment of disambiguation before we continue: <em>graphs</em> in the sense that we will use them here refer to collections of<a data-primary="nodes" data-type="indexterm" id="id1244"/><a data-primary="edges" data-type="indexterm" id="id1245"/> <em>nodes</em> and <em>edges</em>. These are purely mathematical concepts, but generally we can think of nodes as the objects of interest and edges as the relationships between them. These mathematical objects are useful for distilling down the core of what is necessary for the kind of representation you wish to build. While the objects may seem very simple, we can add just the right amount of complexity in a variety of ways to capture more nuance.</p>&#13;
&#13;
<p>In the simplest setups, each node on the graph represents an item or user, and each edge represents a relationship such as a user’s interaction with an item. However, user-to-user and item-to-item networks are extremely powerful extensions as well. Our co-occurrence models are simple graph networks; however, we did not learn a representation from these and instead directly took these as our models.</p>&#13;
&#13;
<p>Let’s consider a few examples of adding more structure to a graph to encode ideas:</p>&#13;
<dl>&#13;
<dt>Directionality</dt>&#13;
<dd>&#13;
<p>This<a data-primary="directionality" data-type="indexterm" id="id1246"/> ordering on an edge’s vertices can be added to indicate a strict relationship of one node acting on the other; e.g., a user <em>reads</em> a book but not the other way around.</p>&#13;
</dd>&#13;
<dt>Edge decorations</dt>&#13;
<dd>&#13;
<p>Descriptors<a data-primary="edge decorations" data-type="indexterm" id="id1247"/> such as edge labels can be added to communicate features about the relationships; e.g., two users share account credentials, <em>and one of the users is identified as a child</em>.</p>&#13;
</dd>&#13;
<dt>Multiedges</dt>&#13;
<dd>&#13;
<p>These<a data-primary="multiedges" data-type="indexterm" id="id1248"/> can allow for relationships to have higher multiplicity, or allow for the same two entities to have multiple relationships. In a graph of outfits with clothing items as nodes, each edge can be another clothing item that makes the other two go well together.</p>&#13;
</dd>&#13;
<dt>Hyper-edges</dt>&#13;
<dd>&#13;
<p>A<a data-primary="hyper-edges" data-type="indexterm" id="id1249"/> step further up the level of abstraction may add these edges, which connect multiple nodes simultaneously. For video scenes, you may detect objects of various classes, and your graph may have nodes for those classes, but understanding not only which pairs of object classes appear but which higher-order combinations appear can be identified with hyper-edges.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Let’s explore the basics of GNNs and how their representations are a bit different.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Neural Message Passing" data-type="sect2"><div class="sect2" id="id185">&#13;
<h2>Neural Message Passing</h2>&#13;
&#13;
<p>In GNNs our object of interest is assigned as the nodes in our graph. Usually, the main objective in GNNs is to build powerful representations of the nodes and edges, or both, via their relationships.</p>&#13;
&#13;
<p>The fundamental difference between GNNs and traditional neural networks is that during the training, we’re explicitly using operators that transfer data between node representations “along the edges.” This is called<a data-primary="message passing" data-type="indexterm" id="id1250"/> <em>message passing</em>. Let’s start with an example to prime the basic idea.</p>&#13;
&#13;
<p>Let nodes represent users, and their features are persona details such as demographic, onboarding survey question, etc. Let edges be the social network graph: are they friends? And let’s add decoration to the edges, such as the number of DMs exchanged between them on the platform. If we are the social media company that wants to introduce ad shopping to our platform, we may start with those persona features, but we’d ideally like to use something about this network of communication. In theory, people who communicate and share content with each other a lot may have similar tastes. Somewhat tellingly, we introduce a concept called a<a data-primary="message function" data-type="indexterm" id="id1251"/> <em>message function</em>, which allows features to be sent from node to node. The message function uses features from each node and the edge between them, written mathematically as follows, for <math alttext="h Subscript i Superscript left-parenthesis k right-parenthesis">&#13;
  <msubsup><mi>h</mi> <mi>i</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msubsup>&#13;
</math> the features at node <math alttext="i">&#13;
  <mi>i</mi>&#13;
</math> and <math alttext="h Subscript j Superscript left-parenthesis k right-parenthesis">&#13;
  <msubsup><mi>h</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msubsup>&#13;
</math> at node <math alttext="j">&#13;
  <mi>j</mi>&#13;
</math>, respectively:</p>&#13;
<div data-type="equation">&#13;
<math alttext="m Subscript i j Superscript left-parenthesis k right-parenthesis Baseline equals script upper M left-parenthesis h Subscript i Superscript left-parenthesis k right-parenthesis Baseline comma h Subscript j Superscript left-parenthesis k right-parenthesis Baseline comma e Subscript i j Baseline right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <msubsup><mi>m</mi> <mrow><mi>i</mi><mi>j</mi></mrow> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msubsup>&#13;
    <mo>=</mo>&#13;
    <mi>ℳ</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msubsup><mi>h</mi> <mi>i</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msubsup>&#13;
      <mo>,</mo>&#13;
      <msubsup><mi>h</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msubsup>&#13;
      <mo>,</mo>&#13;
      <msub><mi>e</mi> <mrow><mi>i</mi><mi>j</mi></mrow> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>The features of the edge are <math alttext="e Subscript i j">&#13;
  <msub><mi>e</mi> <mrow><mi>i</mi><mi>j</mi></mrow> </msub>&#13;
</math> and <math alttext="script upper M">&#13;
  <mi>ℳ</mi>&#13;
</math> is some differentiable function. Note that the superscript <math alttext="Superscript left-parenthesis k right-parenthesis">&#13;
  <msup><mphantom/> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msup>&#13;
</math> refers to the layer as is standard in back-prop notation. Here are two simple examples:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><math alttext="m Subscript i j Superscript left-parenthesis k right-parenthesis Baseline equals h Subscript i Superscript left-parenthesis k right-parenthesis">&#13;
  <mrow>&#13;
    <msubsup><mi>m</mi> <mrow><mi>i</mi><mi>j</mi></mrow> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msubsup>&#13;
    <mo>=</mo>&#13;
    <msubsup><mi>h</mi> <mi>i</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msubsup>&#13;
  </mrow>&#13;
</math> means “take the features from a neighbor node”</p>&#13;
</li>&#13;
<li>&#13;
<p><math alttext="m Subscript i j Superscript left-parenthesis k right-parenthesis Baseline equals StartFraction h Subscript i Superscript left-parenthesis k right-parenthesis Baseline Over c Subscript i j Baseline EndFraction">&#13;
  <mrow>&#13;
    <msubsup><mi>m</mi> <mrow><mi>i</mi><mi>j</mi></mrow> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msubsup>&#13;
    <mo>=</mo>&#13;
    <mstyle displaystyle="true" scriptlevel="0">&#13;
      <mfrac><msubsup><mi>h</mi> <mi>i</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msubsup> <msub><mi>c</mi> <mrow><mi>i</mi><mi>j</mi></mrow> </msub></mfrac>&#13;
    </mstyle>&#13;
  </mrow>&#13;
</math> means “average by the number of edges between <em>i</em> and <em>j</em>"</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Many powerful message-passing schemes that use learning use approaches from other areas of ML—like adding an attention mechanism on node features—but this book doesn’t dive deep into this theory.</p>&#13;
&#13;
<p>The next function we’ll introduce is the<a data-primary="aggregation function" data-type="indexterm" id="id1252"/> <em>aggregation function</em>, which takes as input the collection of messages and aggregates them. The most common types of aggregation functions do the following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Concatenate all the messages</p>&#13;
</li>&#13;
<li>&#13;
<p>Sum all the messages</p>&#13;
</li>&#13;
<li>&#13;
<p>Average all the messages</p>&#13;
</li>&#13;
<li>&#13;
<p>Take the max of the messages</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Finally, we will use the output of the aggregation as part of our update function, which takes node features and aggregated message functions and then applies additional transformations. If you’ve been wondering, “Where does this model learn anything?” the answer is in the update function. The update function usually has a weight matrix associated to it, so as you train this neural network, you are learning the weights in the update function. The simplest update functions multiply a weight matrix by the vectorized output of your aggregation and then apply an activation function per vector.</p>&#13;
&#13;
<p>This chain of message passing, aggregating, and updating is the core of GNNs and encompasses a broad capability. They’ve been useful for ML tasks of every kind, including recommendations. Let’s see some direct applications to recommendation systems.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Applications" data-type="sect2"><div class="sect2" id="id322">&#13;
<h2>Applications</h2>&#13;
&#13;
<p>Let’s revisit some of the high-level ideas that GNNs may touch in the RecSys space.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Modeling user-item interactions" data-type="sect3"><div class="sect3" id="id234">&#13;
<h3>Modeling user-item interactions</h3>&#13;
&#13;
<p>In<a data-primary="user-item ratings" data-secondary="GNNs for" data-type="indexterm" id="id1253"/> other methods we’ve presented, such as matrix factorization, the interactions between users and items are considered, but the complex network among users or items is not exploited. In contrast, GNNs can capture the complex connections in the user-item interaction graph and then use the structure of this graph to make more accurate recommendations.</p>&#13;
&#13;
<p>Thinking back to our message passing, it allowed us to “spread” the information of some nodes (in this case, user and items) to their neighbors. An analogy for this would be that as a user interacts more and more with items with specific features, some of those features are imbued onto the user. This may sound similar to latent features, because it is! These are ultimately helping the network build a latent representation from the messages that pass features from items to user. This can be even more powerful than other latent embedding methods, because you explicitly define the structural relationships  and how they communicate these features.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Feature learning" data-type="sect3"><div class="sect3" id="id186">&#13;
<h3>Feature learning</h3>&#13;
&#13;
<p>GNNs<a data-primary="feature augmentation/engineering" data-type="indexterm" id="id1254"/> can learn more expressive feature representations of nodes (users or items) in a graph by aggregating feature information from their neighbors, leveraging the connections between nodes. These learned features can provide rich information about users’ preferences or items’ characteristics, which can greatly enhance the performance of recommendation systems.</p>&#13;
&#13;
<p class="less_space pagebreak-before">Previously, we talked about how a user’s representations can learn from the items they interact with, but items can also learn from one another. Similar to the way item-item collaborative filtering (CF) allows items to pick up latent features from shared users, GNNs allow us to add potentially many other direct relationships between items.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Cold-start problem" data-type="sect3"><div class="sect3" id="id187">&#13;
<h3>Cold-start problem</h3>&#13;
&#13;
<p>Recall<a data-primary="cold starting" data-type="indexterm" id="id1255"/> our cold-start problem: providing recommendations for new users or items is difficult because of the lack of historical interactions. By using the features of nodes and the structure of the graph, GNNs can learn the embeddings for new users or items, potentially alleviating the cold-start problem.</p>&#13;
&#13;
<p>In some of our graphical representations of our user graph, the edges need not only exist between users with lots of prior recommendations. It’s possible to use other user actions to <em>bootstrap</em> some early edges. Structural edges like “share a physical location” or “invited by the same user” or “answers onboarding questions similarly” can be enough to quickly bootstrap several user-user edges, which allow us to warm-start recommendations for them.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Context-aware recommendations" data-type="sect3"><div class="sect3" id="id235">&#13;
<h3>Context-aware recommendations</h3>&#13;
&#13;
<p>GNNs<a data-primary="context" data-secondary="context-aware recommendations" data-type="indexterm" id="id1256"/> can incorporate contextual information into the recommendation process. For example, in a session-based recommendation, a GNN can model the sequence of items a user has interacted with in a session as a graph, where each item is a node and the sequential order forms edges. The GNN can then learn the dynamic and complex transitions among items to make context-aware recommendations.</p>&#13;
&#13;
<p>These high-level ideas should point to the opportunity in graph encoding for recommender problems, but let’s look at two specific applications next: random walks and metapaths.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Random Walks" data-type="sect2"><div class="sect2" id="id188">&#13;
<h2>Random Walks</h2>&#13;
&#13;
<p>Random walks<a data-primary="random-walk-based algorithms" data-type="indexterm" id="id1257"/> in GNNs enable methods to use the user-item interaction graph to learn effective node (i.e., user or item) embeddings. The embeddings are then used to make recommendations. In the context of graphs, a random walk is an iterative process of starting on a particular node and then stochastically moving to another connected node via a randomized choice.</p>&#13;
&#13;
<p>One popular random-walk-based algorithm for network embedding is<a data-primary="DeepWalk algorithm" data-type="indexterm" id="id1258"/> DeepWalk, which has been adapted and extended in many ways for various tasks, including recommendation systems.</p>&#13;
&#13;
<p class="less_space pagebreak-before">Here’s how a random-walk GNN approach might work in a recommendation context:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Random walks generation: start by performing random walks on the interaction graph. Starting from each node, make a series of random steps to other connected nodes. This results in a set of paths, or “walks,” that represent the relationships between different nodes.</p>&#13;
</li>&#13;
<li>&#13;
<p>Node embeddings: the sequences of nodes generated by the random walks are treated similar to sentences in a corpus of text, and each node is treated like a word. Word2vec or similar language-modeling techniques are then used to learn embeddings for the nodes (vector representations), such that nodes appearing in similar contexts (in the same walks) have similar embeddings.</p>&#13;
</li>&#13;
<li>&#13;
<p>Recommendations: once you have learned node embeddings, you can use them to make recommendations. For a given user, you might recommend items that are “close” to that user in the embedding space, according to a distance metric. This can use all the techniques we’ve previously developed for recommendations from latent space representations.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>This approach has some nice properties:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>It can capture the high-order connections in the graph. Each random walk can explore a part of the graph that’s not directly connected to the starting node.</p>&#13;
</li>&#13;
<li>&#13;
<p>It can help with the sparsity problem in recommender systems because it uses the graph’s structure to learn representations, which requires less interaction data.</p>&#13;
</li>&#13;
<li>&#13;
<p>It naturally attempts to handle cold-start issues. For new users or items with few interactions, their embeddings can be learned from connected nodes.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Nevertheless, this approach has some challenges. Random walks can be computationally expensive on large graphs, and it might be difficult to choose appropriate hyperparameters, such as the length of the random walks. Also, this approach may not work as well for dynamic graphs, where interactions change over time, since it doesn’t inherently consider temporal information.</p>&#13;
&#13;
<p>This method implicitly assumes that the nodes are heterogeneous, and so co-embedding them via connections is natural. While it was not an explicit requirement, the type of sequence embeddings DeepWalk builds tends to structurally assume this. Let’s break this rule to accommodate learning between heterogeneous types in our next architecture example, metapaths.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="Metapath and Heterogeneity" data-type="sect2"><div class="sect2" id="id189">&#13;
<h2>Metapath and Heterogeneity</h2>&#13;
&#13;
<p><a href="https://oreil.ly/pZIkC">Metapath</a><a data-primary="metapath" data-type="indexterm" id="id1259"/> was introduced to improve explainable recommendations and integrate the ideas of knowledge graphs with GNNs.</p>&#13;
&#13;
<p>A <em>metapath</em> is a path in a heterogeneous network (or graph) that connects different types of nodes via different types of relationships. Heterogeneous networks contain various types of nodes and edges, representing multiple types of objects and interactions. Beyond simply users and items, the node types can be “carts of items” or “viewing sessions” or “channel used for purchase.”</p>&#13;
&#13;
<p>Metapaths can be used in GNNs for handling<a data-primary="heterogeneous information networks (HINs)" data-type="indexterm" id="id1260"/><a data-primary="HINs (heterogeneous information networks)" data-type="indexterm" id="id1261"/> heterogeneous information networks (HINs). These networks provide a more comprehensive representation of the real world. When used in a GNN, a metapath provides a scheme for the way information should be aggregated and propagated through the network. It defines the type of paths to be considered when pooling information from a node’s neighborhood.</p>&#13;
&#13;
<p>For example, in a recommender system, you might have a heterogeneous network with users, movies, and genres as node types, and “watches” and “belongs to” as edge types. A metapath could be defined as “User - watches → Movie - belongs to → Genre - belongs to → Movie - watches → User.” This metapath represents a way of connecting two users through the movies they watch and the genres of those movies.</p>&#13;
&#13;
<p>A popular method that utilizes metapaths is the heterogeneous GNN (Hetero-GNN) and its variants. These models leverage the metapath concept to capture the rich semantics in HINs, enhancing the learning of node representations.</p>&#13;
&#13;
<p>Metapath-based models have shown promising results in various applications, as they allow you to explicitly encode much more abstract relationships into the message-passing mechanisms we’ve mentioned.</p>&#13;
&#13;
<p>If higher-order modeling is your thing, buckle up for the last concept we’ll cover in this book. This topic is state of the art and full of high-level abstractions. Language-model-backed agents are at the absolute cutting edge of ML modeling.<a data-primary="" data-startref="RSgraph18" data-type="indexterm" id="id1262"/><a data-primary="" data-startref="gnn18" data-type="indexterm" id="id1263"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="LLM Applications" data-type="sect1"><div class="sect1" id="id236">&#13;
<h1>LLM Applications</h1>&#13;
&#13;
<p>All<a data-primary="large language models (LLMs)" data-secondary="basics of" data-type="indexterm" id="id1264"/><a data-primary="LLMs" data-see="large language models" data-type="indexterm" id="id1265"/> of the superlatives for LLMs have been used up. For that reason, we’ll just say this: LLMs are powerful and have a surprisingly large number of applications.</p>&#13;
&#13;
<p>LLMs are general models that allow users to interact with them via natural language. Fundamentally, these models are generative (they write text) and auto-regressive (what they write is determined by what came before). Because LLMs can speak conversationally, they’ve been branded as general artificial <em>agents</em>. It’s natural to then ask, “Can an agent recommend things for me?” Let’s start by examining how to use an LLM to make recommendations.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="LLM Recommenders" data-type="sect2"><div class="sect2" id="id237">&#13;
<h2>LLM Recommenders</h2>&#13;
&#13;
<p>Natural language<a data-primary="large language models (LLMs)" data-secondary="recommenders using" data-type="indexterm" id="id1266"/> is a wonderful interface to ask for recommendations. If you want a coworker’s recommendation for lunch, maybe you’ll show up at their desk and say nothing—hoping they’ll remember their latent knowledge of your preferences, identify the time-of-day context, recall the availability of restaurants based on day-of-week, and keep in mind that yesterday you had a pastrami sandwich.</p>&#13;
&#13;
<p>More effectively, you could simply ask, “Any suggestions for lunch?”</p>&#13;
&#13;
<p>Like your astute coworker, models may be more effective at providing recommendations if you simply ask them to. This approach also adds the capability of defining more precisely the kind of recommendation you want. A popular application of LLMs is to ask them for recipes that use a set of ingredients. Thinking through this in the context of the kind of recommenders we’ve built, building a recommender of this kind has some hurdles. It probably needs some user modeling, but it’s very dependent on the items specified. This means that there’s a very low signal for each combination of specified items.</p>&#13;
&#13;
<p>An LLM, on the other hand, is quite effective at the autoregressive nature of this task: given a few ingredients, what’s most likely to be included next in the context of a recipe. By generating several items like this, a ranking model can augment this to provide a realistic recommender.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="LLM Training" data-type="sect2"><div class="sect2" id="id190">&#13;
<h2>LLM Training</h2>&#13;
&#13;
<p>Large generative language models<a data-primary="large language models (LLMs)" data-secondary="training" data-type="indexterm" id="LLMtrain18"/><a data-primary="training" data-secondary="large language models (LLMs)" data-type="indexterm" id="Tllms18"/> of the type that have exploded in popularity are trained in three stages:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Pretraining for completion</p>&#13;
</li>&#13;
<li>&#13;
<p>Supervised fine-tuning for dialogue</p>&#13;
</li>&#13;
<li>&#13;
<p>Reinforcement learning from human feedback</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>Sometimes the latter two steps are combined into what is called<a data-primary="InstructGPT paper" data-type="indexterm" id="id1267"/> <em>Instruct</em>. For an exceptionally deep dive into this topic, see the original InstructGPT paper <a href="https://oreil.ly/e-T2J">“Training Language Models to Follow Instructions with Human Feedback”</a> by Long Ouyang et al.</p>&#13;
&#13;
<p class="less_space pagebreak-before">Let’s recall that text-completion tasks are equivalent to training the model to predict the correct word in a sequence after seeing <em>k</em> previous ones. This may remind you of GloVe from <a data-type="xref" href="ch08.html#ch:wikipedia-e2e">Chapter 8</a>, or our discussion about sequential recommenders.</p>&#13;
&#13;
<p>Next up is fine-tuning for dialogue; this step is necessary to teach the model that the “next word or phrase” should sometimes be a response instead of an extension of the original statement.</p>&#13;
&#13;
<p>During<a data-primary="demonstration data" data-type="indexterm" id="id1268"/> this stage, the data used for this training is in the form of <em>demonstration data</em>, i.e., pairs of statements and responses. Examples include the following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>A request and then a response to that request</p>&#13;
</li>&#13;
<li>&#13;
<p>A statement and then a translation of that statement</p>&#13;
</li>&#13;
<li>&#13;
<p>A long text and then a summarization of that text</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>For recommendations, you can imagine that the first is highly relevant to the task we hope the model to demonstrate.</p>&#13;
&#13;
<p>Finally, we<a data-primary="human-in-the loop ML" data-type="indexterm" id="id1269"/><a data-primary="reinforcement learning from human feedback (RLHF)" data-type="indexterm" id="id1270"/><a data-primary="RLHF (reinforcement learning from human feedback)" data-type="indexterm" id="id1271"/> move to the reinforcement learning from human feedback (RLHF) stage; the goal here is to learn a reward function that we can later use to further optimize our LLM. However, the reward model <em>itself</em> needs to be trained. Interestingly for recommendation systems enthusiasts like yourself, AI engineers do this via a ranking dataset.</p>&#13;
&#13;
<p>A large number of tuples—similar to the demonstration data we’ve seen—provide statements and responses, although instead of only one response, there are multiple responses. They are ranked (via a human labeler), and then for each pair of superior-inferior responses <math alttext="left-parenthesis x comma s u p comma i n f right-parenthesis">&#13;
  <mrow>&#13;
    <mo>(</mo>&#13;
    <mi>x</mi>&#13;
    <mo>,</mo>&#13;
    <mi>s</mi>&#13;
    <mi>u</mi>&#13;
    <mi>p</mi>&#13;
    <mo>,</mo>&#13;
    <mi>i</mi>&#13;
    <mi>n</mi>&#13;
    <mi>f</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>, we evaluate the loss:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><math alttext="r Subscript s u p Baseline equals normal upper Theta left-parenthesis x comma s u p right-parenthesis">&#13;
  <mrow>&#13;
    <msub><mi>r</mi> <mrow><mi>s</mi><mi>u</mi><mi>p</mi></mrow> </msub>&#13;
    <mo>=</mo>&#13;
    <mi>Θ</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>x</mi>&#13;
      <mo>,</mo>&#13;
      <mi>s</mi>&#13;
      <mi>u</mi>&#13;
      <mi>p</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math> is the reward model’s score for the superior response.</p>&#13;
</li>&#13;
<li>&#13;
<p><math alttext="r Subscript i n f Baseline equals normal upper Theta left-parenthesis x comma i n f right-parenthesis">&#13;
  <mrow>&#13;
    <msub><mi>r</mi> <mrow><mi>i</mi><mi>n</mi><mi>f</mi></mrow> </msub>&#13;
    <mo>=</mo>&#13;
    <mi>Θ</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>x</mi>&#13;
      <mo>,</mo>&#13;
      <mi>i</mi>&#13;
      <mi>n</mi>&#13;
      <mi>f</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math> is the reward model’s score for the inferior response.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The final loss is computed: <math alttext="minus l o g left-parenthesis sigma left-parenthesis s u p minus i n f right-parenthesis right-parenthesis">&#13;
  <mrow>&#13;
    <mo>-</mo>&#13;
    <mi>l</mi>&#13;
    <mi>o</mi>&#13;
    <mi>g</mi>&#13;
    <mo>(</mo>&#13;
    <mi>σ</mi>&#13;
    <mo>(</mo>&#13;
    <mi>s</mi>&#13;
    <mi>u</mi>&#13;
    <mi>p</mi>&#13;
    <mo>-</mo>&#13;
    <mi>i</mi>&#13;
    <mi>n</mi>&#13;
    <mi>f</mi>&#13;
    <mo>)</mo>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>.</p>&#13;
&#13;
<p>This reward function is then used to fine-tune the model.</p>&#13;
&#13;
<p>OpenAI summarizes this approach via the diagram in <a data-type="xref" href="#fig-18-1">Figure 18-1</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig-18-1">&#13;
<img alt="Instruct methodology for model fine-tuning" src="assets/brpj_1801.png"/>&#13;
<h6><span class="label">Figure 18-1. </span>Instruct methodology for model fine-tuning</h6>&#13;
</div></figure>&#13;
&#13;
<p>From this brief overview, you can see that these LLMs are trained to respond to requests—something well suited for a recommender. Let’s see how to augment this training.<a data-primary="" data-startref="LLMtrain18" data-type="indexterm" id="id1272"/><a data-primary="" data-startref="Tllms18" data-type="indexterm" id="id1273"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Instruct Tuning for Recommendations" data-type="sect2"><div class="sect2" id="id238">&#13;
<h2>Instruct Tuning for Recommendations</h2>&#13;
&#13;
<p>In<a data-primary="large language models (LLMs)" data-secondary="Instruct tuning for recommendations" data-type="indexterm" id="id1274"/> the previous discussion of instruct pairs, we saw that ultimately the aim of the training was to learn a rank comparison between two responses. This kind of training should feel quite familiar. In <a href="https://oreil.ly/ViZCT">“TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation”</a> by Keqin Bao et al., the authors use a similar setup to teach user preferences to the model.</p>&#13;
&#13;
<p>As the paper mentions, historical interaction items are collected into two groups based on their ratings: user likes and user dislikes. They collect this information into natural language prompts to format a final “Rec Input”:</p>&#13;
<ol>&#13;
<li>&#13;
<p>User preference: <math alttext="left-bracket i t e m 1 comma period period period comma i t e m Subscript n Baseline">&#13;
  <mrow>&#13;
    <mo>[</mo>&#13;
    <mi>i</mi>&#13;
    <mi>t</mi>&#13;
    <mi>e</mi>&#13;
    <msub><mi>m</mi> <mn>1</mn> </msub>&#13;
    <mo>,</mo>&#13;
    <mo>.</mo>&#13;
    <mo>.</mo>&#13;
    <mo>.</mo>&#13;
    <mo>,</mo>&#13;
    <mi>i</mi>&#13;
    <mi>t</mi>&#13;
    <mi>e</mi>&#13;
    <msub><mi>m</mi> <mi>n</mi> </msub>&#13;
  </mrow>&#13;
</math>]</p>&#13;
</li>&#13;
<li>&#13;
<p>User preference: <math alttext="left-bracket i t e m 1 comma period period period comma i t e m Subscript n Baseline">&#13;
  <mrow>&#13;
    <mo>[</mo>&#13;
    <mi>i</mi>&#13;
    <mi>t</mi>&#13;
    <mi>e</mi>&#13;
    <msub><mi>m</mi> <mn>1</mn> </msub>&#13;
    <mo>,</mo>&#13;
    <mo>.</mo>&#13;
    <mo>.</mo>&#13;
    <mo>.</mo>&#13;
    <mo>,</mo>&#13;
    <mi>i</mi>&#13;
    <mi>t</mi>&#13;
    <mi>e</mi>&#13;
    <msub><mi>m</mi> <mi>n</mi> </msub>&#13;
  </mrow>&#13;
</math>]</p>&#13;
</li>&#13;
<li>&#13;
<p>Will the user enjoy the User preference, <math alttext="left-bracket i t e m Subscript n plus 1 Baseline">&#13;
  <mrow>&#13;
    <mo>[</mo>&#13;
    <mi>i</mi>&#13;
    <mi>t</mi>&#13;
    <mi>e</mi>&#13;
    <msub><mi>m</mi> <mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow> </msub>&#13;
  </mrow>&#13;
</math>]?</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>These follow the same training pattern as InstructGPT noted previously. The authors achieve dramatically improved performance on recommender problems as compared to an untrained LLM for recommendations; however, those should be considered baselines as it’s not their target task.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="LLM Rankers" data-type="sect2"><div class="sect2" id="id239">&#13;
<h2>LLM Rankers</h2>&#13;
&#13;
<p>So<a data-primary="large language models (LLMs)" data-secondary="rankers" data-type="indexterm" id="id1275"/><a data-primary="ranker" data-secondary="LLM rankers" data-type="indexterm" id="id1276"/> far in this chapter, we’ve thought of the LLM as a recommender in totality, but instead, the LLM can be used as simply the ranker. The most trivial approach to this is to simply prompt the LLM with the relevant features of a user and a list of items and ask it to suggest the best options.</p>&#13;
&#13;
<p>While naive, variants on this approach have seen somewhat surprising results in very generic settings: “The user wants to watch a scary movie tonight and isn’t sure which will be the best if he doesn’t like gore: movie-1, movie-2, etc.” But we can do better.</p>&#13;
&#13;
<p>Ultimately, as with LTR approaches, we can think of pointwise, pairwise, and listwise. If we wish to use an LLM for a pointwise ranking, we should constrain our prompting and responses to a setting in which these models may be useful. Take, for example, a recommender for scientific papers; a user may wish to write what they’re working on and have the LLM helpfully suggest papers of relevance. While a traditional search problem, this is a setting in which our modern tools can bring a lot of utility: LLMs are effective at summarizing and semantic matching, which means that semantically similar results may be found from a large corpus, and then the agent can synthesize the output of those results into a cogent response. The biggest challenge here is hallucination, or suggesting papers that may not exist.</p>&#13;
&#13;
<p>You can think of pairwise and listwise similarly: distilling the reference data into a shape that the unique capabilities of these LLMs can use to make significant assists.</p>&#13;
&#13;
<p>While we’re near the topic of search and retrieval, it’s important to mention one of the ways in which recommendation can help LLM applications: retrieval augmentation.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Recommendations for AI" data-type="sect2"><div class="sect2" id="id191">&#13;
<h2>Recommendations for AI</h2>&#13;
&#13;
<p>We’ve<a data-primary="large language models (LLMs)" data-secondary="recommendations for AI" data-type="indexterm" id="id1277"/><a data-primary="artificial intelligence (AI)" data-type="indexterm" id="id1278"/> seen how LLMs can be used to generate recommendations, but how do recommenders improve LLM applications? LLM agents are extremely general in their capabilities but lack specificity on many tasks. If you ask an agent, “Which of the books I read this year were written by nonwestern authors?” the agent has no chance of success. Fundamentally, this is because the general pretrained models have no idea what books you’ve read this year.</p>&#13;
&#13;
<p>To solve for this, you’ll want to leverage<a data-primary="retrieval" data-secondary="retrieval augmentation" data-type="indexterm" id="id1279"/> <em>retrieval augmentation</em>, i.e., providing relevant information to the model from an existing data store. The data store may be an SQL database, a lookup table, or a vector database, but ultimately the important component here is that somehow from your request, you’re able to find relevant information and then provide it to an agent.</p>&#13;
&#13;
<p>One assumption we’ve made here is that your request is interpretable by your retrieval system. In the preceding example, you’d like the system to automatically understand the “which of the books I read this year” phrase as an information-retrieval task equivalent to something like this:</p>&#13;
&#13;
<pre data-code-language="sql" data-type="programlisting"><code class="k">SELECT</code> <code class="o">*</code> <code class="k">FROM</code> <code class="n">read_books</code>&#13;
<code class="k">WHERE</code> <code class="k">CAST</code><code class="p">(</code><code class="n">finished_date</code><code class="p">,</code> <code class="k">YEAR</code><code class="p">)</code> <code class="o">=</code> <code class="k">CAST</code><code class="p">(</code><code class="n">today</code><code class="p">(),</code> <code class="k">YEAR</code><code class="p">)</code></pre>&#13;
&#13;
<p>Here we’ve just made up an SQL database, but you can imagine schema to satisfy this request. Converting from the request to this SQL is now yet another task you need to model—maybe it’s the job of another agent request.</p>&#13;
&#13;
<p>In other contexts, you want a full-scale recommender to help with the retrieval: if you want users to ask an agent for a movie tonight, but also to continue to use your deep understanding of each user’s tastes, you could first filter the potential movies by the user’s preference and then send only movies your recommender model thinks are great for them. The agent can then service the text request from a subset of movies that are already determined to be great.</p>&#13;
&#13;
<p>The<a data-primary="recommendation systems" data-secondary="intersection with LLMs" data-type="indexterm" id="id1280"/> intersection of LLMs and recommendation systems is going to dominate much of the conversation in recommendation systems for a while. There’s a lot of <span class="keep-together">low-hanging</span> fruit in bringing the knowledge of recommender systems to this new industry. As Eugene Yan recently said:</p>&#13;
<blockquote>&#13;
<p>I think the key challenge, and solution, is getting them [LLMs] the right information at the right time. Having a well-organized document store can help. And by using a hybrid of keyword and semantic search, we can accurately retrieve the context that LLMs need.</p></blockquote>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="id192">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>The<a data-primary="recommendation systems" data-secondary="future of" data-type="indexterm" id="id1281"/> future of recommendation systems is bright, but the technology will continue to get more complicated. One of the major changes over the last five years has been an incredible shift to<a data-primary="GPU-based training" data-type="indexterm" id="id1282"/><a data-primary="training" data-secondary="GPU-based training" data-type="indexterm" id="id1283"/> GPU-based training and the architectures that can use these GPUs. This is the primary motivation for why this book favors JAX over TensorFlow or Torch.</p>&#13;
&#13;
<p>The methods in this chapter embrace bigger models, more interconnections, and potentially inference on a scale that’s hard to house in most organizations. Ultimately, recommendation problems<a data-primary="recommendation systems" data-secondary="solving recommendation problems" data-type="indexterm" id="id1284"/> will always be solved via the following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Careful problem framing</p>&#13;
</li>&#13;
<li>&#13;
<p>Deeply relevant representations of users and items</p>&#13;
</li>&#13;
<li>&#13;
<p>Thoughtful loss functions that encode the nuances of the task</p>&#13;
</li>&#13;
<li>&#13;
<p>Great data collection</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
</div></section></body></html>