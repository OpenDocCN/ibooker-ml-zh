<html><head></head><body><section data-pdf-bookmark="Chapter 8. Hands-On Autoencoder" data-type="chapter" epub:type="chapter"><div class="chapter" id="Chapter_8">&#13;
<h1><span class="label">Chapter 8. </span>Hands-On Autoencoder</h1>&#13;
&#13;
&#13;
<p>In<a data-primary="autoencoders" data-see="also autoencoder example project" data-type="indexterm" id="idm140637542251984"/><a data-primary="autoencoder example project" data-see="also autoencoders" data-type="indexterm" id="idm140637542251008"/> this chapter, we will build applications using various versions of autoencoders, including undercomplete, overcomplete, sparse, denoising, and variational autoencoders.</p>&#13;
&#13;
<p>To start, let’s return to the credit card fraud detection problem we introduced in <a data-type="xref" href="ch03.html#Chapter_3">Chapter 3</a>. For this problem, we have 284,807 credit card transactions, of which only 492 are fraudulent. Using a supervised model, we achieved an average precision of 0.82, which is very impressive. We can find well over 80% of the fraud with an over 80% precision. Using an unsupervised model, we achieved an average precision of 0.69, which is very good considering we did not use labels. We can find over 75% of the fraud with an over 75% precision.</p>&#13;
&#13;
<p>Let’s see how this same problem can be solved using an autoencoder, which is also an unsupervised algorithm but one that uses a neural network.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Data Preparation" data-type="sect1"><div class="sect1" id="idm140637542247424">&#13;
<h1>Data Preparation</h1>&#13;
&#13;
<p>Let’s<a data-primary="autoencoder example project" data-secondary="data preparation" data-type="indexterm" id="AEPdata08"/> first load the necessary libaries:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="sd">'''Main'''</code>&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="kn">as</code> <code class="nn">pd</code>&#13;
<code class="kn">import</code> <code class="nn">os</code><code class="o">,</code> <code class="nn">time</code><code class="o">,</code> <code class="nn">re</code>&#13;
<code class="kn">import</code> <code class="nn">pickle</code><code class="o">,</code> <code class="nn">gzip</code>&#13;
&#13;
<code class="sd">'''Data Viz'''</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="kn">as</code> <code class="nn">plt</code>&#13;
<code class="kn">import</code> <code class="nn">seaborn</code> <code class="kn">as</code> <code class="nn">sns</code>&#13;
<code class="n">color</code> <code class="o">=</code> <code class="n">sns</code><code class="o">.</code><code class="n">color_palette</code><code class="p">()</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib</code> <code class="kn">as</code> <code class="nn">mpl</code>&#13;
&#13;
<code class="o">%</code><code class="n">matplotlib</code> <code class="n">inline</code>&#13;
&#13;
<code class="sd">'''Data Prep and Model Evaluation'''</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn</code> <code class="kn">import</code> <code class="n">preprocessing</code> <code class="k">as</code> <code class="n">pp</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">train_test_split</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">StratifiedKFold</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">log_loss</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">precision_recall_curve</code><code class="p">,</code> <code class="n">average_precision_score</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">roc_curve</code><code class="p">,</code> <code class="n">auc</code><code class="p">,</code> <code class="n">roc_auc_score</code>&#13;
&#13;
<code class="sd">'''Algos'''</code>&#13;
<code class="kn">import</code> <code class="nn">lightgbm</code> <code class="kn">as</code> <code class="nn">lgb</code>&#13;
&#13;
<code class="sd">'''TensorFlow and Keras'''</code>&#13;
<code class="kn">import</code> <code class="nn">tensorflow</code> <code class="kn">as</code> <code class="nn">tf</code>&#13;
<code class="kn">import</code> <code class="nn">keras</code>&#13;
<code class="kn">from</code> <code class="nn">keras</code> <code class="kn">import</code> <code class="n">backend</code> <code class="k">as</code> <code class="n">K</code>&#13;
<code class="kn">from</code> <code class="nn">keras.models</code> <code class="kn">import</code> <code class="n">Sequential</code><code class="p">,</code> <code class="n">Model</code>&#13;
<code class="kn">from</code> <code class="nn">keras.layers</code> <code class="kn">import</code> <code class="n">Activation</code><code class="p">,</code> <code class="n">Dense</code><code class="p">,</code> <code class="n">Dropout</code>&#13;
<code class="kn">from</code> <code class="nn">keras.layers</code> <code class="kn">import</code> <code class="n">BatchNormalization</code><code class="p">,</code> <code class="n">Input</code><code class="p">,</code> <code class="n">Lambda</code>&#13;
<code class="kn">from</code> <code class="nn">keras</code> <code class="kn">import</code> <code class="n">regularizers</code>&#13;
<code class="kn">from</code> <code class="nn">keras.losses</code> <code class="kn">import</code> <code class="n">mse</code><code class="p">,</code> <code class="n">binary_crossentropy</code></pre>&#13;
&#13;
<p>Next, load the dataset and prepare it for use. We will create a <code>dataX</code> matrix with all the PCA components and the feature <code>Amount</code>, but  drop <code>Class</code> and <code>Time</code>. We will store the <code>Class</code> labels in the <code>dataY</code> matrix. We will also scale the features in the <code>dataX</code> matrix so that all the features have a mean of zero and standard deviation of one:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">data</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'creditcard.csv'</code><code class="p">)</code>&#13;
<code class="n">dataX</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code><code class="o">.</code><code class="n">drop</code><code class="p">([</code><code class="s1">'Class'</code><code class="p">,</code><code class="s1">'Time'</code><code class="p">],</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">dataY</code> <code class="o">=</code> <code class="n">data</code><code class="p">[</code><code class="s1">'Class'</code><code class="p">]</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code>&#13;
<code class="n">featuresToScale</code> <code class="o">=</code> <code class="n">dataX</code><code class="o">.</code><code class="n">columns</code>&#13;
<code class="n">sX</code> <code class="o">=</code> <code class="n">pp</code><code class="o">.</code><code class="n">StandardScaler</code><code class="p">(</code><code class="n">copy</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">with_mean</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">with_std</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>&#13;
<code class="n">dataX</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">featuresToScale</code><code class="p">]</code> <code class="o">=</code> <code class="n">sX</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">dataX</code><code class="p">[</code><code class="n">featuresToScale</code><code class="p">])</code></pre>&#13;
&#13;
<p>As we did in <a data-type="xref" href="ch03.html#Chapter_3">Chapter 3</a>, we will create a training set with two-thirds of the data and the labels and a test set with one-third of the data and the labels.</p>&#13;
&#13;
<p>Let’s store the training set and the test set as <em>X_train_AE</em> and <em>X_test_AE</em>, respectively. We will use these in the autoencoders soon:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">X_train</code><code class="p">,</code> <code class="n">X_test</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> \&#13;
    <code class="n">train_test_split</code><code class="p">(</code><code class="n">dataX</code><code class="p">,</code> <code class="n">dataY</code><code class="p">,</code> <code class="n">test_size</code><code class="o">=</code><code class="mf">0.33</code><code class="p">,</code> \&#13;
                     <code class="n">random_state</code><code class="o">=</code><code class="mi">2018</code><code class="p">,</code> <code class="n">stratify</code><code class="o">=</code><code class="n">dataY</code><code class="p">)</code>&#13;
&#13;
<code class="n">X_train_AE</code> <code class="o">=</code> <code class="n">X_train</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code>&#13;
<code class="n">X_test_AE</code> <code class="o">=</code> <code class="n">X_test</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code></pre>&#13;
&#13;
<p>Let’s<a data-primary="anomaly Scores function" data-type="indexterm" id="idm140637542058864"/> also use reuse the function we introduced earlier in the book, called <code>anomalyScores</code>, to calculate the reconstruction error between the original feature matrix and the newly reconstructed feature matrix. The function takes the sum of squared errors and normalizes them to a range between zero and one.</p>&#13;
&#13;
<p>This is a crucial function. The transactions with errors close to one are the ones that are most anomalous (i.e., have the highest reconstruction error) and, therefore, are most likely to be fraudulent. The transactions with errors close to zero have the lowest reconstruction error and are most likely to be normal:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="k">def</code> <code class="nf">anomalyScores</code><code class="p">(</code><code class="n">originalDF</code><code class="p">,</code> <code class="n">reducedDF</code><code class="p">):</code>&#13;
    <code class="n">loss</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">sum</code><code class="p">((</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">originalDF</code><code class="p">)</code> <code class="o">-</code> \&#13;
                   <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">reducedDF</code><code class="p">))</code><code class="o">**</code><code class="mi">2</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
    <code class="n">loss</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">loss</code><code class="p">,</code><code class="n">index</code><code class="o">=</code><code class="n">originalDF</code><code class="o">.</code><code class="n">index</code><code class="p">)</code>&#13;
    <code class="n">loss</code> <code class="o">=</code> <code class="p">(</code><code class="n">loss</code><code class="o">-</code><code class="n">np</code><code class="o">.</code><code class="n">min</code><code class="p">(</code><code class="n">loss</code><code class="p">))</code><code class="o">/</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">max</code><code class="p">(</code><code class="n">loss</code><code class="p">)</code><code class="o">-</code><code class="n">np</code><code class="o">.</code><code class="n">min</code><code class="p">(</code><code class="n">loss</code><code class="p">))</code>&#13;
    <code class="k">return</code> <code class="n">loss</code></pre>&#13;
&#13;
<p>We<a data-primary="plotResults function" data-type="indexterm" id="idm140637542035456"/> will also reuse the function to plot the precision-recall curve, the average precision, and the ROC curve. This function is called <code>plotResults</code>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="k">def</code> <code class="nf">plotResults</code><code class="p">(</code><code class="n">trueLabels</code><code class="p">,</code> <code class="n">anomalyScores</code><code class="p">,</code> <code class="n">returnPreds</code> <code class="o">=</code> <code class="bp">False</code><code class="p">):</code>&#13;
    <code class="n">preds</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">trueLabels</code><code class="p">,</code> <code class="n">anomalyScores</code><code class="p">],</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
    <code class="n">preds</code><code class="o">.</code><code class="n">columns</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'trueLabel'</code><code class="p">,</code> <code class="s1">'anomalyScore'</code><code class="p">]</code>&#13;
    <code class="n">precision</code><code class="p">,</code> <code class="n">recall</code><code class="p">,</code> <code class="n">thresholds</code> <code class="o">=</code> \&#13;
        <code class="n">precision_recall_curve</code><code class="p">(</code><code class="n">preds</code><code class="p">[</code><code class="s1">'trueLabel'</code><code class="p">],</code> \&#13;
                               <code class="n">preds</code><code class="p">[</code><code class="s1">'anomalyScore'</code><code class="p">])</code>&#13;
    <code class="n">average_precision</code> <code class="o">=</code> <code class="n">average_precision_score</code><code class="p">(</code> \&#13;
                        <code class="n">preds</code><code class="p">[</code><code class="s1">'trueLabel'</code><code class="p">],</code> <code class="n">preds</code><code class="p">[</code><code class="s1">'anomalyScore'</code><code class="p">])</code>&#13;
&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">step</code><code class="p">(</code><code class="n">recall</code><code class="p">,</code> <code class="n">precision</code><code class="p">,</code> <code class="n">color</code><code class="o">=</code><code class="s1">'k'</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="mf">0.7</code><code class="p">,</code> <code class="n">where</code><code class="o">=</code><code class="s1">'post'</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">fill_between</code><code class="p">(</code><code class="n">recall</code><code class="p">,</code> <code class="n">precision</code><code class="p">,</code> <code class="n">step</code><code class="o">=</code><code class="s1">'post'</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="mf">0.3</code><code class="p">,</code> <code class="n">color</code><code class="o">=</code><code class="s1">'k'</code><code class="p">)</code>&#13;
&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'Recall'</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'Precision'</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">ylim</code><code class="p">([</code><code class="mf">0.0</code><code class="p">,</code> <code class="mf">1.05</code><code class="p">])</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">xlim</code><code class="p">([</code><code class="mf">0.0</code><code class="p">,</code> <code class="mf">1.0</code><code class="p">])</code>&#13;
&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'Precision-Recall curve: Average Precision = </code><code class="se">\</code>&#13;
<code class="s1">        {0:0.2f}'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">average_precision</code><code class="p">))</code>&#13;
&#13;
    <code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="n">thresholds</code> <code class="o">=</code> <code class="n">roc_curve</code><code class="p">(</code><code class="n">preds</code><code class="p">[</code><code class="s1">'trueLabel'</code><code class="p">],</code> \&#13;
                                     <code class="n">preds</code><code class="p">[</code><code class="s1">'anomalyScore'</code><code class="p">])</code>&#13;
    <code class="n">areaUnderROC</code> <code class="o">=</code> <code class="n">auc</code><code class="p">(</code><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">)</code>&#13;
&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">()</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="n">color</code><code class="o">=</code><code class="s1">'r'</code><code class="p">,</code> <code class="n">lw</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s1">'ROC curve'</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">([</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="n">color</code><code class="o">=</code><code class="s1">'k'</code><code class="p">,</code> <code class="n">lw</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">linestyle</code><code class="o">=</code><code class="s1">'--'</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">xlim</code><code class="p">([</code><code class="mf">0.0</code><code class="p">,</code> <code class="mf">1.0</code><code class="p">])</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">ylim</code><code class="p">([</code><code class="mf">0.0</code><code class="p">,</code> <code class="mf">1.05</code><code class="p">])</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'False Positive Rate'</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'True Positive Rate'</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'Receiver operating characteristic: Area under the </code><code class="se">\</code>&#13;
<code class="s1">        curve = {0:0.2f}'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">areaUnderROC</code><code class="p">))</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s2">"lower right"</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code>&#13;
&#13;
    <code class="k">if</code> <code class="n">returnPreds</code><code class="o">==</code><code class="bp">True</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="n">preds</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Components of an Autoencoder" data-type="sect1"><div class="sect1" id="idm140637542246800">&#13;
<h1>The Components of an Autoencoder</h1>&#13;
&#13;
<p>First, let’s<a data-primary="" data-startref="AEPdata08" data-type="indexterm" id="idm140637541960048"/><a data-primary="autoencoder example project" data-secondary="overview of" data-type="indexterm" id="idm140637541959040"/> build a very simple autoencoder with the input layer, a single hidden layer, and the output layer. We will feed the original feature matrix <em>x</em> into the autoencoder—this is represented by the input layer. Then, an<a data-primary="encoders" data-type="indexterm" id="idm140637541957456"/> activation function will be applied to the input layer, generating the hidden layer. This activation function is called <em>f</em> and represents the <em>encoder</em> portion of the autoencoder. The hidden layer is called <em>h</em> (which is equal to <em>f(x)</em>) and represents the newly learned representation.</p>&#13;
&#13;
<p>Next, an<a data-primary="decoders" data-type="indexterm" id="idm140637541472608"/> activation function is applied to the hidden layer (i.e., the newly learned representation) to reconstruct the original observations. This activation function is called <em>g</em> and represents the <em>decoder</em> portion of the autoencoder. The output layer is called <em>r</em> (which is equal to <em>g(h)</em>) and represents the newly reconstructed observations. To calculate the reconstruction error, we will compare the newly constructed observations <em>r</em> with the original ones <em>x</em>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Activation Functions" data-type="sect1"><div class="sect1" id="idm140637541468736">&#13;
<h1>Activation Functions</h1>&#13;
&#13;
<p>Before<a data-primary="autoencoder example project" data-secondary="activation functions" data-type="indexterm" id="idm140637541467136"/><a data-primary="activation functions" data-type="indexterm" id="idm140637541466112"/> we decide the number of nodes to use in this single hidden layer autoencoder, let’s discuss activation functions.</p>&#13;
&#13;
<p>A neural network learns the weights to apply to the nodes at each of the layers but whether the nodes will be activated or not (for use in the next layer) is determined by the activation function. In other words, an activation function is applied to the weighted input (plus bias, if any) at each layer. We will call the weighted input plus bias <em>Y</em>.</p>&#13;
&#13;
<p>The activation function takes in <em>Y</em> and either activates (if <em>Y</em> is above a certain threshold) or does not. If activated, the information in a given node is passed to the next layer; otherwise, it is not. However, we do not want simple binary activations. Instead, we want a range of activation values. To do this, we can choose a<a data-primary="linear activation function" data-type="indexterm" id="idm140637541462400"/> linear activation function or a nonlinear activation function. The linear activation function is unbounded. It can generate activation values between negative infinity and positive infinity. Common nonlinear activation functions include sigmoid, hyperbolic tangent (or tanh for short), rectified linear unit (or ReLu for short), and softmax:</p>&#13;
<dl>&#13;
<dt>Sigmoid function</dt>&#13;
<dd>&#13;
<p>The<a data-primary="sigmoid activation function" data-type="indexterm" id="idm140637541459456"/> sigmoid function is bounded and can generate activation values between zero and one.</p>&#13;
</dd>&#13;
<dt>Tanh function</dt>&#13;
<dd>&#13;
<p>The<a data-primary="hyperbolic tangent (tanh) activation function" data-type="indexterm" id="idm140637541457344"/> tanh function is also bounded and can generate activation values between negative one and positive one. Its gradient is steeper than that of the sigmoid function.</p>&#13;
</dd>&#13;
<dt>ReLu function</dt>&#13;
<dd>&#13;
<p>The<a data-primary="rectified linear unit (ReLU) activation function" data-type="indexterm" id="idm140637541454992"/> ReLu function has an interesting property. If <em>Y</em> is positive, ReLu will return <em>Y</em>. Otherwise, it will return zero. Therefore, ReLu is unbounded for positive values of <em>Y</em>.</p>&#13;
</dd>&#13;
<dt>Softmax function</dt>&#13;
<dd>&#13;
<p>The<a data-primary="softmax activation function" data-type="indexterm" id="idm140637541451536"/> softmax function is used as the final activation function in a neural network for classification problems because it normalizes classification probabilities to values that add up to a probability of one.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Of all these functions, the linear activation function is the simplest and least computationally expensive. ReLu is the next least computationally expensive, followed by the others.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Our First Autoencoder" data-type="sect1"><div class="sect1" id="idm140637541449552">&#13;
<h1>Our First Autoencoder</h1>&#13;
&#13;
<p>Let’s<a data-primary="autoencoder example project" data-secondary="two-layer AE with linear activation function" data-type="indexterm" id="AEPtwo08"/> start with a two-layer autoencoder with a linear activation function for both the encoder and the decoder functions. Note that only the number of hidden layers plus the output layer count toward the <em>number of layers</em> in a neural network. Since we have a single hidden layer, this is known as a two-layer neural network.</p>&#13;
&#13;
<p>To<a data-primary="Sequential model API" data-type="indexterm" id="idm140637541445408"/> build this using TensorFlow and Keras, we must first call the <em>Sequential model API</em>. The Sequential model is a linear stack of layers, and we will pass the types of layers we want into the model before we compile the model and train on our data.<sup><a data-type="noteref" href="ch08.html#idm140637541443984" id="idm140637541443984-marker">1</a></sup></p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Model one</code>&#13;
<code class="c1"># Two layer complete autoencoder with linear activation</code>&#13;
&#13;
<code class="c1"># Call neural network API</code>&#13;
<code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code></pre>&#13;
&#13;
<p>Once we call the Sequential model, we then need to specify the input shape by designating the number of dimensions, which should match the number of dimensions in the original feature matrix, <em>dataX</em>. This number is 29.</p>&#13;
&#13;
<p>We also need to specify the activation function (also known as the encoder function) applied to the input layer and the number of nodes we want the hidden layer to have. We will pass <em>linear</em> as the activation function.</p>&#13;
&#13;
<p>To start, let’s use a complete autoencoder, where the number of nodes in the hidden layer equals the number of nodes in the input layer, which is 29. All of this is done using a single line of code:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">,</code><code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code></pre>&#13;
&#13;
<p>Similarly, we need to specify the activation function (also known as the decoder function) applied to the hidden layer to reconstruct the observations and the number of dimensions we want the output layer to have. Since we want the final reconstructed matrix to have the same dimensions as the original matrix, the dimension needs to be 29. And, we will use a linear activation function for the decoder, too:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code></pre>&#13;
&#13;
<p>Next, we<a data-primary="loss functions" data-type="indexterm" id="idm140637541324672"/><a data-primary="objective functions" data-type="indexterm" id="idm140637541324064"/><a data-primary="optimizers" data-type="indexterm" id="idm140637541323424"/> will need to compile the layers we have designed for the neural network. This requires us to select a <em>loss function</em> (also known as the <em>objective function</em>) to guide the learning of the weights, an <em>optimizer</em> to set the process by which the weights are learned, and a list of <em>metrics</em> to output to help us evaluate the goodness of the neural network.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Loss Function" data-type="sect2"><div class="sect2" id="idm140637541366736">&#13;
<h2>Loss Function</h2>&#13;
&#13;
<p>Let’s start with the loss function. Recall that we are evaluating the model based on the reconstruction error between the newly reconstructed matrix of features based on the autoencoder and the original feature matrix that we feed into the autoencoder.</p>&#13;
&#13;
<p>Therefore, we<a data-primary="mean squared error (MSE)" data-type="indexterm" id="idm140637541364720"/> want to use <em>mean squared error</em> as the evaluation metric. (For our custom evaluation function, we use sum of squared errors, which is similar.).<sup><a data-type="noteref" href="ch08.html#idm140637541363344" id="idm140637541363344-marker">2</a></sup></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Optimizer" data-type="sect2"><div class="sect2" id="idm140637541361808">&#13;
<h2>Optimizer</h2>&#13;
&#13;
<p>Neural networks<a data-primary="epochs" data-type="indexterm" id="idm140637541360272"/> train for many rounds (known as <em>epochs</em>). In each of these epochs, the neural network readjusts its learned weights to reduce its loss from the previous epoch. The process for learning these weights is set by the optimizer. We want a process that helps the neural network efficiently learn the optimal weights for the various nodes across all the layers that minimizes the loss function we have chosen.</p>&#13;
&#13;
<p>To learn the optimal weights, the neural network needs to adjust its “guess” for the optimal weights in an intelligent way. One approach is to iteratively move the weights in the direction that helps reduce the loss function incrementally. But an even better approach is to move the weights in this direction but with a degree of randomness—in other words, to move the weights stochastically.</p>&#13;
&#13;
<p>Although<a data-primary="stochastic gradient descent (SGD)" data-type="indexterm" id="idm140637541357392"/> there is more to this, this process is known as <em>stochastic gradient descent</em> (or SGD for short), the most commonly used optimizer in training neural networks.<sup><a data-type="noteref" href="ch08.html#idm140637541313568" id="idm140637541313568-marker">3</a></sup> SGD<a data-primary="learning rates" data-type="indexterm" id="idm140637541312176"/><a data-primary="alpha hyperparameter" data-type="indexterm" id="idm140637541311472"/> has a single learning rate, known as <em>alpha</em>, for all the weight updates that it makes, and this learning rate does not change during training. However, in most cases, it’s better to adjust the learning rate over the course of the training. For example, in the earlier epochs, it makes more sense to adjust the weights by a large degree—in other words, to have a large learning rate or alpha.</p>&#13;
&#13;
<p>In later epochs, when the weights are more optimal, it makes more sense to adjust the weights by a small degree to delicately fine-tune the weights than to take massive steps in one direction or another. Therefore, an even better optimzer than SGD<a data-primary="algorithms" data-secondary="Adam optimization algorithm" data-type="indexterm" id="idm140637541309328"/><a data-primary="Adam optimization algorithm" data-type="indexterm" id="idm140637541308336"/> is the <em>Adam optimization algorithm</em>, which is derived from adaptive moment estimation. The Adam optimizer dynamically adjusts the learning rate over the course of the training process, unlike SGD, and is the optimizer we will use.<sup><a data-type="noteref" href="ch08.html#idm140637541306896" id="idm140637541306896-marker">4</a></sup></p>&#13;
&#13;
<p>For this optimizer, we can set the alpha, which sets the pace at which weights are updated. Larger alpha values result in faster initial learning before the learning rate is updated.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Training the Model" data-type="sect2"><div class="sect2" id="idm140637541304816">&#13;
<h2>Training the Model</h2>&#13;
&#13;
<p>Finally, we need to choose the evaluation metric, which we will set to <code>accuracy</code> to keep things simple:<sup><a data-type="noteref" href="ch08.html#idm140637541302672" id="idm140637541302672-marker">5</a></sup></p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'adam'</code><code class="p">,</code>&#13;
              <code class="n">loss</code><code class="o">=</code><code class="s1">'mean_squared_error'</code><code class="p">,</code>&#13;
              <code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'accuracy'</code><code class="p">])</code></pre>&#13;
&#13;
<p>Next, we<a data-primary="fit method" data-type="indexterm" id="idm140637541269216"/> need to select the number of epochs and the batch size and then begin the training process by calling the method <em>fit</em>. The number of epochs determines the number of times the training occurs over the entire dataset we pass into the neural network. We will set this to 10 to start.</p>&#13;
&#13;
<p>The batch sets the number of samples the neural network trains on before making the next gradient update. If the batch is equal to the total number of observations, the neural network will make a gradient update once every epoch. Otherwise, it will make updates multiple times per epoch. We will set this to a generic 32 samples to start.</p>&#13;
&#13;
<p>Into the fit method, we will pass in the initial input matrix, <em>x</em>, and the target matrix, <em>y</em>. In our case, both <em>x</em> and <em>y</em> will be the original feature matrix, <em>X_train_AE</em>, because we want to compare the output of the autoencoder—the reconstructed feature matrix—with the original feature matrix to calculate the reconstruction error.</p>&#13;
&#13;
<p>Remember, this is a purely unsupervised solution so we will not use the <em>y</em> matrix at all. We will also validate our model as we go by testing the reconstruction error on the entire training matrix:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">10</code>&#13;
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">32</code>&#13;
&#13;
<code class="n">history</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x</code><code class="o">=</code><code class="n">X_train_AE</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="n">X_train_AE</code><code class="p">,</code>&#13;
                    <code class="n">epochs</code><code class="o">=</code><code class="n">num_epochs</code><code class="p">,</code>&#13;
                    <code class="n">batch_size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">,</code>&#13;
                    <code class="n">shuffle</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code>&#13;
                    <code class="n">validation_data</code><code class="o">=</code><code class="p">(</code><code class="n">X_train_AE</code><code class="p">,</code> <code class="n">X_train_AE</code><code class="p">),</code>&#13;
                    <code class="n">verbose</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code></pre>&#13;
&#13;
<p>Since this a complete autoencoder—where the hidden layer has the same number of dimensions as the input layer—the loss is very low, for both the training and validation sets:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of complete autoencoder&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 29s 154us/step - loss: 0.1056&#13;
- acc: 0.8728 - val_loss: 0.0013 - val_acc: 0.9903&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 27s 140us/step - loss: 0.0012&#13;
- acc: 0.9914 - val_loss: 1.0425e-06 - val_acc: 0.9995&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 23s 122us/step - loss: 6.6244&#13;
e-04 - acc: 0.9949 - val_loss: 5.2491e-04 - val_acc: 0.9913&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 23s 119us/step - loss: 0.0016&#13;
- acc: 0.9929 - val_loss: 2.2246e-06 - val_acc: 0.9995&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 23s 119us/step - loss: 5.7424&#13;
e-04 - acc: 0.9943 - val_loss: 9.0811e-05 - val_acc: 0.9970&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 22s 118us/step - loss: 5.4950&#13;
e-04 - acc: 0.9941 - val_loss: 6.0598e-05 - val_acc: 0.9959&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 22s 117us/step - loss: 5.2291&#13;
e-04 - acc: 0.9946 - val_loss: 0.0023 - val_acc: 0.9675&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 22s 117us/step - loss: 6.5130&#13;
e-04 - acc: 0.9932 - val_loss: 4.5059e-04 - val_acc: 0.9945&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 23s 122us/step - loss: 4.9077&#13;
e-04 - acc: 0.9952 - val_loss: 7.2591e-04 - val_acc: 0.9908&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 23s 118us/step - loss: 6.1469&#13;
e-04 - acc: 0.9945 - val_loss: 4.4131e-06 - val_acc: 0.9991</pre>&#13;
&#13;
<p>This is not optimal—the autoencoder has reconstructed the original feature matrix too precisely, memorizing the inputs.</p>&#13;
&#13;
<p>Recall<a data-primary="identity function" data-type="indexterm" id="idm140637540994672"/> that the autoencoder is meant to learn a new representation that captures the most salient information in the original input matrix while dropping the less relevant information. Simply memorizing the inputs—also known as learning the <em>identity function</em>—will not result in new and improved representation learning.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Evaluating on the Test Set" data-type="sect2"><div class="sect2" id="idm140637541304192">&#13;
<h2>Evaluating on the Test Set</h2>&#13;
&#13;
<p>Let’s use<a data-primary="predict method" data-type="indexterm" id="idm140637540991504"/> the test set to evaluate just how successively this autoencoder can identify fraud in the credit card transactions dataset. We will use the <code>predict</code> method to do this:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">predictions</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">anomalyScoresAE</code> <code class="o">=</code> <code class="n">anomalyScores</code><code class="p">(</code><code class="n">X_test</code><code class="p">,</code> <code class="n">predictions</code><code class="p">)</code>&#13;
<code class="n">preds</code> <code class="o">=</code> <code class="n">plotResults</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code> <code class="n">anomalyScoresAE</code><code class="p">,</code> <code class="bp">True</code><code class="p">)</code></pre>&#13;
&#13;
<p>As seen in <a data-type="xref" href="#evaluation_metrics_of_complete_autoencoder">Figure 8-1</a>, the average precision is 0.30, which is not very good. The best average precision using unsupervised learning from <a data-type="xref" href="ch04.html#Chapter_4">Chapter 4</a> was 0.69, and the supervised system had an average precision of 0.82. However, each training process will yield slightly different results for the trained autoencoder, so you may not see the same performance for your run.</p>&#13;
&#13;
<p>To get a better sense of how a two-layer complete autoencoder performs on the test set, let’s run this training process ten separate times and store the average precision on the test set for each run. We will assess how good this complete autoencoder is at capturing fraud based on the mean of the average precision from these 10 runs.</p>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_complete_autoencoder">&#13;
<img alt="Evaluation Metrics of Complete Autoencoder" src="assets/hulp_0801.png"/>&#13;
<h6><span class="label">Figure 8-1. </span>Evaluation metrics of complete autoencoder</h6>&#13;
</div></figure>&#13;
&#13;
<p>To consolidate our work thus far, here is the code to simulate 10 runs from start to finish:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># 10 runs - We will capture mean of average precision</code>&#13;
<code class="n">test_scores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code><code class="mi">10</code><code class="p">):</code>&#13;
    <code class="c1"># Call neural network API</code>&#13;
    <code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
&#13;
    <code class="c1"># Apply linear activation function to input layer</code>&#13;
    <code class="c1"># Generate hidden layer with 29 nodes, the same as the input layer</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">,</code><code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code>&#13;
&#13;
    <code class="c1"># Apply linear activation function to hidden layer</code>&#13;
    <code class="c1"># Generate output layer with 29 nodes</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code>&#13;
&#13;
    <code class="c1"># Compile the model</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'adam'</code><code class="p">,</code>&#13;
                  <code class="n">loss</code><code class="o">=</code><code class="s1">'mean_squared_error'</code><code class="p">,</code>&#13;
                  <code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'accuracy'</code><code class="p">])</code>&#13;
&#13;
    <code class="c1"># Train the model</code>&#13;
    <code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">10</code>&#13;
    <code class="n">batch_size</code> <code class="o">=</code> <code class="mi">32</code>&#13;
&#13;
    <code class="n">history</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x</code><code class="o">=</code><code class="n">X_train_AE</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="n">X_train_AE</code><code class="p">,</code>&#13;
                        <code class="n">epochs</code><code class="o">=</code><code class="n">num_epochs</code><code class="p">,</code>&#13;
                        <code class="n">batch_size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">,</code>&#13;
                        <code class="n">shuffle</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code>&#13;
                        <code class="n">validation_data</code><code class="o">=</code><code class="p">(</code><code class="n">X_train_AE</code><code class="p">,</code> <code class="n">X_train_AE</code><code class="p">),</code>&#13;
                        <code class="n">verbose</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
&#13;
    <code class="c1"># Evaluate on test set</code>&#13;
    <code class="n">predictions</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
    <code class="n">anomalyScoresAE</code> <code class="o">=</code> <code class="n">anomalyScores</code><code class="p">(</code><code class="n">X_test</code><code class="p">,</code> <code class="n">predictions</code><code class="p">)</code>&#13;
    <code class="n">preds</code><code class="p">,</code> <code class="n">avgPrecision</code> <code class="o">=</code> <code class="n">plotResults</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code> <code class="n">anomalyScoresAE</code><code class="p">,</code> <code class="bp">True</code><code class="p">)</code>&#13;
    <code class="n">test_scores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">avgPrecision</code><code class="p">)</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="s2">"Mean average precision over 10 runs: "</code><code class="p">,</code> <code class="n">np</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">test_scores</code><code class="p">))</code>&#13;
<code class="n">test_scores</code></pre>&#13;
&#13;
<p>The following code summarizes the results for the 10 runs. The mean of the average precision is 0.30, but the average precision ranges from a low of 0.02 to .72. The<a data-primary="coefficient of variation" data-type="indexterm" id="idm140637541206320"/> <em>coefficient of variation</em> (defined as the standard deviation divided by the mean over 10 runs) is 0.88.</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.30108318944579776&#13;
Coefficient of variation over 10 runs: 0.8755095071789248&#13;
&#13;
[0.25468022666666157,&#13;
0.092705950994909,&#13;
0.716481644928299,&#13;
0.01946589342639965,&#13;
0.25623865457838263,&#13;
0.33597083510378234,&#13;
0.018757053070824415,&#13;
0.6188569405068724,&#13;
0.6720552647581304,&#13;
0.025619070873716072]</pre>&#13;
&#13;
<p>Let’s try to improve our results by building variations of this autoencoder.<a data-primary="" data-startref="AEPtwo08" data-type="indexterm" id="idm140637540832960"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Two-Layer Undercomplete Autoencoder with Linear Activation Function" data-type="sect1"><div class="sect1" id="idm140637541449056">&#13;
<h1>Two-Layer Undercomplete Autoencoder with Linear Activation Function</h1>&#13;
&#13;
<p>Let’s<a data-primary="autoencoder example project" data-secondary="two-layer undercomplete AE with linear activation function" data-type="indexterm" id="AEPunderAE08"/> try an undercomplete autoencoder rather than a complete one.</p>&#13;
&#13;
<p>Compared to the previous autoencoder, the only thing that changes is the number of nodes in the hidden layer. Instead of setting this to the number of original dimensions (29), we will set the nodes to 20. In other words, this autoencoder is a <span class="keep-together">constrained</span> autoencoder. The encoder function is forced to capture the information in the input layer with a fewer number of nodes, and the decoder has to take this new representation to reconstruct the original matrix.</p>&#13;
&#13;
<p>We should expect the loss here to be higher compared to that of the complete autoencoder. Let’s run the code. We will perform 10 independent runs to test how well the various undercomplete autoencoders are at catching fraud:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># 10 runs - We will capture mean of average precision</code>&#13;
<code class="n">test_scores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code><code class="mi">10</code><code class="p">):</code>&#13;
    <code class="c1"># Call neural network API</code>&#13;
    <code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
&#13;
    <code class="c1"># Apply linear activation function to input layer</code>&#13;
    <code class="c1"># Generate hidden layer with 20 nodes</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">20</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">,</code><code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code>&#13;
&#13;
    <code class="c1"># Apply linear activation function to hidden layer</code>&#13;
    <code class="c1"># Generate output layer with 29 nodes</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code>&#13;
&#13;
    <code class="c1"># Compile the model</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'adam'</code><code class="p">,</code>&#13;
                  <code class="n">loss</code><code class="o">=</code><code class="s1">'mean_squared_error'</code><code class="p">,</code>&#13;
                  <code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'accuracy'</code><code class="p">])</code>&#13;
&#13;
    <code class="c1"># Train the model</code>&#13;
    <code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">10</code>&#13;
    <code class="n">batch_size</code> <code class="o">=</code> <code class="mi">32</code>&#13;
&#13;
    <code class="n">history</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x</code><code class="o">=</code><code class="n">X_train_AE</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="n">X_train_AE</code><code class="p">,</code>&#13;
                        <code class="n">epochs</code><code class="o">=</code><code class="n">num_epochs</code><code class="p">,</code>&#13;
                        <code class="n">batch_size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">,</code>&#13;
                        <code class="n">shuffle</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code>&#13;
                        <code class="n">validation_data</code><code class="o">=</code><code class="p">(</code><code class="n">X_train_AE</code><code class="p">,</code> <code class="n">X_train_AE</code><code class="p">),</code>&#13;
                        <code class="n">verbose</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
&#13;
    <code class="c1"># Evaluate on test set</code>&#13;
    <code class="n">predictions</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
    <code class="n">anomalyScoresAE</code> <code class="o">=</code> <code class="n">anomalyScores</code><code class="p">(</code><code class="n">X_test</code><code class="p">,</code> <code class="n">predictions</code><code class="p">)</code>&#13;
    <code class="n">preds</code><code class="p">,</code> <code class="n">avgPrecision</code> <code class="o">=</code> <code class="n">plotResults</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code> <code class="n">anomalyScoresAE</code><code class="p">,</code> <code class="bp">True</code><code class="p">)</code>&#13;
    <code class="n">test_scores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">avgPrecision</code><code class="p">)</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="s2">"Mean average precision over 10 runs: "</code><code class="p">,</code> <code class="n">np</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">test_scores</code><code class="p">))</code>&#13;
<code class="n">test_scores</code></pre>&#13;
&#13;
<p>As the following shows, the losses of the undercomplete autoencoder are considerably higher than those of the complete autoencoder. It is clear that the autoencoder learns a representation that is new and more constrained than the original input matrix—the autoencoder did not simply memorize the inputs:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of undercomplete autoencoder with 20 nodes&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 28s 145us/step - loss: 0.3588&#13;
- acc: 0.5672 - val_loss: 0.2789 - val_acc: 0.6078&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 29s 153us/step - loss: 0.2817&#13;
- acc: 0.6032 - val_loss: 0.2757 - val_acc: 0.6115&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 28s 147us/step - loss: 0.2793&#13;
- acc: 0.6147 - val_loss: 0.2755 - val_acc: 0.6176&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 30s 155us/step - loss: 0.2784&#13;
- acc: 0.6164 - val_loss: 0.2750 - val_acc: 0.6167&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 29s 152us/step - loss: 0.2786&#13;
- acc: 0.6188 - val_loss: 0.2746 - val_acc: 0.6126&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 29s 151us/step - loss: 0.2776&#13;
- acc: 0.6140 - val_loss: 0.2752 - val_acc: 0.6043&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 30s 156us/step - loss: 0.2775&#13;
- acc: 0.5947 - val_loss: 0.2745 - val_acc: 0.5946&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 29s 149us/step - loss: 0.2770&#13;
- acc: 0.5903 - val_loss: 0.2740 - val_acc: 0.5882&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 29s 153us/step - loss: 0.2768&#13;
- acc: 0.5921 - val_loss: 0.2770 - val_acc: 0.5801&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 29s 150us/step - loss: 0.2767&#13;
- acc: 0.5803 - val_loss: 0.2744 - val_acc: 0.5743&#13;
93987/93987[==============================] - 3s 36us/step</pre>&#13;
&#13;
<p>This is how an autoencoder should work—it should learn a new representation. <a data-type="xref" href="#evaluation_metrics_of_undercomplete_autoencoder_with_20_nodes">Figure 8-2</a> shows how effective this new representation is at identifying fraud.</p>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_undercomplete_autoencoder_with_20_nodes">&#13;
<img alt="Evaluation Metrics of Undercomplete Autoencoder with 20 Nodes" src="assets/hulp_0802.png"/>&#13;
<h6><span class="label">Figure 8-2. </span>Evaluation metrics of undercomplete autoencoder with 20 nodes</h6>&#13;
</div></figure>&#13;
&#13;
<p>The average precision is 0.29, similar to that of the complete autoencoder.</p>&#13;
&#13;
<p>The following code shows the distribution of average precisions across the 10 runs. The mean of the average precision is 0.31, but the dispersion is very tight (as the coefficient of variation 0.03 indicates). This is a considerably more stable system than the one designed with a complete autoencoder.</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.30913783987972737&#13;
Coefficient of variation over 10 runs: 0.032251659812254876&#13;
&#13;
[0.2886910204920736,&#13;
0.3056142045082387,&#13;
0.31658073591381186,&#13;
0.30590858583039254,&#13;
0.31824197682595556,&#13;
0.3136952374067599,&#13;
0.30888135217515555,&#13;
0.31234000424933206,&#13;
0.29695149753706923,&#13;
0.3244746838584846]</pre>&#13;
&#13;
<p>But we are still stuck at a fairly mediocre average precision. Why did the undercomplete autoencoder not perform better? It could be that this undercomplete autoencoder does not have enough nodes. Or, maybe we need to train using more hidden layers. Let’s experiment with these two changes, one by one.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Increasing the Number of Nodes" data-type="sect2"><div class="sect2" id="idm140637540695632">&#13;
<h2>Increasing the Number of Nodes</h2>&#13;
&#13;
<p>The following code displays the training losses when using a two-layer undercomplete autocoder with 27 nodes instead of just 20:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of undercomplete autoencoder with 27 nodes&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 29s 150us/step - loss: 0.1169&#13;
- acc: 0.8224 - val_loss: 0.0368 - val_acc: 0.8798&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 29s 154us/step - loss: 0.0388&#13;
- acc: 0.8610 - val_loss: 0.0360 - val_acc: 0.8530&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 30s 156us/step - loss: 0.0382&#13;
- acc: 0.8680 - val_loss: 0.0359 - val_acc: 0.8745&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 30s 156us/step - loss: 0.0371&#13;
- acc: 0.8811 - val_loss: 0.0353 - val_acc: 0.9021&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 30s 155us/step - loss: 0.0373&#13;
- acc: 0.9114 - val_loss: 0.0352 - val_acc: 0.9226&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 30s 155us/step - loss: 0.0377&#13;
- acc: 0.9361 - val_loss: 0.0370 - val_acc: 0.9416&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 30s 156us/step - loss: 0.0361&#13;
- acc: 0.9448 - val_loss: 0.0358 - val_acc: 0.9378&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 30s 156us/step - loss: 0.0354&#13;
- acc: 0.9521 - val_loss: 0.0350 - val_acc: 0.9503&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 29s 153us/step - loss: 0.0352&#13;
- acc: 0.9613 - val_loss: 0.0349 - val_acc: 0.9263&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 29s 153us/step - loss: 0.0353&#13;
- acc: 0.9566 - val_loss: 0.0343 - val_acc: 0.9477&#13;
93987/93987[==============================] - 4s 39us/step</pre>&#13;
&#13;
<p><a data-type="xref" href="#evaluation_metrics_of_undercomplete_autoencoder_with_27_nodes">Figure 8-3</a> displays the average precision, precision-recall curve, and auROC curve.</p>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_undercomplete_autoencoder_with_27_nodes">&#13;
<img alt="Evaluation Metrics of Undercomplete Autoencoder with 27 Nodes" src="assets/hulp_0803.png"/>&#13;
<h6><span class="label">Figure 8-3. </span>Evaluation metrics of undercomplete autoencoder with 27 nodes</h6>&#13;
</div></figure>&#13;
&#13;
<p>The average precision improves considerably to 0.70. This is better than the average precision of the complete autoencoder and better than the best unsupervised learning solution from <a data-type="xref" href="ch04.html#Chapter_4">Chapter 4</a>.</p>&#13;
&#13;
<p>The following code summarizes the distribution of average precision across the 10 runs. The mean of the average precision is 0.53, considerably better than the ~0.30 average precision earlier. The dispersion of average precision is reasonably good, with a coefficient of variation of 0.50.</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.5273341559141779&#13;
Coefficient of variation over 10 runs: 0.5006880691999009&#13;
&#13;
[0.689799495450694,&#13;
0.7092146840717755,&#13;
0.7336692377321005,&#13;
0.6154173765950426,&#13;
0.7068800243349335,&#13;
0.35250757724667586,&#13;
0.6904117414832501,&#13;
0.02335388808244066,&#13;
0.690798140588336,&#13;
0.061289393556529626]</pre>&#13;
&#13;
<p>We have a clear improvement over our previous autoencoder-based anomaly detection system.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Adding More Hidden Layers" data-type="sect2"><div class="sect2" id="idm140637540684528">&#13;
<h2>Adding More Hidden Layers</h2>&#13;
&#13;
<p>Let’s see if we can improve our results by adding an extra hidden layer to the autoencoder. We will continue to use linear activation functions for now.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Experimentation is a major part of discovering the best neural network architecture for the problem you have to solve. Some changes you make will lead to better results, others to worse. Knowing how to modify the neural network and the hyperparameters as part of your search to improve the solution is very important.</p>&#13;
</div>&#13;
&#13;
<p>Instead of a single hidden layer with 27 nodes, we will use one hidden layer with 28 nodes and another with 27 nodes. This is only a slight variation from the one we used previously. This is now a three-layer neural network since we have two hidden layers plus the output layer. The input layer does not “count” toward this number.</p>&#13;
&#13;
<p>This additional hidden layer requires just one additional line of code, as shown here:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Model two</code>&#13;
<code class="c1"># Three layer undercomplete autoencoder with linear activation</code>&#13;
<code class="c1"># With 28 and 27 nodes in the two hidden layers, respectively</code>&#13;
&#13;
<code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">28</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">,</code><code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">27</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code></pre>&#13;
&#13;
<p>The following code summarizes the distribution of average precisions across the 10 runs. The mean of the average precision is 0.36, worse than the 0.53 we just achieved. The dispersion of average precision is also worse, with a coefficient of variation<a data-primary="" data-startref="AEPunderAE08" data-type="indexterm" id="idm140637540657856"/> of 0.94 (higher is worse):</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.36075271075596366&#13;
Coefficient of variation over 10 runs: 0.9361649046827353&#13;
&#13;
[0.02259626054852924,&#13;
0.6984699403560997,&#13;
0.011035001202665167,&#13;
0.06621450000830197,&#13;
0.008916986608776182,&#13;
0.705399684020873,&#13;
0.6995233144849828,&#13;
0.008263068338243631,&#13;
0.6904537524978872,&#13;
0.6966545994932775]</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Nonlinear Autoencoder" data-type="sect1"><div class="sect1" id="idm140637540831392">&#13;
<h1>Nonlinear Autoencoder</h1>&#13;
&#13;
<p>Now<a data-primary="autoencoder example project" data-secondary="nonlinear autoencoder" data-type="indexterm" id="AEPnonlinear08"/> let’s build an undercomplete autoencoder using a nonlinear activation function. We will use ReLu, but you are welcome to experiment with tanh, sigmoid, and the other nonlinear activation functions.</p>&#13;
&#13;
<p>We will include three hidden layers, with 27, 22, and 27 nodes, respectively. Conceptually, the first two activation functions (applied on the input and first hidden layer) perform the encoding, creating the second hidden layer with 22 nodes. Then, the next two activation functions perform the decoding, reconstructing the 22-node representation to the original number of dimensions, 29:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">27</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'relu'</code><code class="p">,</code><code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">22</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'relu'</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">27</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'relu'</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'relu'</code><code class="p">))</code></pre>&#13;
&#13;
<p>The following code shows the losses from this autoencoder, and <a data-type="xref" href="#evaluation_metrics_of_undercomplete_autoencoder_with_three_hidden_layers_and_relu_activation_function">Figure 8-4</a> shows the average precision, the precision-recall curve, and the auROC curve:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of undercomplete autoencoder with three hidden layers and ReLu&#13;
activation function&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 32s 169us/step - loss: 0.7010&#13;
- acc: 0.5626 - val_loss: 0.6339 - val_acc: 0.6983&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 33s 174us/step - loss: 0.6302&#13;
- acc: 0.7132 - val_loss: 0.6219 - val_acc: 0.7465&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 34s 177us/step - loss: 0.6224&#13;
- acc: 0.7367 - val_loss: 0.6198 - val_acc: 0.7528&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 34s 179us/step - loss: 0.6227&#13;
- acc: 0.7380 - val_loss: 0.6205 - val_acc: 0.7471&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 33s 174us/step - loss: 0.6206&#13;
- acc: 0.7452 - val_loss: 0.6202 - val_acc: 0.7353&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 33s 175us/step - loss: 0.6206&#13;
- acc: 0.7458 - val_loss: 0.6192 - val_acc: 0.7485&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 33s 174us/step - loss: 0.6199&#13;
- acc: 0.7481 - val_loss: 0.6239 - val_acc: 0.7308&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 33s 175us/step - loss: 0.6203&#13;
- acc: 0.7497 - val_loss: 0.6183 - val_acc: 0.7626&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 34s 177us/step - loss: 0.6197&#13;
- acc: 0.7491 - val_loss: 0.6188 - val_acc: 0.7531&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 34s 177us/step - loss: 0.6201&#13;
- acc: 0.7486 - val_loss: 0.6188 - val_acc: 0.7540&#13;
93987/93987 [==============================] - 5s 48 us/step</pre>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_undercomplete_autoencoder_with_three_hidden_layers_and_relu_activation_function">&#13;
<img alt="Evaluation Metrics of Undercomplete Autoencoder with Three Hidden Layers and ReLu Activation Function" src="assets/hulp_0804.png"/>&#13;
<h6><span class="label">Figure 8-4. </span>Evaluation metrics of undercomplete autoencoder with three hidden layers and ReLu activation function</h6>&#13;
</div></figure>&#13;
&#13;
<p>The results are considerably worse.</p>&#13;
&#13;
<p>The following code summarizes the distribution of average precisions across the 10 runs. The mean of the average precision is 0.22, worse than the 0.53 we achieved earlier. The dispersion of average precisions is very tight, with a coefficient of variation of 0.06:</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs:    0.2232934196381843&#13;
Coefficient of variation over 10 runs:   0.060779960264380296&#13;
&#13;
[0.22598829389665595,&#13;
0.22616147166925166,&#13;
0.22119489753135715,&#13;
0.2478548473814437,&#13;
0.2251289336369011,&#13;
0.2119454446242229,&#13;
0.2126914064768752,&#13;
0.24581338950742185,&#13;
0.20665608837737512,&#13;
0.20949942328033827]</pre>&#13;
&#13;
<p>These results are much worse than those from a simple autoencoder using a linear activation function. It could be that—for this dataset—a linear, undercomplete autoencoder is the best solution.</p>&#13;
&#13;
<p>For other datasets, that may not always be the case. As always, experimentation is required to find the optimal solution. Change the number of nodes, the number of hidden layers, and the mix of activation functions, and see how much better or worse the solutions become.</p>&#13;
&#13;
<p>This<a data-primary="hyperparameter optimization" data-type="indexterm" id="idm140637540450208"/> type of experimentation is known as <em>hyperparameter optimization</em>. You are adjusting the hyperparameters—the number of nodes, the number of layers, and the mix of activation functions—in search of the optimal solution.<a data-primary="" data-startref="AEPnonlinear08" data-type="indexterm" id="idm140637540448720"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Overcomplete Autoencoder with Linear Activation" data-type="sect1"><div class="sect1" id="idm140637540525248">&#13;
<h1>Overcomplete Autoencoder with Linear Activation</h1>&#13;
&#13;
<p>Now let’s<a data-primary="autoencoder example project" data-secondary="overcomplete AE with linear activation" data-type="indexterm" id="AEPover08"/><a data-primary="capacity" data-type="indexterm" id="idm140637540444752"/> highlight the problem with overcomplete autoencoders. Overcomplete autoencoders have more nodes in the hidden layer than either the input or output layer. Because the <em>capacity</em> of the neural network model is so high, the autoencoder simply memorizes the observations it trains on.</p>&#13;
&#13;
<p>In<a data-primary="identity function" data-type="indexterm" id="idm140637540442832"/> other words, the autoencoder learns the <em>identity function</em>, which is exactly what we want to avoid. The autoencoder will overfit the training data and will perform very poorly in separating fraudulent credit card transactions from normal ones.</p>&#13;
&#13;
<p>Recall that we need the autoencoder to learn the salient aspects of the credit card transactions in the training set so that it learns what the normal transactions look like—without memorizing the information in the less normal, rare fraudulent ones.</p>&#13;
&#13;
<p>Only if the autoencoder is able to lose some of the information in the training set will it be able to separate the fraudulent transactions from the normal ones:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">40</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">,</code><code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code></pre>&#13;
&#13;
<p>The following code shows the losses from this autoencoder, and <a data-type="xref" href="#evaluation_metrics_of_overcomplete_autoencoder_with_single_hidden_layer_and_linear_activation_function">Figure 8-5</a> displays the average precision, the precision-recall curve, and the auROC curve:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of overcomplete autoencoder with single hidden layer and&#13;
 linear activation function&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 31s 161us/step - loss: 0.0498&#13;
- acc: 0.9438 - val_loss: 9.2301e-06 - val_acc: 0.9982&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 33s 171us/step - loss: 0.0014&#13;
- acc: 0.9925 - val_loss: 0.0019 - val_acc: 0.9909&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 33s 172us/step - loss: 7.6469&#13;
e-04 - acc: 0.9947 - val_loss: 4.5314e-05 - val_acc: 0.9970&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 35s 182us/step - loss: 0.0010&#13;
- acc: 0.9930 - val_loss: 0.0039 - val_acc: 0.9859&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 32s 166us/step - loss: 0.0012&#13;
- acc: 0.9924 - val_loss: 8.5141e-04 - val_acc: 0.9886&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 31s 163us/step - loss: 5.0655&#13;
e-04 - acc: 0.9955 - val_loss: 8.2359e-04 - val_acc: 0.9910&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 30s 156us/step - loss: 7.6046&#13;
e-04 - acc: 0.9930 - val_loss: 0.0045 - val_acc: 0.9933&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 30s 157us/step - loss: 9.1609&#13;
e-04 - acc: 0.9930 - val_loss: 7.3662e-04 - val_acc: 0.9872&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 30s 158us/step - loss: 7.6287&#13;
e-04 - acc: 0.9929 - val_loss: 2.5671e-04 - val_acc: 0.9940&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 30s 157us/step - loss: 7.0697&#13;
e-04 - acc: 0.9928 - val_loss: 4.5272e-06 - val_acc: 0.9994&#13;
93987/93987[==============================] - 4s 48us/step</pre>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_overcomplete_autoencoder_with_single_hidden_layer_and_linear_activation_function">&#13;
<img alt="Evaluation Metrics of Overcomplete Autoencoder with Single Hidden Layer and Linear Activation Function" src="assets/hulp_0805.png"/>&#13;
<h6><span class="label">Figure 8-5. </span>Evaluation metrics of overcomplete autoencoder with single hidden layer and linear activation function</h6>&#13;
</div></figure>&#13;
&#13;
<p>As expected, the losses are very low, and the overfit overcomplete autoencoder has very poor performance in detecting the fraudulent credit card transactions.</p>&#13;
&#13;
<p>The following code summarizes the distribution of average precision across the 10 runs. The mean of the average precision is 0.31, worse than the 0.53 we achieved earlier. The dispersion of average precision is not very tight, with a coefficient<a data-primary="" data-startref="AEPover08" data-type="indexterm" id="idm140637540158704"/> of variation of 0.89:</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.3061984081568074&#13;
Coefficient of variation over 10 runs: 0.8896921668864564&#13;
&#13;
[0.03394897465567298,&#13;
0.14322827274920255,&#13;
0.03610123178524601,&#13;
0.019735235731640446,&#13;
0.012571999125881402,&#13;
0.6788921569665146,&#13;
0.5411349583727725,&#13;
0.388474572258503,&#13;
0.7089617645810736,&#13;
0.4989349153415674]</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Overcomplete Autoencoder with Linear Activation and Dropout" data-type="sect1"><div class="sect1" id="idm140637540447184">&#13;
<h1>Overcomplete Autoencoder with Linear Activation and Dropout</h1>&#13;
&#13;
<p>One<a data-primary="autoencoder example project" data-secondary="overcomplete AE with linear activation and dropout" data-type="indexterm" id="idm140637540154912"/><a data-primary="dropout" data-type="indexterm" id="idm140637540153904"/><a data-primary="regularization" data-type="indexterm" id="idm140637540153232"/> way to improve the overcomplete autoencoder solution is to use a regularization technique to reduce the overfitting. One such technique is known as <em>dropout</em>. With dropout, we force the autoencoder to drop out some defined percentage of units from the layers in the neural network.</p>&#13;
&#13;
<p>With this new constraint, the overcomplete autoencoder cannot simply memorize the credit card transactions in the training set. Instead, the autoencoder has to generalize a bit more. The autoencoder is forced to learn more of the salient features in the dataset and lose some of the less salient information.</p>&#13;
&#13;
<p>We will use a dropout percentage of 10%, which we will apply to the hidden layer. In other words, 10% of the neurons are dropped. The higher the dropout percentage, the stronger the regularization. This is done with just a single additional line of code.</p>&#13;
&#13;
<p>Let’s see if this improves the results:</p>&#13;
&#13;
<pre data-type="programlisting">model = Sequential()&#13;
model.add(Dense(units=40, activation='linear', input_dim=29))&#13;
model.add(Dropout(0.10))&#13;
model.add(Dense(units=29, activation='linear'))</pre>&#13;
&#13;
<p>The following code shows the losses from this autoencoder, and <a data-type="xref" href="#evaluation_metrics_of_overcomplete_autoencoder_with_single_hidden_layer_dropout_and_linear_activation_function">Figure 8-6</a> displays the average precision, the precision-recall curve, and the auROC curve:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of overcomplete autoencoder with single hidden layer,&#13;
dropout, and linear activation function&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 27s 141us/step - loss: 0.1358&#13;
- acc: 0.7430 - val_loss: 0.0082 - val_acc: 0.9742&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 28s 146us/step - loss: 0.0782&#13;
- acc: 0.7849 - val_loss: 0.0094 - val_acc: 0.9689&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 28s 149us/step - loss: 0.0753&#13;
- acc: 0.7858 - val_loss: 0.0102 - val_acc: 0.9672&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 28s 148us/step - loss: 0.0772&#13;
- acc: 0.7864 - val_loss: 0.0093 - val_acc: 0.9677&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 28s 147us/step - loss: 0.0813&#13;
- acc: 0.7843 - val_loss: 0.0108 - val_acc: 0.9631&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 28s 149us/step - loss: 0.0756&#13;
- acc: 0.7844 - val_loss: 0.0095 - val_acc: 0.9654&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 29s 150us/step - loss: 0.0743&#13;
- acc: 0.7850 - val_loss: 0.0077 - val_acc: 0.9768&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 29s 150us/step - loss: 0.0767&#13;
- acc: 0.7840 - val_loss: 0.0070 - val_acc: 0.9759&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 29s 150us/step - loss: 0.0762&#13;
- acc: 0.7851 - val_loss: 0.0072 - val_acc: 0.9733&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 29s 151us/step - loss: 0.0756&#13;
- acc: 0.7849 - val_loss: 0.0067 - val_acc: 0.9749&#13;
93987/93987 [==============================] - 3s 32us/step</pre>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_overcomplete_autoencoder_with_single_hidden_layer_dropout_and_linear_activation_function">&#13;
<img alt="Evaluation Metrics of Overcomplete Autoencoder with Single Hidden Layer, Dropout, and Linear Activation Function" src="assets/hulp_0806.png"/>&#13;
<h6><span class="label">Figure 8-6. </span>Evaluation metrics of overcomplete autoencoder with single hidden layer, dropout, and linear activation function</h6>&#13;
</div></figure>&#13;
&#13;
<p>As expected, the losses are very low, and the overfit overcomplete autoencoder has very poor performance in detecting the fraudulent credit card transactions.</p>&#13;
&#13;
<p>The following code summarizes the distribution of average precision across the 10 runs. The mean of the average precision is 0.21, worse than the 0.53 we achieved earlier. The coefficient of variation is 0.40:</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.21150415381770646&#13;
Coefficient of variation over 10 runs: 0.40295807771579256&#13;
&#13;
[0.22549974304927337,&#13;
0.22451178120391296,&#13;
0.17243952488912334,&#13;
0.2533716906936315,&#13;
0.13251890273915556,&#13;
0.1775116247503748,&#13;
0.4343283958332979,&#13;
0.10469065867732033,&#13;
0.19480068075466764,&#13;
0.19537213558630712]</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sparse Overcomplete Autoencoder with Linear Activation" data-type="sect1"><div class="sect1" id="idm140637540155984">&#13;
<h1>Sparse Overcomplete Autoencoder with Linear Activation</h1>&#13;
&#13;
<p>Another regularization<a data-primary="autoencoder example project" data-secondary="sparse overcomplete AE with linear activation" data-type="indexterm" id="AEPsparse08"/><a data-primary="sparsity penalty" data-type="indexterm" id="idm140637540137840"/> technique is <em>sparsity</em>. We can force the autoencoder to take the sparsity of the matrix into consideration such that the majority of the autoencoder’s neurons are inactive most of the time—in other words, they do not fire. This makes it harder for the autoencoder to memorize the identity function even when the autoencoder is overcomplete because most of the nodes cannot fire and, therefore, cannot overfit the observations as easily.</p>&#13;
&#13;
<p>We will use a single hidden layer overcomplete autoencoder with 40 nodes like before but with just the sparsity penalty, not dropout.</p>&#13;
&#13;
<p>Let’s see if the results improve from the 0.21 average precision we had earlier:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">40</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">,</code>  \&#13;
        <code class="n">activity_regularizer</code><code class="o">=</code><code class="n">regularizers</code><code class="o">.</code><code class="n">l1</code><code class="p">(</code><code class="mf">10e-5</code><code class="p">),</code> <code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code></pre>&#13;
&#13;
<p>The following code shows the losses from this autoencoder, and <a data-type="xref" href="#evaluation_metrics_of_sparse_overcomplete_autoencoder_with_single_hidden_layer_and_linear_activation_function">Figure 8-7</a> displays the average precision, the precision-recall curve, and the auROC curve:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of sparse overcomplete autoencoder with single hidden layer&#13;
and linear activation function&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 27s 142us/step - loss: 0.0985&#13;
- acc: 0.9380 - val_loss: 0.0369 - val_acc: 0.9871&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 26s 136us/step - loss: 0.0284&#13;
- acc: 0.9829 - val_loss: 0.0261 - val_acc: 0.9698&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 26s 136us/step - loss: 0.0229&#13;
- acc: 0.9816 - val_loss: 0.0169 - val_acc: 0.9952&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 26s 137us/step - loss: 0.0201&#13;
- acc: 0.9821 - val_loss: 0.0147 - val_acc: 0.9943&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 26s 137us/step - loss: 0.0183&#13;
- acc: 0.9810 - val_loss: 0.0142 - val_acc: 0.9842&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 26s 137us/step - loss: 0.0206&#13;
- acc: 0.9774 - val_loss: 0.0158 - val_acc: 0.9906&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 26s 136us/step - loss: 0.0169&#13;
- acc: 0.9816 - val_loss: 0.0124 - val_acc: 0.9866&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 26s 137us/step - loss: 0.0165&#13;
- acc: 0.9795 - val_loss: 0.0208 - val_acc: 0.9537&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 26s 136us/step - loss: 0.0164&#13;
- acc: 0.9801 - val_loss: 0.0105 - val_acc: 0.9965&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 27s 140us/step - loss: 0.0167&#13;
- acc: 0.9779 - val_loss: 0.0102 - val_acc: 0.9955&#13;
93987/93987 [==============================] - 3s 32us/step</pre>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_sparse_overcomplete_autoencoder_with_single_hidden_layer_and_linear_activation_function">&#13;
<img alt="Evaluation Metrics of Sparse Overcomplete Autoencoder with Single Hidden Layer and Linear Activation Function" src="assets/hulp_0807.png"/>&#13;
<h6><span class="label">Figure 8-7. </span>Evaluation metrics of sparse overcomplete autoencoder with single hidden layer and linear activation function</h6>&#13;
</div></figure>&#13;
&#13;
<p>The following code summarizes the distribution of average precision across the 10 runs. The mean of the average precision is 0.21, worse than the 0.53 we achieved earlier. The<a data-primary="" data-startref="AEPsparse08" data-type="indexterm" id="idm140637540226000"/> coefficient of variation is 0.99:</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.21373659011504448&#13;
Coefficient of variation over 10 runs: 0.9913040763536749&#13;
&#13;
[0.1370972172100049,&#13;
0.28328895710699215,&#13;
0.6362677613798704,&#13;
0.3467265637372019,&#13;
0.5197889253491589,&#13;
0.01871495737323161,&#13;
0.0812609121251577,&#13;
0.034749761900336684,&#13;
0.04846036143317335,&#13;
0.031010483535317393]</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sparse Overcomplete Autoencoder with Linear Activation and Dropout" data-type="sect1"><div class="sect1" id="idm140637540140256">&#13;
<h1>Sparse Overcomplete Autoencoder with Linear Activation and Dropout</h1>&#13;
&#13;
<p>Of<a data-primary="autoencoder example project" data-secondary="sparse overcomplete AE with linear activation and dropout" data-type="indexterm" id="AEPspdrop08"/> course, we can combine the regularization techniques to improve the solution. Here is a sparse overcomplete autoencoder with linear activation, 40 nodes in the single hidden layer, and dropout of 5%:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">40</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">,</code>  \&#13;
        <code class="n">activity_regularizer</code><code class="o">=</code><code class="n">regularizers</code><code class="o">.</code><code class="n">l1</code><code class="p">(</code><code class="mf">10e-5</code><code class="p">),</code> <code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="mf">0.05</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code></pre>&#13;
&#13;
<p>The following training data shows the losses from this autoencoder, and <a data-type="xref" href="#evaluation_metrics_of_sparse_overcomplete_autoencoder_with_single_hidden_layer_dropout_and_linear_activation">Figure 8-8</a> displays the average precision, the precision-recall curve, and the auROC curve:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of sparse overcomplete autoencoder with single hidden layer,&#13;
dropout, and linear activation function&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 31s 162us/step - loss: 0.1477&#13;
- acc: 0.8150 - val_loss: 0.0506 - val_acc: 0.9727&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 29s 154us/step - loss: 0.0756&#13;
- acc: 0.8625 - val_loss: 0.0344 - val_acc: 0.9788&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 29s 152us/step - loss: 0.0687&#13;
- acc: 0.8612 - val_loss: 0.0291 - val_acc: 0.9790&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 29s 154us/step - loss: 0.0644&#13;
- acc: 0.8606 - val_loss: 0.0274 - val_acc: 0.9734&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 31s 163us/step - loss: 0.0630&#13;
- acc: 0.8597 - val_loss: 0.0242 - val_acc: 0.9746&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 31s 162us/step - loss: 0.0609&#13;
- acc: 0.8600 - val_loss: 0.0220 - val_acc: 0.9800&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 30s 156us/step - loss: 0.0624&#13;
- acc: 0.8581 - val_loss: 0.0289 - val_acc: 0.9633&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 29s 154us/step - loss: 0.0589&#13;
- acc: 0.8588 - val_loss: 0.0574 - val_acc: 0.9366&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 29s 154us/step - loss: 0.0596&#13;
- acc: 0.8571 - val_loss: 0.0206 - val_acc: 0.9752&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 31s 165us/step - loss: 0.0593&#13;
- acc: 0.8590 - val_loss: 0.0204 - val_acc: 0.9808&#13;
93987/93987 [==============================] - 4s 38us/step</pre>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_sparse_overcomplete_autoencoder_with_single_hidden_layer_dropout_and_linear_activation">&#13;
<img alt="Evaluation Metrics of Sparse Overcomplete Autoencoder with Single Hidden Layer, Dropout, and Linear Activation Function" src="assets/hulp_0808.png"/>&#13;
<h6><span class="label">Figure 8-8. </span>Evaluation metrics of sparse overcomplete autoencoder with single hidden layer, dropout, and linear activation function</h6>&#13;
</div></figure>&#13;
&#13;
<p>The following code summarizes the distribution of average precision across the 10 runs. The mean of the average precision is 0.24, worse than the 0.53 we achieved earlier. The<a data-primary="" data-startref="AEPspdrop08" data-type="indexterm" id="idm140637540057936"/> coefficient of variation is 0.62:</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.2426994231628755&#13;
Coefifcient of variation over 10 runs: 0.6153219870606188&#13;
&#13;
[0.6078198313533932,&#13;
0.20862366991302814,&#13;
0.25854513247057875,&#13;
0.08496595007072019,&#13;
0.26313491674585093,&#13;
0.17001322998258625,&#13;
0.15338215561753896,&#13;
0.1439107390306835,&#13;
0.4073422280287587,&#13;
0.1292563784156162]</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Working with Noisy Datasets" data-type="sect1"><div class="sect1" id="idm140637540055712">&#13;
<h1>Working with Noisy Datasets</h1>&#13;
&#13;
<p>A<a data-primary="autoencoder example project" data-secondary="noisy datasets" data-type="indexterm" id="idm140637540054416"/><a data-primary="noisy datasets" data-type="indexterm" id="idm140637540053440"/> common problem with real-world data is noisiness data is often distorted in some way because of data quality issues from data capture, data migration, data transformation, etc. We need autoencoders to be robust enough against such noise so that they are not fooled and can learn from the truly important underlying structure in the data.</p>&#13;
&#13;
<p>To simulate this noise, let’s add a Gaussian random matrix of noise to our credit card transactions dataset and then train an autoencoder on this noisy training set. Then, we will see how well the autoencoder does in predicting fraud on the noisy test set:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">noise_factor</code> <code class="o">=</code> <code class="mf">0.50</code>&#13;
<code class="n">X_train_AE_noisy</code> <code class="o">=</code> <code class="n">X_train_AE</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code> <code class="o">+</code> <code class="n">noise_factor</code> <code class="o">*</code> \&#13;
 <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">normal</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="mf">0.0</code><code class="p">,</code> <code class="n">scale</code><code class="o">=</code><code class="mf">1.0</code><code class="p">,</code> <code class="n">size</code><code class="o">=</code><code class="n">X_train_AE</code><code class="o">.</code><code class="n">shape</code><code class="p">)</code>&#13;
<code class="n">X_test_AE_noisy</code> <code class="o">=</code> <code class="n">X_test_AE</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code> <code class="o">+</code> <code class="n">noise_factor</code> <code class="o">*</code> \&#13;
 <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">normal</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="mf">0.0</code><code class="p">,</code> <code class="n">scale</code><code class="o">=</code><code class="mf">1.0</code><code class="p">,</code> <code class="n">size</code><code class="o">=</code><code class="n">X_test_AE</code><code class="o">.</code><code class="n">shape</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Denoising Autoencoder" data-type="sect1"><div class="sect1" id="idm140637540005904">&#13;
<h1>Denoising Autoencoder</h1>&#13;
&#13;
<p>Compared<a data-primary="autoencoder example project" data-secondary="denoising autoencoders" data-type="indexterm" id="AEPdenoise08"/><a data-primary="denoising autoencoders" data-secondary="goal of" data-type="indexterm" id="idm140637539961072"/> to the original, nondistorted dataset, the penalty for overfitting to the noisy dataset of credit card transactions is much higher. There is enough noise in the dataset that an autoencoder that fits too well to the noisy data will have a poor time detecting fraudulent transactions from normal ones.</p>&#13;
&#13;
<p>This should make sense. We need an autoencoder that fits well enough to the data so that it is able to reconstruct most of the observations well enough but not so well enough that it accidentally reconstructs the noise, too. In other words, we want the autoencoder to learn the underlying structure but forget the noise in the data.</p>&#13;
&#13;
<p>Let’s try a few options from what has worked well so far. First, we will try a single hidden layer, 27-node undercomplete autoencoder with linear activation. Next, we will try a single hidden layer, 40-node sparse overcomplete autoencoder with dropout. And, finally, we will use an autoencoder with a nonlinear activation function.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Two-Layer Denoising Undercomplete Autoencoder with Linear Activation" data-type="sect2"><div class="sect2" id="idm140637539958048">&#13;
<h2>Two-Layer Denoising Undercomplete Autoencoder with Linear Activation</h2>&#13;
&#13;
<p>On<a data-primary="denoising autoencoders" data-secondary="two-layer undercomplete with linear activation" data-type="indexterm" id="idm140637539956352"/> the noisy dataset, the single hidden layer autoencoder with linear activation and 27 nodes had an average precision of 0.69. Let’s see how well it does on the noisy dataset. This autoencoder—because it is working with a noisy dataset and trying to denoise it—is known as a <em>denoising autoencoder</em>.</p>&#13;
&#13;
<p>The code is similar to what we had before except now we are applying it to the noisy training and test datasets, <code>X_train_AE_noisy</code> and <code>X_test_AE_noisy</code>, respectively:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code><code class="mi">10</code><code class="p">):</code>&#13;
    <code class="c1"># Call neural network API</code>&#13;
    <code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
&#13;
    <code class="c1"># Generate hidden layer with 27 nodes using linear activation</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">27</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">,</code> <code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code>&#13;
&#13;
    <code class="c1"># Generate output layer with 29 nodes</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code>&#13;
&#13;
    <code class="c1"># Compile the model</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'adam'</code><code class="p">,</code>&#13;
                  <code class="n">loss</code><code class="o">=</code><code class="s1">'mean_squared_error'</code><code class="p">,</code>&#13;
                  <code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'accuracy'</code><code class="p">])</code>&#13;
&#13;
    <code class="c1"># Train the model</code>&#13;
    <code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">10</code>&#13;
    <code class="n">batch_size</code> <code class="o">=</code> <code class="mi">32</code>&#13;
&#13;
    <code class="n">history</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x</code><code class="o">=</code><code class="n">X_train_AE_noisy</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="n">X_train_AE_noisy</code><code class="p">,</code>&#13;
                        <code class="n">epochs</code><code class="o">=</code><code class="n">num_epochs</code><code class="p">,</code>&#13;
                        <code class="n">batch_size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">,</code>&#13;
                        <code class="n">shuffle</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code>&#13;
                        <code class="n">validation_data</code><code class="o">=</code><code class="p">(</code><code class="n">X_train_AE</code><code class="p">,</code> <code class="n">X_train_AE</code><code class="p">),</code>&#13;
                        <code class="n">verbose</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
&#13;
    <code class="c1"># Evaluate on test set</code>&#13;
    <code class="n">predictions</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test_AE_noisy</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
    <code class="n">anomalyScoresAE</code> <code class="o">=</code> <code class="n">anomalyScores</code><code class="p">(</code><code class="n">X_test</code><code class="p">,</code> <code class="n">predictions</code><code class="p">)</code>&#13;
    <code class="n">preds</code><code class="p">,</code> <code class="n">avgPrecision</code> <code class="o">=</code> <code class="n">plotResults</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code> <code class="n">anomalyScoresAE</code><code class="p">,</code> <code class="bp">True</code><code class="p">)</code>&#13;
    <code class="n">test_scores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">avgPrecision</code><code class="p">)</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">reset_states</code><code class="p">()</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="s2">"Mean average precision over 10 runs: "</code><code class="p">,</code> <code class="n">np</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">test_scores</code><code class="p">))</code>&#13;
<code class="n">test_scores</code></pre>&#13;
&#13;
<p>The following training data shows the losses from this autoencoder, and <a data-type="xref" href="#evaluation_metrics_of_denoising_undercomplete_autoencoder_with_single_hidden_layer_and_linear_activation_function">Figure 8-9</a> displays the average precision, the precision-recall curve, and the auROC curve:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of denoising undercomplete autoencoder with single hidden layer&#13;
and linear activation function&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 25s 133us/step - loss: 0.1733&#13;
- acc: 0.7756 - val_loss: 0.0356 - val_acc: 0.9123&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 24s 126us/step - loss: 0.0546&#13;
- acc: 0.8793 - val_loss: 0.0354 - val_acc: 0.8973&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 24s 126us/step - loss: 0.0531&#13;
- acc: 0.8764 - val_loss: 0.0350 - val_acc: 0.9399&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 24s 126us/step - loss: 0.0525&#13;
- acc: 0.8879 - val_loss: 0.0342 - val_acc: 0.9573&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 24s 126us/step - loss: 0.0530&#13;
- acc: 0.8910 - val_loss: 0.0347 - val_acc: 0.9503&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 24s 126us/step - loss: 0.0524&#13;
- acc: 0.8889 - val_loss: 0.0350 - val_acc: 0.9138&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 24s 126us/step - loss: 0.0531&#13;
- acc: 0.8845 - val_loss: 0.0343 - val_acc: 0.9280&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 24s 126us/step - loss: 0.0530&#13;
- acc: 0.8798 - val_loss: 0.0339 - val_acc: 0.9507&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 24s 126us/step - loss: 0.0526&#13;
- acc: 0.8877 - val_loss: 0.0337 - val_acc: 0.9611&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 24s 127us/step - loss: 0.0528&#13;
- acc: 0.8885 - val_loss: 0.0352 - val_acc: 0.9474&#13;
93987/93987 [==============================] - 3s 34us/step</pre>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_denoising_undercomplete_autoencoder_with_single_hidden_layer_and_linear_activation_function">&#13;
<img alt="Evaluation Metrics of Denoising Undercomplete Autoencoder with Single Hidden Layer and Linear Activation Function" src="assets/hulp_0809.png"/>&#13;
<h6><span class="label">Figure 8-9. </span>Evaluation metrics of denoising undercomplete autoencoder with single hidden layer and linear activation function</h6>&#13;
</div></figure>&#13;
&#13;
<p>The mean average precision is now 0.28. You can see just how difficult it is for the linear autoencoder to denoise this noisy dataset:</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.2825997155005206&#13;
Coeficient of variation over 10 runs: 1.1765416185187383&#13;
&#13;
[0.6929639885685303,&#13;
0.008450118408150287,&#13;
0.6970753417267612,&#13;
0.011820311633718597,&#13;
0.008924124892696377,&#13;
0.010639537507746342,&#13;
0.6884911855668772,&#13;
0.006549332886020607,&#13;
0.6805304226634528,&#13;
0.02055279115125298]</pre>&#13;
&#13;
<p>It struggles with separating the true underlying structure in the data from the Gaussian noise we added.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Two-Layer Denoising Overcomplete Autoencoder with Linear Activation" data-type="sect2"><div class="sect2" id="idm140637539957488">&#13;
<h2>Two-Layer Denoising Overcomplete Autoencoder with Linear Activation</h2>&#13;
&#13;
<p>Let’s<a data-primary="denoising autoencoders" data-secondary="two-layer overcomplete with linear activation" data-type="indexterm" id="idm140637539766064"/> now try a single hidden layer overcomplete autoencoder with 40 nodes, a sparsity regularizer, and dropout of 0.05%.</p>&#13;
&#13;
<p>This had an average precision of 0.56 on the original dataset:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">40</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">,</code>&#13;
 <code class="n">activity_regularizer</code><code class="o">=</code><code class="n">regularizers</code><code class="o">.</code><code class="n">l1</code><code class="p">(</code><code class="mf">10e-5</code><code class="p">),</code>&#13;
                <code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="mf">0.05</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code></pre>&#13;
&#13;
<p>The following training data shows the losses from this autoencoder, and <a data-type="xref" href="#evaluation_metrics_of_denoising_overcomplete_autoencoder_with_dropout_and_linear_activation_function">Figure 8-10</a> displays the average precision, the precision-recall curve, and the auROC curve:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of denoising overcomplete autoencoder with dropout and linear&#13;
activation function&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 28s 145us/step - loss: 0.1726&#13;
- acc: 0.8035 - val_loss: 0.0432 - val_acc: 0.9781&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 26s 138us/step - loss: 0.0868&#13;
- acc: 0.8490 - val_loss: 0.0307 - val_acc: 0.9775&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 26s 138us/step - loss: 0.0809&#13;
- acc: 0.8455 - val_loss: 0.0445 - val_acc: 0.9535&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 26s 138us/step - loss: 0.0777&#13;
- acc: 0.8438 - val_loss: 0.0257 - val_acc: 0.9709&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 27s 139us/step - loss: 0.0748&#13;
- acc: 0.8434 - val_loss: 0.0219 - val_acc: 0.9787&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 26s 138us/step - loss: 0.0746&#13;
- acc: 0.8425 - val_loss: 0.0210 - val_acc: 0.9794&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 26s 138us/step - loss: 0.0713&#13;
- acc: 0.8437 - val_loss: 0.0294 - val_acc: 0.9503&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 26s 138us/step - loss: 0.0708&#13;
- acc: 0.8426 - val_loss: 0.0276 - val_acc: 0.9606&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 26s 139us/step - loss: 0.0704&#13;
- acc: 0.8428 - val_loss: 0.0180 - val_acc: 0.9811&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 27s 139us/step - loss: 0.0702&#13;
- acc: 0.8424 - val_loss: 0.0185 - val_acc: 0.9710&#13;
93987/93987 [==============================] - 4s 38us/step</pre>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_denoising_overcomplete_autoencoder_with_dropout_and_linear_activation_function">&#13;
<img alt="Evaluation Metrics of Denoising Overcomplete Autoencoder with Dropout and Linear Activation Function" src="assets/hulp_0810.png"/>&#13;
<h6><span class="label">Figure 8-10. </span>Evaluation metrics of denoising overcomplete autoencoder with dropout and linear activation function</h6>&#13;
</div></figure>&#13;
&#13;
<p>The following code summarizes the distribution of average precision across the 10 runs. The mean of the average precision is 0.10, worse than the 0.53 we achieved earlier. The coefficient of variation is 0.83:</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.10112931070692295&#13;
Coefficient of variation over 10 runs: 0.8343774832756188&#13;
&#13;
[0.08283546387140524,&#13;
0.043070120657586454,&#13;
0.018901753737287603,&#13;
0.02381040174486509,&#13;
0.16038446580196433,&#13;
0.03461061251209459,&#13;
0.17847771715513427,&#13;
0.2483282420447288,&#13;
0.012981344347664117,&#13;
0.20789298519649893]</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Two-Layer Denoising Overcomplete Autoencoder with ReLu Activation" data-type="sect2"><div class="sect2" id="idm140637539717888">&#13;
<h2>Two-Layer Denoising Overcomplete Autoencoder with ReLu Activation</h2>&#13;
&#13;
<p>Finally, let’s<a data-primary="denoising autoencoders" data-secondary="two-layer overcomplete with ReLu activation" data-type="indexterm" id="idm140637539716352"/> see how the same autoencoder fares using ReLu as the activation function instead of a linear activation function. Recall that the nonlinear activation function autoencoder did not perform quite as well as the one with linear activation on the original dataset:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">40</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'relu'</code><code class="p">,</code>  \&#13;
        <code class="n">activity_regularizer</code><code class="o">=</code><code class="n">regularizers</code><code class="o">.</code><code class="n">l1</code><code class="p">(</code><code class="mf">10e-5</code><code class="p">),</code> <code class="n">input_dim</code><code class="o">=</code><code class="mi">29</code><code class="p">))</code>&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="mf">0.05</code><code class="p">))</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code><code class="o">=</code><code class="mi">29</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'relu'</code><code class="p">))</code></pre>&#13;
&#13;
<p>The following training data shows the losses from this autoencoder, and <a data-type="xref" href="#evaluation_metrics_of_denoising_overcomplete_autoencoder_with_dropout_and_relu_activation_function">Figure 8-11</a> displays the average precision, the precision-recall curve, and the auROC curve:</p>&#13;
&#13;
<pre data-type="programlisting">Training history of denoising overcomplete autoencoder with dropout and ReLU&#13;
activation function"&#13;
&#13;
Train on 190820 samples, validate on 190820 samples&#13;
Epoch 1/10&#13;
190820/190820 [==============================] - 29s 153us/step - loss: 0.3049&#13;
- acc: 0.6454 - val_loss: 0.0841 - val_acc: 0.8873&#13;
Epoch 2/10&#13;
190820/190820 [==============================] - 27s 143us/step - loss: 0.1806&#13;
- acc: 0.7193 - val_loss: 0.0606 - val_acc: 0.9012&#13;
Epoch 3/10&#13;
190820/190820 [==============================] - 27s 143us/step - loss: 0.1626&#13;
- acc: 0.7255 - val_loss: 0.0500 - val_acc: 0.9045&#13;
Epoch 4/10&#13;
190820/190820 [==============================] - 27s 143us/step - loss: 0.1567&#13;
- acc: 0.7294 - val_loss: 0.0445 - val_acc: 0.9116&#13;
Epoch 5/10&#13;
190820/190820 [==============================] - 27s 143us/step - loss: 0.1484&#13;
- acc: 0.7309 - val_loss: 0.0433 - val_acc: 0.9136&#13;
Epoch 6/10&#13;
190820/190820 [==============================] - 27s 144us/step - loss: 0.1467&#13;
- acc: 0.7311 - val_loss: 0.0375 - val_acc: 0.9101&#13;
Epoch 7/10&#13;
190820/190820 [==============================] - 27s 143us/step - loss: 0.1427&#13;
- acc: 0.7335 - val_loss: 0.0384 - val_acc: 0.9013&#13;
Epoch 8/10&#13;
190820/190820 [==============================] - 27s 143us/step - loss: 0.1397&#13;
- acc: 0.7307 - val_loss: 0.0337 - val_acc: 0.9145&#13;
Epoch 9/10&#13;
190820/190820 [==============================] - 27s 143us/step - loss: 0.1361&#13;
- acc: 0.7322 - val_loss: 0.0343 - val_acc: 0.9066&#13;
Epoch 10/10&#13;
190820/190820 [==============================] - 27s 144us/step - loss: 0.1349&#13;
- acc: 0.7331 - val_loss: 0.0325 - val_acc: 0.9107&#13;
93987/93987 [==============================] - 4s 41us/step</pre>&#13;
&#13;
<figure><div class="figure" id="evaluation_metrics_of_denoising_overcomplete_autoencoder_with_dropout_and_relu_activation_function">&#13;
<img alt="Evaluation Metrics of Denoising Overcomplete Autoencoder with Dropout and ReLU Activation Function" src="assets/hulp_0811.png"/>&#13;
<h6><span class="label">Figure 8-11. </span>Evaluation metrics of denoising overcomplete autoencoder with dropout and ReLU activation function</h6>&#13;
</div></figure>&#13;
&#13;
<p>The following code summarizes the distribution of average precision across the 10 runs. The mean of the average precision is 0.20, worse than the 0.53 we achieved earlier. The coefficient of variation is 0.55:</p>&#13;
&#13;
<pre data-type="programlisting">Mean average precision over 10 runs: 0.1969608394689088&#13;
Coefficient of variation over 10 runs: 0.5566706365802669&#13;
&#13;
[0.22960316854089222,&#13;
0.37609633487223315,&#13;
0.11429775486529765,&#13;
0.10208135698072755,&#13;
0.4002384343852861,&#13;
0.13317480663248088,&#13;
0.15764518571284625,&#13;
0.2406315655171392,&#13;
0.05080529996343734,&#13;
0.1650344872187474]</pre>&#13;
&#13;
<p>You can experiment with the number of nodes, layers, degree of sparsity, dropout percentage, and the activation functions to see if you can improve the results from here.<a data-primary="" data-startref="AEPdenoise08" data-type="indexterm" id="idm140637539431904"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm140637539430800">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>In this chapter, we returned to the credit card fraud problem from earlier in the book to develop a neural network-based unsupervised fraud detection solution.</p>&#13;
&#13;
<p>To find the optimal architecture for our autoencoder, we experimented with a variety of autoencoders. We tried complete, undercomplete, and overcomplete autoencoders with either a single or a few hidden layers. We also used both linear and nonlinear activation functions and employed two major types of regularization, sparsity and dropout.</p>&#13;
&#13;
<p>We found that a pretty simple two-layer undercomplete neural network with linear activation worked best on the original credit card dataset, but we needed a sparse two-layer overcomplete autoencoder with linear activation and dropout to address the noise in the noisy credit card dataset.</p>&#13;
&#13;
<p>A lot of our experiments were based on trial and error—for each experiment, we adjusted several hyperparameters and compared results with previous iterations. It is possible that an even better autoencoder-based fraud detection solution exists, and I encourage you to experiment on your own to see what you find.</p>&#13;
&#13;
<p>So far in this book, we have viewed supervised and unsupervised as separate and distinct approaches, but in <a data-type="xref" href="ch09.html#Chapter_9">Chapter 9</a>, we will explore how to employ both supervised and unsupervised approaches jointly to develop a so-called semisupervised solution that is better than either standalone approach.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm140637541443984"><sup><a href="ch08.html#idm140637541443984-marker">1</a></sup> Visit the official documentation for more on the <a href="http://bit.ly/2FZbUrq">Keras Sequential model</a>.</p><p data-type="footnote" id="idm140637541363344"><sup><a href="ch08.html#idm140637541363344-marker">2</a></sup> For more on loss functions, refer to the <a href="https://keras.io/losses/">official Keras documentation</a>.</p><p data-type="footnote" id="idm140637541313568"><sup><a href="ch08.html#idm140637541313568-marker">3</a></sup> Consult Wikipedia for more on <a href="http://bit.ly/2G3Ak30">stochastic gradient descent</a>.</p><p data-type="footnote" id="idm140637541306896"><sup><a href="ch08.html#idm140637541306896-marker">4</a></sup> For more information on optimizers, refer to the <a href="https://keras.io/optimizers/">documentation</a>.</p><p data-type="footnote" id="idm140637541302672"><sup><a href="ch08.html#idm140637541302672-marker">5</a></sup> For more on evaluation metrics, refer to the <a href="https://keras.io/metrics/">documentation</a>.</p></div></div></section></body></html>