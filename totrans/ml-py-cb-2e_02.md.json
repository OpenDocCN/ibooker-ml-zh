["```py\n# Load scikit-learn's datasets\nfrom sklearn import datasets\n\n# Load digits dataset\ndigits = datasets.load_digits()\n\n# Create features matrix\nfeatures = digits.data\n\n# Create target vector\ntarget = digits.target\n\n# View first observation\nfeatures[0]\n```", "```py\narray([  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.,   0.,   0.,  13.,\n        15.,  10.,  15.,   5.,   0.,   0.,   3.,  15.,   2.,   0.,  11.,\n         8.,   0.,   0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.,   0.,\n         5.,   8.,   0.,   0.,   9.,   8.,   0.,   0.,   4.,  11.,   0.,\n         1.,  12.,   7.,   0.,   0.,   2.,  14.,   5.,  10.,  12.,   0.,\n         0.,   0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.])\n```", "```py\n# Load scikit-learn's datasets\nfrom sklearn import datasets\n\n# Load digits dataset\ndigits = datasets.load_digits()\n\n# Print the attribute\nprint(digits.DESCR)\n```", "```py\n.. _digits_dataset:\n\nOptical recognition of handwritten digits dataset\n--------------------------------------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 1797\n    :Number of Attributes: 64\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n    :Missing Attribute Values: None\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n    :Date: July; 1998\n...\n```", "```py\n# Load library\nfrom sklearn.datasets import make_regression\n\n# Generate features matrix, target vector, and the true coefficients\nfeatures, target, coefficients = make_regression(n_samples = 100,\n                                                 n_features = 3,\n                                                 n_informative = 3,\n                                                 n_targets = 1,\n                                                 noise = 0.0,\n                                                 coef = True,\n                                                 random_state = 1)\n\n# View feature matrix and target vector\nprint('Feature Matrix\\n', features[:3])\nprint('Target Vector\\n', target[:3])\n```", "```py\nFeature Matrix\n [[ 1.29322588 -0.61736206 -0.11044703]\n [-2.793085    0.36633201  1.93752881]\n [ 0.80186103 -0.18656977  0.0465673 ]]\nTarget Vector\n [-10.37865986  25.5124503   19.67705609]\n```", "```py\n# Load library\nfrom sklearn.datasets import make_classification\n\n# Generate features matrix and target vector\nfeatures, target = make_classification(n_samples = 100,\n                                       n_features = 3,\n                                       n_informative = 3,\n                                       n_redundant = 0,\n                                       n_classes = 2,\n                                       weights = [.25, .75],\n                                       random_state = 1)\n\n# View feature matrix and target vector\nprint('Feature Matrix\\n', features[:3])\nprint('Target Vector\\n', target[:3])\n```", "```py\nFeature Matrix\n [[ 1.06354768 -1.42632219  1.02163151]\n [ 0.23156977  1.49535261  0.33251578]\n [ 0.15972951  0.83533515 -0.40869554]]\nTarget Vector\n [1 0 0]\n```", "```py\n# Load library\nfrom sklearn.datasets import make_blobs\n\n# Generate features matrix and target vector\nfeatures, target = make_blobs(n_samples = 100,\n                              n_features = 2,\n                              centers = 3,\n                              cluster_std = 0.5,\n                              shuffle = True,\n                              random_state = 1)\n\n# View feature matrix and target vector\nprint('Feature Matrix\\n', features[:3])\nprint('Target Vector\\n', target[:3])\n```", "```py\nFeature Matrix\n [[ -1.22685609   3.25572052]\n [ -9.57463218  -4.38310652]\n [-10.71976941  -4.20558148]]\nTarget Vector\n [0 1 1]\n```", "```py\n# Load library\nimport matplotlib.pyplot as plt\n\n# View scatterplot\nplt.scatter(features[:,0], features[:,1], c=target)\nplt.show()\n```", "```py\n# Load library\nimport pandas as pd\n\n# Create URL\nurl = 'https://raw.githubusercontent.com/chrisalbon/sim_data/master/data.csv'\n\n# Load dataset\ndataframe = pd.read_csv(url)\n\n# View first two rows\ndataframe.head(2)\n```", "```py\n# Load library\nimport pandas as pd\n\n# Create URL\nurl = 'https://raw.githubusercontent.com/chrisalbon/sim_data/master/data.xlsx'\n\n# Load data\ndataframe = pd.read_excel(url, sheet_name=0, header=0)\n\n# View the first two rows\ndataframe.head(2)\n```", "```py\n# Load library\nimport pandas as pd\n\n# Create URL\nurl = 'https://raw.githubusercontent.com/chrisalbon/sim_data/master/data.json'\n\n# Load data\ndataframe = pd.read_json(url, orient='columns')\n\n# View the first two rows\ndataframe.head(2)\n```", "```py\n# Load library\nimport pandas as pd\n\n# Create URL\nurl = 'https://machine-learning-python-cookbook.s3.amazonaws.com/data.parquet'\n\n# Load data\ndataframe = pd.read_parquet(url)\n\n# View the first two rows\ndataframe.head(2)\n```", "```py\n# Load library\nimport requests\nimport pandavro as pdx\n\n# Create URL\nurl = 'https://machine-learning-python-cookbook.s3.amazonaws.com/data.avro'\n\n# Download file\nr = requests.get(url)\nopen('data.avro', 'wb').write(r.content)\n\n# Load data\ndataframe = pdx.read_avro('data.avro')\n\n# View the first two rows\ndataframe.head(2)\n```", "```py\n# Load libraries\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\n# Create a connection to the database\ndatabase_connection = create_engine('sqlite:///sample.db')\n\n# Load data\ndataframe = pd.read_sql_query('SELECT * FROM data', database_connection)\n\n# View first two rows\ndataframe.head(2)\n```", "```py\n# Import libraries\nimport pymysql\nimport pandas as pd\n\n# Create a DB connection\n# Use the following example to start a DB instance\n# https://github.com/kylegallatin/mysql-db-example\nconn = pymysql.connect(\n    host='localhost',\n    user='root',\n    password = \"\",\n    db='db',\n)\n\n# Read the SQL query into a dataframe\ndataframe = pd.read_sql(\"select * from data\", conn)\n\n# View the first two rows\ndataframe.head(2)\n```", "```py\n# Import libraries\nimport pandas as pd\n\n# Google Sheet URL that downloads the sheet as a CSV\nurl = \"https://docs.google.com/spreadsheets/d/\"\\\n      \"1ehC-9otcAuitqnmWksqt1mOrTRCL38dv0K9UjhwzTOA/export?format=csv\"\n\n# Read the CSV into a dataframe\ndataframe = pd.read_csv(url)\n\n# View the first two rows\ndataframe.head(2)\n```", "```py\n# Import libraries\nimport pandas as pd\n\n# S3 path to CSV\ns3_uri = \"s3://machine-learning-python-cookbook/data.csv\"\n\n# Set AWS credentials (replace with your own)\nACCESS_KEY_ID = \"*`xxxxxxxxxxxxx`*\"\nSECRET_ACCESS_KEY = \"*`xxxxxxxxxxxxxxxx`*\"\n\n# Read the CSV into a dataframe\ndataframe = pd.read_csv(s3_uri,storage_options={\n        \"key\": ACCESS_KEY_ID,\n        \"secret\": SECRET_ACCESS_KEY,\n  }\n)\n\n# View first two rows\ndataframe.head(2)\n\n```", "```py\n# Import libraries\nimport requests\n\n# URL to download the txt file from\ntxt_url = \"https://machine-learning-python-cookbook.s3.amazonaws.com/text.txt\"\n\n# Get the txt file\nr = requests.get(txt_url)\n\n# Write it to text.txt locally\nwith open('text.txt', 'wb') as f:\n    f.write(r.content)\n\n# Read in the file\nwith open('text.txt', 'r') as f:\n    text = f.read()\n\n# Print the content\nprint(text)\n```", "```py\nHello there!\n```"]