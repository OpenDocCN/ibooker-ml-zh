<html><head></head><body><section data-pdf-bookmark="Preface" data-type="preface" epub:type="preface"><div class="preface" id="idm140637565348720">&#13;
<h1>Preface</h1>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="A Brief History of Machine Learning" data-type="sect1"><div class="sect1" id="idm140637565275472">&#13;
<h1>A Brief History of Machine Learning</h1>&#13;
&#13;
<p>Machine learning<a data-primary="machine learning" data-secondary="history of" data-type="indexterm" id="idm140637565273264"/><a data-primary="artificial intelligence (AI)" data-secondary="history of" data-type="indexterm" id="idm140637565205200"/> is a subfield of artificial intelligence (AI) in which computers learn from data—usually to improve their performance on some narrowly defined task—without being explicitly programmed. The term <em>machine learning</em> was coined as early as 1959 (by Arthur Samuel, a legend in the field of AI), but there were few major commercial successes in machine learning during the twenty-first century. Instead, the field remained a niche research area for academics at universities.</p>&#13;
&#13;
<p>Early on (in the 1960s) many in the AI community were too optimistic about its future. Researchers at the time, such as Herbert Simon and Marvin Minsky, claimed that AI would reach human-level intelligence within a matter of decades:<sup><a data-type="noteref" href="preface01.html#idm140637565202624" id="idm140637565202624-marker">1</a></sup></p>&#13;
<blockquote>&#13;
<p>Machines will be capable, within twenty years, of doing any work a man can do.</p>&#13;
<p data-type="attribution">Herbert Simon, 1965</p>&#13;
</blockquote>&#13;
<blockquote>&#13;
<p>From three to eight years, we will have a machine with the general intelligence of an average human being.</p>&#13;
<p data-type="attribution">Marvin Minsky, 1970</p>&#13;
</blockquote>&#13;
&#13;
<p>Blinded<a data-primary="general artificial intelligence" data-type="indexterm" id="idm140637564479664"/><a data-primary="strong AI" data-type="indexterm" id="idm140637565244032"/> by their optimism, researchers focused on so-called <em>strong AI</em> or <em>general artificial intelligence (AGI)</em> projects, attempting to build AI agents capable of problem solving, knowledge representation, learning and planning, natural language processing, perception, and motor control. This optimism helped attract significant funding into the nascent field from major players such as the Department of Defense, but the problems these researchers tackled were too ambitious and ultimately doomed to fail.</p>&#13;
&#13;
<p>AI research rarely made the leap from academia to industry, and a series of so-called AI winters followed. In these AI winters (an analogy based on the nuclear winter during this Cold War era), interest in and funding for AI dwindled. Occasionally, hype cycles around AI occurred but had very little staying power. By the early 1990s, interest in and funding for AI had hit a trough.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="AI Is Back, but Why Now?" data-type="sect1"><div class="sect1" id="idm140637565241008">&#13;
<h1>AI Is Back, but Why Now?</h1>&#13;
&#13;
<p>AI<a data-primary="machine learning" data-secondary="critical developments in" data-type="indexterm" id="idm140637570451792"/><a data-primary="artificial intelligence (AI)" data-secondary="critical developments in" data-type="indexterm" id="idm140637570450816"/> has re-emerged with a vengeance over the past two decades—first as a purely academic area of interest and now as a full-blown field attracting the brightest minds at both universities and corporations.</p>&#13;
&#13;
<p>Three critical developments are behind this resurgence: breakthroughs in machine learning algorithms, the availability of lots of data, and superfast computers.</p>&#13;
&#13;
<p>First, instead<a data-primary="weak AI" data-type="indexterm" id="idm140637570448608"/><a data-primary="narrow AI" data-type="indexterm" id="idm140637570447872"/> of focusing on overly ambitious strong AI projects, researchers turned their attention to narrowly defined subproblems of strong AI, also known as <em>weak AI</em> or <em>narrow AI</em>. This focus on improving solutions for narrowly defined tasks led to algorithmic breakthroughs, which paved the way for successful commercial applications. Many of these algorithms—often developed initially at universities or private research labs—were quickly open-sourced, speeding up the adoption of these technologies by industry.</p>&#13;
&#13;
<p>Second, data capture became a focus for most organizations, and the costs of storing data fell dramatically driven by advances in digital data storage. Thanks to the internet, lots of data also became widely and publicly available at a scale never before seen.</p>&#13;
&#13;
<p>Third, computers became increasingly powerful and available over the cloud, allowing AI researchers to easily and cheaply scale their IT infrastructure as required without making huge upfront investments in hardware.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Emergence of Applied AI" data-type="sect1"><div class="sect1" id="idm140637565149136">&#13;
<h1>The Emergence of Applied AI</h1>&#13;
&#13;
<p>These<a data-primary="applied AI (artificial intelligence)" data-type="indexterm" id="idm140637565147760"/><a data-primary="machine learning" data-secondary="applied AI" data-type="indexterm" id="idm140637565282880"/><a data-primary="artificial intelligence (AI)" data-secondary="applied artificial intelligence" data-type="indexterm" id="idm140637565281936"/> three forces have pushed AI from academia to industry, helping attract increasingly higher levels of interest and funding every year. AI is no longer just a theoretical area of interest but rather a full-blown applied field. <a data-type="xref" href="#ml-over-time">Figure P-1</a> shows a chart from Google Trends, indicating the growth in interest in machine learning over the past five years.</p>&#13;
&#13;
<figure><div class="figure" id="ml-over-time">&#13;
<img alt="Interest in machine learning over time" src="assets/hulp_0001.png"/>&#13;
<h6><span class="label">Figure P-1. </span>Interest in machine learning over time</h6>&#13;
</div></figure>&#13;
&#13;
<p>AI is now viewed as a breakthrough horizontal technology, akin to the advent of computers and smartphones, that will have a significant impact on every single industry over the next decade.<sup><a data-type="noteref" href="preface01.html#idm140637564315808" id="idm140637564315808-marker">2</a></sup></p>&#13;
&#13;
<p>Successful<a data-primary="machine learning" data-secondary="commercial applications for" data-type="indexterm" id="idm140637564314720"/><a data-primary="artificial intelligence (AI)" data-secondary="commercial applications for" data-type="indexterm" id="idm140637564313696"/> commercial applications involving machine learning include—but are certainly not limited to—optical character recognition, email spam filtering, image <span class="keep-together">classification</span>, computer vision, speech recognition, machine translation, group <span class="keep-together">segmentation</span> and clustering, generation of synthetic data, anomaly detection, cybercrime prevention, credit card fraud detection, internet fraud detection, time series prediction, natural language processing, board game and video game playing, document classification, recommender systems, search, robotics, online advertising, <span class="keep-together">sentiment</span> analysis, DNA sequencing, financial market analysis, information retrieval, question answering, and healthcare decision making.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Major Milestones in Applied AI over the Past 20 Years" data-type="sect1"><div class="sect1" id="idm140637564309776">&#13;
<h1>Major Milestones in Applied AI over the Past 20 Years</h1>&#13;
&#13;
<p>The<a data-primary="machine learning" data-secondary="major milestones in applied AI" data-type="indexterm" id="MLmajor00"/><a data-primary="artificial intelligence (AI)" data-secondary="major milestones in applied AI" data-type="indexterm" id="AImajor00"/><a data-primary="applied AI (artificial intelligence)" data-type="indexterm" id="idm140637565314944"/> milestones presented here helped bring AI from a mostly academic topic of conversation then to a mainstream staple in technology today.</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>1997: Deep Blue, an AI bot that had been in development since the mid-1980s, beats world chess champion Garry Kasparov in a highly publicized chess event.</p>&#13;
</li>&#13;
<li>&#13;
<p>2004: DARPA introduces the DARPA Grand Challenge, an annually held autonomous driving challenge held in the desert. In 2005, Stanford takes the top prize. In 2007, Carnegie Mellon University performs this feat in an urban setting. In 2009, Google builds a self-driving car. By 2015, many major technology giants, including Tesla, Alphabet’s Waymo, and Uber, have launched well-funded programs to build mainstream self-driving technology.</p>&#13;
</li>&#13;
<li>&#13;
<p>2006: Geoffrey Hinton of the University of Toronto introduces a fast learning algorithm to train neural networks with many layers, kicking off the deep learning revolution.</p>&#13;
</li>&#13;
<li>&#13;
<p>2006: Netflix launches the Netflix Prize competition, with a one million dollar purse, challenging teams to use machine learning to improve its recommendation system’s accuracy by at least 10%. A team won the prize in 2009.</p>&#13;
</li>&#13;
<li>&#13;
<p>2007: AI achieves superhuman performance at checkers, solved by a team from the University of Alberta.</p>&#13;
</li>&#13;
<li>&#13;
<p>2010: ImageNet launches an annual contest—the ImageNet Large Scale Visual Recognition Challenge (ILSVRC)—in which teams use machine learning algorithms to correctly detect and classify objects in a large, well-curated image dataset. This draws significant attention from both academia and technology giants. The classification error rate falls from 25% in 2011 to just a few percent by 2015, backed by advances in deep convolutional neural networks. This leads to commercial applications of computer vision and object recognition.</p>&#13;
</li>&#13;
<li>&#13;
<p>2010: Microsoft launches Kinect for Xbox 360. Developed by the computer vision team at Microsoft Research, Kinect is capable of tracking human body movement and translating this into gameplay.</p>&#13;
</li>&#13;
<li>&#13;
<p>2010: Siri, one of the first mainstream digital voice assistants, is acquired by Apple and released as part of iPhone 4S in October 2011. Eventually, Siri is rolled out across all of Apple’s products. Powered by convolutional neural networks and long short-term memory recurrent neural networks, Siri performs both speech recognition and natural language processing. Eventually, Amazon, Microsoft, and Google enter the race, releasing Alexa (2014), Cortana (2014), and Google Assistant (2016), respectively.</p>&#13;
</li>&#13;
<li>&#13;
<p>2011: IBM Watson, a question-answering AI agent developed by a team led by David Ferrucci, beats former <em>Jeopardy!</em> winners Brad Rutter and Ken Jennings. IBM Watson is now used across several industries, including healthcare and retail.</p>&#13;
</li>&#13;
<li>&#13;
<p>2012: Google Brain team, led by Andrew Ng and Jeff Dean, trains a neural network to recognize cats by watching unlabeled images taken from YouTube <span class="keep-together">videos</span>.</p>&#13;
</li>&#13;
<li>&#13;
<p>2013: Google wins DARPA’s Robotics Challenge, involving trials in which semi-autonomous bots perform complex tasks in treacherous environments, such as driving a vehicle, walking across rubble, removing debris from a blocked entryway, opening a door, and climbing a ladder.</p>&#13;
</li>&#13;
<li>&#13;
<p>2014: Facebook publishes work on DeepFace, a neural network-based system that can identify faces with 97% accuracy. This is near human-level performance and is a more than 27% improvement over previous systems.</p>&#13;
</li>&#13;
<li>&#13;
<p>2015: AI goes mainstream, and is commonly featured in media outlets around the world.</p>&#13;
</li>&#13;
<li>&#13;
<p>2015: Google DeepMind’s AlphaGo beats world-class professional Fan Hui at the game Go. In 2016, AlphaGo defeats Lee Sedol, and in 2017, AlphaGo defeats Ke Jie. In 2017, a new version called AlphaGo Zero defeats the previous AlphaGo version 100 to zero. AlphaGo Zero incorporates unsupervised learning techniques and masters Go just by playing itself.</p>&#13;
</li>&#13;
<li>&#13;
<p>2016: Google launches a major revamp to its language translation, Google <span class="keep-together">Translate</span>, replacing its existing phrase-based translation system with a deep learning-based neural machine translation system, reducing translation errors by up to 87% and approaching near human-level accuracy.</p>&#13;
</li>&#13;
<li>&#13;
<p>2017: Libratus, developed by Carnegie Mellon, wins at head-to-head no-limit Texas Hold’em.</p>&#13;
</li>&#13;
<li>&#13;
<p>2017: OpenAI-trained bot beats professional gamer at Dota 2 tournament.<a data-primary="" data-startref="AImajor00" data-type="indexterm" id="idm140637565477296"/><a data-primary="" data-startref="MLmajor00" data-type="indexterm" id="idm140637565476320"/></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="From Narrow AI to AGI" data-type="sect1"><div class="sect1" id="idm140637565475120">&#13;
<h1>From Narrow AI to AGI</h1>&#13;
&#13;
<p>Of course, these<a data-primary="narrow AI" data-type="indexterm" id="idm140637565186720"/><a data-primary="general artificial intelligence (AGI)" data-type="indexterm" id="idm140637565185984"/> successes in applying AI to narrowly defined problems are just a starting point. There is a growing belief in the AI community that—by combining several weak AI systems—we can develop strong AI. This strong AI or AGI agent will be capable of human-level performance at many broadly defined tasks.</p>&#13;
&#13;
<p>Soon<a data-primary="superintelligence" data-type="indexterm" id="idm140637565184512"/> after AI achieves human-level performance, some researchers predict this strong AI will surpass human intelligence and reach so-called <em>superintelligence</em>. Estimates for attaining such superintelligence range from as little as 15 years to as many as 100 years from now, but most researchers believe AI will advance enough to achieve this in a few generations. Is this inflated hype once again (like what we saw in previous AI cycles), or is it different this time around?</p>&#13;
&#13;
<p>Only time will tell.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Objective and Approach" data-type="sect1"><div class="sect1" id="idm140637565182096">&#13;
<h1>Objective and Approach</h1>&#13;
&#13;
<p>Most<a data-primary="unsupervised learning" data-secondary="approach to learning" data-type="indexterm" id="idm140637565180496"/><a data-primary="machine learning" data-secondary="unsupervised learning for unlabeled data" data-type="indexterm" id="idm140637565179488"/><a data-primary="artificial intelligence (AI)" data-secondary="unsupervised learning for unlabeled data" data-type="indexterm" id="idm140637565178576"/><a data-primary="labeled versus unlabeled data" data-type="indexterm" id="idm140637565177584"/><a data-primary="unlabeled versus labeled data" data-type="indexterm" id="idm140637565176896"/> of the successful commercial applications to date—in areas such as computer vision, speech recognition, machine translation, and natural language processing—have involved supervised learning, taking advantage of labeled datasets. However, most of the world’s data is <em>unlabeled</em>.</p>&#13;
&#13;
<p>In this book, we will cover the field of <em>unsupervised learning</em> (which is a branch of machine learning used to find hidden patterns) and learn the underlying structure in unlabeled data. According to many industry experts, such as Yann LeCun, the Director of AI Research at Facebook and a professor at NYU, unsupervised learning is the next frontier in AI and may hold the key to AGI. For this and many other reasons, unsupervised learning is one of the trendiest topics in AI today.</p>&#13;
&#13;
<p>The book’s goal is to outline the concepts and tools required for you to develop the intuition necessary for applying this technology to everyday problems that you work on. In other words, this is an applied book, one that will allow you to build real-world systems. We will also explore how to efficiently label unlabeled datasets to turn unsupervised learning problems into semisupervised ones.</p>&#13;
&#13;
<p>The book will use a hands-on approach, introducing some theory but focusing mostly on applying unsupervised learning techniques to solving real-world problems. The datasets and code are available online as Jupyter notebooks on <a href="http://bit.ly/2Gd4v7e">GitHub</a>.</p>&#13;
&#13;
<p>Armed with the conceptual understanding and hands-on experience you’ll gain from this book, you will be able to apply unsupervised learning to large, unlabeled datasets to uncover hidden patterns, obtain deeper business insight, detect anomalies, cluster groups based on similarity, perform automatic feature engineering and selection, generate synthetic datasets, and more.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Prerequisites" data-type="sect1"><div class="sect1" id="idm140637565170960">&#13;
<h1>Prerequisites</h1>&#13;
&#13;
<p>This<a data-primary="unsupervised learning" data-secondary="prerequisites to learning" data-type="indexterm" id="idm140637565169632"/> book assumes that you have some Python programming experience, including familiarity with NumPy and Pandas.</p>&#13;
&#13;
<p>For<a data-primary="Jupyter Notebook" data-secondary="resources for learning" data-type="indexterm" id="idm140637565146736"/> more on Python, visit the <a href="https://www.python.org/">official Python website</a>. For more on Jupyter Notebook, visit the <a href="http://jupyter.org/index.html">official Jupyter website</a>. For a refresher on college-level calculus, linear algebra, probability, and statistics, read <a href="http://www.deeplearningbook.org/">Part I of the <em>Deep Learning</em> textbook</a> by Ian Goodfellow and Yoshua Bengio. For<a data-primary="machine learning" data-secondary="resources for learning" data-type="indexterm" id="idm140637565142832"/> a refresher on machine learning, read <a href="https://stanford.io/2Tju4al"><em>The Elements of Statistical Learning</em></a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Roadmap" data-type="sect1"><div class="sect1" id="idm140637565140720">&#13;
<h1>Roadmap</h1>&#13;
&#13;
<p>The<a data-primary="unsupervised learning" data-secondary="topics covered" data-type="indexterm" id="idm140637565139184"/> book is organized into four parts, covering the following topics:</p>&#13;
<dl>&#13;
<dt><a data-type="xref" data-xrefstyle="part-num-title" href="part01.html#Part_One">Part I, <em>Fundamentals of Unsupervised Learning</em></a></dt>&#13;
<dd>&#13;
<p>Differences between supervised and unsupervised learning, an overview of popular supervised and unsupervised algorithms, and an end-to-end machine <span class="keep-together">learning project</span></p>&#13;
</dd>&#13;
<dt><a data-type="xref" data-xrefstyle="part-num-title" href="part02.html#Part_Two">Part II, <em>Unsupervised Learning Using <span class="keep-together">Scikit-Learn</span></em></a></dt>&#13;
<dd>&#13;
<p>Dimensionality reduction, anomaly detection, and clustering and group <span class="keep-together">segmentation</span></p>&#13;
</dd>&#13;
</dl>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>For more information on the concepts discussed in Parts I and II, refer to the <a href="https://scikit-learn.org/stable/modules/classes.html">Scikit-learn documentation</a>.</p>&#13;
</div>&#13;
<dl>&#13;
<dt><a data-type="xref" data-xrefstyle="part-num-title" href="part03.html#Part_Three">Part III, <em>Unsupervised Learning Using TensorFlow and Keras</em></a></dt>&#13;
<dd>&#13;
<p>Representation learning and automatic feature extraction, autoencoders, and semisupervised learning</p>&#13;
</dd>&#13;
<dt><a data-type="xref" data-xrefstyle="part-num-title" href="part04.html#Part_Four">Part IV, <em>Deep Unsupervised Learning Using TensorFlow and Keras</em></a></dt>&#13;
<dd>&#13;
<p>Restricted Boltzmann machines, deep belief networks, and generative adversarial networks</p>&#13;
</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Conventions Used in This Book" data-type="sect1"><div class="sect1" id="idm140637565124608">&#13;
<h1>Conventions Used in This Book</h1>&#13;
&#13;
<p>The<a data-primary="typographical conventions" data-type="indexterm" id="idm140637565123040"/> following typographical conventions are used in this book:</p>&#13;
<dl>&#13;
<dt><em>Italic</em></dt>&#13;
<dd>&#13;
<p>Indicates new terms, URLs, email addresses, filenames, and file extensions.</p>&#13;
</dd>&#13;
<dt><code>Constant width</code></dt>&#13;
<dd>&#13;
<p>Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.</p>&#13;
</dd>&#13;
<dt><strong><code>Constant width bold</code></strong></dt>&#13;
<dd>&#13;
<p>Shows commands or other text that should be typed literally by the user.</p>&#13;
</dd>&#13;
<dt><em><code>Constant width italic</code></em></dt>&#13;
<dd>&#13;
<p>Shows text that should be replaced with user-supplied values or by values determined by context.</p>&#13;
</dd>&#13;
</dl>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>This element signifies a tip or suggestion.</p>&#13;
</div>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>This element signifies a general note.</p>&#13;
</div>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>This element indicates a warning or caution.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Using Code Examples" data-type="sect1"><div class="sect1" id="idm140637565111504">&#13;
<h1>Using Code Examples</h1>&#13;
&#13;
<p>Supplemental<a data-primary="code examples, obtaining and using" data-type="indexterm" id="idm140637565109936"/> material (code examples, etc.) is available for download on <a href="http://bit.ly/2Gd4v7e">GitHub</a>.</p>&#13;
&#13;
<p>This book is here to help you get your job done. In general, if example code is offered with this book, you may use it in your programs and documentation. You do not need to contact us for permission unless you’re reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing a CD-ROM of examples from O’Reilly books does require permission. Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product’s documentation does require permission.</p>&#13;
&#13;
<p>We<a data-primary="attributions" data-type="indexterm" id="idm140637565106800"/> appreciate, but do not require, attribution. An attribution usually includes the title, author, publisher, and ISBN. For example: “<em>Hands-On Unsupervised Learning Using Python</em> by Ankur A. Patel (O’Reilly). Copyright 2019 Ankur A. Patel, 978-1-492-03564-0.”</p>&#13;
&#13;
<p>If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at <a class="email" href="mailto:permissions@oreilly.com"><em>permissions@oreilly.com</em></a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="O’Reilly Online Learning" data-type="sect1"><div class="sect1" id="idm140637565103584">&#13;
<h1>O’Reilly Online Learning</h1>&#13;
<div class="ormenabled" data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>For almost 40 years, <a class="orm:hideurl" href="http://oreilly.com"><em class="hyperlink">O’Reilly Media</em></a> has provided technology and business training, knowledge, and insight to help companies succeed.</p>&#13;
</div>&#13;
&#13;
<p>Our unique network of experts and innovators share their knowledge and expertise through books, articles, conferences, and our online learning platform. O’Reilly’s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from O’Reilly and 200+ other publishers. For more information, please visit <a class="orm:hideurl" href="http://oreilly.com"><em>http://oreilly.com</em></a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="How to Contact Us" data-type="sect1"><div class="sect1" id="idm140637565097376">&#13;
<h1>How to Contact Us</h1>&#13;
&#13;
<p>Please<a data-primary="contact information" data-type="indexterm" id="idm140637565095376"/><a data-primary="questions and comments" data-type="indexterm" id="idm140637565094640"/><a data-primary="comments and questions" data-type="indexterm" id="idm140637565093968"/> address comments and questions concerning this book to the publisher:</p>&#13;
<ul class="simplelist">&#13;
  <li>O’Reilly Media, Inc.</li>&#13;
  <li>1005 Gravenstein Highway North</li>&#13;
  <li>Sebastopol, CA 95472</li>&#13;
  <li>800-998-9938 (in the United States or Canada)</li>&#13;
  <li>707-829-0515 (international or local)</li>&#13;
  <li>707-829-0104 (fax)</li>&#13;
</ul>&#13;
&#13;
<p>We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at <a href="http://bit.ly/unsupervised-learning"><em class="hyperlink">http://bit.ly/unsupervised-learning</em></a>.</p>&#13;
<!--Don't forget to update the link above.-->&#13;
&#13;
<p>To comment or ask technical questions about this book, send email to <a class="email" href="mailto:bookquestions@oreilly.com"><em>bookquestions@oreilly.com</em></a>.</p>&#13;
&#13;
<p>For more information about our books, courses, conferences, and news, see our website at <a href="http://www.oreilly.com"><em class="hyperlink">http://www.oreilly.com</em></a>.</p>&#13;
&#13;
<p>Find us on Facebook: <a href="http://facebook.com/oreilly"><em class="hyperlink">http://facebook.com/oreilly</em></a></p>&#13;
&#13;
<p>Follow us on Twitter: <a href="http://twitter.com/oreillymedia"><em class="hyperlink">http://twitter.com/oreillymedia</em></a></p>&#13;
&#13;
<p>Watch us on YouTube: <a href="http://www.youtube.com/oreillymedia"><em class="hyperlink">http://www.youtube.com/oreillymedia</em></a></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm140637565202624"><sup><a href="preface01.html#idm140637565202624-marker">1</a></sup> Such views inspired Stanley Kubrick in 1968 to create the AI agent HAL 9000 in <em>2001: A Space Odyssey</em>.</p><p data-type="footnote" id="idm140637564315808"><sup><a href="preface01.html#idm140637564315808-marker">2</a></sup> According to McKinsey Global Institute, over half of all the professional activities people are paid to do could be automated by 2055.</p></div></div></section></body></html>