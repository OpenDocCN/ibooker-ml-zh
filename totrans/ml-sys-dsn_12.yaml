- en: 10 Training pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 训练管道
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章节涵盖
- en: The essence of training pipelines
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练管道的本质
- en: Tools and platforms you can use to build and maintain training pipelines
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用哪些工具和平台来构建和维护训练管道
- en: Scalability and configurability of training pipelines
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练管道的可扩展性和可配置性
- en: Methods of testing pipelines
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试管道的方法
- en: 'There’s an empirical heuristic to distinguish experienced machine learning
    (ML) engineers from newcomers: ask them to describe a working system’s training
    procedure in one sentence. Newcomers tend to focus on models, while somewhat experienced
    individuals include data processing. Mature engineers often describe the pipeline—a
    list of stages required to produce a trained ML model in the end. In this chapter,
    we will walk in ML engineers’ shoes to analyze these steps and discuss how to
    interconnect and orchestrate them.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个经验法则可以区分经验丰富的机器学习（ML）工程师和新手：要求他们用一句话描述一个工作系统的训练过程。新手往往关注模型，而有些经验丰富的人会包括数据处理。成熟的工程师通常描述管道——最终产生训练好的ML模型所需的一系列阶段。在本章中，我们将以ML工程师的视角来分析这些步骤，并讨论如何相互连接和编排它们。
- en: '10.1 Training pipeline: What are you?'
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 训练管道：你是谁？
- en: Imagine a small pizza chain company. Its business has been a success in the
    local market, but the owners who understand that software is eating the world
    (a phrase taken from Marc Anderssen’s article, [https://a16z.com/why-software-is-eating-the-world/](https://a16z.com/why-software-is-eating-the-world/))
    and everything is going digital know there’s more pie to grab. So it makes this
    digitalization bet before the COVID pandemic and hires several engineers to build
    mobile apps, a simple customer relationship management plan, and multiple internal
    software systems. In other words, the company doesn’t have the scale or appetite
    of a tech giant, but it follows major trends and knows how to invest in software
    now to make significant profits later. Suffice it to mention that its app helped
    the company survive the pandemic in 2020.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一家小型比萨连锁公司。它在当地市场取得了成功，但那些理解软件正在吞噬世界（这句话来自马克·安德森的文章，[https://a16z.com/why-software-is-eating-the-world/](https://a16z.com/why-software-is-eating-the-world/))以及一切都在数字化的老板们知道还有更多的市场份额可以抢占。因此，在COVID大流行之前，它就下注于数字化，雇佣了几位工程师来构建移动应用、简单的客户关系管理计划和多个内部软件系统。换句话说，这家公司没有科技巨头的规模或胃口，但它遵循主要趋势，并知道如何现在投资软件以在将来获得显著的利润。只需提及，它的应用帮助公司在2020年大流行中幸存下来。
- en: 'Now, with the company following trends and the AI hype train full steam ahead,
    it’s no surprise that it hires Jane, a young and promising ML engineer whose interest
    in ML is undeniable. After onboarding, the CTO delegates her first problem to
    solve: build an AI-powered assistant that will help Pizzaiolos perform basic visual
    assessments like listing and calculating the number of components on the pizza
    base for each order.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，随着公司跟随趋势，人工智能热潮全面展开，雇佣Jane这位年轻而有潜力的机器学习工程师也就不足为奇了。她的兴趣在机器学习方面是无可否认的。入职后，CTO将她的第一个问题交给她解决：构建一个AI驱动的助手，帮助比萨师傅对每个订单的比萨底部的组件进行基本视觉评估，如列出和计算组件数量。
- en: The software development lifecycle in this pizza company hasn’t included ML
    systems so far. Thus, engineering manager Alex asks Jane to prepare a model and
    a small code snippet showing how to run it; the internal systems team will handle
    the rest.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这家比萨公司中，软件开发生命周期至今尚未包括机器学习系统。因此，工程经理Alex要求Jane准备一个模型和一小段代码片段，展示如何运行它；内部系统团队将处理其余部分。
- en: 'Fast-forward several months later: Jane gathered a small dataset and trained
    a model, and it all looked fine during the initial testing, so Alex’s team managed
    to wrap it in a service. But right before deployment, the product manager brought
    multiple new recipes that were added to the menu and said the model should be
    able to support those too. This was nothing complicated and involved just adding
    some more data, changing the labels map, and retraining the model—sounds like
    something that shouldn’t affect the deployment schedule much. However, after a
    discussion, Jane and Alex realized it would take several more months, even assuming
    the new dataset is readily available. What went wrong here? Jane performed all
    the required steps to train a model—manually validating datasets, applying numerous
    data processing and cleaning steps in the Jupyter Notebook environment, training
    the model with multiple interruptions, validating the result with the chef and
    customer happiness team on an ad hoc basis, uploading the trained model to the
    company’s shared storage, and sending the link back to Alex.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 快进几个月后：Jane 收集了一个小数据集并训练了一个模型，在最初的测试中一切看起来都很正常，所以 Alex 的团队设法将其包装成一个服务。但在部署前，产品经理带来了多个新食谱，并说模型也应该能够支持这些。这并不复杂，只需要添加一些更多数据，更改标签映射，并重新训练模型——听起来好像不会对部署时间表产生太大影响。然而，经过讨论，Jane
    和 Alex 认识到即使假设新的数据集已经准备好，这也需要额外几个月的时间。这里出了什么问题？Jane 执行了所有训练模型所需的步骤——手动验证数据集，在
    Jupyter Notebook 环境中应用大量数据处理和清洗步骤，多次中断训练模型，临时性地与厨师和客户满意度团队验证结果，将训练好的模型上传到公司的共享存储，并将链接发送回
    Alex。
- en: Note  She did all the right things but followed an ad hoc approach, with no
    proper effort to make those steps reproducible in a single, transparent workflow.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：她做了所有正确的事情，但采取了一种临时的方法，没有适当的努力使这些步骤在一个单一的、透明的流程中可重复。
- en: With this example, we want to show that ML is not just about training a model
    but also about building a pipeline that allows for the preparation of the model
    and other artifacts in a reproducible way. In this chapter, we will discuss the
    steps in the pipeline, how to orchestrate them, and how to make them reproducible.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个例子，我们想表明机器学习不仅仅是训练一个模型，还包括构建一个流水线，以便以可重复的方式准备模型和其他工件。在本章中，我们将讨论流水线中的步骤，如何编排它们，以及如何使它们可重复。
- en: 10.1.1 Training pipeline vs. inference pipeline
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 训练流水线与推理流水线
- en: In the ML world, the term “pipeline” is used in many different contexts. Usually,
    people refer to a pipeline as a series of ordered steps and processes. Each step
    is a program that takes some input, performs some actions, and produces some output.
    The output of one step is the input for the next step. Speaking more formally,
    we can usually describe the pipeline as a directed acyclic graph (DAG) of steps.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习领域，“流水线”这个术语被用于许多不同的上下文中。通常，人们将流水线视为一系列有序的步骤和过程。每个步骤都是一个程序，它接受一些输入，执行一些操作，并产生一些输出。一个步骤的输出是下一个步骤的输入。更正式地说，我们通常可以将流水线描述为步骤的有向无环图（DAG）。
- en: To make things more complicated, the model itself is usually a pipeline of another
    kind. For example, a simple logistic regression classifier is often enhanced with
    a feature scaling step, resulting in a pipeline of at least two steps. Usually,
    there’s also basic feature engineering (e.g., one-hot encoding for categorical
    variables), so even the simplest model has the properties of a pipeline. Other
    modalities like images, text, audio, etc., require additional preprocessing steps.
    For instance, a typical image classification model is a pipeline of image reading,
    normalization, resizing, and the model itself. If we switch to natural language
    processing, the pipeline almost always starts with text tokenization, etc. All
    in all, there’s a lot of space for ambiguity and confusion surrounding the term
    “pipeline” itself. To make things clearer, we will use the following terminology.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要使事情更加复杂，模型本身通常是一个另一种类型的流水线。例如，一个简单的逻辑回归分类器通常通过一个特征缩放步骤来增强，从而形成一个至少包含两个步骤的流水线。通常，还会有基本的特征工程（例如，对分类变量进行独热编码），因此即使是最简单的模型也具有流水线的特性。其他模态，如图像、文本、音频等，需要额外的预处理步骤。例如，一个典型的图像分类模型是一个包含图像读取、归一化、调整大小以及模型本身的流水线。如果我们转向自然语言处理，流水线几乎总是从文本分词等步骤开始。总的来说，围绕“流水线”这个术语本身存在很多模糊和混淆的空间。为了使事情更清晰，我们将使用以下术语。
- en: '*Training pipeline* refers to a pipeline used to train a model. It’s a DAG
    of steps that takes the full dataset and, optionally, additional metadata as input
    and produces a trained model as output. It is a higher-level abstraction than
    the model itself (see figure 10.1).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*训练管道*指的是用于训练模型的管道。它是一系列步骤的DAG（有向无环图），这些步骤接收完整的数据集和可选的元数据作为输入，并产生一个训练好的模型作为输出。它比模型本身是一个更高层次的抽象（见图10.1）。'
- en: '![figure](../Images/CH10_F01_Babushkin.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F01_Babushkin.png)'
- en: Figure 10.1 A DAG scheme representing a training pipeline
  id: totrans-19
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.1 表示训练管道的DAG方案
- en: '*Inference pipeline* refers to a pipeline used to run a model in production
    or as part of a training pipeline (e.g., training a neural network with gradient
    descent requires numerous inference steps, each of which is a pipeline). It’s
    a DAG of steps that takes raw data as input and produces predictions as output.
    It is a lower-level abstraction than the training pipeline (see figure 10.2).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*推理管道*指的是用于在生产环境中运行模型或作为训练管道一部分的管道（例如，使用梯度下降训练神经网络需要多个推理步骤，每个步骤都是一个管道）。它是一系列步骤的DAG，这些步骤接收原始数据作为输入，并产生预测作为输出。它比训练管道是一个更低层次的抽象（见图10.2）。'
- en: '![figure](../Images/CH10_F02_Babushkin.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F02_Babushkin.png)'
- en: Figure 10.2 A scheme representing a training step in a pipeline
  id: totrans-22
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.2 表示管道中训练步骤的方案
- en: 'In this chapter, we will focus on the training pipeline, while the inference
    pipeline will be discussed in chapter 15\. At the highest level, a typical training
    pipeline includes the following steps:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注训练管道，而推理管道将在第15章中讨论。在最高层次上，典型的训练管道包括以下步骤：
- en: Data fetching
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据获取
- en: Preprocessing
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理
- en: Model training
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练
- en: Model evaluation and testing
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型评估和测试
- en: Postprocessing
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 后处理
- en: Report generation
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 报告生成
- en: Artifact packaging
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 艺术品打包
- en: Let’s briefly break down each of the steps.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要地分解每个步骤。
- en: '*Data fetching* is the first step in the pipeline. It is responsible for downloading
    the data from the sources and making it available for the subsequent steps. As
    mentioned in chapter 6, we do not consider ourselves data engineering experts,
    so we will not discuss data fetching and storage in detail.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据获取*是管道中的第一步。它负责从源下载数据，并使其对后续步骤可用。如第6章所述，我们不将自己视为数据工程专家，因此不会详细讨论数据获取和存储。'
- en: '*Preprocessing* is usually the second step in the pipeline. It is a very generic
    term that can have a different meaning for a respective task. In general, preprocessing
    is a set of actions performed to prepare the data for model training. While we
    separate the training and inference pipelines for the sake of the book’s structure,
    the distinction can be somewhat blurry in practice. For example, you can fully
    preprocess the raw dataset before training the model or, alternatively, make it
    part of a single model inference. In this context, we are discussing training-specific
    preprocessing. Feature selection is one example of such preprocessing: we only
    do it before training and freeze the selected features for the subsequent steps.
    *Model training* is the core of the training pipeline. It is a step that takes
    preprocessed data and produces a trained model; it is usually the longest and
    most complex (especially in deep learning-based systems) step in the pipeline.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*预处理*通常是管道中的第二步。这是一个非常通用的术语，对于不同的任务可能有不同的含义。一般来说，预处理是一组为准备数据以供模型训练而执行的操作。虽然我们为了本书的结构将训练和推理管道分开，但在实践中这种区分可能有些模糊。例如，你可以在训练模型之前完全预处理原始数据集，或者将其作为单个模型推理的一部分。在这种情况下，我们讨论的是特定于训练的预处理。特征选择是此类预处理的一个例子：我们只在训练之前执行它，并将选定的特征冻结在后续步骤中。*模型训练*是训练管道的核心。这是一个接收预处理数据并产生训练模型的步骤；它通常是管道中最长且最复杂的步骤（尤其是在基于深度学习的系统中）。'
- en: 'After the model has been trained, it can be *evaluated and tested*. These are
    different aspects aiming to answer the same question: how good is the model? Evaluation
    is a step of computing metrics, while tests are a set of checks performed to ensure
    that the model is working as expected.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练完成后，它可以被*评估和测试*。这些不同的方面旨在回答同一个问题：模型有多好？评估是计算指标的一个步骤，而测试是一系列检查，以确保模型按预期工作。
- en: '*Postprocessing* is a step that is performed after evaluation and testing.
    It is a set of actions performed to prepare the model for deployment. Here, we
    can convert the model to a format supported by the target platforms, apply posttraining
    quantization or other optimizations if applicable, prepare tasks for human evaluation,
    and so on. It is worth noting that postprocessing and evaluation can be swapped.
    For example, we can evaluate the model before converting it to the target format,
    or alternatively, we can convert the model to the target format and then evaluate
    it using the deployment format.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*后处理*是在评估和测试之后执行的一个步骤。它是一组执行以准备模型部署的动作。在这里，我们可以将模型转换为支持的目标平台格式，如果适用，应用后训练量化或其他优化，准备供人类评估的任务，等等。值得注意的是，后处理和评估可以互换。例如，我们可以在将模型转换为目标格式之前评估模型，或者相反，我们可以在将模型转换为目标格式后使用部署格式进行评估。'
- en: '*Artifact packaging* is the last step in the pipeline. It is responsible for
    packaging the model and other artifacts (e.g., config files with preprocessor
    parameters) into a format that can be easily deployed to production. The goal
    here is to simplify further deployment and separate the training and deployment
    pipelines. Ideally, the output should be as agnostic as possible to the training
    pipeline. For example, the model is exported to a universal format like ONNX for
    backend serving or CoreML for iOS serving, all config files are exported to a
    universal format like JSON, and any changes in the training pipeline should affect
    deployment as little as possible. Otherwise, the deployment pipeline will be tightly
    coupled with the training pipeline and will require many changes after each training
    pipeline update, becoming an obstacle for rapid model development and related
    experiments.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*工件打包*是流程中的最后一步。它负责将模型和其他工件（例如，包含预处理参数的配置文件）打包成易于部署到生产环境的格式。这里的目的是简化进一步的部署并分离训练和部署流程。理想情况下，输出应该尽可能与训练流程无关。例如，模型被导出为ONNX这样的通用格式以供后端服务或CoreML以供iOS服务使用，所有配置文件都导出为JSON这样的通用格式，并且训练流程中的任何变化都应尽可能少地影响部署。否则，部署流程将与训练流程紧密耦合，并在每次训练流程更新后需要许多更改，从而成为快速模型开发和相关实验的障碍。'
- en: '*Reports* are a special case of artifacts. It is a generic term that can be
    related to many things, including a basic table containing validation/test metrics,
    various types of error analysis (recall chapter 9), additional visualizations,
    and other auxiliary information. While these artifacts are not directly used for
    deployment, they’re crucial to consider the training successful; no responsible
    engineer can release a newly trained model without having at least a short look
    at proper reports. The only exception we have seen is a variation of an AutoML
    scenario when many new models are trained automatically per user requests. In
    this case, manual validation is not always possible; thus, engineers can only
    review suspicious outliers. We will touch on the topic of the release cycle in
    chapter 13\.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*报告*是工件的一种特殊情况。这是一个通用术语，可以与许多事物相关联，包括包含验证/测试指标的基本表格、各种类型的错误分析（参见第9章）、额外的可视化和其他辅助信息。虽然这些工件不是直接用于部署的，但它们对于考虑训练成功至关重要；没有责任心的工程师在至少简要查看适当的报告之前不会发布新训练的模型。我们看到的唯一例外是AutoML场景的一种变体，当根据用户请求自动训练许多新模型时。在这种情况下，手动验证并不总是可能的；因此，工程师只能审查可疑的异常值。我们将在第13章中讨论发布周期的话题。'
- en: Some of these artifacts are related to experiment tracking and reproducibility,
    and those are crucial for projects with multiple contributors or involved parties.
    When a researcher works alone on their own problem, they can track all their ideas
    and experiments using a simple notebook or a text file. However, when a team of
    researchers works on the same problem, they need a more structured way to track,
    compare, and reproduce their experiments. A centralized repository for all experiments
    is one tool that can help achieve this.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一些这些工件与实验跟踪和可重复性相关，对于有多个贡献者或参与方的项目来说，这些是至关重要的。当研究人员独立研究他们自己的问题时，他们可以使用简单的笔记本或文本文件来跟踪他们所有的想法和实验。然而，当一组研究人员共同研究同一个问题时，他们需要一个更结构化的方式来跟踪、比较和重现他们的实验。为所有实验建立一个集中式存储库是帮助实现这一目标的工具之一。
- en: 10.2 Tools and platforms
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 工具和平台
- en: Tools and practices related to the training pipeline, along with the inference
    pipelines, deployment pipelines, and monitoring services in the context of the
    ML system design, are often attributed to ML operations (MLOps). Given that MLOps
    is a relatively new field, there are no well-established standards for platforms
    and tools. Some of them are relatively recognizable (MLflow, Kubeflow, BentoML,
    AWS Sagemaker, Google Vertex AI, Azure ML), some are gaining traction right now,
    and some are still in the early stages of development.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 与训练管道相关的工具和实践，以及机器学习系统设计背景下的推理管道、部署管道和监控服务，通常归因于机器学习操作（MLOps）。鉴于MLOps是一个相对较新的领域，平台和工具还没有形成良好的标准。其中一些相对容易识别（MLflow、Kubeflow、BentoML、AWS
    Sagemaker、Google Vertex AI、Azure ML），一些正在获得关注，而一些还处于早期开发阶段。
- en: 'In this book, we don’t want to highlight any specific platform or tool, so
    we will not discuss them in detail. Given the pace of changes in the MLOps landscape,
    it’s very likely that our current understanding of the tools and platforms will
    be outdated by the time the book is published. Instead, we will focus on the principles
    and practices that are common to all platforms and tools. In the simplest case,
    you can implement a full training pipeline using generic non-ML tools—by creating
    a series of Python scripts connected with shell scripts, for example. However,
    this is rarely the case in practice: usually, there are some ML-specific tools
    that introduce abstractions and simplify the pipeline implementation. Most MLOps
    tools are “opinionated,” which means that using them strongly suggests a particular
    way of structuring your code. In the long run, this improves the training pipeline’s
    code consistency and makes it easier to maintain in the future (see chapter 16).
    Typical features required from the training pipeline platform are'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们不希望突出任何特定的平台或工具，因此我们不会详细讨论它们。鉴于MLOps领域的变革速度，我们目前对工具和平台的理解在本书出版时很可能已经过时。相反，我们将专注于所有平台和工具共有的原则和实践。在最简单的情况下，你可以使用通用的非机器学习工具实现完整的训练管道——例如，通过创建一系列与shell脚本连接的Python脚本。然而，在实践中很少是这样：通常有一些特定的机器学习工具引入了抽象并简化了管道实现。大多数MLOps工具都是“有偏见的”，这意味着使用它们强烈暗示了特定的代码结构方式。从长远来看，这提高了训练管道代码的一致性，并使其在未来更容易维护（参见第16章）。通常需要从训练管道平台获得的一些典型功能包括
- en: '*Resolving dependencies—*As the pipeline is a DAG of steps, it’s important
    to resolve dependencies between steps and run them in the right order.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*解决依赖关系—*由于管道是一系列步骤的DAG，因此解决步骤之间的依赖关系并按正确顺序运行它们很重要。'
- en: '*Reproducibility—*Given a set of parameters and pipeline version (e.g., specified
    by git commit), the pipeline should produce the same result every time.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可重现性—*给定一组参数和管道版本（例如，由git提交指定），管道应该每次都产生相同的结果。'
- en: '*Integration with computational resources (such as cloud providers or Kubernetes
    installations)*—For example, users should be able to run the job on a specific
    compute instance (e.g., a virtual machine with X CPU cores and N GPUs) or on a
    cluster of instances.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*与计算资源集成（如云提供商或Kubernetes安装）*—例如，用户应该能够在特定的计算实例上运行作业（例如，具有X个CPU核心和N个GPU的虚拟机）或在一组实例的集群上。'
- en: '*Artifacts storage—*Once the training pipeline has been run, its artifacts
    should be available. Experiment tracking can be viewed as a subset of this feature.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*工件存储—*一旦训练管道运行完毕，其工件应该可用。实验跟踪可以被视为此功能的一个子集。'
- en: '*Caching intermediate results—*As long as many steps in the pipeline are computationally
    expensive, it’s important to cache intermediate results to save resources and
    time.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*缓存中间结果—*只要管道中的许多步骤都是计算密集型的，缓存中间结果以节省资源和时间就很重要。'
- en: Besides features, it is important to mention some nonfunctional requirements
    that practitioners need from platforms, including cost-effectiveness and data
    privacy (especially in such sensitive areas as healthcare or legal).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 除了功能之外，还重要的是要提及一些实践者从平台中需要的非功能性需求，包括成本效益和数据隐私（尤其是在医疗保健或法律等敏感领域）。
- en: It’s important to emphasize here that features don’t have to be covered by the
    same platform. For example, you can use a generic platform for running the pipeline
    and a custom tool for experiment tracking because market solutions don’t satisfy
    custom requirements. Sometimes it’s just a matter of cost optimization. Arseny
    worked in a company that used a hybrid of two tools just because one provided
    many useful features and an overall nice developer experience, while the other
    was integrated with a cloud provider with the cheapest GPUs for training. In this
    situation, it was reasonable to spend some time on integration and save a lot
    of money on training costs.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要强调的是，功能不一定需要由同一个平台提供。例如，你可以使用一个通用平台来运行流水线，并使用一个定制的工具来进行实验跟踪，因为市场解决方案无法满足定制需求。有时这只是一个成本优化的问题。阿森尼曾在一家公司工作，该公司使用两种工具的混合体，因为其中一种提供了许多有用的功能，并且整体上为开发者提供了良好的体验，而另一种则与提供最便宜GPU的云服务提供商集成。在这种情况下，花一些时间进行集成并在训练成本上节省大量资金是合理的。
- en: Choosing proper tools is determined by the problem scale and the infrastructure
    of the company. FAANG-level companies usually have their own ML platforms and
    tools that can operate on a proper scale, while smaller companies typically prefer
    a set of open-source tools and cloud services. Every tool has its own adoption
    cost, so it’s important to choose the proper tool for the right problem. To the
    best of our knowledge, there is no one-size-fits-all solution, unlike with many
    other more mature software engineering problems (see figure 10.3).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的工具取决于问题规模和公司的基础设施。FAANG级别的公司通常拥有自己的机器学习平台和工具，能够在适当的规模上运行，而较小的公司通常更倾向于使用一套开源工具和云服务。每个工具都有自己的采用成本，因此选择适合特定问题的工具非常重要。据我们所知，没有一种适合所有情况的解决方案，这与许多其他更为成熟的软件工程问题不同（见图10.3）。
- en: '![figure](../Images/CH10_F03_Babushkin.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F03_Babushkin.png)'
- en: Figure 10.3 Using proper frameworks for a training pipeline is usually a good
    practice, although sometimes it is enough to keep things simple.
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.3 使用适当的框架进行训练管道通常是良好的实践，尽管有时保持简单就足够了。
- en: 10.3 Scalability
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 可扩展性
- en: Scalability can be a crucial property of the training pipeline for certain problems.
    If we’re dealing with a dataset of thousands of samples of almost any kind, it’s
    not a significant concern, as even a single machine can likely handle it. However,
    when it comes to huge datasets, the situation changes. What constitutes a huge
    dataset? It depends on the problem and type of data (1 million tabular records
    are nothing compared to 1 million video clips), but what if we have to choose
    a criterion “for a dataset that doesn’t fit into the RAM of a single machine”?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性可能是某些问题的训练管道的关键属性。如果我们处理的是数千个样本的数据集，那么这并不是一个重大的问题，因为即使是单台机器也可能能够处理它。然而，当涉及到大型数据集时，情况就改变了。什么构成了大型数据集？这取决于问题和数据类型（1百万张表格记录与1百万个视频剪辑相比微不足道），但如果我们必须选择一个标准“对于不适合单台机器RAM的数据集”呢？
- en: The current size of a dataset should not be confused with the size of a dataset
    expected to be used in the future. We may face a cold-start problem (see chapter
    6), and having even thousands of samples may be a significant advantage for the
    initial phase of system development. However, in the future, it can grow by several
    orders of magnitude, and if you want to use all the data, you need to be able
    to handle it.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当前数据集的大小不应与未来预期使用的数据集大小混淆。我们可能会遇到冷启动问题（见第6章），即使有数千个样本也可能在系统开发的初始阶段具有显著优势。然而，在未来，它可能增长几个数量级，如果你想要使用所有数据，你需要能够处理它。
- en: While there is no silver bullet for training models on huge datasets, there
    are two classic software engineering approaches to scaling. Those are vertical
    and horizontal scaling (see figure 10.4).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在大型数据集上训练模型没有一劳永逸的解决方案，但有两种经典的软件工程方法可以实现扩展。这些是垂直扩展和水平扩展（见图10.4）。
- en: '![figure](../Images/CH10_F04_Babushkin.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F04_Babushkin.png)'
- en: Figure 10.4 Vertical scaling vs. horizontal scaling
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.4 垂直扩展与水平扩展
- en: '*Vertical scaling* means upgrading your hardware or replacing the training
    machine with a more powerful node. The biggest advantage of this approach lies
    in its simplicity; adding more resources (especially if using cloud compute resources,
    which is often the case) is very easy. The drawback, however, is how limited vertical
    scaling is. Let’s say you doubled or even quadrupled machine RAM and upgraded
    the GPU to the latest generation. If that’s not enough, there isn’t much you can
    do within the vertical scaling approach.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*垂直扩展*意味着升级您的硬件或用更强大的节点替换训练机器。这种方法的最大的优点在于其简单性；增加更多资源（尤其是在使用云计算资源的情况下，这通常是情况）非常容易。然而，缺点是垂直扩展的局限性。比如说，您将机器的RAM加倍甚至四倍，并将GPU升级到最新一代。如果还不够，在垂直扩展方法内您能做的事情就很少了。'
- en: '*Horizontal scaling* involves splitting the load between multiple machines.
    The first level of horizontal scaling is using multiple GPU machines; in this
    case, an ML engineer often needs to introduce small changes to the pipeline code,
    as most of the heavy lifting is already done by the training framework. However,
    this isn’t true horizontal scaling, as we’re still talking about a single machine.
    Genuine horizontal scaling involves using multiple machines and distributing the
    load among them. Nowadays, this type of scaling is often provided by frameworks
    as well, but it is more complex and usually requires more engineering effort during
    implementation. DeepSpeed by Microsoft, Accelerate by Hugging Face, and Horovod,
    originated in Uber, are some examples of such frameworks.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*水平扩展*涉及在多台机器之间分配负载。水平扩展的第一级是使用多GPU机器；在这种情况下，机器学习工程师通常需要修改管道代码，因为大部分繁重的工作已经由训练框架完成。然而，这并不是真正的水平扩展，因为我们仍在谈论一台机器。真正的水平扩展涉及使用多台机器并将负载在他们之间分配。如今，这种扩展通常也由框架提供，但这种方法更复杂，通常在实施过程中需要更多的工程努力。微软的DeepSpeed、Hugging
    Face的Accelerate以及起源于Uber的Horovod就是这类框架的例子。'
- en: 'One ML-specific way of scaling is subsampling: if your dataset is overly huge,
    it could be reasonable to subsample it and reduce the required compute resources.
    The most straightforward way of subsampling is applicable to most problems and
    involves removing duplicated samples. However, there are more aggressive methods:
    downsampling near-duplicates (samples that are very similar based on a simple
    distance function; e.g., Levenshtein distance for strings) and downsampling based
    on an internal ID (e.g., not more than X samples per user) or an artificial ID
    (e.g., clusterizing the full dataset with a simple method and keeping not more
    than X samples per cluster).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一种特定的机器学习扩展方法是子采样：如果您的数据集过于庞大，对其进行子采样并减少所需的计算资源可能是合理的。最直接的子采样方法适用于大多数问题，涉及去除重复的样本。然而，还有更激进的方法：基于简单距离函数（例如，字符串的Levenshtein距离）的近重复样本下采样，以及基于内部ID（例如，每个用户不超过X个样本）或人工ID（例如，使用简单方法对整个数据集进行聚类并保持每个聚类不超过X个样本）的下采样。
- en: 'In ML pipelines, scaling often requires changing other pipeline parameters:
    for example, batch size is limited by GPU memory, larger batches lead to faster
    convergence, and the learning rate schedule depends on both batch size and expected
    convergence schedule. So the ability to alter the parameters is important.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习管道中，扩展通常需要更改其他管道参数：例如，批大小受GPU内存限制，较大的批大小会导致收敛更快，而学习率计划取决于批大小和预期的收敛计划。因此，改变参数的能力很重要。
- en: 10.4 Configurability
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 可配置性
- en: 'When ML engineers design the configurability of a training pipeline, there
    is a spectrum with two bad practices on each side: underconfiguration and overconfiguration.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当机器学习工程师设计训练管道的可配置性时，存在一个光谱，每边都有两种不良做法：配置不足和配置过度。
- en: '*Underconfiguration* means that the pipeline is not configurable enough, making
    it difficult to change the model’s architecture, dataset, preprocessing steps,
    etc. Things are hardcoded here and there in a convoluted way, and it’s hard to
    understand how the pipeline works or alter even the simplest aspects. This is
    a typical problem in the early stages of ML development. When the pipeline is
    small and simple, it’s easy to understand and change. Therefore, researchers without
    a software engineering background may find it unnecessary to introduce proper
    software abstractions, leading to the addition of more and more code without proper
    structure. This antipattern often occurs among such researchers.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*配置不足*意味着管道的可配置性不足，这使得改变模型的架构、数据集、预处理步骤等变得困难。事物在这里和那里以复杂的方式硬编码，很难理解管道的工作方式或改变最简单的方面。这是机器学习发展早期的一个典型问题。当管道小而简单时，理解和改变都很容易。因此，没有软件工程背景的研究人员可能会觉得引入适当的软件抽象是不必要的，从而导致越来越多的代码被无结构地添加。这种反模式在研究人员中很常见。'
- en: '*Overconfiguration* is not ideal either. A typical ML pipeline has many hyperparameters
    related to dataset processing, model architecture, feature engineering, and the
    training process. In reality, it’s hard to predict all the possible use cases
    and parameters that can be changed, and inexperienced developers may try to cover
    all the possible cases and introduce as many abstractions as possible. At some
    point, these additional abstraction layers only increase complexity. Note that
    in this section, we use “parameters of the training pipeline” and “hyperparameters
    of the model” interchangeably. Just as a reminder, hyperparameters are those parameters
    of the model that are not learned during the training process but are set by the
    user.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*配置过度*同样不理想。典型的机器学习管道有许多与数据集处理、模型架构、特征工程和训练过程相关的超参数。在现实中，很难预测所有可能的使用案例和可更改的参数，并且缺乏经验的开发者可能会试图覆盖所有可能的情况，并尽可能多地引入抽象。在某个时候，这些额外的抽象层只会增加复杂性。请注意，在本节中，我们交替使用“训练管道的参数”和“模型的超参数”。仅作提醒，超参数是在训练过程中没有学习到的模型参数，而是由用户设置的。'
- en: In the example of overconfigured code in the following listing, we see how a
    multilevel hierarchy of subconfigs may complicate things.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下列表中过度配置的代码示例中，我们可以看到多级子配置层次结构如何使事情复杂化。
- en: Listing 10.1 Multilevel hierarchy of subcodings
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.1 多级子编码层次结构
- en: '[PRE0]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To find a good balance between the two extremes, you should estimate the probability
    of various parameters being changed. For example, it’s practically 100% certain
    that datasets will be updated, and it’s not very likely that activation functions
    inside the model will be changed. So it’s reasonable to make datasets configurable
    while ignoring activation functions. Changeable parameters differ for various
    pipelines, so the only way to find a good balance is to consider what potential
    experiments you would deem low-hanging fruits in the next few months. One helpful
    guide we recommend for deep learning-based pipelines is provided by the Google
    team: [https://github.com/google-research/tuning_playbook](https://github.com/google-research/tuning_playbook).'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在两种极端之间找到一个良好的平衡，你应该估计各种参数被改变的概率。例如，数据集被更新几乎是100%确定的事情，而模型内部的激活函数被改变的可能性并不大。因此，在忽略激活函数的同时，使数据集可配置是合理的。可变参数因各种管道而异，因此找到良好平衡的唯一方法就是考虑你会在接下来的几个月内认为的低垂之果的潜在实验。我们推荐的一个有助于基于深度学习管道的有用指南是由谷歌团队提供的：[https://github.com/google-research/tuning_playbook](https://github.com/google-research/tuning_playbook)。
- en: After preliminarily deciding which hyperparameters are tunable, it’s important
    to determine the tuning strategy. When computational resources are limited, handcrafted
    experiments are preferable. When resources are abundant, it makes sense to apply
    an automated hyperparameter tuning method, such as a straightforward random search
    or a more advanced Bayesian optimization. Tools for hyperparameter tuning (e.g.,
    Hyperopt, Optuna, and scikit-optimize) can be part of the ML platform and may
    dictate how the configuration files should look.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在初步决定哪些超参数可调整后，确定调整策略非常重要。当计算资源有限时，手工实验更可取。当资源充足时，应用自动超参数调整方法（如简单的随机搜索或更高级的贝叶斯优化）是有意义的。超参数调整工具（例如，Hyperopt、Optuna和scikit-optimize）可以是机器学习平台的一部分，并可能规定配置文件应该如何看起来。
- en: From our experience, extensive hyperparameter tuning is more applicable for
    small datasets, where it’s possible to run numerous experiments in a reasonable
    time. When a single experiment takes weeks, it’s more practical to rely on the
    intuition of the ML engineer and run a few experiments manually. It is worth noting
    that experiments with smaller datasets may help build this intuition, although
    not every conclusion may generalize to a large training run.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的经验，广泛的超参数调整更适合小数据集，因为在合理的时间内可以运行大量的实验。当单个实验需要数周时间时，更实际的做法是依靠机器学习工程师的直觉手动运行几个实验。值得注意的是，使用小数据集进行的实验可能有助于建立这种直觉，尽管并非每个结论都能推广到大规模的训练运行中。
- en: It is important to find a proper way to config the training pipeline (see figure
    10.5).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 找到适当的方式来配置训练管道非常重要（见图10.5）。
- en: '![figure](../Images/CH10_F05_Babushkin.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F05_Babushkin.png)'
- en: Figure 10.5 A pipeline requires proper config for optimal performance
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.5 管道需要适当的配置以实现最佳性能
- en: The most typical approach would be dedicating a single file (often written in
    a specific language like YAML or TOML) that contains all the changeable values.
    Another popular way to go is using libraries like Hydra ([https://hydra.cc/](https://hydra.cc/)).
    One antipattern we have seen is having the config spread between the training
    pipeline files with the same parameter specified in multiple files that have various
    priority levels (e.g., batch size can be read from file X, but if not specified
    there, try fetching from file Y). It could be error-prone at the experimentation
    stage, especially if experiments are performed by less experienced engineers who
    are not familiar with this particular pipeline.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最典型的做法可能是分配一个单独的文件（通常是用像YAML或TOML这样的特定语言编写的），其中包含所有可更改的值。另一种流行的方法是使用像Hydra ([https://hydra.cc/](https://hydra.cc/))这样的库。我们见过的一个反模式是将配置分散在具有相同参数的多个训练管道文件中，这些文件具有不同的优先级水平（例如，批大小可以从文件X中读取，但如果未指定，则尝试从文件Y中获取）。在实验阶段可能会出错，特别是如果实验是由不太熟悉这个特定管道的缺乏经验的工程师进行的。
- en: 10.5 Testing
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 测试
- en: One common problem we often see in ML pipelines is the lack of tests. It’s not
    surprising, as testing ML pipelines is not an easy task. When building a regular
    software system, we can test it by running it with some input and checking the
    output. However, running a training pipeline may take days, and obviously we can’t
    run it again after every change we implement. Another problem, as mentioned earlier,
    is that ML pipelines are often not configurable enough, making them difficult
    to test in isolation. Finally, given the number of possible hyperparameters, it’s
    nearly impossible to test all the possible combinations in a reasonable time.
    Simply put, introducing tests to ML pipelines is a challenging task. But it’s
    worth doing!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在机器学习管道中经常看到的一个常见问题是缺乏测试。这并不奇怪，因为测试机器学习管道并不是一件容易的事情。在构建常规软件系统时，我们可以通过运行它并检查输出来进行测试。然而，运行训练管道可能需要几天时间，显然我们不可能在每次实施更改后都再次运行它。另一个问题，如前所述，是机器学习管道通常配置不足，这使得它们难以单独测试。最后，考虑到可能的超参数数量，在合理的时间内测试所有可能的组合几乎是不可能的。简而言之，向机器学习管道引入测试是一项具有挑战性的任务。但这是值得做的！
- en: 'Proper tests serve three purposes:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 适当的测试有三个目的：
- en: Avoiding regression bugs while introducing changes
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在引入更改的同时避免回归错误
- en: Increasing iteration speed by catching defects earlier
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过尽早捕捉缺陷来提高迭代速度
- en: Improving pipeline design overall, as it forces an engineer to find the proper
    balance of configurability
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改进整体管道设计，因为它迫使工程师找到适当的可配置性平衡
- en: Our suggestion for testing ML pipelines is to use a combination of high-level
    smoke tests for the whole pipeline and low-level unit tests for at least its most
    important individual components.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对测试机器学习管道的建议是结合对整个管道的高级别烟雾测试和对其最重要的单个组件的低级别单元测试。
- en: A smoke test should be as fast as possible so you can run it on a small subset
    of the dataset, a small number of epochs, and maybe with a reduced version of
    the model. It should check that the pipeline runs without errors and produces
    reasonable output—for example, it ensures that the loss is decreasing on this
    toy dataset. The following listing shows a simplified example of a smoke test
    for a training pipeline.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 烟雾测试应该尽可能快，这样你就可以在数据集的小子集上运行它，运行少量epoch，也许使用模型的简化版本。它应该检查管道运行无误并产生合理的输出——例如，它确保在这个玩具数据集上损失正在减少。以下列表展示了训练管道烟雾测试的简化示例。
- en: Listing 10.2 What a smoke test for a training pipeline might look like
  id: totrans-84
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.2 训练管道的烟雾测试可能看起来像什么
- en: '[PRE1]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Smoke tests like this significantly increase iteration speed, thus simplifying
    experimentation and debugging. However, there is a downside. Like any integration
    tests, they require a lot of maintenance efforts on their own. This is because
    almost any significant pipeline change may affect the code. Lower-level unit tests
    should cover individual components of the pipeline. It’s not uncommon to have
    a few of them or even none at all—and there’s no reason to be ashamed if you don’t
    have them. However, we recommend covering at least the most sensitive components.
    An example of such a sensitive component could be the final model conversion—imagine
    the model is trained with Pytorch and later is supposed to be deployed to iOS
    (and run with CoreML) and the backend (and run with ONNX). It’s important to make
    sure that the model is converted properly and the conversion process doesn’t introduce
    any changes, which means results by the converted models should be the same as
    by the original model.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的烟雾测试显著提高了迭代速度，从而简化了实验和调试。然而，也存在一个缺点。像任何集成测试一样，它们需要大量的维护工作。这是因为几乎任何重大的管道更改都可能影响代码。低级别的单元测试应该覆盖管道的各个组件。拥有几个这样的单元测试或甚至没有它们并不罕见——如果你没有它们，也没有什么可耻的。然而，我们建议至少覆盖最敏感的组件。这样一个敏感组件的例子可能是最终的模型转换——想象一下，模型是用Pytorch训练的，后来被部署到iOS（并使用CoreML运行）以及后端（并使用ONNX运行）。确保模型被正确转换并且转换过程没有引入任何变化非常重要，这意味着转换模型的输出应该与原始模型相同。
- en: 10.5.1 Property-based testing
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.1 基于属性的测试
- en: Another group of tests is applicable to the trained model, inspired by the property-based
    testing approach. Property-based testing is a software testing approach that involves
    generating random inputs for a function or a system and then verifying that certain
    properties or invariants hold true for all the inputs. Instead of writing specific
    test cases with predetermined inputs and expected outputs, property-based testing
    focuses on defining the general properties that the system should satisfy and
    then automatically generates test cases to validate those properties.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 另一组测试适用于训练好的模型，其灵感来源于基于属性的测试方法。基于属性的测试是一种软件测试方法，它涉及为函数或系统生成随机输入，然后验证对于所有输入某些属性或不变量是否成立。与编写具有预定输入和预期输出的特定测试用例不同，基于属性的测试侧重于定义系统应满足的一般属性，然后自动生成测试用例以验证这些属性。
- en: 'In the context of an ML project, property-based testing can be used to ensure
    that the final trained model behaves as expected and satisfies certain properties.
    The following are some examples of properties that can be tested in an ML project:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习项目的背景下，基于属性的测试可以用来确保最终训练好的模型按预期行为并满足某些属性。以下是一些在机器学习项目中可以测试的属性示例：
- en: '*Consistency**—*Given the same input data, the model should produce the same
    output or prediction consistently, regardless of the number of times it is executed:'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*一致性**—*给定相同的输入数据，模型应该始终如一地产生相同的输出或预测，无论执行多少次：'
- en: '![figure](../Images/babushkin-ch10-eqs-0x.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/babushkin-ch10-eqs-0x.png)'
- en: '*Monotonicity**—*In simple ML models, the output should be monotonically increasing
    or decreasing with respect to certain input features. Property-based testing can
    be used to verify that the model’s output follows the expected monotonic behavior:'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*单调性**—*在简单的机器学习模型中，输出应该相对于某些输入特征单调递增或递减。基于属性的测试可以用来验证模型的输出遵循预期的单调行为：'
- en: '![figure](../Images/babushkin-ch10-eqs-1x.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/babushkin-ch10-eqs-1x.png)'
- en: Monotonicity is often expected in various price prediction models. For example,
    the price of a house should increase with its square footage if the rest of the
    features are fixed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 单调性通常在各种价格预测模型中是预期的。例如，如果其他特征固定，房屋的价格应该随着其面积的增大而增加。
- en: '*Invariance under transformations**—*Some ML models should be invariant under
    specific transformations of the input data, such as scaling or rotation. Property-based
    testing can be used to check that the model’s output remains unchanged when the
    input data is transformed in a specific way:'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*变换不变性**—*某些机器学习模型应该在输入数据的特定变换（如缩放或旋转）下保持不变。基于属性的测试可以用来检查当输入数据以特定方式变换时，模型的输出是否保持不变：'
- en: '![figure](../Images/babushkin-ch10-eqs-2x.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/babushkin-ch10-eqs-2x.png)'
- en: where g is an expected transformation. This could be a rotation or scaling for
    images, changing an entity to its synonym for natural language processing, altering
    the volume of a sound for audio, and so on.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 其中g是一个预期的转换。这可能是对图像进行旋转或缩放，将实体更改为其同义词进行自然语言处理，改变声音的音量，等等。
- en: '*Robustness**—*The model should be robust to small perturbations in the input
    data. Property-based testing can be used to verify that the model’s output does
    not change significantly when the input data is perturbed by a small amount:'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*鲁棒性**—*模型应能抵抗输入数据中的小扰动。可以使用基于属性的测试来验证当输入数据被小量扰动时，模型的输出不会发生显著变化：'
- en: '![figure](../Images/babushkin-ch10-eqs-3x.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/babushkin-ch10-eqs-3x.png)'
- en: '*Negation**—*The model should provide the opposite prediction when the input
    data is flipped. Property-based testing can be used to verify that the model’s
    output is the opposite of the expected output when the input data is negated.
    The simplest example is the sentiment analysis, where the model usually should
    predict a negative sentiment if the word “love” is replaced with “hate”:'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*否定**—*当输入数据被反转时，模型应提供相反的预测。可以使用基于属性的测试来验证当输入数据被否定时，模型的输出是预期输出的相反。最简单的例子是情感分析，其中模型通常应该预测负面情感，如果将单词“爱”替换为“恨”：'
- en: '![figure](../Images/babushkin-ch10-eqs-4x.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/babushkin-ch10-eqs-4x.png)'
- en: We already covered a very similar concept in section 5.2.1\. The difference
    is that in one case, we expect some variation in the results (and we want to measure
    it), while in the other case, we expect strict consistency (and thus we want to
    assert it). Using some data samples as fixtures and writing property-based tests
    for them is a good way to ensure that the model behaves as expected and maintains
    its reliability.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在5.2.1节中介绍了一个非常类似的概念。区别在于，在一种情况下，我们期望结果存在一些变化（并且我们想要测量它），而在另一种情况下，我们期望严格的致性（因此我们想要断言它）。使用一些数据样本作为固定值并为他们编写基于属性的测试是确保模型按预期行为并保持其可靠性的好方法。
- en: An exact list of tests is not usually included in the design document; however,
    we recommend thinking about it in advance and mentioning it in the document. The
    design document is often used as a reference for implementation, so it’s useful
    to mention the tests in it.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 通常不会在设计文档中包含一个精确的测试列表；然而，我们建议提前考虑它并在文档中提及。设计文档通常用作实现的参考，因此提及测试是有用的。
- en: 'NOTE  If you’re interested in ML testing, we recommend Arseny’s slides with
    a deeper review of the topic: [https://arseny.info/reliable_ML](https://arseny.info/reliable_ML).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您对机器学习测试感兴趣，我们推荐阅读Arseny关于该主题的深入评论的幻灯片：[https://arseny.info/reliable_ML](https://arseny.info/reliable_ML)。
- en: '10.6 Design document: Training pipelines'
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.6 设计文档：训练管道
- en: As we continue our work on two separate design documents for our imaginary businesses,
    it’s time to cover training pipelines for Supermegaretail and PhotoStock Inc.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续为我们的虚构业务制作两个独立的设计文档的工作，现在是时候介绍Supermegaretail和PhotoStock Inc.的训练管道了。
- en: 10.6.1 Training pipeline for Supermegaretail
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.1 Supermegaretail的训练管道
- en: Let’s see how a potential pipeline could look for Supermegaretail.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看Supermegaretail可能的管道可能是什么样子。
- en: 'Design document: Supermegaretail'
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设计文档：Supermegaretail
- en: VII. Training pipeline
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII. 训练管道
- en: i. Overview
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: i. 概述
- en: The demand forecasting model for Supermegaretail aims to predict the demand
    for specific items in specific stores during a particular period. To achieve this,
    we need a training pipeline that can preprocess data, train the model, and evaluate
    its performance. We assume the pipeline should be scalable and easy to maintain
    and allow for experimentation with various model architectures, feature engineering
    techniques, and hyperparameters.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Supermegaretail的需求预测模型旨在预测特定时间段内特定商店中特定商品的需求。为了实现这一点，我们需要一个训练管道，它可以预处理数据，训练模型，并评估其性能。我们假设该管道应该是可扩展的并且易于维护，并允许对各种模型架构、特征工程技术和超参数进行实验。
- en: ii. Toolset
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ii. 工具集
- en: The suggested tools for the pipeline are
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 管道建议的工具是
- en: Python as the primary programming language for its versatility and rich ecosystem
    for data processing and ML
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python作为主要编程语言，因其多功能性和丰富的数据处理和机器学习生态系统
- en: Spark for parallel and distributed computing
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于并行和分布式计算的Spark
- en: PyTorch for deep learning models
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch用于深度学习模型
- en: MLflow for tracking experiments and managing the machine learning lifecycle
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow用于跟踪实验和管理机器学习生命周期
- en: Docker for containerization and reproducibility
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker用于容器化和可重复性
- en: AWS Sagemaker or Google Cloud AI Platform for cloud-based training and deployment
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS Sagemaker或Google Cloud AI Platform用于基于云的训练和部署
- en: iii. Data preprocessing
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: iii. 数据预处理
- en: The data preprocessing stage should include
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理阶段应包括
- en: '*Data cleaning*—Handling missing values, removing duplicates, and correcting
    erroneous data points'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据清洗*—处理缺失值、删除重复项和纠正错误数据点'
- en: '*Feature engineering*—Creating new features from existing ones, such as aggregating
    sales data, extracting temporal features (day of the week, month, etc.), and incorporating
    external data (e.g., holidays, weather, and promotions)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征工程*—从现有特征创建新特征，例如汇总销售数据、提取时间特征（如星期几、月份等）以及整合外部数据（例如，假日、天气和促销活动）'
- en: '*Data normalization*—Scaling numeric features to a standard range'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据归一化*—将数值特征缩放到标准范围'
- en: '*Train–test split*—Splitting the dataset into training and validation sets,
    ensuring that they do not overlap in time to prevent data leakage'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*训练-测试分割*—将数据集分割成训练集和验证集，确保它们在时间上不重叠，以防止数据泄露'
- en: iv. Model training
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: iv. 模型训练
- en: The model training stage should accommodate various model architectures and
    configurations, including
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练阶段应适应各种模型架构和配置，包括
- en: '*Baseline models*—Simple forecasting methods like moving average, exponential
    smoothing, and autoregressive integrated moving average'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基线模型*—简单的预测方法，如移动平均、指数平滑和自回归积分移动平均'
- en: '*ML models**—*Decision trees, random forests, gradient boosting machines, and
    support vector machines'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习模型*—决策树、随机森林、梯度提升机和支持向量机'
- en: '*Deep learning models*—Recurrent neural networks, long short-term memory networks,
    and transformers (if needed!)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深度学习模型*—循环神经网络、长短期记忆网络和转换器（如有需要！）'
- en: We should also implement a mechanism for hyperparameter tuning, such as grid
    search or Bayesian optimization, to find the best model configurations.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该实现一个超参数调整机制，例如网格搜索或贝叶斯优化，以找到最佳模型配置。
- en: v. Model evaluation
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: v. 模型评估
- en: Model performance should be evaluated using metrics we derived prior to that,
    such as quantile metrics for quantiles of 1.5, 25, 50, 75, 95, and 99, both as
    is and with weights equal to SKU price. It is calculated as point estimates with
    95% confidence intervals (using bootstrap or cross-validation) plus standard metrics
    such as mean absolute error (MAE), mean squared error (MSE), or root mean squared
    error (RMSE). We should also include custom metrics specific to Supermegaretail’s
    business requirements, such as the cost of overstock and out-of-stock situations.
    (See *Validation* chapter.)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 应使用我们之前推导出的指标来评估模型性能，例如1.5、25、50、75、95和99分位数指标，以及作为是和权重等于SKU价格的权重。它计算为点估计值，具有95%置信区间（使用自助法或交叉验证），加上标准指标，如平均绝对误差（MAE）、平均平方误差（MSE）或均方根误差（RMSE）。我们还应包括针对Supermegaretail业务需求的特定自定义指标，例如过剩库存和缺货情况的成本。（见*验证*章节。）
- en: vi. Experiment tracking and model management
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: vi. 实验跟踪和模型管理
- en: Using a tool like MLflow, we should track and manage experiments, including
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像MLflow这样的工具，我们应该跟踪和管理实验，包括
- en: Model parameters and hyperparameters
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型参数和超参数
- en: Input data and feature engineering techniques
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入数据和特征工程技术
- en: Evaluation metrics and performance
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估指标和性能
- en: Model artifacts, such as trained model weights and serialized models
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型工件，如训练模型权重和序列化模型
- en: vii. Continuous integration and deployment
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: vii. 持续集成和部署
- en: The training pipeline should be integrated into Supermegaretail’s existing CI/CD
    infrastructure. This includes setting up automated training and evaluation on
    a regular basis, ensuring that the latest data is used to update the model, and
    deploying the updated model to production with minimal manual intervention.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 训练管道应集成到Supermegaretail现有的CI/CD基础设施中。这包括定期设置自动训练和评估，确保使用最新数据更新模型，并以最小的人工干预将更新的模型部署到生产中。
- en: viii. Monitoring and maintenance
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: viii. 监控和维护
- en: We should monitor the model’s performance in production and set up alerts for
    significant deviations from expected performance. This will enable us to catch
    problems early and trigger retraining or model updates when necessary (see chapter
    14).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该监控模型在生产中的性能，并设置对预期性能的重大偏差的警报。这将使我们能够及早发现问题，并在必要时触发重新训练或模型更新（见第14章）。
- en: ix. Future work and experimentation
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ix. 未来工作和实验
- en: The training pipeline should be flexible enough to accommodate future experimentation,
    such as incorporating additional data sources, trying new model architectures,
    and adjusting loss functions to optimize for specific business objectives.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 训练流水线应该足够灵活，以适应未来的实验，例如整合额外的数据源、尝试新的模型架构以及调整损失函数以优化特定的业务目标。
- en: 10.6.2 Training pipeline for PhotoStock Inc.
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.2 PhotoStock Inc.的训练流水线
- en: Now we go back to PhotoStock Inc., where we are required to build a smart in-house
    search engine to boost correct result output.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们回到PhotoStock Inc.，在那里我们被要求构建一个智能内部搜索引擎以提升正确结果的输出。
- en: 'Design document: PhotoStock Inc.'
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设计文档：PhotoStock Inc.
- en: VII. Training pipeline
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII. 训练流水线
- en: The multimodal ranking model is a core component of the PhotoStock Inc. search
    engine, and we need a training pipeline to train this model. As discussed earlier,
    we have a solid baseline based on the pretrained CLIP model. However, we need
    to finetune it on our own dataset, which is a combination of images and text descriptions.
    While the dataset is not going to be large in the beginning, it can grow down
    the stretch, so we need to make the pipeline somewhat scalable. We assume we can
    start with training it on a single top-class GPU, but we want to be able to scale
    it to multiple GPUs on a single machine in the future. We don’t aim for fully
    distributed training at the moment.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态排名模型是PhotoStock Inc.搜索引擎的核心组件，我们需要一个训练流水线来训练这个模型。如前所述，我们有一个基于预训练CLIP模型的坚实基础。然而，我们需要在我们的数据集上对其进行微调，这是一个图像和文本描述的组合。虽然数据集最初可能不会很大，但它可能会在后期增长，因此我们需要使流水线具有一定的可扩展性。我们假设我们可以从在单个顶级GPU上训练它开始，但希望将来能够将其扩展到单台机器上的多个GPU。目前我们不追求完全分布式训练。
- en: 'We suggest the following toolset for the pipeline:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议以下工具集用于流水线：
- en: '*PyTorch*—The default deep learning framework, as it’s the most popular one
    worldwide and has a lot of community support'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PyTorch*——默认的深度学习框架，因为它是全球最受欢迎的，并且拥有大量的社区支持。'
- en: '*PyTorch Lightning*—A high-level framework to simplify the training loop and
    make it more reproducible'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PyTorch Lightning*——一个高级框架，用于简化训练循环并使其更具可重复性。'
- en: '*Flyte*—A workflow management tool because it’s already used in the company
    for data engineering jobs, and we can reuse some of the existing code'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Flyte*——一个工作流程管理工具，因为它已经在公司用于数据工程工作，我们可以重用一些现有的代码。'
- en: '*AWS Sagemaker*—A training platform because AWS is already used in the company,
    and it’s easy to integrate with Flyte'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AWS Sagemaker*——一个训练平台，因为AWS已经在公司使用，并且很容易与Flyte集成。'
- en: '*Tensorboard*—A simple visualization tool for training metrics'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Tensorboard*——一个简单的训练指标可视化工具。'
- en: '*Docker*—A containerization tool to make the pipeline more portable and reproducible'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Docker*——一个容器化工具，使流水线更加便携和可重复。'
- en: 'The pipeline’s output should be two models: a text encoder and an image encoder.
    Both should be converted to static graph representation (ONNX) and saved to S3\.
    Additionally, we should output the list of training parameters that will be used
    for inference (prompt generation, image preprocessing, distance function). Finally,
    every run should produce a report with training metrics. All the artifacts should
    be saved to S3 after the run.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线的输出应该是两个模型：一个文本编码器和图像编码器。两者都应转换为静态图表示（ONNX）并保存到S3。此外，我们还应该输出用于推理（提示生成、图像预处理、距离函数）的训练参数列表。最后，每次运行都应该生成一个包含训练指标的报告。所有工件应在运行后保存到S3。
- en: 'We expect active experimentation in the following areas:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预计将在以下领域进行积极的实验：
- en: '*What to finetune*—Some components, the full model, or a combination of both
    with a custom scheduler.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*要微调的内容*——一些组件、整个模型，或者两者的组合，并使用自定义调度器。'
- en: '*Augmentation techniques*—We can use different augmentation techniques for
    images and text.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*增强技术*——我们可以为图像和文本使用不同的增强技术。'
- en: '*Various loss functions*—With different weights for different components.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*各种损失函数*——为不同的组件分配不同的权重。'
- en: '*Various backbones for the CLIP model family*—For example, convolutional-based
    or transformer-based encoder for images; there is no strong intuition about which
    one is better, so we need to experiment with both.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*CLIP模型系列的多种骨干网络*——例如，基于卷积或基于transformer的图像编码器；对于哪一个更好，没有强烈的直觉，因此我们需要对两者都进行实验。'
- en: '*Ways to generate text prompts for the text encoder*—It must be a composition
    of image description, tags, etc.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*为文本编码器生成文本提示的方法*——它必须是图像描述、标签等的组合。'
- en: '*Ways to preprocess image inputs*—For example, resize, crop, pad parameters.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预处理图像输入的方法*——例如，调整大小、裁剪、填充参数。'
- en: Summary
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Remember that ML is not just about training a model. One of its pillars is building
    a pipeline that allows for the preparation of the model and other artifacts in
    a reproducible way.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记住，机器学习不仅仅是训练一个模型。其支柱之一是构建一个管道，允许以可重复的方式准备模型和其他工件。
- en: 'While the difference between training pipelines and inference pipelines may
    seem somewhat vague and hard to distinguish, we suggest the following definition
    for each: a training pipeline is used to train a model itself, while an inference
    pipeline is used to run a model in production or as part of a training pipeline.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然训练管道和推理管道之间的区别可能看起来有些模糊且难以区分，但我们建议以下定义：训练管道用于训练模型本身，而推理管道用于在生产环境中运行模型或作为训练管道的一部分。
- en: The life cycle of a typical training pipeline includes seven sequential steps,
    from data fetching, preprocessing, training, evaluating, and testing the model
    to postprocessing, artifact packaging, and report generating.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 典型训练管道的生命周期包括七个连续步骤，从数据获取、预处理、训练、评估和测试模型到后处理、工件打包和报告生成。
- en: At this point, there are no well-established standards for platforms and tools
    to use when working with pipelines. However, there are time-proven solutions in
    general ML that you can find fitting for the type of system you’re designing.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 到目前为止，在处理管道时还没有确立的平台和工具的标准。然而，在通用机器学习中存在经过时间考验的解决方案，您可以根据您设计的系统类型找到合适的解决方案。
- en: At some point, you will face a choice between the two scaling methods for your
    pipeline—vertical scaling or horizontal scaling. The former is simpler and easy
    to achieve yet is limited by the potential maximum performance of your machine.
    The latter, however, allows much bigger opportunities for enhancing the performance
    of your hardware.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在某个时候，您将面临在两种管道扩展方法之间进行选择——垂直扩展或水平扩展。前者更简单且易于实现，但受限于机器的潜在最大性能。然而，后者却为提高硬件性能提供了更大的机会。
- en: Try to find a way to make your pipeline well-balanced in terms of its configurability.
    If you fall into either of the extremes (underconfiguration or overconfiguration),
    your pipeline will be either too rigid and resistant to change or overly complex
    for a given set of objectives.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试找到一种方法，使您的管道在可配置性方面保持平衡。如果您陷入任一极端（欠配置或过配置），您的管道将要么过于僵化且难以改变，要么对于既定的目标来说过于复杂。
- en: Don’t neglect testing your pipeline! It will help you avoid regression bugs
    while introducing changes, increase iteration speed by catching defects earlier,
    and improve the overall design, as it will force you to find the proper balance
    of configurability.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要忽视测试您的管道！它将帮助您在引入更改时避免回归错误，通过早期捕捉缺陷来提高迭代速度，并改善整体设计，因为它将迫使您找到适当的可配置性平衡。
