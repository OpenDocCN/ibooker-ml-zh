- en: Chapter 16\. Explaining Regression Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the techniques used to explain classification models apply to regression
    models. In this chapter, I will show how to use the SHAP library to interpret
    regression models.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will interpret an XGBoost model for the Boston housing dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Shapley
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I’m a big fan of Shapley because it is model agnostic. This library also gives
    us global insight into our model and helps explain individual predictions. If
    you have a black-box model, I find it very useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will first look at the prediction for index 5\. Our model predicts the value
    to be 27.26:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To use the model, we have to create a `TreeExplainer` from our model and estimate
    the SHAP values for our samples. If we want to use Jupyter and have an interactive
    interface, we also need to call the `initjs` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'With the explainer and the SHAP values, we can create a force plot to explain
    the prediction (see [Figure 16-1](#shapr1)). This informs us that the base prediction
    is 23, and that the population status (LSTAT) and property tax rate (TAX) push
    the price up, while the number of rooms (RM) pushes the price down:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Force plot for regression. The expected value is pushed up from 23 to 27
    due to the population status and tax rate.](assets/mlpr_1601.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-1\. Force plot for regression. The expected value is pushed up from
    23 to 27 due to the population status and tax rate.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can view the force plot for all of the samples as well to get an overall
    feel of the behavior. If we are using the interactive JavaScript mode on Jupyter,
    we can mouse over the samples and see what features are impacting the result (see
    [Figure 16-2](#shapr2)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Force plot for regression for all samples.](assets/mlpr_1602.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-2\. Force plot for regression for all samples.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: From the force plot of the sample, we saw that the LSTAT feature had a big impact.
    To visualize how LSTAT affects the result, we can create a dependence plot. The
    library will automatically choose a feature to color it by (you can provide the
    `interaction_index` parameter to set your own).
  prefs: []
  type: TYPE_NORMAL
- en: 'From the dependence plot for LSTAT (see [Figure 16-3](#shapr3)), we can see
    that as LSTAT increases (the percent of lower status population), the SHAP value
    goes down (pushing down the target). A very low LSTAT value pushes SHAP up. From
    viewing the coloring of the TAX (property tax rate), it appears that as the rate
    goes down (more blue), the SHAP value goes up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Dependence plot for LSTAT. As LSTAT goes up, the predicted value goes down.](assets/mlpr_1603.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-3\. Dependence plot for LSTAT. As LSTAT goes up, the predicted value
    goes down.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here is another dependence plot, shown in [Figure 16-4](#shapr4), to explore
    the DIS (distance to employment centers). It appears that this feature has little
    effect unless it is very small:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![Dependence plot for DIS. Unless DIS is very small, SHAP stays relatively
    flat.](assets/mlpr_1604.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-4\. Dependence plot for DIS. Unless DIS is very small, SHAP stays
    relatively flat.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Finally, we will look at the global effect of the features using a summary
    plot (see [Figure 16-5](#shapr5)). The features at the top have the most impact
    to the model. From this view you can see that large values of RM (number of rooms)
    push up the target a lot, while medium and smaller values push it down a little:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![Summary plot. The most important features are at the top.](assets/mlpr_1605.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-5\. Summary plot. The most important features are at the top.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The SHAP library is a great tool to have in your toolbelt. It helps understand
    the global impact of features and also helps explain individual predictions.
  prefs: []
  type: TYPE_NORMAL
