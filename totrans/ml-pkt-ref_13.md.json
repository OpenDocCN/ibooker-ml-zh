["```py\n>>> dt = DecisionTreeClassifier(\n...     random_state=42, max_depth=3\n... )\n>>> dt.fit(X_train, y_train)\n```", "```py\n>>> from lime import lime_tabular\n>>> explainer = lime_tabular.LimeTabularExplainer(\n...     X_train.values,\n...     feature_names=X.columns,\n...     class_names=[\"died\", \"survived\"],\n... )\n>>> exp = explainer.explain_instance(\n...     X_train.iloc[-1].values, dt.predict_proba\n... )\n```", "```py\nexp.show_in_notebook()\n```", "```py\n>>> fig = exp.as_pyplot_figure()\n>>> fig.tight_layout()\n>>> fig.savefig(\"images/mlpr_1301.png\")\n```", "```py\n>>> data = X_train.iloc[-2].values.copy()\n>>> dt.predict_proba(\n...     [data]\n... )  # predicting that a woman lives\n[[0.48062016 0.51937984]]\n>>> data[5] = 1  # change to male\n>>> dt.predict_proba([data])\narray([[0.87954545, 0.12045455]])\n```", "```py\n>>> from treeinterpreter import (\n...     treeinterpreter as ti,\n... )\n>>> instances = X.iloc[:2]\n>>> prediction, bias, contribs = ti.predict(\n...     rf5, instances\n... )\n>>> i = 0\n>>> print(\"Instance\", i)\n>>> print(\"Prediction\", prediction[i])\n>>> print(\"Bias (trainset mean)\", bias[i])\n>>> print(\"Feature contributions:\")\n>>> for c, feature in zip(\n...     contribs[i], instances.columns\n... ):\n...     print(\"  {} {}\".format(feature, c))\nInstance 0\nPrediction [0.98571429 0.01428571]\nBias (trainset mean) [0.63984716 0.36015284]\nFeature contributions:\n pclass [ 0.03588478 -0.03588478]\n age [ 0.08569306 -0.08569306]\n sibsp [ 0.01024538 -0.01024538]\n parch [ 0.0100742 -0.0100742]\n fare [ 0.06850243 -0.06850243]\n sex_male [ 0.12000073 -0.12000073]\n embarked_Q [ 0.0026364 -0.0026364]\n embarked_S [ 0.01283015 -0.01283015]\n```", "```py\n>>> rf5 = ensemble.RandomForestClassifier(\n...     **{\n...         \"max_features\": \"auto\",\n...         \"min_samples_leaf\": 0.1,\n...         \"n_estimators\": 200,\n...         \"random_state\": 42,\n...     }\n... )\n>>> rf5.fit(X_train, y_train)\n```", "```py\n>>> from pdpbox import pdp\n>>> feat_name = \"age\"\n>>> p = pdp.pdp_isolate(\n...     rf5, X, X.columns, feat_name\n... )\n>>> fig, _ = pdp.pdp_plot(\n...     p, feat_name, plot_lines=True\n... )\n>>> fig.savefig(\"images/mlpr_1302.png\", dpi=300)\n```", "```py\n>>> features = [\"fare\", \"sex_male\"]\n>>> p = pdp.pdp_interact(\n...     rf5, X, X.columns, features\n... )\n>>> fig, _ = pdp.pdp_interact_plot(p, features)\n>>> fig.savefig(\"images/mlpr_1303.png\", dpi=300)\n```", "```py\n>>> from sklearn import svm\n>>> sv = svm.SVC()\n>>> sv.fit(X_train, y_train)\n>>> sur_dt = tree.DecisionTreeClassifier()\n>>> sur_dt.fit(X_test, sv.predict(X_test))\n>>> for col, val in sorted(\n...     zip(\n...         X_test.columns,\n...         sur_dt.feature_importances_,\n...     ),\n...     key=lambda x: x[1],\n...     reverse=True,\n... )[:7]:\n...     print(f\"{col:10}{val:10.3f}\")\nsex_male       0.723\npclass         0.076\nsibsp          0.061\nage            0.056\nembarked_S     0.050\nfare           0.028\nparch          0.005\n```", "```py\n>>> rf5.predict_proba(X_test.iloc[[20]])\narray([[0.59223553, 0.40776447]])\n```", "```py\n>>> import shap\n>>> s = shap.TreeExplainer(rf5)\n>>> shap_vals = s.shap_values(X_test)\n>>> target_idx = 1\n>>> shap.force_plot(\n...     s.expected_value[target_idx],\n...     shap_vals[target_idx][20, :],\n...     feature_names=X_test.columns,\n... )\n```", "```py\n>>> shap.force_plot(\n...     s.expected_value[1],\n...     shap_vals[1],\n...     feature_names=X_test.columns,\n... )\n```", "```py\n>>> fig, ax = plt.subplots(figsize=(6, 4))\n>>> res = shap.dependence_plot(\n...     \"age\",\n...     shap_vals[target_idx],\n...     X_test,\n...     feature_names=X_test.columns,\n...     alpha=0.7,\n... )\n>>> fig.savefig(\n...     \"images/mlpr_1306.png\",\n...     bbox_inches=\"tight\",\n...     dpi=300,\n... )\n```", "```py\n>>> fig, ax = plt.subplots(figsize=(6, 4))\n>>> shap.summary_plot(shap_vals[0], X_test)\n>>> fig.savefig(\"images/mlpr_1307.png\", dpi=300)\n```"]