<html><head></head><body><section data-pdf-bookmark="Chapter 2. End-to-End Machine Learning Project" data-type="chapter" epub:type="chapter"><div class="chapter" id="Chapter_2">&#13;
<h1><span class="label">Chapter 2. </span>End-to-End Machine Learning Project</h1>&#13;
&#13;
&#13;
<p>Before<a data-primary="machine learning example project" data-see="also machine learning" data-type="indexterm" id="idm140637564873440"/> we begin exploring unsupervised learning algorithms in detail, we will review how to set up and manage machine learning projects, covering everything from acquiring data to building and evaluating a model and implementing a solution. We will work with supervised learning models in this chapter—an area most readers should have some experience in—before jumping into unsupervised learning models in the next chapter.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Environment Setup" data-type="sect1"><div class="sect1" id="idm140637564871680">&#13;
<h1>Environment Setup</h1>&#13;
&#13;
<p>Let’s<a data-primary="environment setup" data-type="indexterm" id="envset02"/><a data-primary="machine learning example project" data-secondary="environment setup" data-type="indexterm" id="MLPenv02"/> set up the data science environment before going further. This environment is the same for both supervised and unsupervised learning.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>These instructions are optimized for the Windows operating system but installation packages are available for Mac and Linux, too.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Version Control: Git" data-type="sect2"><div class="sect2" id="idm140637564866096">&#13;
<h2>Version Control: Git</h2>&#13;
&#13;
<p>If<a data-primary="version control" data-type="indexterm" id="idm140637564864768"/><a data-primary="Git" data-type="indexterm" id="idm140637564864032"/> you have not already, you will need to install <a href="https://git-scm.com/">Git</a>. Git is a version control system for code, and all the coding examples in this book are available as Jupyter notebooks from <a href="http://bit.ly/2Gd4v7e">the GitHub repository</a>. Review Roger Dudler’s <a href="http://rogerdudler.github.io/git-guide/">Git guide</a> to learn how to clone repositories; add, commit, and push changes; and maintain version control with branches.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Clone the Hands-On Unsupervised Learning Git Repository" data-type="sect2"><div class="sect2" id="idm140637564860608">&#13;
<h2>Clone the Hands-On Unsupervised Learning Git Repository</h2>&#13;
&#13;
<p>Open<a data-primary="code examples, obtaining and using" data-type="indexterm" id="idm140637564859072"/> the command-line interface (i.e., command prompt on Windows, terminal on Mac, etc.). Navigate to the directory where you will store your unsupervised learning projects. Use the following prompt to clone the repository associated with this book from GitHub:</p>&#13;
&#13;
<pre data-type="programlisting">$ git clone https://github.com/aapatel09/handson-unsupervised-learning.git&#13;
$ git lfs pull</pre>&#13;
&#13;
<p>Alternatively, you can visit <a href="http://bit.ly/2Gd4v7e">the repository</a> on the GitHub website and manually download the repository for your use. You can <em>watch</em> or <em>star</em> the repository to stay updated on changes.</p>&#13;
&#13;
<p>Once the repository has been pulled or manually downloaded, use the command-line interface to navigate into the <em>handson-unsupervised-learning</em> repository.</p>&#13;
&#13;
<pre data-type="programlisting">$ cd handson-unsupervised-learning</pre>&#13;
&#13;
<p>For the rest of the installations, we will continue to use the command-line interface.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Scientific Libraries: Anaconda Distribution of Python" data-type="sect2"><div class="sect2" id="idm140637564852896">&#13;
<h2>Scientific Libraries: Anaconda Distribution of Python</h2>&#13;
&#13;
<p>To<a data-primary="Anaconda" data-type="indexterm" id="idm140637564851360"/> install Python and the scientific libraries necessary for machine learning, download the <a href="https://www.anaconda.com/download/">Anaconda distribution</a> of Python (version 3.6 is recommended because version 3.7 is relatively new as of the writing of this book and not supported by all the machine libraries we will use).</p>&#13;
&#13;
<p>Create an isolated Python environment so that you can import different libraries for each project separately:</p>&#13;
&#13;
<pre data-type="programlisting">$ conda create -n unsupervisedLearning python=3.6 anaconda</pre>&#13;
&#13;
<p>This creates an isolated Python 3.6 environment—with all of the scientific libraries that come with the Anaconda distribution—called <code>unsupervisedLearning</code>.</p>&#13;
&#13;
<p>Now, activate this for use:</p>&#13;
&#13;
<pre data-type="programlisting">$ activate unsupervisedLearning</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Neural Networks: TensorFlow and Keras" data-type="sect2"><div class="sect2" id="idm140637564845984">&#13;
<h2>Neural Networks: TensorFlow and Keras</h2>&#13;
&#13;
<p>Once<a data-primary="TensorFlow" data-secondary="installing" data-type="indexterm" id="idm140637564844448"/> unsupervisedLearning is activated, you will need to install TensorFlow and Keras to build neutral networks. TensorFlow is an open source project by Google and is not part of the Anaconda distribution:</p>&#13;
&#13;
<pre data-type="programlisting">$ pip install tensorflow</pre>&#13;
&#13;
<p>Keras<a data-primary="Keras" data-secondary="installing" data-type="indexterm" id="idm140637564841968"/> is an open source netural network library that offers a higher-level API for us to use the lower-level functions in TensorFlow. In other words, we will use Keras on top of TensorFlow (the backend) to have a more intuitive set of API calls to develop our deep learning models:</p>&#13;
&#13;
<pre data-type="programlisting">$ pip install keras</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Gradient Boosting, Version One: XGBoost" data-type="sect2"><div class="sect2" id="idm140637564839760">&#13;
<h2>Gradient Boosting, Version One: XGBoost</h2>&#13;
&#13;
<p>Next, install<a data-primary="XGBoost" data-secondary="installing" data-type="indexterm" id="idm140637564838304"/> one version of gradient boosting known as XGBoost. To make this simple (for Windows users, at least), you can navigate into the <em>xgboost</em> folder in the <em>handson-unsupervised-learning</em> repository and find the package there.</p>&#13;
&#13;
<p>To install the package, use <code>pip install</code>:</p>&#13;
&#13;
<pre data-type="programlisting">cd xgboost&#13;
pip install xgboost-0.6+20171121-cp36-cp36m-win_amd64.whl</pre>&#13;
&#13;
<p>Alternatively, download the correct version of <a href="http://bit.ly/2G1jBxs">XGBoost</a> based on your system—either the 32-bit or the 64-bit version.</p>&#13;
&#13;
<p>In the command-line interface, navigate to the folder with this newly downloaded file. Use <code>pip install</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ pip install xgboost-0.6+20171121-cp36-cp36m-win_amd64.whl</pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Your XGBoost WHL filename may be slightly different as newer versions of the software are released publicly.</p>&#13;
</div>&#13;
&#13;
<p>Once XGBoost has been successfully installed, navigate back to the <em>handson-unsupervised-learning</em> folder.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Gradient Boosting, Version Two: LightGBM" data-type="sect2"><div class="sect2" id="idm140637564829104">&#13;
<h2>Gradient Boosting, Version Two: LightGBM</h2>&#13;
&#13;
<p>Install<a data-primary="LightGBM" data-secondary="installing" data-type="indexterm" id="idm140637564827744"/> another version of gradient boosting, Microsoft’s LightGBM:</p>&#13;
&#13;
<pre data-type="programlisting">$ pip install lightgbm</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Clustering Algorithms" data-type="sect2"><div class="sect2" id="idm140637564825616">&#13;
<h2>Clustering Algorithms</h2>&#13;
&#13;
<p>Let’s install<a data-primary="algorithms" data-secondary="for clustering" data-type="indexterm" id="idm140637564824016"/><a data-primary="fastcluster package" data-type="indexterm" id="idm140637564823008"/><a data-primary="clustering" data-secondary="algorithms for" data-type="indexterm" id="idm140637564822336"/> a few clustering algorithms we will use later in the book. One clustering package, <em>fastcluster</em>, is a C++ library with an interface in Python/SciPy.<sup><a data-type="noteref" href="ch02.html#idm140637564820880" id="idm140637564820880-marker">1</a></sup></p>&#13;
&#13;
<p>This fastcluster package can be installed with the following command:</p>&#13;
&#13;
<pre data-type="programlisting">$ pip install fastcluster</pre>&#13;
&#13;
<p>Another clustering algorithm is <em>hdbscan</em>, which can also be installed via pip:</p>&#13;
&#13;
<pre data-type="programlisting">$ pip install hdbscan</pre>&#13;
&#13;
<p>And, for time series clustering, let’s install <em>tslearn</em>:</p>&#13;
&#13;
<pre data-type="programlisting">$ pip install tslearn</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Interactive Computing Environment: Jupyter Notebook" data-type="sect2"><div class="sect2" id="idm140637564814992">&#13;
<h2>Interactive Computing Environment: Jupyter Notebook</h2>&#13;
&#13;
<p>Jupyter notebook<a data-primary="Jupyter Notebook" data-secondary="activating" data-type="indexterm" id="idm140637564813424"/> is part of the Anaconda distribution, so we will now activate it to launch the environment we just set up. Make sure you are in the <em>handson-unsupervised-learning</em> repository before you enter the following command (for ease of use):</p>&#13;
&#13;
<pre data-type="programlisting">$ jupyter notebook</pre>&#13;
&#13;
<p>You should see your browser open up and launch the <em><a href="http://localhost:8888/"><em class="hyperlink">http://localhost:8888/</em></a></em> page. Cookies must be enabled for proper access.</p>&#13;
&#13;
<p>We are now ready to build our first machine learning project.<a data-primary="" data-startref="MLPenv02" data-type="indexterm" id="idm140637564808688"/><a data-primary="" data-startref="envset02" data-type="indexterm" id="idm140637564807664"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Overview of the Data" data-type="sect1"><div class="sect1" id="idm140637564871088">&#13;
<h1>Overview of the Data</h1>&#13;
&#13;
<p>In<a data-primary="machine learning example project" data-secondary="overview of data" data-type="indexterm" id="idm140637564805184"/> this chapter, we will use a real dataset of anonymized credit card transactions made by European cardholders from September 2013.<sup><a data-type="noteref" href="ch02.html#idm140637564803888" id="idm140637564803888-marker">2</a></sup> These transactions are labeled as fraudulent or genuine, and we will build a fraud detection solution using machine learning to predict the correct labels for never-before-seen instances.</p>&#13;
&#13;
<p>This dataset is highly imbalanced. Of the 284,807 transactions, only 492 are <span class="keep-together">fraudulent</span> (0.172%). This low percentage of fraud is pretty typical for credit card transactions.</p>&#13;
&#13;
<p>There are 28 features, all of which are numerical, and there are no categorical variables.<sup><a data-type="noteref" href="ch02.html#idm140637564800304" id="idm140637564800304-marker">3</a></sup> These features are not the original features but rather the output of principal component analysis, which we will explore in <a data-type="xref" href="ch03.html#Chapter_3">Chapter 3</a>. The original features were distilled to 28 principal components using this form of dimensionality reduction.</p>&#13;
&#13;
<p>In addition to the 28 principal components, we have three other variables—the time of the transaction, the amount of the transaction, and the true class of the transaction (one if fraud, zero if genuine).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Data Preparation" data-type="sect1"><div class="sect1" id="idm140637564797632">&#13;
<h1>Data Preparation</h1>&#13;
&#13;
<p>Before<a data-primary="machine learning example project" data-secondary="data preparation" data-type="indexterm" id="MLPprep02"/> we can use machine learning to train on the data and develop a fraud detection solution, we need to prepare the data for the algorithms.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Data Acquisition" data-type="sect2"><div class="sect2" id="idm140637564794352">&#13;
<h2>Data Acquisition</h2>&#13;
&#13;
<p>The first step in any machine learning project is data acquisition.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Download the data" data-type="sect3"><div class="sect3" id="idm140637564792688">&#13;
<h3>Download the data</h3>&#13;
&#13;
<p>Download the dataset and, within the <em>handson-unsupervised-learning</em> directory, place the CSV file in a folder called <em>/datasets/credit_card_data/</em>. If you downloaded the GitHub repository earlier, you already have this file in this folder in the repository.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Import the necessary libraries" data-type="sect3"><div class="sect3" id="idm140637564789984">&#13;
<h3>Import the necessary libraries</h3>&#13;
&#13;
<p>Import the Python libraries that we will need to build our fraud detection solution:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="sd">'''Main'''</code>&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="kn">as</code> <code class="nn">pd</code>&#13;
<code class="kn">import</code> <code class="nn">os</code>&#13;
&#13;
<code class="sd">'''Data Viz'''</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="kn">as</code> <code class="nn">plt</code>&#13;
<code class="kn">import</code> <code class="nn">seaborn</code> <code class="kn">as</code> <code class="nn">sns</code>&#13;
<code class="n">color</code> <code class="o">=</code> <code class="n">sns</code><code class="o">.</code><code class="n">color_palette</code><code class="p">()</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib</code> <code class="kn">as</code> <code class="nn">mpl</code>&#13;
&#13;
<code class="o">%</code><code class="n">matplotlib</code> <code class="n">inline</code>&#13;
&#13;
<code class="sd">'''Data Prep'''</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn</code> <code class="kn">import</code> <code class="n">preprocessing</code> <code class="k">as</code> <code class="n">pp</code>&#13;
<code class="kn">from</code> <code class="nn">scipy.stats</code> <code class="kn">import</code> <code class="n">pearsonr</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">train_test_split</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">StratifiedKFold</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">log_loss</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">precision_recall_curve</code><code class="p">,</code> <code class="n">average_precision_score</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">roc_curve</code><code class="p">,</code> <code class="n">auc</code><code class="p">,</code> <code class="n">roc_auc_score</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">confusion_matrix</code><code class="p">,</code> <code class="n">classification_report</code>&#13;
&#13;
<code class="sd">'''Algos'''</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">LogisticRegression</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.ensemble</code> <code class="kn">import</code> <code class="n">RandomForestClassifier</code>&#13;
<code class="kn">import</code> <code class="nn">xgboost</code> <code class="kn">as</code> <code class="nn">xgb</code>&#13;
<code class="kn">import</code> <code class="nn">lightgbm</code> <code class="kn">as</code> <code class="nn">lgb</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Read the data" data-type="sect3"><div class="sect3" id="idm140637564784144">&#13;
<h3>Read the data</h3>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">current_path</code> <code class="o">=</code> <code class="n">os</code><code class="o">.</code><code class="n">getcwd</code><code class="p">()</code>&#13;
<code class="nb">file</code> <code class="o">=</code> <code class="s1">'</code><code class="se">\\</code><code class="s1">datasets</code><code class="se">\\</code><code class="s1">credit_card_data</code><code class="se">\\</code><code class="s1">credit_card.csv'</code>&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="n">current_path</code> <code class="o">+</code> <code class="nb">file</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Preview the data" data-type="sect3"><div class="sect3" id="idm140637561408064">&#13;
<h3>Preview the data</h3>&#13;
&#13;
<p><a data-type="xref" href="#preview_of_the_data">Table 2-1</a> shows the first five rows of the dataset. As you can see, the data has been properly loaded:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">data</code><code class="o">.</code><code class="n">head</code><code class="p">()</code></pre>&#13;
<table id="preview_of_the_data">&#13;
<caption><span class="label">Table 2-1. </span>Preview of the data</caption>&#13;
<thead>&#13;
<tr>&#13;
<th/>&#13;
<th>Time</th>&#13;
<th>V1</th>&#13;
<th>V2</th>&#13;
<th>V3</th>&#13;
<th>V4</th>&#13;
<th>V5</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>0</p></td>&#13;
<td><p>0.0</p></td>&#13;
<td><p>–1.359807</p></td>&#13;
<td><p>–0.072781</p></td>&#13;
<td><p>2.536347</p></td>&#13;
<td><p>1.378155</p></td>&#13;
<td><p>–0.338321</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>1</p></td>&#13;
<td><p>0.0</p></td>&#13;
<td><p>1.191857</p></td>&#13;
<td><p>0.266151</p></td>&#13;
<td><p>0.166480</p></td>&#13;
<td><p>0.448154</p></td>&#13;
<td><p>0.060018</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>2</p></td>&#13;
<td><p>1.0</p></td>&#13;
<td><p>–1.358354</p></td>&#13;
<td><p>–1.340163</p></td>&#13;
<td><p>1.773209</p></td>&#13;
<td><p>0.379780</p></td>&#13;
<td><p>–0.503198</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>3</p></td>&#13;
<td><p>1.0</p></td>&#13;
<td><p>–0.966272</p></td>&#13;
<td><p>–0.185226</p></td>&#13;
<td><p>1.792993</p></td>&#13;
<td><p>–0.863291</p></td>&#13;
<td><p>–0.010309</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>4</p></td>&#13;
<td><p>2.0</p></td>&#13;
<td><p>–1.158233</p></td>&#13;
<td><p>0.877737</p></td>&#13;
<td><p>1.548718</p></td>&#13;
<td><p>0.403034</p></td>&#13;
<td><p>–0.407193</p></td>&#13;
</tr>&#13;
</tbody>&#13;
<tfoot>&#13;
<tr>&#13;
<td colspan="7"><p>5 rows x 31 columns</p></td>&#13;
</tr>&#13;
</tfoot>&#13;
</table>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Data Exploration" data-type="sect2"><div class="sect2" id="idm140637561377440">&#13;
<h2>Data Exploration</h2>&#13;
&#13;
<p>Next, let’s get a deeper understanding of the data. We will generate summary statistics for the data, identify any missing values or categorical features, and count the number of distinct values by feature.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Generate summary statistics" data-type="sect3"><div class="sect3" id="idm140637561375520">&#13;
<h3>Generate summary statistics</h3>&#13;
&#13;
<p><a data-type="xref" href="#simple_summary_statistics">Table 2-2</a> describes the data, column by column. The block of code that follows lists all the column names for easy reference.</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">data</code><code class="o">.</code><code class="n">describe</code><code class="p">()</code></pre>&#13;
<table class="pagebreak-before" id="simple_summary_statistics">&#13;
<caption><span class="label">Table 2-2. </span>Simple summary statistics</caption>&#13;
<thead>&#13;
<tr>&#13;
<th/>&#13;
<th>Time</th>&#13;
<th>V1</th>&#13;
<th>V2</th>&#13;
<th>V3</th>&#13;
<th>V4</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>count</p></td>&#13;
<td><p>284807.000000</p></td>&#13;
<td><p>2.848070e+05</p></td>&#13;
<td><p>2.848070e+05</p></td>&#13;
<td><p>2.848070e+05</p></td>&#13;
<td><p>2.848070e+05</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>mean</p></td>&#13;
<td><p>94813.859575</p></td>&#13;
<td><p>3.919560e–15</p></td>&#13;
<td><p>5.688174e–16</p></td>&#13;
<td><p>–8.769071e–15</p></td>&#13;
<td><p>2.782312e–15</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>std</p></td>&#13;
<td><p>47488.145955</p></td>&#13;
<td><p>1.958696e+00</p></td>&#13;
<td><p>1.651309e+00</p></td>&#13;
<td><p>1.516255e+00</p></td>&#13;
<td><p>1.415869e+00</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>min</p></td>&#13;
<td><p>0.000000</p></td>&#13;
<td><p>–5.640751e+01</p></td>&#13;
<td><p>–7.271573e+01</p></td>&#13;
<td><p>–4.832559e+01</p></td>&#13;
<td><p>–5.683171e+00</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>25%</p></td>&#13;
<td><p>54201.500000</p></td>&#13;
<td><p>–9.203734e–01</p></td>&#13;
<td><p>–5.985499e–01</p></td>&#13;
<td><p>–8.903648e–01</p></td>&#13;
<td><p>–8.486401e–01</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>50%</p></td>&#13;
<td><p>84692.000000</p></td>&#13;
<td><p>1.810880e–02</p></td>&#13;
<td><p>6.548556e–02</p></td>&#13;
<td><p>1.798463e–01</p></td>&#13;
<td><p>–1.984653e–02</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>75%</p></td>&#13;
<td><p>139320.500000</p></td>&#13;
<td><p>1.315642e+00</p></td>&#13;
<td><p>8.037239e–01</p></td>&#13;
<td><p>1.027196e+00</p></td>&#13;
<td><p>7.433413e–01</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>max</p></td>&#13;
<td><p>172792.000000</p></td>&#13;
<td><p>2.454930e+00</p></td>&#13;
<td><p>2.205773e+01</p></td>&#13;
<td><p>9.382558e+00</p></td>&#13;
<td><p>1.687534e+01</p></td>&#13;
</tr>&#13;
</tbody>&#13;
<tfoot>&#13;
<tr>&#13;
<td colspan="6"><p>8 rows x 31 columns</p></td>&#13;
</tr>&#13;
</tfoot>&#13;
</table>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">data</code><code class="o">.</code><code class="n">columns</code></pre>&#13;
&#13;
<pre data-type="programlisting">Index(['Time', 'V1,' 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',&#13;
'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',&#13;
'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'],&#13;
dtype='object')</pre>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">data</code><code class="p">[</code><code class="s1">'Class'</code><code class="p">]</code><code class="o">.</code><code class="n">sum</code><code class="p">()</code></pre>&#13;
&#13;
<p>The total number of positive labels, or fraudulent transactions, is 492. There are 284,807 instances and 31 columns as expected—28 numerical features (V1 through V28), Time, Amount, and Class.</p>&#13;
&#13;
<p>The timestamps range from 0 to 172,792, the amounts range from 0 to 25,691.16, and there are 492 fraudulent transactions. These fraudulent transactions are also referred to as positive cases or positive labels (labeled as one); the normal transactions are negative cases or negative labels (labeled as zero).</p>&#13;
&#13;
<p>The<a data-primary="standardization" data-type="indexterm" id="idm140637561165552"/> 28 numerical features are not standardized yet, but we will standardize the data soon. <em>Standardization</em> rescales the data to have a mean of zero and standard deviation of one.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Some machine learning solutions are very sensitive to the scale of the data, so having all the data on the same relative scale—via standardization—is a good machine learning practice.</p>&#13;
&#13;
<p>Another<a data-primary="normalization" data-type="indexterm" id="idm140637561249840"/> common method to scale data is <em>normalization</em>, which rescales the data to a zero to one range. Unlike the standardized data, all the normalized data is on a positive scale.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Identify nonnumerical values by feature" data-type="sect3"><div class="sect3" id="idm140637561374896">&#13;
<h3>Identify nonnumerical values by feature</h3>&#13;
&#13;
<p>Some<a data-primary="not a number (NaNs)" data-type="indexterm" id="idm140637561246816"/> machine learning algorithms cannot handle nonnumerical values or missing values. Therefore, it is best practice to identify nonnumerical values (also known as <em>not a number</em>, or <em>NaNs</em>).</p>&#13;
&#13;
<p>In the case of missing values, we can impute the value—for example, by replacing the missing points with the mean, median, or mode of the feature—or substitute with some user-defined value. In the case of categorical values, we can encode the data such that all the categorical values are represented with a sparse matrix. This sparse matrix is then combined with the numerical features. The machine learning algorithm trains on this combined feature set.</p>&#13;
&#13;
<p>The following code shows that none of the observations have NaNs, so we will not need to impute or encode any of the values:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">nanCounter</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">isnan</code><code class="p">(</code><code class="n">data</code><code class="p">)</code><code class="o">.</code><code class="n">sum</code><code class="p">()</code></pre>&#13;
&#13;
<pre data-type="programlisting">Time 		0&#13;
V1 		0&#13;
V2 		0&#13;
V3 		0&#13;
V4 		0&#13;
V5 		0&#13;
V6 		0&#13;
V7 		0&#13;
V8 		0&#13;
V9 		0&#13;
V10 		0&#13;
V11 		0&#13;
V12 		0&#13;
V13 		0&#13;
V14 		0&#13;
V15 		0&#13;
V16 		0&#13;
V17 		0&#13;
V18 		0&#13;
V19 		0&#13;
V20 		0&#13;
V21 		0&#13;
V22 		0&#13;
V23 		0&#13;
V24 		0&#13;
V25 		0&#13;
V26 		0&#13;
V27 		0&#13;
V28 		0&#13;
Amount 	0&#13;
Class 		0&#13;
dtype: 	int64</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Identify distinct values by feature" data-type="sect3"><div class="sect3" id="idm140637561130112">&#13;
<h3>Identify distinct values by feature</h3>&#13;
&#13;
<p>To develop a better understanding of the credit card transactions dataset, let’s count the number of distinct values by feature.</p>&#13;
&#13;
<p>The following code shows that we have 124,592 distinct timestamps. But we know from earlier that we have 284,807 observations in total. That means that there are multiple transactions at some timestamps.</p>&#13;
&#13;
<p>And, as expected, there are just two classes—one for fraud, zero for not fraud:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">distinctCounter</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="nb">len</code><code class="p">(</code><code class="n">x</code><code class="o">.</code><code class="n">unique</code><code class="p">()))</code></pre>&#13;
&#13;
<pre data-type="programlisting">Time 		124592&#13;
V1 		275663&#13;
V2 		275663&#13;
V3 		275663&#13;
V4 		275663&#13;
V5 		275663&#13;
V6 		275663&#13;
V7 		275663&#13;
V8 		275663&#13;
V9 		275663&#13;
V10 		275663&#13;
V11 		275663&#13;
V12 		275663&#13;
V13 		275663&#13;
V14 		275663&#13;
V15 		275663&#13;
V16 		275663&#13;
V17 		275663&#13;
V18 		275663&#13;
V19 		275663&#13;
V20 		275663&#13;
V21 		275663&#13;
V22 		275663&#13;
V23 		275663&#13;
V24 		275663&#13;
V25 		275663&#13;
V26 		275663&#13;
V27 		275663&#13;
V28 		275663&#13;
Amount 	32767&#13;
Class 		2&#13;
dtype: 	int64</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Generate Feature Matrix and Labels Array" data-type="sect2"><div class="sect2" id="idm140637561176912">&#13;
<h2>Generate Feature Matrix and Labels Array</h2>&#13;
&#13;
<p>Let’s create and standardize the feature matrix X and isolate the labels array y (one for fraud, zero for not fraud). Later on we will feed these into the machine learning algorithms during training.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Create the feature matrix X and the labels array Y" data-type="sect3"><div class="sect3" id="idm140637561233280">&#13;
<h3>Create the feature matrix X and the labels array Y</h3>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">dataX</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code><code class="o">.</code><code class="n">drop</code><code class="p">([</code><code class="err">‘</code><code class="n">Class</code><code class="err">’</code><code class="p">],</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">dataY</code> <code class="o">=</code> <code class="n">data</code><code class="p">[</code><code class="err">‘</code><code class="n">Class</code><code class="err">’</code><code class="p">]</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Standardize the feature matrix X" data-type="sect3"><div class="sect3" id="idm140637561231488">&#13;
<h3>Standardize the feature matrix X</h3>&#13;
&#13;
<p>Let’s rescale the feature matrix so that each feature, except for time, has a mean of zero and standard deviation of one:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">featuresToScale</code> <code class="o">=</code> <code class="n">dataX</code><code class="o">.</code><code class="n">drop</code><code class="p">([</code><code class="s1">'Time'</code><code class="p">],</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="o">.</code><code class="n">columns</code>&#13;
<code class="n">sX</code> <code class="o">=</code> <code class="n">pp</code><code class="o">.</code><code class="n">StandardScaler</code><code class="p">(</code><code class="n">copy</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>&#13;
<code class="n">dataX</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">featuresToScale</code><code class="p">]</code> <code class="o">=</code> <code class="n">sX</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">dataX</code><code class="p">[</code><code class="n">featuresToScale</code><code class="p">])</code></pre>&#13;
&#13;
<p>As shown in <a data-type="xref" href="#summary_of_scaled_features">Table 2-3</a>, the standardized features now have a mean of zero and a standard deviation of one.</p>&#13;
<table id="summary_of_scaled_features">&#13;
<caption><span class="label">Table 2-3. </span>Summary of scaled features</caption>&#13;
<thead>&#13;
<tr>&#13;
<th/>&#13;
<th>Time</th>&#13;
<th>V1</th>&#13;
<th>V2</th>&#13;
<th>V3</th>&#13;
<th>V4</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>count</p></td>&#13;
<td><p>284807.000000</p></td>&#13;
<td><p>2.848070e+05</p></td>&#13;
<td><p>2.848070e+05</p></td>&#13;
<td><p>2.848070e+05</p></td>&#13;
<td><p>2.848070e+05</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>mean</p></td>&#13;
<td><p>94813.859575</p></td>&#13;
<td><p>–8.157366e–16</p></td>&#13;
<td><p>3.154853e–17</p></td>&#13;
<td><p>–4.409878e–15</p></td>&#13;
<td><p>–6.734811e–16</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>std</p></td>&#13;
<td><p>47488.145955</p></td>&#13;
<td><p>1.000002e+00</p></td>&#13;
<td><p>1.000002e+00</p></td>&#13;
<td><p>1.000002e+00</p></td>&#13;
<td><p>1.000002e+00</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>min</p></td>&#13;
<td><p>0.000000</p></td>&#13;
<td><p>–2.879855e+01</p></td>&#13;
<td><p>–4.403529e+01</p></td>&#13;
<td><p>–3.187173e+01</p></td>&#13;
<td><p>–4.013919e+00</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>25%</p></td>&#13;
<td><p>54201.500000</p></td>&#13;
<td><p>–4.698918e–01</p></td>&#13;
<td><p>–3.624707e–01</p></td>&#13;
<td><p>–5.872142e–01</p></td>&#13;
<td><p>–5.993788e–01</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>50%</p></td>&#13;
<td><p>84692.000000</p></td>&#13;
<td><p>9.245351e–03</p></td>&#13;
<td><p>3.965683e–02</p></td>&#13;
<td><p>1.186124e–02</p></td>&#13;
<td><p>–1.401724e–01</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>75%</p></td>&#13;
<td><p>139320.500000</p></td>&#13;
<td><p>6.716939e–01</p></td>&#13;
<td><p>4.867202e–01</p></td>&#13;
<td><p>6.774569e–01</p></td>&#13;
<td><p>5.250082e–01</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>max</p></td>&#13;
<td><p>172792.000000</p></td>&#13;
<td><p>1.253351e+00</p></td>&#13;
<td><p>1.335775e+01</p></td>&#13;
<td><p>6.187993e+00</p></td>&#13;
<td><p>1.191874e+01</p></td>&#13;
</tr>&#13;
</tbody>&#13;
<tfoot>&#13;
<tr>&#13;
<td colspan="6"><p>8 rows x 30 columns</p></td>&#13;
</tr>&#13;
</tfoot>&#13;
</table>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Feature Engineering and Feature Selection" data-type="sect2"><div class="sect2" id="idm140637556637184">&#13;
<h2>Feature Engineering and Feature Selection</h2>&#13;
&#13;
<p>In<a data-primary="feature engineering" data-type="indexterm" id="idm140637556635648"/><a data-primary="feature selection" data-type="indexterm" id="idm140637556634912"/> most machine learning projects, we should consider <em>feature engineering</em> and <em>feature selection</em> as part of the solution. Feature engineering involves creating new features—for example, calculating ratios or counts or sums from the original features—to help the machine learning algorithm extract a stronger signal from the dataset.</p>&#13;
&#13;
<p>Feature selection involves selecting a subset of the features for training, effectively removing some of the less relevant features from consideration. This may help prevent the machine learning algorithm from overfitting to the noise in the dataset.</p>&#13;
&#13;
<p>For this credit card fraud dataset, we do not have the original features. We have only the principal components, which were derived from PCA, a form of dimensionality reduction that we will explore in <a data-type="xref" href="ch03.html#Chapter_3">Chapter 3</a>. Since we do not know what any of the features represent, we cannot perform any intelligent feature engineering.</p>&#13;
&#13;
<p>Feature selection is not necessary either since the number of observations (284,807) vastly outnumbers the number of features (30), which dramatically reduces the chances of overfitting. And, as <a data-type="xref" href="#correlation_matrix">Figure 2-1</a> shows, the features are only slightly correlated to each other. In other words, we do not have redundant features. If we did, we could remove or reduce the redundancy via dimensionality reduction. Of course, this is not a surprise. PCA was already performed on this credit card dataset, removing the redundancy for us.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Check correlation of features" data-type="sect3"><div class="sect3" id="idm140637556628784">&#13;
<h3>Check correlation of features</h3>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">correlationMatrix</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code><code class="n">index</code><code class="o">=</code><code class="n">dataX</code><code class="o">.</code><code class="n">columns</code><code class="p">,</code>&#13;
<code class="n">columns</code><code class="o">=</code><code class="n">dataX</code><code class="o">.</code><code class="n">columns</code><code class="p">)</code>&#13;
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="n">dataX</code><code class="o">.</code><code class="n">columns</code><code class="p">:</code>&#13;
    <code class="k">for</code> <code class="n">j</code> <code class="ow">in</code> <code class="n">dataX</code><code class="o">.</code><code class="n">columns</code><code class="p">:</code>&#13;
        <code class="n">correlationMatrix</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">i</code><code class="p">,</code><code class="n">j</code><code class="p">]</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">round</code><code class="p">(</code><code class="n">pearsonr</code><code class="p">(</code><code class="n">dataX</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">i</code><code class="p">],</code>&#13;
         <code class="n">dataX</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">j</code><code class="p">])[</code><code class="mi">0</code><code class="p">],</code><code class="mi">2</code><code class="p">)</code></pre>&#13;
&#13;
<figure><div class="figure" id="correlation_matrix">&#13;
<img alt="Correlation matrix" src="assets/hulp_0201.png"/>&#13;
<h6><span class="label">Figure 2-1. </span>Correlation matrix</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Data Visualization" data-type="sect2"><div class="sect2" id="idm140637556445776">&#13;
<h2>Data Visualization</h2>&#13;
&#13;
<p>As a final step, let’s visualize the data to appreciate just how imbalanced the dataset is (<a data-type="xref" href="#frequency_percentage_of_labels">Figure 2-2</a>). Since<a data-primary="" data-startref="MLPprep02" data-type="indexterm" id="idm140637556443504"/> there are so few cases of fraud to learn from, this is a difficult problem to solve; fortunately, we have labels for the entire dataset:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">count_classes</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="s1">'Class'</code><code class="p">],</code><code class="n">sort</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code class="o">.</code><code class="n">sort_index</code><code class="p">()</code>&#13;
<code class="n">ax</code> <code class="o">=</code> <code class="n">sns</code><code class="o">.</code><code class="n">barplot</code><code class="p">(</code><code class="n">x</code><code class="o">=</code><code class="n">count_classes</code><code class="o">.</code><code class="n">index</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="nb">tuple</code><code class="p">(</code><code class="n">count_classes</code><code class="o">/</code><code class="nb">len</code><code class="p">(</code><code class="n">data</code><code class="p">)))</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="s1">'Frequency Percentage by Class'</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_xlabel</code><code class="p">(</code><code class="s1">'Class'</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_ylabel</code><code class="p">(</code><code class="s1">'Frequency Percentage'</code><code class="p">)</code></pre>&#13;
&#13;
<figure><div class="figure" id="frequency_percentage_of_labels">&#13;
<img alt="Frequency percentage of labels" src="assets/hulp_0202.png"/>&#13;
<h6><span class="label">Figure 2-2. </span>Frequency percentage of labels</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Model Preparation" data-type="sect1"><div class="sect1" id="idm140637556259168">&#13;
<h1>Model Preparation</h1>&#13;
&#13;
<p>Now<a data-primary="machine learning example project" data-secondary="model preparation" data-type="indexterm" id="idm140637556257664"/> that the data is ready, let’s prepare for the model. We need to split the data into a training and a test set, select a cost function, and prepare for <em>k</em>-fold cross-validation.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Split into Training and Test Sets" data-type="sect2"><div class="sect2" id="idm140637556255872">&#13;
<h2>Split into Training and Test Sets</h2>&#13;
&#13;
<p>As you may recall from <a data-type="xref" href="ch01.html#Chapter_1">Chapter 1</a>, machine learning algorithms learn from data (i.e., train on the data) to have good performance (i.e., accurately predict) on never-before-seen cases. The<a data-primary="generalization error" data-type="indexterm" id="idm140637556253264"/> performance on these never-before-seen cases is known as the generalization error—this is the most important metric in determining the goodness of a machine learning model.</p>&#13;
&#13;
<p>We need to set up our machine learning project so that we have a training set from which the machine learning algorithm learns. We also need a test set (the never-before-seen cases) the machine learning algorithm can make predictions on. The performance on this test set will be the ultimate gauge of success.</p>&#13;
&#13;
<p>Let’s go ahead and split our credit card transactions dataset into a training set and a test set.</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">X_train</code><code class="p">,</code> <code class="n">X_test</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> <code class="n">train_test_split</code><code class="p">(</code><code class="n">dataX</code><code class="p">,</code>&#13;
                                    <code class="n">dataY</code><code class="p">,</code> <code class="n">test_size</code><code class="o">=</code><code class="mf">0.33</code><code class="p">,</code>&#13;
                                    <code class="n">random_state</code><code class="o">=</code><code class="mi">2018</code><code class="p">,</code> <code class="n">stratify</code><code class="o">=</code><code class="n">dataY</code><code class="p">)</code></pre>&#13;
&#13;
<p>We now have a training set with 190,280 instances (67% of the original dataset) and a test set with 93,987 instances (the remaining 33%). To preserve the percentage of fraud (~0.17%) for both the training and the test set, we have set the stratify parameter. We also fixed the random state to 2018 to make it easier to reproduce results.<sup><a data-type="noteref" href="ch02.html#idm140637556238384" id="idm140637556238384-marker">4</a></sup></p>&#13;
&#13;
<p>We will use the test set for a final evaluation of our generalization error (also known as out-of-sample error).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Select Cost Function" data-type="sect2"><div class="sect2" id="idm140637556209248">&#13;
<h2>Select Cost Function</h2>&#13;
&#13;
<p>Before we train on the training set, we need a cost function (also referred to as the error rate or value function) to pass into the machine learning algorithm. The machine learning algorithm will try to minimize this cost function by learning from the training examples.</p>&#13;
&#13;
<p>Since this is a supervised classification problem—with two classes—let’s use <em>binary classification log loss</em> (as shown in <a data-type="xref" href="#log_loss_function">Equation 2-1</a>), which will calculate the cross-entropy between the true labels and the model-based predictions.</p>&#13;
<div data-type="equation" id="log_loss_function"><h5><span class="label">Equation 2-1. </span>Log loss function</h5>&#13;
<math class="center" display="block">&#13;
<mi>log loss</mi><mo>=</mo>&#13;
<mrow>&#13;
 	<mo>–</mo>&#13;
	<mfrac>&#13;
		<mn>1</mn><mi>N</mi>&#13;
	</mfrac>&#13;
</mrow>&#13;
<munderover>&#13;
	<mo mathsize="200%">Σ</mo>&#13;
	<mrow><mi>i</mi><mo>=</mo><mi>1</mi></mrow>&#13;
	<mi>N</mi>&#13;
</munderover>&#13;
<munderover>&#13;
	<mo mathsize="200%">Σ</mo>&#13;
	<mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow>&#13;
	<mi>M</mi>&#13;
</munderover>&#13;
<msub>&#13;
	<mi>y</mi>&#13;
	<mrow><mi>i</mi><mtext>,</mtext><mi>j</mi></mrow></msub>&#13;
<mi>log</mi>&#13;
<mo stretchy="false">(</mo>&#13;
<msub>&#13;
	<mi>p</mi>&#13;
	<mrow><mi>i</mi><mtext>,</mtext><mi>j</mi></mrow></msub>&#13;
<mo stretchy="false">)</mo>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>Where <em>N</em> is the number of observations; <em>M</em> is the number of class labels (in this case, two); log is the natural logarithm; <sub><em>yi,j</em></sub> is 1 if observation <em>i</em> is in class <em>j</em> and 0 otherwise; and <sub><em>pi,j</em></sub> is the predicted probability that observation <em>i</em> is in class <em>j</em>.</p>&#13;
&#13;
<p>The machine learning model will generate the fraud probability for each credit card transaction. The closer the fraud probabilities are to the true labels (i.e., one for fraud or zero for not fraud), the lower the value of the log loss function. This is what the machine learning algorithm will try to minimize.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Create k-Fold Cross-Validation Sets" data-type="sect2"><div class="sect2" id="idm140637556184096">&#13;
<h2>Create k-Fold Cross-Validation Sets</h2>&#13;
&#13;
<p>To help the machine learning algorithm estimate what its performance will be on the never-before-seen examples (the test set), it is best practice to further split the training set into a training set and a validation set.</p>&#13;
&#13;
<p>For example, if we split the training set into fifths, we can train on four-fifths of the original training set and evalulate the newly training model by making predictions on the fifth slice of the original training set, known as the validation set.</p>&#13;
&#13;
<p>It is possible to train and evaluate like this five times—leaving aside a different fifth slice as the validation set each time. This is known as<a data-primary="k-fold cross-validation" data-type="indexterm" id="idm140637556181216"/> <em>k-fold cross-validation</em>, where <em>k</em> in this case is five. With this approach, we will have not one estimate but five estimates for the generalization error.</p>&#13;
&#13;
<p>We will store the training score and the cross-validation score for each of the five runs, and we will store the cross-validation predictions each time. After all five runs are complete, we will have cross-validation predictions for the entire dataset. This will be the best all-in estimate of the performance the test set.</p>&#13;
&#13;
<p>Here’s how to set up for the <em>k</em>-fold validation, where <em>k</em> is five:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">k_fold</code> <code class="o">=</code> <code class="n">StratifiedKFold</code><code class="p">(</code><code class="n">n_splits</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> <code class="n">shuffle</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">2018</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Machine Learning Models (Part I)" data-type="sect1"><div class="sect1" id="idm140637556258864">&#13;
<h1>Machine Learning Models (Part I)</h1>&#13;
&#13;
<p>Now we’re ready to build the machine learning models. For each machine algorithm we consider, we will set hyperparameters, train the model, and evaluate the results.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Model #1: Logistic Regression" data-type="sect2"><div class="sect2" id="idm140637556399344">&#13;
<h2>Model #1: Logistic Regression</h2>&#13;
&#13;
<p>Let’s start<a data-primary="algorithms" data-secondary="logistic regression" data-type="indexterm" id="idm140637556397648"/><a data-primary="machine learning example project" data-secondary="logistic regression model" data-type="indexterm" id="MLPlogreg02"/><a data-primary="linear methods" data-secondary="logistic regression algorithm" data-type="indexterm" id="LMlogreg02"/><a data-primary="logistic regression algorithm" data-type="indexterm" id="logreg2"/> with the most basic classification algorithm, logistic regression.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Set hyperparameters" data-type="sect3"><div class="sect3" id="idm140637556393136">&#13;
<h3>Set hyperparameters</h3>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">penalty</code> <code class="o">=</code> <code class="s1">'l2'</code>&#13;
<code class="n">C</code> <code class="o">=</code> <code class="mf">1.0</code>&#13;
<code class="n">class_weight</code> <code class="o">=</code> <code class="s1">'balanced'</code>&#13;
<code class="n">random_state</code> <code class="o">=</code> <code class="mi">2018</code>&#13;
<code class="n">solver</code> <code class="o">=</code> <code class="s1">'liblinear'</code>&#13;
&#13;
<code class="n">logReg</code> <code class="o">=</code> <code class="n">LogisticRegression</code><code class="p">(</code><code class="n">penalty</code><code class="o">=</code><code class="n">penalty</code><code class="p">,</code> <code class="n">C</code><code class="o">=</code><code class="n">C</code><code class="p">,</code>&#13;
            <code class="n">class_weight</code><code class="o">=</code><code class="n">class_weight</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="n">random_state</code><code class="p">,</code>&#13;
                            <code class="n">solver</code><code class="o">=</code><code class="n">solver</code><code class="p">,</code> <code class="n">n_jobs</code><code class="o">=</code><code class="n">n_jobs</code><code class="p">)</code></pre>&#13;
&#13;
<p>We will set the penalty to the default value L2 instead of L1. Compared to L1, L2 is less sensitive to outliers and will assign nonzero weights to nearly all the features, resulting in a stable solution. L1 will assign high weights to the most important features and near-zero weights to the rest, essentially performing feature selection as the algorithm trains. However, because the weights vary so much feature to feature, the L1 solution is not as stable to changes in data points as the L2 solution.<sup><a data-type="noteref" href="ch02.html#idm140637556129056" id="idm140637556129056-marker">5</a></sup></p>&#13;
&#13;
<p>C is the regularization strength. As you may recall from <a data-type="xref" href="ch01.html#Chapter_1">Chapter 1</a>, regularization helps address overfitting by penalizing complexity. In other words, the stronger the regularization, the greater the penalty the machine learning algorithm applies to complexity. Regularization nudges the machine learning algorithm to prefer simpler models to more complex ones, all else equal.</p>&#13;
&#13;
<p>This regularization constant, C, must be a positive floating number. The smaller the value, the stronger the regularization. We will keep the default 1.0.</p>&#13;
&#13;
<p>Our credit card transactions dataset is very imbalanced—out of all the 284,807 cases, only 492 are fraudulent. As the machine learning algorithm trains, we want the algorithm to focus more attention on learning from the positive labeled transactions—in other words, the fraudulent transactions—because there are so few of them in the dataset.</p>&#13;
&#13;
<p>For this logistic regression model, we will set the <code>class_weight</code> to balanced. This signals to the logistic regression algorithm that we have an imbalanced class problem; the algorithm will need to weigh the positive labels more heavily as it trains. In this case, the weights will be inversely proportional to the class frequencies; the algorithm will assign higher weights to the rare positive labels (i.e., fraud) and lower weights to the more frequent negative labels (i.e., not fraud).</p>&#13;
&#13;
<p>The random state is fixed to 2018 to help others—such as you, the reader—reproduce results. We will keep the default solver liblinear.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Train the model" data-type="sect3"><div class="sect3" id="idm140637556159504">&#13;
<h3>Train the model</h3>&#13;
&#13;
<p>Now that the hyperparameters are set, we will train the logistic regression model on each of the five <em>k</em>-fold cross-validation splits, training on four-fifths of the training set and evaulating the performance on the fifth slice that is held aside.</p>&#13;
&#13;
<p>As we train and evaluate like this five times, we will calculate the cost function—log loss for our credit card transactions problem—for the training (i.e., the four-fifths slice of the original training set) and for the validation (i.e., the one-fifth slice of the original training set). We will also store the predictions for each of the five cross-validation sets; by the end of the fifth run, we will have predictions for the entire training set:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">trainingScores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">cvScores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">predictionsBasedOnKFolds</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code>&#13;
                                        <code class="n">index</code><code class="o">=</code><code class="n">y_train</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code><code class="mi">1</code><code class="p">])</code>&#13;
&#13;
<code class="n">model</code> <code class="o">=</code> <code class="n">logReg</code>&#13;
&#13;
<code class="k">for</code> <code class="n">train_index</code><code class="p">,</code> <code class="n">cv_index</code> <code class="ow">in</code> <code class="n">k_fold</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">X_train</code><code class="p">))</code>&#13;
                                          <code class="p">,</code><code class="n">y_train</code><code class="o">.</code><code class="n">ravel</code><code class="p">()):</code>&#13;
    <code class="n">X_train_fold</code><code class="p">,</code> <code class="n">X_cv_fold</code> <code class="o">=</code> <code class="n">X_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_index</code><code class="p">,:],</code> \&#13;
        <code class="n">X_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">cv_index</code><code class="p">,:]</code>&#13;
    <code class="n">y_train_fold</code><code class="p">,</code> <code class="n">y_cv_fold</code> <code class="o">=</code> <code class="n">y_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_index</code><code class="p">],</code> \&#13;
        <code class="n">y_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">cv_index</code><code class="p">]</code>&#13;
&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_fold</code><code class="p">,</code> <code class="n">y_train_fold</code><code class="p">)</code>&#13;
    <code class="n">loglossTraining</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_train_fold</code><code class="p">,</code>&#13;
                               <code class="n">model</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">X_train_fold</code><code class="p">)[:,</code><code class="mi">1</code><code class="p">])</code>&#13;
    <code class="n">trainingScores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">loglossTraining</code><code class="p">)</code>&#13;
&#13;
    <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">X_cv_fold</code><code class="o">.</code><code class="n">index</code><code class="p">,:]</code> <code class="o">=</code> \&#13;
        <code class="n">model</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">X_cv_fold</code><code class="p">)</code>&#13;
    <code class="n">loglossCV</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_cv_fold</code><code class="p">,</code>&#13;
                         <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">X_cv_fold</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="mi">1</code><code class="p">])</code>&#13;
    <code class="n">cvScores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">loglossCV</code><code class="p">)</code>&#13;
&#13;
    <code class="k">print</code><code class="p">(</code><code class="s1">'Training Log Loss: '</code><code class="p">,</code> <code class="n">loglossTraining</code><code class="p">)</code>&#13;
    <code class="k">print</code><code class="p">(</code><code class="s1">'CV Log Loss: '</code><code class="p">,</code> <code class="n">loglossCV</code><code class="p">)</code>&#13;
&#13;
<code class="n">loglossLogisticRegression</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_train</code><code class="p">,</code>&#13;
                                     <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="mi">1</code><code class="p">])</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="s1">'Logistic Regression Log Loss: '</code><code class="p">,</code> <code class="n">loglossLogisticRegression</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Evaluate the results" data-type="sect3"><div class="sect3" id="idm140637556102208">&#13;
<h3>Evaluate the results</h3>&#13;
&#13;
<p>The training log loss and cross-validation log loss are shown for each of the five runs in the following code. Generally (but not always) the training log loss will be lower than the cross-validation log loss. Because the machine learning algorithm has learned directly from the training data, its performance (i.e., log loss) should be better on the training set than on the cross-validation set. Remember, the cross-validation set has the transactions that were explicitly held out from the training exercise.</p>&#13;
&#13;
<pre data-type="programlisting">Training Log Loss: 		0.10080139188958696&#13;
CV Log Loss:		0.10490645274118293&#13;
Training Log Loss: 		0.12098957040484648&#13;
CV Log Loss:		0.11634801169793386&#13;
Training Log Loss: 		0.1074616029843435&#13;
CV Log Loss:		0.10845630232487576&#13;
Training Log Loss: 		0.10228137039781758&#13;
CV Log Loss:		0.10321736161148198&#13;
Training Log Loss: 		0.11476012373315266&#13;
CV Log Loss:		0.1160124452312548</pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>For our credit card transactions dataset, it is important to keep in mind that we are building a fraud detection solution. When<a data-primary="performance" data-type="indexterm" id="idm140637555961552"/> we refer to the <em>performance</em> of the machine learning model, we mean how good the model is at predicting fraud among the transactions in the dataset.</p>&#13;
&#13;
<p>The machine learning model outputs a prediction probability for each transaction, where one is fraud and zero is not fraud. The closer the probability is to one, the more likely the transaction is fraudulent; the closer the probability is to zero, the more likely the transaction is normal. By comparing the model’s probabilities with the true labels, we can assess the goodness of the model.</p>&#13;
</div>&#13;
&#13;
<p>For each of the five runs, their training and cross-validation log losses are similar. The logistic regression model does not exhibit severe overfitting; if it did, we would have a low training log loss and comparably high cross-validation log loss.</p>&#13;
&#13;
<p>Since<a data-primary="" data-startref="MLPlogreg02" data-type="indexterm" id="idm140637555958096"/><a data-primary="" data-startref="LMlogreg02" data-type="indexterm" id="idm140637555957088"/><a data-primary="" data-startref="logreg2" data-type="indexterm" id="idm140637555956144"/> we stored the predictions for each of the five cross-validation sets, we can combine the predictions into a single set. This single set is the same as the original training set, and we can now calculate the overall log loss for this entire training set. This is the best estimate for the logistic regression model’s log loss on the test set:</p>&#13;
&#13;
<pre data-type="programlisting">Logistic Regression Log Loss: 0.10978811472134588</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Evaluation Metrics" data-type="sect1"><div class="sect1" id="idm140637555953792">&#13;
<h1>Evaluation Metrics</h1>&#13;
&#13;
<p>Although<a data-primary="machine learning example project" data-secondary="evaluation metrics" data-type="indexterm" id="MLPevmet02"/><a data-primary="evaluation metrics" data-secondary="uses for" data-type="indexterm" id="idm140637555950752"/> the log loss is a great way to estimate the performance of the machine learning model, we may want a more intuitive way to understand the results. For example, of the fraudulent transactions in the training set, how many did we catch? This<a data-primary="recall" data-type="indexterm" id="idm140637555949424"/> is known as the <em>recall</em>. Or, the transactions that were flagged as fraudulent by the logistic regression model, how many were truly fraudulent? This<a data-primary="precision" data-type="indexterm" id="idm140637555948064"/> is known as the <em>precision</em> of the model.</p>&#13;
&#13;
<p>Let’s take a look at these and other similar evaluation metrics to help us more intuitively grasp the results.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>These evaluation metrics are very important because they empower data scientists to intuitively explain results to business people, who may be less familiar with log loss, cross-entropy, and other cost functions. The ability to convey complex results as simply as possible to nondata scientists is one of the essential skills for applied data scientists to master.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Confusion Matrix" data-type="sect2"><div class="sect2" id="idm140637555944720">&#13;
<h2>Confusion Matrix</h2>&#13;
&#13;
<p>In<a data-primary="evaluation metrics" data-secondary="confusion matrix" data-type="indexterm" id="idm140637555943152"/><a data-primary="confusion matrix" data-type="indexterm" id="idm140637555942144"/> a typical classification problem (without class imbalance) we can evaluate the results using a confusion matrix, which is a table that summarizes the number of true positives, true negatives, false positives, and false negatives (<a data-type="xref" href="#confusion_matrix">Figure 2-3</a>).<sup><a data-type="noteref" href="ch02.html#idm140637555940304" id="idm140637555940304-marker">6</a></sup></p>&#13;
&#13;
<figure><div class="figure" id="confusion_matrix">&#13;
<img alt="Confusion matrix" src="assets/hulp_0203.png"/>&#13;
<h6><span class="label">Figure 2-3. </span>Confusion matrix</h6>&#13;
</div></figure>&#13;
&#13;
<p>Given that our credit card transactions dataset is highly imbalanced, using the confusion matrix would be meaningful. For example, if we predict that every transaction is not fraudulent, we would have 284,315 true negatives, 492 false negatives, zero true positives, and zero false positives. We would have a 0% accuracy in identifying the truly fraudulent transactions. The confusion matrix does a poor job of capturing this suboptimal outcome given this imbalanced class problem.</p>&#13;
&#13;
<p>For problems involving more balanced classes (i.e., the number of true positives is roughly similar to the number of true negatives), the confusion matrix may be a good, straightforward evaluation metric. We need to find a more appropriate evaluation metric given our imbalanced dataset.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Precision-Recall Curve" data-type="sect2"><div class="sect2" id="idm140637555935568">&#13;
<h2>Precision-Recall Curve</h2>&#13;
&#13;
<p>For<a data-primary="evaluation metrics" data-secondary="precision-recall curve" data-type="indexterm" id="EMprc02"/><a data-primary="precision-recall curve" data-type="indexterm" id="precrec02"/> our imbalanced credit card transactions dataset, a better way to evaluate the results is to use precision and recall. <em>Precision</em> is the number of true positives over the number of total positive predictions. In other words, how many of the fraudulent transactions does the model catch?</p>&#13;
<div data-type="equation">&#13;
<math>&#13;
<mi>Precision</mi>&#13;
<mo>=</mo>&#13;
<mi>True Positives</mi>&#13;
<mo>∕</mo>&#13;
<mo>(</mo><mi>True Positives</mi> <mo>+</mo> <mi>False Positives</mi><mo>)</mo>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>A high precision means that—of all our positive predictions—many are true positives (in other words, it has a low false positive rate).</p>&#13;
&#13;
<p><em>Recall</em> is the number of true positives over the number of total actual positives in the dataset. In other words how many of the fraudulent transactions does the model catch?<sup><a data-type="noteref" href="ch02.html#idm140637555924656" id="idm140637555924656-marker">7</a></sup></p>&#13;
<div data-type="equation">&#13;
<math>&#13;
<mi>Recall</mi>&#13;
<mo>=</mo>&#13;
<mi>True Positives</mi>&#13;
<mo>∕</mo>&#13;
<mo>(</mo><mi>True Positives</mi> <mo>+</mo> <mi>False Positives</mi><mo>)</mo>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>A high recall means that the model has captured most of the true positives (in other words, it has a low false negative rate).</p>&#13;
&#13;
<p>A solution with high recall but low precision returns many results—capturing many of the positives—but with many false alarms. A solution with high precision but low recall is the exact opposite; it returns few results—capturing a fraction of all the positives in the dataset—but most of its predictions are correct.</p>&#13;
&#13;
<p>To put this into context, if our solution had high precision but low recall, there would be a very small number of fraudulent transactions found but most would be truly fraudulent.</p>&#13;
&#13;
<p>However, if the solution had low precision but high recall it would flag many of the transactions as fraudulent, thus catching a lot of the fraud, but most of the flagged transactions would not be fraudulent.</p>&#13;
&#13;
<p>Obviously, both solutions have major problems. In the high precision–low recall case, the credit card company would lose a lot of money due to fraud, but it would not antagonize customers by unnecessarily rejecting transactions. In the low precision-high recall case, the credit card company would catch a lot of the fraud, but it would most certainly anger customers by unnecessarily rejecting a lot of normal, non-fraudulent transactions.</p>&#13;
&#13;
<p>An optimal solution needs to have high precision and high recall, rejecting only those transactions that are truly fraudulent (i.e., high precision) and catching most of the fraudulent cases in the dataset (high recall).</p>&#13;
&#13;
<p>There<a data-primary="threshold" data-type="indexterm" id="idm140637555914224"/> is generally a trade-off between precision and recall, which is usually determined by the threshold set by the algorithm to separate the positive cases from the negative cases; in our example, positive is fraud and negative is not fraud. If the threshold is set too high, very few cases are predicted as positive, resulting in high precision but low recall. As the threshold is lowered, more cases are predicted as positive, generally decreasing the precision and increasing the recall.</p>&#13;
&#13;
<p>For our credit card transactions dataset, think of the threshold as the sensitivity of the machine learning model in rejecting transactions. If the threshold is too high/strict, the model will reject few transactions, but the ones it does reject will be very likely to be fraudulent.</p>&#13;
&#13;
<p>As the threshold moves lower (i.e., becomes less strict), the model will reject more transactions, catching more of the fraudulent cases but also unnecessarily rejecting more of the normal cases as well.</p>&#13;
&#13;
<p>A graph of the trade-off between precision and recall is known as the precision-recall curve. To evaluate the precision-recall curve, we can calculate the average precision, which is the weighted mean of the precision achieved at each threshold. The higher the average precision, the better the solution.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The choice of the threshold is a very important one and usually involves the input of business decision makers. Data scientists can present the precision-recall curve to these business decision makers to figure out where the threshold should be.</p>&#13;
&#13;
<p>For our credit card transactions dataset, the key question is how do we balance customer experience (i.e., avoid rejecting normal transactions) with fraud detection (i.e., catch the fraudulent transactions)? We cannot answer this without business input, but we can find the model with the best precision-recall curve. Then, we can present this model to business decision makers to set the appropriate threshold.<a data-primary="" data-startref="precrec02" data-type="indexterm" id="idm140637555908688"/><a data-primary="" data-startref="EMprc02" data-type="indexterm" id="idm140637555907712"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Receiver Operating Characteristic" data-type="sect2"><div class="sect2" id="idm140637555934944">&#13;
<h2>Receiver Operating Characteristic</h2>&#13;
&#13;
<p>Another<a data-primary="receiver operating characteristic (ROC)" data-type="indexterm" id="roc02"/><a data-primary="evaluation metrics" data-secondary="receiver operating characteristic (ROC)" data-type="indexterm" id="EMroc02"/><a data-primary="area under the receiver operating characteristic (auROC)" data-type="indexterm" id="idm140637555903024"/> good evaluation metric is the area under the receiver operating characteristic (auROC). The receiver operating characteristic (ROC) curve plots the true positive rate on the Y axis and the false positive rate on the X axis. The true positive rate can also be referred to as the sensitivity, and the false positive rate can also be referred to as the 1-specificity. The closer the curve is to the top-left corner of the plot, the better the solution—with a value of (0.0, 1.0) as the absolute optimal point, signifying a 0% false positive rate and a 100% true positive rate.</p>&#13;
&#13;
<p>To evaluate the solution, we can compute the area under this curve. The larger the auROC, the better the solution.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Evaluating the logistic regression model" data-type="sect3"><div class="sect3" id="idm140637555901024">&#13;
<h3>Evaluating the logistic regression model</h3>&#13;
&#13;
<p>Now that we understand some of the evaluation metrics used, let’s use them to better understand the logistic regression model’s results.</p>&#13;
&#13;
<p>First, let’s plot the precision-recall curve and calculate the average precision:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">preds</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">y_train</code><code class="p">,</code><code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="mi">1</code><code class="p">]],</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">preds</code><code class="o">.</code><code class="n">columns</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'trueLabel'</code><code class="p">,</code><code class="s1">'prediction'</code><code class="p">]</code>&#13;
<code class="n">predictionsBasedOnKFoldsLogisticRegression</code> <code class="o">=</code> <code class="n">preds</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code>&#13;
&#13;
<code class="n">precision</code><code class="p">,</code> <code class="n">recall</code><code class="p">,</code> <code class="n">thresholds</code> <code class="o">=</code> <code class="n">precision_recall_curve</code><code class="p">(</code><code class="n">preds</code><code class="p">[</code><code class="s1">'trueLabel'</code><code class="p">],</code>&#13;
                                                       <code class="n">preds</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
&#13;
<code class="n">average_precision</code> <code class="o">=</code> <code class="n">average_precision_score</code><code class="p">(</code><code class="n">preds</code><code class="p">[</code><code class="s1">'trueLabel'</code><code class="p">],</code>&#13;
                                            <code class="n">preds</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">step</code><code class="p">(</code><code class="n">recall</code><code class="p">,</code> <code class="n">precision</code><code class="p">,</code> <code class="n">color</code><code class="o">=</code><code class="s1">'k'</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="mf">0.7</code><code class="p">,</code> <code class="n">where</code><code class="o">=</code><code class="s1">'post'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">fill_between</code><code class="p">(</code><code class="n">recall</code><code class="p">,</code> <code class="n">precision</code><code class="p">,</code> <code class="n">step</code><code class="o">=</code><code class="s1">'post'</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="mf">0.3</code><code class="p">,</code> <code class="n">color</code><code class="o">=</code><code class="s1">'k'</code><code class="p">)</code>&#13;
&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'Recall'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'Precision'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">ylim</code><code class="p">([</code><code class="mf">0.0</code><code class="p">,</code> <code class="mf">1.05</code><code class="p">])</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">xlim</code><code class="p">([</code><code class="mf">0.0</code><code class="p">,</code> <code class="mf">1.0</code><code class="p">])</code>&#13;
&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'Precision-Recall curve: Average Precision = {0:0.2f}'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code>&#13;
          <code class="n">average_precision</code><code class="p">))</code></pre>&#13;
&#13;
<p><a data-type="xref" href="#precision_recall_curve_of_logistic_regression">Figure 2-4</a> shows the plot of the precision-recall curve. Putting together what we discussed earlier, you can see that we can achieve approximately 80% recall (i.e., catch 80% of the fraudulent transactions) with approximately 70% precision (i.e., of the transactions the model flags as fraudulent, 70% are truly fraudulent while the remaining 30% were incorrectly flagged as fraudulent).</p>&#13;
&#13;
<figure><div class="figure" id="precision_recall_curve_of_logistic_regression">&#13;
<img alt="Precision-recall curve of logistic regression" src="assets/hulp_0204.png"/>&#13;
<h6><span class="label">Figure 2-4. </span>Precision-recall curve of logistic regression</h6>&#13;
</div></figure>&#13;
&#13;
<p>We can distill this precision-recall curve into a single number by calculating the average precision, which is 0.73 for this logistic regression model. We cannot yet tell whether this is good or bad average precision yet since we have no other models to compare our logistic regression against.</p>&#13;
&#13;
<p>Now, let’s measure the auROC:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="n">thresholds</code> <code class="o">=</code> <code class="n">roc_curve</code><code class="p">(</code><code class="n">preds</code><code class="p">[</code><code class="s1">'trueLabel'</code><code class="p">],</code><code class="n">preds</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
&#13;
<code class="n">areaUnderROC</code> <code class="o">=</code> <code class="n">auc</code><code class="p">(</code><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">)</code>&#13;
&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">()</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="n">color</code><code class="o">=</code><code class="s1">'r'</code><code class="p">,</code> <code class="n">lw</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s1">'ROC curve'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">([</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="n">color</code><code class="o">=</code><code class="s1">'k'</code><code class="p">,</code> <code class="n">lw</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">linestyle</code><code class="o">=</code><code class="s1">'--'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">xlim</code><code class="p">([</code><code class="mf">0.0</code><code class="p">,</code> <code class="mf">1.0</code><code class="p">])</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">ylim</code><code class="p">([</code><code class="mf">0.0</code><code class="p">,</code> <code class="mf">1.05</code><code class="p">])</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'False Positive Rate'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'True Positive Rate'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'Receiver operating characteristic:</code>&#13;
          <code class="n">Area</code> <code class="n">under</code> <code class="n">the</code> <code class="n">curve</code> <code class="o">=</code> <code class="p">{</code><code class="mi">0</code><code class="p">:</code><code class="mf">0.2</code><code class="n">f</code><code class="p">}</code><code class="s1">'.format(areaUnderROC))</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s2">"lower right"</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>&#13;
&#13;
<p>As shown in <a data-type="xref" href="#area_under_the_roc_curve_of_logistic_regression">Figure 2-5</a>, the auROC curve is 0.97. This metric is just another way to evaluate the goodness of the logistic regression model, allowing you to determine how much of the fraud you can catch while keeping the false positive rate as low as possible. As with the average precision, we do not know whether this auROC curve of 0.97 is good or not, but we will once we compare it with those of other models.<a data-primary="" data-startref="MLPevmet02" data-type="indexterm" id="idm140637555790352"/><a data-primary="" data-startref="EMroc02" data-type="indexterm" id="idm140637555789472"/><a data-primary="" data-startref="roc02" data-type="indexterm" id="idm140637555597504"/></p>&#13;
&#13;
<figure><div class="figure" id="area_under_the_roc_curve_of_logistic_regression">&#13;
<img alt="Area under the ROC curve of logistic regression" src="assets/hulp_0205.png"/>&#13;
<h6><span class="label">Figure 2-5. </span>auROC curve of logistic regression</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Machine Learning Models (Part II)" data-type="sect1"><div class="sect1" id="idm140637555594496">&#13;
<h1>Machine Learning Models (Part II)</h1>&#13;
&#13;
<p>To compare the goodness of the logistic regression model, let’s build a few more models using other supervised learning algorithms.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Model #2: Random Forests" data-type="sect2"><div class="sect2" id="idm140637555592688">&#13;
<h2>Model #2: Random Forests</h2>&#13;
&#13;
<p>Let’s<a data-primary="machine learning example project" data-secondary="random forests model" data-type="indexterm" id="MLPrand02"/><a data-primary="random forests" data-type="indexterm" id="random02"/><a data-primary="tree-based methods" data-secondary="random forests" data-type="indexterm" id="TBMran02"/> start with random forests.</p>&#13;
&#13;
<p>As with logistic regression, we will set the hyperparameters, train the model, and evaluate the results using the precision-recall curve and the auROC.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Set the hyperparameters" data-type="sect3"><div class="sect3" id="idm140637555586896">&#13;
<h3>Set the hyperparameters</h3>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">n_estimators</code> <code class="o">=</code> <code class="mi">10</code>&#13;
<code class="n">max_features</code> <code class="o">=</code> <code class="s1">'auto'</code>&#13;
<code class="n">max_depth</code> <code class="o">=</code> <code class="bp">None</code>&#13;
<code class="n">min_samples_split</code> <code class="o">=</code> <code class="mi">2</code>&#13;
<code class="n">min_samples_leaf</code> <code class="o">=</code> <code class="mi">1</code>&#13;
<code class="n">min_weight_fraction_leaf</code> <code class="o">=</code> <code class="mf">0.0</code>&#13;
<code class="n">max_leaf_nodes</code> <code class="o">=</code> <code class="bp">None</code>&#13;
<code class="n">bootstrap</code> <code class="o">=</code> <code class="bp">True</code>&#13;
<code class="n">oob_score</code> <code class="o">=</code> <code class="bp">False</code>&#13;
<code class="n">n_jobs</code> <code class="o">=</code> <code class="o">-</code><code class="mi">1</code>&#13;
<code class="n">random_state</code> <code class="o">=</code> <code class="mi">2018</code>&#13;
<code class="n">class_weight</code> <code class="o">=</code> <code class="s1">'balanced'</code>&#13;
&#13;
<code class="n">RFC</code> <code class="o">=</code> <code class="n">RandomForestClassifier</code><code class="p">(</code><code class="n">n_estimators</code><code class="o">=</code><code class="n">n_estimators</code><code class="p">,</code>&#13;
        <code class="n">max_features</code><code class="o">=</code><code class="n">max_features</code><code class="p">,</code> <code class="n">max_depth</code><code class="o">=</code><code class="n">max_depth</code><code class="p">,</code>&#13;
        <code class="n">min_samples_split</code><code class="o">=</code><code class="n">min_samples_split</code><code class="p">,</code> <code class="n">min_samples_leaf</code><code class="o">=</code><code class="n">min_samples_leaf</code><code class="p">,</code>&#13;
        <code class="n">min_weight_fraction_leaf</code><code class="o">=</code><code class="n">min_weight_fraction_leaf</code><code class="p">,</code>&#13;
        <code class="n">max_leaf_nodes</code><code class="o">=</code><code class="n">max_leaf_nodes</code><code class="p">,</code> <code class="n">bootstrap</code><code class="o">=</code><code class="n">bootstrap</code><code class="p">,</code>&#13;
        <code class="n">oob_score</code><code class="o">=</code><code class="n">oob_score</code><code class="p">,</code> <code class="n">n_jobs</code><code class="o">=</code><code class="n">n_jobs</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="n">random_state</code><code class="p">,</code>&#13;
        <code class="n">class_weight</code><code class="o">=</code><code class="n">class_weight</code><code class="p">)</code></pre>&#13;
&#13;
<p>Let’s start with the default hyperparameters. The number of estimators is set at 10; in other words, we will build 10 trees and average the results across these 10 trees. For each tree, the model will consider the square root of the total number of features (in this case, the square root of 30 total features, which is 5 features, rounded down).</p>&#13;
&#13;
<p>By setting the <code>max_depth</code> to none, the tree will grow as deep as possible, splitting as much as possible given the subset of features. Similar to what we did for logistic regression, we set the random state to 2018 for reproducibility of results and class weight to balanced given our imbalanced dataset.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Train the model" data-type="sect3"><div class="sect3" id="idm140637555195296">&#13;
<h3>Train the model</h3>&#13;
&#13;
<p>We will run <em>k</em>-fold cross-validation five times, training on four-fifths of the training data and predicting on the fifth slice. We will store the predictions as we go:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">trainingScores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">cvScores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">predictionsBasedOnKFolds</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code>&#13;
                                        <code class="n">index</code><code class="o">=</code><code class="n">y_train</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code><code class="mi">1</code><code class="p">])</code>&#13;
&#13;
<code class="n">model</code> <code class="o">=</code> <code class="n">RFC</code>&#13;
&#13;
<code class="k">for</code> <code class="n">train_index</code><code class="p">,</code> <code class="n">cv_index</code> <code class="ow">in</code> <code class="n">k_fold</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">X_train</code><code class="p">)),</code>&#13;
                                          <code class="n">y_train</code><code class="o">.</code><code class="n">ravel</code><code class="p">()):</code>&#13;
    <code class="n">X_train_fold</code><code class="p">,</code> <code class="n">X_cv_fold</code> <code class="o">=</code> <code class="n">X_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_index</code><code class="p">,:],</code> \&#13;
        <code class="n">X_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">cv_index</code><code class="p">,:]</code>&#13;
    <code class="n">y_train_fold</code><code class="p">,</code> <code class="n">y_cv_fold</code> <code class="o">=</code> <code class="n">y_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_index</code><code class="p">],</code> \&#13;
        <code class="n">y_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">cv_index</code><code class="p">]</code>&#13;
&#13;
    <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_fold</code><code class="p">,</code> <code class="n">y_train_fold</code><code class="p">)</code>&#13;
    <code class="n">loglossTraining</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_train_fold</code><code class="p">,</code> \&#13;
                                <code class="n">model</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">X_train_fold</code><code class="p">)[:,</code><code class="mi">1</code><code class="p">])</code>&#13;
    <code class="n">trainingScores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">loglossTraining</code><code class="p">)</code>&#13;
&#13;
    <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">X_cv_fold</code><code class="o">.</code><code class="n">index</code><code class="p">,:]</code> <code class="o">=</code> \&#13;
        <code class="n">model</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">X_cv_fold</code><code class="p">)</code>&#13;
    <code class="n">loglossCV</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_cv_fold</code><code class="p">,</code> \&#13;
        <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">X_cv_fold</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="mi">1</code><code class="p">])</code>&#13;
    <code class="n">cvScores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">loglossCV</code><code class="p">)</code>&#13;
&#13;
    <code class="k">print</code><code class="p">(</code><code class="s1">'Training Log Loss: '</code><code class="p">,</code> <code class="n">loglossTraining</code><code class="p">)</code>&#13;
    <code class="k">print</code><code class="p">(</code><code class="s1">'CV Log Loss: '</code><code class="p">,</code> <code class="n">loglossCV</code><code class="p">)</code>&#13;
&#13;
<code class="n">loglossRandomForestsClassifier</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_train</code><code class="p">,</code>&#13;
                                          <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="mi">1</code><code class="p">])</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="s1">'Random Forests Log Loss: '</code><code class="p">,</code> <code class="n">loglossRandomForestsClassifier</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Evaluate the results" data-type="sect3"><div class="sect3" id="idm140637555192144">&#13;
<h3>Evaluate the results</h3>&#13;
&#13;
<p>The training and cross-validation log loss results are as follows:</p>&#13;
&#13;
<pre data-type="programlisting">Training Log Loss: 		0.0003951763883952557&#13;
CV Log Loss:		0.014479198936303003&#13;
Training Log Loss: 		0.0004501221178398935&#13;
CV Log Loss:		0.005712702421375242&#13;
Training Log Loss: 		0.00043128813023860164&#13;
CV Log Loss:		0.00908372752510077&#13;
Training Log Loss: 		0.0004341676022058672&#13;
CV Log Loss:		0.013491161736979267&#13;
Training Log Loss: 		0.0004275530435950083&#13;
CV Log Loss:		0.009963232439211515</pre>&#13;
&#13;
<p>Notice that the training log losses are considerably lower than the cross-validation log losses, suggesting that the random forests classifier—with the mostly default hyperparameters—overfits the data during the training somewhat.</p>&#13;
&#13;
<p>The following code shows the log loss over the entire training set (using cross-validation predictions):</p>&#13;
&#13;
<pre data-type="programlisting">Random Forests Log Loss: 0.010546004611793962</pre>&#13;
&#13;
<p>Even though it overfits the training data somewhat, the random forests has a validation log loss that is about one-tenth that of the logistic regression—significant improvement over the previous machine learning solution. The random forests model is better at correctly flagging the fraud among credit card transactions.</p>&#13;
&#13;
<p><a data-type="xref" href="#precision_recall_curve_of_random_forests">Figure 2-6</a> shows the precision-recall curve of random forests. As you can see from the curve, the model can catch approximately 80% of all the fraud with approximately 80% precision. This is more impressive than the approximately 80% of all the fraud the logistic regression model caught with 70% precision.</p>&#13;
&#13;
<figure><div class="figure" id="precision_recall_curve_of_random_forests">&#13;
<img alt="Precision-recall curve of random forests" src="assets/hulp_0206.png"/>&#13;
<h6><span class="label">Figure 2-6. </span>Precision-recall curve of random fores"ts</h6>&#13;
</div></figure>&#13;
&#13;
<p>The average precision of 0.79 of the random forests model is a clear improvement over the 0.73 average precision of the logistic regression model. However, the auROC, shown in <a data-type="xref" href="#area_under_the_roc_curve_of_random_forests">Figure 2-7</a>, is somewhat worse—0.93 for random forests versus 0.97 for logistic regression.<a data-primary="" data-startref="TBMran02" data-type="indexterm" id="idm140637555082112"/><a data-primary="" data-startref="random02" data-type="indexterm" id="idm140637555081168"/><a data-primary="" data-startref="MLPrand02" data-type="indexterm" id="idm140637555080224"/></p>&#13;
&#13;
<figure><div class="figure" id="area_under_the_roc_curve_of_random_forests">&#13;
<img alt="Area under the ROC curve of random forests" src="assets/hulp_0207.png"/>&#13;
<h6><span class="label">Figure 2-7. </span>auROC curve of random forests</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Model #3: Gradient Boosting Machine (XGBoost)" data-type="sect2"><div class="sect2" id="idm140637555191632">&#13;
<h2>Model #3: Gradient Boosting Machine (XGBoost)</h2>&#13;
&#13;
<p>Now let’s train<a data-primary="gradient boosting machines (GBMs)" data-type="indexterm" id="gbm02"/><a data-primary="XGBoost" data-secondary="model creation and evaluation" data-type="indexterm" id="xgbmof02"/><a data-primary="machine learning example project" data-secondary="XGBoost model" data-type="indexterm" id="MLPxboost02"/> using gradient boosting and evaluate the results. There are two popular versions of gradient boosting—one known as XGBoost and another, much faster version by Microsoft called LightGBM. Let’s build a model using each one, starting with XGBoost.<sup><a data-type="noteref" href="ch02.html#idm140637555072000" id="idm140637555072000-marker">8</a></sup></p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Set the hyperparameters" data-type="sect3"><div class="sect3" id="idm140637555070576">&#13;
<h3>Set the hyperparameters</h3>&#13;
&#13;
<p>We will set this up as a binary classification problem and use log loss as the cost function. We will set the max depth of each tree to the default six and a default learning rate of 0.3. For each tree, we will use all the observations and all the features; these are the default settings. We will set a random state of 2018 to ensure the reproducibility of the results:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">params_xGB</code> <code class="o">=</code> <code class="p">{</code>&#13;
    <code class="s1">'nthread'</code><code class="p">:</code><code class="mi">16</code><code class="p">,</code> <code class="c1">#number of cores</code>&#13;
    <code class="s1">'learning rate'</code><code class="p">:</code> <code class="mf">0.3</code><code class="p">,</code> <code class="c1">#range 0 to 1, default 0.3</code>&#13;
    <code class="s1">'gamma'</code><code class="p">:</code> <code class="mi">0</code><code class="p">,</code> <code class="c1">#range 0 to infinity, default 0</code>&#13;
        <code class="c1"># increase to reduce complexity (increase bias, reduce variance)</code>&#13;
    <code class="s1">'max_depth'</code><code class="p">:</code> <code class="mi">6</code><code class="p">,</code> <code class="c1">#range 1 to infinity, default 6</code>&#13;
    <code class="s1">'min_child_weight'</code><code class="p">:</code> <code class="mi">1</code><code class="p">,</code> <code class="c1">#range 0 to infinity, default 1</code>&#13;
    <code class="s1">'max_delta_step'</code><code class="p">:</code> <code class="mi">0</code><code class="p">,</code> <code class="c1">#range 0 to infinity, default 0</code>&#13;
    <code class="s1">'subsample'</code><code class="p">:</code> <code class="mf">1.0</code><code class="p">,</code> <code class="c1">#range 0 to 1, default 1</code>&#13;
        <code class="c1"># subsample ratio of the training examples</code>&#13;
    <code class="s1">'colsample_bytree'</code><code class="p">:</code> <code class="mf">1.0</code><code class="p">,</code> <code class="c1">#range 0 to 1, default 1</code>&#13;
        <code class="c1"># subsample ratio of features</code>&#13;
    <code class="s1">'objective'</code><code class="p">:</code><code class="s1">'binary:logistic'</code><code class="p">,</code>&#13;
    <code class="s1">'num_class'</code><code class="p">:</code><code class="mi">1</code><code class="p">,</code>&#13;
    <code class="s1">'eval_metric'</code><code class="p">:</code><code class="s1">'logloss'</code><code class="p">,</code>&#13;
    <code class="s1">'seed'</code><code class="p">:</code><code class="mi">2018</code><code class="p">,</code>&#13;
    <code class="s1">'silent'</code><code class="p">:</code><code class="mi">1</code>&#13;
<code class="p">}</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Train the model" data-type="sect3"><div class="sect3" id="idm140637555067248">&#13;
<h3>Train the model</h3>&#13;
&#13;
<p>As before, we will use <em>k</em>-fold cross-validation, training on a different four-fifths of the training data and predicting on the fifth slice for a total of five runs.</p>&#13;
&#13;
<p>For each of the five runs, the gradient boosting model will train for as many as two thousand rounds, evaluating whether the cross-validation log loss is decreasing as it goes. If the cross-validation log loss stops improving (over the previous two hundred rounds), the training process will stop to avoid overfitting. The results of the training process are verbose, so we will not print them here, but they can be found via the <a href="http://bit.ly/2Gd4v7e">code on GitHub</a>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">trainingScores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">cvScores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">predictionsBasedOnKFolds</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code>&#13;
                                    <code class="n">index</code><code class="o">=</code><code class="n">y_train</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
&#13;
<code class="k">for</code> <code class="n">train_index</code><code class="p">,</code> <code class="n">cv_index</code> <code class="ow">in</code> <code class="n">k_fold</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">X_train</code><code class="p">)),</code>&#13;
                                          <code class="n">y_train</code><code class="o">.</code><code class="n">ravel</code><code class="p">()):</code>&#13;
    <code class="n">X_train_fold</code><code class="p">,</code> <code class="n">X_cv_fold</code> <code class="o">=</code> <code class="n">X_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_index</code><code class="p">,:],</code> \&#13;
        <code class="n">X_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">cv_index</code><code class="p">,:]</code>&#13;
    <code class="n">y_train_fold</code><code class="p">,</code> <code class="n">y_cv_fold</code> <code class="o">=</code> <code class="n">y_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_index</code><code class="p">],</code> \&#13;
        <code class="n">y_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">cv_index</code><code class="p">]</code>&#13;
&#13;
    <code class="n">dtrain</code> <code class="o">=</code> <code class="n">xgb</code><code class="o">.</code><code class="n">DMatrix</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">X_train_fold</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="n">y_train_fold</code><code class="p">)</code>&#13;
    <code class="n">dCV</code> <code class="o">=</code> <code class="n">xgb</code><code class="o">.</code><code class="n">DMatrix</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">X_cv_fold</code><code class="p">)</code>&#13;
&#13;
    <code class="n">bst</code> <code class="o">=</code> <code class="n">xgb</code><code class="o">.</code><code class="n">cv</code><code class="p">(</code><code class="n">params_xGB</code><code class="p">,</code> <code class="n">dtrain</code><code class="p">,</code> <code class="n">num_boost_round</code><code class="o">=</code><code class="mi">2000</code><code class="p">,</code>&#13;
                 <code class="n">nfold</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> <code class="n">early_stopping_rounds</code><code class="o">=</code><code class="mi">200</code><code class="p">,</code> <code class="n">verbose_eval</code><code class="o">=</code><code class="mi">50</code><code class="p">)</code>&#13;
&#13;
    <code class="n">best_rounds</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">argmin</code><code class="p">(</code><code class="n">bst</code><code class="p">[</code><code class="s1">'test-logloss-mean'</code><code class="p">])</code>&#13;
    <code class="n">bst</code> <code class="o">=</code> <code class="n">xgb</code><code class="o">.</code><code class="n">train</code><code class="p">(</code><code class="n">params_xGB</code><code class="p">,</code> <code class="n">dtrain</code><code class="p">,</code> <code class="n">best_rounds</code><code class="p">)</code>&#13;
&#13;
    <code class="n">loglossTraining</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_train_fold</code><code class="p">,</code> <code class="n">bst</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">dtrain</code><code class="p">))</code>&#13;
    <code class="n">trainingScores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">loglossTraining</code><code class="p">)</code>&#13;
&#13;
    <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">X_cv_fold</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="s1">'prediction'</code><code class="p">]</code> <code class="o">=</code> \&#13;
        <code class="n">bst</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">dCV</code><code class="p">)</code>&#13;
    <code class="n">loglossCV</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_cv_fold</code><code class="p">,</code> \&#13;
        <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">X_cv_fold</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
    <code class="n">cvScores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">loglossCV</code><code class="p">)</code>&#13;
&#13;
    <code class="k">print</code><code class="p">(</code><code class="s1">'Training Log Loss: '</code><code class="p">,</code> <code class="n">loglossTraining</code><code class="p">)</code>&#13;
    <code class="k">print</code><code class="p">(</code><code class="s1">'CV Log Loss: '</code><code class="p">,</code> <code class="n">loglossCV</code><code class="p">)</code>&#13;
&#13;
<code class="n">loglossXGBoostGradientBoosting</code> <code class="o">=</code> \&#13;
    <code class="n">log_loss</code><code class="p">(</code><code class="n">y_train</code><code class="p">,</code> <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="s1">'XGBoost Gradient Boosting Log Loss: '</code><code class="p">,</code> <code class="n">loglossXGBoostGradientBoosting</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Evaluate the results" data-type="sect3"><div class="sect3" id="idm140637555029088">&#13;
<h3>Evaluate the results</h3>&#13;
&#13;
<p>As shown in the following results, the log loss over the entire training set (using the cross-validation predictions) is one-fifth that of the random forests and one-fiftieth that of logistic regression. This is a substantial improvement over the previous two models:</p>&#13;
&#13;
<pre data-type="programlisting">XGBoost Gradient Boosting Log Loss: 0.0029566906288156715</pre>&#13;
&#13;
<p>As shown in <a data-type="xref" href="#precision_recall_curve_of_xgboost_gradient_boosting">Figure 2-8</a>, the average precision is 0.82, just shy of that of random forests (0.79) and considerably better than that of logistic regression (0.73).</p>&#13;
&#13;
<figure><div class="figure" id="precision_recall_curve_of_xgboost_gradient_boosting">&#13;
<img alt="Precision-recall curve of XGBoost Gradient Boosting" src="assets/hulp_0208.png"/>&#13;
<h6><span class="label">Figure 2-8. </span>Precision-recall curve of XGBoost gradient boosting</h6>&#13;
</div></figure>&#13;
&#13;
<p>As shown in <a data-type="xref" href="#area_under_the_roc_curve_of_xgboost_gradient_boosting">Figure 2-9</a>, the auROC curve is 0.97, the same as that of logistic regression (0.97) and an improvement over random forests (0.93). So far, gradient boosting is the best of the three models based on the log loss, the precision-recall curve, and the auROC.<a data-primary="" data-startref="MLPxboost02" data-type="indexterm" id="idm140637554691488"/><a data-primary="" data-startref="xgbmof02" data-type="indexterm" id="idm140637554690544"/></p>&#13;
&#13;
<figure><div class="figure" id="area_under_the_roc_curve_of_xgboost_gradient_boosting">&#13;
<img alt="Area under the ROC curve of XGBoost Gradient Boosting" src="assets/hulp_0209.png"/>&#13;
<h6><span class="label">Figure 2-9. </span>auROC curve of XGBoost gradient boosting</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Model #4: Gradient Boosting Machine (LightGBM)" data-type="sect2"><div class="sect2" id="idm140637554687472">&#13;
<h2>Model #4: Gradient Boosting Machine (LightGBM)</h2>&#13;
&#13;
<p>Let’s<a data-primary="machine learning example project" data-secondary="LightGBM model" data-type="indexterm" id="MLPlight02"/><a data-primary="LightGBM" data-secondary="model creation and evaluation" data-type="indexterm" id="lightG02"/> now train using another version of gradient boosting known as LightGBM.<sup><a data-type="noteref" href="ch02.html#idm140637554683376" id="idm140637554683376-marker">9</a></sup></p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Set the hyperparameters" data-type="sect3"><div class="sect3" id="idm140637554682016">&#13;
<h3>Set the hyperparameters</h3>&#13;
&#13;
<p>We will set this up as a binary classification problem and use log loss as the cost function. We will set the max depth of each tree to 4 and use a learning rate of 0.1. For each tree, we will use all the samples and all the features; these are the default settings. We will use the default number of leaves for one tree (31) and set a random state to ensure reproducibility of the results:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">params_lightGB</code> <code class="o">=</code> <code class="p">{</code>&#13;
    <code class="s1">'task'</code><code class="p">:</code> <code class="s1">'train'</code><code class="p">,</code>&#13;
    <code class="s1">'application'</code><code class="p">:</code><code class="s1">'binary'</code><code class="p">,</code>&#13;
    <code class="s1">'num_class'</code><code class="p">:</code><code class="mi">1</code><code class="p">,</code>&#13;
    <code class="s1">'boosting'</code><code class="p">:</code> <code class="s1">'gbdt'</code><code class="p">,</code>&#13;
    <code class="s1">'objective'</code><code class="p">:</code> <code class="s1">'binary'</code><code class="p">,</code>&#13;
    <code class="s1">'metric'</code><code class="p">:</code> <code class="s1">'binary_logloss'</code><code class="p">,</code>&#13;
    <code class="s1">'metric_freq'</code><code class="p">:</code><code class="mi">50</code><code class="p">,</code>&#13;
    <code class="s1">'is_training_metric'</code><code class="p">:</code><code class="bp">False</code><code class="p">,</code>&#13;
    <code class="s1">'max_depth'</code><code class="p">:</code><code class="mi">4</code><code class="p">,</code>&#13;
    <code class="s1">'num_leaves'</code><code class="p">:</code> <code class="mi">31</code><code class="p">,</code>&#13;
    <code class="s1">'learning_rate'</code><code class="p">:</code> <code class="mf">0.01</code><code class="p">,</code>&#13;
    <code class="s1">'feature_fraction'</code><code class="p">:</code> <code class="mf">1.0</code><code class="p">,</code>&#13;
    <code class="s1">'bagging_fraction'</code><code class="p">:</code> <code class="mf">1.0</code><code class="p">,</code>&#13;
    <code class="s1">'bagging_freq'</code><code class="p">:</code> <code class="mi">0</code><code class="p">,</code>&#13;
    <code class="s1">'bagging_seed'</code><code class="p">:</code> <code class="mi">2018</code><code class="p">,</code>&#13;
    <code class="s1">'verbose'</code><code class="p">:</code> <code class="mi">0</code><code class="p">,</code>&#13;
    <code class="s1">'num_threads'</code><code class="p">:</code><code class="mi">16</code>&#13;
<code class="p">}</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Train the model" data-type="sect3"><div class="sect3" id="idm140637554678368">&#13;
<h3>Train the model</h3>&#13;
&#13;
<p>As before, we will use <em>k</em>-fold cross-validation and cycle through this five times, storing the predictions on the validation sets as we go:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">trainingScores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">cvScores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">predictionsBasedOnKFolds</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code>&#13;
                                <code class="n">index</code><code class="o">=</code><code class="n">y_train</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
&#13;
<code class="k">for</code> <code class="n">train_index</code><code class="p">,</code> <code class="n">cv_index</code> <code class="ow">in</code> <code class="n">k_fold</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">X_train</code><code class="p">)),</code>&#13;
                                          <code class="n">y_train</code><code class="o">.</code><code class="n">ravel</code><code class="p">()):</code>&#13;
    <code class="n">X_train_fold</code><code class="p">,</code> <code class="n">X_cv_fold</code> <code class="o">=</code> <code class="n">X_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_index</code><code class="p">,:],</code> \&#13;
        <code class="n">X_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">cv_index</code><code class="p">,:]</code>&#13;
    <code class="n">y_train_fold</code><code class="p">,</code> <code class="n">y_cv_fold</code> <code class="o">=</code> <code class="n">y_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_index</code><code class="p">],</code> \&#13;
        <code class="n">y_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">cv_index</code><code class="p">]</code>&#13;
&#13;
    <code class="n">lgb_train</code> <code class="o">=</code> <code class="n">lgb</code><code class="o">.</code><code class="n">Dataset</code><code class="p">(</code><code class="n">X_train_fold</code><code class="p">,</code> <code class="n">y_train_fold</code><code class="p">)</code>&#13;
    <code class="n">lgb_eval</code> <code class="o">=</code> <code class="n">lgb</code><code class="o">.</code><code class="n">Dataset</code><code class="p">(</code><code class="n">X_cv_fold</code><code class="p">,</code> <code class="n">y_cv_fold</code><code class="p">,</code> <code class="n">reference</code><code class="o">=</code><code class="n">lgb_train</code><code class="p">)</code>&#13;
    <code class="n">gbm</code> <code class="o">=</code> <code class="n">lgb</code><code class="o">.</code><code class="n">train</code><code class="p">(</code><code class="n">params_lightGB</code><code class="p">,</code> <code class="n">lgb_train</code><code class="p">,</code> <code class="n">num_boost_round</code><code class="o">=</code><code class="mi">2000</code><code class="p">,</code>&#13;
                   <code class="n">valid_sets</code><code class="o">=</code><code class="n">lgb_eval</code><code class="p">,</code> <code class="n">early_stopping_rounds</code><code class="o">=</code><code class="mi">200</code><code class="p">)</code>&#13;
&#13;
    <code class="n">loglossTraining</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_train_fold</code><code class="p">,</code> \&#13;
                <code class="n">gbm</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_train_fold</code><code class="p">,</code> <code class="n">num_iteration</code><code class="o">=</code><code class="n">gbm</code><code class="o">.</code><code class="n">best_iteration</code><code class="p">))</code>&#13;
    <code class="n">trainingScores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">loglossTraining</code><code class="p">)</code>&#13;
&#13;
    <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">X_cv_fold</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="s1">'prediction'</code><code class="p">]</code> <code class="o">=</code> \&#13;
        <code class="n">gbm</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_cv_fold</code><code class="p">,</code> <code class="n">num_iteration</code><code class="o">=</code><code class="n">gbm</code><code class="o">.</code><code class="n">best_iteration</code><code class="p">)</code>&#13;
    <code class="n">loglossCV</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_cv_fold</code><code class="p">,</code> \&#13;
        <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">X_cv_fold</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
    <code class="n">cvScores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">loglossCV</code><code class="p">)</code>&#13;
&#13;
    <code class="k">print</code><code class="p">(</code><code class="s1">'Training Log Loss: '</code><code class="p">,</code> <code class="n">loglossTraining</code><code class="p">)</code>&#13;
    <code class="k">print</code><code class="p">(</code><code class="s1">'CV Log Loss: '</code><code class="p">,</code> <code class="n">loglossCV</code><code class="p">)</code>&#13;
&#13;
<code class="n">loglossLightGBMGradientBoosting</code> <code class="o">=</code> \&#13;
    <code class="n">log_loss</code><code class="p">(</code><code class="n">y_train</code><code class="p">,</code> <code class="n">predictionsBasedOnKFolds</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="s1">'LightGBM gradient boosting Log Loss: '</code><code class="p">,</code> <code class="n">loglossLightGBMGradientBoosting</code><code class="p">)</code></pre>&#13;
&#13;
<p>For each of the five runs, the gradient boosting model will train for as many as two thousand rounds, evaluating whether the cross-validation log loss is decreasing as it goes. If the cross-validation log loss stops improving (over the previous two hundred rounds), the training process will stop to avoid overfitting. The results of the training process are verbose, so we will not print them here, but they can be found via the <a href="http://bit.ly/2Gd4v7e">code on GitHub</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Evaluate the results" data-type="sect3"><div class="sect3" id="idm140637554604976">&#13;
<h3>Evaluate the results</h3>&#13;
&#13;
<p>The following results show that the log loss over the entire training set (using the cross-validation predictions) is similar to that of XGBoost, one-fifth that of the random forests and one-fiftieth that of logistic regression. But compared to XGBoost, LightGBM is considerably faster:</p>&#13;
&#13;
<pre data-type="programlisting">LightGBM Gradient Boosting Log Loss: 0.0029732268054261826</pre>&#13;
&#13;
<p>As shown in <a data-type="xref" href="#precision_recall_curve_of_lightgbm_gradient_boosting">Figure 2-10</a>, the average precision is 0.82, the same as that of XGboost (0.82), better than that of random forests (0.79), and considerably better than that of logistic regression (0.73).</p>&#13;
&#13;
<figure><div class="figure" id="precision_recall_curve_of_lightgbm_gradient_boosting">&#13;
<img alt="Precision-recall curve of LightGBM gadient boosting" src="assets/hulp_0210.png"/>&#13;
<h6><span class="label">Figure 2-10. </span>Precision-recall curve of LightGBM gradient boosting</h6>&#13;
</div></figure>&#13;
&#13;
<p>As shown in <a data-type="xref" href="#area_under_the_roc_curve_of_lightgbm_gradient_boosting">Figure 2-11</a>, the auROC curve is 0.98, an improvement over that of XGBoost (0.97), logistic regression (0.97), and random forests (0.93).<a data-primary="" data-startref="gbm02" data-type="indexterm" id="idm140637554248544"/><a data-primary="" data-startref="lightG02" data-type="indexterm" id="idm140637554247600"/><a data-primary="" data-startref="MLPlight02" data-type="indexterm" id="idm140637554246656"/></p>&#13;
&#13;
<figure><div class="figure" id="area_under_the_roc_curve_of_lightgbm_gradient_boosting">&#13;
<img alt="Area under the ROC curve of LightGBM gradient boosting" src="assets/hulp_0211.png"/>&#13;
<h6><span class="label">Figure 2-11. </span>auROC curve of LightGBM gradient boosting</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Evaluation of the Four Models Using the Test Set" data-type="sect1"><div class="sect1" id="idm140637554243584">&#13;
<h1>Evaluation of the Four Models Using the Test Set</h1>&#13;
&#13;
<p>So<a data-primary="machine learning example project" data-secondary="model evaluation" data-type="indexterm" id="MLPeval02"/><a data-primary="model evaluation" data-type="indexterm" id="modeleval02"/> far in this chapter, we have learned how to:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Set up the environment for machine learning projects</p>&#13;
</li>&#13;
<li>&#13;
<p>Acquire, load, explore, clean, and visualize data</p>&#13;
</li>&#13;
<li>&#13;
<p>Split the dataset into training and test sets and set up <em>k</em>-fold cross-validation sets</p>&#13;
</li>&#13;
<li>&#13;
<p>Choose the appropriate cost function</p>&#13;
</li>&#13;
<li>&#13;
<p>Set the hyperparameters and perform training and cross-validation</p>&#13;
</li>&#13;
<li>&#13;
<p>Evaluate the results</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>We have not explored how to adjust the hyperparameters (a process known as hyperparameter fine-tuning) to improve the results of each machine learning solution and address underfitting/overfitting, but the <a href="http://bit.ly/2Gd4v7e">code on GitHub</a> will allow you to conduct these experiments very easily.</p>&#13;
&#13;
<p>Even without such fine-tuning, the results are pretty clear. Based on our training and <em>k</em>-fold cross-validation, LightGBM gradient boosting is the best solution, closely followed by XGBoost. Random forests and logistic regression are worse.</p>&#13;
&#13;
<p>Let’s use the test set as a final evaluation of each of the four models.</p>&#13;
&#13;
<p>For each model, we will use the trained model to predict the fraud probabilities for the test set transactions. Then, we will calculate the log loss for each model by comparing the fraud probabilities predicted by the model against the true fraud labels:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">predictionsTestSetLogisticRegression</code> <code class="o">=</code> \&#13;
    <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code><code class="n">index</code><code class="o">=</code><code class="n">y_test</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
<code class="n">predictionsTestSetLogisticRegression</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="s1">'prediction'</code><code class="p">]</code> <code class="o">=</code> \&#13;
    <code class="n">logReg</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">X_test</code><code class="p">)[:,</code><code class="mi">1</code><code class="p">]</code>&#13;
<code class="n">logLossTestSetLogisticRegression</code> <code class="o">=</code> \&#13;
    <code class="n">log_loss</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code> <code class="n">predictionsTestSetLogisticRegression</code><code class="p">)</code>&#13;
&#13;
<code class="n">predictionsTestSetRandomForests</code> <code class="o">=</code> \&#13;
    <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code><code class="n">index</code><code class="o">=</code><code class="n">y_test</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
<code class="n">predictionsTestSetRandomForests</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="s1">'prediction'</code><code class="p">]</code> <code class="o">=</code> \&#13;
    <code class="n">RFC</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">X_test</code><code class="p">)[:,</code><code class="mi">1</code><code class="p">]</code>&#13;
<code class="n">logLossTestSetRandomForests</code> <code class="o">=</code> \&#13;
    <code class="n">log_loss</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code> <code class="n">predictionsTestSetRandomForests</code><code class="p">)</code>&#13;
&#13;
<code class="n">predictionsTestSetXGBoostGradientBoosting</code> <code class="o">=</code> \&#13;
    <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code><code class="n">index</code><code class="o">=</code><code class="n">y_test</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
<code class="n">dtest</code> <code class="o">=</code> <code class="n">xgb</code><code class="o">.</code><code class="n">DMatrix</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">X_test</code><code class="p">)</code>&#13;
<code class="n">predictionsTestSetXGBoostGradientBoosting</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="s1">'prediction'</code><code class="p">]</code> <code class="o">=</code> \&#13;
    <code class="n">bst</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">dtest</code><code class="p">)</code>&#13;
<code class="n">logLossTestSetXGBoostGradientBoosting</code> <code class="o">=</code> \&#13;
    <code class="n">log_loss</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code> <code class="n">predictionsTestSetXGBoostGradientBoosting</code><code class="p">)</code>&#13;
&#13;
<code class="n">predictionsTestSetLightGBMGradientBoosting</code> <code class="o">=</code> \&#13;
    <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code><code class="n">index</code><code class="o">=</code><code class="n">y_test</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
<code class="n">predictionsTestSetLightGBMGradientBoosting</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="s1">'prediction'</code><code class="p">]</code> <code class="o">=</code> \&#13;
    <code class="n">gbm</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test</code><code class="p">,</code> <code class="n">num_iteration</code><code class="o">=</code><code class="n">gbm</code><code class="o">.</code><code class="n">best_iteration</code><code class="p">)</code>&#13;
<code class="n">logLossTestSetLightGBMGradientBoosting</code> <code class="o">=</code> \&#13;
    <code class="n">log_loss</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code> <code class="n">predictionsTestSetLightGBMGradientBoosting</code><code class="p">)</code></pre>&#13;
&#13;
<p>There are no surprises in the following log loss block. LightGBM gradient boosting has the lowest log loss on the test set, followed by the rest.</p>&#13;
&#13;
<pre data-type="programlisting">Log Loss of Logistic Regression on Test Set: 0.123732961313&#13;
Log Loss of Random Forests on Test Set: 0.00918192757674&#13;
Log Loss of XGBoost Gradient Boosting on Test Set: 0.00249116807943&#13;
Log Loss of LightGBM Gradient Boosting on Test Set: 0.002376320092424</pre>&#13;
&#13;
<p>Figures <a data-type="xref" data-xrefstyle="select:labelnumber" href="#test_set_precision_recall_curve_of_logistic_regression">2-12</a> through <a data-type="xref" data-xrefstyle="select:labelnumber" href="#test_set_area_under_the_roc_curve_of_lightgbm_gradient_boosting">2-19</a> are the precision-recall curves, average precisions, and auROC curve for all four models, corroborating our findings above.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Logistic regression" data-type="sect3"><div class="sect3" id="idm140637554083376">&#13;
<h3>Logistic regression</h3>&#13;
&#13;
<figure><div class="figure" id="test_set_precision_recall_curve_of_logistic_regression">&#13;
<img alt="Test set precision-recall curve of logistic regression" src="assets/hulp_0212.png"/>&#13;
<h6><span class="label">Figure 2-12. </span>Test set precision-recall curve of logistic regression</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="test_set_area_under_the_roc_curve_of_logistic_regression">&#13;
<img alt="Test set area under the ROC curve of logistic regression" src="assets/hulp_0213.png"/>&#13;
<h6><span class="label">Figure 2-13. </span>Test set auROC curve of logistic regression</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Random forests" data-type="sect3"><div class="sect3" id="idm140637554078176">&#13;
<h3>Random forests</h3>&#13;
&#13;
<figure><div class="figure">&#13;
<img alt="Test set precision-recall curve of random forests" src="assets/hulp_0214.png"/>&#13;
<h6><span class="label">Figure 2-14. </span>Test set precision-recall curve of random forests</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure">&#13;
<img alt="Test set area under the ROC curve of random forests" src="assets/hulp_0215.png"/>&#13;
<h6><span class="label">Figure 2-15. </span>Test set auROC curve of logistic regression</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="XGBoost gradient boosting" data-type="sect3"><div class="sect3" id="idm140637554073424">&#13;
<h3>XGBoost gradient boosting</h3>&#13;
&#13;
<figure><div class="figure">&#13;
<img alt="Test set precision-recall curve of XGBoost gradient boosting" src="assets/hulp_0216.png"/>&#13;
<h6><span class="label">Figure 2-16. </span>Test set precision-recall curve of XGBoost gradient boosting</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure">&#13;
<img alt="Test set area under the ROC curve of XGBoost gradient boosting" src="assets/hulp_0217.png"/>&#13;
<h6><span class="label">Figure 2-17. </span>Test set auROC curve of XGBoost gradient boosting</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="LightGBM gradient boosting" data-type="sect3"><div class="sect3" id="idm140637554068896">&#13;
<h3>LightGBM gradient boosting</h3>&#13;
&#13;
<figure><div class="figure">&#13;
<img alt="Test set precision-recall curve of LightGBM gradient boosting" src="assets/hulp_0218.png"/>&#13;
<h6><span class="label">Figure 2-18. </span>Test set precision-recall curve of LightGBM gradient boosting</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="test_set_area_under_the_roc_curve_of_lightgbm_gradient_boosting">&#13;
<img alt="Test set area under the ROC curve of LightGBM gradient boosting" src="assets/hulp_0219.png"/>&#13;
<h6><span class="label">Figure 2-19. </span>Test set auROC curve of LightGBM gradient boosting</h6>&#13;
</div></figure>&#13;
&#13;
<p>The results of LightGBM gradient boosting are impressive—we can catch over 80% of the fraudulent transactions with nearly 90% precision (in other words, in catching 80% of the total fraud the LightGBM model gets only 10% of the cases wrong).</p>&#13;
&#13;
<p>Considering how few cases of fraud our dataset has, this is a great accomplishment.<a data-primary="" data-startref="modeleval02" data-type="indexterm" id="idm140637554062752"/><a data-primary="" data-startref="MLPeval02" data-type="indexterm" id="idm140637554061776"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Ensembles" data-type="sect1"><div class="sect1" id="ensembles">&#13;
<h1>Ensembles</h1>&#13;
&#13;
<p>Instead<a data-primary="machine learning example project" data-secondary="ensembles" data-type="indexterm" id="MLPensem02"/> of picking just one of the machine learning solutions we have developed for use in production, we can evaluate whether an ensemble of the models leads to an improved fraud detection rate.<sup><a data-type="noteref" href="ch02.html#idm140637554057392" id="idm140637554057392-marker">10</a></sup></p>&#13;
&#13;
<p>Generally, if we include similarly strong solutions from different machine learning families (such as one from random forests and one from neural networks), the ensemble of the solutions will lead to a better result than any of the standalone solutions. This is because each of the standalone solutions has different strengths and weaknesses. By including the standalone solutions together in an ensemble, the strengths of some of the models compensate for the weaknesses of the others, and vice versa.</p>&#13;
&#13;
<p>There are important caveats, though. If the standalone solutions are similarly strong, the ensemble will have better performance than any of the standalone solutions. But if one of the solutions is much better than the others, the ensemble’s performance will equal the performance of the best standalone solution; the subpar solutions will contribute nothing to the ensemble’s performance.</p>&#13;
&#13;
<p>Also, the standalone solutions need to be relatively uncorrelated. If they are very correlated, the strengths of one will mirror those of the rest, and the same will be true with the weaknesses. We will see little benefit from diversifying via an ensemble.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Stacking" data-type="sect2"><div class="sect2" id="idm140637554052096">&#13;
<h2>Stacking</h2>&#13;
&#13;
<p>In<a data-primary="stacking" data-type="indexterm" id="idm140637554050528"/> our problem here, two of the models (LightGBM gradient boosting and XGBoost gradient boosting) are much stronger than the others (random forests and logistic regression). But the two strongest models are from the same family, which means their strengths and weaknesses will be highly correlated.</p>&#13;
&#13;
<p>We<a data-primary="layer one predictions" data-type="indexterm" id="idm140637554048960"/> can use stacking (which is a form of ensembling) to determine whether we can get an improvement in performance compared to the standalone models from earlier. In stacking, we take the predictions from the <em>k</em>-fold cross-validation from each of the four standalone models (known as <em>layer one predictions</em>) and append them to the original training dataset. We then train on this original features plus layer one predictions dataset using <em>k</em>-fold cross-validation.</p>&#13;
&#13;
<p>This will result in a new set of <em>k</em>-fold cross-validation predictions, known as layer two predictions, which we will evaluate to see if we have an improvement in performance over any of the standalone models.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Combine layer one predictions with the original training dataset" data-type="sect3"><div class="sect3" id="idm140637554045280">&#13;
<h3>Combine layer one predictions with the original training dataset</h3>&#13;
&#13;
<p>First, let’s combine the predictions from each of the four machine learning models that we have built with the original training dataset:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">predictionsBasedOnKFoldsFourModels</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code><code class="n">index</code><code class="o">=</code><code class="n">y_train</code><code class="o">.</code><code class="n">index</code><code class="p">)</code>&#13;
<code class="n">predictionsBasedOnKFoldsFourModels</code> <code class="o">=</code> <code class="n">predictionsBasedOnKFoldsFourModels</code><code class="o">.</code><code class="n">join</code><code class="p">(</code>&#13;
    <code class="n">predictionsBasedOnKFoldsLogisticRegression</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">]</code><code class="o">.</code><code class="n">astype</code><code class="p">(</code><code class="nb">float</code><code class="p">),</code> \&#13;
    <code class="n">how</code><code class="o">=</code><code class="s1">'left'</code><code class="p">)</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">predictionsBasedOnKFoldsRandomForests</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">]</code> \&#13;
	<code class="o">.</code><code class="n">astype</code><code class="p">(</code><code class="nb">float</code><code class="p">),</code><code class="n">how</code><code class="o">=</code><code class="s1">'left'</code><code class="p">,</code><code class="n">rsuffix</code><code class="o">=</code><code class="s2">"2"</code><code class="p">)</code><code class="o">.</code><code class="n">join</code><code class="p">(</code> \&#13;
    <code class="n">predictionsBasedOnKFoldsXGBoostGradientBoosting</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">]</code> \&#13;
	<code class="o">.</code><code class="n">astype</code><code class="p">(</code><code class="nb">float</code><code class="p">),</code> <code class="n">how</code><code class="o">=</code><code class="s1">'left'</code><code class="p">,</code><code class="n">rsuffix</code><code class="o">=</code><code class="s2">"3"</code><code class="p">)</code><code class="o">.</code><code class="n">join</code><code class="p">(</code> \&#13;
    <code class="n">predictionsBasedOnKFoldsLightGBMGradientBoosting</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">]</code> \&#13;
	<code class="o">.</code><code class="n">astype</code><code class="p">(</code><code class="nb">float</code><code class="p">),</code> <code class="n">how</code><code class="o">=</code><code class="s1">'left'</code><code class="p">,</code><code class="n">rsuffix</code><code class="o">=</code><code class="s2">"4"</code><code class="p">)</code>&#13;
<code class="n">predictionsBasedOnKFoldsFourModels</code><code class="o">.</code><code class="n">columns</code> <code class="o">=</code> \&#13;
    <code class="p">[</code><code class="s1">'predsLR'</code><code class="p">,</code><code class="s1">'predsRF'</code><code class="p">,</code><code class="s1">'predsXGB'</code><code class="p">,</code><code class="s1">'predsLightGBM'</code><code class="p">]</code>&#13;
&#13;
<code class="n">X_trainWithPredictions</code> <code class="o">=</code> \&#13;
    <code class="n">X_train</code><code class="o">.</code><code class="n">merge</code><code class="p">(</code><code class="n">predictionsBasedOnKFoldsFourModels</code><code class="p">,</code>&#13;
                  <code class="n">left_index</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code class="n">right_index</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Set the hyperparameters" data-type="sect3"><div class="sect3" id="idm140637554041056">&#13;
<h3>Set the hyperparameters</h3>&#13;
&#13;
<p>Now we will use LightGBM gradient boosting—the best machine learning algorithm from the earlier exercise—to train on this original features plus layer one predictions dataset. The hyperparameters will remain the same as before:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">params_lightGB</code> <code class="o">=</code> <code class="p">{</code>&#13;
    <code class="s1">'task'</code><code class="p">:</code> <code class="s1">'train'</code><code class="p">,</code>&#13;
    <code class="s1">'application'</code><code class="p">:</code><code class="s1">'binary'</code><code class="p">,</code>&#13;
    <code class="s1">'num_class'</code><code class="p">:</code><code class="mi">1</code><code class="p">,</code>&#13;
    <code class="s1">'boosting'</code><code class="p">:</code> <code class="s1">'gbdt'</code><code class="p">,</code>&#13;
    <code class="s1">'objective'</code><code class="p">:</code> <code class="s1">'binary'</code><code class="p">,</code>&#13;
    <code class="s1">'metric'</code><code class="p">:</code> <code class="s1">'binary_logloss'</code><code class="p">,</code>&#13;
    <code class="s1">'metric_freq'</code><code class="p">:</code><code class="mi">50</code><code class="p">,</code>&#13;
    <code class="s1">'is_training_metric'</code><code class="p">:</code><code class="bp">False</code><code class="p">,</code>&#13;
    <code class="s1">'max_depth'</code><code class="p">:</code><code class="mi">4</code><code class="p">,</code>&#13;
    <code class="s1">'num_leaves'</code><code class="p">:</code> <code class="mi">31</code><code class="p">,</code>&#13;
    <code class="s1">'learning_rate'</code><code class="p">:</code> <code class="mf">0.01</code><code class="p">,</code>&#13;
    <code class="s1">'feature_fraction'</code><code class="p">:</code> <code class="mf">1.0</code><code class="p">,</code>&#13;
    <code class="s1">'bagging_fraction'</code><code class="p">:</code> <code class="mf">1.0</code><code class="p">,</code>&#13;
    <code class="s1">'bagging_freq'</code><code class="p">:</code> <code class="mi">0</code><code class="p">,</code>&#13;
    <code class="s1">'bagging_seed'</code><code class="p">:</code> <code class="mi">2018</code><code class="p">,</code>&#13;
    <code class="s1">'verbose'</code><code class="p">:</code> <code class="mi">0</code><code class="p">,</code>&#13;
    <code class="s1">'num_threads'</code><code class="p">:</code><code class="mi">16</code>&#13;
<code class="p">}</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Train the model" data-type="sect3"><div class="sect3" id="idm140637553815120">&#13;
<h3>Train the model</h3>&#13;
&#13;
<p>As before, we will use <em>k</em>-fold cross-validation and generate fraud probabilities for the five different cross-validation sets:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">trainingScores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">cvScores</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">predictionsBasedOnKFoldsEnsemble</code> <code class="o">=</code> \&#13;
    <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code><code class="n">index</code><code class="o">=</code><code class="n">y_train</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
&#13;
<code class="k">for</code> <code class="n">train_index</code><code class="p">,</code> <code class="n">cv_index</code> <code class="ow">in</code> <code class="n">k_fold</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">X_train</code><code class="p">)),</code> \&#13;
                                          <code class="n">y_train</code><code class="o">.</code><code class="n">ravel</code><code class="p">()):</code>&#13;
    <code class="n">X_train_fold</code><code class="p">,</code> <code class="n">X_cv_fold</code> <code class="o">=</code> \&#13;
        <code class="n">X_trainWithPredictions</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_index</code><code class="p">,:],</code> \&#13;
        <code class="n">X_trainWithPredictions</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">cv_index</code><code class="p">,:]</code>&#13;
    <code class="n">y_train_fold</code><code class="p">,</code> <code class="n">y_cv_fold</code> <code class="o">=</code> <code class="n">y_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_index</code><code class="p">],</code> <code class="n">y_train</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">cv_index</code><code class="p">]</code>&#13;
&#13;
    <code class="n">lgb_train</code> <code class="o">=</code> <code class="n">lgb</code><code class="o">.</code><code class="n">Dataset</code><code class="p">(</code><code class="n">X_train_fold</code><code class="p">,</code> <code class="n">y_train_fold</code><code class="p">)</code>&#13;
    <code class="n">lgb_eval</code> <code class="o">=</code> <code class="n">lgb</code><code class="o">.</code><code class="n">Dataset</code><code class="p">(</code><code class="n">X_cv_fold</code><code class="p">,</code> <code class="n">y_cv_fold</code><code class="p">,</code> <code class="n">reference</code><code class="o">=</code><code class="n">lgb_train</code><code class="p">)</code>&#13;
    <code class="n">gbm</code> <code class="o">=</code> <code class="n">lgb</code><code class="o">.</code><code class="n">train</code><code class="p">(</code><code class="n">params_lightGB</code><code class="p">,</code> <code class="n">lgb_train</code><code class="p">,</code> <code class="n">num_boost_round</code><code class="o">=</code><code class="mi">2000</code><code class="p">,</code>&#13;
                   <code class="n">valid_sets</code><code class="o">=</code><code class="n">lgb_eval</code><code class="p">,</code> <code class="n">early_stopping_rounds</code><code class="o">=</code><code class="mi">200</code><code class="p">)</code>&#13;
&#13;
    <code class="n">loglossTraining</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_train_fold</code><code class="p">,</code> \&#13;
        <code class="n">gbm</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_train_fold</code><code class="p">,</code> <code class="n">num_iteration</code><code class="o">=</code><code class="n">gbm</code><code class="o">.</code><code class="n">best_iteration</code><code class="p">))</code>&#13;
    <code class="n">trainingScores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">loglossTraining</code><code class="p">)</code>&#13;
&#13;
    <code class="n">predictionsBasedOnKFoldsEnsemble</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">X_cv_fold</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="s1">'prediction'</code><code class="p">]</code> <code class="o">=</code> \&#13;
        <code class="n">gbm</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_cv_fold</code><code class="p">,</code> <code class="n">num_iteration</code><code class="o">=</code><code class="n">gbm</code><code class="o">.</code><code class="n">best_iteration</code><code class="p">)</code>&#13;
    <code class="n">loglossCV</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_cv_fold</code><code class="p">,</code> \&#13;
        <code class="n">predictionsBasedOnKFoldsEnsemble</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">X_cv_fold</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
    <code class="n">cvScores</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">loglossCV</code><code class="p">)</code>&#13;
&#13;
    <code class="k">print</code><code class="p">(</code><code class="s1">'Training Log Loss: '</code><code class="p">,</code> <code class="n">loglossTraining</code><code class="p">)</code>&#13;
    <code class="k">print</code><code class="p">(</code><code class="s1">'CV Log Loss: '</code><code class="p">,</code> <code class="n">loglossCV</code><code class="p">)</code>&#13;
&#13;
<code class="n">loglossEnsemble</code> <code class="o">=</code> <code class="n">log_loss</code><code class="p">(</code><code class="n">y_train</code><code class="p">,</code> \&#13;
        <code class="n">predictionsBasedOnKFoldsEnsemble</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="s1">'prediction'</code><code class="p">])</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="s1">'Ensemble Log Loss: '</code><code class="p">,</code> <code class="n">loglossEnsemble</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Evaluate the results" data-type="sect3"><div class="sect3" id="idm140637553618368">&#13;
<h3>Evaluate the results</h3>&#13;
&#13;
<p>In the following results, we do not see an improvement. The ensemble log loss is very similar to the standalone gradient boosting log loss. Since the best standalone solutions are from the same family (gradient boosting), we do not see an improvement in the results. They have highly correlated strengths and weaknesses in detecting fraud. There is no benefit in diversifying across models:</p>&#13;
&#13;
<pre data-type="programlisting">Ensemble Log Loss: 0.002885415974220497</pre>&#13;
&#13;
<p>As shown in Figures <a data-type="xref" data-xrefstyle="select:labelnumber" href="#precision_recall_curve_of_the_ensemble">2-20</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="#area_under_the_roc_curve_of_the_ensemble">2-21</a>, the precision-recall curve, the average precision, and the auROC also corroborate the lack of improvement.<a data-primary="" data-startref="MLPensem02" data-type="indexterm" id="idm140637553347648"/></p>&#13;
&#13;
<figure><div class="figure" id="precision_recall_curve_of_the_ensemble">&#13;
<img alt="Precision-recall curve of ensemble" src="assets/hulp_0220.png"/>&#13;
<h6><span class="label">Figure 2-20. </span>Precision-recall curve of the ensemble</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="area_under_the_roc_curve_of_the_ensemble">&#13;
<img alt="Area under the ROC curve of the ensemble" src="assets/hulp_0221.png"/>&#13;
<h6><span class="label">Figure 2-21. </span>auROC curve of the ensemble</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Final Model Selection" data-type="sect1"><div class="sect1" id="idm140637553342416">&#13;
<h1>Final Model Selection</h1>&#13;
&#13;
<p>Since<a data-primary="machine learning example project" data-secondary="final model selection" data-type="indexterm" id="idm140637553340848"/> the ensemble does not improve performance, we favor the simplicity of the standalone LightGBM gradient boosting model and will use it in production.</p>&#13;
&#13;
<p>Before we create a pipeline for new, incoming transactions, let’s visualize how well the LightGBM model separates the fraudulent transactions from the normal transactions for the test set.</p>&#13;
&#13;
<p><a data-type="xref" href="#plot_of_prediction_probabilities_and_the_true_label">Figure 2-22</a> displays the predicted probabilities on the x-axis. Based on this plot, the model does a reasonably good job of assigning a high probability of fraud to the transactions that are actually fraudulent. Vice versa, the model generally assigns a low probability to the transactions that are not fraudulent. Occasionally, the model is wrong, and assigns a low probability to a case of actual fraud and a high probability to a case of not fraud.</p>&#13;
&#13;
<p>Overall, the results are pretty impressive.</p>&#13;
&#13;
<figure><div class="figure" id="plot_of_prediction_probabilities_and_the_true_label">&#13;
<img alt="Plot of prediction probabilities and the true label" src="assets/hulp_0222.png"/>&#13;
<h6><span class="label">Figure 2-22. </span>Plot of prediction probabilities and the true label</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Production Pipeline" data-type="sect1"><div class="sect1" id="idm140637553334832">&#13;
<h1>Production Pipeline</h1>&#13;
&#13;
<p>Now<a data-primary="machine learning example project" data-secondary="production pipeline" data-type="indexterm" id="idm140637553333264"/> that we have selected a model for production, let’s design a simple pipeline that performs three simple steps on new, incoming data: load the data, scale the features, and generate predictions using the LightGBM model we have already trained and selected for use in production:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="sd">'''Pipeline for New Data'''</code>&#13;
<code class="c1"># first, import new data into a dataframe called 'newData'</code>&#13;
<code class="c1"># second, scale data</code>&#13;
<code class="c1"># newData.loc[:,featuresToScale] = sX.transform(newData[featuresToScale])</code>&#13;
<code class="c1"># third, predict using LightGBM</code>&#13;
<code class="c1"># gbm.predict(newData, num_iteration=gbm.best_iteration)</code></pre>&#13;
&#13;
<p>Once these predictions are generated, analysts can act on (i.e., investigate further) the ones with the highest predicted probability of being fraudulent and work through the list. Or, if automation is the goal, analysts can use a system that automatically rejects transactions that have a predicted probability of being fraudulent above a certain threshold.</p>&#13;
&#13;
<p>For example, based on <a data-type="xref" href="#test_set_area_under_the_roc_curve_of_logistic_regression">Figure 2-13</a>, if we automatically reject transactions with a predicted probability above 0.90, we will reject cases that are almost certain to be fraudulent without accidentally rejecting a case of not fraud.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm140637553328832">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>Congratulations! You have built a credit card fraud detection system using supervised learning.</p>&#13;
&#13;
<p>Together, we set up a machine learning environment, acquired and prepared the data, trained and evaluated multiple models, selected the final model for production, and designed a pipeline for new, incoming transactions. You have successfully created an applied machine learning solution.</p>&#13;
&#13;
<p>Now we will use this same hands-on approach to develop applied machine learning solutions using unsupervised learning.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The solution above will need to be retrained over time as the patterns of fraud change. Also, we should find other machine learning algorithms—from different machine learning families—that perform just as well as gradient boosting and include them in an ensemble to improve fraud detection performance overall.</p>&#13;
&#13;
<p>Finally, interpretability is very important for real-world applications of machine learning. Because the features in this credit card transactions dataset are the output of PCA (a form of dimensionality reduction that we will explore in <a data-type="xref" href="ch03.html#Chapter_3">Chapter 3</a>) we cannot explain in plain English why certain transactions are being flagged as potentially fraudulent. For greater interpretability of the results, we need access to the original pre-PCA features, which we do not have for this sample dataset.<a data-primary="" data-startref="ULfund01a" data-type="indexterm" id="idm140637553321216"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm140637564820880"><sup><a href="ch02.html#idm140637564820880-marker">1</a></sup> For more on fastcluster, consult the <a href="https://pypi.org/project/fastcluster/">documentation</a>.</p><p data-type="footnote" id="idm140637564803888"><sup><a href="ch02.html#idm140637564803888-marker">2</a></sup> This dataset is available via <a href="https://www.kaggle.com/dalpozz/creditcardfraud">Kaggle</a> and was collected during a research collaboration by Worldline and the Machine Learning Group of Universite Libre de Bruxelles. For more information, see Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi, “Calibrating Probability with Undersampling for Unbalanced Classification” in Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015.</p><p data-type="footnote" id="idm140637564800304"><sup><a href="ch02.html#idm140637564800304-marker">3</a></sup> Categorical variables take on one of a limited number of possible qualitative values and often have to be encoded for use in machine learning algorithms.</p><p data-type="footnote" id="idm140637556238384"><sup><a href="ch02.html#idm140637556238384-marker">4</a></sup> For more on how the stratify parameter preserves the ratio of positive labels, visit <a href="http://bit.ly/2NiKWfi">the official website</a>. To reproduce the same split in your experiments, set the random state to 2018. If you set this to another number or don’t set it at all, the results will be different.</p><p data-type="footnote" id="idm140637556129056"><sup><a href="ch02.html#idm140637556129056-marker">5</a></sup> For more on L1 versus L2, refer to the blog post <a href="http://bit.ly/2Bcx413">“Differences Between L1 and L2 as Loss Function and Regularization.”</a></p><p data-type="footnote" id="idm140637555940304"><sup><a href="ch02.html#idm140637555940304-marker">6</a></sup> True positives are instances where the prediction and the actual label are both true. True negatives are instances where the prediction and the actual label are both false. False positives are instances where the prediction is true but the actual label is false (also known as a false alarm or Type I error). False negatives are instances where the prediction is false but the actual label is true (also known as a miss or Type II error).</p><p data-type="footnote" id="idm140637555924656"><sup><a href="ch02.html#idm140637555924656-marker">7</a></sup> Recall is also known as sensitivity or true positive rate. Related to sensitivity is a concept called specificity, or the true negative rate. This is defined as the number of true negatives over the total number of total actual negatives in the dataset. Specificity = true negative rate = true negatives / (true negatives + false positives).</p><p data-type="footnote" id="idm140637555072000"><sup><a href="ch02.html#idm140637555072000-marker">8</a></sup> For more on XGBoost gradient boosting, consult the <a href="https://github.com/dmlc/xgboost">GitHub repository</a>.</p><p data-type="footnote" id="idm140637554683376"><sup><a href="ch02.html#idm140637554683376-marker">9</a></sup> For more on Microsoft’s LightGBM gradient boosting, consult the <a href="https://github.com/Microsoft/LightGBM">GitHub repository</a>.</p><p data-type="footnote" id="idm140637554057392"><sup><a href="ch02.html#idm140637554057392-marker">10</a></sup> For more on ensemble learning, refer to the <a href="https://mlwave.com/kaggle-ensembling-guide/">“Kaggle Ensembling Guide,”</a> <a href="http://bit.ly/2RYV4iF">“Introduction to Ensembling/Stacking in Python,”</a> and <a href="http://bit.ly/2Rrs1iI">“A Kaggler’s Guide to Model Stacking in Practice”</a>.</p></div></div></section></body></html>