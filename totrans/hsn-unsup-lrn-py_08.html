<html><head></head><body><section data-pdf-bookmark="Chapter 6. Group Segmentation" data-type="chapter" epub:type="chapter"><div class="chapter" id="Chapter_6">&#13;
<h1><span class="label">Chapter 6. </span>Group Segmentation</h1>&#13;
&#13;
&#13;
<p>In <a data-type="xref" href="ch05.html#Chapter_5">Chapter 5</a>, we introduced clustering, an unsupervised learning approach to identify the underlying structure in data and grouping points based on similarity. These groups (known as clusters) should be homogeneous and distinct. In other words, the members within a group should be very similar to each other and very distinct from members of any other group.</p>&#13;
&#13;
<p>From<a data-primary="group segmentation" data-secondary="applications for" data-type="indexterm" id="idm140637544817792"/> an applied perspective, the ability to segment members into groups based on similarity and without any guidance from labels is very powerful. For example, such a technique could be applied to find different consumer groups for online retailers, customizing a marketing strategy for each of the distinct groups (i.e., budget shoppers, fashionistas, sneakerheads, techies, audiophiles, etc.). Group segmentation could improve targeting in online advertising and improve recommendations in recommender systems for movies, music, news, social networking, dating, etc.</p>&#13;
&#13;
<p>In this chapter, we will build an applied unsupervised learning solution using the clustering algorithms from the previous chapter—more specifically, we will perform group segmentation.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Lending Club Data" data-type="sect1"><div class="sect1" id="idm140637544815360">&#13;
<h1>Lending Club Data</h1>&#13;
&#13;
<p>For<a data-primary="group segmentation" data-secondary="Lending Club data" data-type="indexterm" id="GSlend06"/><a data-primary="Lending Club data" data-type="indexterm" id="lend05"/> this chapter, we will use loan data from Lending Club, a US peer-to-peer lending company. Borrowers on the platform can borrow between $1,000 to $40,000 in the form of unsecured personal loans, for a term of either three or five years.</p>&#13;
&#13;
<p>Investors can browse the loan applications and choose to finance the loans based on the credit history of the borrower, the amount of the loan, the loan grade, and the purpose of the loan. Investors earn money through interest paid on the loans, and Lending Club makes money from loan origination fees and service charges.</p>&#13;
&#13;
<p>The loan data we will use is from 2007–2011 and is publicly available on <a href="http://bit.ly/2FYN2zX">the Lending Club website</a>. A data dictionary is also available there.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Data Preparation" data-type="sect2"><div class="sect2" id="idm140637544809072">&#13;
<h2>Data Preparation</h2>&#13;
&#13;
<p>Like in previous chapters, let’s prepare the environment to work with the Lending Club data.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Load libraries" data-type="sect3"><div class="sect3" id="idm140637544807536">&#13;
<h3>Load libraries</h3>&#13;
&#13;
<p>First, let’s load the necessary libraries:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Import libraries</code>&#13;
<code class="sd">'''Main'''</code>&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="kn">as</code> <code class="nn">pd</code>&#13;
<code class="kn">import</code> <code class="nn">os</code><code class="o">,</code> <code class="nn">time</code><code class="o">,</code> <code class="nn">re</code>&#13;
<code class="kn">import</code> <code class="nn">pickle</code><code class="o">,</code> <code class="nn">gzip</code>&#13;
&#13;
<code class="sd">'''Data Viz'''</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="kn">as</code> <code class="nn">plt</code>&#13;
<code class="kn">import</code> <code class="nn">seaborn</code> <code class="kn">as</code> <code class="nn">sns</code>&#13;
<code class="n">color</code> <code class="o">=</code> <code class="n">sns</code><code class="o">.</code><code class="n">color_palette</code><code class="p">()</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib</code> <code class="kn">as</code> <code class="nn">mpl</code>&#13;
&#13;
<code class="o">%</code><code class="n">matplotlib</code> <code class="n">inline</code>&#13;
&#13;
<code class="sd">'''Data Prep and Model Evaluation'''</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn</code> <code class="kn">import</code> <code class="n">preprocessing</code> <code class="k">as</code> <code class="n">pp</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">train_test_split</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">precision_recall_curve</code><code class="p">,</code> <code class="n">average_precision_score</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">roc_curve</code><code class="p">,</code> <code class="n">auc</code><code class="p">,</code> <code class="n">roc_auc_score</code>&#13;
&#13;
<code class="sd">'''Algorithms'''</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.decomposition</code> <code class="kn">import</code> <code class="n">PCA</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.cluster</code> <code class="kn">import</code> <code class="n">KMeans</code>&#13;
<code class="kn">import</code> <code class="nn">fastcluster</code>&#13;
<code class="kn">from</code> <code class="nn">scipy.cluster.hierarchy</code> <code class="kn">import</code> <code class="n">dendrogram</code><code class="p">,</code> <code class="n">cophenet</code><code class="p">,</code> <code class="n">fcluster</code>&#13;
<code class="kn">from</code> <code class="nn">scipy.spatial.distance</code> <code class="kn">import</code> <code class="n">pdist</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Explore the data" data-type="sect3"><div class="sect3" id="idm140637544804400">&#13;
<h3>Explore the data</h3>&#13;
&#13;
<p>Next, let’s load the loan data and designate which of the columns to keep:</p>&#13;
&#13;
<p>The original loan data file has 144 columns, but most of these columns are empty and are of little value to us. Therefore, we will designate a subset of the columns that are mostly populated and are worth using in our clustering application. These fields include attributes of the loan such as the amount requested, the amount funded, the term, the interest rate, the loan grade, etc., and attributes of the borrower such as employment length, home ownership status, annual income, address, and purpose for borrowing money.</p>&#13;
&#13;
<p>We will also explore the data a bit:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Load the data</code>&#13;
<code class="n">current_path</code> <code class="o">=</code> <code class="n">os</code><code class="o">.</code><code class="n">getcwd</code><code class="p">()</code>&#13;
<code class="nb">file</code> <code class="o">=</code> <code class="s1">'</code><code class="se">\\</code><code class="s1">datasets</code><code class="se">\\</code><code class="s1">lending_club_data</code><code class="se">\\</code><code class="s1">LoanStats3a.csv'</code>&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="n">current_path</code> <code class="o">+</code> <code class="nb">file</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Select columns to keep</code>&#13;
<code class="n">columnsToKeep</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'loan_amnt'</code><code class="p">,</code><code class="s1">'funded_amnt'</code><code class="p">,</code><code class="s1">'funded_amnt_inv'</code><code class="p">,</code><code class="s1">'term'</code><code class="p">,</code> \&#13;
                 <code class="s1">'int_rate'</code><code class="p">,</code><code class="s1">'installment'</code><code class="p">,</code><code class="s1">'grade'</code><code class="p">,</code><code class="s1">'sub_grade'</code><code class="p">,</code> \&#13;
                 <code class="s1">'emp_length'</code><code class="p">,</code><code class="s1">'home_ownership'</code><code class="p">,</code><code class="s1">'annual_inc'</code><code class="p">,</code> \&#13;
                 <code class="s1">'verification_status'</code><code class="p">,</code><code class="s1">'pymnt_plan'</code><code class="p">,</code><code class="s1">'purpose'</code><code class="p">,</code> \&#13;
                 <code class="s1">'addr_state'</code><code class="p">,</code><code class="s1">'dti'</code><code class="p">,</code><code class="s1">'delinq_2yrs'</code><code class="p">,</code><code class="s1">'earliest_cr_line'</code><code class="p">,</code> \&#13;
                 <code class="s1">'mths_since_last_delinq'</code><code class="p">,</code><code class="s1">'mths_since_last_record'</code><code class="p">,</code> \&#13;
                 <code class="s1">'open_acc'</code><code class="p">,</code><code class="s1">'pub_rec'</code><code class="p">,</code><code class="s1">'revol_bal'</code><code class="p">,</code><code class="s1">'revol_util'</code><code class="p">,</code> \&#13;
                 <code class="s1">'total_acc'</code><code class="p">,</code><code class="s1">'initial_list_status'</code><code class="p">,</code><code class="s1">'out_prncp'</code><code class="p">,</code> \&#13;
                 <code class="s1">'out_prncp_inv'</code><code class="p">,</code><code class="s1">'total_pymnt'</code><code class="p">,</code><code class="s1">'total_pymnt_inv'</code><code class="p">,</code> \&#13;
                 <code class="s1">'total_rec_prncp'</code><code class="p">,</code><code class="s1">'total_rec_int'</code><code class="p">,</code><code class="s1">'total_rec_late_fee'</code><code class="p">,</code> \&#13;
                 <code class="s1">'recoveries'</code><code class="p">,</code><code class="s1">'collection_recovery_fee'</code><code class="p">,</code><code class="s1">'last_pymnt_d'</code><code class="p">,</code> \&#13;
                 <code class="s1">'last_pymnt_amnt'</code><code class="p">]</code>&#13;
&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">columnsToKeep</code><code class="p">]</code>&#13;
&#13;
<code class="n">data</code><code class="o">.</code><code class="n">shape</code>&#13;
&#13;
<code class="n">data</code><code class="o">.</code><code class="n">head</code><code class="p">()</code></pre>&#13;
&#13;
<p>The data has 42,542 loans and 37 features (42,542, 37).</p>&#13;
&#13;
<p><a data-type="xref" href="#first_few_rows_of_the_loan_data">Table 6-1</a> previews the data.</p>&#13;
<table id="first_few_rows_of_the_loan_data">&#13;
<caption><span class="label">Table 6-1. </span>First few rows of the loan data</caption>&#13;
<thead>&#13;
<tr>&#13;
<th/>&#13;
<th>loan_amnt</th>&#13;
<th>funded_amnt</th>&#13;
<th>funded_amnt_inv</th>&#13;
<th>term</th>&#13;
<th>int_rate</th>&#13;
<th>instsallment</th>&#13;
<th>grade</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>0</p></td>&#13;
<td><p>5000.0</p></td>&#13;
<td><p>5000.0</p></td>&#13;
<td><p>4975.0</p></td>&#13;
<td><p>36 months</p></td>&#13;
<td><p>10.65%</p></td>&#13;
<td><p>162.87</p></td>&#13;
<td><p>B</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>1</p></td>&#13;
<td><p>2500.0</p></td>&#13;
<td><p>2500.0</p></td>&#13;
<td><p>2500.0</p></td>&#13;
<td><p>60 months</p></td>&#13;
<td><p>15.27%</p></td>&#13;
<td><p>59.83</p></td>&#13;
<td><p>C</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>2</p></td>&#13;
<td><p>2400.0</p></td>&#13;
<td><p>2400.0</p></td>&#13;
<td><p>2400.0</p></td>&#13;
<td><p>35 months</p></td>&#13;
<td><p>15.96%</p></td>&#13;
<td><p>84.33</p></td>&#13;
<td><p>C</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>3</p></td>&#13;
<td><p>10000.0</p></td>&#13;
<td><p>10000.0</p></td>&#13;
<td><p>10000.0</p></td>&#13;
<td><p>36 months</p></td>&#13;
<td><p>13.49%</p></td>&#13;
<td><p>339.31</p></td>&#13;
<td><p>C</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>4</p></td>&#13;
<td><p>3000.0</p></td>&#13;
<td><p>3000.0</p></td>&#13;
<td><p>3000.0</p></td>&#13;
<td><p>60 months</p></td>&#13;
<td><p>12.69%</p></td>&#13;
<td><p>67.79</p></td>&#13;
<td><p>B</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Transform String Format to Numerical Format" data-type="sect2"><div class="sect2" id="idm140637544551008">&#13;
<h2>Transform String Format to Numerical Format</h2>&#13;
&#13;
<p>A few of the features—the term of the loan, the interest rate of the loan, employment length of the borrower, and revolving utilization of the borrower—need to be altered from a string format to a numerical format. Let’s perform the transformation:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Transform features from string to numeric</code>&#13;
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="p">[</code><code class="s2">"term"</code><code class="p">,</code><code class="s2">"int_rate"</code><code class="p">,</code><code class="s2">"emp_length"</code><code class="p">,</code><code class="s2">"revol_util"</code><code class="p">]:</code>&#13;
    <code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> \&#13;
        <code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">i</code><code class="p">]</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">re</code><code class="o">.</code><code class="n">sub</code><code class="p">(</code><code class="s2">"[^0-9]"</code><code class="p">,</code> <code class="s2">""</code><code class="p">,</code> <code class="nb">str</code><code class="p">(</code><code class="n">x</code><code class="p">)))</code>&#13;
    <code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">to_numeric</code><code class="p">(</code><code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">i</code><code class="p">])</code></pre>&#13;
&#13;
<p>For our clustering application, we will consider just the numerical features and ignore all the categorical features because nonnumerical features cannot be handled by our clustering algorithms in their current form.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Impute Missing Values" data-type="sect2"><div class="sect2" id="idm140637544227648">&#13;
<h2>Impute Missing Values</h2>&#13;
&#13;
<p>Let’s find<a data-primary="not a number (NaNs)" data-type="indexterm" id="idm140637544226208"/> these numerical features and count the number of NaNs per feature. We will then impute these NaNs with either the mean of the feature or, in some cases, just the number zero, depending on what the feature represents from a business perspective:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Determine which features are numerical</code>&#13;
<code class="n">numericalFeats</code> <code class="o">=</code> <code class="p">[</code><code class="n">x</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">data</code><code class="o">.</code><code class="n">columns</code> <code class="k">if</code> <code class="n">data</code><code class="p">[</code><code class="n">x</code><code class="p">]</code><code class="o">.</code><code class="n">dtype</code> <code class="o">!=</code> <code class="s1">'object'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Display NaNs by feature</code>&#13;
<code class="n">nanCounter</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">isnan</code><code class="p">(</code><code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">numericalFeats</code><code class="p">])</code><code class="o">.</code><code class="n">sum</code><code class="p">()</code>&#13;
<code class="n">nanCounter</code></pre>&#13;
&#13;
<p>The following code shows the number of NaNs by feature:</p>&#13;
&#13;
<pre data-type="programlisting">loan_amnt               7&#13;
funded_amnt             7&#13;
funded_amnt_inv         7&#13;
term                    7&#13;
int_rate                7&#13;
installment             7&#13;
emp_length              1119&#13;
annual_inc              11&#13;
dti                     7&#13;
delinq_2yrs             36&#13;
mths_since_last_delinq  26933&#13;
mths_since_last_record  38891&#13;
open_acc                36&#13;
pub_rec                 36&#13;
revol_bal               7&#13;
revol_util              97&#13;
total_acc               36&#13;
out_prncp               7&#13;
out_prncp_inv           7&#13;
total_pymnt             7&#13;
total_pymnt_inv         7&#13;
total_rec_prncp         7&#13;
total_rec_int           7&#13;
total_rec_late_fee      7&#13;
recoveries              7&#13;
collection_recovery_fee 7&#13;
last_pymnt_amnt         7&#13;
dtype: int64</pre>&#13;
&#13;
<p>Most features have a few NaNs, and some—such as the months since last delinquency and last change in record—have many.</p>&#13;
&#13;
<p>Let’s impute these so we do not have to deal with any NaNs during the clustering process:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Impute NaNs with mean</code>&#13;
<code class="n">fillWithMean</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'loan_amnt'</code><code class="p">,</code><code class="s1">'funded_amnt'</code><code class="p">,</code><code class="s1">'funded_amnt_inv'</code><code class="p">,</code><code class="s1">'term'</code><code class="p">,</code> \&#13;
                <code class="s1">'int_rate'</code><code class="p">,</code><code class="s1">'installment'</code><code class="p">,</code><code class="s1">'emp_length'</code><code class="p">,</code><code class="s1">'annual_inc'</code><code class="p">,</code>\&#13;
                <code class="s1">'dti'</code><code class="p">,</code><code class="s1">'open_acc'</code><code class="p">,</code><code class="s1">'revol_bal'</code><code class="p">,</code><code class="s1">'revol_util'</code><code class="p">,</code><code class="s1">'total_acc'</code><code class="p">,</code>\&#13;
                <code class="s1">'out_prncp'</code><code class="p">,</code><code class="s1">'out_prncp_inv'</code><code class="p">,</code><code class="s1">'total_pymnt'</code><code class="p">,</code> \&#13;
                <code class="s1">'total_pymnt_inv'</code><code class="p">,</code><code class="s1">'total_rec_prncp'</code><code class="p">,</code><code class="s1">'total_rec_int'</code><code class="p">,</code> \&#13;
                <code class="s1">'last_pymnt_amnt'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Impute NaNs with zero</code>&#13;
<code class="n">fillWithZero</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'delinq_2yrs'</code><code class="p">,</code><code class="s1">'mths_since_last_delinq'</code><code class="p">,</code> \&#13;
                <code class="s1">'mths_since_last_record'</code><code class="p">,</code><code class="s1">'pub_rec'</code><code class="p">,</code><code class="s1">'total_rec_late_fee'</code><code class="p">,</code> \&#13;
                <code class="s1">'recoveries'</code><code class="p">,</code><code class="s1">'collection_recovery_fee'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Perform imputation</code>&#13;
<code class="n">im</code> <code class="o">=</code> <code class="n">pp</code><code class="o">.</code><code class="n">Imputer</code><code class="p">(</code><code class="n">strategy</code><code class="o">=</code><code class="s1">'mean'</code><code class="p">)</code>&#13;
<code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">fillWithMean</code><code class="p">]</code> <code class="o">=</code> <code class="n">im</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="n">fillWithMean</code><code class="p">])</code>&#13;
&#13;
<code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">fillWithZero</code><code class="p">]</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">fillWithZero</code><code class="p">]</code><code class="o">.</code><code class="n">fillna</code><code class="p">(</code><code class="n">value</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code></pre>&#13;
&#13;
<p>Let’s recalculate the NaNs to make sure no NaNs remain.</p>&#13;
&#13;
<p>We are now safe. All the NaNs have been filled:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">numericalFeats</code> <code class="o">=</code> <code class="p">[</code><code class="n">x</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">data</code><code class="o">.</code><code class="n">columns</code> <code class="k">if</code> <code class="n">data</code><code class="p">[</code><code class="n">x</code><code class="p">]</code><code class="o">.</code><code class="n">dtype</code> <code class="o">!=</code> <code class="s1">'object'</code><code class="p">]</code>&#13;
&#13;
<code class="n">nanCounter</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">isnan</code><code class="p">(</code><code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">numericalFeats</code><code class="p">])</code><code class="o">.</code><code class="n">sum</code><code class="p">()</code>&#13;
<code class="n">nanCounter</code></pre>&#13;
&#13;
<pre data-type="programlisting">loan_amnt               0&#13;
funded_amnt             0&#13;
funded_amnt_inv         0&#13;
term                    0&#13;
int_rate                0&#13;
installment             0&#13;
emp_length              0&#13;
annual_inc              0&#13;
dti                     0&#13;
delinq_2yrs             0&#13;
mths_since_last_delinq  0&#13;
mths_since_last_record  0&#13;
open_acc                0&#13;
pub_rec                 0&#13;
revol_bal               0&#13;
revol_util              0&#13;
total_acc               0&#13;
out_prncp               0&#13;
out_prncp_inv           0&#13;
total_pymnt             0&#13;
total_pymnt_inv         0&#13;
total_rec_prncp         0&#13;
total_rec_int           0&#13;
total_rec_late_fee      0&#13;
recoveries              0&#13;
collection_recovery_fee 0&#13;
last_pymnt_amnt         0&#13;
dtype: int64</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Engineer Features" data-type="sect2"><div class="sect2" id="idm140637544376320">&#13;
<h2>Engineer Features</h2>&#13;
&#13;
<p>Let’s also engineer a few more features to add to the existing feature set. These new features are mostly ratios between loan amount, revolving balance, payments, and the borrower’s annual income:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Feature engineering</code>&#13;
<code class="n">data</code><code class="p">[</code><code class="s1">'installmentOverLoanAmnt'</code><code class="p">]</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">installment</code><code class="o">/</code><code class="n">data</code><code class="o">.</code><code class="n">loan_amnt</code>&#13;
<code class="n">data</code><code class="p">[</code><code class="s1">'loanAmntOverIncome'</code><code class="p">]</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">loan_amnt</code><code class="o">/</code><code class="n">data</code><code class="o">.</code><code class="n">annual_inc</code>&#13;
<code class="n">data</code><code class="p">[</code><code class="s1">'revol_balOverIncome'</code><code class="p">]</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">revol_bal</code><code class="o">/</code><code class="n">data</code><code class="o">.</code><code class="n">annual_inc</code>&#13;
<code class="n">data</code><code class="p">[</code><code class="s1">'totalPymntOverIncome'</code><code class="p">]</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">total_pymnt</code><code class="o">/</code><code class="n">data</code><code class="o">.</code><code class="n">annual_inc</code>&#13;
<code class="n">data</code><code class="p">[</code><code class="s1">'totalPymntInvOverIncome'</code><code class="p">]</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">total_pymnt_inv</code><code class="o">/</code><code class="n">data</code><code class="o">.</code><code class="n">annual_inc</code>&#13;
<code class="n">data</code><code class="p">[</code><code class="s1">'totalRecPrncpOverIncome'</code><code class="p">]</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">total_rec_prncp</code><code class="o">/</code><code class="n">data</code><code class="o">.</code><code class="n">annual_inc</code>&#13;
<code class="n">data</code><code class="p">[</code><code class="s1">'totalRecIncOverIncome'</code><code class="p">]</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">total_rec_int</code><code class="o">/</code><code class="n">data</code><code class="o">.</code><code class="n">annual_inc</code>&#13;
&#13;
<code class="n">newFeats</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'installmentOverLoanAmnt'</code><code class="p">,</code><code class="s1">'loanAmntOverIncome'</code><code class="p">,</code> \&#13;
            <code class="s1">'revol_balOverIncome'</code><code class="p">,</code><code class="s1">'totalPymntOverIncome'</code><code class="p">,</code> \&#13;
           <code class="s1">'totalPymntInvOverIncome'</code><code class="p">,</code><code class="s1">'totalRecPrncpOverIncome'</code><code class="p">,</code> \&#13;
            <code class="s1">'totalRecIncOverIncome'</code><code class="p">]</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Select Final Set of Features and Perform Scaling" data-type="sect2"><div class="sect2" id="idm140637544120480">&#13;
<h2>Select Final Set of Features and Perform Scaling</h2>&#13;
&#13;
<p>Next, we will generate the training dataframe and scale the features for our clustering algorithms:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Select features for training</code>&#13;
<code class="n">numericalPlusNewFeats</code> <code class="o">=</code> <code class="n">numericalFeats</code><code class="o">+</code><code class="n">newFeats</code>&#13;
<code class="n">X_train</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">numericalPlusNewFeats</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Scale data</code>&#13;
<code class="n">sX</code> <code class="o">=</code> <code class="n">pp</code><code class="o">.</code><code class="n">StandardScaler</code><code class="p">()</code>&#13;
<code class="n">X_train</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,:]</code> <code class="o">=</code> <code class="n">sX</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Designate Labels for Evaluation" data-type="sect2"><div class="sect2" id="idm140637543899616">&#13;
<h2>Designate Labels for Evaluation</h2>&#13;
&#13;
<p>Clustering is an unsupervised learning approach, and, therefore, labels are not used. However, to judge the goodness of our clustering algorithm at finding distinct and homogeneous groups of borrowers in this Lending Club dataset, we will use the loan grade as a proxy label.</p>&#13;
&#13;
<p>The loan grade is currently graded by letters, with loan grade “A” as the most credit-worthy and safe and loan grade “G” as the least:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">labels</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">grade</code>&#13;
<code class="n">labels</code><code class="o">.</code><code class="n">unique</code><code class="p">()</code></pre>&#13;
&#13;
<pre data-type="programlisting">array(['B', 'C', 'A', 'E', 'F', 'D', 'G', nan], dtype=object)</pre>&#13;
&#13;
<p>There<a data-primary="Scikit-learn" data-secondary="group segmentation" data-type="indexterm" id="SCLgroup06"/><a data-primary="Scikit-learn" data-secondary="LabelEncoder" data-type="indexterm" id="idm140637543859680"/><a data-primary="LabelEncoder" data-type="indexterm" id="idm140637543857872"/> are some NaNs in the loan grade. We will fill these with a value of “Z” and then use the <code>LabelEncoder</code> from Scikit-Learn to transform the letter grades to numerical grades. To remain consistent, we will load these labels into a “y_train” Python series:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Fill missing labels</code>&#13;
<code class="n">labels</code> <code class="o">=</code> <code class="n">labels</code><code class="o">.</code><code class="n">fillna</code><code class="p">(</code><code class="n">value</code><code class="o">=</code><code class="s2">"Z"</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Convert labels to numerical values</code>&#13;
<code class="n">lbl</code> <code class="o">=</code> <code class="n">pp</code><code class="o">.</code><code class="n">LabelEncoder</code><code class="p">()</code>&#13;
<code class="n">lbl</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="nb">list</code><code class="p">(</code><code class="n">labels</code><code class="o">.</code><code class="n">values</code><code class="p">))</code>&#13;
<code class="n">labels</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">lbl</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">labels</code><code class="o">.</code><code class="n">values</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"grade"</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Store as y_train</code>&#13;
<code class="n">y_train</code> <code class="o">=</code> <code class="n">labels</code>&#13;
&#13;
<code class="n">labelsOriginalVSNew</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">labels</code><code class="p">,</code> <code class="n">data</code><code class="o">.</code><code class="n">grade</code><code class="p">],</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">labelsOriginalVSNew</code></pre>&#13;
<table class="pagebreak-before" id="numerical_versus_letter_loan_grades">&#13;
<caption><span class="label">Table 6-2. </span>Numerical versus letter loan grades</caption>&#13;
<thead>&#13;
<tr>&#13;
<th/>&#13;
<th>grade</th>&#13;
<th>grade</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>0</p></td>&#13;
<td><p>1</p></td>&#13;
<td><p>B</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>1</p></td>&#13;
<td><p>2</p></td>&#13;
<td><p>C</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>2</p></td>&#13;
<td><p>2</p></td>&#13;
<td><p>C</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>3</p></td>&#13;
<td><p>2</p></td>&#13;
<td><p>C</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>4</p></td>&#13;
<td><p>1</p></td>&#13;
<td><p>B</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>5</p></td>&#13;
<td><p>0</p></td>&#13;
<td><p>A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>6</p></td>&#13;
<td><p>2</p></td>&#13;
<td><p>C</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>7</p></td>&#13;
<td><p>4</p></td>&#13;
<td><p>E</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>8</p></td>&#13;
<td><p>5</p></td>&#13;
<td><p>F</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>9</p></td>&#13;
<td><p>1</p></td>&#13;
<td><p>B</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>10</p></td>&#13;
<td><p>2</p></td>&#13;
<td><p>C</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>11</p></td>&#13;
<td><p>1</p></td>&#13;
<td><p>B</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>12</p></td>&#13;
<td><p>2</p></td>&#13;
<td><p>C</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>13</p></td>&#13;
<td><p>1</p></td>&#13;
<td><p>B</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>14</p></td>&#13;
<td><p>1</p></td>&#13;
<td><p>B</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>15</p></td>&#13;
<td><p>3</p></td>&#13;
<td><p>D</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>16</p></td>&#13;
<td><p>2</p></td>&#13;
<td><p>C</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>As you can see from <a data-type="xref" href="#numerical_versus_letter_loan_grades">Table 6-2</a>, all the “A” grades have been transformed into 0, the “B” grades into 1, etc.</p>&#13;
&#13;
<p>Let’s also check whether grade “A” loans generally have the lowest interest rate charged, since they are the least risky and other loans are charged progressively higher rates of interest:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Compare loan grades with interest rates</code>&#13;
<code class="n">interestAndGrade</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[</code><code class="n">data</code><code class="o">.</code><code class="n">int_rate</code><code class="p">,</code><code class="n">labels</code><code class="p">])</code>&#13;
<code class="n">interestAndGrade</code> <code class="o">=</code> <code class="n">interestAndGrade</code><code class="o">.</code><code class="n">T</code>&#13;
&#13;
<code class="n">interestAndGrade</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s2">"grade"</code><code class="p">)</code><code class="o">.</code><code class="n">mean</code><code class="p">()</code></pre>&#13;
&#13;
<p><a data-type="xref" href="#grade_versus_interest_rate">Table 6-3</a> confirms this. Higher<a data-primary="" data-startref="GSlend06" data-type="indexterm" id="idm140637543635056"/><a data-primary="" data-startref="Lending Club data" data-type="indexterm" id="idm140637543634176"/> letter grade loans have higher interest rates.<sup><a data-type="noteref" href="ch06.html#idm140637543541600" id="idm140637543541600-marker">1</a></sup></p>&#13;
<table id="grade_versus_interest_rate">&#13;
<caption><span class="label">Table 6-3. </span>Grade versus interest rate</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>grade</th>&#13;
<th>int_rate</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>0.0</p></td>&#13;
<td><p>734.270844</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>1.0</p></td>&#13;
<td><p>1101.420857</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>2.0</p></td>&#13;
<td><p>1349.988902</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>3.0</p></td>&#13;
<td><p>1557.714927</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>4.0</p></td>&#13;
<td><p>1737.676783</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>5.0</p></td>&#13;
<td><p>1926.530361</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>6.0</p></td>&#13;
<td><p>2045.125000</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>7.0</p></td>&#13;
<td><p>1216.501563</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Goodness of the Clusters" data-type="sect1"><div class="sect1" id="idm140637544814864">&#13;
<h1>Goodness of the Clusters</h1>&#13;
&#13;
<p>Now<a data-primary="group segmentation" data-secondary="analyzing cluster homogeneity" data-type="indexterm" id="idm140637543523376"/> the data is ready. We have an X_train with all of our 34 numerical features, and a y_train with the numerical loan grades, which we use only to validate the results, not to train with the algorithm as you would do in a supervised machine learning problem. Before we build our first clustering application, let’s introduce a function to <span class="keep-together">analyze</span> the goodness of the clusters we generate using the clustering algorithms. Specifically, we will use the concept of homogeneity to assess the goodness of each cluster.</p>&#13;
&#13;
<p>If the clustering algorithm does a good job separating the borrowers in the Lending Club dataset, each cluster should have borrowers that are very similar to each other and dissimilar to those in other groups. Presumably, borrowers that are similar to each other and grouped together should have similar credit profiles—in other words, their creditworthiness should be similar.</p>&#13;
&#13;
<p>If this is the case (and with real-world problems, a lot of these assumptions are only partially true), borrowers in a given cluster should generally be assigned the same numerical loan grade, which we will validate using the numerical loan grades we set aside in y_train. The higher the percentage of borrowers that have the most <span class="keep-together">frequently</span> occurring numerical loan grade in each and every cluster, the better the clustering application.</p>&#13;
&#13;
<p>As an example, consider a cluster with one hundred borrowers. If 30 borrowers have a numerical loan grade of 0, 25 borrowers have a loan grade of 1, 20 borrowers have a loan grade of 2, and the remaining borrowers have loan grades ranging from 3 to 7, we would say that the cluster has a 30% accuracy, given that the most frequently occuring loan grade for that cluster applies to just 30% of the borrowers in that <span class="keep-together">cluster</span>.</p>&#13;
&#13;
<p>If we did not have a y_train with the numerical loan grades to validate the goodness of the clusters, we could use an alternative approach. We could sample a few borrowers in each cluster, determine the numerical loan grade for them by hand, and determine if we would give roughly the same numerical loan grade to those borrowers. If yes, then the cluster is a good cluster—it is homogeneous enough that we would give roughly the same numerical loan grade to the borrowers we sampled. If not, then the cluster is not good enough—the borrowers are too heterogeneous, and we should try to improve the solution using more data, a different clustering algorithm, etc.</p>&#13;
&#13;
<p>We won’t have to sample and manually hand-label the borrowers, though, given that we have the numerical loan grades already, but this is important to keep in mind in case you do not have labels for your particular problem.</p>&#13;
&#13;
<p>Here is the function to analyze the clusters:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="k">def</code> <code class="nf">analyzeCluster</code><code class="p">(</code><code class="n">clusterDF</code><code class="p">,</code> <code class="n">labelsDF</code><code class="p">):</code>&#13;
    <code class="n">countByCluster</code> <code class="o">=</code> \&#13;
        <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">clusterDF</code><code class="p">[</code><code class="s1">'cluster'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">())</code>&#13;
    <code class="n">countByCluster</code><code class="o">.</code><code class="n">reset_index</code><code class="p">(</code><code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code class="n">drop</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>&#13;
    <code class="n">countByCluster</code><code class="o">.</code><code class="n">columns</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'cluster'</code><code class="p">,</code><code class="s1">'clusterCount'</code><code class="p">]</code>&#13;
&#13;
    <code class="n">preds</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">labelsDF</code><code class="p">,</code><code class="n">clusterDF</code><code class="p">],</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
    <code class="n">preds</code><code class="o">.</code><code class="n">columns</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'trueLabel'</code><code class="p">,</code><code class="s1">'cluster'</code><code class="p">]</code>&#13;
&#13;
    <code class="n">countByLabel</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">preds</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s1">'trueLabel'</code><code class="p">)</code><code class="o">.</code><code class="n">count</code><code class="p">())</code>&#13;
&#13;
    <code class="n">countMostFreq</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">preds</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s1">'cluster'</code><code class="p">)</code><code class="o">.</code><code class="n">agg</code><code class="p">(</code> \&#13;
        <code class="k">lambda</code> <code class="n">x</code><code class="p">:</code><code class="n">x</code><code class="o">.</code><code class="n">value_counts</code><code class="p">()</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="mi">0</code><code class="p">]))</code>&#13;
    <code class="n">countMostFreq</code><code class="o">.</code><code class="n">reset_index</code><code class="p">(</code><code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code class="n">drop</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>&#13;
    <code class="n">countMostFreq</code><code class="o">.</code><code class="n">columns</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'cluster'</code><code class="p">,</code><code class="s1">'countMostFrequent'</code><code class="p">]</code>&#13;
&#13;
    <code class="n">accuracyDF</code> <code class="o">=</code> <code class="n">countMostFreq</code><code class="o">.</code><code class="n">merge</code><code class="p">(</code><code class="n">countByCluster</code><code class="p">,</code> \&#13;
        <code class="n">left_on</code><code class="o">=</code><code class="s2">"cluster"</code><code class="p">,</code><code class="n">right_on</code><code class="o">=</code><code class="s2">"cluster"</code><code class="p">)</code>&#13;
&#13;
    <code class="n">overallAccuracy</code> <code class="o">=</code> <code class="n">accuracyDF</code><code class="o">.</code><code class="n">countMostFrequent</code><code class="o">.</code><code class="n">sum</code><code class="p">()</code><code class="o">/</code> \&#13;
        <code class="n">accuracyDF</code><code class="o">.</code><code class="n">clusterCount</code><code class="o">.</code><code class="n">sum</code><code class="p">()</code>&#13;
&#13;
    <code class="n">accuracyByLabel</code> <code class="o">=</code> <code class="n">accuracyDF</code><code class="o">.</code><code class="n">countMostFrequent</code><code class="o">/</code> \&#13;
        <code class="n">accuracyDF</code><code class="o">.</code><code class="n">clusterCount</code>&#13;
&#13;
    <code class="k">return</code> <code class="n">countByCluster</code><code class="p">,</code> <code class="n">countByLabel</code><code class="p">,</code> <code class="n">countMostFreq</code><code class="p">,</code> \&#13;
        <code class="n">accuracyDF</code><code class="p">,</code> <code class="n">overallAccuracy</code><code class="p">,</code> <code class="n">accuracyByLabel</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="k-Means Application" data-type="sect1"><div class="sect1" id="idm140637543595312">&#13;
<h1>k-Means Application</h1>&#13;
&#13;
<p>Our<a data-primary="group segmentation" data-secondary="k-means application" data-type="indexterm" id="idm140637543593520"/><a data-primary="k-means clustering" data-secondary="group segmentation" data-type="indexterm" id="idm140637543409968"/> first clustering application using this Lending Club dataset will use <em>k</em>-means, which we introduced in <a data-type="xref" href="ch05.html#Chapter_5">Chapter 5</a>. Recall that in <em>k</em>-means clustering, we need to specify the desired clusters <em>k</em>, and the algorithm will assign each borrower to exactly one of these <em>k</em> clusters.</p>&#13;
&#13;
<p>The algorithm will accomplish this by minimizing the within-cluster variation, which is also known as inertia, such that the sum of the within-cluster variations across all <em>k</em> clusters is as small as possible.</p>&#13;
&#13;
<p>Instead of specifying just one value of <em>k</em>, we will run an experiment where we set <em>k</em> from a range of 10 to 30 and plot the results of the accuracy measure we defined in the previous section.</p>&#13;
&#13;
<p>Based on which <em>k</em> measure performs best, we can build the pipeline for clustering using this best-performing <em>k</em> measure:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">sklearn.cluster</code> <code class="kn">import</code> <code class="n">KMeans</code>&#13;
&#13;
<code class="n">n_clusters</code> <code class="o">=</code> <code class="mi">10</code>&#13;
<code class="n">n_init</code> <code class="o">=</code> <code class="mi">10</code>&#13;
<code class="n">max_iter</code> <code class="o">=</code> <code class="mi">300</code>&#13;
<code class="n">tol</code> <code class="o">=</code> <code class="mf">0.0001</code>&#13;
<code class="n">random_state</code> <code class="o">=</code> <code class="mi">2018</code>&#13;
<code class="n">n_jobs</code> <code class="o">=</code> <code class="mi">2</code>&#13;
&#13;
<code class="n">kmeans</code> <code class="o">=</code> <code class="n">KMeans</code><code class="p">(</code><code class="n">n_clusters</code><code class="o">=</code><code class="n">n_clusters</code><code class="p">,</code> <code class="n">n_init</code><code class="o">=</code><code class="n">n_init</code><code class="p">,</code> \&#13;
                <code class="n">max_iter</code><code class="o">=</code><code class="n">max_iter</code><code class="p">,</code> <code class="n">tol</code><code class="o">=</code><code class="n">tol</code><code class="p">,</code> \&#13;
                <code class="n">random_state</code><code class="o">=</code><code class="n">random_state</code><code class="p">,</code> <code class="n">n_jobs</code><code class="o">=</code><code class="n">n_jobs</code><code class="p">)</code>&#13;
&#13;
<code class="n">kMeans_inertia</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code><code class="n">index</code><code class="o">=</code><code class="nb">range</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code class="mi">31</code><code class="p">),</code> \&#13;
                              <code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'inertia'</code><code class="p">])</code>&#13;
&#13;
<code class="n">overallAccuracy_kMeansDF</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="p">[],</code> \&#13;
    <code class="n">index</code><code class="o">=</code><code class="nb">range</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code class="mi">31</code><code class="p">),</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'overallAccuracy'</code><code class="p">])</code>&#13;
&#13;
<code class="k">for</code> <code class="n">n_clusters</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code class="mi">31</code><code class="p">):</code>&#13;
    <code class="n">kmeans</code> <code class="o">=</code> <code class="n">KMeans</code><code class="p">(</code><code class="n">n_clusters</code><code class="o">=</code><code class="n">n_clusters</code><code class="p">,</code> <code class="n">n_init</code><code class="o">=</code><code class="n">n_init</code><code class="p">,</code> \&#13;
                    <code class="n">max_iter</code><code class="o">=</code><code class="n">max_iter</code><code class="p">,</code> <code class="n">tol</code><code class="o">=</code><code class="n">tol</code><code class="p">,</code> \&#13;
                    <code class="n">random_state</code><code class="o">=</code><code class="n">random_state</code><code class="p">,</code> <code class="n">n_jobs</code><code class="o">=</code><code class="n">n_jobs</code><code class="p">)</code>&#13;
&#13;
    <code class="n">kmeans</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>&#13;
    <code class="n">kMeans_inertia</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">n_clusters</code><code class="p">]</code> <code class="o">=</code> <code class="n">kmeans</code><code class="o">.</code><code class="n">inertia_</code>&#13;
    <code class="n">X_train_kmeansClustered</code> <code class="o">=</code> <code class="n">kmeans</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>&#13;
    <code class="n">X_train_kmeansClustered</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code> \&#13;
        <code class="n">X_train_kmeansClustered</code><code class="p">,</code> <code class="n">index</code><code class="o">=</code><code class="n">X_train</code><code class="o">.</code><code class="n">index</code><code class="p">,</code> \&#13;
        <code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'cluster'</code><code class="p">])</code>&#13;
&#13;
    <code class="n">countByCluster_kMeans</code><code class="p">,</code> <code class="n">countByLabel_kMeans</code><code class="p">,</code> \&#13;
    <code class="n">countMostFreq_kMeans</code><code class="p">,</code> <code class="n">accuracyDF_kMeans</code><code class="p">,</code> \&#13;
    <code class="n">overallAccuracy_kMeans</code><code class="p">,</code> <code class="n">accuracyByLabel_kMeans</code> <code class="o">=</code> \&#13;
    <code class="n">analyzeCluster</code><code class="p">(</code><code class="n">X_train_kmeansClustered</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>&#13;
&#13;
    <code class="n">overallAccuracy_kMeansDF</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">n_clusters</code><code class="p">]</code> <code class="o">=</code> \&#13;
        <code class="n">overallAccuracy_kMeans</code>&#13;
&#13;
<code class="n">overallAccuracy_kMeansDF</code><code class="o">.</code><code class="n">plot</code><code class="p">()</code></pre>&#13;
&#13;
<p><a data-type="xref" href="#overall_accuracy_for_different_ks_using_k_means">Figure 6-1</a> displays the plot of the results.</p>&#13;
&#13;
<figure><div class="figure" id="overall_accuracy_for_different_ks_using_k_means">&#13;
<img alt="Overall Accuracy for Different Ks using K-means" src="assets/hulp_0601.png"/>&#13;
<h6><span class="label">Figure 6-1. </span>Overall accuracy for different k measures using k-means</h6>&#13;
</div></figure>&#13;
&#13;
<p>As we can see, the accuracy is best around 30 clusters and levels out there at approximately 39%. In other words, for any given cluster, the most-frequently occurring label for that cluster applies to approximately 39% of the borrowers. The remaining 61% of the borrowers have labels that are not the most-frequently occurring.</p>&#13;
&#13;
<p>The following code displays the accuracy by cluster for <em>k</em> = 30:</p>&#13;
&#13;
<pre data-type="programlisting">0      0.326633&#13;
1      0.258993&#13;
2      0.292240&#13;
3      0.234242&#13;
4      0.388794&#13;
5      0.325654&#13;
6      0.303797&#13;
7      0.762116&#13;
8      0.222222&#13;
9      0.391381&#13;
10     0.292910&#13;
11     0.317533&#13;
12     0.206897&#13;
13     0.312709&#13;
14     0.345233&#13;
15     0.682208&#13;
16     0.327250&#13;
17     0.366605&#13;
18     0.234783&#13;
19     0.288757&#13;
20     0.500000&#13;
21     0.375466&#13;
22     0.332203&#13;
23     0.252252&#13;
24     0.338509&#13;
25     0.232000&#13;
26     0.464418&#13;
27     0.261583&#13;
28     0.376327&#13;
29     0.269129&#13;
dtype: float64</pre>&#13;
&#13;
<p>The accuracy varies quite a bit cluster to cluster. Some clusters are much more homogeneous than others. For example, cluster 7 has an accuracy of 76%, while cluster 12 has an accuracy of just 21%. This is a starting point to build a clustering application to automatically assign new borrowers that apply for a Lending Club loan into a preexisting group based on how similar they are to other borrowers. Based on this <span class="keep-together">clustering</span>, it is possible to automatically assign a tentative numerical loan grade to the new borrower, which will be correct approximately 39% of the time.</p>&#13;
&#13;
<p>This is not the best possible solution, and we should consider whether acquiring more data, performing more feature engineering and selection, selecting different parameters for the <em>k</em>-means algorithm, or changing to a different clustering algorithm will improve the results. It is possible that we do not have enough data to meaningfully separate the borrowers into distinct and homogeneous groups more than we have already; if this is the case, more data and more feature engineering and selection are required. Or, it could be that, for the limited data that we have, <em>k</em>-means is not best for performing this separation.</p>&#13;
&#13;
<p>Let’s switch to hierarchical clustering to see if our results improve.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Hierarchical Clustering Application" data-type="sect1"><div class="sect1" id="idm140637543594720">&#13;
<h1>Hierarchical Clustering Application</h1>&#13;
&#13;
<p>Recall<a data-primary="hierarchical clustering" data-secondary="group segmentation" data-type="indexterm" id="HCgroup06"/><a data-primary="group segmentation" data-secondary="hierarchical clustering" data-type="indexterm" id="GShierarch06"/> that in hierarchical clustering we do not need to precommit to a particular number of clusters. Instead, we can choose how many clusters we would like after the hierarchical clustering has finished running. Hierarchical clustering will build a dendrogram, which can be conceptually viewed as an upside-down tree. The leaves at the very bottom are the individual borrowers that apply for loans on Lending Club.</p>&#13;
&#13;
<p>Hierarchical clustering joins the borrowers together as we move vertically up the upside-down tree based on how similar they are to each other. The borrowers that are most similar to each other are joined sooner, while borrowers that are not as similar are joined much later. Eventually, all the borrowers are joined together at the very top—the trunk—of the upside-down tree.</p>&#13;
&#13;
<p>From a business perspective, this clustering process is clearly very powerful. If we are able to find borrowers that are similar to each other and group them together, we can more efficiently assign creditworthiness ratings to them. We can also have specific strategies for distinct groups of borrowers and better manage them from a relationship perspective, providing better overall client service.</p>&#13;
&#13;
<p>Once the hierarchical clustering algorithm finishes running, we can determine where we want to cut the tree. The lower we cut, the more groups of borrowers we are left with.</p>&#13;
&#13;
<p>Let’s first train the hierarchical clustering algorithm like we did in <a data-type="xref" href="ch05.html#Chapter_5">Chapter 5</a>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">fastcluster</code>&#13;
<code class="kn">from</code> <code class="nn">scipy.cluster.hierarchy</code> <code class="kn">import</code> <code class="n">dendrogram</code>&#13;
<code class="kn">from</code> <code class="nn">scipy.cluster.hierarchy</code> <code class="kn">import</code> <code class="n">cophenet</code>&#13;
<code class="kn">from</code> <code class="nn">scipy.spatial.distance</code> <code class="kn">import</code> <code class="n">pdist</code>&#13;
&#13;
<code class="n">Z</code> <code class="o">=</code> <code class="n">fastcluster</code><code class="o">.</code><code class="n">linkage_vector</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">method</code><code class="o">=</code><code class="s1">'ward'</code><code class="p">,</code> \&#13;
                               <code class="n">metric</code><code class="o">=</code><code class="s1">'euclidean'</code><code class="p">)</code>&#13;
&#13;
<code class="n">Z_dataFrame</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">Z</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'clusterOne'</code><code class="p">,</code> \&#13;
                <code class="s1">'clusterTwo'</code><code class="p">,</code><code class="s1">'distance'</code><code class="p">,</code><code class="s1">'newClusterSize'</code><code class="p">])</code></pre>&#13;
&#13;
<p><a data-type="xref" href="#bottom_most_leaves_of_hierarchical_clustering">Table 6-4</a> shows what the output dataframe looks like. The first few rows are the initial linkages of the bottom-most borrowers.</p>&#13;
<table id="bottom_most_leaves_of_hierarchical_clustering">&#13;
<caption><span class="label">Table 6-4. </span>Bottom-most leaves of hierarchical clustering</caption>&#13;
<thead>&#13;
<tr>&#13;
<th/>&#13;
<th>clusterOne</th>&#13;
<th>clusterTwo</th>&#13;
<th>distance</th>&#13;
<th>newClusterSize</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>0</p></td>&#13;
<td><p>39786.0</p></td>&#13;
<td><p>39787.0</p></td>&#13;
<td><p>0.000000e+00</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>1</p></td>&#13;
<td><p>39788.0</p></td>&#13;
<td><p>42542.0</p></td>&#13;
<td><p>0.000000e+00</p></td>&#13;
<td><p>3.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>2</p></td>&#13;
<td><p>42538.0</p></td>&#13;
<td><p>42539.0</p></td>&#13;
<td><p>0.000000e+00</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>3</p></td>&#13;
<td><p>42540.0</p></td>&#13;
<td><p>42544.0</p></td>&#13;
<td><p>0.000000e+00</p></td>&#13;
<td><p>3.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>4</p></td>&#13;
<td><p>42541.0</p></td>&#13;
<td><p>42545.0</p></td>&#13;
<td><p>3.399350e-17</p></td>&#13;
<td><p>4.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>5</p></td>&#13;
<td><p>42543.0</p></td>&#13;
<td><p>42546.0</p></td>&#13;
<td><p>5.139334e-17</p></td>&#13;
<td><p>7.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>6</p></td>&#13;
<td><p>33251.0</p></td>&#13;
<td><p>33261.0</p></td>&#13;
<td><p>1.561313e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>7</p></td>&#13;
<td><p>42512.0</p></td>&#13;
<td><p>42535.0</p></td>&#13;
<td><p>3.342654e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>8</p></td>&#13;
<td><p>42219.0</p></td>&#13;
<td><p>42316.0</p></td>&#13;
<td><p>3.368231e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>9</p></td>&#13;
<td><p>6112.0</p></td>&#13;
<td><p>21928.0</p></td>&#13;
<td><p>3.384368e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>10</p></td>&#13;
<td><p>33248.0</p></td>&#13;
<td><p>33275.0</p></td>&#13;
<td><p>3.583819e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>11</p></td>&#13;
<td><p>33253.0</p></td>&#13;
<td><p>33265.0</p></td>&#13;
<td><p>3.595331e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>12</p></td>&#13;
<td><p>33258.0</p></td>&#13;
<td><p>42552.0</p></td>&#13;
<td><p>3.719377e-01</p></td>&#13;
<td><p>3.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>13</p></td>&#13;
<td><p>20430.0</p></td>&#13;
<td><p>23299.0</p></td>&#13;
<td><p>3.757307e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>14</p></td>&#13;
<td><p>5455.0</p></td>&#13;
<td><p>32845.0</p></td>&#13;
<td><p>3.828709e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>15</p></td>&#13;
<td><p>28615.0</p></td>&#13;
<td><p>30306.0</p></td>&#13;
<td><p>3.900294e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>16</p></td>&#13;
<td><p>9056 .0</p></td>&#13;
<td><p>9769.0</p></td>&#13;
<td><p>3.967378e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>17</p></td>&#13;
<td><p>11162.0</p></td>&#13;
<td><p>13857.0</p></td>&#13;
<td><p>3.991124e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>18</p></td>&#13;
<td><p>33270.0</p></td>&#13;
<td><p>42548.0</p></td>&#13;
<td><p>3.995620e-01</p></td>&#13;
<td><p>3.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>19</p></td>&#13;
<td><p>17422.0</p></td>&#13;
<td><p>17986.0</p></td>&#13;
<td><p>4.061704e-01</p></td>&#13;
<td><p>2.0</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Recall that the last few rows represent the top of the upside-down tree, and all 42,541 borrowers are combined together eventually (see <a data-type="xref" href="#topmost_leaves_of_hierarchical_clustering">Table 6-5</a>).</p>&#13;
<table id="topmost_leaves_of_hierarchical_clustering">&#13;
<caption><span class="label">Table 6-5. </span>Top-most leaves of hierarchical clustering</caption>&#13;
<thead>&#13;
<tr>&#13;
<th/>&#13;
<th>clusterOne</th>&#13;
<th>clusterTwo</th>&#13;
<th>distance</th>&#13;
<th>newClusterSize</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>42521</p></td>&#13;
<td><p>85038.0</p></td>&#13;
<td><p>85043.0</p></td>&#13;
<td><p>132.715723</p></td>&#13;
<td><p>3969.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42522</p></td>&#13;
<td><p>85051.0</p></td>&#13;
<td><p>85052.0</p></td>&#13;
<td><p>141.386569</p></td>&#13;
<td><p>2899.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42532</p></td>&#13;
<td><p>85026.0</p></td>&#13;
<td><p>85027.0</p></td>&#13;
<td><p>146.976703</p></td>&#13;
<td><p>2351.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42524</p></td>&#13;
<td><p>85048.0</p></td>&#13;
<td><p>85049.0</p></td>&#13;
<td><p>152.660192</p></td>&#13;
<td><p>5691.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42525</p></td>&#13;
<td><p>85036.0</p></td>&#13;
<td><p>85059.0</p></td>&#13;
<td><p>153.512281</p></td>&#13;
<td><p>5956.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42526</p></td>&#13;
<td><p>85033.0</p></td>&#13;
<td><p>85044.0</p></td>&#13;
<td><p>160.825959</p></td>&#13;
<td><p>2203.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42527</p></td>&#13;
<td><p>85055.0</p></td>&#13;
<td><p>85061.0</p></td>&#13;
<td><p>163.701428</p></td>&#13;
<td><p>668.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42528</p></td>&#13;
<td><p>85062.0</p></td>&#13;
<td><p>85066.0</p></td>&#13;
<td><p>168.199295</p></td>&#13;
<td><p>6897.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42529</p></td>&#13;
<td><p>85054.0</p></td>&#13;
<td><p>85060.0</p></td>&#13;
<td><p>168.924039</p></td>&#13;
<td><p>9414.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42530</p></td>&#13;
<td><p>85028.0</p></td>&#13;
<td><p>85064.0</p></td>&#13;
<td><p>185.215769</p></td>&#13;
<td><p>3118.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42531</p></td>&#13;
<td><p>85067.0</p></td>&#13;
<td><p>85071.0</p></td>&#13;
<td><p>187.832588</p></td>&#13;
<td><p>15370.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42532</p></td>&#13;
<td><p>85056.0</p></td>&#13;
<td><p>85073.0</p></td>&#13;
<td><p>203.212147</p></td>&#13;
<td><p>17995.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42533</p></td>&#13;
<td><p>85057.0</p></td>&#13;
<td><p>85063.0</p></td>&#13;
<td><p>205.285993</p></td>&#13;
<td><p>9221.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42534</p></td>&#13;
<td><p>85068.0</p></td>&#13;
<td><p>85072.0</p></td>&#13;
<td><p>207.902660</p></td>&#13;
<td><p>5321.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42535</p></td>&#13;
<td><p>85069.0</p></td>&#13;
<td><p>85075.0</p></td>&#13;
<td><p>236.754581</p></td>&#13;
<td><p>9889.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42536</p></td>&#13;
<td><p>85070.0</p></td>&#13;
<td><p>85077.0</p></td>&#13;
<td><p>298.587755</p></td>&#13;
<td><p>16786.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42537</p></td>&#13;
<td><p>85058.0</p></td>&#13;
<td><p>85078.0</p></td>&#13;
<td><p>309.946867</p></td>&#13;
<td><p>16875.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42538</p></td>&#13;
<td><p>85074.0</p></td>&#13;
<td><p>85079.0</p></td>&#13;
<td><p>375.698458</p></td>&#13;
<td><p>34870.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42539</p></td>&#13;
<td><p>85065.0</p></td>&#13;
<td><p>85080.0</p></td>&#13;
<td><p>400.711547</p></td>&#13;
<td><p>37221.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>42504</p></td>&#13;
<td><p>85076.0</p></td>&#13;
<td><p>85081.0</p></td>&#13;
<td><p>644.047472</p></td>&#13;
<td><p>42542.0</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Now, let’s cut the dendrogram so that we are left with a manageable number of clusters. This is set based on the <code>distance_threshold</code>. Based on trial and error, a <code>distance_threshold</code> of 100 results in 32 clusters, which is what we will use for this example.</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">scipy.cluster.hierarchy</code> <code class="kn">import</code> <code class="n">fcluster</code>&#13;
<code class="n">distance_threshold</code> <code class="o">=</code> <code class="mi">100</code>&#13;
<code class="n">clusters</code> <code class="o">=</code> <code class="n">fcluster</code><code class="p">(</code><code class="n">Z</code><code class="p">,</code> <code class="n">distance_threshold</code><code class="p">,</code> <code class="n">criterion</code><code class="o">=</code><code class="s1">'distance'</code><code class="p">)</code>&#13;
<code class="n">X_train_hierClustered</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">clusters</code><code class="p">,</code>&#13;
 <code class="n">index</code><code class="o">=</code><code class="n">X_train_PCA</code><code class="o">.</code><code class="n">index</code><code class="p">,</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'cluster'</code><code class="p">])</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="s2">"Number of distinct clusters: "</code><code class="p">,</code>&#13;
 <code class="nb">len</code><code class="p">(</code><code class="n">X_train_hierClustered</code><code class="p">[</code><code class="s1">'cluster'</code><code class="p">]</code><code class="o">.</code><code class="n">unique</code><code class="p">()))</code></pre>&#13;
&#13;
<p>The number of distinct clusters given the distance threshold we picked is 32:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">countByCluster_hierClust</code><code class="p">,</code> <code class="n">countByLabel_hierClust</code><code class="p">,</code> <code class="n">countMostFreq_hierClust</code><code class="p">,</code>&#13;
 <code class="n">accuracyDF_hierClust</code><code class="p">,</code> <code class="n">overallAccuracy_hierClust</code><code class="p">,</code> <code class="n">accuracyByLabel_hierClust</code> <code class="o">=</code>&#13;
 <code class="n">analyzeCluster</code><code class="p">(</code><code class="n">X_train_hierClustered</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="s2">"Overall accuracy from hierarchical clustering: "</code><code class="p">,</code>&#13;
 <code class="n">overallAccuracy_hierClust</code><code class="p">)</code></pre>&#13;
&#13;
<p>The following code shows the overall accuracy of hierarchical clustering:</p>&#13;
&#13;
<pre data-type="programlisting">Overall accuracy from hierarchical clustering: 0.3651685393258427</pre>&#13;
&#13;
<p>The overall accuracy is approximately 37%, a bit worse than with <em>k</em>-means clustering. That being said, hierarchical clustering works differently than <em>k</em>-means and may group some borrowers more accurately than <em>k</em>-means, while <em>k</em>-means may group other borrowers more accurately than hierarchical clustering.</p>&#13;
&#13;
<p>In other words, the two clustering algorithms may complement each other, and this is worth exploring by ensembling the two and assessing the ensemble’s results compared to the results of either standalone solution.<sup><a data-type="noteref" href="ch06.html#idm140637542559056" id="idm140637542559056-marker">2</a></sup> As<a data-primary="" data-startref="HCgroup06" data-type="indexterm" id="idm140637542556704"/><a data-primary="" data-startref="GShierarch06" data-type="indexterm" id="idm140637542555760"/> with <em>k</em>-means, the accuracy varies quite a bit across the clusters. Some clusters are much more homogeneous than others:</p>&#13;
&#13;
<pre data-type="programlisting">Accuracy by cluster for hierarchical clustering&#13;
&#13;
0      0.304124&#13;
1      0.219001&#13;
2      0.228311&#13;
3      0.379722&#13;
4      0.240064&#13;
5      0.272011&#13;
6      0.314560&#13;
7      0.263930&#13;
8      0.246138&#13;
9      0.318942&#13;
10     0.302752&#13;
11     0.269772&#13;
12     0.335717&#13;
13     0.330403&#13;
14     0.346320&#13;
15     0.440141&#13;
16     0.744155&#13;
17     0.502227&#13;
18     0.294118&#13;
19     0.236111&#13;
20     0.254727&#13;
21     0.241042&#13;
22     0.317979&#13;
23     0.308771&#13;
24     0.284314&#13;
25     0.243243&#13;
26     0.500000&#13;
27     0.289157&#13;
28     0.365283&#13;
29     0.479693&#13;
30     0.393559&#13;
31     0.340875</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="HDBSCAN Application" data-type="sect1"><div class="sect1" id="idm140637543213968">&#13;
<h1>HDBSCAN Application</h1>&#13;
&#13;
<p>Now let’s<a data-primary="group segmentation" data-secondary="HDBSCAN (hierarchical DBSCAN)" data-type="indexterm" id="idm140637542551520"/><a data-primary="HDBSCAN (hierarchical DBSCAN)" data-type="indexterm" id="idm140637542550496"/> turn to HDBSCAN and apply this clustering algorithm to group similar borrowers in this Lending Club dataset.</p>&#13;
&#13;
<p>Recall that HDBSCAN will group borrowers together based on how closely packed together their attributes are in a high-dimensional space. Unlike <em>k</em>-means or hierarchical clustering, not all the borrowers will be grouped. Some borrowers that are very distinct from other groups of borrowers may remain ungrouped. These are outlier borrowers and are worth investigating to see if there is a good business reason they are dissimilar from other borrowers. It may be possible to automatically assign numerical loan grades to some groups of borrowers but other borrowers—those that are dissimilar—may require a more nuanced credit-scoring approach.</p>&#13;
&#13;
<p>Let’s see how well HDBSCAN does:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">hdbscan</code>&#13;
&#13;
<code class="n">min_cluster_size</code> <code class="o">=</code> <code class="mi">20</code>&#13;
<code class="n">min_samples</code> <code class="o">=</code> <code class="mi">20</code>&#13;
<code class="n">alpha</code> <code class="o">=</code> <code class="mf">1.0</code>&#13;
<code class="n">cluster_selection_method</code> <code class="o">=</code> <code class="s1">'leaf'</code>&#13;
&#13;
<code class="n">hdb</code> <code class="o">=</code> <code class="n">hdbscan</code><code class="o">.</code><code class="n">HDBSCAN</code><code class="p">(</code><code class="n">min_cluster_size</code><code class="o">=</code><code class="n">min_cluster_size</code><code class="p">,</code> \&#13;
    <code class="n">min_samples</code><code class="o">=</code><code class="n">min_samples</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="n">alpha</code><code class="p">,</code> \&#13;
    <code class="n">cluster_selection_method</code><code class="o">=</code><code class="n">cluster_selection_method</code><code class="p">)</code>&#13;
&#13;
<code class="n">X_train_hdbscanClustered</code> <code class="o">=</code> <code class="n">hdb</code><code class="o">.</code><code class="n">fit_predict</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>&#13;
<code class="n">X_train_hdbscanClustered</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="o">=</code> \&#13;
    <code class="n">X_train_hdbscanClustered</code><code class="p">,</code> <code class="n">index</code><code class="o">=</code><code class="n">X_train</code><code class="o">.</code><code class="n">index</code><code class="p">,</code> \&#13;
    <code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'cluster'</code><code class="p">])</code>&#13;
&#13;
<code class="n">countByCluster_hdbscan</code><code class="p">,</code> <code class="n">countByLabel_hdbscan</code><code class="p">,</code> \&#13;
    <code class="n">countMostFreq_hdbscan</code><code class="p">,</code> <code class="n">accuracyDF_hdbscan</code><code class="p">,</code> \&#13;
    <code class="n">overallAccuracy_hdbscan</code><code class="p">,</code> <code class="n">accuracyByLabel_hdbscan</code> <code class="o">=</code> \&#13;
    <code class="n">analyzeCluster</code><code class="p">(</code><code class="n">X_train_hdbscanClustered</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code></pre>&#13;
&#13;
<p>The following code shows the overall accuracy for HDBSCAN:</p>&#13;
&#13;
<pre data-type="programlisting">Overall accuracy from HDBSCAN: 0.3246203751586667</pre>&#13;
&#13;
<p>As seen here, the overall accuracy is approximately 32%, worse than that of either <em>k</em>-means or hierarchical clustering.</p>&#13;
&#13;
<p><a data-type="xref" href="#cluster_results_for_hdbscan_chap_six">Table 6-6</a> shows the various clusters and their cluster sizes.</p>&#13;
<table id="cluster_results_for_hdbscan_chap_six">&#13;
<caption><span class="label">Table 6-6. </span>Cluster results for HDBSCAN</caption>&#13;
<thead>&#13;
<tr>&#13;
<th/>&#13;
<th>cluster</th>&#13;
<th>clusterCount</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>0</p></td>&#13;
<td><p>–1</p></td>&#13;
<td><p>32708</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>1</p></td>&#13;
<td><p>7</p></td>&#13;
<td><p>4070</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>2</p></td>&#13;
<td><p>2</p></td>&#13;
<td><p>3668</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>3</p></td>&#13;
<td><p>1</p></td>&#13;
<td><p>1096</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>4</p></td>&#13;
<td><p>4</p></td>&#13;
<td><p>773</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>5</p></td>&#13;
<td><p>0</p></td>&#13;
<td><p>120</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>6</p></td>&#13;
<td><p>6</p></td>&#13;
<td><p>49</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>7</p></td>&#13;
<td><p>3</p></td>&#13;
<td><p>38</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>8</p></td>&#13;
<td><p>5</p></td>&#13;
<td><p>20</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>32,708 of the borrowers are in cluster -1, which means they are ungrouped.</p>&#13;
&#13;
<p>The following shows the accuracy by cluster:</p>&#13;
&#13;
<pre data-type="programlisting">0       0.284487&#13;
1       0.341667&#13;
2       0.414234&#13;
3       0.332061&#13;
4       0.552632&#13;
5       0.438551&#13;
6       0.400000&#13;
7       0.408163&#13;
8       0.590663</pre>&#13;
&#13;
<p>Among these clusters, the accuracy ranges from 28% to 59%.<a data-primary="" data-startref="ULscikit03" data-type="indexterm" id="idm140637542514640"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm140637542552624">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>In this chapter, we built an unsupervised clustering application based on borrowers that applied for unsecured personal loans on Lending Club from 2007-2011. The applications were based on <em>k</em>-means, hierarchical clustering, and hierarchical DBSCAN. <em>k</em>-means performed the best, scoring an approximately 39% overall accuracy.</p>&#13;
&#13;
<p>While these applications performed okay, they can be improved quite a bit. You should experiment with these algorithms to improve the solution from here.</p>&#13;
&#13;
<p>This concludes the unsupervised learning using Scikit-Learn portion of the book. Next, we will explore neural network-based forms of unsupervised learning using TensorFlow and Keras.<a data-primary="" data-startref="SCLgroup06" data-type="indexterm" id="idm140637542510128"/> We will start with representation learning and autoencoders in <a data-type="xref" href="ch07.html#Chapter_7">Chapter 7</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm140637543541600"><sup><a href="ch06.html#idm140637543541600-marker">1</a></sup> We can ignore grade “7,” which corresponds to loan grade “Z.” These are the loans with missing loan grades that we had to fill in.</p><p data-type="footnote" id="idm140637542559056"><sup><a href="ch06.html#idm140637542559056-marker">2</a></sup> We explored ensembling in <a data-type="xref" href="ch02.html#Chapter_2">Chapter 2</a>. Refer back to <a data-type="xref" href="ch02.html#ensembles">“Ensembles”</a> if you need a refresher.</p></div></div></section></body></html>