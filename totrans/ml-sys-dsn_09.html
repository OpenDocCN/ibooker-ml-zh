<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div class="readable-text" id="p1"> 
   <h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">8</span> </span> <span class="chapter-title-text">Baseline solution</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header sigil_not_in_toc">This chapter covers</h3> 
   <ul> 
    <li class="readable-text" id="p2">What is the baseline?</li> 
    <li class="readable-text" id="p3">Constant baselines</li> 
    <li class="readable-text" id="p4">Model baselines and feature baselines</li> 
    <li class="readable-text" id="p5">A variety of deep learning baselines</li> 
    <li class="readable-text" id="p6">Baseline comparison</li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p7"> 
   <blockquote>
    <div>
     Everything should be made as simple as possible, but not simpler. 
     <div class=" quote-cite">
       — Albert Einstein 
     </div>
    </div>
   </blockquote> 
  </div> 
  <div class="readable-text" id="p8"> 
   <p>When we start to think about the building blocks of our future machine learning (ML) system, the essential part of it, or core component of it, seems to be a model built using ML techniques. In some sense, this is so true that we may even think that “this is it: this is the primary point where I should spend most of my time, energy, and creative power.”</p> 
  </div> 
  <div class="readable-text intended-text" id="p9"> 
   <p>But in reality, this may turn out to be a trap that the majority of ML projects fall into and get bogged down in without ever reaching production. An ML model is not necessarily the most important thing in the context of an ML system and its design document. Although the temptation is great, you should always keep in mind that it is extremely easy to spend a lot of time, team effort, and, more importantly, money on building a cool, modern, and sophisticated AI model that doesn’t ever bring any value to users and your company. A mediocre model in production is usually better than a great model on paper.</p> 
  </div> 
  <div class="readable-text intended-text" id="p10"> 
   <p>One of the first versions of this book’s title was <em>Machine Learning System Design That Works</em>, and it corresponds to the primary goal of any ML project, which is to build a system that will work; only then, when it brings profit, will we start to iteratively improve it while gradually increasing its complexity (if needed). In this chapter, we will discuss the baseline solution, the first step in bringing our system to life. We will cover why baselines are needed, as well as the purpose of building them. We will go all the way from constant baselines to sophisticated specialized models and also through various feature baselines.</p> 
  </div> 
  <div class="readable-text" id="p11"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_75"><span class="num-string">8.1</span> Baseline: What are you? </h2> 
  </div> 
  <div class="readable-text" id="p12"> 
   <p>A baseline is the simplest possible (but working!) version of a model, feature set, or anything else in your system. It’s the minimum viable product (MVP) in the world of ML systems that brings value from the start without yet diving into complexity. Let’s elaborate a bit more on the MVP analogy by outlining key goals that may equally apply to both:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p13"> <em>Reduce the maximum risk with the lowest amount of time, cost, and effort invested in a product</em>. At the beginning of the product’s life, it is still unclear whether the market needs it, what use cases the product will have, whether the economy will converge, and so on. To a large extent, these risks are peculiar to ML products, too. In a way, a baseline (or MVP) is the easiest way to test a hypothesis that lies at the heart of your product. </li> 
   <li class="readable-text" id="p14"> <em>Get early feedback</em>. This is the fail-fast principle cut down to the product scale. If the whole idea of your ML system is wrong, you can see it at an early stage, rethink the entire plan, rewrite the design document with new knowledge, and start anew. </li> 
   <li class="readable-text" id="p15"> <em>Bring user value as soon as possible</em>. Each company aims to generate revenue by making its customers happy. If we can bring value to customers early with a baseline and then update it stage by stage while generating a predictable amount of money, why not do this? It will leave everyone in the equation satisfied. </li> 
  </ul> 
  <div class="readable-text" id="p16"> 
   <p>These three points form the grand basis of similarities between a baseline and an MVP. However, there are three more purely baseline-specific goals: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p17"> <em>A placeholder to check that components work properly</em><em> </em>—Baselines are like smoke tests. As Cem Kaner, James Bach, and Brett Pettichord once said in their <em>Lessons Learned in Software Testing</em>, the phrase “smoke test” comes from electronic hardware testing. You plug in a new board and turn on the power. If you see smoke coming from the board, turn off the power. You don’t have to do any more testing. <br/>First you want to check whether the system works and, second, whether it works correctly. To “compile” the whole system, you don’t need a powerful ML model. You need something that predicts something with the required format, optionally, based on something. Why not choose the easiest possible alternative? </li> 
  </ul> 
  <ul> 
   <li class="readable-text" id="p19"> <em>A thing to compare with</em><em> </em>—Shall we go further and think about how much our investment in the model could pay in the future? The baseline is a “base line.” It is the origin of the coordinate plane—something we compare new models with in terms of some metrics. <br/>When working in the industry, the model’s performance is not the only metric by which we compare models. Others require effort, interpretability, maintainability, and so on. We’ll cover them in section 8.5. </li> 
  </ul> 
  <ul> 
   <li class="readable-text" id="p21"> <em>A fallback answer</em><em> </em>—Unlike MVP, when we move on to its second and subsequent versions, we don’t throw out the baseline completely. It is good practice when it lives in parallel with the sophisticated model. The system switches to the baseline response when this primary model goes south while making a prediction. </li> 
  </ul> 
  <div class="readable-text" id="p22"> 
   <p>So what are the advantages of a well-chosen baseline? Simplicity automatically brings a lot of pros with it: it is robust, not prone to unexpected behavior and overfitting (due to fewer degrees of freedom), easy to build and maintain, and not too pressing on computing resources. Consequently, baselines are easy to scale. As an additional bonus, from non-ML colleagues’ perspective, simple models are easier to interpret and make it less difficult to understand what is going on under the hood. It can help increase trust in our ML product, which can be critical when the stakes are high. However, simplicity is not a goal by itself but a valuable property.</p> 
  </div> 
  <div class="readable-text intended-text" id="p23"> 
   <p>If we think of our ML system as a Lego model, a baseline is an opportunity to assemble all the other blocks as fast as possible. Still, we encourage you to make your system as modular (i.e., “orthogonal”) as possible by design. This will make later updates easier, including the transition to more complex models and features (initial design doesn’t dictate how fast you can update a system in the future). The initial system should be simple and agile, not trivial or restricted, with a baseline.</p> 
  </div> 
  <div class="readable-text intended-text" id="p24"> 
   <p>Still, despite all the advantages baselines provide without requiring a lot, they are not used as often as they deserve. The bitter truth is that, unfortunately, complexity sells better. There is a brilliant article from Eugene Yan that we strongly recommend reading. It’s called “Simplicity Is an Advantage But Sadly Complexity Sells Better” (<a href="https://eugeneyan.com/writing/simplicity/">https://eugeneyan.com/writing/simplicity/</a>), highlighting the main reasons why many choose complexity over simplicity, which are:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p25"> Complexity signals effort. </li> 
   <li class="readable-text" id="p26"> Complexity signals mastery. </li> 
   <li class="readable-text" id="p27"> Complexity signals innovation. </li> 
   <li class="readable-text" id="p28"> Complexity signals more features. </li> 
  </ul> 
  <div class="readable-text" id="p29"> 
   <p>This leads to complexity bias, where we give undue credit to and favor complex ideas and systems over simpler solutions.</p> 
  </div> 
  <div class="readable-text intended-text" id="p30"> 
   <p>Of course, baselines are not a silver bullet, and there are reasonable cases when baselines are not necessary or are even irrelevant:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p31"> <em>Accuracy is crucial</em>. In many cases, an error of a couple of percentage points will not even be noticed. But if we can’t afford decreased quality—for example, in some medical applications like cancer detection or when dealing with autonomous cars—a baseline will be a bad life-saving rope. In this case, explicit switching to manual control would be a better idea. </li> 
   <li class="readable-text" id="p32"> <em>There is a high degree of certainty</em>. We clearly understand what the user wants (for example, based on a competitor’s experience), or we have our own experience of implementing identical systems. In this case, we don’t need to reinvent the wheel and waste our time on gradual iterations if we have a plan already proven in battle and can just copy-paste the system. </li> 
   <li class="readable-text" id="p33"> <em>We are rebuilding an already-working system</em>. Suppose we already have a working search engine based on the deep semantic similarity model (DSSM) architecture. The whole pipeline is already implemented and tested. So when it consistently brings value to users, it is a good time for optimization in terms of speed and accuracy—for example, by switching to a Transformer-based model. It is not the right place to think about baselines because the old version is effectively a baseline. </li> 
  </ul> 
  <div class="readable-text" id="p34"> 
   <p>Still, we believe that even if complexity at an early stage can be justified in certain cases, it can’t be the go-to solution by default because it incentivizes people to make things unnecessarily complicated; it encourages the “not invented here” mindset, where people prefer to build from scratch and avoid reusing existing components even though it saves time and effort, and it wastes time and resources while often leading to poorer outcomes.</p> 
  </div> 
  <div class="readable-text intended-text" id="p35"> 
   <p>That is why we believe a baseline solution is the first thing to do, with incremental improvements where and when needed.</p> 
  </div> 
  <div class="readable-text" id="p36"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_76"><span class="num-string">8.2</span> Constant baselines</h2> 
  </div> 
  <div class="readable-text" id="p37"> 
   <p>A good metaphor for a baseline is building a bridge: sometimes you don’t need a team of bridge construction engineers, huge budgets, plans, or years to build it. Sometimes you just need a stably fixed log. A baseline is the very log that allows you to connect components and solve a given task at a minimal scale—in the case of a baseline, a temporary, primitive, easy-to-build solution (see figure 8.1).</p> 
  </div> 
  <div class="readable-text intended-text" id="p38"> 
   <p>The idea we want to convey before going into detail is simple: build a lean, operable ML system first, and improve it later. Think of the complexity of possible solutions as a continuum. Choose an appropriate initial point in this range based on the effort–accuracy tradeoff, and move ahead. Don’t spend too much time on modeling unless it’s necessary.</p> 
  </div> 
  <div class="browsable-container figure-container" id="p39">  
   <img alt="figure" src="../Images/CH08_F01_Babushkin.png" width="1017" height="592"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 8.1</span> Before building a complicated model, start with a primitive baseline, which may well be the most appropriate foundation for your future ML system.<span class="aframe-location"/></h5>
  </div> 
  <div class="readable-text" id="p40"> 
   <p>Keeping in mind that analogy, let’s start the discussion with the most spartan solutions that look like a log bridge. When we initiate a search for a suitable baseline, we often ask ourselves, “What is the most straightforward ML model that could solve the problem?” or “What is the right ML model to start from?” but frequently these questions turn out to be the wrong ones to ask. We believe the right one could sound like, “Do we need ML at all to solve this problem?” </p> 
  </div> 
  <div class="readable-text intended-text" id="p41"> 
   <p>Sometimes we either don’t even need ML for the problem or at least should not reinvent the wheel on our own and can instead use a third-party vendor. We already discussed this alternative in chapter 3 (section 3.2).</p> 
  </div> 
  <div class="readable-text intended-text" id="p42"> 
   <p>But let’s say we decided to build our own model. Good modeling starts with no model at all: with trying to hack a defined metric by picking the most trivial and lazy solution from the solution space. It will be the very first approximation of our problem. You can argue that a constant baseline represents a model by itself. With a constant baseline, we approximate all dependencies and interactions by a constant.</p> 
  </div> 
  <div class="readable-text intended-text" id="p43"> 
   <p>To immediately give an idea of what we are talking about, here are a couple of examples that you already know: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p44"> For regression tasks, constant baselines are average or median predictions (in time-series forecasting, you can take both by last day/week/month/year) by the last available value (e.g., for the corresponding user or item). Also, this could be some user-defined constant that maximizes the metric. </li> 
   <li class="readable-text" id="p45"> For classification tasks, it will be prediction by the major class (let’s say, in the antifraud problem, we can assume that there is no fraud at all) or the constant prediction of the probability of a positive class. </li> 
   <li class="readable-text" id="p46"> For ranking, this could be either a random order of documents or sorting based on an irrelevant numerical property like document ID or a simple heuristic like “number of queried keywords contained in an item description.” </li> 
  </ul> 
  <div class="readable-text" id="p47"> 
   <p>In a way, a constant baseline is like the first term in the Taylor Series or the mean predictor as the first base estimator in gradient boosting (see figure 8.2). Neither even depends on variable x; they already do (although roughly) something related to our problem—no more, no less.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p48">  
   <img alt="figure" src="../Images/CH08_F02_Babushkin.png" width="870" height="178"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 8.2</span> A constant baseline is like the first term of the Taylor Series—the simplest approximation that sets the foundation for more complex models.</h5>
  </div> 
  <div class="readable-text" id="p49"> 
   <h3 class="readable-text-h3" id="sigil_toc_id_77"><span class="num-string">8.2.1</span> Why do we need constant baselines?</h3> 
  </div> 
  <div class="readable-text" id="p50"> 
   <p>There are two goals for building such a baseline. </p> 
  </div> 
  <div class="readable-text intended-text" id="p51"> 
   <p>The first one is benchmarking. It is helpful to get a baseline value of a selected metric for a random prediction. A simple sanity check compares your model against simple rules of thumb. Indeed, it would be sad to do 2 weeks of hardcore ML modeling and then finally implement the most straightforward possible baseline in 5 minutes that beats your model. It sounds ridiculous, but the situation is quite common in real life.</p> 
  </div> 
  <div class="readable-text intended-text" id="p52"> 
   <p>There’s a cool story from Valerii about this case. He was lucky enough to work with an engineer who is a wonderful person and a great specialist. Once, she won an ML competition with the goal of predicting some factory time series with just a constant baseline—or, as she likes to correct him, a stepwise constant. Conducting ML competitions is usually a very straightforward process. Participants have a labeled dataset and an unlabeled dataset. Their goal is to build a model using the labeled dataset that will output predictions to the unlabeled dataset that are the closest to the actual ones (available to the organizers only). Now imagine the frustration of other participants who have been engineering dozens of features for months and tuning parameters of their gradient-boosting models.</p> 
  </div> 
  <div class="readable-text intended-text" id="p53"> 
   <p>This case inspired us to look for and start with the simplest models, and this is something we’d like to encourage everyone to do. Don’t limit yourself to them, though. It will give you a much more adequate understanding of your metric and target values from the beginning so you can get a vision of what can be done with given data and what cannot.</p> 
  </div> 
  <div class="readable-text intended-text" id="p54"> 
   <p>The second goal of constant baselines is to provide a bulletproof fallback. If your real ML model could not make a prediction during runtime, due to some raised error, because of running into response-time constraints, or because there is no history for calculating features (aka the cold start problem with new users and new items)—or it simply goes crazy (which sometimes happens)—your ML service should return at least something. So, in this case, a constant baseline is all you need.</p> 
  </div> 
  <div class="readable-text intended-text" id="p55"> 
   <p>At the same time, we can easily imagine situations where a constant baseline is too primitive and brings no value at all. So the simplest usable baseline should be more complicated, represented as a set of heuristics/regular expressions or as a shallow model. Constant baselines tend to work fine for simple regression/classification problems on tabular or small text data; however, it is impossible to build a chatbot or voice recognition system with a constant baseline.</p> 
  </div> 
  <div class="readable-text" id="p56"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_78"><span class="num-string">8.3</span> Model baselines and feature baselines</h2> 
  </div> 
  <div class="readable-text" id="p57"> 
   <p>If we move further along the complexity scale, our next stop is rule-based models, although it is not always possible to draw a clear line between constant baselines and rule-based ones, as in most cases we can define the last one as a constant on top of some grouping. But there is also another well-known and illustrative example of rule-based baselines: to start solving natural language processing problems with just regular expressions.</p> 
  </div> 
  <div class="readable-text intended-text" id="p58"> 
   <p>A couple of years ago, Arseny worked for a taxi aggregator company, where he was involved in developing a service that would predict the time it would take for the nearest car to get to a client. The problem was apparent: if we overpredicted, the client could decide not to wait and would look for another service; if we underpredicted, the client would wait longer than we promised, which would mean we disappointed them. </p> 
  </div> 
  <div class="readable-text intended-text" id="p59"> 
   <p>Arseny’s colleague, who was a senior engineer at the time, treated it like a standard regression task and started with models like “always predict 5 minutes” or “if borough == ‘manhattan’: return 4.” Long story short: these types of baselines were hard to beat with hardcore ML alchemy, and ironically, the latter was even in production for a while as a fallback.</p> 
  </div> 
  <div class="readable-text intended-text" id="p60"> 
   <p>The “if district == X: return Y” model is an excellent example of a rule-based baseline. We can generate similar models by taking the mean/median/mode of some category or several categories—in our example, the median by location.</p> 
  </div> 
  <div class="readable-text intended-text" id="p61"> 
   <p>The further we go down the progression, the more complex our model gets and the more connections between objects’ properties and the labels it can find. </p> 
  </div> 
  <div class="readable-text intended-text" id="p62"> 
   <p>A typical sequence of baselines in an ML problem would begin with the following: constant baseline, rule-based baseline, and linear model (see figure 8.3). We need something more sophisticated and specialized only if these baselines are insufficient for our task.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p63">  
   <img alt="figure" src="../Images/CH08_F03_Babushkin.png" width="779" height="176"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 8.3</span> A typical sequence of baselines at the early stage of designing your model</h5>
  </div> 
  <div class="readable-text" id="p64"> 
   <p>For example, when building a recommender system, we start with some constant retrieval, then try collaborative filtering (e.g., alternate least squares), factorization machines, and, finally, deep learning (e.g., deep structured semantic model) if needed.</p> 
  </div> 
  <div class="readable-text intended-text" id="p65"> 
   <p>Whatever problem you face, be aware of simple approaches in this field. They don’t necessarily perform worse than more sophisticated ones.</p> 
  </div> 
  <div class="readable-text intended-text" id="p66"> 
   <p>A vivid example of that can be found in the paper called “Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches” by Maurizio Ferrari Dacrema et al. (<a href="https://arxiv.org/abs/1907.06902">https://arxiv.org/abs/1907.06902</a>) that took RecSys’ Best Paper Award in 2019 (<a href="https://recsys.acm.org/best-papers/">https://recsys.acm.org/best-papers/</a>). The paper is notable for unveiling strikingly impressive stats. The research group examined 18 algorithms that had been presented at top-level research conferences in the preceding years. After studying these algorithms, only seven of them could be reproduced with reasonable effort. Things got even more interesting when it turned out that six out of seven algorithms could often be outperformed using relatively simple heuristic methods (e.g., those based on nearest-neighbor or graph-based techniques). The only remaining algorithm clearly outclassed baselines; however, it could not consistently outperform a well-tuned nonneural linear ranking method.</p> 
  </div> 
  <div class="readable-text intended-text" id="p67"> 
   <p>A nonexhaustive list of examples from the already-mentioned Eugene Yan article includes the following:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p68"> Tree-based models (random forest, gradient boosting) in most cases beat deep neural networks on tabular data, especially on small/medium datasets (say, &lt; 1 million) (<a href="https://arxiv.org/abs/2207.08815">https://arxiv.org/abs/2207.08815</a>). </li> 
   <li class="readable-text" id="p69"> Greedy algorithms outperform graph neural networks on combinatorial graph problems (<a href="https://arxiv.org/abs/2206.13211">https://arxiv.org/abs/2206.13211</a>). </li> 
   <li class="readable-text" id="p70"> Simple averaging is often not worse than complex optimizers on multitask learning problems (<a href="https://arxiv.org/abs/2201.04122">https://arxiv.org/abs/2201.04122</a>). </li> 
   <li class="readable-text" id="p71"> A dot product of embeddings outperforms neural collaborative filtering in item recommendation and retrieval (<a href="https://arxiv.org/abs/2005.09683">https://arxiv.org/abs/2005.09683</a>). </li> 
  </ul> 
  <div class="readable-text" id="p72"> 
   <p>Up to now, we have been talking about baselines focusing on models. But what about features? Features are effectively a part of the model and sometimes are even the most important part of it. In classic ML, we have to engineer features manually, and choosing features for a baseline is based on the same principles; we start with a small group of essential features (most likely, those that are easier to calculate). There are two ways of adding new features: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p73"> Engineering new features, which is challenging and time-consuming and requires building new ETL pipelines </li> 
   <li class="readable-text" id="p74"> Generating features that derive from ones that already exist </li> 
  </ul> 
  <div class="readable-text" id="p75"> 
   <p>The sequence of baseline features we need to try should look like this: the original minimum set of features, all sorts of interactions and counters, then embeddings, and then something more complicated (see figure 8.4). </p> 
  </div> 
  <div class="browsable-container figure-container" id="p76">  
   <img alt="figure" src="../Images/CH08_F04_Babushkin.png" width="778" height="166"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 8.4</span> A sequence of baseline features you need to try: from the simplest to the more complicated <span class="aframe-location"/></h5>
  </div> 
  <div class="readable-text" id="p77"> 
   <p>What are the properties of a good bunch of features to start from? The answer is exactly the same as for the models, and we’ll discuss it further.</p> 
  </div> 
  <div class="readable-text intended-text" id="p78"> 
   <p>For a typical problem usually solved with deep learning methods, there can be a simple baseline built with shallow models. As we recall, deep learning is a part of representation learning, which means that instead of handcrafting features, we delegate this work to a neural network. However, for some problems like image or text classification, you can apply naive approaches (rule-based or linear model-based). For example, naive Bayes was a very strong baseline in a natural language processing world before BERT-like architectures emerged. For computer vision, some problems can be solved by using a histogram of pixel color (or even just mean/median value!) as features for a linear model. Having said that, for most scenarios, starting with a simple deep learning model—either foundational in a few-shot setup or a trained one—can be a better choice because these models have already proven themselves in a wide variety of tasks. </p> 
  </div> 
  <div class="readable-text intended-text" id="p79"> 
   <p>Arseny once designed a take-home exercise for candidates, where they were provided with a script solving anomaly detection problems on a simple image dataset. The script contained two baselines—one with a neural network and one with a color histogram—and candidates were instructed to improve either of them to beat some metric. Both baselines already performed on a similar level, and both were implemented specifically poorly, so the candidates had room for improvement. The majority of candidates preferred working on a more complicated deep learning solution, and only the most experienced of them noticed that it was possible to reach the required result with a single line of code changed for a histogram-based baseline.</p> 
  </div> 
  <div class="readable-text" id="p80"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_79"><span class="num-string">8.4</span> Variety of deep learning baselines</h2> 
  </div> 
  <div class="readable-text" id="p81"> 
   <p>When a problem is not trivial and suggests the use of deep learning because of the data structure (which can be applicable to most computer vision or language processing problems), the variety of baselines is slightly different. The most common are reusing pretrained models and training/fine-tuning the simplest models.</p> 
  </div> 
  <div class="readable-text intended-text" id="p82"> 
   <p>Reusing pretrained models is a common practice if a problem is not unique and there is a model that has been trained on a similar task. For example, if we want to train a model that can recognize breeds of pets, we can reuse a model that was trained on an ImageNet dataset. ImageNet is a dataset that contains images of 1,000 classes, and more than 100 of them are dog breeds. So, once your goal is to recognize cats and dogs, you can reuse a model that was trained on ImageNet dataset without retraining it. This is a common practice for many generic problems like speech recognition, object detection, text classification, sentiment analysis, end so on. </p> 
  </div> 
  <div class="readable-text intended-text" id="p83"> 
   <p>A slightly more advanced version of this approach is reusing features (also known as <em>embeddings</em> or <em>representations</em>) from a pretrained model to train a simple shallow model. For example, you can take a pretrained model that was trained on an ImageNet dataset and use its representations from the last backbone layer (before the final classification layer) to train a simple linear model that will classify images into a custom set of classes. This approach is especially useful when the dataset is small and the final task is more or less trivial (e.g., classification), so training large models from scratch is not likely to work. This approach is also known as a specific case of transfer learning. We have seen cases where such a baseline was literally unbeatable, and no fancy models were able to outperform it.</p> 
  </div> 
  <div class="readable-text intended-text" id="p84"> 
   <p>An even more specific version of using pretraining models is using pretrained models or third-party APIs capable of zero-shot or few-shot performance (meaning they require no or a few training samples to provide a result). A glorified example of such an API is the GPT family, but there are many APIs available for different tasks—for example, all major cloud vendors have a long list of AI solutions, such as Amazon Rekognition or Google Cloud Vision AI in the computer vision niche; detailed information about them is out of the scope of this book.</p> 
  </div> 
  <div class="readable-text intended-text" id="p85"> 
   <p>Using a third-party API by a major vendor as a baseline has a nice side effect: it is a bargaining chip in negotiations, such as selling a software product to a big enterprise or proving a startup tech is solid to potential investors. Potential customers may not know what a good metric is for a given problem (recall chapter 5), but comparing your tech to an AWS solution frames the problem in a proper way. Arseny knows at least three startups that have used this approach, bragging about how they beat alternatives such as Amazon, Google, and OpenAI. In all three cases, the companies’ claims were legit, and that’s expected, as major vendors aim to tailor one-size-fits-all solutions, while startups can offer more niche ML systems doing one thing just great.</p> 
  </div> 
  <div class="readable-text intended-text" id="p86"> 
   <p>Finally, if none of these options work, you can try to train a simple model from scratch. However, it is recommended to avoid recent state-of-the-art models and use something simpler and time proven. Recent models are often more “capricious” during training, while some older “stars” are already more researched, and recipes for stable training are well-known. A popular example of such models is the ResNet family for vision and the BERT family for natural language processing. Our personal heuristic is to start with models that are at least 2 years old, but it is not a strict rule. It depends on the level of innovation required for the system, as discussed in chapter 3.</p> 
  </div> 
  <div class="readable-text intended-text" id="p87"> 
   <p>It’s worth noting that there are multiple shades of fine-tuning between “training a shallow model on top of a pretrained model” and “training a model from scratch.” Choosing the right degree of fine-tuning is very case-specific and may require some experiments. For example, when training a text classification model based on BERT, you can gradually complicate the scope of training: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p88"> Train only the last layer. </li> 
   <li class="readable-text" id="p89"> Train some blocks using adapter methods such as low-rank adaptation (<a href="https://arxiv.org/abs/2106.09685">https://arxiv.org/abs/2106.09685</a>). </li> 
   <li class="readable-text" id="p90"> Train some encoder blocks. </li> 
   <li class="readable-text" id="p91"> Train normalization layers. </li> 
   <li class="readable-text" id="p92"> Train embedding layer. </li> 
   <li class="readable-text" id="p93"> Train full model. </li> 
   <li class="readable-text" id="p94"> Train full model + tokenizer. </li> 
  </ul> 
  <div class="readable-text" id="p95"> 
   <p>This variety leads to the question, “How do we choose a proper baseline?”</p> 
  </div> 
  <div class="readable-text" id="p96"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_80"><span class="num-string">8.5</span> Baseline comparison</h2> 
  </div> 
  <div class="readable-text" id="p97"> 
   <p>Let’s examined various features and model baselines, starting with the trivial ones. We can answer the central question, which is how to decide when to stop adding complexity and how to determine a suitable baseline for our system. There are multiple factors we should consider simultaneously; some of them are</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p98"> Accuracy </li> 
   <li class="readable-text" id="p99"> Effort (mostly, time of development) </li> 
   <li class="readable-text" id="p100"> Interpretability </li> 
   <li class="readable-text" id="p101"> Computation time </li> 
  </ul> 
  <div class="readable-text" id="p102"> 
   <p>The most fundamental is the tradeoff between a model’s accuracy (or other ML metric) and the effort it requires. The first component in the equation is accuracy. When you move from a constant baseline to a rule-based baseline, from a rule-based one to a linear model, or from original features to their aggregations and ratios, you already start to get a feeling for what increase in metrics these small changes give. Is it responsive or not? How difficult is it to significantly surpass your constant baseline? Is it reasonable to invest more time attempting to gain more accuracy? </p> 
  </div> 
  <div class="readable-text intended-text" id="p103"> 
   <p>In some sense, as an ML engineer, you do backpropagation by getting “feedback” from your training loop and updating your understanding of the problem with its data and accuracy distribution across the solution space.</p> 
  </div> 
  <div class="readable-text intended-text" id="p104"> 
   <p>The second component is effort. By “effort,” we mostly mean time and computing resources. No ML project has an infinite budget and, hence, an infinite amount of time. We consider the time required to implement a new model (or feature), train it, debug it, and test it. You should also pay attention to all the attendant complications and pitfalls that may arise on the way, especially infrastructural ones.</p> 
  </div> 
  <div class="readable-text intended-text" id="p105"> 
   <p>Let’s examine a constant baseline. It takes almost no time to implement, and it provides us with the lowest accuracy. So we will map it into the (0, 0)-point in time-accuracy coordinates (as shown in figure 8.5). </p> 
  </div> 
  <div class="browsable-container figure-container" id="p106">  
   <img alt="figure" src="../Images/CH08_F05_Babushkin.png" width="1100" height="633"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 8.5</span> Simple baselines are easy to build but sacrifice final system metrics (example for a time-series prediction).</h5>
  </div> 
  <div class="readable-text intended-text" id="p107"> 
   <p>Let’s take a look at the linear model. It requires more effort but also most likely provides us with better accuracy. We will probably find the corresponding point to the right and higher than the previous one, and so on. On the other hand, it is important to understand that as the model improves and evolves (and therefore gains in complexity), the cost–accuracy ratio begins to decrease. A striking example of such a drop in efficiency is gradient boosting, which we mentioned earlier. Based on our estimates and experience, gradient boosting requires more input than all the simpler models you would use at the earlier stages put together while giving no significant increase in accuracy.<span class="aframe-location"/></p> 
  </div> 
  <div class="readable-text intended-text" id="p108"> 
   <p>We should estimate how long it would take to try a more complex model each time and how much additional accuracy it could provide. Once we understand that the next step requires too much effort for almost no significant score improvement, we should stop. This “early stopping threshold” differs depending on the concrete domain and problem.</p> 
  </div> 
  <div class="readable-text intended-text" id="p109"> 
   <p>But what if something goes wrong or some additional change in the model is required? What model would be easier to debug or update?</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p110"> On the left of the spectrum, we have linear regression with an exact form solution. </li> 
   <li class="readable-text" id="p111"> A deep neural network with sophisticated training and inference pipelines is on the right. </li> 
  </ul> 
  <div class="readable-text" id="p112"> 
   <p>Which one would you prefer to face?</p> 
  </div> 
  <div class="readable-text intended-text" id="p113"> 
   <p>Maintenance, which we will touch upon in more detail in chapter 16, includes the amount of additional work that is necessary for debugging implemented features or a model. We could count maintenance as a part of the extra effort the more complex baseline requires.</p> 
  </div> 
  <div class="readable-text intended-text" id="p114"> 
   <p>Another essential property of a baseline is computation time. How does the computation time of our model and its features affect the response time? Does our baseline meet the service-level agreement? Is it the natural limit for solution space, especially when dealing with real-time systems? But even with no real-time requirements, computation time also determines how fast we will iterate during more thorough experimentation in the future.</p> 
  </div> 
  <div class="readable-text intended-text" id="p115"> 
   <p>Finally, we have interpretability. This parameter matters when we deal with the very first iteration of any ML system, especially for other teammates. When we deal, for example, with sensitive or medical data, it becomes a safety problem, too, not just a question of trust in the predictions of our model only. The general pattern is trivial: the simpler the baseline, the easier it is to explain how it works. </p> 
  </div> 
  <div class="readable-text intended-text" id="p116"> 
   <p>We’ll discuss this topic in detail later in chapter 11.</p> 
  </div> 
  <div class="readable-text" id="p117"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_81"><span class="num-string">8.6</span> Design document: Baselines</h2> 
  </div> 
  <div class="readable-text" id="p118"> 
   <p>As long as baselines can be part of your design document, we are going to fill this gap for our fictional companies, Supermegaretail and PhotoStock, Inc. </p> 
  </div> 
  <div class="readable-text" id="p119"> 
   <h3 class="readable-text-h3" id="sigil_toc_id_82"><span class="num-string">8.6.1</span> Baselines for Supermegaretail</h3> 
  </div> 
  <div class="readable-text" id="p120"> 
   <p>Let’s start with the forecast system. Here, seasonality will be a huge factor when choosing a prediction model, so we can’t but consider it in our design document. </p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p121"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">Design document: Supermegaretail</h4> 
   </div> 
   <div class="readable-text" id="p122"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">V. Baseline solution</h4> 
   </div> 
   <div class="readable-text" id="p123"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">i. Constant baseline</h4> 
   </div> 
   <div class="readable-text" id="p124"> 
    <p>As a constant baseline for Supermegaretail’s demand forecasting system, we plan to use the actual value of the previous day per SKU per grocery. Knowing that data sometimes could appear with delay and that grocery sales experience strong weekly seasonality, we will go 1 full week back instead of going 1 day back. As a result, our prediction for a specific item on September 8, 2022, will be the actual sales value for this item on September 1, 2022.</p> 
   </div> 
   <div class="readable-text" id="p125"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">ii. Advanced constant baseline</h4> 
   </div> 
   <div class="readable-text" id="p126"> 
    <p>Chapter 5 mentioned quantile losses of 1.5th, 25th, 50th, 75th, 95th, and 99th percentiles. We can calculate the same with our baseline using a yearly window.</p> 
   </div> 
   <div class="readable-text" id="p127"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">iii. Linear model baseline</h4> 
   </div> 
   <div class="readable-text" id="p128"> 
    <p>We will use a basic set of features to use linear regression with quantile loss; for a start, we can only use target variables but with multiple lags and aggregations like sum/min/max/avg/median or corresponding quantiles for the last 7/14/30/60/90/180 days or different rolling windows of different sizes. The same magic could be done with other dynamic data beyond sales date, like price, revenue, average check, or number of unique customers.</p> 
   </div> 
   <div class="readable-text" id="p129"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">iv. Time-series-specific baseline<span class="aframe-location"/></h4> 
   </div> 
   <div class="browsable-container figure-container" id="p130"> 
    <img alt="figure" src="../Images/CH08_UN01_Babushkin.png" width="922" height="490"/> 
   </div> 
   <div class="readable-text" id="p131"> 
    <p>Autoregressive integrated moving average (ARIMA) and seasonal ARIMA (SARIMA) are both autoregressive algorithms for forecasting; the second one considers any seasonality patterns.</p> 
   </div> 
   <div class="readable-text intended-text" id="p132"> 
    <p>Both require fine-tuning multiple hyperparameters to provide satisfying accuracy. To avoid this, we may prefer a state-of-the-art forecasting procedure that works great out-of-the-box and is called Prophet (<a href="https://github.com/facebook/prophet">https://github.com/facebook/prophet</a>). The nice advantage of Prophet is that it’s robust and doesn’t require a lot of preprocessing: outliers, missing values, shifts, and trends are handled automatically. </p> 
   </div> 
   <div class="readable-text" id="p133"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">v. Feature baselines</h4> 
   </div> 
   <div class="readable-text" id="p134"> 
    <p>What additional information can some baselines and possible future models benefit from?</p> 
   </div> 
   <div class="readable-text intended-text" id="p135"> 
    <p>We will include extra static info about products (brand, category), shops (geo features), and context (time-based features, seasonality, day of the week)—all of them with preprocessing and encoding appropriate for a chosen model. </p> 
   </div> 
   <div class="readable-text intended-text" id="p136"> 
    <p>Features that are also suitable for the baseline are counters and interactions. Examples include</p> 
   </div> 
   <ul> 
    <li class="readable-text" id="p137"> The difference between current and average price (absolute and relative) </li> 
    <li class="readable-text" id="p138"> Penetration: the ratio of product sales to sales of a category (of levels 1, 2, 3) for rolling windows of different sizes </li> 
    <li class="readable-text" id="p139"> Number of days since the last purchase </li> 
    <li class="readable-text" id="p140"> Number of unique customers </li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p141"> 
   <h3 class="readable-text-h3" id="sigil_toc_id_83"><span class="num-string">8.6.2</span> Baselines for PhotoStock Inc.</h3> 
  </div> 
  <div class="readable-text" id="p142"> 
   <p>Now we switch to the PhotoStock Inc. case, where we are building an advanced search engine set to provide better, more accurate results and eventually increase sales.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p143"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">Design document: PhotoStock Inc</h4> 
   </div> 
   <div class="readable-text" id="p144"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">V. Baseline solution</h4> 
   </div> 
   <div class="readable-text" id="p145"> 
    <p>We suggest three approaches to our baseline model for the PhotoStock Inc. search engine problem. </p> 
   </div> 
   <div class="readable-text" id="p146"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">i. Non-ML solution as a baseline</h4> 
   </div> 
   <div class="readable-text" id="p147"> 
    <p>Currently, PhotoStock Inc. uses a simple non-ML solution for its search engine. It is a keyword-based search engine with the ElasticSearch database capable of fuzzy search. It doesn’t require any training, and it is already deployed to production, so it is a solid candidate for a baseline model. </p> 
   </div> 
   <div class="readable-text intended-text" id="p148"> 
    <p>It has two drawbacks, though: it doesn’t use images in the search, only metadata (e.g., tags, descriptions, etc.), and it’s not too easy to embed it into a new ML pipeline for comparison. However, it’s still very useful to have it as a baseline model because it will allow us to compare the performance of an ML model with the performance of a non-ML solution.</p> 
   </div> 
   <div class="readable-text" id="p149"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">ii. Simple ML solution as a baseline</h4> 
   </div> 
   <div class="readable-text" id="p150"> 
    <p>Following the previous example, we can use a simple ML model as a baseline. It will not use images but only metadata. Such a model can use queries and metadata as raw input, transform them into features using a naive term frequency—inverse document frequency (TF-IDF) vectorizer, and then use a simple linear model to predict a relevance score. On top of that, it will be easy to implement and train, and its outstanding simplicity can help with early-stage debugging and understanding of the problem.</p> 
   </div> 
   <div class="readable-text" id="p151"> 
    <h4 class="readable-text-h4 sigil_not_in_toc">iii. Pretrained model as a baseline</h4> 
   </div> 
   <div class="readable-text" id="p152"> 
    <p>Finally, we can use a pretrained model as a baseline. Given the problem’s origin, we need a solution capable of unifying visual and text domains, and the most famous one is CLIP (<a href="https://openai.com/index/clip/">https://openai.com/index/clip/</a>). CLIP was released in 2021 and proved to be useful across various tasks. There are also several CLIP successors available, so they can be reviewed for future iterations if needed. </p> 
   </div> 
   <div class="readable-text intended-text" id="p153"> 
    <p>CLIP, in a nutshell, is an image encoder and a text encoder trained to predict which images were paired with proper text descriptions. It was trained on a huge dataset and thus demonstrates reasonable performance on a variety of tasks. CLIP is open source and is distributed under the MIT license, so it can be used for commercial purposes. </p> 
   </div> 
   <div class="readable-text intended-text" id="p154"> 
    <p>To make it work for our use case, we can start by using its output for a pair of queries (images) as a relevancy score. This approach doesn’t use metadata and text descriptions, so it can be either combined with a previous approach or developed further to use a two-component score—for example: </p> 
   </div> 
   <div class="readable-text indented-paragraph equation-paragraph" id="p155"> 
    <p>relevancy_score = distance(query, image) + distance(query, description)</p> 
   </div> 
   <div class="readable-text" id="p156"> 
    <p>Both distances can be computed using CLIP—one using both text and image encoders and the other using only a text encoder.</p> 
   </div> 
   <div class="readable-text intended-text" id="p157"> 
    <p>As a first step, we may avoid any training at all. As for the next steps, we can start fine-tuning the model or its components on our dataset.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p158"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_84">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p159"> Consider baselines an integral point of ML system design, as they effectively solve technical, ML, and product-related problems (interconnecting components, setting up a metric to compare with, and understanding product UX with a weak model inside). </li> 
   <li class="readable-text" id="p160"> Even though baselines are perceived as something as easy as ABC, the skill of recognizing where to start, both in terms of features and models, is underestimated. </li> 
   <li class="readable-text" id="p161"> As you dive deeper into your project, your common progression will lean toward the following progression: constant baseline, then rule-based baseline, then linear model, then something more complicated. </li> 
   <li class="readable-text" id="p162"> While building a complex model from the start may seem tempting, always consider kicking off with a constant baseline; this will save you resources and time and point to whether you’re moving in the right direction with minimum expenses. </li> 
   <li class="readable-text" id="p163"> When a problem implies the use of deep learning, the most common practice is reusing pretrained models, training/fine-tuning the simplest models, or training a simple model from scratch if neither of the first two approaches works. </li> 
   <li class="readable-text" id="p164"> When choosing between various baseline options, consider accuracy, effort (mostly time of development), interpretability, and computation time as key factors, with the accuracy–effort tradeoff being especially important. </li> 
   <li class="readable-text" id="p165"> As your model evolves and gains in complexity, the cost accuracy inevitably decreases. This is especially the case with switching to gradient boosting, which, as practice shows, requires more input than all previous models put together while giving no significant increase in accuracy. </li> 
  </ul>
 </div></div></body></html>