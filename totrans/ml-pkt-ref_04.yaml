- en: Chapter 4\. Missing Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need to deal with missing data. The previous chapter showed an example.
    This chapter will dive into it a bit more. Most algorithms will not work if data
    is missing. Notable exceptions are the recent boosting libraries: XGBoost, CatBoost,
    and LightGBM.'
  prefs: []
  type: TYPE_NORMAL
- en: As with many things in machine learning, there are no hard answers for how to
    treat missing data. Also, missing data could represent different situations. Imagine
    census data coming back and an age feature being reported as missing. Is it because
    the sample didn’t want to reveal their age? They didn’t know their age? The one
    asking the questions forgot to even ask about age? Is there a pattern to missing
    ages? Does it correlate to another feature? Is it completely random?
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also various ways to handle missing data:'
  prefs: []
  type: TYPE_NORMAL
- en: Remove any row with missing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove any column with missing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Impute missing values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an indicator column to signify data was missing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examining Missing Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s go back to the Titanic data. Because Python treats `True` and `False`
    as `1` and `0`, respectively, we can use this trick in pandas to get percent of
    missing data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To visualize patterns in the missing data, use the [missingno library](https://oreil.ly/rgYJG).
    This library is useful for viewing contiguous areas of missing data, which would
    indicate that the missing data is not random (see [Figure 4-1](#id2)). The `matrix`
    function includes a sparkline along the right side. Patterns here would also indicate
    nonrandom missing data. You may need to limit the number of samples to be able
    to see the patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![Where data is missing. No clear patterns jump out to the author.](assets/mlpr_0401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-1\. Where data is missing. No clear patterns jump out to the author.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can create a bar plot of missing data counts using pandas (see [Figure 4-2](#id3)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Percents of nonmissing data with pandas. Boat and body are leaky so we should
    ignore those. Interesting that some ages are missing.](assets/mlpr_0402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-2\. Percents of nonmissing data with pandas. Boat and body are leaky
    so we should ignore those. Interesting that some ages are missing.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Or use the missingno library to create the same plot (see [Figure 4-3](#id4)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Percents of nonmissing data with missingno.](assets/mlpr_0403.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-3\. Percents of nonmissing data with missingno.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can create a heat map showing if there are correlations where data is missing
    (see [Figure 4-4](#id5)). In this case, it doesn’t look like the locations where
    data are missing are correlated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Correlations of missing data with missingno.](assets/mlpr_0404.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-4\. Correlations of missing data with missingno.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can create a dendrogram showing the clusterings of where data is missing
    (see [Figure 4-5](#id6)). Leaves that are at the same level predict one another’s
    presence (empty or filled). The vertical arms are used to indicate how different
    clusters are. Short arms mean that branches are similar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Dendrogram of missing data with missingno. We can see the columns without
    missing data on the upper right.](assets/mlpr_0405.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-5\. Dendrogram of missing data with missingno. We can see the columns
    without missing data on the upper right.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Dropping Missing Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The pandas library can drop all rows with missing data with the `.dropna` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To drop columns, we can note what columns are missing and use the `.drop` method.
    We can pass in a list of column names or a single column name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can use the `.dropna` method and set `axis=1` (drop along
    the column axis):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Be careful about dropping data. I typically view this as a last resort option.
  prefs: []
  type: TYPE_NORMAL
- en: Imputing Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you have a tool for predicting data, you can use that to predict missing
    data. The general task of defining values for missing values is called *imputation*.
  prefs: []
  type: TYPE_NORMAL
- en: If you are imputing data, you will need to build up a pipeline and use the same
    imputation logic during model creation and prediction time. The `SimpleImputer`
    class in scikit-learn will handle mean, median, and most frequent feature values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The default behavior is to calculate the mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Provide `strategy='median'` or `strategy='most_frequent'` to change the replaced
    value to median or most common, respectively. If you wish to fill with a constant
    value, say `-1`, use `strategy``='constant'` in combination with `fill_value=-1`.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can use the `.fillna` method in pandas to impute missing values as well.
    Make sure that you do not leak data though. If you are filling in with the mean
    value, make sure you use the same mean value during model creation and model prediction
    time.
  prefs: []
  type: TYPE_NORMAL
- en: The most frequent and constant strategies may be used with numeric or string
    data. The mean and median require numeric data.
  prefs: []
  type: TYPE_NORMAL
- en: The fancyimpute library implements many algorithms and follows the scikit-learn
    interface. Sadly, most of the algorithms are *transductive*, meaning that you
    can’t call the `.transform` method by itself after fitting the algorithm. The
    `IterativeImputer` is *inductive* (has since been migrated from fancyimpute to
    scikit-learn) and supports transforming after fitting.
  prefs: []
  type: TYPE_NORMAL
- en: Adding Indicator Columns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The lack of data in and of itself may provide some signal to a model. The pandas
    library can add a new column to indicate that a value was missing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
