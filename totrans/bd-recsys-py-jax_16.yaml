- en: 'Chapter 13\. Putting It All Together: Experimenting and Ranking'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第13章。汇总一切：实验和排名
- en: In the last few chapters, we have covered many aspects of ranking, including
    various kinds of loss functions as well as metrics for measuring the performance
    of ranking systems. In this chapter, we will show an example of a ranking loss
    and ranking metric on the [Spotify Million Playlist dataset](https://oreil.ly/j3nvH).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近的几章中，我们涵盖了排名的许多方面，包括各种损失函数以及衡量排名系统性能的指标。在本章中，我们将展示一个排名损失和排名指标的示例，使用了[Spotify百万播放列表数据集](https://oreil.ly/j3nvH)。
- en: This chapter encourages a lot more experimentation and is more open-ended than
    the previous ones, whose goal was to introduce concepts and infrastructure. This
    chapter, on the other hand, is written to encourage you to roll up your sleeves
    and engage directly with loss functions and writing metrics.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章鼓励更多的实验和比之前更加开放的方式，其目标是引入概念和基础设施。另一方面，本章旨在鼓励您直接参与损失函数和编写指标的工作。
- en: Experimentation Tips
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验技巧
- en: Before we begin digging into the data and modeling, let’s cover some practices
    that will make your life easier when doing a lot of experimentation and rapid
    iteration. These are general guidelines that have made our experimentation faster.
    As a result, we’re able to rapidly iterate toward solutions that help us reach
    our objectives.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始挖掘数据和建模之前，让我们探讨一些实践方法，这些方法在进行大量实验和快速迭代时会使您的生活更加轻松。这些是一些通用的指导原则，使我们的实验更快。因此，我们能够快速迭代向解决方案，帮助我们达到我们的目标。
- en: Experimental code is different from engineering code in that the code is written
    to explore ideas, not for robustness. The goal is to achieve maximum velocity
    while not sacrificing too much in terms of code quality. So you should think about
    whether a piece of code should be thoroughly tested or whether this isn’t necessary
    because the code is present only to test a hypothesis and then it will be thrown
    away. With that in mind, here are some tips. Keep in mind that these tips are
    the opinion of the authors, developed over time, and are not hard-and-fast rules,
    just some flavored opinions that some may disagree with.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 实验代码与工程代码不同，实验代码是为了探索思路而写的，并非为了稳健性。目标是在不牺牲代码质量太多的情况下达到最大速度。因此，你应该考虑一段代码是否需要彻底测试，或者这并不必要，因为该代码只是为了测试一个假设，然后将被丢弃。考虑到这一点，以下是一些建议。请记住，这些建议是作者多年发展出来的观点，不是硬性规则，只是一些有趣的观点，可能会有人不同意。
- en: Keep It Simple
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保持简单
- en: In terms of the overall structure of research code, it’s best to keep it as
    simple as possible. Try not to overthink too much in terms of inheritance and
    reusability during the early stages of the lifecycle of exploration. At the start
    of a project, we usually don’t know what it needs yet, so the preference should
    be keeping the code easily readable and simple for debugging. That means you don’t
    have to focus too much on code reuse because at the early stage of a project,
    many code changes will occur while the structure of the model, data ingestion,
    and interaction of various parts of a system are being worked out. When the uncertainties
    have been worked out, then you can rewrite the code into a more robust form, but
    refactoring too early actually slows velocity.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究代码的整体结构方面，最好保持尽可能简单。在探索生命周期的早期阶段，尽量不要在继承和可重用性方面思考太多。在项目开始阶段，我们通常还不知道它需要什么，因此首选应该是保持代码易于阅读和简单调试。这意味着在早期阶段，不必过多关注代码重用，因为在项目的早期阶段，模型结构、数据摄入以及系统各部分的交互将会发生许多代码更改。当不确定性问题解决后，然后可以将代码重写为更稳健的形式，但是过早地重构实际上会降低速度。
- en: A general rule of thumb is that it is OK to copy code three times and then refactor
    out into a library the fourth time, because you’ll have seen enough use cases
    to justify the reuse of code. If refactoring is done too early, you might not
    have seen enough use cases of a piece of code to cover the possible use cases
    that it might need to handle.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一般的经验法则是，可以复制代码三次，第四次将其重构为库，因为你会看到足够多的用例来证明代码的复用是合理的。如果重构得太早，可能没有看到足够多的代码片段的用例来覆盖它可能需要处理的可能用例。
- en: Debug Print Statements
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调试打印语句
- en: If you’ve read a number of ML research papers, you may expect your data to be
    fairly clean and orderly at the start of a project. However, real-world data can
    be messy, with missing fields and unexpected values. Having lots of print functions
    allows you to print and visually inspect a sample of the data and also helps in
    crafting the input data pipelines and transformations to feed the model. Also,
    printing sample outputs of the model is useful in making sure the output is as
    expected.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你阅读了多篇机器学习研究论文，你可能期望你的数据在项目开始时是相当干净和有序的。然而，现实世界的数据可能会很杂乱，存在缺失字段和意外值。有很多打印函数可以让你打印并视觉检查数据的样本，还有助于制定输入数据的管道和转换，以供模型使用。此外，打印模型的样本输出对于确保输出符合预期也是有用的。
- en: The most important places to include logging are the input and output schema
    between components of your system; these help you understand where reality may
    be deviating from expectations. Later, you can make unit tests to ensure that
    refactoring of the model doesn’t break anything, but the unit tests can wait for
    when the model architecture is stable. A good rule of thumb is to add unit tests
    when you want to refactor code or reuse or optimize the code to preserve functionality
    or when the code is stable and you want to ensure that it doesn’t break a build.
    Another good use case of adding print statements is when you inevitably run into
    not-a-number (NaN) errors when running training code.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 包括记录日志的最重要的地方是系统组件之间的输入和输出模式；这些帮助你理解现实可能与期望偏差的地方。稍后，你可以编写单元测试来确保重构模型不会出错，但单元测试可以等到模型架构稳定时再做。一个良好的经验法则是当你想重构代码、重用代码或优化代码以保持功能性时，或者当代码稳定并且你希望确保它不会破坏构建时，添加单元测试。在运行训练代码时不可避免地遇到非数字
    (NaN) 错误时，添加打印语句也是一个很好的用例。
- en: 'In JAX, you can enable NaN debugging by using the following lines:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在 JAX 中，你可以通过以下方式启用 NaN 调试：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The debug NaNs configuration setting will rerun a jitted function if it finds
    any NaNs, and the debug print function will print the value of the tensors even
    inside a JIT. A regular print won’t work inside a JIT because it is not a compilable
    command and is skipped over during the tracing, so you have to use the debug print
    function instead, which does work inside a JIT.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 调试 NaN 配置设置将在发现任何 NaN 时重新运行编译的函数，并且调试打印函数将打印张量的值，即使在 JIT 内部也是如此。常规打印在 JIT 内部不起作用，因为它不是可编译的命令，在跟踪期间会被跳过，因此你必须使用调试打印函数，它在
    JIT 内部是有效的。
- en: Defer Optimization
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推迟优化
- en: In research code, there is a lot of temptation to optimize early—in particular,
    focusing on the implementation of your models or system to ensure they’re efficient
    computationally or the code is elegant. However, research code is written for
    higher velocity in experimentation, not execution speed.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究代码中，有很多诱惑让你早早进行优化——特别是关注模型或系统的实现，以确保它们在计算上是高效的或者代码是优雅的。然而，研究代码是为了更高的实验速度而写的，而不是执行速度。
- en: Our suggestion is do not optimize too early unless it hinders research velocity.
    One reason for this is the system might not be complete, so optimizing one part
    might not make sense if another part of the system is even slower and is the actual
    bottleneck. Another reason is the part that you are optimizing might not make
    it to the final model, so all the optimization work might go to waste if the code
    is refactored away anyway.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议不要过早优化，除非它影响了研究的速度。其中一个原因是系统可能还不完整，因此如果系统的另一部分更慢且是真正的瓶颈，优化其中一部分可能没有意义。另一个原因是你正在优化的部分可能不会成为最终模型的一部分，因此如果代码被重构掉了，所有的优化工作可能都会白费。
- en: Finally, optimization might actually hinder the ability to modify or inject
    newer design choices in terms of architecture or functionality. Optimized code
    tends to have certain choices that were made that fit the current structure of
    the data flow but might not be amenable to further changes. For example, in the
    code for this chapter, one possible optimization choice would have been to batch
    together playlists of the same size so that the code might be able to run in larger
    batches. However, at this point of the experimentation, that optimization would
    have been premature and distracting because it might make the metrics code more
    complicated. Our gentle advice is to defer optimization until after the bulk of
    experimentation has been done and the architecture, loss functions, and metrics
    have been chosen and settled upon.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，优化实际上可能会妨碍在架构或功能方面修改或注入较新设计选择的能力。优化代码往往会有一些选择，这些选择适合当前数据流结构，但可能不适合进一步的更改。例如，在本章的代码中，一种可能的优化选择是批量处理相同大小的播放列表，以便代码可以批量运行。然而，在此实验阶段，这种优化可能过早并且会分散注意力，因为它可能使度量代码变得更加复杂。我们的温和建议是，推迟优化，直到大部分实验完成并且架构、损失函数和度量标准已经选择并确定。
- en: Keep Track of Changes
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪变更
- en: In research code, too many variables are probably at play for you to change
    them one at a time to see their effects. This problem is particularly noticeable
    with larger datasets that require a lot of runs to determine which change causes
    which effects. So, in general, fixing a number of parameters and changing the
    code bit by bit is still a good idea so that you can keep track of the change
    that causes the most improvement. Parameters have to be tracked, but so do the
    code changes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究代码中，可能会涉及太多变量，以至于您不能一次更改它们以查看其效果。这个问题在需要大量运行来确定哪些更改导致哪些效果的大型数据集中尤为明显。因此，一般来说，固定一些参数并逐步改变代码仍然是个好主意，这样您可以跟踪导致最大改进的变更。参数必须被跟踪，但代码变更也同样重要。
- en: One way to keep track of changes is through services such as Weights & Biases
    that we discussed in [Chapter 5](ch05.html#ch:pinterest-content). Keeping track
    of the exact code that led to a change and the parameters is a good idea so that
    experiments can be reproduced and analyzed. Especially with research code that
    changes so frequently and is sometimes not checked in, you have to be diligent
    in keeping a copy of the code that produced a run somewhere, and MLOps tools allow
    you to track code and hyperparameters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通过像我们在[第5章](ch05.html#ch:pinterest-content)讨论的Weights & Biases这样的服务，可以跟踪变更的一种方法。记录导致变更的确切代码和参数是一个好主意，这样实验可以被重现和分析。特别是在经常变化且有时未经检查的研究代码中，您必须在某处保存生成运行的代码副本，而MLOps工具允许您跟踪代码和超参数。
- en: Use Feature Engineering
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用特征工程
- en: Unlike in academic papers, most applied research is interested in a good outcome
    rather than a theoretically beautiful result. We’re not shackled by purist views
    that the model has to learn everything about the data by itself. Instead, we’re
    pragmatic and concerned about good outcomes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 与学术论文不同，大多数应用研究更关心良好的结果而不是理论上美丽的结果。我们并不被纯粹主义观点所束缚，即模型必须自己学习数据的一切。相反，我们是实用主义者，关心良好的结果。
- en: We should not discard practices like feature engineering, especially when we
    have little data or are crunched for time and need decent results fast. Using
    feature engineering means that if you know whether a handcrafted feature is correlated
    positively or negatively with an outcome like the ranking of an item, then by
    all means add these engineered features to the data. An example in recommender
    systems is having an attribute of the item being scored that matches something
    in the user’s profile. So, if an item has the same artist or album in the user’s
    playlist, we can return a Boolean True; otherwise, we return False. This extra
    feature simply helps the model converge faster, and the model can still use other
    latent features such as embeddings to compensate if the hand-engineered features
    don’t do so well.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不应放弃诸如特征工程之类的实践，特别是当数据稀少或时间紧迫时，并且需要快速得到合理的结果。使用特征工程意味着，如果您知道手工制作的特征与像排名这样的结果正相关或负相关，那么请务必将这些工程特征添加到数据中。在推荐系统中的一个例子是，如果一个项目的属性与用户的播放列表中的艺术家或专辑匹配，则返回布尔值True；否则，返回False。这种额外的特征简单地帮助模型更快地收敛，如果手工制作的特征表现不佳，模型仍然可以使用其他潜在特征（如嵌入）来进行补偿。
- en: It is generally a good practice to ablate the hand-engineered features once
    in a while. To do this, hold back an experiment without some features to see if
    those features have become obsolete over time or if they still benefit the business
    metrics.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 定期消除手工设计的特征通常是一个好的实践。为了做到这一点，偶尔保留一个没有某些特征的实验，以查看这些特征是否随着时间的推移已经过时，或者它们是否仍然有益于业务指标。
- en: Ablation
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消融
- en: '*Ablation* in ML applications is the practice of measuring the change in performance
    of a model when a particular feature is removed. In computer vision applications,
    ablation often refers to blocking part of the image or view field to see how it
    impacts the model’s ability to identify or segment data. In other kinds of ML,
    it can mean strategically removing certain features.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习应用中，*消融*是指当特定特征被移除时，模型性能的变化情况。在计算机视觉应用中，消融通常是指阻塞图像或视野的一部分，以查看它对模型识别或分割数据的影响。在其他类型的机器学习中，它可以意味着有策略地移除某些特征。
- en: One gotcha with ablation is what to replace the feature with. Simply *zeroing
    out* the feature can significantly skew the output of the model. This is called
    *zero-ablation*, and can force the model to treat that feature out of distribution,
    which yields less believable outcomes. Instead, some advocate for mean-ablation,
    or taking the average or most common value of that feature. This allows the model
    to see much more expected values, and reduce these risks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 消融的一个要注意的地方是要用什么来替换该特征。简单地将该特征*清零*可能会显著地扭曲模型的输出。这被称为*零消融*，可以强制模型将该特征视为超出分布，从而产生较不可信的结果。相反，一些人主张进行均值消融，或者取该特征的平均值或最常见值。这使模型能够看到更多预期的值，并降低这些风险。
- en: However, this fails to consider the most important aspects of the kinds of models
    we’ve been working on—latent high-order interactions. One of the authors has investigated
    a deeper approach to ablation called *causal scrubbing*, in which you fix the
    ablation value to be sampled from the posterior distribution produced by other
    feature values, i.e., a value that “makes sense” with the rest of the values the
    model will see at that time.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这未能考虑到我们一直在研究的模型的最重要的方面——潜在的高阶交互作用。其中一位作者调查了一种更深入的消融方法，称为*因果擦除*，在这种方法中，您将消融值固定为从其他特征值产生的后验分布中采样的值，即，一个与模型在那时将看到的其余值“合理”的值。
- en: Understand Metrics Versus Business Metrics
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解指标与业务指标
- en: Sometimes, as ML practitioners, we obsess over the best possible metrics our
    models can achieve. However, we should temper that enthusiasm as the best ML metric
    might not totally represent the business interests at hand. Furthermore, other
    systems that contain business logic might sit on top of our models and modify
    the output. As a result, it is best not to obsess too heavily over ML metrics
    and to do proper A/B tests that contain business metrics instead since that’s
    the main measure of a good outcome with ML.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，作为机器学习从业者，我们过分关注我们的模型可以达到的最佳指标。然而，我们应该控制一下这种热情，因为最佳的机器学习指标可能并不完全代表手头的业务利益。此外，包含业务逻辑的其他系统可能会位于我们的模型之上并修改输出。因此，最好不要过分关注机器学习指标，而是进行包含业务指标的适当
    A/B 测试，因为这是评估机器学习结果的主要指标。
- en: The best possible circumstance is to find a loss function that aligns well or
    predicts the relevant business metric. This, unfortunately, is often not easy
    to find, especially when the business metrics are nuanced or have competing priorities.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的情况是找到一个与相关业务指标很好地对齐或预测的损失函数。不幸的是，这通常并不容易找到，特别是当业务指标很微妙或有竞争优先级时。
- en: Perform Rapid Iteration
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进行快速迭代
- en: Don’t be afraid to look at results of runs that are rather short. There’s no
    need to do a full pass over the data at the beginning, when you are figuring out
    the interaction between a model architecture and the data. It’s OK to do some
    rapid runs with minor tweaks to see how they change the metrics over a short number
    of time steps. In the Spotify Million Playlist dataset, we tweaked the model architecture
    by using 100,000 playlists before doing longer runs. Sometimes the changes can
    be so dramatic that the effects can be seen immediately, even at the first test-set
    evaluation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 不要害怕查看运行时间较短的结果。在开始时，当您正在弄清楚模型架构与数据之间的交互作用时，没有必要对数据进行完整的遍历。进行一些快速运行，并进行一些轻微的调整，以查看它们在较短的时间步长内如何改变指标是可以的。在
    Spotify 百万播放列表数据集中，我们在进行较长的运行之前通过使用 100,000 个播放列表来调整了模型架构。有时更改可能会如此显著，以至于效果可以立即看到，甚至在第一次测试集评估时也是如此。
- en: Now that we have the basics of experimental research coding covered, let’s hop
    over to the data and code and play a bit with modeling music recommendations.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经掌握了实验研究编码的基础知识，让我们转到数据和代码，稍微玩弄一下建模音乐推荐。
- en: Spotify Million Playlist Dataset
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spotify 百万播放列表数据集
- en: The code for this section can be found in [this book’s GitHub repo](https://github.com/BBischof/ESRecsys/tree/main/spotify).
    The documentation for the data can be found at [Spotify Million Playlist Dataset
    Challenge](https://oreil.ly/eVA7f).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 此节的代码可以在[此书的 GitHub 存储库](https://github.com/BBischof/ESRecsys/tree/main/spotify)找到。数据的文档可以在[Spotify
    百万播放列表数据集挑战](https://oreil.ly/eVA7f)找到。
- en: 'The first thing we should do is take a look at the data:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们应该查看数据：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'That should produce the following output:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该产生以下输出：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: When encountering a new dataset, it is always important to look at it and plan
    which features to use to generate recommendations for the data. One possible goal
    of the Spotify Million Playlist Dataset Challenge is to see if the next tracks
    in a playlist can be predicted from the first five tracks in the playlist.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在遇到新数据集时，总是重要的是看一下它，并计划使用哪些特征来生成数据的推荐。Spotify 百万播放列表数据集挑战的一个可能目标是从播放列表中的前五个曲目预测接下来的曲目。
- en: 'In this case, several features might be useful for the task. We have track,
    artist, and album universal resource identifiers (URIs), which are unique identifiers
    for tracks, artists, and albums, respectively. And we have artist and album names
    and names of playlists. The dataset also includes numerical features like duration
    of a track and the number of followers in a playlist. Intuitively, the number
    of followers of a playlist should not affect the ordering of tracks in a playlist,
    so you might want to look for better features before using these possibly uninformative
    ones. Looking at the overall statistics of features, you can also obtain a lot
    of insight:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，对任务可能有用的几个特征。我们有曲目、艺术家和专辑的统一资源标识符（URI），它们分别是曲目、艺术家和专辑的唯一标识符。我们还有艺术家和专辑的名称以及播放列表的名称。数据集还包括诸如曲目时长和播放列表关注者数量等数值特征。直觉上，播放列表的关注者数量不应影响播放列表中曲目的排序，因此在使用这些可能不具信息量的特征之前，您可能希望寻找更好的特征。查看特征的整体统计信息，您还可以获得很多见解：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: First of all, notice that the number of tracks is more than the number of playlists.
    This implies that quite a few tracks might have very little training data. So
    the `track_uri` might not be a feature that generalizes very well. On the other
    hand, the `album_uri` and `artist_uri` would generalize because they would occur
    multiple times in different playlists. For the sake of code clarity, we will mostly
    work with the `album_uri` and `artist_uri` as the features that represent a track.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要注意的是曲目数比播放列表数多。这意味着很多曲目可能有非常少的训练数据。因此，`track_uri`可能不是一个很好泛化的特征。另一方面，`album_uri`和`artist_uri`会泛化，因为它们会在不同的播放列表中多次出现。为了代码清晰起见，我们将主要使用`album_uri`和`artist_uri`作为代表曲目的特征。
- en: In previous “Putting It All Together” chapters, we demonstrated the use of content-based
    features or text token-based features that may be used instead, but direct embedding
    features are the clearest for demonstrating ranking. In a real-world application,
    embedding features and content-based features may be concatenated together to
    form a feature that generalizes better for recommendation ranking. For the purposes
    of this chapter, we will represent a track as the tuple of (`track_id`, `album_id`,
    `artist_id`), where the ID is an integer representing the URI. We will build dictionaries
    that map from the URI to the integer ID in the next section.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的“综合应用”章节中，我们展示了可以替代的基于内容的特征或文本令牌化特征的使用，但是直接嵌入特征最清晰地用于排名演示。在实际应用中，嵌入特征和基于内容的特征可以连接在一起形成更好推荐排名的特征。在本章中，我们将把一个曲目表示为元组(`track_id`,
    `album_id`, `artist_id`)，其中ID是表示URI的整数。我们将在下一节建立从URI到整数ID的字典。
- en: Building URI Dictionaries
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建URI字典
- en: Similar to [Chapter 8](ch08.html#ch:wikipedia-e2e), we will first start by constructing
    a dictionary for all the URIs. This dictionary allows us to represent the text
    URI as an integer for faster processing on the JAX side, as we can easily look
    up embeddings from integers as opposed to arbitrary URI strings.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于[第8章](ch08.html#ch:wikipedia-e2e)，我们将首先构建所有URI的字典。这个字典允许我们将文本URI表示为整数，以便在JAX端更快地处理，因为我们可以轻松地从整数查找嵌入，而不是任意的URI字符串。
- en: 'Here is the code for *make_dictionary.py*:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 *make_dictionary.py* 的代码：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Whenever a new URI is encountered, we simply increment a counter and assign
    that unique identifier to the URI. We do this for tracks, artists, and albums
    and save it as a JSON file.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 每当遇到新的 URI 时，我们只需递增计数器并将该唯一标识符分配给 URI。我们对曲目、艺术家和专辑执行此操作，并将其保存为 JSON 文件。
- en: Although we could have used a data processing framework like PySpark for this,
    it is important to take note of the data size. If the data size is small, like
    a million playlists, it would just be faster to do it on a single machine. We
    should be wise about when to use a big data processing framework, and for small
    datasets it can sometimes be faster to simply run the code on one machine instead
    of writing code that runs on a cluster.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们可以使用像 PySpark 这样的数据处理框架，但重要的是要注意数据大小。如果数据量小，例如百万个播放列表，仅在单台机器上执行会更快。在何时使用大数据处理框架时我们应该明智，并且对于小数据集，有时仅在一台机器上运行代码可能更快，而不是编写在集群上运行的代码。
- en: Building the Training Data
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建训练数据
- en: 'Now that we have the dictionaries, we can use them to convert the raw JSON
    playlist logs into a more usable form for ML training. The code for this is in
    *make_training.py*:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了字典，我们可以使用它们将原始 JSON 播放列表日志转换为更可用的形式进行 ML 训练。此代码在 *make_training.py* 中实现：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This code reads in a raw playlist JSON file, converts the URIs from textual
    identifiers to the index in the dictionary, and filters out playlists that are
    under a minimum size. In addition, we partition the playlist such that the first
    five elements are grouped into the context, or user that we are recommending items
    for, and the next items, which are the items we wish to predict for a given user.
    We call the first five elements the *context* because they represent a playlist
    and because there won’t be a one-to-one mapping between a playlist and a user
    if a user has more than one playlist. We then write each playlist as a TensorFlow
    example in a TensorFlow record file for use with the TensorFlow data input pipeline.
    The records will always contain five tracks, albums, and artists for the context
    and at least five more next tracks for learning the inference tasks of predicting
    the next tracks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码读取原始播放列表 JSON 文件，将 URIs 从文本标识符转换为字典中的索引，并过滤出小于最小大小的播放列表。此外，我们对播放列表进行分区，使前五个元素分组为上下文或我们推荐项目的用户，而接下来的元素则是我们希望为给定用户预测的项目。我们称前五个元素为
    *上下文*，因为它们代表一个播放列表，并且因为如果用户有多个播放列表，播放列表与用户之间不会有一对一的映射。然后，我们将每个播放列表写为 TensorFlow
    记录文件中的 TensorFlow 示例，以供 TensorFlow 数据输入管道使用。记录将始终包含上下文的五个曲目、专辑和艺术家，以及至少五个更多的下一个曲目，用于学习预测下一个曲目的推断任务。
- en: Note
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We use TensorFlow objects here because of their compatibility with JAX and to
    introduce some very convenient data formats.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用 TensorFlow 对象，因为它们与 JAX 兼容，并且引入了一些非常方便的数据格式。
- en: We also store unique rows of tracks with all the features, which is mostly for
    debugging and display should we need to convert a `track_uri` into a human-readable
    form. This track data is stored in *all_tracks.json*.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还存储具有所有特征的唯一曲目行，这主要是为了调试和显示，如果我们需要将 `track_uri` 转换为人类可读格式。此曲目数据存储在 *all_tracks.json*
    中。
- en: Reading the Input
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 读取输入
- en: 'The input is then read via *input_pipeline.py*:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过 *input_pipeline.py* 读取输入：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We use the TensorFlow data’s functionality to read and decode the TensorFlow
    records and examples. For that to work, we need to supply a schema, or a dictionary,
    telling the decoder the names and types of features to expect. Since we have picked
    five tracks each for the context, we should expect five each of `track_context`,
    `album_context`, and `artist_context`. However, since the playlists themselves
    are of variable lengths, we tell the decoder to expect variable-length integers
    for the `next_track`, `next_album`, and `next_artist` features.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 TensorFlow 数据的功能来读取和解码 TensorFlow 记录和示例。为此，我们需要提供一个模式或字典，告诉解码器期望哪些特征的名称和类型。由于我们为上下文选择了五个曲目，我们应该期望每个
    `track_context`、`album_context` 和 `artist_context` 有五个。然而，由于播放列表本身的长度是可变的，我们告诉解码器期望
    `next_track`、`next_album` 和 `next_artist` 特征的可变长度整数。
- en: 'The second part of *input_pipeline.py* is for reusable input code to load the
    dictionaries and track metadata:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*input_pipeline.py* 的第二部分是用于可重用的输入代码，用于加载字典并跟踪元数据：'
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We also supply a utility function to convert the *all_tracks.json* file into
    the entire corpus of tracks for scoring in the final recommendations. After all,
    the goal is to rank the entire corpus, given the first five context tracks, and
    see how well they match the given next track data.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供一个实用函数，将*all_tracks.json*文件转换为最终推荐中用于评分的所有轨道语料库。毕竟，目标是排名整个语料库，给定前五个上下文轨道，并查看它们与给定的下一个轨道数据匹配的情况。
- en: Modeling the Problem
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对问题进行建模
- en: Next, let’s think of how we will model the problem. We have five context tracks,
    each with an associated artist and album. We know that we have more tracks than
    playlists, so for now we will simply ignore the `track_id` and just use the `album_id`
    and `artist_id` as features. One strategy could be to use one-hot encoding for
    the album and artist, and this would work well, but one-hot encoding tends to
    lead to models with high precision but less generalization.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们考虑如何对问题进行建模。我们有五个上下文轨道，每个轨道都有一个关联的艺术家和专辑。我们知道轨道数量比播放列表多，所以暂时我们将忽略`track_id`，仅使用`album_id`和`artist_id`作为特征。一种策略是对专辑和艺术家使用一位有效编码（one-hot
    encoding），这种方法效果不错，但一位有效编码往往导致模型具有较高的精度但泛化能力较差。
- en: An alternate way to represent identifiers is to embed them—that is, to make
    a lookup table to an embedding of a fixed size that is lower dimensional than
    the cardinality of the identifiers. This embedding can be thought of as a low-rank
    approximation to the full-rank matrix of identifiers. We covered low-rank embeddings
    in earlier chapters, and we use that concept here as features to represent the
    album and artists.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 表示标识符的另一种方法是将它们嵌入——即制作一个查找表，将标识符嵌入到一个比标识符基数低的固定大小的嵌入中。这种嵌入可以被看作是标识符全秩矩阵的低秩逼近。我们在早期章节中介绍了低秩嵌入，并且在这里使用这个概念作为表示专辑和艺术家特征的方法。
- en: 'Take a look at *models.py*, which contains the code for `SpotifyModel`:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 查看*models.py*，其中包含`SpotifyModel`的代码的另一种表示方法：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the setup code, notice that we have two embeddings, for the albums and the
    artists. We have a lot of albums, so we show one way to reduce the memory footprint
    of album embeddings: take the mod of a smaller number than the number of embeddings
    so that multiple albums might share an embedding. If more memory is available,
    you can remove the mod, but this technique is demonstrated here as a way of getting
    some benefit of having an embedding for a feature with very large cardinality.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置代码中，请注意我们有两个嵌入，分别用于专辑和艺术家。我们有很多专辑，因此我们展示了一种减少专辑嵌入内存占用的方法：取一个比嵌入数量更小的数的模，以便多个专辑可以共享一个嵌入。如果内存更多，可以去掉模运算，但这里演示了一种在具有非常大基数特征的情况下获取一些好处的技术。
- en: The artist is probably the most informative feature, and the data includes far
    fewer unique artists, so we have a one-to-one mapping between the `artist_id`
    and the embeddings. When we convert the tuple of `(album_id, artist_id)` to an
    embedding, we do separate lookups for each ID and then concatenate the embeddings
    and return one complete embedding to represent a track. If more playlist data
    becomes available, you might also want to embed the `track_id`. However, given
    that we have more unique tracks than playlists, the `track_id` feature will not
    generalize well until we have more playlist data and the `track_id` could occur
    more often as observations. A general rule of thumb is that a feature should occur
    at least 100 times to be useful; otherwise, the gradients for that feature will
    not be updated very often, and it might as well be a random number because it
    is initialized as such.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 艺术家可能是最信息丰富的特征，数据包含的独特艺术家较少，因此我们在`artist_id`和嵌入之间有一对一映射。当我们将`(album_id, artist_id)`元组转换为一个嵌入时，我们对每个ID进行单独查找，然后连接嵌入并返回一个完整的嵌入来表示一个轨道。如果有更多播放列表数据可用，您可能还希望嵌入`track_id`。但是，鉴于我们的独特轨道比播放列表多，直到有更多的播放列表数据和`track_id`更频繁地出现作为观察结果之前，`track_id`特征将不会很好地泛化。一个经验法则是，特征至少应出现100次才有用；否则，该特征的梯度将不会经常更新，它可能与随机数一样，因为它被初始化为这样。
- en: 'In the `call` section, we do the heavy lifting of computing the affinity of
    a context to other tracks:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在`call`部分，我们完成了计算上下文与其他轨道亲和性的重要工作：
- en: '[PRE9]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let’s dig into this a bit since this is the core of the model code. The first
    part is pretty straightforward: we convert the indices into embeddings by looking
    up the album and artist embedding and concatenating them as a single vector per
    track. It is in this location that you would add in other dense features by concatenation,
    or convert sparse features to embeddings as we have done.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入研究这个模型代码的核心，因为这是第一部分相当直接：我们通过查找专辑和艺术家嵌入并将它们串联为每个曲目的单一向量来将索引转换为嵌入。在这个位置，您可以通过串联添加其他密集特征，或者像我们所做的那样将稀疏特征转换为嵌入。
- en: The next part computes the affinity of the context to the next tracks. Recall
    that the context is composed of the first five tracks, and the next track is the
    rest of the playlist to be computed. We have several choices here for representing
    the context and computing the affinity.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 下一部分计算上下文与下一首曲目的关联性。请注意，上下文由前五首曲目组成，而下一首曲目是待计算的播放列表的其余部分。在这里，我们有几种选择来表示上下文并计算关联性。
- en: For the affinity of the context, we have chosen the simplest form of affinity,
    that of a dot product. The other consideration is how we treat the context, since
    it is composed of five tracks. One possible way is to average all the context
    embeddings and use the average as the representation for the context. Another
    way is to find the track with the maximal affinity as the closest track in the
    context to that of the next track.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上下文的关联性，我们选择了最简单形式的关联性，即点积。另一个考虑因素是我们如何处理上下文，因为它由五个曲目组成。一种可能的方法是对所有上下文嵌入求平均值，并使用平均值作为上下文的表示。另一种方法是找到与下一首曲目的上下文中最大关联的曲目作为最接近的曲目。
- en: Details on various options can be found in [“Affinity Weighted Embedding”](https://oreil.ly/ig7Ch)
    by Jason Weston et al. We have found that if a user has diverse interests, finding
    the max affinity doesn’t update the context embeddings in the same direction as
    the next track, as using the mean embedding does. In the case of playlists, the
    mean context embedding vector should function just as well because playlists tend
    to be on a single theme.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有关各种选项的详细信息可以在[“关联加权嵌入”](https://oreil.ly/ig7Ch)中找到，作者是Jason Weston等人。我们发现，如果用户兴趣广泛，找到最大关联性不会像使用平均嵌入那样使上下文嵌入朝着与下一首曲目相同的方向更新。在播放列表的情况下，平均上下文嵌入向量应该同样有效，因为播放列表往往是单一主题的。
- en: Notice that we compute the affinity for the negative tracks as well. This is
    because we want the next tracks to have more affinity to the context than the
    negative tracks. In addition to the affinity of the context and next tracks to
    the context, we also compute the L2 norm of the vectors as a way to regularize
    the model so it does not overfit on the training data. We also reverse the embedding
    vectors and compute what we call *self-affinity*, or the affinity of the context,
    next, and negative embeddings to themselves, simply by reversing the list of vectors
    and taking the dot product. This does not exhaustively compute all the affinities
    of the set with itself; this again is left as an exercise for you as it builds
    intuition and skill in using JAX.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们还计算负曲目的关联性。这是因为我们希望下一首曲目与上下文的关联性比负曲目更强。除了上下文与下一首曲目之间的关联性外，我们还计算向量的L2范数作为一种正则化模型的方法，以防止其在训练数据上过拟合。我们还颠倒嵌入向量并计算我们称之为*自关联*的量，或者上下文、下一首曲目和负嵌入向量与自身的关联性，简单地通过颠倒向量列表并进行点积来完成。这并不完全计算集合与自身的所有关联性；这留给你作为练习，因为它能建立使用JAX的直觉和技能。
- en: The results are then returned as a tuple to the caller.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 结果会作为一个元组返回给调用者。
- en: Framing the Loss Function
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 捕捉损失函数
- en: 'Now, let’s look at *train_spotify.py*. We will skip the boilerplate code and
    just look at the evaluation and training steps:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看*train_spotify.py*。我们将跳过样板代码，只看评估和训练步骤：
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The first piece of code is the evaluation step. To compute the affinities of
    the entire corpus, we pass in the album and artist indices for every possible
    track in the corpus to the model and then sort them using `jax.lax.top_k`. The
    first two lines are the scoring code for recommending the next tracks from the
    context during recommendations. LAX is a utility library that comes with JAX that
    contains functions outside of the NumPy API that are handy to work with vector
    processors like GPUs and TPUs. In the Spotify Million Playlist Dataset Challenge,
    one of the metrics is the recall@k at the artist and track level. For the tracks,
    the `isin` function returns the correct metric of the intersection of the next
    tracks and the top 500 scoring tracks of the corpus divided by the size of the
    set of next tracks. This is because the tracks are unique in the corpus. However,
    JAX’s `isin` doesn’t support making the elements unique, so for the artist recall
    metric, we might count artists in the recall set more than once. For the sake
    of computational efficiency, we use the multiple counts instead so that the evaluation
    might be computed quickly on the GPU so as not to stall the training pipeline.
    On a final evaluation, we might want to move the dataset to a CPU for a more accurate
    metric.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 第一段代码是评估步骤。为了计算整个语料库的亲和力，我们对模型传入每个可能曲目的专辑和艺术家索引，然后使用`jax.lax.top_k`对它们进行排序。前两行是推荐上下文中下一个曲目的评分代码。LAX是一个实用的工具库，配备了JAX，其中包含了在像GPU和TPU这样的向量处理器上工作时非NumPy
    API的函数。在Spotify百万播放列表数据集挑战中，一个度量指标是艺术家和曲目级别的recall@k。对于曲目，`isin`函数返回下一个曲目和语料库中得分最高的前500个曲目的交集的正确度量，除以下一个曲目集的大小。这是因为语料库中的曲目是唯一的。然而，JAX的`isin`不支持使元素唯一化，因此对于艺术家召回度量，我们可能多次计算在召回集中的艺术家。为了计算效率，我们使用多次计数而不是唯一计数，以便在GPU上快速计算评估，以避免阻塞训练流水线。在最终评估中，我们可能会希望将数据集移动到CPU上，以获得更准确的度量。
- en: 'We use Weights & Biases again to track all the metrics, as depicted in [Figure 13-1](#wandb_spotify_metrics_figure).
    You can see how they fare with each other over several experiments:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次使用Weights & Biases来跟踪所有指标，如[图13-1](#wandb_spotify_metrics_figure)所示。您可以看到它们在多个实验中的表现如何比较：
- en: '![Spotify Million Platlist Dataset Evaluation Metrics](assets/brpj_1301.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![Spotify百万播放列表数据集评估指标](assets/brpj_1301.png)'
- en: Figure 13-1\. Weights & Biases experiment tracking
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-1\. Weights & Biases实验追踪
- en: 'Next, we will look at the loss functions, another juicy part that you can experiment
    with in the exercises at the end of the chapter:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看一下损失函数，这是本章末尾的练习中可以进行实验的另一个精彩部分：
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We have several losses here, some directly related to the main task and others
    that help with regularization and generalization.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个损失函数，一些与主要任务直接相关，其他一些帮助正则化和泛化。
- en: We initially started with the `mean_triplet_loss`, which is simply a loss that
    states that the positive affinity, or the affinity of the context tracks to the
    next tracks, should be one more than the negative affinity, or the affinity of
    the context tracks to the negative tracks. We will discuss how we experimented
    to obtain the other auxiliary loss functions.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最初使用的是`mean_triplet_loss`，这只是一个简单的损失函数，指出了正亲和力或者上下文曲目对下一个曲目的亲和力应该比负亲和力或者上下文曲目对负曲目的亲和力多一个。我们将讨论如何进行实验以获得其他辅助损失函数。
- en: Experiment tracking, depicted in [Figure 13-2](#wandb_spotify_eval_track_metrics_figure),
    is important in the process of improving the model, as is reproducibility. We
    have tried as much as possible to make the training process deterministic by using
    random-number generators from JAX that are reproducible by using the same starting
    random-number generator seed.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图13-2](#wandb_spotify_eval_track_metrics_figure)中所示的实验追踪在改进模型过程中非常重要，如可复现性所示。我们尽可能使用来自JAX的随机数生成器使训练过程确定性，通过使用相同的起始随机数生成器种子来使其可复现。
- en: '![Spotify Million Platlist Dataset Experiments - Evaluation Track Recall](assets/brpj_1302.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![Spotify百万播放列表数据集实验 - 评估曲目召回](assets/brpj_1302.png)'
- en: Figure 13-2\. Track recall experiments
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-2\. 曲目召回实验
- en: We started with the `mean_triplet_loss` and `reg_loss`, which is the regularization
    loss as a good baseline. These two losses simply make sure that the mean positive
    affinity of the context to the next track is one more than the negative affinity
    of the context to the negative tracks, and that the L2 norm of the embeddings
    does not exceed the regularization thresholds. These correspond to the metrics
    that did the worst. Notice that we do not run the experiment for the entire dataset.
    This is because for rapid iteration, it might be faster to just run on a smaller
    number of steps first and compare before interleaving occasionally with longer
    runs that use the entire dataset.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`mean_triplet_loss`和`reg_loss`开始，即正则化损失作为一个良好的基准。这两个损失函数简单地确保了上下文到下一个曲目的平均正关联比上下文到负曲目的负关联多一个，并且嵌入的L2范数不超过正则化阈值。这些对应于做得最差的指标。注意，我们并没有对整个数据集运行实验。这是因为为了快速迭代，最好先仅运行少量步骤，然后偶尔与使用整个数据集的长时间运行交错比较快。
- en: The next loss we added was the `max_neg_affinity` and the `min_pos_affinity`.
    This loss was inspired in part by [“Efficient Coordinate Descent or Ranking with
    Domination Loss”](https://oreil.ly/_aEF9) by Mark A. Stevens and [“Learning to
    Rank Recommendations with the *k*-Order Statistic Loss”](https://oreil.ly/CPexf)
    by Jason Weston et al. However, we do not use the entire negative set but merely
    a subsample. Why? Because the negative set is noisy. Just because a user hasn’t
    added a particular track to a playlist doesn’t mean that the track is not relevant
    to the playlist. Maybe the user hasn’t heard the track yet, so the noise is due
    to lack of exposure. We also do not do the sampling step as discussed in the *k*-order
    statistic loss paper because sampling is CPU friendly but not GPU friendly. So
    we combine ideas from both papers and take the largest negative affinity and make
    it one less than the smallest positive affinity. The addition of this loss on
    the extremal tracks from both the next and negative sets gave us the next boost
    in performance in our experiments.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来添加的损失函数是`max_neg_affinity`和`min_pos_affinity`。这个损失函数在一定程度上受到了Mark A. Stevens的[“高效协调下降或使用支配损失进行排序”](https://oreil.ly/_aEF9)以及Jason
    Weston等人的[“学习使用*k*阶统计损失进行推荐排序”](https://oreil.ly/CPexf)的启发。然而，我们并没有使用整个负集，而只是一个子样本。为什么呢？因为负集存在噪音。仅仅因为用户没有将特定曲目添加到播放列表中，并不意味着该曲目与播放列表无关。也许用户还没有听过这首曲目，所以噪音是由于缺乏接触。我们也不像*k*阶统计损失论文中讨论的那样进行采样步骤，因为采样对CPU友好但对GPU不友好。因此，我们结合了这两篇论文的思想，取最大的负关联性并将其设为最小正关联性减一。在我们的实验中，这种在极端轨迹上的损失的添加为我们带来了性能的进一步提升。
- en: Finally, we added the self-affinity losses. These ensure that tracks from the
    context and next track sets have affinities of at least 0.5 and that the negative
    track affinities are at most 0\. These are dot-product affinities and are more
    absolute as opposed to the relative positive and negative affinities that make
    the positive affinity one more than the negative affinities. In the long run,
    they didn’t help much, but they did help the model converge faster in the beginning.
    We left them in because they still offer some improvement on the evaluation metrics
    on the last training step. This wraps up the explanatory part of this “Putting
    It All Together” chapter. Now comes the fun part, the exercises!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们添加了自关联损失。这些确保了来自上下文和下一个曲目集的曲目之间的关联至少为0.5，并且负曲目的关联最多为0。这些是点积关联，相对于使正关联比负关联多一个的相对关联，它们更加绝对。从长远来看，它们并没有帮助太多，但它们确实帮助模型在开始阶段更快地收敛。我们保留它们是因为它们在最后训练步骤的评估指标上仍然提供了一些改进。这结束了本章“将所有内容放在一起”的解释部分。现在来到有趣的部分，练习！
- en: Exercises
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: We offer a lot of exercises because playing with the data and code is helpful
    in building out your intuition about different loss functions and ways of modeling
    the user. Also, thinking about how to write the code allows you to improve your
    proficiency with using JAX. So we have a list of helpful exercises to try out
    that are fun and will help you understand the material provided in this book.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了大量的练习，因为玩弄数据和代码有助于建立关于不同损失函数和建模用户方法的直觉。此外，考虑如何编写代码可以提高您使用JAX的熟练程度。因此，我们列出了一些有趣且有助于理解本书提供内容的有用练习清单。
- en: To wrap up this chapter, here are some interesting exercises to experiment with.
    Doing them should give you lots of intuition about loss functions and the way
    JAX works, as well as a feel for the experimental process.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 总结本章，以下是一些有趣的练习可以进行尝试。完成它们应该会让您对损失函数和 JAX 的工作方式有很多直觉，以及对实验过程的感觉。
- en: 'Here are some easy exercises to start with:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些简单的练习可以开始尝试：
- en: Try out different optimizers (e.g., ADAM, RMSPROP).
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试不同的优化器（例如 ADAM、RMSPROP）。
- en: Try changing the feature sizes.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试改变特征的大小。
- en: Add in duration as a feature (take care on normalization!).
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加持续时间作为特征（在归一化时要小心！）。
- en: What if you use cosine distance for inference and dot product for training?
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果在推断中使用余弦距离，而在训练中使用点积，会发生什么？
- en: Add in a new metric, like NDCG.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加一个新的指标，比如 NDCG。
- en: Play with distribution of positive versus negative affinities in the loss.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在损失中玩弄正负亲和力的分布。
- en: Hinge loss with the lowest next track and the highest negative track.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最低的下一个跟踪和最高的负跟踪的铰链损失。
- en: 'Continue exploring with these more difficult exercises:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 继续尝试这些更难的练习：
- en: Try using the track names as features and see if they help generalize.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试使用跟踪名称作为特征，并查看它们是否有助于泛化。
- en: What happens if you use a two-layer network for affinity?
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用两层网络来计算亲和力会发生什么？
- en: What happens if you use an LSTM to compute affinity?
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用 LSTM 计算亲和力会发生什么？
- en: Replace track embeddings with correlation.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将跟踪嵌入替换为相关性。
- en: Compute all the self-affinities in a set.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算集合中的所有自身亲和力。
- en: Summary
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: What does it mean to replace an embedding with a feature? In our example of
    positive and negative affinity, we used the dot product to compute the affinity
    between two entities, such as two tracks, <math alttext="x"><mi>x</mi></math>
    and <math alttext="y"><mi>y</mi></math> . Rather than having the features as latent,
    represented by embeddings, an alternative is to manually construct features that
    represent the affinity between the two entities, <math alttext="x"><mi>x</mi></math>
    and <math alttext="y"><mi>y</mi></math> . As covered in [Chapter 9](ch09.html#feature-counting),
    this can be log counts or Dice correlation coefficient or mutual information.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 用特征替换嵌入是什么意思？在我们对正负亲和力的示例中，我们使用点积来计算两个实体之间的亲和力，例如两个跟踪，<math alttext="x"><mi>x</mi></math>
    和 <math alttext="y"><mi>y</mi></math> 。与其将特征作为潜在的嵌入表示，一个替代方法是手动构建代表两个实体之间亲和力的特征，<math
    alttext="x"><mi>x</mi></math> 和 <math alttext="y"><mi>y</mi></math> 。正如[第 9 章](ch09.html#feature-counting)所介绍的，这可以是对数计数、Dice
    相关系数或互信息。
- en: Some kind of counting feature can be made and then stored in a database. Upon
    training and inference, the database is looked up for each entity <math alttext="x"><mi>x</mi></math>
    and <math alttext="y"><mi>y</mi></math> , and the affinity scores are then used
    instead of or in conjunction with the dot product that is being learned. These
    features tend to be more precise but have less recall than an embedding representation.
    The embedding representation, being of low rank, has the ability to generalize
    better and improve recall. Having counting features is synergistic with embedding
    features because we can simultaneously improve precision with the use of precise
    counting features and, at the same time, improve recall with the help of low-rank
    features like embeddings.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 可以制作某种类型的计数特征，然后将其存储在数据库中。在训练和推断时，为每个实体 <math alttext="x"><mi>x</mi></math>
    和 <math alttext="y"><mi>y</mi></math> 查找数据库，然后使用亲和分数代替或与正在学习的点积一起使用。这些特征往往更精确，但召回率较低于嵌入表示。低秩的嵌入表示能够更好地泛化并提高召回率。具有计数特征是与嵌入特征协同作用的，因为我们可以通过使用精确的计数特征同时使用精确的计数特征来提高精度，同时通过使用嵌入等低秩特征来提高召回率。
- en: For computing all <math alttext="n squared"><msup><mi>n</mi> <mn>2</mn></msup></math>
    affinities of tracks to other tracks in a set, consider using JAX’s `vmap` function.
    `vmap` can be used to convert code that, for example, computes one track’s affinity
    with all the other tracks and makes it run for all tracks versus all other tracks.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑使用 JAX 的 `vmap` 函数计算集合中跟踪与其他跟踪的所有 <math alttext="n 平方"><msup><mi>n</mi> <mn>2</mn></msup></math>
    亲和性。`vmap` 可用于转换代码，例如计算一个跟踪与所有其他跟踪的亲和性，并使其运行以与所有其他跟踪相比。
- en: We hope that you have enjoyed playing with the data and code and that your skill
    in writing recommender systems in JAX has improved considerably after trying these
    exercises!
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望您在玩弄数据和代码后享受其中，并且在尝试这些练习后，您在 JAX 中编写推荐系统的能力得到了显著提高！
