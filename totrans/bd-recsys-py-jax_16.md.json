["```py\nfrom jax import config\nconfig.update(\"jax_debug_nans\", True)\n\n@jax.jit\ndef f(x):\n  jax.debug.print(\"Debugging {x}\", x=x)\n```", "```py\nless data/spotify_million_playlist_dataset/data/mpd.slice.0-999.json\n```", "```py\n{\n    \"info\": {\n        \"generated_on\": \"2017-12-03 08:41:42.057563\",\n        \"slice\": \"0-999\",\n        \"version\": \"v1\"\n    },\n    \"playlists\": [\n        {\n            \"name\": \"Throwbacks\",\n            \"collaborative\": \"false\",\n            \"pid\": 0,\n            \"modified_at\": 1493424000,\n            \"num_tracks\": 52,\n            \"num_albums\": 47,\n            \"num_followers\": 1,\n            \"tracks\": [\n                {\n                    \"pos\": 0,\n                    \"artist_name\": \"Missy Elliott\",\n                    \"track_uri\": \"spotify:track:0UaMYEvWZi0ZqiDOoHU3YI\",\n                    \"artist_uri\": \"spotify:artist:2wIVse2owClT7go1WT98tk\",\n                    \"track_name\": \"Lose Control (feat. Ciara & Fat Man Scoop)\",\n                    \"album_uri\": \"spotify:album:6vV5UrXcfyQD1wu4Qo2I9K\",\n                    \"duration_ms\": 226863,\n                    \"album_name\": \"The Cookbook\"\n                },\n     }\n }\n```", "```py\nless data/spotify_million_playlist_dataset/stats.txt\nnumber of playlists 1000000\nnumber of tracks 66346428\nnumber of unique tracks 2262292\nnumber of unique albums 734684\nnumber of unique artists 295860\nnumber of unique titles 92944\nnumber of playlists with descriptions 18760\nnumber of unique normalized titles 17381\navg playlist length 66.346428\n\ntop playlist titles\n  10000 country\n  10000 chill\n   8493 rap\n   8481 workout\n   8146 oldies\n   8015 christmas\n   6848 rock\n   6157 party\n   5883 throwback\n   5063 jams\n   5052 worship\n   4907 summer\n   4677 feels\n   4612 new\n   4186 disney\n   4124 lit\n   4030 throwbacks\n```", "```py\nimport glob\nimport json\nimport os\nfrom typing import Any, Dict, Tuple\n\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\nimport numpy as np\nimport tensorflow as tf\n\nFLAGS = flags.FLAGS\n_PLAYLISTS = flags.DEFINE_string(\"playlists\", None, \"Playlist json glob.\")\n_OUTPUT_PATH = flags.DEFINE_string(\"output\", \"data\", \"Output path.\")\n\n# Required flag.\nflags.mark_flag_as_required(\"playlists\")\n\ndef update_dict(dict: Dict[Any, int], item: Any):\n    \"\"\"Adds an item to a dictionary.\"\"\"\n    if item not in dict:\n        index = len(dict)\n        dict[item] = index\n\ndef dump_dict(dict: Dict[str, str], name: str):\n  \"\"\"Dumps a dictionary as json.\"\"\"\n  fname = os.path.join(_OUTPUT_PATH.value, name)\n  with open(fname, \"w\") as f:\n    json.dump(dict, f)\n\ndef main(argv):\n    \"\"\"Main function.\"\"\"\n    del argv  # Unused.\n\n    tf.config.set_visible_devices([], 'GPU')\n    tf.compat.v1.enable_eager_execution()\n    playlist_files = glob.glob(_PLAYLISTS.value)\n    track_uri_dict = {}\n    artist_uri_dict = {}\n    album_uri_dict = {}\n\n    for playlist_file in playlist_files:\n        print(\"Processing \", playlist_file)\n        with open(playlist_file, \"r\") as file:\n            data = json.load(file)\n            playlists = data[\"playlists\"]\n            for playlist in playlists:\n                tracks = playlist[\"tracks\"]\n                for track in tracks:\n                  update_dict(track_uri_dict, track[\"track_uri\"])\n                  update_dict(artist_uri_dict, track[\"artist_uri\"])\n                  update_dict(album_uri_dict, track[\"album_uri\"])\n\n    dump_dict(track_uri_dict, \"track_uri_dict.json\")\n    dump_dict(artist_uri_dict, \"artist_uri_dict.json\")\n    dump_dict(album_uri_dict, \"album_uri_dict.json\")\n\nif __name__ == \"__main__\":\n    app.run(main)\n```", "```py\nimport glob\nimport json\nimport os\nfrom typing import Any, Dict, Tuple\n\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\nimport numpy as np\nimport tensorflow as tf\n\nimport input_pipeline\n\nFLAGS = flags.FLAGS\n_PLAYLISTS = flags.DEFINE_string(\"playlists\", None, \"Playlist json glob.\")\n_DICTIONARY_PATH = flags.DEFINE_string(\"dictionaries\", \"data/dictionaries\",\n                   \"Dictionary path.\")\n_OUTPUT_PATH = flags.DEFINE_string(\"output\", \"data/training\", \"Output path.\")\n_TOP_K = flags.DEFINE_integer(\"topk\", 5, \"Top K tracks to use as context.\")\n_MIN_NEXT = flags.DEFINE_integer(\"min_next\", 10, \"Min number of tracks.\")\n\n# Required flag.\nflags.mark_flag_as_required(\"playlists\")\n\ndef main(argv):\n    \"\"\"Main function.\"\"\"\n    del argv  # Unused.\n\n    tf.config.set_visible_devices([], 'GPU')\n    tf.compat.v1.enable_eager_execution()\n    playlist_files = glob.glob(_PLAYLISTS.value)\n\n    track_uri_dict = input_pipeline.load_dict(\n      _DICTIONARY_PATH.value, \"track_uri_dict.json\")\n\n    print(\"%d tracks loaded\" % len(track_uri_dict))\n    artist_uri_dict = input_pipeline.load_dict(\n      _DICTIONARY_PATH.value, \"artist_uri_dict.json\")\n    print(\"%d artists loaded\" % len(artist_uri_dict))\n    album_uri_dict = input_pipeline.load_dict(\n      _DICTIONARY_PATH.value, \"album_uri_dict.json\")\n    print(\"%d albums loaded\" % len(album_uri_dict))\n    topk = _TOP_K.value\n    min_next = _MIN_NEXT.value\n    print(\"Filtering out playlists with less than %d tracks\" % min_next)\n\n    raw_tracks = {}\n\n    for pidx, playlist_file in enumerate(playlist_files):\n        print(\"Processing \", playlist_file)\n        with open(playlist_file, \"r\") as file:\n            data = json.load(file)\n            playlists = data[\"playlists\"]\n            tfrecord_name = os.path.join(\n              _OUTPUT_PATH.value, \"%05d.tfrecord\" % pidx)\n            with tf.io.TFRecordWriter(tfrecord_name) as file_writer:\n              for playlist in playlists:\n                  if playlist[\"num_tracks\"] < min_next:\n                      continue\n                  tracks = playlist[\"tracks\"]\n                  # The first topk tracks are all for the context.\n                  track_context = []\n                  artist_context = []\n                  album_context = []\n                  # The rest are for predicting.\n                  next_track = []\n                  next_artist = []\n                  next_album = []\n                  for tidx, track in enumerate(tracks):\n                      track_uri_idx = track_uri_dict[track[\"track_uri\"]]\n                      artist_uri_idx = artist_uri_dict[track[\"artist_uri\"]]\n                      album_uri_idx = album_uri_dict[track[\"album_uri\"]]\n                      if track_uri_idx not in raw_tracks:\n                          raw_tracks[track_uri_idx] = track\n                      if tidx < topk:\n                          track_context.append(track_uri_idx)\n                          artist_context.append(artist_uri_idx)\n                          album_context.append(album_uri_idx)\n                      else:\n                          next_track.append(track_uri_idx)\n                          next_artist.append(artist_uri_idx)\n                          next_album.append(album_uri_idx)\n                  assert(len(next_track) > 0)\n                  assert(len(next_artist) > 0)\n                  assert(len(next_album) > 0)\n                  record = tf.train.Example(\n                    features=tf.train.Features(feature={\n                      \"track_context\": tf.train.Feature(\n                      int64_list=tf.train.Int64List(value=track_context)),\n                      \"album_context\": tf.train.Feature(\n                      int64_list=tf.train.Int64List(value=album_context)),\n                      \"artist_context\": tf.train.Feature(\n                      int64_list=tf.train.Int64List(value=artist_context)),\n                      \"next_track\": tf.train.Feature(\n                      int64_list=tf.train.Int64List(value=next_track)),\n                      \"next_album\": tf.train.Feature(\n                      int64_list=tf.train.Int64List(value=next_album)),\n                      \"next_artist\": tf.train.Feature(\n                      int64_list=tf.train.Int64List(value=next_artist)),\n                    }))\n                  record_bytes = record.SerializeToString()\n                  file_writer.write(record_bytes)\n\n    filename = os.path.join(_OUTPUT_PATH.value, \"all_tracks.json\")\n    with open(filename, \"w\") as f:\n        json.dump(raw_tracks, f)\n\nif __name__ == \"__main__\":\n    app.run(main)\n```", "```py\nimport glob\nimport json\nimport os\nfrom typing import Sequence, Tuple, Set\n\nimport tensorflow as tf\nimport jax.numpy as jnp\n\n_schema = {\n   \"track_context\": tf.io.FixedLenFeature([5], dtype=tf.int64),\n   \"album_context\": tf.io.FixedLenFeature([5], dtype=tf.int64),\n   \"artist_context\": tf.io.FixedLenFeature([5], dtype=tf.int64),\n   \"next_track\": tf.io.VarLenFeature(dtype=tf.int64),\n   \"next_album\": tf.io.VarLenFeature(dtype=tf.int64),\n   \"next_artist\": tf.io.VarLenFeature(dtype=tf.int64),\n}\n\ndef _decode_fn(record_bytes):\n  result = tf.io.parse_single_example(record_bytes, _schema)\n  for key in _schema.keys():\n    if key.startswith(\"next\"):\n      result[key] = tf.sparse.to_dense(result[key])\n  return result\n\ndef create_dataset(\n    pattern: str):\n    \"\"\"Creates a spotify dataset.\n\n Args:\n pattern: glob pattern of tfrecords.\n \"\"\"\n    filenames = glob.glob(pattern)\n    ds = tf.data.TFRecordDataset(filenames)\n    ds = ds.map(_decode_fn)\n    return ds\n```", "```py\ndef load_dict(dictionary_path: str, name: str):\n    \"\"\"Loads a dictionary.\"\"\"\n    filename = os.path.join(dictionary_path, name)\n    with open(filename, \"r\") as f:\n        return json.load(f)\n\ndef load_all_tracks(all_tracks_file: str,\n                    track_uri_dict, album_uri_dict, artist_uri_dict):\n  \"\"\"Loads all tracks.\n\n \"\"\"\n  with open(all_tracks_file, \"r\") as f:\n    all_tracks_json = json.load(f)\n  all_tracks_dict = {\n    int(k): v for k, v in all_tracks_json.items()\n  }\n  all_tracks_features = {\n    k: (track_uri_dict[v[\"track_uri\"]],\n        album_uri_dict[v[\"album_uri\"]],\n        artist_uri_dict[v[\"artist_uri\"]])\n    for k,v in all_tracks_dict.items()\n  }\n  return all_tracks_dict, all_tracks_features\n\ndef make_all_tracks_numpy(all_tracks_features):\n  \"\"\"Makes the entire corpus available for scoring.\"\"\"\n  all_tracks = []\n  all_albums = []\n  all_artists = []\n  items = sorted(all_tracks_features.items())\n  for row in items:\n    k, v = row\n    all_tracks.append(v[0])\n    all_albums.append(v[1])\n    all_artists.append(v[2])\n  all_tracks = jnp.array(all_tracks, dtype=jnp.int32)\n  all_albums = jnp.array(all_albums, dtype=jnp.int32)\n  all_artists = jnp.array(all_artists, dtype=jnp.int32)\n  return all_tracks, all_albums, all_artists\n```", "```py\nfrom functools import partial\nfrom typing import Any, Callable, Sequence, Tuple\n\nfrom flax import linen as nn\nimport jax.numpy as jnp\n\nclass SpotifyModel(nn.Module):\n    \"\"\"Spotify model that takes a context and predicts the next tracks.\"\"\"\n    feature_size : int\n\n    def setup(self):\n        # There are too many tracks and albums so limit by hashing.\n        self.max_albums = 100000\n        self.album_embed = nn.Embed(self.max_albums, self.feature_size)\n        self.artist_embed = nn.Embed(295861, self.feature_size)\n\n    def get_embeddings(self, album, artist):\n        \"\"\"\n Given track, album, artist indices return the embeddings.\n Args:\n album: ints of shape nx1\n artist: ints of shape nx1\n Returns:\n Embeddings representing the track.\n \"\"\"\n        album_modded = jnp.mod(album, self.max_albums)\n        album_embed = self.album_embed(album_modded)\n        artist_embed = self.artist_embed(artist)\n        result = jnp.concatenate([album_embed, artist_embed], axis=-1)\n        return result\n```", "```py\ndef __call__(self,\n                 track_context, album_context, artist_context,\n                 next_track, next_album, next_artist,\n                 neg_track, neg_album, neg_artist):\n        \"\"\"Returns the affinity score to the context.\n Args:\n track_context: ints of shape n\n album_context: ints of shape n\n artist_context: ints of shape n\n next_track: int of shape m\n next_album: int of shape m\n next_artist: int of shape m\n neg_track: int of shape o\n neg_album: int of shape o\n neg_artist: int of shape o\n Returns:\n pos_affinity: affinity of context to the next track of shape m.\n neg_affinity: affinity of context to the neg tracks of shape o.\n \"\"\"\n        context_embed = self.get_embeddings(album_context, artist_context)\n        next_embed = self.get_embeddings(next_album, next_artist)\n        neg_embed = self.get_embeddings(neg_album, neg_artist)\n\n        # The affinity of the context to the other track is simply the dot\n        # product of each context embedding with the other track's embedding.\n        # We also add a small boost if the album or artist match.\n        pos_affinity = jnp.max(jnp.dot(next_embed, context_embed.T), axis=-1)\n        pos_affinity = pos_affinity + 0.1 * jnp.isin(next_album, album_context)\n        pos_affinity = pos_affinity + 0.1 * jnp.isin(next_artist, artist_context)\n\n        neg_affinity = jnp.max(jnp.dot(neg_embed, context_embed.T), axis=-1)\n        neg_affinity = neg_affinity + 0.1 * jnp.isin(neg_album, album_context)\n        neg_affinity = neg_affinity + 0.1 * jnp.isin(neg_artist, artist_context)\n\n        all_embeddings = jnp.concatenate(\n        [context_embed, next_embed, neg_embed], axis=-2)\n        all_embeddings_l2 = jnp.sqrt(\n        jnp.sum(jnp.square(all_embeddings), axis=-1))\n\n        context_self_affinity = jnp.dot(jnp.flip(\n        context_embed, axis=-2), context_embed.T)\n        next_self_affinity = jnp.dot(jnp.flip(\n        next_embed, axis=-2), next_embed.T)\n        neg_self_affinity = jnp.dot(jnp.flip(neg_embed, axis=-2), neg_embed.T)\n\n        return (pos_affinity, neg_affinity,\n                context_self_affinity, next_self_affinity, neg_self_affinity,\n                all_embeddings_l2)\n```", "```py\ndef eval_step(state, y, all_tracks, all_albums, all_artists):\n    result = state.apply_fn(\n            state.params,\n            y[\"track_context\"], y[\"album_context\"], y[\"artist_context\"],\n            y[\"next_track\"], y[\"next_album\"], y[\"next_artist\"],\n            all_tracks, all_albums, all_artists)\n    all_affinity = result[1]\n    top_k_scores, top_k_indices = jax.lax.top_k(all_affinity, 500)\n    top_tracks = all_tracks[top_k_indices]\n    top_artists = all_artists[top_k_indices]\n    top_tracks_count = jnp.sum(jnp.isin(\n      top_tracks, y[\"next_track\"])).astype(jnp.float32)\n    top_artists_count = jnp.sum(jnp.isin(\n      top_artists, y[\"next_artist\"])).astype(jnp.float32)\n\n    top_tracks_recall = top_tracks_count / y[\"next_track\"].shape[0]\n    top_artists_recall = top_artists_count / y[\"next_artist\"].shape[0]\n\n    metrics = jnp.stack([top_tracks_recall, top_artists_recall])\n\n    return metrics\n```", "```py\ndef train_step(state, x, regularization):\n    def loss_fn(params):\n        result = state.apply_fn(\n            params,\n            x[\"track_context\"], x[\"album_context\"], x[\"artist_context\"],\n            x[\"next_track\"], x[\"next_album\"], x[\"next_artist\"],\n            x[\"neg_track\"], x[\"neg_album\"], x[\"neg_artist\"])\n      pos_affinity = result[0]\n      neg_affinity = result[1]\n      context_self_affinity = result[2]\n      next_self_affinity = result[3]\n      neg_self_affinity = result[4]\n      all_embeddings_l2 = result[5]\n\n      mean_neg_affinity = jnp.mean(neg_affinity)\n      mean_pos_affinity = jnp.mean(pos_affinity)\n      mean_triplet_loss = nn.relu(1.0 + mean_neg_affinity - mean_pos_affinity)\n\n      max_neg_affinity = jnp.max(neg_affinity)\n      min_pos_affinity = jnp.min(pos_affinity)\n      extremal_triplet_loss = nn.relu(\n                              1.0 + max_neg_affinity - min_pos_affinity\n                                )\n\n      context_self_affinity_loss = jnp.mean(nn.relu(0.5 - context_self_affinity))\n      next_self_affinity_loss = jnp.mean(nn.relu(\n                                0.5 - next_self_affinity)\n                                )\n      neg_self_affinity_loss = jnp.mean(nn.relu(neg_self_affinity))\n\n      reg_loss = jnp.sum(nn.relu(all_embeddings_l2 - regularization))\n      loss = (extremal_triplet_loss + mean_triplet_loss + reg_loss +\n              context_self_affinity_loss + next_self_affinity_loss +\n              neg_self_affinity_loss)\n      return loss\n\n    grad_fn = jax.value_and_grad(loss_fn)\n    loss, grads = grad_fn(state.params)\n    new_state = state.apply_gradients(grads=grads)\n    return new_state, loss\n```"]