["```py\n# Load libraries\nimport joblib\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create decision tree classifer object\nclassifer = RandomForestClassifier()\n\n# Train model\nmodel = classifer.fit(features, target)\n\n# Save model as pickle file\njoblib.dump(model, \"model.pkl\")\n```", "```py\n['model.pkl']\n```", "```py\n# Load model from file\nclassifer = joblib.load(\"model.pkl\")\n```", "```py\n# Create new observation\nnew_observation = [[ 5.2,  3.2,  1.1,  0.1]]\n\n# Predict observation's class\nclassifer.predict(new_observation)\n```", "```py\narray([0])\n```", "```py\n# Import library\nimport sklearn\n\n# Get scikit-learn version\nscikit_version = sklearn.__version__\n\n# Save model as pickle file\njoblib.dump(model, \"model_{version}.pkl\".format(version=scikit_version))\n```", "```py\n['model_1.2.0.pkl']\n```", "```py\n# Load libraries\nimport numpy as np\nfrom tensorflow import keras\n\n# Set random seed\nnp.random.seed(0)\n\n# Create model with one hidden layer\ninput_layer = keras.Input(shape=(10,))\nhidden_layer = keras.layers.Dense(10)(input_layer)\noutput_layer = keras.layers.Dense(1)(input_layer)\nmodel = keras.Model(input_layer, output_layer)\nmodel.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n\n# Train the model\nx_train = np.random.random((1000, 10))\ny_train = np.random.random((1000, 1))\nmodel.fit(x_train, y_train)\n\n# Save the model to a directory called `save_model`\nmodel.save(\"saved_model\")\n```", "```py\n32/32 [==============================] - 1s 8ms/step - loss: 0.2056\nINFO:tensorflow:Assets written to: saved_model/assets\n```", "```py\n# Load neural network\nmodel =  keras.models.load_model(\"saved_model\")\n```", "```py\nls saved_model\n```", "```py\nassets\tfingerprint.pb\tkeras_metadata.pb  saved_model.pb  variables\n```", "```py\n# Load libraries\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.optim import RMSprop\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\n\n# Create training and test sets\nfeatures, target = make_classification(n_classes=2, n_features=10,\n    n_samples=1000)\nfeatures_train, features_test, target_train, target_test = train_test_split(\n    features, target, test_size=0.1, random_state=1)\n\n# Set random seed\ntorch.manual_seed(0)\nnp.random.seed(0)\n\n# Convert data to PyTorch tensors\nx_train = torch.from_numpy(features_train).float()\ny_train = torch.from_numpy(target_train).float().view(-1, 1)\nx_test = torch.from_numpy(features_test).float()\ny_test = torch.from_numpy(target_test).float().view(-1, 1)\n\n# Define a neural network using `Sequential`\nclass SimpleNeuralNet(nn.Module):\n    def __init__(self):\n        super(SimpleNeuralNet, self).__init__()\n        self.sequential = torch.nn.Sequential(\n            torch.nn.Linear(10, 16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16,16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16, 1),\n            torch.nn.Dropout(0.1), # Drop 10% of neurons\n            torch.nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        x = self.sequential(x)\n        return x\n\n# Initialize neural network\nnetwork = SimpleNeuralNet()\n\n# Define loss function, optimizer\ncriterion = nn.BCELoss()\noptimizer = RMSprop(network.parameters())\n\n# Define data loader\ntrain_data = TensorDataset(x_train, y_train)\ntrain_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n\n# Compile the model using torch 2.0's optimizer\nnetwork = torch.compile(network)\n\n# Train neural network\nepochs = 5\nfor epoch in range(epochs):\n    for batch_idx, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        output = network(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n# Save the model after it's been trained\ntorch.save(\n    {\n        'epoch': epoch,\n        'model_state_dict': network.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss,\n    },\n    \"model.pt\"\n)\n\n# Reinitialize neural network\nnetwork = SimpleNeuralNet()\nstate_dict = torch.load(\n    \"model.pt\",\n    map_location=torch.device('cpu')\n    )[\"model_state_dict\"]\nnetwork.load_state_dict(state_dict, strict=False)\nnetwork.eval()\n```", "```py\nSimpleNeuralNet(\n  (sequential): Sequential(\n    (0): Linear(in_features=10, out_features=16, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=16, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=1, bias=True)\n    (5): Dropout(p=0.1, inplace=False)\n    (6): Sigmoid()\n  )\n)\n```", "```py\n# Import libraries\nimport joblib\nfrom flask import Flask, request\n\n# Instantiate a flask app\napp = Flask(__name__)\n\n# Load the model from disk\nmodel = joblib.load(\"model.pkl\")\n\n# Create a predict route that takes JSON data, makes predictions, and\n# returns them\n@app.route(\"/predict\", methods = [\"POST\"])\ndef predict():\n    print(request.json)\n    inputs = request.json[\"inputs\"]\n    prediction = model.predict(inputs)\n    return {\n        \"prediction\" : prediction.tolist()\n    }\n\n # Run the app\nif __name__ == \"__main__\":\n    app.run()\n```", "```py\npython3 -m pip install flask==2.2.3 joblib==1.2.0 scikit-learn==1.2.0\n```", "```py\npython3 app.py\n```", "```py\n * Serving Flask app 'app'\n * Debug mode: off\nWARNING: This is a development server. Do not use it in a production deployment.\n    Use a production WSGI server instead.\n * Running on http://127.0.0.1:5000\nPress CTRL+C to quit\n```", "```py\ncurl -X POST http://127.0.0.1:5000/predict  -H 'Content-Type: application/json'\n    -d '{\"inputs\":[[5.1, 3.5, 1.4, 0.2]]}'\n```", "```py\n{\"prediction\":[0]}\n```", "```py\ndocker run -p 8501:8501 -p 8500:8500 \\\n--mount type=bind,source=$(pwd)/saved_model,target=/models/saved_model/1 \\\n-e MODEL_NAME=saved_model -t tensorflow/serving\n```", "```py\n{\n    \"model_version_status\": [\n        {\n            \"version\": \"1\",\n            \"state\": \"AVAILABLE\",\n            \"status\": {\n                \"error_code\": \"OK\",\n                \"error_message\": \"\"\n            }\n        }\n    ]\n}\n```", "```py\n{\n\"model_spec\":{\n \"name\": \"saved_model\",\n \"signature_name\": \"\",\n \"version\": \"1\"\n}\n,\n\"metadata\": {\"signature_def\": {\n \"signature_def\": {\n  \"serving_default\": {\n   \"inputs\": {\n    \"input_8\": {\n     \"dtype\": \"DT_FLOAT\",\n     \"tensor_shape\": {\n      \"dim\": [\n       {\n        \"size\": \"-1\",\n        \"name\": \"\"\n       },\n       {\n        \"size\": \"10\",\n        \"name\": \"\"\n       }\n      ],\n      \"unknown_rank\": false\n     },\n     \"name\": \"serving_default_input_8:0\"\n    }\n   },\n   \"outputs\": {\n    \"dense_11\": {\n     \"dtype\": \"DT_FLOAT\",\n     \"tensor_shape\": {\n      \"dim\": [\n       {\n        \"size\": \"-1\",\n        \"name\": \"\"\n       },\n       {\n        \"size\": \"1\",\n        \"name\": \"\"\n       }\n      ],\n      \"unknown_rank\": false\n     },\n     \"name\": \"StatefulPartitionedCall:0\"\n    }\n   },\n   \"method_name\": \"tensorflow/serving/predict\"\n  },\n  \"__saved_model_init_op\": {\n   \"inputs\": {},\n   \"outputs\": {\n    \"__saved_model_init_op\": {\n     \"dtype\": \"DT_INVALID\",\n     \"tensor_shape\": {\n      \"dim\": [],\n      \"unknown_rank\": true\n     },\n     \"name\": \"NoOp\"\n    }\n   },\n   \"method_name\": \"\"\n  }\n }\n}\n}\n}\n```", "```py\ncurl -X POST http://localhost:8501/v1/models/saved_model:predict\n    -d '{\"inputs\":[[1,2,3,4,5,6,7,8,9,10]]}'\n```", "```py\n{\n    \"outputs\": [\n        [\n            5.59353495\n        ]\n    ]\n}\n```", "```py\n# Import libraries\nimport torch\nimport torch.nn as nn\nimport logging\n\n# Create a PyTorch model class\nclass SimpleNeuralNet(nn.Module):\n    def __init__(self):\n        super(SimpleNeuralNet, self).__init__()\n        self.sequential = torch.nn.Sequential(\n            torch.nn.Linear(10, 16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16,16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16, 1),\n            torch.nn.Dropout(0.1), # Drop 10% of neurons\n            torch.nn.Sigmoid(),\n\n        )\n# Create a Seldon model object with the name `MyModel`\nclass MyModel(object):\n\n    # Loads the model\n    def __init__(self):\n        self.network = SimpleNeuralNet()\n        self.network.load_state_dict(\n            torch.load(\"model.pt\")[\"model_state_dict\"],\n            strict=False\n        )\n        logging.info(self.network.eval())\n\n    # Makes a prediction\n    def predict(self, X, features_names=None):\n        return self.network.forward(X)\n```", "```py\ndocker run -it -v $(pwd):/app -p 9000:9000 kylegallatin/seldon-example\n    seldon-core-microservice MyModel --service-type MODEL\n```", "```py\n2023-03-11 14:40:52,277 - seldon_core.microservice:main:578 -\n    INFO:  Starting microservice.py:main\n2023-03-11 14:40:52,277 - seldon_core.microservice:main:579 -\n    INFO:  Seldon Core version: 1.15.0\n2023-03-11 14:40:52,279 - seldon_core.microservice:main:602 -\n    INFO:  Parse JAEGER_EXTRA_TAGS []\n2023-03-11 14:40:52,287 - seldon_core.microservice:main:605 -\n    INFO:  Annotations: {}\n2023-03-11 14:40:52,287 - seldon_core.microservice:main:609 -\n    INFO:  Importing MyModel\n2023-03-11 14:40:55,901 - root:__init__:25 - INFO:  SimpleNeuralNet(\n  (sequential): Sequential(\n    (0): Linear(in_features=10, out_features=16, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=16, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=1, bias=True)\n    (5): Dropout(p=0.1, inplace=False)\n    (6): Sigmoid()\n  )\n)\n2023-03-11 14:40:56,024 - seldon_core.microservice:main:640 -\n    INFO:  REST gunicorn microservice running on port 9000\n2023-03-11 14:40:56,028 - seldon_core.microservice:main:655 -\n    INFO:  REST metrics microservice running on port 6000\n2023-03-11 14:40:56,029 - seldon_core.microservice:main:665 -\n    INFO:  Starting servers\n2023-03-11 14:40:56,029 - seldon_core.microservice:start_servers:80 -\n    INFO:  Using standard multiprocessing library\n2023-03-11 14:40:56,049 - seldon_core.microservice:server:432 -\n    INFO:  Gunicorn Config:  {'bind': '0.0.0.0:9000', 'accesslog': None,\n    'loglevel': 'info', 'timeout': 5000, 'threads': 1, 'workers': 1,\n    'max_requests': 0, 'max_requests_jitter': 0, 'post_worker_init':\n    <function post_worker_init at 0x7f5aee2c89d0>, 'worker_exit':\n    functools.partial(<function worker_exit at 0x7f5aee2ca170>,\n    seldon_metrics=<seldon_core.metrics.SeldonMetrics object at\n    0x7f5a769f0b20>), 'keepalive': 2}\n2023-03-11 14:40:56,055 - seldon_core.microservice:server:504 -\n    INFO:  GRPC Server Binding to 0.0.0.0:5000 with 1 processes.\n2023-03-11 14:40:56,090 - seldon_core.wrapper:_set_flask_app_configs:225 -\n    INFO:  App Config:  <Config {'ENV': 'production', 'DEBUG': False,\n    'TESTING': False, 'PROPAGATE_EXCEPTIONS': None, 'SECRET_KEY': None,\n    'PERMANENT_SESSION_LIFETIME': datetime.timedelta(days=31),\n    'USE_X_SENDFILE': False, 'SERVER_NAME': None, 'APPLICATION_ROOT': '/',\n    'SESSION_COOKIE_NAME': 'session', 'SESSION_COOKIE_DOMAIN': None,\n    'SESSION_COOKIE_PATH': None, 'SESSION_COOKIE_HTTPONLY': True,\n    'SESSION_COOKIE_SECURE': False, 'SESSION_COOKIE_SAMESITE': None,\n    'SESSION_REFRESH_EACH_REQUEST': True, 'MAX_CONTENT_LENGTH': None,\n    'SEND_FILE_MAX_AGE_DEFAULT': None, 'TRAP_BAD_REQUEST_ERRORS': None,\n    'TRAP_HTTP_EXCEPTIONS': False, 'EXPLAIN_TEMPLATE_LOADING': False,\n    'PREFERRED_URL_SCHEME': 'http', 'JSON_AS_ASCII': None,\n    'JSON_SORT_KEYS': None, 'JSONIFY_PRETTYPRINT_REGULAR': None,\n    'JSONIFY_MIMETYPE': None, 'TEMPLATES_AUTO_RELOAD': None,\n    'MAX_COOKIE_SIZE': 4093}>\n2023-03-11 14:40:56,091 - seldon_core.wrapper:_set_flask_app_configs:225 -\n    INFO:  App Config:  <Config {'ENV': 'production', 'DEBUG': False,\n    'TESTING': False, 'PROPAGATE_EXCEPTIONS': None, 'SECRET_KEY': None,\n    'PERMANENT_SESSION_LIFETIME': datetime.timedelta(days=31),\n    'USE_X_SENDFILE': False, 'SERVER_NAME': None, 'APPLICATION_ROOT': '/',\n    'SESSION_COOKIE_NAME': 'session', 'SESSION_COOKIE_DOMAIN': None,\n    'SESSION_COOKIE_PATH': None, 'SESSION_COOKIE_HTTPONLY': True,\n    'SESSION_COOKIE_SECURE': False, 'SESSION_COOKIE_SAMESITE': None,\n    'SESSION_REFRESH_EACH_REQUEST': True, 'MAX_CONTENT_LENGTH': None,\n    'SEND_FILE_MAX_AGE_DEFAULT': None, 'TRAP_BAD_REQUEST_ERRORS': None,\n    'TRAP_HTTP_EXCEPTIONS': False, 'EXPLAIN_TEMPLATE_LOADING': False,\n    'PREFERRED_URL_SCHEME': 'http', 'JSON_AS_ASCII': None,\n    'JSON_SORT_KEYS': None, 'JSONIFY_PRETTYPRINT_REGULAR': None,\n    'JSONIFY_MIMETYPE': None, 'TEMPLATES_AUTO_RELOAD': None,\n    'MAX_COOKIE_SIZE': 4093}>\n2023-03-11 14:40:56,096 - seldon_core.microservice:_run_grpc_server:466 - INFO:\n    Starting new GRPC server with 1 threads.\n[2023-03-11 14:40:56 +0000] [23] [INFO] Starting gunicorn 20.1.0\n[2023-03-11 14:40:56 +0000] [23] [INFO] Listening at: http://0.0.0.0:6000 (23)\n[2023-03-11 14:40:56 +0000] [23] [INFO] Using worker: sync\n[2023-03-11 14:40:56 +0000] [30] [INFO] Booting worker with pid: 30\n[2023-03-11 14:40:56 +0000] [1] [INFO] Starting gunicorn 20.1.0\n[2023-03-11 14:40:56 +0000] [1] [INFO] Listening at: http://0.0.0.0:9000 (1)\n[2023-03-11 14:40:56 +0000] [1] [INFO] Using worker: sync\n[2023-03-11 14:40:56 +0000] [34] [INFO] Booting worker with pid: 34\n2023-03-11 14:40:56,217 - seldon_core.gunicorn_utils:load:103 - INFO:\n    Tracing not active\n```", "```py\ncurl -X POST http://127.0.0.1:9000/predict  -H 'Content-Type: application/json'\n    -d '{\"data\": {\"ndarray\":[[0, 0, 0, 0, 0, 0, 0, 0, 0]]}}'\n```", "```py\n{\"data\":{\"names\":[\"t:0\",\"t:1\",\"t:2\",\"t:3\",\"t:4\",\"t:5\",\"t:6\",\"t:7\",\"t:8\"],\n    \"ndarray\":[[0,0,0,0,0,0,0,0,0]]},\"meta\":{}}\n```"]