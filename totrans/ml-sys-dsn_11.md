# 9 错误分析

### 本章涵盖

+   学习曲线分析

+   剩余分析

+   在残差中寻找共性

一旦我们组装了初始的构建块，包括收集第一个数据集、选择指标、定义评估程序和训练基线，我们就准备好开始迭代调整过程。正如神经网络中的反向传播计算最快损失减少的方向并将它从层到层传递回去一样，错误分析找到了整个系统的最快改进方式。

错误分析成为指导系统迭代更新的指南针。它帮助你在训练阶段（学习曲线分析）和预测阶段之后（残差分析）理解错误动态。通过分析这些错误，你可以识别出共性、趋势和模式，这些可以指导你改进机器学习（ML）系统。在本章中，我们将考察其关键阶段和类型，并提供我们希望有助于你更好地理解这一主题的示例。

错误分析在为机器学习系统设计时常常被忽略，这看似是一个合理的理由——因为这个步骤本身并不属于*构建系统*的过程。然而，在错误分析上花费的时间总是值得的，因为它揭示了系统的弱点，并提出了改进系统的方法。如果我们在这本书中省略这一步骤，那将是我们的一大失误。

## 9.1 学习曲线分析

学习曲线分析通过绘制和分析学习曲线来评估学习过程，显示了模型训练性能与所用训练数据量之间的关系。学习曲线分析旨在回答两个关键问题：

+   模型是否收敛？

+   如果是这样，我们是否避免了欠拟合或过拟合问题？

如果这两个问题都得到了否定的答案，就没有必要进行剩余的分析。

在我们深入细节之前，什么是学习曲线？这个术语起源于行为心理学，在那里它被用来显示在一段时间内观察到的个人或动物的学习进度（见图 9.1）。例如，我们可能分析受试者在每次新测试迭代中犯的错误数量，或者研究老鼠在迷宫中找到路径所需的时间与试验次数的比较。

![图](img/CH09_F01_Babushkin.png)

##### 图 9.1 学习曲线的基本表示

在机器学习中，学习曲线本质上是一种图形表示，显示了所选指标对特定数值属性（如迭代次数、数据集大小或模型复杂性）的依赖性。让我们简要地分解这三个属性：

+   *迭代次数—*这种曲线描绘了训练过程中损失或指标的变化，有助于检查模型是否收敛。在某些资料中，它被称为损失曲线或收敛曲线。迭代的一个好例子是神经网络中的训练轮数。

+   *模型复杂度—*这种类型的学习曲线显示了模型性能如何随着模型复杂度的变化而变化。随着复杂度的增加，模型倾向于更好地拟合训练数据，但可能开始对未见过的数据泛化不佳。模型复杂度的参数示例包括树深度、特征数量以及神经网络中的层数。

+   *数据集大小—*这条学习曲线揭示了训练数据集中样本数量如何影响模型的表现。这有助于确定模型是否能够从更多数据中受益。

这些特性揭示了三种最常见的学习曲线类型。在深入探讨每一种之前，我们应该回顾“机器学习的圣杯追求”，即过拟合和欠拟合问题，有时也被称为偏差-方差权衡（见图 9.2）。

![figure](img/CH09_F02_Babushkin.png)

##### 图 9.2 随着模型参数数量的增加，训练误差趋于越来越低，同时最小化偏差。同时，模型方差增加，为我们提供了一个 U 形的验证误差。

### 9.1.1 过拟合和欠拟合

过拟合发生在模型在训练数据上表现出色，而在未见过的数据上表现不佳的情况下。通常，这是因为它对训练数据学得太好，变得过于专业化，无法泛化，过分关注新数据中不存在的细微细节和模式。

另一方面，当模型过于简单，错过了特征与目标变量之间的一些重要关系时，就会发生欠拟合，导致在训练数据和新的数据上表现都较差。

这两种情况都与偏差-方差权衡密切相关，这是模型复杂度与输入数据量之间的平衡。模型从数据中捕捉有用信号的能力越强，偏差就越低，过拟合的风险就越高。另一方面，减少方差需要降低复杂度，这会导致模型偏差增加。

*偏差*是由模型捕捉数据中有用信号的能力低而引起的错误。换句话说，模型倾向于对其关于数据的简化假设。当模型有偏差时，我们称之为*欠拟合*。

*方差*是由模型对训练集中微小波动的过高敏感性引起的错误。模型在新数据上的泛化能力较差，从模型参数的角度来看，这些数据与训练集中看到的数据差异很大。通常，高方差是*过拟合*（假设系统其他部分没有问题）的主要原因。

一个好的学习算法应该同时最小化偏差和方差。然而，偏差-方差权衡却生动地展示了减少方差往往涉及增加偏差，反之亦然。这里的追求就是在这两者之间找到合适的平衡。这时，学习曲线分析就能为我们提供指导。

请记住，模型的冗余复杂性（即高方差）并不是过拟合的唯一原因。其他可能的情况包括

+   *数据泄露*（在推理过程中使用不应知道的信息）

+   *噪声或高度细粒度的特征*迫使模型捕捉无关的模式

+   *异常值的存在*对损失函数有重大影响

+   模型整体*外推能力*较差

+   训练集和验证集简单地属于*different distributions*

不论是哪种情况，学习曲线都是检测欠拟合和过拟合的有效工具。掌握了关于过拟合和欠拟合的知识，我们就准备好去分析不同类型的曲线以及它们在这个追求中给出的提示。

### 9.1.2 损失曲线

当机器学习工程师听到“学习曲线”这个词时，首先想到的是基于学习迭代的损失曲线（也称为收敛曲线或学习曲线）。它显示了算法随着将越来越多的学习努力投入到任务中而不断改进的情况。

曲线在垂直轴上绘制损失（或指标），在水平轴上绘制训练迭代次数（或时期）。随着模型的训练，损失应该减少，理想情况下形成一个向曲线底部的下降斜率。

与学习曲线不同，其中 X 轴是数据集大小或模型复杂性（我们很快就会讨论），迭代曲线只需要一次训练运行，这使得即使对于大型数据集，当单次训练运行需要数小时甚至数天时，其跟踪也是实用的。损失曲线有助于在整个训练过程中保持对脉搏的把握。如果你只运行了 200 个训练时期中的 10 个，你就可以了解损失值是否按预期进展，或者是否存在使进一步训练无意义的问题。

一定要跟踪损失曲线，收集所有进行的实验的损失曲线，并使它们可用于未来的分析。在构建训练流程的早期阶段就将其纳入损失曲线监控是一个非常有价值的单次努力，因为您将需要这些洞察来用于所有未来的实验，并且对整个流程的可重复性有帮助（我们将在第十章深入探讨这个主题）。

### 9.1.3 解释损失曲线

损失曲线的行为存在几种主要模式，与设计期望不符。让我们简要分析每种模式，并看看我们如何解释在调试系统时可能遇到的不同模式（可以得出什么结论，以及应采取哪些步骤来调试检测到的问题）。

#### 模式 1

模式 1 表明损失曲线发散（没有收敛到期望的损失值，而是振荡；参见图 9.3）。我们如何尝试使训练过程更稳定？考虑以下因素：

+   检查特征和目标是否以任何方式相关——或者样本和标签是否按正确顺序传递给模型。

+   降低学习率以防止模型在参数空间中弹跳。

+   将数据集大小减少到单个批次（或 10-100 个样本），并检查模型是否能够过度拟合它们。

+   从一个更简单的模型开始，逐步增加复杂性。每次，检查它是否优于恒定基线或基于规则的基线。

![figure](img/CH09_F03_Babushkin.png)

##### 图 9.3 损失在振荡，这表明没有收敛。

#### 模式 2

模式 2 表明损失爆炸或趋向于 NaN（不是一个数字）（参见图 9.4）。这种行为表明，当梯度爆炸（在这种情况下，梯度裁剪、降低学习率或不同的权重初始化技术等解决方案可能有所帮助）或出现某些数学问题时（例如，除以零、零或负数的对数、或数据中的 NaN——因此，这通常表明实现错误或数据预处理不足）。

![figure](img/CH09_F04_Babushkin.png)

##### 图 9.4 模型在出现错误之前一直在收敛。

#### 模式 3

模式 3 表明损失在下降，但指标是矛盾的（参见图 9.5）。如果模型根据损失继续改进，但指标停滞不前，这可能表明所选指标不适合该问题或实现不当。通常，这种情况发生在分类和其他相关任务中，我们使用包括一定阈值的指标。

![figure](img/CH09_F05_Babushkin.png)

##### 图 9.5 损失在下降，而指标保持恒定低。

##### Valerii 的篝火故事

当我在一家提供消息服务公司的公司工作时，我们的一项任务是改进现有的反垃圾邮件和反欺诈系统。我们面临的主要挑战是，在给定数据集上训练的模型在离线测试期间显示出有希望的指标，但在部署后并没有达到预期的效果。

在深入调查可能的原因后，我们发现存在三个主要问题：

+   我们没有使用适当的指标进行离线测试。例如，像在定义的召回率下的精确度这样的指标对于欺诈检测并不那么有用，因为它们是类别敏感的（精确度），而在定义的召回率下的特异性则产生了更好的结果（参见第五章）。然而，召回率本身就像薛定谔的猫一样，因为我们从未完全了解欺诈的全貌（我们错过了欺诈案例，也不知道有多少）；因此，我们的召回率只能基于已知欺诈案例的子集来计算。

+   第二个问题隐藏在性能评估中。我们基于点估计进行评估，但现实往往偏离点估计，考虑到每天有 1000 亿个事件这一规模，即使是 0.1%的偏差也会导致与预期相比有显著的错误分类事件数量（1 亿）。

+   第三个问题在于我们通过垃圾邮件/非垃圾邮件的二分类来评估系统，使用对数损失作为损失函数。我们真正需要的是让用户满意并将垃圾邮件减少到适当的水平（总是会有垃圾邮件，但有时并不是大问题，有时则是个问题），排除像在 1 秒内从单个号码接收 10 万条消息这样的情况。

虽然前两个问题具有挑战性但尚可管理，但第三个问题极其复杂，需要适当的指标层次结构、自定义损失函数以及持续实验。

这就是机器学习的本质：我们使用特定的损失函数训练模型，我们使用不同的指标集来衡量其性能，希望得到与第一和第二次不同的结果，迟早我们会遇到一个平台期，其中第一个甚至第二个元素有所改善，但第三个元素没有反应。

我们从这个案例中学到的最重要的教训是，尽管你可以调整你的错误分析直到达到完美，但如果一开始就错误地选择了指标，这并不能让你免于灾难。

#### 模式 4

模式 4 显示了训练曲线的收敛以及意外的损失值。虽然训练曲线的曲率看起来很有希望，但观察到的值令人困惑。为了提前识别这样的异常，建议通过在一个批次上运行简单的单元测试来执行合理性检查，以确认损失是否在预期的范围内。通常，这种问题的原因在于缩放变换（例如，图像或分割中的掩模归一化）。

#### 模式 5

![figure](img/CH09_F06_Babushkin.png)

##### 图 9.6 训练损失在下降，但验证损失没有下降，反映了潜在的过拟合。

模式 5 显示，训练损失在下降，而验证损失在上升（见图 9.6）。这是由于高方差导致的过拟合的经典教科书示例。在这些情况下，你应该限制模型的容量，要么直接减少其复杂性，要么通过增加正则化来实现。

### 9.1.4 模型级学习曲线

在我们确保模型收敛并且训练损失达到平台期，没有剧烈的过拟合或欠拟合之后，我们可以结束学习曲线分析并继续前进。这在初始部署阶段尤其相关。

然而，如果我们面临过拟合/欠拟合问题，或者有足够的时间实验最佳模型大小，那么第二种类型的学习曲线就派上用场了（见图 9.7）：

1.  首先，我们选择一个代表可变模型复杂性的超参数。再次，它可能是梯度提升中的树深度，正则化强度，特征数量，或者深度神经网络中的层数。

1.  我们为这个超参数定义一个网格（例如，树深度的 2，3，4，……，16；正则化项的 10^(-2)，10^(-1)，1，10，10²，10³）。

1.  我们训练每个模型直到收敛，并捕获最终的损失/指标值。

![图像](img/CH09_F07_Babushkin.png)

##### 图 9.7 基于学习曲线寻找最佳模型复杂性

现在，我们将这些值映射到垂直轴上，并将相应的超参数值映射到水平轴上。这个学习曲线帮助我们轻松地看到对于给定的数据，哪个模型复杂度范围（由这个超参数决定）是最优的。

### 9.1.5 样本级学习曲线

最后，让我们改变数据集的大小。我们在第六章第 6.4 节中详细讨论了这项技术。简而言之，我们保持验证集不变，并在训练集中探测不同数量的样本：100，1,000，10,000 等等。就像在模型级学习曲线中一样，我们训练模型直到其收敛，并绘制训练和验证学习曲线。

如果我们外推验证指标，我们可以估计需要多少新数据才能使指标增加 1%，反之亦然。如果我们预计收集 N 个更多数据样本，我们可以预测这将带来多少指标提升。

除了这种外推之外，样本级学习曲线还起到揭示过拟合和欠拟合的作用。具体来说，通过分析训练和验证曲线，我们能得到哪些见解？

+   如果曲线几乎收敛（在最大样本数时曲线之间存在小的或没有差距），则模型泛化良好，无需向数据集中添加更多样本，因为这不会提高模型性能。

+   具体来说，如果训练和验证曲线几乎收敛，但损失水平在两者中都保持较高，则报告高偏差问题（欠拟合）。在这种情况下，增加数据集大小也不会有所帮助。可能有益的是使用更复杂的模型。

+   如果曲线之间存在较大差距，这表明存在高方差问题或训练集和验证集之间的简单差异。在前一种情况下，我们应该减少模型复杂性或收集更多数据来解决这个问题。在后一种情况下，我们需要检查数据拆分过程，并确保它公平地代表模型将遇到的现实世界场景。

按样本阶段的学习曲线表明当前系统中的瓶颈是否是数据量。理解指标对数据集大小的依赖性指导我们下一步改进系统，这可能包括收集更多数据和投入精力进行特征工程以及模型超参数调整。

### 9.1.6 双重下降

偏差-方差权衡在经典机器学习模型和适度规模的深度神经网络中像时钟一样运行。然而，对于现代过参数化的深度神经网络，事情变得更加复杂。

存在一种称为*双重下降*的现象，其中测试误差首先变好，然后变差，然后再变好。令人惊讶的是，研究人员发现与所有三个学习曲线相对应的不同双重下降阶段：按时间阶段、按模型阶段和按样本阶段。

双重下降背后的机制是什么，为什么它会发生，以及它是否意味着大型深度神经网络的重过拟合不是一个问题，这仍然是一个未解之谜。双重下降背后的常见假设如下：

+   如果模型的容量（参数数量）低于数据集大小，它试图逼近数据，导致偏差-方差权衡发生的经典阶段。我们称这种模型为*欠参数化*。

+   在插值阈值处，模型有足够的能力完美地拟合训练数据并达到零偏差。在这个参数空间中实际上只有一个这样的模型。强迫这个模型拟合甚至稍微有噪声的标签将破坏其全局结构。

+   然而，在过参数化阶段，有许多这样的模型。其中一些不仅插值训练集，而且在测试集上表现良好。结果发现，随机梯度下降由于我们尚未理解的原因导致这些“好模型”。

对于更详细的信息，我们建议阅读 OpenAI 的《深度双重下降》（[`openai.com/index/deep-double-descent/`](https://openai.com/index/deep-double-descent/))。

大型神经网络的现代缩放定律重新定义了我们的建模策略。双下降现象可能会让那些只熟悉经典偏差-方差权衡的人感到惊讶，在选择系统模型时（尤其是在处理大型卷积网络和变压器时）以及确定训练和调试程序时，考虑这一点至关重要。

我们在这里只提到这一点，以强调之前描述的大多数启发式方法并不是一成不变的定律。就像机器学习设计中许多事情一样，它们揭示了信号——通常是很有用的信号——但可能并不完全适合特定的问题。

## 9.2 残差分析

> 当然，提出新想法很重要，但更重要的是理解结果。——伊利亚·苏茨克维

一旦我们确保了机器学习模型已经收敛并且没有受到欠拟合或过拟合的困扰，模型调试的下一步就是进行残差分析。这涉及到研究模型做出的单个预测与其相应的真实标签之间的差异。残差分析包括计算预测值和实际值之间的差异，称为*残差*（见图 9.8）：

*residual[i] = y_pred[i] – y_true[i]*

首先，残差究竟是什么？在狭义上，残差仅仅是回归中预测值和真实值之间的差异。在广义上，残差可以是模型预测和真实值之间的任何样本级差异或误差。

![figure](img/CH09_F08_Babushkin.png)

##### 图 9.8 基本情况：单个回归器 x。每条垂直线代表一个残差误差（e）或简单地说是残差。回归器上方的线带有负号（实际值高于预测值），而回归器下方的线带有正号。

因此，为了将残差与特定的损失函数对齐，你可能更愿意使用损失总和的单个项作为伪残差，而不是原始差异，这些差异对于均方误差是平方误差，对于均方对数误差是对数误差，对于 LogLoss 是类别标签乘以该类别的预测概率。

通常，残差仅与回归和分类任务相关联。但回归和分类任务之外的残差又如何呢？从更广泛的角度来看，我们几乎可以在任何与机器学习相关的任务中找到等效的工具。

例如，在搜索引擎的背景下，真实标签通常是从搜索查询到前 N 个最相关文档或产品的映射。为了计算这种背景下的残差，我们可以测量模型预测的排名与列表中每个项目的真实排名之间的差异（见图 9.9）。

![figure](img/CH09_F09_Babushkin.png)

##### 图 9.9 图像分割问题的残差示例（图片来源：[`arxiv.org/abs/1810.13230`](https://arxiv.org/abs/1810.13230))

在图像分割中，我们可以计算每个图像的预测和真实掩码之间的差异，这会产生二维残差，突出显示哪些对象的部分没有被掩码覆盖或被错误地覆盖。

### 9.2.1 残差分析的目标

残差分析有助于识别模型所犯错误中的模式，以便我们可以检测到改进系统的明确方向。与模型的整体误差通常用一个单一的数字表示，如损失或度量不同，残差分析则相反。它检查预测值和真实标签之间的原始差异，为模型性能提供更细致的诊断。

此外，残差分析还有其他主要目的：

+   *验证模型假设。* 首先，它挑战了我们关于模型的基本假设。残差是否遵循正态分布？模型的预测是否存在偏差？如果我们发现任何显著的差异，我们可能需要重新评估我们的方法或选择不同的模型。

+   *检测度量变化的原因。* 整体性能可能提高或保持不变。无论如何，捕捉度量分布的显著变化是可能的。哪些数据样本在不同模型中显示出不同的残差模式？在哪个数据子集中，我们错误答案的数量最多？哪些样本对最终分数的影响最大？

+   *确保残差的公平性。* 残差分析使我们能够评估模型是否公平地对待每个样本，并在不同的群体中具有相同的分布。如果我们发现任何显著的偏斜或不平等，我们可以做出相应的调整，以确保模型无偏见并平等地对待所有样本。

+   *执行最坏情况和最好情况分析。* 最大的 N 个残差样本之间是否存在共性？我们应该改变什么，以便我们的模型在这些情况下表现更好？对于最小的 N 个残差样本呢？

+   *检查边界情况。* 对于具有最短或最长历史记录的用户，或者根据我们解决的问题，最短/最长的音频记录、文本和会话，我们的模型表现如何？它如何处理价格最低/最高的项目、零库存或最高收入的项目？我们必须熟悉业务案例和数据性质，以评估所有可能的陷阱。

这些问题是残差分析的核心，找到这些问题的答案就关闭了离线评估的反馈循环。我们越早开始收集进行实验的硬样本（和损失曲线），就越好。在设计文档中，收集训练后具有最大残差的 10 到 20 个对象作为附属工件是一种好习惯。很难高估在设计文档的训练流程中思考这些步骤的价值。

在项目的后期阶段，我们将它转化为每个训练模型的自动报告的一部分，包括模型漂移监控和数据质量报告。假设大多数情况下指标有所增加，但在一个关键部分略有下降。根据我们的政策，我们可能要么拒绝这个版本，要么在未来的迭代中额外关注这种变化。

### 9.2.2 模型假设

无论我们训练哪种模型，我们对其预测、偏差和残差分布都有先验假设。假设检查帮助我们确保我们选择了正确的模型，收集了足够的数据，并构建了正确的特征。如果假设揭示出意外的模式，可能会促使我们探索替代解决方案。

再次，从设计角度来看，我们需要提前确定我们对模型预测或，具体来说，残差的真实假设是什么，并通过相应的单元测试来表达。这将防止在下次部署后出现意外的模型行为。在下一章中，我们将深入探讨测试的更全面概述及其在训练流程中的作用。让我们探索两个不同的例子，看看假设是如何应用的。

#### 示例 1\. 线性回归假设

假设我们使用简单的线性回归来解决需求预测问题。我们在这里做出了哪些关键假设？

+   *线性**—*预测变量（x）和目标（y）之间的关系是线性的。

+   *严格外生性**—*残差应该是零中心的。

+   *正态性**—*假设残差是正态分布的。

+   *同方差性**—*残差的方差对于任何 X 的值都是相同的。

+   *独立性**—*残差误差项应该是独立的。

在拟合我们的模型之后，我们检查这些假设是否成立。潜在问题包括

+   X-Y 关系中的 *非线性*

+   *偏差* 在残差中

+   *异方差性:* 错误项的非常数方差

+   存在具有 *极高影响* 的数据点：预测值（y）或回归变量（x）中的异常值

为了检查回归假设，我们将检查残差的分布。为此，我们以四种不同的方式绘制残差，并构建所谓的 *诊断图*（见图 9.10 和 9.11）：

+   *残差与拟合**—*用于评估线性关系的假设。一条没有明显模式的水平线表明存在线性关系，这是有利的。实线和虚线之间没有差异意味着强烈的线性依赖。

+   *正态分位数-分位数（Q-Q）图**—*用于检查残差是否正态分布。我们将标准正态分布的分位数作为 x 坐标，将标准化残差（减去均值并除以标准差后的残差）的分位数作为 y 坐标。如果得到的点接近直线（图上的虚线），则残差遵循正态分布。

+   *尺度-位置**—*用于评估残差中方差的一致性。一条水平线且点均匀分布是同方差性的强烈迹象。在我们的例子中并非如此，我们有一个异方差性问题（拟合值越高，方差越大）。

+   *残差与杠杆率**—*用于识别影响较大的案例，即可能影响回归结果时包含或排除分析中的极端值。*杠杆率*指的是如果我们从数据集中移除特定观测值，回归模型中的系数会改变的幅度。有一个常用的测量影响数据点的指标，称为库克距离（Cook’s Distance）。

![图](img/CH09_F10_Babushkin.png)

##### 图 9.10 两种情况（情况 1：假设成立）下线性回归残差分析的四个诊断图

![图](img/CH09_F11_Babushkin.png)

##### 图 9.11 两种情况（情况 2：假设不成立）下线性回归残差分析的四个诊断图

有时通过直接将我们的先验知识纳入模型，强制模型更严格地遵循我们的假设是有益的。

#### 示例 2. 注意力图

想象一下，你是银行应用程序的产品所有者，你的下一个重大更新是添加语音助手。在调查了你的“内圈”专家后，你聘请了 Stacy，一位在文本到语音（TTS）系统方面世界级的专家。经过几周的工作，Stacy 构建了一个语音合成系统的第一个版本。

在 TTS 任务领域，存在一个基本假设：文本中字符的顺序应该在对应音频段中随时间线性增长。当我们阅读文本时，自然会假设文本的位置与听到的音频紧密对齐。这与其他序列到序列任务形成对比，例如机器翻译，在这些任务中，需要一个注意力模块来解决不同句法或标记顺序的语言之间的词对齐，例如英语和中文。

为了评估这个假设的有效性，Stacy 使用了一个*注意力图*——一种视觉表示，描述了音频帧（x 轴）和字符（y 轴）之间的激活映射。通过在训练过程中定期观察这个图，Stacy 旨在评估它多么接近一个几乎对角线的矩阵。

为了使注意力矩阵呈现出接近对角线的模式，Stacy 采用了一种称为*引导注意力*的技术。每当注意力矩阵与对角线显著偏离时，它就会使用辅助损失进行惩罚。这种启发式方法不仅加速了训练过程，而且从一开始就引导模型朝着与潜在假设一致的有意义解决方案发展（见图 9.12）。

![图](img/CH09_F12_Babushkin.png)

##### 图 9.12 无（左）和有（右）引导注意力损失的注意力图训练演变

注意力图与对角矩阵的偏差不过是残差。适度的残差是合适的：人们说话的速度有快有慢；因此，图表不会代表一条直线。然而，大的残差揭示了模型无法很好地学习的特定声音或字符组合。

带着这些知识，Stacy 可以制定一个即将到来的数据收集策略，以解决模型的困难并提高其性能。

要了解更多关于典型 TTS 网络架构的信息，包括此情况下注意力模块构建的细节，我们建议研究论文“基于深度卷积网络和引导注意力的高效可训练语音合成系统”（[`arxiv.org/abs/1710.08969`](https://arxiv.org/abs/1710.08969)）。

### 9.2.3 残差分布

如果模型的所有假设都不成立，那么这是一个调整训练流程、收集更多数据、工程新特征或探索替代模型和损失的信号。但我们是怎样确定必要的改进步骤的呢？猜测和检查的方法可能看起来很有吸引力，但我们不建议用它来探索解决方案空间。

例如，让我们违反相同线性回归的正态性假设（图 9.13-9.15）。

![figure](img/CH09_F13_Babushkin.png)

##### 图 9.13 在案例 1 中，当线性假设成立时，我们观察到正态的残差分布。

![figure](img/CH09_F14_Babushkin.png)

##### 图 9.14 案例 2 展示了当目标变量的对数正态分布导致线性假设不成立时的非正态残差分布（分布中存在明显的偏斜）。

![figure](img/CH09_F15_Babushkin.png)

##### 图 9.15 在案例 3 中，由于目标变量对回归器的非单调依赖性，当线性假设不成立时，线性回归存在非正态的残差分布。

在这个例子中，我们很幸运，立刻就看到了模型的问题：

+   *案例 2—*我们似乎没有考虑目标变量的分布。像收入、销售额和价格这样的实体遵循对数正态分布，而回归模型最小化的均方误差或平均绝对误差（至少不是直接）不合适。为了克服这个问题，通常对目标变量应用对数变换有帮助。

+   *案例 3—*残差形成多个簇。在这种情况下，转换目标变量将没有任何帮助。目标变量对特征依赖性不是单调的。在这种情况下，可以尝试一个能够捕捉非单调依赖性的模型，或者工程新的特征，帮助线性模型将非单调依赖性降低到单调甚至线性。

### 9.2.4 残差的公平性

在机器学习（ML）中，公平性是数据中不平等的一个指标。个体样本是如何贡献到损失或指标的？我们通过什么成本来增加指标？新的模型是在残差中增加不平等还是减少它？基本上，“公平性”是定义残差分布偏斜的另一个术语。

并非每一次指标的变化都意味着平等。一些改进在所有样本中均匀分布，而其他改进在一个阶层中增加显著增长，同时引起其他阶层的减少。残差分析中的“公平性”概念推动我们朝着更全面的模型评估程序发展，远超估计单一值指标。

为了更好地理解什么是公平性，请考虑图 9.16。

![figure](img/CH09_F16_Babushkin.png)

##### 图 9.16 公平与不公平的残差分布

在这个简化的例子中，我们有两个模型。它们都通过 20%降低了平均绝对误差（MAE）。然而，我们更愿意部署第一个模型，因为它在所有 10 个样本中均匀地减少了绝对残差。相比之下，第二个模型在一半的样本上大幅提高了指标，而在另一半上减少了指标。在这种情况下，我们在残差分布中增加了不平等，因此我们称这种分布为不公平。

评估公平性的一个定量方法，而不是完全依赖可视化，是使用经济学中的基尼指数（见图 9.17）。为了计算它，残差应根据它们的绝对值进行排序，然后绝对值的累积比例应除以残差数量的累积比例。

![figure](img/CH09_F17_Babushkin.png)

##### 图 9.17 基尼系数的图形表示：该图显示基尼系数等于标记为 A 的面积除以标记为 A 和 B 的面积之和——即，基尼系数 = A/(A + B)。它也等于 2A 和 1 − 2B，因为 A + B = 0.5（因为坐标轴的刻度从 0 到 1）。

对于完全公平（基尼系数 = 0.0），几乎所有残差对总误差的贡献相同。对于完全不平等（基尼系数 = 1.0），单个残差在窃取覆盖。这些是你在现实生活中很少会遇到的两极，而常见的值总是在两者之间。

关注公平性的两个主要原因。首先，我们希望模型在所有用户、物品或其他实体上都有高性能，而不仅仅是其中的一部分。这也包括在系统的每次迭代中逐步减少残差的整体不平等。

其次，我们不仅希望提高整体误差数值，还希望减少每个残差。如果我们通过提高搜索引擎质量 5%来减少预测质量，那么它将使用户的一些部分的预测质量降低 20%，这会损害用户体验。通过提高平均质量所获得的收益可能会被这些用户流失率的增加所抵消。

从长远来看，我们追求所有层级的接近相等增长。每条规则都有例外，公平性对于每个项目和每个指标来说并不那么关键。我们应该注意残差分布尾部的误差成本。这应该定义我们平均和样本改进之间的权衡。

### 9.2.5 低估和过度预测

在回归任务中，我们通常根据符号来分割残差——正残差表示过度预测（预测值大于真实值），而负残差表示低估预测。

根据我们要解决的问题，模型的一个或另一个偏差可能更受欢迎。例如，如果我们正在构建一个需求预测系统，错失的利润不如适度的过剩库存那么令人不快。另一方面，如果我们为银行预测客户的信用度，我们最好低估它而不是高估它。

因此，错误的成本往往是非对称的，它应该告诉我们应该最关注哪些符号和大小残差。

### 9.2.6 弹性曲线

需求特定错误分析工具之一是弹性图。它不是一个适用于任何机器学习系统的通用工具，但由于它对于定价相关应用至关重要，值得我们关注。尽管我们之前讨论了大多数曲线形状的分析方法，但这个例子属于这里，因为它可以被视为残差分析的一个特例。

需求预测背后的核心模型假设之一是价格-需求依赖性——价格越高，需求越低，反之亦然。这几乎适用于所有类型的商品（除非是一些特殊案例，如凡勃伦商品和吉芬商品，如果你还记得微观经济学 101 的话）。

弹性图是更通用概念“部分依赖图”的一个特例，其中我们改变一些特征并分析预测结果如何变化。它用于模型可解释性（我们将在第十一章中介绍）。

有两种方式来绘制我们模型的弹性曲线：

+   使用训练数据（已知真实价格）：

    +   取特定 SKU 的销售历史

    +   预测每个数据点的销售（Y）

    +   取每个数据点（X）的历史价格

    +   绘制 X-Y（价格→预测销售）依赖关系图

+   使用合成数据和真实数据的混合：

    +   取特定 SKU 的最后价格

    +   将此价格乘以不同的系数（-20%，-19%，-18%，…，+19%，+20%）

    +   重新计算所有基于价格的特征，并预测每行的新销售（Y）

    +   绘制 X-Y（价格→预测销售）依赖关系图

正如我们之前提到的，在理想情况下，图表显示了反向依赖性：价格越高，销量越低。然而，如果这个图表显示了相反的情况，是嘈杂的（部分或全部非单调），或者有任何其他争议性的模式，它将表明以下情况之一：

+   对于这个 SKU，我们没有足够的价格变化来捕捉其弹性（例如，销售历史很短）。

+   这个 SKU 的销售非常随机。例如，这个 SKU 经常受到促销活动、季节性或其他外部因素的影响）。

+   由于某种原因（“一个难题”），模型无法捕捉到它。

“更好”的图表（在负方向上更单调）意味着我们可以更多地依赖模型对这些 SKU 的预测。如果弹性“不好”，这表明预测不可靠，应该对这些“困难”SKU 进行进一步调查，而不是部署（见图 9.18 和 9.19）。

![figure](img/CH09_F18_Babushkin.png)

##### 图 9.18 需求弹性的理论示例

![figure](img/CH09_F19_Babushkin.png)

##### 图 9.19 需求无弹性的理论示例

不仅为预测销售绘制弹性曲线，还为实际销售绘制弹性曲线是有帮助的。了解这个特定的 SKU 是否显示出独特的弹性也很重要。如果它没有，我们不应该期望预测需求会有弹性。

如果你需要更多关于价格弹性概念的信息，我们推荐阅读文章“使用需求价格弹性进行预测”([`mng.bz/GN5v`](https://mng.bz/GN5v))。

我们的一位朋友最近讲述了他使用弹性曲线应用的故事。他一直在处理一个定价问题，他们的解决方案实际上是一个美化的弹性图。他们构建了一个梯度提升模型，使用各种特征来预测销售数量，包括基于价格的特性和对不同可能价格的估计销售。他们的第一个模型揭示了一个令人惊讶的模式：图表看起来并不平滑，而是有一个明显的“梯子”状步骤。经过更深入的分析，他们意识到这些步骤的起源与使用的特征有关；连续变量被分割成低基数（例如，对于市场上所有商品的可能的全部价格，只有 256 个桶），这限制了模型敏感性。在增加桶的数量后，模型能够捕捉到更详细的模式，弹性曲线变得平滑，从而提高了整体系统性能。

## 9.3 在残差中寻找共同点

现在我们已经整体考察了残差分布，是时候研究残差子组中的模式和趋势了。为此，我们从两端来解决这个问题（见图 9.20）：

+   我们根据样本的残差将样本分组，并分析每个组中的特征。

+   我们根据样本的特征将样本分组，并分析每个组中的残差。

![figure](img/CH09_F20_Babushkin.png)

##### 图 9.20 寻找残差共同点的两种方法：通过残差排名或通过样本属性选择子集

按值分组残差包括最坏/最好情况分析；它还涵盖了过度预测和不足预测问题。按属性分组残差产生分组分析和边界情况分析。

### 9.3.1 最坏/最好情况分析

最坏/最好情况分析的目标是定义模型运行良好的典型情况以及我们应该避免基于此模型做出决策的情况。在这些极端情况下，残差有什么共同之处？

##### Valerii 的篝火故事

回到前几章提到的案例，一旦我们在一个大市场中部署了一个基于预测需求的动态定价系统，我们就开始遇到它无法准确预测销售的情况。我们决定专注于剩余量最大的前 200 个产品。很快，我们就意识到最明显的问题集群：

+   第一个集群围绕着最近添加到市场组合矩阵中的**新产品**，这个问题被称为**冷启动**问题。这些商品由于缺乏历史数据而难以准确预测，构成了挑战。很明显，仅依靠我们的机器学习模型在这种情况下是不够的。相反，我们需要开发启发式方法，利用同一类别内产品的销售升温来为预测建立一个坚实的基础。

+   另一个集群来自**电子设备类别**，揭示了不同的困境。这些产品在时间上的销售稀疏，使得依赖我们模型的预测变得困难。意识到这一点，我们做出了一个关键的决定，将这批商品排除在我们的试点之外，并探索提高预测质量的其他方法。我们考虑了将模型分成更大类别的想法，相信这将更有效地捕捉每个组内的特定动态。

+   然而，最大的偏差是由**营销活动**——**大促销、促销代码和折扣——引起的。模型难以解释这些因素，导致明显的不足预测，表现为大的负残差。为了纠正这种偏差，我们将促销日历纳入我们的特征集。通过这样做，我们使模型能够做出相应的调整，从而提高预测的准确性。

除了确定我们的模型不足的领域外，我们还研究了接近零的残差，以确定我们模型适用性的边界。这种分析帮助我们了解在哪些情况下我们可以对模型的预测有信心，在哪些情况下质量可能令人满意但处于可接受范围内，以及在哪些情况下依赖模型的预测变得风险。

通过检查这些残差模式，我们全面了解了我们的动态定价系统的优势和局限性，使我们能够就其推广做出明智的决定，并确保其适当的使用。

### 9.3.2 对抗验证

如果手动最坏情况分析不会提供新的见解，一个“用于分析机器学习模型的机器学习模型”可能会有所帮助。在第七章中，我们讨论了一个称为对抗验证的概念。它源于机器学习竞赛，用于检查两个数据集的分布是否不同。通常，我们会将带有标签 0 和 1 的数据集连接起来，进行训练和测试。

对抗验证可以轻松转移到残差分析的轨道上：我们将“好”样本数据设置为 0，“坏”样本数据设置为 1（例如，在第二种情况下，取最大的 N%残差）。我们应该尝试为我们的特定集合尝试不同的阈值。

算法的其余部分类似：我们在这些标签上拟合一个简单的分类器（例如，逻辑回归）并计算接收者操作特征曲线下的面积（ROC AUC）。如果两个类别是可分离的（曲线下的面积显著大于 0.5），那么我们分析模型的权重，这为我们提供了关于哪些确切特征最能区分我们的“最坏”案例的线索。

有时在最坏情况分析中找不到容易定义的模式。这是可以的。这意味着我们已经在模型改进空间中捕获了最大的低垂之果。

### 9.3.3 组分析的多样性

组分析能够识别各种群体、段、类别、队列或集群的残差中的独特模式和趋势。例如，在二进制和多类分类场景中，一种有效的方法是按类别（即目标变量）拆分残差，允许对每个组中的残差进行单独分析。

许多处理表格数据的典型应用，如欺诈检测系统，依赖于根据特定特征（如地理位置或流量来源）对样本进行分组。通过分析每个段内的残差，可以揭示模型预测中存在的共同偏差。这些见解可以指导通过纳入更多相关特征或调整现有特征的权重来进一步改进模型。

当处理文本、图像或视频形式的数据时，默认情况下可能没有明显的群体或分组。在这种情况下，一种替代方法涉及手动对一组 N 个残差进行分类，并为遇到的每个问题分配标签（例如，识别过暗或模糊的图像或标记具有特定措辞或风格的文本）。这个过程允许发现模型表现不佳的具体问题集群。因此，它提供了关于应收集哪种类型的数据以改进系统的指导。

### 9.3.4 边缘情况分析

边缘情况分析旨在测试模型在罕见情况下。通常，我们希望有一个基准，一个固定集合的已捕获的边缘情况，以便快速检查每个新模型的行为。

这里有一些关于我们在边缘情况分析期间可以检查的内容的想法：

+   *预测模型*——历史短暂或无历史的用户/物品、动作/销售数量极多的用户/物品、特征 X 的最高和最低值、动作/销售稀有的用户/物品

+   *图像分割*——低质量图像、低分辨率图像、高分辨率图像、遮挡和反射、异常光照条件、一张图像中的多个对象、图像中没有对象

+   *语言模型*——最短和最长的文本、笑话、冒犯性话题、简单的算术、带错别字的文本、包含 N 种不同语言的文本、大量使用表情符号

+   *语音识别*——最短或最长的音频、低质量音频、无语音音频、音乐而不是音频、发音过快或过慢的样本、嘈杂的环境、无声的语音、包含多个说话者的样本（即“鸡尾酒会”）

当最佳/最坏情况分析询问我们的模型在哪些数据上表现优秀或糟糕时，边缘情况分析和队列分析则询问模型在预定义数据子集上的性能。

##### 阿尔谢尼的篝火故事

当我在增强现实公司工作时，系统的一个重要部分是基于深度学习模型的关键点检测器。任务是识别几个关键点，这些关键点后来被用来理解物体坐标。从一开始，训练流程就使用了适当的诊断工具，所以我们早期就发现某些损失较高的样本表现出一个共同的模式——某些图像包含镜子或其他反射表面（甚至雨天的一个水坑！），模型无法区分关键点与其反射。这意味着我们需要从系统中获取额外的属性：选择“真实”的物体，记住它，并忽略属于反射物体的关键点。对这一问题的早期理解帮助我们调整解决方案，以减轻反射关键点的情况。

![侧边栏图像](img/CH09_F21_Babushkin.png)

##### 模型检测到真实的脚，而不是反射

## 9.4 设计文档：错误分析

因为我们坚信错误分析应该是机器学习系统设计的基本要素之一，所以我们将在我们的设计文档中包含这一阶段。

### 9.4.1 超级大零售的错误分析

我们从超级大零售开始，我们将提出一种帮助公司实现其主要目标的方法——尽可能缩小交付和销售物品之间的差距，同时避免缺货情况。

#### 设计文档：超级大零售

#### VI. 错误分析

记住，我们有针对目标值 1.5 分位数、25 分位数、50 分位数、75 分位数、95 分位数和 99 分位数的六个分位数损失，以及每个分位数对应的六个模型。常量基线根据产品过去 N 天的销售情况来估计每个产品的这些分位数。这些基线已经具有一些特定的残差分布和一些有用的特定偏差。

将更复杂的模型（线性模型和梯度提升）与这些基线模型进行比较，将帮助我们了解我们在建模和特征工程方面是否朝着正确的方向前进。

#### i. 学习曲线分析

##### i. 收敛分析

当我们开始尝试梯度提升算法时，基于迭代次数的逐步学习曲线才发挥作用。在检查损失曲线时，我们应该回答的关键问题是

+   模型是否真的收敛？

+   模型是否优于基线指标（分位数损失，平均绝对百分比误差等）？

+   是否存在欠拟合/过拟合等问题？

一旦我们确保模型收敛，我们可以在一个粗略的网格（500-1,000-2,000-3,000-5,000）上选择足够多的树，并固定用于未来的实验。对于更简单的基线，不需要进行收敛分析。

##### ii. 模型复杂性

我们将使用模型级学习曲线来决定最佳特征数量和整体模型复杂性。

假设我们固定所有超参数，除了我们使用的滞后数：我们取的越多，模型可以捕捉到的复杂模式和季节性就越多——并且更容易过拟合训练数据。应该是 N - 1，N - 2，N - 3 天？还是 N - 1，N - 2，……，N - 30 天？最佳数量可以通过“模型大小与错误大小”图来确定。

同样，我们可以优化窗口大小。例如，“7/14/21/…”这样的窗口比“30/60/90/…”更细粒度。通过使用模型级学习曲线，我们可以选择适当的粒度级别。

以同样的方式，我们在初始调整期间调整模型的其它关键超参数——例如，正则化项的大小。

##### iii. 数据集大小

我们是否需要使用所有可用数据来训练模型？需要多少个月的数据足够且相关？我们需要利用所有（日，店铺，商品）数据点，还是可以下采样 20%/10%/5%而不会在指标上明显下降？

救援来了：样本级学习曲线分析，它决定了验证集上的错误达到平台期所需的样本数量。

我们应该做出一个重要的设计决策，即是否将（日，店铺，商品）作为数据集的对象，或者转向更粗粒度（周，店铺，商品）。最后一个选项可以将所需的计算量减少 7 倍，同时模型性能可以保持不变，甚至可能提高。

这个设计决策不仅会影响预测服务的速度和性能，还会影响整体产品（库存管理系统），极大地重塑了其可能的用例。因此，尽管可能有优势，这个决策应该与我们的产品经理、用户（品类经理）和利益相关者达成一致。

#### ii. 残差分析

记住我们有一个非对称的成本函数：过剩库存远比缺货问题危害小。我们可能面临过期商品或错失利润。未满足的需求问题是一个更糟糕的情况，从长远来看，它体现在顾客的不满和增加的风险，即他们可能会转向竞争对手。

##### i. 残差分布

提到的需求特性应指导我们在预测模型残差分析中的整个过程：正残差（高估）比负残差（低估）更受欢迎。然而，过度高估同样不好。

因此，我们绘制了残差的分布图，以及它们的偏差（原始残差中的简单平均值）。我们期望在以下可能的场景之一中这是正确的：

+   小的正偏差表明略微高估，这是理想的结果。如果，此外，残差分布不广（方差低），我们就会得到一个完美的场景。

+   在负向和正向方向上均匀分布的残差是可以接受的，但不如前一种情况受欢迎。我们应该迫使模型产生更乐观的预测，以确保我们最小化错失的利润。

+   最糟糕的情况是我们对负残差有偏差。这意味着我们的模型倾向于增加顾客的不满。这肯定是对当前模型版本部署的一个红旗。

+   如果我们有偏差但有利于正残差，这无疑是 Supermegaretail 的好案例，因此不如第一种情况受欢迎。

这些场景适用于我们试图估计无偏需求（我们使用中位数预测）时。但如前所述，我们还有其他几个模型用于其他分位数（1.5%，25%，75%，95%，99%）。

![figure](img/CH09_UN01_Babushkin.png)![figure](img/CH09_UN02_Babushkin.png)

对于每一个模型，我们分析其背后的基本假设——例如：

+   对于预测 95%分位数的模型，95%的残差都是正的吗？

+   对于预测 25%分位数的模型，75%的残差都是负的吗？

##### ii. 弹性

我们应该使用弹性曲线验证弹性假设。对于所有商品是否都期望表现出弹性，没有明确的理解，这需要与利益相关者确认。

如果我们面临与弹性相关的问题，我们有两种选择来提高弹性捕捉：

+   *后处理*（快速、简单、临时解决方案）——我们可以应用一个额外的模型（例如，等调回归）进行预测后处理以校准预测。

+   *改进模型*（慢速、困难、通用解决方案）——这需要额外的建模、特征工程、数据预处理等。没有一组预定义的操作可以肯定地解决问题。

##### iii. 最佳情况 vs. 最坏情况 vs. 边缘情况

每次我们推出模型的新版本时，我们会自动报告其在最佳/最差/边缘情况下的性能，并将前 N%的案例保存为训练管道的工件。以下是一份清单草案，其中我们应在报告中找到答案：

+   当一个物品的销售历史较短时，模型的预测误差是多少？残差主要是正的还是主要是负的？

+   对于价格高或价格低的物品怎么办？

+   预测误差如何依赖于周末/假日/促销日？

+   几乎没有残差的物品之间有哪些共同点？是否必须要求它们有长期的销售历史？为了获得可接受的表现，销售历史应该有多长？模型是否需要其他条件，以帮助我们区分那些我们对预测质量有把握的情况？

+   具有最大负残差的物品之间有哪些共同点？我们 100%希望排除这些案例或整个类别从 A/B 测试组或试点中。当我们开始改进模型时，我们也应该关注这些物品。

+   具有最大正残差的物品有哪些共同点？

### 9.4.2 PhotoStock Inc.的错误分析

现在我们回到 PhotoStock Inc.，它需要一个现代的搜索工具，能够根据客户的文本查询找到最相关的照片，同时提供出色的性能并显示最相关的库存图像。

#### 设计文档：PhotoStock Inc.

#### VI. 错误分析

为了能够尽早诊断潜在问题，我们应该从一开始就包括错误分析工具。在本节文档中，我们希望提前规划一些我们想要关注的部分。

##### i. 学习曲线分析

+   应该启用损失曲线以进行合理性检查和进一步调整关键超参数，如早期停止阈值、学习率等。

+   由于我们的损失是复合的（包含多个组件；参见之前的指标和损失部分），我们需要能够看到每个组件的损失曲线，以便调整其权重。

+   应该能够在数据子样本上训练模型，以便稍后绘制样本大小学习曲线，并估计新数据如何提高整体性能。

+   与损失曲线并行，应该有度量曲线以确保它们有公平的相关性。

+   由于数据集可能被共享，我们需要能够看到每个分片（shard）的曲线。

##### ii. 残差分析

+   对于每个训练周期，我们应该报告最有趣的样本，例如整体和每个组件损失最高/最低的样本。

+   对于每个显示的样本，应该提供元数据，因此我们不仅报告搜索查询和相关的图像，还包括类别、标签、查询地理、查询语言和其他可能出现的属性。

在训练每个候选模型（被认为是足够好，可以用于实际系统的模型）之后，我们建议以下程序：

+   样本 100 个高损失/指标的结果。

+   对于每一个样本，建议提出一个简短假设来说明这个样本为何突出（例如，建议的图像模糊，图像描述过度优化，查询太短等），并按这些分辨率对这些结果进行分组。在计划系统改进的新步骤时，应进行进一步分析，因为它是一个重要的信号来源。

在未来，我们可以考虑在这里也应用可解释性技术，因为，在某个时候，诸如“为什么图像 X 在语义上与图像 Y 相似”这样的问题将会出现。然而，从当前的角度来看，它可以推迟。

## 摘要

+   在设计你的机器学习系统时，不要犹豫应用错误分析，因为它将帮助你揭示其弱点并提出改进的方法。

+   学习曲线分析是定义你模型效率的重要第一步。如果模型没有收敛，并且存在过拟合和/或欠拟合问题，就没有必要进行其他分析。

+   过拟合或欠拟合的存在是模型复杂性与输入数据量之间可能不平衡的指标。

+   根据你在错误分析期间观察到的损失曲线类型，你需要采取一系列行动来调试检测到的问题。

+   设计用于计算预测值和实际值之间差异的残差分析对于验证模型假设、检测指标变化的原因、确保残差的公平性、执行最坏情况和最佳情况分析以及检查边缘情况至关重要。
