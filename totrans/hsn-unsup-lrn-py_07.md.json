["```py\n# Import libraries\n'''Main'''\nimport numpy as np\nimport pandas as pd\nimport os, time\nimport pickle, gzip\n\n'''Data Viz'''\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nimport matplotlib as mpl\n\n%matplotlib inline\n\n'''Data Prep and Model Evaluation'''\nfrom sklearn import preprocessing as pp\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve, average_precision_score\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n```", "```py\n# Load the datasets\ncurrent_path = os.getcwd()\nfile = '\\\\datasets\\\\mnist_data\\\\mnist.pkl.gz'\n\nf = gzip.open(current_path+file, 'rb')\ntrain_set, validation_set, test_set = pickle.load(f, encoding='latin1')\nf.close()\n\nX_train, y_train = train_set[0], train_set[1]\nX_validation, y_validation = validation_set[0], validation_set[1]\nX_test, y_test = test_set[0], test_set[1]\n\n# Create Pandas DataFrames from the datasets\ntrain_index = range(0,len(X_train))\nvalidation_index = range(len(X_train), \\\n                         len(X_train)+len(X_validation))\ntest_index = range(len(X_train)+len(X_validation), \\\n                   len(X_train)+len(X_validation)+len(X_test))\n\nX_train = pd.DataFrame(data=X_train,index=train_index)\ny_train = pd.Series(data=y_train,index=train_index)\n\nX_validation = pd.DataFrame(data=X_validation,index=validation_index)\ny_validation = pd.Series(data=y_validation,index=validation_index)\n\nX_test = pd.DataFrame(data=X_test,index=test_index)\ny_test = pd.Series(data=y_test,index=test_index)\n```", "```py\n# Principal Component Analysis\nfrom sklearn.decomposition import PCA\n\nn_components = 784\nwhiten = False\nrandom_state = 2018\n\npca = PCA(n_components=n_components, whiten=whiten, \\\n          random_state=random_state)\n\nX_train_PCA = pca.fit_transform(X_train)\nX_train_PCA = pd.DataFrame(data=X_train_PCA, index=train_index)\n```", "```py\n# k-means - Inertia as the number of clusters varies\nfrom sklearn.cluster import KMeans\n\nn_clusters = 10\nn_init = 10\nmax_iter = 300\ntol = 0.0001\nrandom_state = 2018\nn_jobs = 2\n\nkMeans_inertia = pd.DataFrame(data=[],index=range(2,21), \\\n                              columns=['inertia'])\nfor n_clusters in range(2,21):\n    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, \\\n                max_iter=max_iter, tol=tol, random_state=random_state, \\\n                n_jobs=n_jobs)\n\n    cutoff = 99\n    kmeans.fit(X_train_PCA.loc[:,0:cutoff])\n    kMeans_inertia.loc[n_clusters] = kmeans.inertia_\n```", "```py\ndef analyzeCluster(clusterDF, labelsDF):\n    countByCluster = \\\n        pd.DataFrame(data=clusterDF['cluster'].value_counts())\n    countByCluster.reset_index(inplace=True,drop=False)\n    countByCluster.columns = ['cluster','clusterCount']\n```", "```py\n    preds = pd.concat([labelsDF,clusterDF], axis=1)\n    preds.columns = ['trueLabel','cluster']\n```", "```py\n    countByLabel = pd.DataFrame(data=preds.groupby('trueLabel').count())\n```", "```py\n    countMostFreq = \\\n        pd.DataFrame(data=preds.groupby('cluster').agg( \\\n                        lambda x:x.value_counts().iloc[0]))\n    countMostFreq.reset_index(inplace=True,drop=False)\n    countMostFreq.columns = ['cluster','countMostFrequent']\n```", "```py\n    accuracyDF = countMostFreq.merge(countByCluster, \\\n                        left_on=\"cluster\",right_on=\"cluster\")\n    overallAccuracy = accuracyDF.countMostFrequent.sum()/ \\\n                        accuracyDF.clusterCount.sum()\n```", "```py\n    accuracyByLabel = accuracyDF.countMostFrequent/ \\\n                        accuracyDF.clusterCount\n```", "```py\n# k-means - Accuracy as the number of clusters varies\n\nn_clusters = 5\nn_init = 10\nmax_iter = 300\ntol = 0.0001\nrandom_state = 2018\nn_jobs = 2\n\nkMeans_inertia = \\\n    pd.DataFrame(data=[],index=range(2,21),columns=['inertia'])\noverallAccuracy_kMeansDF = \\\n    pd.DataFrame(data=[],index=range(2,21),columns=['overallAccuracy'])\n\nfor n_clusters in range(2,21):\n    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, \\\n                max_iter=max_iter, tol=tol, random_state=random_state, \\\n                n_jobs=n_jobs)\n\n    cutoff = 99\n    kmeans.fit(X_train_PCA.loc[:,0:cutoff])\n    kMeans_inertia.loc[n_clusters] = kmeans.inertia_\n    X_train_kmeansClustered = kmeans.predict(X_train_PCA.loc[:,0:cutoff])\n    X_train_kmeansClustered = \\\n        pd.DataFrame(data=X_train_kmeansClustered, index=X_train.index, \\\n                     columns=['cluster'])\n\n    countByCluster_kMeans, countByLabel_kMeans, countMostFreq_kMeans, \\\n        accuracyDF_kMeans, overallAccuracy_kMeans, accuracyByLabel_kMeans \\\n        = analyzeCluster(X_train_kmeansClustered, y_train)\n\n    overallAccuracy_kMeansDF.loc[n_clusters] = overallAccuracy_kMeans\n```", "```py\n0    0.636506\n1    0.928505\n2    0.848714\n3    0.521805\n4    0.714337\n5    0.950980\n6    0.893103\n7    0.919040\n8    0.404707\n9    0.500522\n10   0.381526\n11   0.587680\n12   0.463382\n13   0.958046\n14   0.870888\n15   0.942325\n16   0.791192\n17   0.843972\n18   0.455679\n19   0.926480\ndtype:  float64\n```", "```py\n# k-means - Accuracy as the number of components varies\n\nn_clusters = 20\nn_init = 10\nmax_iter = 300\ntol = 0.0001\nrandom_state = 2018\nn_jobs = 2\n\nkMeans_inertia = pd.DataFrame(data=[],index=[9, 49, 99, 199, \\\n                    299, 399, 499, 599, 699, 784],columns=['inertia'])\n\noverallAccuracy_kMeansDF = pd.DataFrame(data=[],index=[9, 49, \\\n                    99, 199, 299, 399, 499, 599, 699, 784], \\\n                    columns=['overallAccuracy'])\n\nfor cutoffNumber in [9, 49, 99, 199, 299, 399, 499, 599, 699, 784]:\n    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, \\\n                max_iter=max_iter, tol=tol, random_state=random_state, \\\n                n_jobs=n_jobs)\n\n    cutoff = cutoffNumber\n    kmeans.fit(X_train_PCA.loc[:,0:cutoff])\n    kMeans_inertia.loc[cutoff] = kmeans.inertia_\n    X_train_kmeansClustered = kmeans.predict(X_train_PCA.loc[:,0:cutoff])\n    X_train_kmeansClustered = pd.DataFrame(data=X_train_kmeansClustered, \\\n                                index=X_train.index, columns=['cluster'])\n\n    countByCluster_kMeans, countByLabel_kMeans, countMostFreq_kMeans, \\\n        accuracyDF_kMeans, overallAccuracy_kMeans, accuracyByLabel_kMeans \\\n        = analyzeCluster(X_train_kmeansClustered, y_train)\n\n    overallAccuracy_kMeansDF.loc[cutoff] = overallAccuracy_kMeans\n```", "```py\n# k-means - Accuracy as the number of components varies\n# On the original MNIST data (not PCA-reduced)\n\nn_clusters = 20\nn_init = 10\nmax_iter = 300\ntol = 0.0001\nrandom_state = 2018\nn_jobs = 2\n\nkMeans_inertia = pd.DataFrame(data=[],index=[9, 49, 99, 199, \\\n                    299, 399, 499, 599, 699, 784],columns=['inertia'])\n\noverallAccuracy_kMeansDF = pd.DataFrame(data=[],index=[9, 49, \\\n                    99, 199, 299, 399, 499, 599, 699, 784], \\\n                    columns=['overallAccuracy'])\n\nfor cutoffNumber in [9, 49, 99, 199, 299, 399, 499, 599, 699, 784]:\n    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, \\\n                max_iter=max_iter, tol=tol, random_state=random_state, \\\n                n_jobs=n_jobs)\n\n    cutoff = cutoffNumber\n    kmeans.fit(X_train.loc[:,0:cutoff])\n    kMeans_inertia.loc[cutoff] = kmeans.inertia_\n    X_train_kmeansClustered = kmeans.predict(X_train.loc[:,0:cutoff])\n    X_train_kmeansClustered = pd.DataFrame(data=X_train_kmeansClustered, \\\n                                index=X_train.index, columns=['cluster'])\n\n    countByCluster_kMeans, countByLabel_kMeans, countMostFreq_kMeans, \\\n        accuracyDF_kMeans, overallAccuracy_kMeans, accuracyByLabel_kMeans \\\n        = analyzeCluster(X_train_kmeansClustered, y_train)\n\n    overallAccuracy_kMeansDF.loc[cutoff] = overallAccuracy_kMeans\n```", "```py\nimport fastcluster\nfrom scipy.cluster.hierarchy import dendrogram, cophenet\nfrom scipy.spatial.distance import pdist\n\ncutoff = 100\nZ = fastcluster.linkage_vector(X_train_PCA.loc[:,0:cutoff], \\\n                               method='ward', metric='euclidean')\nZ_dataFrame = pd.DataFrame(data=Z, \\\n    columns=['clusterOne','clusterTwo','distance','newClusterSize'])\n```", "```py\nfrom scipy.cluster.hierarchy import fcluster\n\ndistance_threshold = 160\nclusters = fcluster(Z, distance_threshold, criterion='distance')\nX_train_hierClustered = \\\n    pd.DataFrame(data=clusters,index=X_train_PCA.index,columns=['cluster'])\n```", "```py\nprint(\"Number of distinct clusters: \", \\\n      len(X_train_hierClustered['cluster'].unique()))\n```", "```py\nNumber of distinct clusters: 20\n```", "```py\ncountByCluster_hierClust, countByLabel_hierClust, \\\n    countMostFreq_hierClust, accuracyDF_hierClust, \\\n    overallAccuracy_hierClust, accuracyByLabel_hierClust \\\n    = analyzeCluster(X_train_hierClustered, y_train)\n\nprint(\"Overall accuracy from hierarchical clustering: \", \\\n      overallAccuracy_hierClust)\n```", "```py\nOverall accuracy from hierarchical clustering: 0.76882\n```", "```py\n0       0.987962\n1       0.983727\n2       0.988998\n3       0.597356\n4       0.678642\n5       0.442478\n6       0.950033\n7       0.829060\n8       0.976062\n9       0.986141\n10      0.990183\n11      0.992183\n12      0.971033\n13      0.554273\n14      0.553617\n15      0.720183\n16      0.538891\n17      0.484590\n18      0.957732\n19      0.977310\ndtype:  float64\n```", "```py\nfrom sklearn.cluster import DBSCAN\n\neps = 3\nmin_samples = 5\nleaf_size = 30\nn_jobs = 4\n\ndb = DBSCAN(eps=eps, min_samples=min_samples, leaf_size=leaf_size,\n            n_jobs=n_jobs)\n\ncutoff = 99\nX_train_PCA_dbscanClustered = db.fit_predict(X_train_PCA.loc[:,0:cutoff])\nX_train_PCA_dbscanClustered = \\\n    pd.DataFrame(data=X_train_PCA_dbscanClustered, index=X_train.index, \\\n                 columns=['cluster'])\n\ncountByCluster_dbscan, countByLabel_dbscan, countMostFreq_dbscan, \\\n    accuracyDF_dbscan, overallAccuracy_dbscan, accuracyByLabel_dbscan \\\n    = analyzeCluster(X_train_PCA_dbscanClustered, y_train)\n\noverallAccuracy_dbscan\n```", "```py\nOverall accuracy from DBSCAN: 0.242\n```", "```py\nimport hdbscan\n\nmin_cluster_size = 30\nmin_samples = None\nalpha = 1.0\ncluster_selection_method = 'eom'\n\nhdb = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, \\\n        min_samples=min_samples, alpha=alpha, \\\n        cluster_selection_method=cluster_selection_method)\n\ncutoff = 10\nX_train_PCA_hdbscanClustered = \\\n    hdb.fit_predict(X_train_PCA.loc[:,0:cutoff])\n\nX_train_PCA_hdbscanClustered = \\\n    pd.DataFrame(data=X_train_PCA_hdbscanClustered, \\\n    index=X_train.index, columns=['cluster'])\n\ncountByCluster_hdbscan, countByLabel_hdbscan, \\\n    countMostFreq_hdbscan, accuracyDF_hdbscan, \\\n    overallAccuracy_hdbscan, accuracyByLabel_hdbscan \\\n    = analyzeCluster(X_train_PCA_hdbscanClustered, y_train)\n```", "```py\nOverall accuracy from HDBSCAN: 0.24696\n```"]