- en: Chapter 7\. Preprocess Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 数据预处理
- en: 'This chapter will explore common preprocessing steps using this data:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨使用此数据的常见预处理步骤：
- en: '[PRE0]'
  id: totrans-2
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Standardize
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准化
- en: 'Some algorithms, such as SVM, perform better when the data is *standardized*.
    Each column should have a mean value of 0 and standard deviation of 1. Sklearn
    provides a `.fit_transform` method that combines both `.fit` and `.transform`:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 某些算法（如SVM）在数据*标准化*时表现更好。每列的均值应为0，标准偏差应为1。Sklearn提供了一个`.fit_transform`方法，结合了`.fit`和`.transform`：
- en: '[PRE1]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After fitting, there are various attributes we can inspect:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合后，我们可以检查各种属性：
- en: '[PRE2]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here is a pandas version. Remember that you will need to track the original
    mean and standard deviation if you use this for preprocessing. Any sample that
    you will use to predict later will need to be standardized with those same values:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个pandas版本。请记住，如果用于预处理，您需要跟踪原始的均值和标准偏差。稍后用于预测的任何样本都需要使用这些相同的值进行标准化：
- en: '[PRE3]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The fastai library also implements this:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: fastai库也实现了这一功能：
- en: '[PRE4]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Scale to Range
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缩放到范围
- en: 'Scaling to range is translating data so it is between 0 and 1, inclusive. Having
    the data bounded may be useful. However, if you have outliers, you probably want
    to be careful using this:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放到范围是将数据转换为0到1之间的值。限制数据的范围可能是有用的。但是，如果您有异常值，可能需要谨慎使用此方法：
- en: '[PRE5]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here is a pandas version:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个pandas版本：
- en: '[PRE6]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Dummy Variables
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚拟变量
- en: 'We can use pandas to create dummy variables from categorical data. This is
    also referred to as one-hot encoding, or indicator encoding. Dummy variables are
    especially useful if the data is nominal (unordered). The `get_dummies` function
    in pandas creates multiple columns for a categorical column, each with a 1 or
    0 if the original column had that value:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用pandas从分类数据创建虚拟变量。这也称为独热编码或指示编码。如果数据是名义（无序）的，虚拟变量特别有用。pandas中的`get_dummies`函数为分类列创建多个列，每列中的值为1或0，如果原始列有该值：
- en: '[PRE7]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here is the pandas version. Note the `drop_first` option can be used to eliminate
    a column (one of the dummy columns is a linear combination of the other columns):'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这是pandas版本。注意`drop_first`选项可以用来消除一列（虚拟列中的一列是其他列的线性组合）。
- en: '[PRE8]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The pyjanitor library also has the ability to split columns with the `expand_column`
    function:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: pyjanitor库还具有使用`expand_column`函数拆分列的功能：
- en: '[PRE9]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If we have high cardinality nominal data, we can use *label encoding*. This
    is introduced in the next section.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有高基数名义数据，我们可以使用*标签编码*。这将在下一节介绍。
- en: Label Encoder
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标签编码器
- en: An alternative to dummy variable encoding is label encoding. This will take
    categorical data and assign each value a number. It is useful for high cardinality
    data. This encoder imposes ordinality, which may or may not be desired. It can
    take up less space than one-hot encoding, and some (tree) algorithms can deal
    with this encoding.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟变量编码的替代方法是标签编码。这将把分类数据转换为数字。对于高基数数据非常有用。该编码器强加序数性，这可能是需要的也可能不需要的。它所占空间比独热编码少，而且一些（树）算法可以处理此编码。
- en: 'The label encoder can only deal with one column at a time:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 标签编码器一次只能处理一列：
- en: '[PRE10]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If you have encoded values, applying the `.inverse_transform` method decodes
    them:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经编码了值，则可以应用`.inverse_transform`方法对其进行解码：
- en: '[PRE11]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You can also use pandas to label encode. First, you convert the column to a
    categorical column type, and then pull out the numeric code from it.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用pandas进行标签编码。首先，将列转换为分类列类型，然后从中提取数值代码。
- en: 'This code will create a new series of numeric data from a pandas series. We
    use the `.as_ordered` method to ensure that the category is ordered:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将从pandas系列创建新的数值数据。我们使用`.as_ordered`方法确保分类是有序的：
- en: '[PRE12]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Frequency Encoding
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 频率编码
- en: 'Another option for handling high cardinality categorical data is to *frequency
    encode* it. This means replacing the name of the category with the count it had
    in the training data. We will use pandas to do this. First, we will use the pandas
    `.value_counts` method to make a mapping (a pandas series that maps strings to
    counts). With the mapping we can use the `.map` method to do the encoding:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 处理高基数分类数据的另一种选择是*频率编码*。这意味着用训练数据中的计数替换类别的名称。我们将使用pandas来执行此操作。首先，我们将使用pandas的`.value_counts`方法创建一个映射（将字符串映射到计数的pandas系列）。有了映射，我们可以使用`.map`方法进行编码：
- en: '[PRE13]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Make sure you store the training mapping so you can encode future data with
    the same data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 确保存储训练映射，以便以后使用相同的数据对未来数据进行编码。
- en: Pulling Categories from Strings
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从字符串中提取类别
- en: 'One way to increase the accuracy of the Titanic model is to pull out titles
    from the names. A quick hack to find the most common triples is to use the `Counter`
    class:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 提高 Titanic 模型准确性的一种方法是从姓名中提取称号。找到最常见的三重组的一个快速方法是使用 `Counter` 类：
- en: '[PRE14]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We can see that “Mr.” and “Miss.” are very common.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，“Mr.” 和 “Miss.” 非常常见。
- en: 'Another option is to use a regular expression to pull out the capital letter
    followed by lowercase letters and a period:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选项是使用正则表达式提取大写字母后跟小写字母和句点：
- en: '[PRE15]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can use `.value_counts` to see the frequency of these:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `.value_counts` 查看这些的频率：
- en: '[PRE16]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: A complete discussion of regular expressions is beyond the scope of this book.
    This expression captures a group with one or more alphabetic characters. This
    group will be followed by a period.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对正则表达式的完整讨论超出了本书的范围。此表达式捕获一个或多个字母字符的组。该组后面将跟随一个句点。
- en: Using these manipulations and pandas, you can create dummy variables or combine
    columns with low counts into other categories (or drop them).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些操作和 pandas，您可以创建虚拟变量或将低计数的列组合到其他类别中（或将它们删除）。
- en: Other Categorical Encoding
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他分类编码
- en: The [categorical_encoding library](https://oreil.ly/JbxWG) is a set of scikit-learn
    transformers used to convert categorical data into numeric data. A nice feature
    of this library is that it supports outputting pandas DataFrames (unlike scikit-learn,
    which transforms them into numpy arrays).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[categorical_encoding 库](https://oreil.ly/JbxWG) 是一组 scikit-learn 转换器，用于将分类数据转换为数值数据。该库的一个优点是它支持输出
    pandas DataFrame（不像 scikit-learn 那样将它们转换为 numpy 数组）。'
- en: 'One algorithm implemented in the library is a hash encoder. This is useful
    if you don’t know how many categories you have ahead of time or if you are using
    a bag of words to represent text. This will hash the categorical columns into
    `n_components`. If you are using online learning (models that can be updated),
    this can be very useful:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 该库实现的一个算法是哈希编码器。如果您事先不知道有多少类别，或者正在使用词袋表示文本，这将会很有用。它将分类列哈希到 `n_components`。如果您使用在线学习（可以更新模型），这将非常有用：
- en: '[PRE17]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The ordinal encoder can convert categorical columns that have order to a single
    column of numbers. Here we convert the size column to ordinal numbers. If a value
    is missing from the mapping dictionary, the default value of `-1` is used:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 序数编码器可以将具有顺序的分类列转换为单个数字列。在这里，我们将大小列转换为序数数字。如果在映射字典中找不到一个值，则使用 `-1` 的默认值：
- en: '[PRE18]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This [reference](https://oreil.ly/JUtYh) explains many of the algorithms of
    the categorical_encoding library.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此 [参考](https://oreil.ly/JUtYh) 解释了 categorical_encoding 库的许多算法。
- en: If you have high cardinality data (a large number of unique values) consider
    using one of the Bayesian encoders that output a single column per categorical
    column. These are `TargetEncoder`, `LeaveOneOutEncoder`, `WOEEncoder`, `JamesSteinEncoder`,
    and `MEstimateEncoder`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有高基数数据（大量唯一值），考虑使用其中一个贝叶斯编码器，它们会为每个分类列输出单独的列。这些包括 `TargetEncoder`, `LeaveOneOutEncoder`,
    `WOEEncoder`, `JamesSteinEncoder` 和 `MEstimateEncoder`。
- en: 'For example, to convert the Titanic survival column to a blend of posterior
    probability of the target and the prior probability given the title (categorical)
    information, use the following code:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要将 Titanic 生存列转换为目标的后验概率和给定标题（分类）信息的先验概率的混合，可以使用以下代码：
- en: '[PRE19]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Date Feature Engineering
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日期特征工程
- en: 'The fastai library has an `add_datepart` function that will generate date attribute
    columns based on a datetime column. This is useful as most machine learning algorithms
    would not be able to infer this type of signal from a numeric representation of
    a date:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: fastai 库有一个 `add_datepart` 函数，它将根据日期时间列生成日期属性列。这对大多数机器学习算法很有用，因为它们无法从日期的数值表示中推断出这种类型的信号：
- en: '[PRE20]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Warning
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: '`add_datepart` mutates the DataFrame, which pandas can do, but normally doesn’t!'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`add_datepart` 会改变 DataFrame，这是 pandas 能做到的，但通常不这样做！'
- en: Add col_na Feature
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加 col_na 特征
- en: 'The fastai library used to have a function for creating a column to fill a
    missing value (with the median) and indicate that a value was missing. There might
    be some signal in knowing that a value was missing. Here is a copy of the function
    and an example using it:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: fastai 库曾经有一个函数用于创建一个列以填充缺失值（使用中位数）并指示缺失值。知道一个值是否缺失可能会有一些信号。以下是该函数的副本及其使用示例：
- en: '[PRE21]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here is a pandas version:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个 pandas 版本：
- en: '[PRE22]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Manual Feature Engineering
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动特征工程
- en: 'We can use pandas to generate new features. For the Titanic dataset, we can
    add aggregate cabin data (maximum age per cabin, mean age per cabin, etc.). To
    get aggregate data per cabin and merge it back in, use the pandas `.groupby` method
    to create the data. Then align it back to the original data using the `.merge`
    method:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 pandas 生成新特征。对于 Titanic 数据集，我们可以添加聚合船舱数据（每个船舱的最大年龄、平均年龄等）。要获得每个船舱的聚合数据并将其合并回原始数据中，使用
    pandas 的 `.groupby` 方法创建数据。然后使用 `.merge` 方法将其与原始数据对齐：
- en: '[PRE23]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: If you wanted to sum up “good” or “bad” columns, you could create a new column
    that is the sum of the aggregated columns (or another mathematical operation).
    This is somewhat of an art and also requires understanding the data.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想总结“好”或“坏”列，你可以创建一个新列，该列是聚合列的总和（或另一个数学操作）。这在某种程度上是一种艺术，也需要理解数据。
