- en: Chapter 7\. Preprocess Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter will explore common preprocessing steps using this data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Standardize
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some algorithms, such as SVM, perform better when the data is *standardized*.
    Each column should have a mean value of 0 and standard deviation of 1. Sklearn
    provides a `.fit_transform` method that combines both `.fit` and `.transform`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'After fitting, there are various attributes we can inspect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a pandas version. Remember that you will need to track the original
    mean and standard deviation if you use this for preprocessing. Any sample that
    you will use to predict later will need to be standardized with those same values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The fastai library also implements this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Scale to Range
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Scaling to range is translating data so it is between 0 and 1, inclusive. Having
    the data bounded may be useful. However, if you have outliers, you probably want
    to be careful using this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a pandas version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Dummy Variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can use pandas to create dummy variables from categorical data. This is
    also referred to as one-hot encoding, or indicator encoding. Dummy variables are
    especially useful if the data is nominal (unordered). The `get_dummies` function
    in pandas creates multiple columns for a categorical column, each with a 1 or
    0 if the original column had that value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the pandas version. Note the `drop_first` option can be used to eliminate
    a column (one of the dummy columns is a linear combination of the other columns):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The pyjanitor library also has the ability to split columns with the `expand_column`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: If we have high cardinality nominal data, we can use *label encoding*. This
    is introduced in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Label Encoder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An alternative to dummy variable encoding is label encoding. This will take
    categorical data and assign each value a number. It is useful for high cardinality
    data. This encoder imposes ordinality, which may or may not be desired. It can
    take up less space than one-hot encoding, and some (tree) algorithms can deal
    with this encoding.
  prefs: []
  type: TYPE_NORMAL
- en: 'The label encoder can only deal with one column at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have encoded values, applying the `.inverse_transform` method decodes
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: You can also use pandas to label encode. First, you convert the column to a
    categorical column type, and then pull out the numeric code from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code will create a new series of numeric data from a pandas series. We
    use the `.as_ordered` method to ensure that the category is ordered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Frequency Encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another option for handling high cardinality categorical data is to *frequency
    encode* it. This means replacing the name of the category with the count it had
    in the training data. We will use pandas to do this. First, we will use the pandas
    `.value_counts` method to make a mapping (a pandas series that maps strings to
    counts). With the mapping we can use the `.map` method to do the encoding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Make sure you store the training mapping so you can encode future data with
    the same data.
  prefs: []
  type: TYPE_NORMAL
- en: Pulling Categories from Strings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One way to increase the accuracy of the Titanic model is to pull out titles
    from the names. A quick hack to find the most common triples is to use the `Counter`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We can see that “Mr.” and “Miss.” are very common.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another option is to use a regular expression to pull out the capital letter
    followed by lowercase letters and a period:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use `.value_counts` to see the frequency of these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A complete discussion of regular expressions is beyond the scope of this book.
    This expression captures a group with one or more alphabetic characters. This
    group will be followed by a period.
  prefs: []
  type: TYPE_NORMAL
- en: Using these manipulations and pandas, you can create dummy variables or combine
    columns with low counts into other categories (or drop them).
  prefs: []
  type: TYPE_NORMAL
- en: Other Categorical Encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The [categorical_encoding library](https://oreil.ly/JbxWG) is a set of scikit-learn
    transformers used to convert categorical data into numeric data. A nice feature
    of this library is that it supports outputting pandas DataFrames (unlike scikit-learn,
    which transforms them into numpy arrays).
  prefs: []
  type: TYPE_NORMAL
- en: 'One algorithm implemented in the library is a hash encoder. This is useful
    if you don’t know how many categories you have ahead of time or if you are using
    a bag of words to represent text. This will hash the categorical columns into
    `n_components`. If you are using online learning (models that can be updated),
    this can be very useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The ordinal encoder can convert categorical columns that have order to a single
    column of numbers. Here we convert the size column to ordinal numbers. If a value
    is missing from the mapping dictionary, the default value of `-1` is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This [reference](https://oreil.ly/JUtYh) explains many of the algorithms of
    the categorical_encoding library.
  prefs: []
  type: TYPE_NORMAL
- en: If you have high cardinality data (a large number of unique values) consider
    using one of the Bayesian encoders that output a single column per categorical
    column. These are `TargetEncoder`, `LeaveOneOutEncoder`, `WOEEncoder`, `JamesSteinEncoder`,
    and `MEstimateEncoder`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to convert the Titanic survival column to a blend of posterior
    probability of the target and the prior probability given the title (categorical)
    information, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Date Feature Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The fastai library has an `add_datepart` function that will generate date attribute
    columns based on a datetime column. This is useful as most machine learning algorithms
    would not be able to infer this type of signal from a numeric representation of
    a date:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '`add_datepart` mutates the DataFrame, which pandas can do, but normally doesn’t!'
  prefs: []
  type: TYPE_NORMAL
- en: Add col_na Feature
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The fastai library used to have a function for creating a column to fill a
    missing value (with the median) and indicate that a value was missing. There might
    be some signal in knowing that a value was missing. Here is a copy of the function
    and an example using it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a pandas version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Manual Feature Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can use pandas to generate new features. For the Titanic dataset, we can
    add aggregate cabin data (maximum age per cabin, mean age per cabin, etc.). To
    get aggregate data per cabin and merge it back in, use the pandas `.groupby` method
    to create the data. Then align it back to the original data using the `.merge`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: If you wanted to sum up “good” or “bad” columns, you could create a new column
    that is the sum of the aggregated columns (or another mathematical operation).
    This is somewhat of an art and also requires understanding the data.
  prefs: []
  type: TYPE_NORMAL
