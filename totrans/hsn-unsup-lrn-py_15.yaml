- en: Chapter 11\. Feature Detection Using Deep Belief Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 11 章。使用深度信念网络进行特征检测
- en: In [Chapter 10](ch10.html#Chapter_10), we explored restricted Boltzmann machines
    and used them to build a recommender system for movie ratings. In this chapter,
    we will stack RBMs together to build *deep belief networks (DBNs)*. DBNs were
    first introduced by Geoff Hinton at the University of Toronto in 2006.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 10 章](ch10.html#Chapter_10)中，我们探索了限制玻尔兹曼机并使用它们构建了一个电影评分的推荐系统。在本章中，我们将堆叠
    RBM 构建*深度信念网络（DBNs）*。DBNs 是由多伦多大学的杰弗·辛顿于 2006 年首次提出的。
- en: RBMs have just two layers, a visible layer and a hidden layer; in other words,
    RBMs are just shallow neural networks. DBNs are made up of multiple RBMs—the hidden
    layer of one RBM serves as the visible layer of the next RBM. Because they involve
    many layers, DBNs are deep neural networks. In fact, they are the first type of
    deep unsupervised neural network we’ve introduced so far.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: RBM 只有两层，一个可见层和一个隐藏层；换句话说，RBM 只是浅层神经网络。DBN 由多个 RBM 组成——一个 RBM 的隐藏层作为下一个 RBM
    的可见层。因为它们涉及许多层，所以 DBN 是深度神经网络。事实上，它们是我们迄今为止介绍的第一种深度无监督神经网络。
- en: Shallow unsupervised neural networks, such as RBMs, cannot capture structure
    in complex data such as images, sound, and text, but DBNs can. DBNs have been
    used to recognize and cluster images, video capture, sound, and text, although
    other deep learning methods have surpassed DBNs in performance over the past decade.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 浅层无监督神经网络，比如 RBM，不能捕获图像、声音和文本等复杂数据的结构，但 DBN 可以。DBN 已被用于识别和聚类图像、视频捕获、声音和文本，尽管过去十年中其他深度学习方法在性能上已超过了
    DBN。
- en: Deep Belief Networks in Detail
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度信念网络详解
- en: Like RBMs, DBNs can learn the underlying structure of input and probabilistically
    reconstruct it. In other words, DBNs—like RBMs—are generative models. And, as
    with RBMs, the layers in DBNs have connections only between layers but not between
    units within each layer.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 与 RBM 一样，DBN 可以学习输入的基本结构并以概率方式重构它。换句话说，DBN——就像 RBM 一样——是生成模型。而且，与 RBM 一样，DBN
    中的层之间只有连接，但每一层内部的单元之间没有连接。
- en: In the DBN, one layer is trained at a time, starting with the very first hidden
    layer, which, along with the input layer, makes up the first RBM. Once this first
    RBM is trained, the hidden layer of the first RBM serves as the visible layer
    of the next RBM and is used to train the second hidden layer of the DBN.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DBN 中，一次训练一层，从第一个隐藏层开始，它与输入层一起组成第一个 RBM。一旦训练了第一个 RBM，第一个 RBM 的隐藏层将作为下一个 RBM
    的可见层，并用于训练 DBN 的第二个隐藏层。
- en: This process continues until all the layers of the DBN are trained. Except for
    the first and final layers of the DBN, each layer in the DBN serves as both a
    hidden layer and a visible layer of an RBM.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程会一直持续到 DBN 的所有层都被训练完毕。除了 DBN 的第一层和最后一层之外，DBN 中的每一层都既充当了一个隐藏层，也充当了一个 RBM
    的可见层。
- en: The DBN is a hierarchy of representations and, like all neural networks, is
    a form of representation learning. Note that the DBN does not use any labels.
    Instead, the DBN is learning the underlying structure in the input data one layer
    at a time.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: DBN 是一种表示的层次结构，就像所有神经网络一样，它是一种表示学习形式。请注意，DBN 不使用任何标签。相反，DBN 一次学习输入数据中的一个层的底层结构。
- en: Labels can be used to fine-tune the last few layers of the DBN but only after
    the initial unsupervised learning has been completed. For example, if we want
    the DBN to be a classifier, we would perform unsupervised learning first (a process
    known as *pre-training*) and then use labels to fine-tune the DBN (a process called
    *fine-tuning*).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 标签可以用来微调 DBN 的最后几层，但只有在初始无监督学习完成后才能这样做。例如，如果我们想要 DBN 成为一个分类器，我们会先进行无监督学习（称为*预训练*过程），然后使用标签微调
    DBN（称为*微调*过程）。
- en: MNIST Image Classification
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MNIST 图像分类
- en: Let’s build an image classifier using DBNs. We will turn to the MNIST dataset
    once again.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次使用 DBN 构建图像分类器。我们将再次使用 MNIST 数据集。
- en: 'First, let’s load the necessary libraries:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们加载必要的库：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will then load the data and store it in Pandas DataFrames. We will also
    encode the labels as one-hot vectors. This is all similar to what we did when
    we first introduced the MNIST dataset earlier in the book:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将加载数据并将其存储在 Pandas DataFrames 中。我们还将将标签编码为 one-hot 向量。这与我们在本书早期介绍 MNIST
    数据集时所做的工作类似：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Restricted Boltzmann Machines
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制玻尔兹曼机
- en: Next, let’s define an RBM class so we can train several RBMs (which are the
    building blocks for DBNs) in quick succession.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们定义一个 RBM 类，这样我们就可以快速连续训练多个 RBM（它们是 DBN 的构建模块）。
- en: Remember that RBMs have an input layer (also referred to as the visible layer)
    and a single hidden layer, and the connections among neurons are restricted such
    that neurons are connected only to the neurons in other layers but not to neurons
    within the same layer. Also, recall that communication between layers happens
    in both directions—not just in one direction or a feedforward way, as in the case
    of autoencoders.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，RBM具有输入层（也称为可见层）和单个隐藏层，神经元之间的连接受到限制，使得神经元仅连接到其他层中的神经元，而不连接同一层中的神经元。还要记住，层间通信是双向的，不仅是单向的或者像自编码器那样的前向方式。
- en: In an RBM, the neurons in the visible layer communicate with the hidden layer,
    the hidden layer generates data from the probabilistic model the RBM has learned,
    and then the hidden layer passes this generated information back to the visible
    layer. The visible layer takes the generated data from the hidden layer, samples
    it, compares it to the original data, and, based on the reconstruction error between
    the generated data sample and the original data, sends new information to the
    hidden layer to repeat the process once again.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在RBM中，可见层的神经元与隐藏层通信，隐藏层从RBM学习的概率模型生成数据，然后隐藏层将这个生成的信息传递回可见层。可见层接收来自隐藏层的生成数据样本，对其进行采样，将其与原始数据进行比较，并根据生成数据样本与原始数据之间的重构误差，向隐藏层发送新信息，以再次重复此过程。
- en: By communicating in this bidirectional way, the RBM develops a generative model
    such that the reconstructions from the output of the hidden layer are similar
    to the original input.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种双向通信方式，RBM开发了一个生成模型，使得从隐藏层输出的重构数据与原始输入相似。
- en: Build the Components of the RBM Class
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建RBM类的组件
- en: Like we did in [Chapter 10](ch10.html#Chapter_10), let’s walk through the various
    components of the `RBM` class.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在[第10章](ch10.html#Chapter_10)中所做的那样，让我们逐步了解`RBM`类的各个组成部分。
- en: 'First, we will initialize the class with a few parameters; these are the input
    size of the RBM, the output size, the learning rate, the number of epochs to train
    for, and the batch size during the training process. We will also create zero
    matrices for the weight matrix, the hidden bias vector, and the visible bias vector:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用几个参数来初始化这个类；它们是RBM的输入大小、输出大小、学习速率、训练时的时代数以及批处理大小。我们还将创建权重矩阵、隐藏偏置向量和可见偏置向量的零矩阵：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next, let’s define functions for the forward pass, the backward pass, and the
    sampling of data during each of these passes back and forth.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们定义正向传递、反向传递以及在每次传递期间对数据进行采样的函数。
- en: 'Here is the forward pass, where *h* is the hidden layer and *v* is the visible
    layer:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是正向传递，其中*h*是隐藏层，*v*是可见层：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here is the backward pass:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是向后传递：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here is the sampling function:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是采样函数：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now we need a function that performs that training. Since we are using TensorFlow,
    we first need to create placeholders for the TensorFlow graph, which we will use
    when we feed data into the TensorFlow session.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要一个执行训练的函数。因为我们使用的是TensorFlow，所以我们首先需要为TensorFlow图创建占位符，当我们将数据提供给TensorFlow会话时将使用这些占位符。
- en: 'We will have placeholders for the weights matrix, the hidden bias vector, and
    the visible bias vector. We will also need to initialize the values for these
    three using zeros. And, we will need one set to hold the current values and one
    set to hold the previous values:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为权重矩阵、隐藏偏置向量和可见偏置向量设立占位符。我们还需要使用零初始化这三者的值。并且，我们需要一个集合来保存当前值，另一个集合来保存先前的值：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Likewise, we need a placeholder for the visible layer. The hidden layer is
    derived from matrix multiplication of the visible layer and the weights matrix
    and the matrix addition of the hidden bias vector:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们需要一个可见层的占位符。隐藏层是通过可见层和权重矩阵的矩阵乘法以及隐藏偏置向量的矩阵加法派生的：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: During the backward pass, we take the hidden layer output, multiply it with
    the transpose of the weights matrix used during the forward pass, and add the
    visible bias vector. Note that the weights matrix is the same weights matrix during
    both the forward and the backward pass.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在向后传递期间，我们获取隐藏层输出，将其与在正向传递期间使用的权重矩阵的转置相乘，并添加可见偏置向量。请注意，权重矩阵在正向和向后传递期间都是相同的。
- en: 'Then we perform the forward pass again:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们再次执行正向传递：
- en: '[PRE8]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To update the weights, we perform constrastive divergence, which we introduced
    in [Chapter 10](ch10.html#Chapter_10). We also define the error as the MSE:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要更新权重，我们执行对比散度，我们在 [第十章](ch10.html#Chapter_10) 中介绍过。我们还定义误差为均方误差（MSE）：
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: With this, we are ready to initialize the TensorFlow session with the variables
    we have just defined.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们就可以用刚刚定义的变量初始化 TensorFlow 会话了。
- en: 'Once we call `sess.run`, we can feed in batches of data to begin the training.
    During the training, forward and backward passes will be made, and the RBM will
    update weights based on how the generated data compares to the original input.
    We will print the reconstruction error from each epoch:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们调用 `sess.run`，我们就可以提供数据的批次开始训练。在训练过程中，将进行前向和反向传播，并根据生成数据与原始输入的比较更新 RBM 的权重。我们将打印每个周期的重建误差：
- en: '[PRE10]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Generate Images Using the RBM Model
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 RBM 模型生成图像
- en: 'Let’s also define a function to generate new images from the generative model
    that the RBM has learned:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也定义一个函数，从 RBM 学习的生成模型中生成新图像：
- en: '[PRE11]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We feed the original matrix of images, called *X*, into the function. We create
    TensorFlow placeholders for the original matrix of images, the weights matrix,
    the hidden bias vector, and the visible bias vector. Then, we push the input matrix
    to produce the output of a forward pass (`out`), a sample of the hidden layer
    (`hiddenGen`), and a sample of the reconstructed images generated by the model
    (`visibleGen`).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将原始图像矩阵 *X* 输入到函数中。我们为原始图像矩阵、权重矩阵、隐藏偏置向量和可见偏置向量创建 TensorFlow 占位符。然后，我们将输入矩阵推送以产生正向传播的输出（`out`）、隐藏层的样本生成（`hiddenGen`）以及模型生成的重建图像的样本（`visibleGen`）。
- en: View the Intermediate Feature Detectors
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看中间特征检测器
- en: 'Finally, let’s define a function to show the feature detectors of the hidden
    layer:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们定义一个函数来显示隐藏层的特征检测器：
- en: '[PRE12]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We will use this and the other functions on the MNIST dataset now.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将在 MNIST 数据集上使用这些函数及其他函数。
- en: Train the Three RBMs for the DBN
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练深度信念网络的三个 RBM
- en: We will now use the MNIST data to train three RBMs, one at a time, such that
    the hidden layer of one RBM is used as the visible layer of the next RBM. These
    three RBMs will make up the DBN that we are building to perform image classification.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用 MNIST 数据来依次训练三个 RBM，其中一个 RBM 的隐藏层将作为下一个 RBM 的可见层。这三个 RBM 将组成我们正在构建的用于图像分类的深度信念网络（DBN）。
- en: First, let’s take the training data and store it as a NumPy array. Next, we
    will create a list to hold the RBMs we train called `rbm_list`. Then, we will
    define the hyperparameters for the three RBMs, including the input size, the output
    size, the learning rate, the number of epochs to train for, and the batch size
    for training.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们将训练数据转换为 NumPy 数组并存储起来。接下来，我们将创建一个名为 `rbm_list` 的列表来保存我们训练的 RBM。然后，我们将定义三个
    RBM 的超参数，包括输入大小、输出大小、学习率、训练周期数以及训练的批次大小。
- en: All of these can be built using the RBM class we defined earlier.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都可以使用我们之前定义的 RBM 类来构建。
- en: 'For our DBN, we will use the following RBMs: the first will take the original
    784-dimension input and output a 700-dimension matrix. The next RBM will use the
    700-dimension matrix output of the first RBM and output a 600-dimension matrix.
    Finally, the last RBM we train will take the 600-dimension matrix and output a
    500-dimension matrix.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的深度信念网络（DBN），我们将使用以下的受限玻尔兹曼机（RBM）：第一个将接收原始的 784 维输入，并输出一个 700 维的矩阵。接下来的
    RBM 将使用第一个 RBM 输出的 700 维矩阵，并输出一个 600 维的矩阵。最后，我们训练的最后一个 RBM 将接收 600 维的矩阵，并输出一个
    500 维的矩阵。
- en: 'We will train all three RBMs using a learning rate of 1.0, train for 100 epochs
    each, and use a batch size of two hundred:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用学习率为 1.0 来训练所有三个 RBM，每个训练 100 个周期，并使用批次大小为两百：
- en: '[PRE13]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now let’s train the RBMs. We will store the trained RBMs in a list called `outputList`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们训练 RBM。我们将把训练好的 RBM 存储在名为 `outputList` 的列表中。
- en: 'Note that we use the `rbm_output` function we defined earlier to produce the
    output matrix—in other words, the hidden layer—for use as the input/visible layer
    of the subsequent RBM we train:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用我们之前定义的 `rbm_output` 函数来生成输出矩阵，换句话说，是后续我们训练的 RBM 的输入/可见层：
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The errors of each RBM decline the longer we train (see Figures [11-1](#reconstruction_Errors_of_first_rbm),
    [11-2](#reconstruction_errors_of_second_rbm), and [11-3](#reconstruction_errors_of_third_rbm)).
    Note that the RBM error reflects how similar the reconstructed data of a given
    RBM is to the data fed into the visible layer of that very RBM.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 随着训练的进行，每个RBM的误差都在下降（参见图[11-1](#reconstruction_Errors_of_first_rbm)，[11-2](#reconstruction_errors_of_second_rbm)和[11-3](#reconstruction_errors_of_third_rbm)）。请注意，RBM误差反映了给定RBM可见层重构数据与输入数据有多相似。
- en: '![Reconstruction Errors of First RBM](assets/hulp_1101.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![第一个RBM的重构误差](assets/hulp_1101.png)'
- en: Figure 11-1\. Reconstruction errors of first RBM
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-1\. 第一个RBM的重构误差
- en: '![Reconstruction Errors of Second RBM](assets/hulp_1102.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![第二个RBM的重构误差](assets/hulp_1102.png)'
- en: Figure 11-2\. Reconstruction errors of second RBM
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-2\. 第二个RBM的重构误差
- en: '![Reconstruction Errors of Third RBM](assets/hulp_1103.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![第三个RBM的重构误差](assets/hulp_1103.png)'
- en: Figure 11-3\. Reconstruction errors of third RBM
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-3\. 第三个RBM的重构误差
- en: Examine Feature Detectors
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查特征探测器
- en: 'Now let’s view the learned features from each of the RBMs using the `rbm.show_features`
    function we defined earlier:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用之前定义的`rbm.show_features`函数来查看每个RBM学到的特征：
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[Figure 11-4](#learned_features_of_the_rbms) displays the learned features
    for the various RBMs.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11-4](#learned_features_of_the_rbms)展示了各个RBM学到的特征。'
- en: As you can see, each RBM learns increasingly abstract features from the MNIST
    data. The features of the first RBM vaguely resemble digits, and the features
    of the second and the third RBMs are increasingly nuanced and less discernible.
    This is pretty typical of how feature detectors work on image data; the deeper
    layers of the neural network recognize increasingly abstract elements from the
    original images.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，每个RBM从MNIST数据中学到的特征越来越抽象。第一个RBM的特征模糊地类似于数字，而第二个和第三个RBM的特征则越来越微妙且难以辨认。这在图像数据的特征探测器中是非常典型的；神经网络的深层逐渐识别原始图像中越来越抽象的元素。
- en: '![Learned Features of the RBMs](assets/hulp_1104.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![RBM的学习特征](assets/hulp_1104.png)'
- en: Figure 11-4\. Learned features of the RBMs
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-4\. RBM的学习特征
- en: View Generated Images
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看生成的图像
- en: Before we build the full DBN, let’s view some of the generated images from one
    of the RBMs we just trained.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们构建完整的DBN之前，让我们查看我们刚刚训练的某个RBM生成的一些图像。
- en: 'To keep things simple, we will feed the original MNIST training matrix into
    the first RBM we trained, which performs a forward pass and a backward pass, then
    will produce the generated images we need. We will compare the first ten images
    of the MNIST dataset with the newly generated images:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化问题，我们将原始的MNIST训练矩阵输入我们训练过的第一个RBM中，进行前向传播和反向传播，然后生成我们需要的图像。我们将比较MNIST数据集的前十张图像与新生成的图像：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[Figure 11-5](#first_generated_image_of_the_first_rbm) shows the first image
    produced by the RBM compared to the first original image.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11-5](#first_generated_image_of_the_first_rbm)展示了第一个RBM生成的第一张图像与第一张原始图像的比较。'
- en: '![First Generated Image of the First RBM](assets/hulp_1105.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![第一个RBM的第一张生成图像](assets/hulp_1105.png)'
- en: Figure 11-5\. First generated image of the first RBM
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-5\. 第一个RBM的第一张生成图像
- en: As you can see, the generated image is similar to the original image — both
    display the digit five.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，生成的图像与原始图像相似——两者都显示数字五。
- en: Let’s view a few more images like this to compare the RBM-generated images with
    the original ones (see Figures [11-6](#second_generated_image_of_the_first_rbm)
    through [11-9](#fifth_generated_image_of_the_first_rbm)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看更多这样的图像，将RBM生成的图像与原始图像进行比较（参见[11-6](#second_generated_image_of_the_first_rbm)到[11-9](#fifth_generated_image_of_the_first_rbm)图）。
- en: '![Second Generated Image of the First RBM](assets/hulp_1106.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![第一个RBM的第二张生成图像](assets/hulp_1106.png)'
- en: Figure 11-6\. Second generated image of the first RBM
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-6\. 第一个RBM的第二张生成图像
- en: '![Third Generated Image of the First RBM](assets/hulp_1107.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![第一个RBM的第三张生成图像](assets/hulp_1107.png)'
- en: Figure 11-7\. Third generated image of the first RBM
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-7\. 第一个RBM的第三张生成图像
- en: '![Fourth Generated Image of the First RBM](assets/hulp_1108.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![第一个RBM的第四张生成图像](assets/hulp_1108.png)'
- en: Figure 11-8\. Fourth generated image of the first RBM
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-8\. 第一个RBM的第四张生成图像
- en: '![Fifth Generated Image of the First RBM](assets/hulp_1109.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![第一个RBM的第五张生成图像](assets/hulp_1109.png)'
- en: Figure 11-9\. Fifth generated image of the first RBM
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-9\. 第一个RBM的第五张生成图像
- en: These digits are zero, four, one, and nine, respectively, and the generated
    images look reasonably similar to the original images.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数字分别是零，四，一和九，并且生成的图像与原始图像看起来相似。
- en: The Full DBN
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完整的DBN
- en: Now, let’s define the DBN class, which will take in the three RBMs we just trained
    and add a fourth RBM that performs forward and backward passes to refine the overall
    DBN-based generative model.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义DBN类，它将接受我们刚刚训练的三个RBM，并添加一个第四个RBM，执行前向和后向传递，以完善基于DBN的生成模型。
- en: 'First, let’s define the hyperparameters of the class. These include the original
    input size, the input size of the third RBM we just trained, the final output
    size we would like to have from the DBN, the learning rate, the number of epochs
    we wish to train for, the batch size for training, and the three RBMs we just
    trained. Like before, we will need to generate zero matrices for the weights,
    hidden bias, and visible bias:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义类的超参数。这些包括原始输入大小，我们刚刚训练的第三个受限玻尔兹曼机（RBM）的输入大小，我们希望从深度置信网络（DBN）得到的最终输出大小，学习率，我们希望训练的周期数，用于训练的批量大小，以及我们刚刚训练的三个RBM。和以前一样，我们需要生成权重矩阵，隐藏偏置和可见偏置的零矩阵：
- en: '[PRE17]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Similar to before, we will define functions to perform the forward pass and
    the backward pass and take samples from each:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 类似之前，我们将定义函数执行前向传递和后向传递，并从每个中获取样本：
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'For the training, we need placeholders for the weights, hidden bias, and visible
    bias. We also need matrices for the previous and current weights, hidden biases,
    and visible biases:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于训练，我们需要权重，隐藏偏置和可见偏置的占位符。我们还需要用于以前和当前权重，隐藏偏置和可见偏置的矩阵：
- en: '[PRE19]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We will set a placeholder for the visible layer.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为可见层设置一个占位符。
- en: 'Next, we will take the initial input—the visible layer—and pass it through
    the three RBMs we trained earlier. This results in the output *forward*, which
    we will pass into the fourth RBM we train as part of this DBN class:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将初始输入——可见层——通过之前训练的三个RBM。这导致了输出*forward*，我们将其传递到我们作为这个DBN类一部分训练的第四个RBM：
- en: '[PRE20]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We will define the contrastive divergence like we did before:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将像之前一样定义对比散度：
- en: '[PRE21]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Once we generate a full forward pass through this DBN—which includes the three
    RBMs we trained earlier plus the latest fourth RBM—we need to send the output
    of the fourth RBM’s hidden layer back through the entire DBN.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们通过这个DBN进行完整的前向传递——包括我们早先训练的三个RBM和最新的第四个RBM——我们需要将第四个RBM的隐藏层输出再通过整个DBN。
- en: 'This requires a backward pass through the fourth RBM as well as a backward
    pass through the first three. We will also use MSE as before. Here is how the
    backward pass occurs:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要通过第四个RBM进行反向传递，以及通过前三个RBM进行反向传递。我们还将像以前一样使用均方误差（MSE）。以下是反向传递发生的方式：
- en: '[PRE22]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here is the actual training portion of the DBN class, again very similar to
    the RBM one earlier:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这是DBN类的实际训练部分，与之前的RBM非常相似：
- en: '[PRE23]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let’s define functions to produce generated images from the DBN and show features.
    These are similar to the RBM versions earlier, but we send the data through all
    four RBMs in the DBN class instead of just through a single RBM:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义函数来从DBN生成图像并展示特征。这些与之前的RBM版本类似，但我们将数据通过DBN类中的所有四个RBM，而不仅仅是一个单独的RBM：
- en: '[PRE24]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: How Training of a DBN Works
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DBN训练的工作原理
- en: Each of the three RBMs we have trained already has its own weights matrix, hidden
    bias vector, and visible bias vector. During the training of the fourth RBM as
    part of the DBN, we will not adjust the weights matrix, hidden bias vector, and
    visible bias vector of those first three RBMs. Rather, we will use the first three
    RBMs as fixed components of the DBN. We will call upon the first three RBMs just
    to do the forward and backward passes (and use samples of the data these three
    generate).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 每个我们已经训练的三个RBM都有自己的权重矩阵，隐藏偏置向量和可见偏置向量。在作为DBN一部分训练的第四个RBM期间，我们不会调整这前三个RBM的权重矩阵，隐藏偏置向量和可见偏置向量。相反，我们将使用这前三个RBM作为DBN的固定组件。我们将仅调用这前三个RBM执行正向和反向传播（并使用这三个生成的数据样本）。
- en: During the training of the fourth RBM in the DBN, we will only adjust weights
    and biases of the fourth RBM. In other words, the fourth RBM in the DBN takes
    the output of the first three RBMs as given and performs forward and backward
    passes to learn a generative model that minimizes the reconstruction error between
    its generated images and the original images.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练DBN的第四个RBM时，我们只会调整第四个RBM的权重和偏置。换句话说，DBN中的第四个RBM以前三个RBM的输出作为给定值，并执行前向和反向传播，学习生成模型，以使其生成的图像与原始图像之间的重构误差最小化。
- en: Another way to train the DBNs would be to allow the DBN to learn and adjust
    weights for all four RBMs as it performs forward and backward passes through the
    entire network. However, training of the DBN would be very computationally expensive
    (perhaps not so with computers of today but certainly by the standards of 2006,
    when DBNs were first introduced).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 训练DBN的另一种方法是允许DBN在执行整个网络的前向和反向传播时学习和调整所有四个RBM的权重。然而，DBN的训练会非常昂贵（也许今天的计算机不算，但从2006年首次引入DBN的标准来看，肯定是如此）。
- en: That being said, if we wish to perform more nuanced pretraining, we could allow
    the weights of the individual RBMs to be adjusted—one RBM at a time—as we perform
    batches of forward and backward passes through the network. We will not delve
    into this, but I encourage you to experiment on your own time.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，如果我们希望进行更细致的预训练，我们可以允许单个受限玻尔兹曼机（RBM）的权重在每次网络前向和反向传播的批次中进行调整。我们不会深入讨论这一点，但我鼓励你在自己的时间里进行实验。
- en: Train the DBN
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练DBN
- en: 'We will now train the DBN. We set the original image dimensions as 784, the
    dimensions of the third RBM output as 500, and the desired dimensions of the DBN
    as 500\. We will use a learning rate of 1.0, train for 50 epochs, and use a batch
    size of 200\. Finally, we will call the first three trained RBMs as part of the
    DBN:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将训练DBN。我们设置原始图像尺寸为784，第三个RBM的输出尺寸为500，DBN的期望尺寸也为500。我们将使用学习率为1.0进行50个epochs的训练，并使用批量大小为200。最后，我们将前三个训练好的RBM称为DBN的一部分：
- en: '[PRE26]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, let’s train:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始训练：
- en: '[PRE27]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[Figure 11-10](#reconstruction_errors_of_the_dbn) displays the reconstruction
    errors of the DBN over the course of the training.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-10](#reconstruction_errors_of_the_dbn) 展示了训练过程中深度信念网络（DBN）的重构误差。'
- en: '![Reconstruction Errors of the DBN](assets/hulp_1110.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![DBN的重构误差](assets/hulp_1110.png)'
- en: Figure 11-10\. Reconstruction errors of the DBN
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-10\. DBN的重构误差
- en: '[Figure 11-11](#learned_features_of_the_fourth_rbm_in_the_dbn) displays the
    learned features from the last layer of the DBN — the hidden layer of the fourth
    RBM.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-11](#learned_features_of_the_fourth_rbm_in_the_dbn) 展示了DBN最后一层——第四个RBM的隐藏层——学到的特征。'
- en: '![Learned Features of the Fourth RBM in the DBN](assets/hulp_1111.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![DBN中第四个RBM的学习特征](assets/hulp_1111.png)'
- en: Figure 11-11\. Learned features of the fourth RBM in the DBN
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-11\. DBN中第四个RBM的学习特征
- en: Both the reconstruction errors and the learned features look reasonable and
    similar to the ones from the individual RBMs we analyzed earlier.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 重构误差和学习到的特征看起来都很合理，并且与我们之前分析的单独RBM的情况相似。
- en: How Unsupervised Learning Helps Supervised Learning
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习如何帮助监督学习
- en: So far, all the work we have done training the RBMs and the DBN involve unsupervised
    learning. We have not used any labels for the images at all. Instead, we have
    built generative models by learning relevant latent features from the original
    MNIST images provided in the 50,000 example training set. These generative models
    generate images that look reasonably similar to the original images (minimizing
    the reconstruction error).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所做的所有关于训练RBM和DBN的工作都涉及无监督学习。我们完全没有使用任何图像的标签。相反，我们通过从50,000个示例训练集中的原始MNIST图像中学习相关的潜在特征来构建生成模型。这些生成模型生成的图像看起来与原始图像相似（最小化重构误差）。
- en: Let’s take a step back to understand the usefulness of such a generative model.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们退一步，以理解这种生成模型的用处。
- en: Recall that most of the data in the world is unlabeled. Therefore, as powerful
    and effective as supervised learning is, we need unsupervised learning to help
    make sense of all the unlabeled data that exists. Supervised learning is not enough.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，世界上大多数数据都是无标签的。因此，尽管监督学习非常强大和有效，我们仍然需要无监督学习来帮助理解所有存在的无标签数据。仅靠监督学习是不够的。
- en: To demonstrate the usefulness of unsupervised learning, imagine if instead of
    50,000 labeled MNIST images in the training set, we had just a fraction—let’s
    say we had only 5,000 labeled MNIST images. A supervised learning-based image
    classifer that had only 5,000 labeled images would not be nearly as effective
    as a supervised learning-based image classifier that had 50,000 images. The more
    labeled data we have, the better the machine learning solution.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示无监督学习的有效性，想象一下，如果训练集中的MNIST图像只有5000张标记图像，而不是50000张标记图像，有监督学习的图像分类器的效果将大不如拥有50000张图像的有监督学习的图像分类器。我们拥有的标记数据越多，机器学习解决方案就越好。
- en: How does unsupervised learning help in such a situation? One way unsupervised
    learning could help is by generating new labeled examples to help supplement the
    originally labeled dataset. Then, the supervised learning could occur on a much
    larger labeled dataset, resulting in a better overall solution.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习在这种情况下如何帮助？无监督学习能提供帮助的一种方式是生成新的带标签示例，以帮助补充最初的标记数据集。然后，有监督学习可以在一个更大的标记数据集上进行，从而获得更好的整体解决方案。
- en: Generate Images to Build a Better Image Classifier
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成图像以构建更好的图像分类器
- en: To simulate this benefit that unsupervised learning is able to provide, let’s
    reduce our MNIST training dataset to just five thousand labeled examples. We will
    store the first five thousand images in a dataframe called `inputXReduced`.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟无监督学习能够提供的这种好处，让我们将MNIST训练数据集缩减到仅有五千个标记示例。我们将把前五千个图像存储在一个名为`inputXReduced`的数据框中。
- en: Then, from these five thousand labeled images, we will generate new images from
    the generative model we just built using a DBN. And, we will do this 20 times
    over. In other words, we will generate five thousand new images 20 times to create
    a dataset that is 100,000 large, all of which will be labeled. Technically, we
    are storing the final hidden layer outputs not the reconstructed images directly,
    although we will store the reconstructed images, too, so we can evaluate them
    soon.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，从这五千张标记图像中，我们将使用刚刚构建的生成模型来生成新的图像，使用 DBN。我们将重复这个过程20次。换句话说，我们将生成五千个新图像，共创建一个包含十万个样本的数据集，所有这些数据都将被标记。从技术上讲，我们存储的是最终的隐藏层输出，而不是直接重构的图像，尽管我们也会存储重构的图像，以便尽快评估它们。
- en: 'We will store these 100,000 outputs in a NumPy array called `generatedImages`:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这100,000个输出存储在名为`generatedImages`的NumPy数组中：
- en: '[PRE28]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We will loop through the first five thousand labels from the training labels,
    called `y_train`, 20 times to generate an array of labels called `labels`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将循环使用训练标签中的前五千个标签，称为`y_train`，重复20次以生成名为`labels`的标签数组：
- en: '[PRE29]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, we will generate the output on the validation set, which we will need
    to evaluate the image classifier we will build soon:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将在验证集上生成输出，这将用于评估我们即将构建的图像分类器：
- en: '[PRE30]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Before we use the data we just generated, let’s view a few of the reconstructed
    images:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用我们刚生成的数据之前，让我们查看一些重构的图像：
- en: '[PRE31]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![First Generated Image of the DBN](assets/hulp_1112.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![DBN 的第一张生成图像](assets/hulp_1112.png)'
- en: Figure 11-12\. First generated image of the DBN
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-12\. DBN 的第一张生成图像
- en: As you can see in [Figure 11-12](#first_generated_image_of_the_dbn), the generated
    image is very similar to the original image—both display the digit five. Unlike
    the RBM-generated images we saw earlier, these are more similar to the original
    MNIST images, including the pixelated bits.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在[图 11-12](#first_generated_image_of_the_dbn)中所看到的，生成的图像与原始图像非常相似——两者都显示数字五。与我们之前看到的由RBM生成的图像不同，这些更类似于原始的MNIST图像，包括像素化的部分。
- en: Let’s view a few more images like this to compare the DBN-generated images with
    the original MNIST ones (see Figures [11-13](#second_generated_image_of_the_dbn)
    through [11-16](#fifth_generated_image_of_the_dbn)).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再查看几张这样的图像，以比较 DBN 生成的图像与原始 MNIST 图像（参见图11-13到图11-16）。
- en: '![Second Generated Image of the DBN](assets/hulp_1113.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![DBN 的第二张生成图像](assets/hulp_1113.png)'
- en: Figure 11-13\. Second generated image of the DBN
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-13\. DBN 的第二张生成图像
- en: '![Third Generated Image of the DBN](assets/hulp_1114.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![DBN 的第三张生成图像](assets/hulp_1114.png)'
- en: Figure 11-14\. Third generated image of the DBN
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-14\. DBN 的第三张生成图像
- en: '![Fourth Generated Image of the DBN](assets/hulp_1115.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![DBN 的第四张生成图像](assets/hulp_1115.png)'
- en: Figure 11-15\. Fourth generated image of the DBN
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-15\. DBN 的第四张生成图像
- en: '![Fifth Generated Image of the DBN](assets/hulp_1116.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![DBN 的第五张生成图像](assets/hulp_1116.png)'
- en: Figure 11-16\. Fifth generated image of the DBN
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-16\. 深度信念网络生成的第五张图像
- en: Also note that the DBN model (as well as the RBM models) is generative and therefore
    the images are produced using a stochastic process. The images are not produced
    using a deterministic process, and, therefore, the images of a single example
    vary from one DBN run to another.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，DBN模型（以及RBM模型）是生成型的，因此图像是使用随机过程生成的。图像不是使用确定性过程生成的，因此同一示例的图像在不同的DBN运行中会有所不同。
- en: 'To simulate this, we will take the first MNIST image and use the DBN to generate
    a new one and do this 10 times over:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟这个过程，我们将采用第一张MNIST图像，并使用深度信念网络生成一张新图像，重复这个过程10次：
- en: '[PRE32]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: As you see from Figures [11-17](#first_two_generated_images_of_the_digit_five)
    through [11-21](#fifth_two_generated_images_of_the_digit_five), all the generated
    images display the number five, but they vary from image to image even though
    they all were generated using the same original MNIST image.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您从图[11-17](#first_two_generated_images_of_the_digit_five)到[11-21](#fifth_two_generated_images_of_the_digit_five)所看到的，所有生成的图像都显示数字五，但它们的图像会因为使用相同的原始MNIST图像而有所不同。
- en: '![First and second Generated Images of the Digit Five](assets/hulp_1117.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![数字五的第一和第二生成图像](assets/hulp_1117.png)'
- en: Figure 11-17\. First and second generated images of the digit five
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-17\. 数字五的第一和第二生成图像
- en: '![Third and fourth Generated Images of the Digit Five](assets/hulp_1118.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![数字五的第三和第四生成图像](assets/hulp_1118.png)'
- en: Figure 11-18\. Third and fourth generated images of the digit five
  id: totrans-169
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-18\. 数字五的第三和第四生成图像
- en: '![Fifth and sixth Generated Images of the Digit Five](assets/hulp_1119.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![数字五的第五和第六生成图像](assets/hulp_1119.png)'
- en: Figure 11-19\. Fifth and sixth generated images of the digit five
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-19\. 数字五的第五和第六生成图像
- en: '![Seventh and eighth Generated Images of the Digit Five](assets/hulp_1120.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![数字五的第七和第八生成图像](assets/hulp_1120.png)'
- en: Figure 11-20\. Seventh and eighth generated images of the digit five
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-20\. 数字五的第七和第八生成图像
- en: '![Ninth and tenth Generated Images of the Digit Five](assets/hulp_1121.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![数字五的第九和第十生成图像](assets/hulp_1121.png)'
- en: Figure 11-21\. Ninth and tenth generated images of the digit five
  id: totrans-175
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-21\. 数字五的第九和第十生成图像
- en: Image Classifier Using LightGBM
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LightGBM的图像分类器
- en: 'Now let’s build an image classifier using a supervised learning algorithm we
    introduced earlier in the book: the gradient boosting algorithm *LightGBM*.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用本书前面介绍的监督学习算法构建一个图像分类器：梯度提升算法*LightGBM*。
- en: Supervised Only
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仅监督学习
- en: The first image classifier will rely on just the first five thousand labeled
    MNIST images. This is the reduced set from the original 50,000 labeled MNIST training
    set; we designed this to simulate real-world problems where we have relatively
    few labeled examples. Since we covered gradient boosting and the LightGBM algorithm
    in depth earlier in the book, we will not go into a lot of detail here.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个图像分类器仅依赖于前五千个标记的MNIST图像。这是从原始的50,000个标记的MNIST训练集中减少的集合；我们设计这个集合来模拟现实世界中标记示例相对较少的问题。由于本书前面已经深入讨论了梯度提升和LightGBM算法，因此我们在这里不会详细介绍。
- en: 'Let’s set the parameters for the algorithm:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为算法设置参数：
- en: '[PRE33]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next, we will train on the 5,000 labeled MNIST training set (the reduced set)
    and validate on the 10,000 labeled MNIST validation set:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在5,000个标记的MNIST训练集（减少后的集合）上进行训练，并在10,000个标记的MNIST验证集上进行验证：
- en: '[PRE34]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The following code shows the training and the validation log loss from this
    supervised-only solution:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码显示了这种仅监督学习解决方案的训练和验证log loss：
- en: '[PRE35]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The following code shows the overall accuracy of this supervised-only image
    classification solution:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码显示了这种仅监督学习图像分类解决方案的总体准确性：
- en: '[PRE36]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Unsupervised and Supervised Solution
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督和监督解决方案
- en: 'Now, instead of training on the five thousand labeled MNIST images, let’s train
    on the 100,000 generated images from the DBN:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们不再训练五千个标记的MNIST图像，而是训练来自DBN生成的10万张图像：
- en: '[PRE38]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The following code displays the log loss of this unsupervised-enchanced image
    classification solution:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码显示了这种无监督增强图像分类解决方案的log loss：
- en: '[PRE40]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The following code shows the overall accuracy of this unsupervised-enchanced
    image classification solution:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码显示了这种无监督增强图像分类解决方案的总体准确性：
- en: '[PRE41]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: As you see, the solution improves by nearly one percentage point, which is considerable.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，这个解决方案提高了近一个百分点，这是相当可观的。
- en: Conclusion
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In [Chapter 10](ch10.html#Chapter_10), we introduced the first class of generative
    models called restricted Boltzmann machines. In this chapter, we built upon this
    concept by introducing more advanced generative models known as deep belief networks,
    which are comprised of multiple RBMs stacked on top of each other.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第10章](ch10.html#Chapter_10)，我们介绍了第一类生成模型——限制玻尔兹曼机。在本章中，我们基于这一概念介绍了更先进的生成模型，称为深度信念网络，它由多个堆叠的RBM组成。
- en: We demonstrated how DBNs work—in a purely unsupervised manner, the DBN learns
    the underlying structure of data and uses its learning to generate new synthetic
    data. Based on how the new synthetic data compares to the original data, the DBN
    improves its generative ability so much so that the synthetic data increasingly
    resembles the original data. We also showed how synthetic data generated by DBNs
    could supplement existing labeled datasets, improving the performance of supervised
    learning models by increasing the size of the overall training set.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了深度玻尔兹曼机（DBNs）的工作原理——在纯无监督的情况下，DBN学习数据的潜在结构，并利用其学习生成新的合成数据。根据新合成数据与原始数据的比较，DBN改善其生成能力，以至于合成数据越来越像原始数据。我们还展示了DBNs生成的合成数据如何补充现有的标记数据集，通过增加整体训练集的大小来提高监督学习模型的性能。
- en: The semisupervised solution we developed using DBNs (unsupervised learning)
    and gradient boosting (supervised learning) outperformed the purely supervised
    solution in the MNIST image classifaction problem we had.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发的半监督解决方案利用了DBNs（无监督学习）和梯度提升（监督学习），在我们所面对的MNIST图像分类问题中，其表现优于纯监督解决方案。
- en: In [Chapter 12](ch12.html#Chapter_12), we introduce one of the latest advances
    in unsupervised learning (and generative modeling, more specifically) known as
    generative adversarial networks.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第12章](ch12.html#Chapter_12)，我们介绍了无监督学习（特别是生成建模）中的最新进展之一，即生成对抗网络。
