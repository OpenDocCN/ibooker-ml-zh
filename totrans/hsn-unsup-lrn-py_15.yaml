- en: Chapter 11\. Feature Detection Using Deep Belief Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 10](ch10.html#Chapter_10), we explored restricted Boltzmann machines
    and used them to build a recommender system for movie ratings. In this chapter,
    we will stack RBMs together to build *deep belief networks (DBNs)*. DBNs were
    first introduced by Geoff Hinton at the University of Toronto in 2006.
  prefs: []
  type: TYPE_NORMAL
- en: RBMs have just two layers, a visible layer and a hidden layer; in other words,
    RBMs are just shallow neural networks. DBNs are made up of multiple RBMs—the hidden
    layer of one RBM serves as the visible layer of the next RBM. Because they involve
    many layers, DBNs are deep neural networks. In fact, they are the first type of
    deep unsupervised neural network we’ve introduced so far.
  prefs: []
  type: TYPE_NORMAL
- en: Shallow unsupervised neural networks, such as RBMs, cannot capture structure
    in complex data such as images, sound, and text, but DBNs can. DBNs have been
    used to recognize and cluster images, video capture, sound, and text, although
    other deep learning methods have surpassed DBNs in performance over the past decade.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Belief Networks in Detail
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like RBMs, DBNs can learn the underlying structure of input and probabilistically
    reconstruct it. In other words, DBNs—like RBMs—are generative models. And, as
    with RBMs, the layers in DBNs have connections only between layers but not between
    units within each layer.
  prefs: []
  type: TYPE_NORMAL
- en: In the DBN, one layer is trained at a time, starting with the very first hidden
    layer, which, along with the input layer, makes up the first RBM. Once this first
    RBM is trained, the hidden layer of the first RBM serves as the visible layer
    of the next RBM and is used to train the second hidden layer of the DBN.
  prefs: []
  type: TYPE_NORMAL
- en: This process continues until all the layers of the DBN are trained. Except for
    the first and final layers of the DBN, each layer in the DBN serves as both a
    hidden layer and a visible layer of an RBM.
  prefs: []
  type: TYPE_NORMAL
- en: The DBN is a hierarchy of representations and, like all neural networks, is
    a form of representation learning. Note that the DBN does not use any labels.
    Instead, the DBN is learning the underlying structure in the input data one layer
    at a time.
  prefs: []
  type: TYPE_NORMAL
- en: Labels can be used to fine-tune the last few layers of the DBN but only after
    the initial unsupervised learning has been completed. For example, if we want
    the DBN to be a classifier, we would perform unsupervised learning first (a process
    known as *pre-training*) and then use labels to fine-tune the DBN (a process called
    *fine-tuning*).
  prefs: []
  type: TYPE_NORMAL
- en: MNIST Image Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s build an image classifier using DBNs. We will turn to the MNIST dataset
    once again.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s load the necessary libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then load the data and store it in Pandas DataFrames. We will also
    encode the labels as one-hot vectors. This is all similar to what we did when
    we first introduced the MNIST dataset earlier in the book:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Restricted Boltzmann Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, let’s define an RBM class so we can train several RBMs (which are the
    building blocks for DBNs) in quick succession.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that RBMs have an input layer (also referred to as the visible layer)
    and a single hidden layer, and the connections among neurons are restricted such
    that neurons are connected only to the neurons in other layers but not to neurons
    within the same layer. Also, recall that communication between layers happens
    in both directions—not just in one direction or a feedforward way, as in the case
    of autoencoders.
  prefs: []
  type: TYPE_NORMAL
- en: In an RBM, the neurons in the visible layer communicate with the hidden layer,
    the hidden layer generates data from the probabilistic model the RBM has learned,
    and then the hidden layer passes this generated information back to the visible
    layer. The visible layer takes the generated data from the hidden layer, samples
    it, compares it to the original data, and, based on the reconstruction error between
    the generated data sample and the original data, sends new information to the
    hidden layer to repeat the process once again.
  prefs: []
  type: TYPE_NORMAL
- en: By communicating in this bidirectional way, the RBM develops a generative model
    such that the reconstructions from the output of the hidden layer are similar
    to the original input.
  prefs: []
  type: TYPE_NORMAL
- en: Build the Components of the RBM Class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Like we did in [Chapter 10](ch10.html#Chapter_10), let’s walk through the various
    components of the `RBM` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will initialize the class with a few parameters; these are the input
    size of the RBM, the output size, the learning rate, the number of epochs to train
    for, and the batch size during the training process. We will also create zero
    matrices for the weight matrix, the hidden bias vector, and the visible bias vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s define functions for the forward pass, the backward pass, and the
    sampling of data during each of these passes back and forth.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the forward pass, where *h* is the hidden layer and *v* is the visible
    layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the backward pass:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the sampling function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now we need a function that performs that training. Since we are using TensorFlow,
    we first need to create placeholders for the TensorFlow graph, which we will use
    when we feed data into the TensorFlow session.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will have placeholders for the weights matrix, the hidden bias vector, and
    the visible bias vector. We will also need to initialize the values for these
    three using zeros. And, we will need one set to hold the current values and one
    set to hold the previous values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Likewise, we need a placeholder for the visible layer. The hidden layer is
    derived from matrix multiplication of the visible layer and the weights matrix
    and the matrix addition of the hidden bias vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: During the backward pass, we take the hidden layer output, multiply it with
    the transpose of the weights matrix used during the forward pass, and add the
    visible bias vector. Note that the weights matrix is the same weights matrix during
    both the forward and the backward pass.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we perform the forward pass again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'To update the weights, we perform constrastive divergence, which we introduced
    in [Chapter 10](ch10.html#Chapter_10). We also define the error as the MSE:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: With this, we are ready to initialize the TensorFlow session with the variables
    we have just defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we call `sess.run`, we can feed in batches of data to begin the training.
    During the training, forward and backward passes will be made, and the RBM will
    update weights based on how the generated data compares to the original input.
    We will print the reconstruction error from each epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Generate Images Using the RBM Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s also define a function to generate new images from the generative model
    that the RBM has learned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We feed the original matrix of images, called *X*, into the function. We create
    TensorFlow placeholders for the original matrix of images, the weights matrix,
    the hidden bias vector, and the visible bias vector. Then, we push the input matrix
    to produce the output of a forward pass (`out`), a sample of the hidden layer
    (`hiddenGen`), and a sample of the reconstructed images generated by the model
    (`visibleGen`).
  prefs: []
  type: TYPE_NORMAL
- en: View the Intermediate Feature Detectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, let’s define a function to show the feature detectors of the hidden
    layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We will use this and the other functions on the MNIST dataset now.
  prefs: []
  type: TYPE_NORMAL
- en: Train the Three RBMs for the DBN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now use the MNIST data to train three RBMs, one at a time, such that
    the hidden layer of one RBM is used as the visible layer of the next RBM. These
    three RBMs will make up the DBN that we are building to perform image classification.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s take the training data and store it as a NumPy array. Next, we
    will create a list to hold the RBMs we train called `rbm_list`. Then, we will
    define the hyperparameters for the three RBMs, including the input size, the output
    size, the learning rate, the number of epochs to train for, and the batch size
    for training.
  prefs: []
  type: TYPE_NORMAL
- en: All of these can be built using the RBM class we defined earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our DBN, we will use the following RBMs: the first will take the original
    784-dimension input and output a 700-dimension matrix. The next RBM will use the
    700-dimension matrix output of the first RBM and output a 600-dimension matrix.
    Finally, the last RBM we train will take the 600-dimension matrix and output a
    500-dimension matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will train all three RBMs using a learning rate of 1.0, train for 100 epochs
    each, and use a batch size of two hundred:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s train the RBMs. We will store the trained RBMs in a list called `outputList`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we use the `rbm_output` function we defined earlier to produce the
    output matrix—in other words, the hidden layer—for use as the input/visible layer
    of the subsequent RBM we train:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The errors of each RBM decline the longer we train (see Figures [11-1](#reconstruction_Errors_of_first_rbm),
    [11-2](#reconstruction_errors_of_second_rbm), and [11-3](#reconstruction_errors_of_third_rbm)).
    Note that the RBM error reflects how similar the reconstructed data of a given
    RBM is to the data fed into the visible layer of that very RBM.
  prefs: []
  type: TYPE_NORMAL
- en: '![Reconstruction Errors of First RBM](assets/hulp_1101.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-1\. Reconstruction errors of first RBM
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Reconstruction Errors of Second RBM](assets/hulp_1102.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-2\. Reconstruction errors of second RBM
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Reconstruction Errors of Third RBM](assets/hulp_1103.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-3\. Reconstruction errors of third RBM
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Examine Feature Detectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let’s view the learned features from each of the RBMs using the `rbm.show_features`
    function we defined earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 11-4](#learned_features_of_the_rbms) displays the learned features
    for the various RBMs.'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, each RBM learns increasingly abstract features from the MNIST
    data. The features of the first RBM vaguely resemble digits, and the features
    of the second and the third RBMs are increasingly nuanced and less discernible.
    This is pretty typical of how feature detectors work on image data; the deeper
    layers of the neural network recognize increasingly abstract elements from the
    original images.
  prefs: []
  type: TYPE_NORMAL
- en: '![Learned Features of the RBMs](assets/hulp_1104.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-4\. Learned features of the RBMs
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: View Generated Images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we build the full DBN, let’s view some of the generated images from one
    of the RBMs we just trained.
  prefs: []
  type: TYPE_NORMAL
- en: 'To keep things simple, we will feed the original MNIST training matrix into
    the first RBM we trained, which performs a forward pass and a backward pass, then
    will produce the generated images we need. We will compare the first ten images
    of the MNIST dataset with the newly generated images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 11-5](#first_generated_image_of_the_first_rbm) shows the first image
    produced by the RBM compared to the first original image.'
  prefs: []
  type: TYPE_NORMAL
- en: '![First Generated Image of the First RBM](assets/hulp_1105.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-5\. First generated image of the first RBM
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, the generated image is similar to the original image — both
    display the digit five.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s view a few more images like this to compare the RBM-generated images with
    the original ones (see Figures [11-6](#second_generated_image_of_the_first_rbm)
    through [11-9](#fifth_generated_image_of_the_first_rbm)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Second Generated Image of the First RBM](assets/hulp_1106.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-6\. Second generated image of the first RBM
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Third Generated Image of the First RBM](assets/hulp_1107.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-7\. Third generated image of the first RBM
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Fourth Generated Image of the First RBM](assets/hulp_1108.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-8\. Fourth generated image of the first RBM
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Fifth Generated Image of the First RBM](assets/hulp_1109.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-9\. Fifth generated image of the first RBM
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: These digits are zero, four, one, and nine, respectively, and the generated
    images look reasonably similar to the original images.
  prefs: []
  type: TYPE_NORMAL
- en: The Full DBN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let’s define the DBN class, which will take in the three RBMs we just trained
    and add a fourth RBM that performs forward and backward passes to refine the overall
    DBN-based generative model.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s define the hyperparameters of the class. These include the original
    input size, the input size of the third RBM we just trained, the final output
    size we would like to have from the DBN, the learning rate, the number of epochs
    we wish to train for, the batch size for training, and the three RBMs we just
    trained. Like before, we will need to generate zero matrices for the weights,
    hidden bias, and visible bias:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to before, we will define functions to perform the forward pass and
    the backward pass and take samples from each:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'For the training, we need placeholders for the weights, hidden bias, and visible
    bias. We also need matrices for the previous and current weights, hidden biases,
    and visible biases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We will set a placeholder for the visible layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will take the initial input—the visible layer—and pass it through
    the three RBMs we trained earlier. This results in the output *forward*, which
    we will pass into the fourth RBM we train as part of this DBN class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We will define the contrastive divergence like we did before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Once we generate a full forward pass through this DBN—which includes the three
    RBMs we trained earlier plus the latest fourth RBM—we need to send the output
    of the fourth RBM’s hidden layer back through the entire DBN.
  prefs: []
  type: TYPE_NORMAL
- en: 'This requires a backward pass through the fourth RBM as well as a backward
    pass through the first three. We will also use MSE as before. Here is how the
    backward pass occurs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the actual training portion of the DBN class, again very similar to
    the RBM one earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s define functions to produce generated images from the DBN and show features.
    These are similar to the RBM versions earlier, but we send the data through all
    four RBMs in the DBN class instead of just through a single RBM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: How Training of a DBN Works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each of the three RBMs we have trained already has its own weights matrix, hidden
    bias vector, and visible bias vector. During the training of the fourth RBM as
    part of the DBN, we will not adjust the weights matrix, hidden bias vector, and
    visible bias vector of those first three RBMs. Rather, we will use the first three
    RBMs as fixed components of the DBN. We will call upon the first three RBMs just
    to do the forward and backward passes (and use samples of the data these three
    generate).
  prefs: []
  type: TYPE_NORMAL
- en: During the training of the fourth RBM in the DBN, we will only adjust weights
    and biases of the fourth RBM. In other words, the fourth RBM in the DBN takes
    the output of the first three RBMs as given and performs forward and backward
    passes to learn a generative model that minimizes the reconstruction error between
    its generated images and the original images.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to train the DBNs would be to allow the DBN to learn and adjust
    weights for all four RBMs as it performs forward and backward passes through the
    entire network. However, training of the DBN would be very computationally expensive
    (perhaps not so with computers of today but certainly by the standards of 2006,
    when DBNs were first introduced).
  prefs: []
  type: TYPE_NORMAL
- en: That being said, if we wish to perform more nuanced pretraining, we could allow
    the weights of the individual RBMs to be adjusted—one RBM at a time—as we perform
    batches of forward and backward passes through the network. We will not delve
    into this, but I encourage you to experiment on your own time.
  prefs: []
  type: TYPE_NORMAL
- en: Train the DBN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now train the DBN. We set the original image dimensions as 784, the
    dimensions of the third RBM output as 500, and the desired dimensions of the DBN
    as 500\. We will use a learning rate of 1.0, train for 50 epochs, and use a batch
    size of 200\. Finally, we will call the first three trained RBMs as part of the
    DBN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s train:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 11-10](#reconstruction_errors_of_the_dbn) displays the reconstruction
    errors of the DBN over the course of the training.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reconstruction Errors of the DBN](assets/hulp_1110.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-10\. Reconstruction errors of the DBN
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 11-11](#learned_features_of_the_fourth_rbm_in_the_dbn) displays the
    learned features from the last layer of the DBN — the hidden layer of the fourth
    RBM.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Learned Features of the Fourth RBM in the DBN](assets/hulp_1111.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-11\. Learned features of the fourth RBM in the DBN
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Both the reconstruction errors and the learned features look reasonable and
    similar to the ones from the individual RBMs we analyzed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: How Unsupervised Learning Helps Supervised Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, all the work we have done training the RBMs and the DBN involve unsupervised
    learning. We have not used any labels for the images at all. Instead, we have
    built generative models by learning relevant latent features from the original
    MNIST images provided in the 50,000 example training set. These generative models
    generate images that look reasonably similar to the original images (minimizing
    the reconstruction error).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a step back to understand the usefulness of such a generative model.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that most of the data in the world is unlabeled. Therefore, as powerful
    and effective as supervised learning is, we need unsupervised learning to help
    make sense of all the unlabeled data that exists. Supervised learning is not enough.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the usefulness of unsupervised learning, imagine if instead of
    50,000 labeled MNIST images in the training set, we had just a fraction—let’s
    say we had only 5,000 labeled MNIST images. A supervised learning-based image
    classifer that had only 5,000 labeled images would not be nearly as effective
    as a supervised learning-based image classifier that had 50,000 images. The more
    labeled data we have, the better the machine learning solution.
  prefs: []
  type: TYPE_NORMAL
- en: How does unsupervised learning help in such a situation? One way unsupervised
    learning could help is by generating new labeled examples to help supplement the
    originally labeled dataset. Then, the supervised learning could occur on a much
    larger labeled dataset, resulting in a better overall solution.
  prefs: []
  type: TYPE_NORMAL
- en: Generate Images to Build a Better Image Classifier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To simulate this benefit that unsupervised learning is able to provide, let’s
    reduce our MNIST training dataset to just five thousand labeled examples. We will
    store the first five thousand images in a dataframe called `inputXReduced`.
  prefs: []
  type: TYPE_NORMAL
- en: Then, from these five thousand labeled images, we will generate new images from
    the generative model we just built using a DBN. And, we will do this 20 times
    over. In other words, we will generate five thousand new images 20 times to create
    a dataset that is 100,000 large, all of which will be labeled. Technically, we
    are storing the final hidden layer outputs not the reconstructed images directly,
    although we will store the reconstructed images, too, so we can evaluate them
    soon.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will store these 100,000 outputs in a NumPy array called `generatedImages`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We will loop through the first five thousand labels from the training labels,
    called `y_train`, 20 times to generate an array of labels called `labels`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will generate the output on the validation set, which we will need
    to evaluate the image classifier we will build soon:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we use the data we just generated, let’s view a few of the reconstructed
    images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '![First Generated Image of the DBN](assets/hulp_1112.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-12\. First generated image of the DBN
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see in [Figure 11-12](#first_generated_image_of_the_dbn), the generated
    image is very similar to the original image—both display the digit five. Unlike
    the RBM-generated images we saw earlier, these are more similar to the original
    MNIST images, including the pixelated bits.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s view a few more images like this to compare the DBN-generated images with
    the original MNIST ones (see Figures [11-13](#second_generated_image_of_the_dbn)
    through [11-16](#fifth_generated_image_of_the_dbn)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Second Generated Image of the DBN](assets/hulp_1113.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-13\. Second generated image of the DBN
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Third Generated Image of the DBN](assets/hulp_1114.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-14\. Third generated image of the DBN
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Fourth Generated Image of the DBN](assets/hulp_1115.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-15\. Fourth generated image of the DBN
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Fifth Generated Image of the DBN](assets/hulp_1116.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-16\. Fifth generated image of the DBN
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Also note that the DBN model (as well as the RBM models) is generative and therefore
    the images are produced using a stochastic process. The images are not produced
    using a deterministic process, and, therefore, the images of a single example
    vary from one DBN run to another.
  prefs: []
  type: TYPE_NORMAL
- en: 'To simulate this, we will take the first MNIST image and use the DBN to generate
    a new one and do this 10 times over:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: As you see from Figures [11-17](#first_two_generated_images_of_the_digit_five)
    through [11-21](#fifth_two_generated_images_of_the_digit_five), all the generated
    images display the number five, but they vary from image to image even though
    they all were generated using the same original MNIST image.
  prefs: []
  type: TYPE_NORMAL
- en: '![First and second Generated Images of the Digit Five](assets/hulp_1117.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-17\. First and second generated images of the digit five
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Third and fourth Generated Images of the Digit Five](assets/hulp_1118.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-18\. Third and fourth generated images of the digit five
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Fifth and sixth Generated Images of the Digit Five](assets/hulp_1119.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-19\. Fifth and sixth generated images of the digit five
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Seventh and eighth Generated Images of the Digit Five](assets/hulp_1120.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-20\. Seventh and eighth generated images of the digit five
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Ninth and tenth Generated Images of the Digit Five](assets/hulp_1121.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-21\. Ninth and tenth generated images of the digit five
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Image Classifier Using LightGBM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now let’s build an image classifier using a supervised learning algorithm we
    introduced earlier in the book: the gradient boosting algorithm *LightGBM*.'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised Only
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first image classifier will rely on just the first five thousand labeled
    MNIST images. This is the reduced set from the original 50,000 labeled MNIST training
    set; we designed this to simulate real-world problems where we have relatively
    few labeled examples. Since we covered gradient boosting and the LightGBM algorithm
    in depth earlier in the book, we will not go into a lot of detail here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s set the parameters for the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will train on the 5,000 labeled MNIST training set (the reduced set)
    and validate on the 10,000 labeled MNIST validation set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows the training and the validation log loss from this
    supervised-only solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows the overall accuracy of this supervised-only image
    classification solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Unsupervised and Supervised Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, instead of training on the five thousand labeled MNIST images, let’s train
    on the 100,000 generated images from the DBN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code displays the log loss of this unsupervised-enchanced image
    classification solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows the overall accuracy of this unsupervised-enchanced
    image classification solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: As you see, the solution improves by nearly one percentage point, which is considerable.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 10](ch10.html#Chapter_10), we introduced the first class of generative
    models called restricted Boltzmann machines. In this chapter, we built upon this
    concept by introducing more advanced generative models known as deep belief networks,
    which are comprised of multiple RBMs stacked on top of each other.
  prefs: []
  type: TYPE_NORMAL
- en: We demonstrated how DBNs work—in a purely unsupervised manner, the DBN learns
    the underlying structure of data and uses its learning to generate new synthetic
    data. Based on how the new synthetic data compares to the original data, the DBN
    improves its generative ability so much so that the synthetic data increasingly
    resembles the original data. We also showed how synthetic data generated by DBNs
    could supplement existing labeled datasets, improving the performance of supervised
    learning models by increasing the size of the overall training set.
  prefs: []
  type: TYPE_NORMAL
- en: The semisupervised solution we developed using DBNs (unsupervised learning)
    and gradient boosting (supervised learning) outperformed the purely supervised
    solution in the MNIST image classifaction problem we had.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 12](ch12.html#Chapter_12), we introduce one of the latest advances
    in unsupervised learning (and generative modeling, more specifically) known as
    generative adversarial networks.
  prefs: []
  type: TYPE_NORMAL
