- en: 5 Loss functions and metrics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 损失函数和指标
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Selecting proper metrics and losses for your machine learning system
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为你的机器学习系统选择合适的指标和损失函数
- en: Defining and utilizing proxy metrics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义和利用代理指标
- en: Applying the hierarchy of metrics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用指标层次结构
- en: In the previous chapter, we first touched on the topic of creating a design
    document for your machine learning (ML) system. We figured out why a design document
    is subject to constant edits and why all the changes you implement in it are not
    only inevitable but also necessary.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们首先触及了为你的机器学习（ML）系统创建设计文档的主题。我们弄清楚了为什么设计文档需要不断编辑，以及为什么你在其中实施的每一个变化不仅不可避免，而且是必要的。
- en: Unfortunately, an ML system can’t directly solve a problem, but it can try to
    approximate it by optimizing a specific task. To do that efficiently, it must
    be adjusted, appropriately guided, and monitored.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 很不幸，一个机器学习系统不能直接解决问题，但它可以通过优化特定任务来尝试近似它。为了有效地做到这一点，它必须得到适当的调整、指导和监控。
- en: To direct an ML system’s effort, we use its algorithm’s loss function to reward
    or punish if for reducing or increasing specific errors. However, the loss function
    is used to train the model and usually must be differentiable, meaning that there
    is a narrowed choice of available loss functions. Thus, to assess the model’s
    performance, we use metrics; and while every loss function can be used as a metric
    (a good example would be root mean squared error [RMSE], which is quite often
    used as a metric, although we are not sure that is the best decision), not every
    metric can be used as a loss function.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了指导机器学习系统的努力，我们使用其算法的损失函数来奖励或惩罚以减少或增加特定的错误。然而，损失函数用于训练模型，通常必须是可微分的，这意味着可用的损失函数选择范围较窄。因此，为了评估模型的表现，我们使用指标；虽然每个损失函数都可以用作指标（一个很好的例子是均方根误差
    [RMSE]，它经常用作指标，尽管我们不确定这是否是最好的决定），但并非每个指标都可以用作损失函数。
- en: In this chapter, we will discuss how to pick the best-fitting metrics and loss
    functions, focusing on how to do proper research and provide motivation for choice
    during the design process.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何选择最佳拟合的指标和损失函数，重点关注如何在设计过程中进行适当的研究并提供选择动机。
- en: 5.1 Losses
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 损失
- en: The *loss function*, also known as the *objective* or *cost function*, effectively
    defines how a model learns about the world and the connections between dependent
    and independent variables, what it pays the most attention to, what it tries to
    avoid, and what it considers acceptable. Thus, the choice of a loss function can
    drastically affect your model’s overall performance, even if everything else—features,
    target, model architecture, dataset size—remains unchanged. Switching to a different
    loss function can completely reshape your whole system.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*损失函数*，也称为*目标函数*或*代价函数*，有效地定义了模型如何了解世界以及因变量和自变量之间的联系，它最关注什么，它试图避免什么，以及它认为什么是可接受的。因此，损失函数的选择可以极大地影响你模型的总体性能，即使其他所有因素——特征、目标、模型架构、数据集大小——保持不变。切换到不同的损失函数可以完全重塑整个系统。'
- en: Picking the right loss function (i.e., choosing the way a model learns from
    its mistakes) is one of the most crucial decisions in designing an ML system.
    Recalling an evergreen anecdote, we can be pretty confident in optimizing for
    the mean while counting the average salary of bar visitors until Bill Gates walks
    in ([https://mng.bz/M1w8](https://mng.bz/M1w8)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的损失函数（即，选择模型从其错误中学习的方式）是设计机器学习系统中最关键的决定之一。回忆一个永恒的轶事，我们可以在计算酒吧访客的平均工资时对均值进行优化，直到比尔·盖茨走进来（[https://mng.bz/M1w8](https://mng.bz/M1w8)）。
- en: 'Unfortunately, not every function can be used as a loss function. In general,
    a loss function feature two properties:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 很不幸，并非每个函数都可以用作损失函数。一般来说，损失函数具有两个特性：
- en: It is globally continuous (changes in predictions lead to changes in losses).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它在全局上是连续的（预测的变化会导致损失的变化）。
- en: 'It is differentiable (its gradient can be calculated for optimization algorithms
    based on the gradient descent). There is one exclusion: in exotic cases, gradient-free
    optimization methods are applicable, although practitioners prefer to avoid them
    as gradient-based methods typically converge much better.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是可微分的（其梯度可以用于基于梯度下降的优化算法）。有一个例外：在特殊情况下，无梯度优化方法适用，尽管实践者通常更喜欢避免它们，因为基于梯度的方法通常收敛得更好。
- en: While these two points are relevant for any loss, it is important to select
    a loss function that will best match your particular case and will be closest
    to the final goal of your system.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这两个点对任何损失函数都相关，但选择一个最适合你特定情况并且最接近你系统最终目标的损失函数是很重要的。
- en: This is where advanced loss functions come into play, providing tempting ways
    of improving your model. Unlike manipulations with features or the model itself,
    they don’t usually affect the runtime aspect, meaning that all the code changes
    are only related to training pipelines, and isolating changes to a small part
    of a system is always a good property of design. But more often than not, we have
    witnessed ML engineers (especially recent graduates) sticking to a particular
    loss function just because they got used to applying it to similar problems. A
    notorious example is the regression problem with the mean squared error (MSE)
    or mean absolute error (MAE) loss function as the default choice and, many times,
    *the only choice* by many practitioners.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是高级损失函数发挥作用的地方，提供了改进你的模型的有吸引力的方法。与对特征或模型本身的操作不同，它们通常不会影响运行时方面，这意味着所有代码更改都仅与训练管道相关，将更改隔离到系统的小部分总是设计的一个好特性。但更常见的是，我们见证了机器学习工程师（尤其是应届毕业生）坚持使用特定的损失函数，仅仅因为他们习惯了将其应用于类似的问题。一个臭名昭著的例子是，回归问题中默认选择均方误差（MSE）或平均绝对误差（MAE）损失函数，并且很多时候，这是许多从业者*唯一的选择*。
- en: 'At the same time, while choosing a proper loss function (or a set of them)
    is a decision that may greatly improve your model’s performance, it is still not
    a silver bullet. We have worked with a few ML engineers (often with respectable
    academic backgrounds and PhDs) who tried to solve all the problems they had with
    just one elegant loss function. This approach is on the opposite end of the spectrum
    from paying no attention to the loss function at all, but it is still far from
    ideal. A good ML system designer keeps many tools in mind, not overfitting for
    one. Overall, the heuristic is the following: the more research-heavy your system
    is, the more likely it is that you need to invest time in finding or designing
    a nontrivial loss function.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，虽然选择一个合适的损失函数（或一组损失函数）是一个可能大大提高你的模型性能的决定，但这并不是万能的解决方案。我们曾与几位机器学习工程师（他们通常拥有令人尊敬的学术背景和博士学位）合作，他们试图仅通过一个优雅的损失函数来解决他们遇到的所有问题。这种方法与完全不关注损失函数的方法正好相反，但仍然远非理想。一个好的机器学习系统设计者会考虑许多工具，而不是过分依赖一个。总的来说，经验法则是这样的：你的系统研究越深入，你越有可能需要投入时间来寻找或设计一个非平凡的损失函数。
- en: A couple of years ago, Valerii worked with an intern on building a model to
    predict the exchange volume of cryptocurrencies. As always, he asked the intern
    to prepare a design document before doing anything, and this was an insightful
    exercise. The intern thoughtlessly skipped the loss function chapter, listing
    some metrics he would use to assess the system performance without any reasoning
    behind them.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 几年前，瓦列里与一名实习生合作，构建了一个预测加密货币交易量的模型。像往常一样，他要求实习生在开始任何工作之前准备一个设计文档，这是一个富有洞察力的练习。实习生没有考虑地跳过了损失函数章节，列出了一些他将用来评估系统性能的指标，而没有给出任何理由。
- en: 'Why is this not acceptable? By using an example, we can review a simplified
    situation with a knowledge of loss functions for regression problems being narrowed
    down to the two most widely used loss functions: MSE and MAE.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这不可接受？通过一个例子，我们可以回顾一个简化的情况，其中关于回归问题的损失函数知识被缩小到两个最广泛使用的损失函数：MSE和MAE。
- en: Imagine that we have a vector of target values Y = [100, 100, 100, 100, 100,
    100, 100, 100, 100, 1000] and a vector of independent variables X being equal
    for all samples.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们有一个目标值向量Y = [100, 100, 100, 100, 100, 100, 100, 100, 100, 1000]和一个对所有样本都相同的独立变量X向量。
- en: 'If we train a model using MSE as a loss function, it will output a vector of
    predictions:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用MSE作为损失函数来训练一个模型，它将输出一个预测向量：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If we train a model using MAE as a loss function, it will output a vector of
    predictions:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用MAE作为损失函数来训练一个模型，它将输出一个预测向量：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: NOTE  Please note that this is a thought experiment to highlight the idea and
    make it easier to comprehend. If we needed to, we could create synthetic data
    to reproduce the whole process—features, targets, and models—but for the sake
    of simplicity, we will use only the preceding numbers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：请注意，这是一个思想实验，旨在突出这个想法并使其更容易理解。如果我们需要，我们可以创建合成数据来重现整个过程——特征、目标和模型，但为了简单起见，我们将只使用前面的数字。
- en: 'When we calculate MSE and MAE for a model with the RMSE loss function, it will
    result in the following numbers: MSE = 72,900, MAE = 162, with the mean of residuals
    equal to 0 and the median of residuals equal to –90 (figure 5.1).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用RMSE损失函数计算模型的MSE和MAE时，会得到以下数字：MSE = 72,900，MAE = 162，残差的均值为0，残差的中位数为-90（图5.1）。
- en: '![figure](../Images/CH05_F01_Babushkin.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F01_Babushkin.png)'
- en: Figure 5.1 Residuals after optimizing the mean
  id: totrans-28
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.1 优化均值后的残差
- en: When we calculate MSE and MAE for a model with the MAE loss function, the result
    will be MSE = 81,000, MAE = 90, with the mean of residuals equal to 90 and the
    median of residuals equal to 0 (figure 5.2).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用MAE损失函数计算模型的MSE和MAE时，结果将是MSE = 81,000，MAE = 90，残差的均值为90，残差的中位数为0（图5.2）。
- en: '![figure](../Images/CH05_F02_Babushkin.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F02_Babushkin.png)'
- en: Figure 5.2 Residuals after optimizing the median
  id: totrans-31
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.2 优化中位数后的残差
- en: No wonder the model optimized for MSE yields better MSE, and as MSE tries to
    minimize the mean, the mean residuals are better. On the other hand, the model
    optimized for MAE delivers better MAE, and as MAE tries to optimize the median,
    the median residuals are better. But what does it mean for us? Which loss function
    is better? That depends on our application.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 没有什么好奇怪的，优化MSE的模型得到了更好的MSE，因为MSE试图最小化均值，所以均值残差更好。另一方面，优化MAE的模型提供了更好的MAE，因为MAE试图优化中位数，所以中位数残差更好。但这对我们意味着什么呢？哪个损失函数更好？这取决于我们的应用。
- en: Let’s say we are optimizing a navigation system for aircraft, and an error larger
    than 850 means that a plane will go off a landing field and crash. In this case,
    optimizing for MAE is not an ideal decision. Of course, we can say 9 out of 10
    times that we have a perfect result, and only 1 out of 10 times a vehicle is destroyed,
    but this is not acceptable by any means. We have to avoid outliers at all costs
    or penalize them, thus using MSE or even some higher-degree modifications.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在优化一个飞机的导航系统，任何大于850的错误都意味着飞机将偏离着陆场并坠毁。在这种情况下，优化MAE不是一个理想的选择。当然，我们可以有9次中有10次得到完美的结果，只有1次车辆被摧毁，但这无论如何都是不可接受的。我们必须不惜一切代价避免异常值或对它们进行惩罚，因此使用MSE甚至是一些更高阶的修改。
- en: 'But suppose we are optimizing the amount of liquidity for a cryptocurrency
    exchange we need for every trading day. *Liquidity* refers to a cryptocurrency’s
    capacity to be converted into cash or other cryptocurrencies without losing value,
    and it is essential for all cryptocurrency exchanges. High liquidity signifies
    a dynamic and stable market, allowing participants to trade quickly at reasonable
    prices. Excessive liquidity, however, means that allocated resources are not used.
    In this case, reserving more cash than required 9 times out of 10 is far from
    desired. We can review it from a different angle: the model optimized for MSE
    overallocated 810 units and underallocated 810 units, while the model optimized
    for MAE was on the spot 9 times out of 10 and underallocated 900 units, which
    seems like a better decision (if underallocation is less than 9 times worse than
    over allocation) to convey to the model what we need.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 但假设我们正在优化一个加密货币交易所每天交易所需的流动性数量。*流动性*指的是加密货币在没有损失价值的情况下转换为现金或其他加密货币的能力，这对所有加密货币交易所都是至关重要的。高流动性意味着一个动态且稳定的市场，允许参与者以合理的价格快速交易。然而，过多的流动性意味着分配的资源没有得到利用。在这种情况下，有9次中有10次预留比所需的现金更多，这远远不是我们想要的。我们可以从不同的角度来审视这个问题：优化MSE的模型多分配了810个单位，少分配了810个单位，而优化MAE的模型有10次中有9次准确无误，并且只少分配了900个单位，这似乎是一个更好的决策（如果少分配不如多分配糟糕9倍的话），向模型传达我们需要的信息。
- en: It’s easy to see that even though we used MSE and MAE to train the models, we
    applied different criteria to assess them. For the aircraft navigation system,
    we counted the number of times when the difference between the actual and predicted
    value was greater than 850\. For liquidity optimization, it was the number of
    times we were on the spot or under an overallocation weighted sum. This illustrates
    that training the model to optimize specific loss functions and assess this model’s
    performance can represent two different tasks, which we will cover in section
    5.2 on metrics. Before we proceed, we’d like to share some insights on the nuances
    and aspects of determining losses for deep learning models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易看出，尽管我们使用了均方误差（MSE）和平均绝对误差（MAE）来训练模型，但我们应用了不同的标准来评估它们。对于飞机导航系统，我们计算实际值与预测值之差大于850的次数。对于流动性优化，这是我们在现场或过度分配加权求和的次数。这表明，训练模型以优化特定的损失函数并评估该模型的表现可以代表两个不同的任务，我们将在第5.2节“指标”中讨论这些任务。在继续之前，我们想分享一些关于确定深度学习模型损失函数的细微差别和方面的见解。
- en: 5.1.1 Loss tricks for deep learning models
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 深度学习模型的损失技巧
- en: In deep-learning-based systems, especially those processing text, image, or
    audio data, loss selection is even more crucial.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于深度学习的系统中，尤其是在处理文本、图像或音频数据的系统中，损失函数的选择更为关键。
- en: A properly chosen loss function can help with many problems related to model
    training, especially a sophisticated model and/or data domain. For example, a
    cross-entropy loss is a classical solution for the classification problem. One
    of the problems with it is related to class imbalance. If one class is heavily
    overrepresented, the model optimized by the entropy loss may face something called
    *mode collapse*—a situation when it outputs a constant (popular class) for any
    input. These problems have been solved in many ways (e.g., data undersampling/oversampling,
    custom weights for classes, etc.), but all of them required significant manual
    tuning and were not reliable. The problem was approached by researchers who tried
    to design a loss addressing it; the most notable result is probably by Lin et
    al. (“Focal Loss for Dense Object Detection,” [https://arxiv.org/abs/1708.02002](https://arxiv.org/abs/1708.02002)),
    and this loss is now taking its honorable place among tools helping to solve the
    data imbalance problem.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正确选择的损失函数可以帮助解决与模型训练相关的许多问题，尤其是对于复杂模型和/或数据领域。例如，交叉熵损失是分类问题的经典解决方案。其中一个问题与类别不平衡有关。如果一个类别被过度代表，通过熵损失优化的模型可能会遇到所谓的*模式崩溃*——即对于任何输入都输出一个常数（流行类别）的情况。这些问题已经通过多种方式得到解决（例如，数据欠采样/过采样、为类别设置自定义权重等），但所有这些都需要大量的手动调整，并且不可靠。研究人员通过尝试设计一个解决该问题的损失函数来解决这个问题；最引人注目的成果可能是林等人（“密集目标检测的焦点损失”，[https://arxiv.org/abs/1708.02002](https://arxiv.org/abs/1708.02002)），现在这种损失函数在帮助解决数据不平衡问题的工具中占据了其应有的位置。
- en: Focal loss (see figure 5.3) is a dynamically scaled cross-entropy loss where
    the scaling factor decays to zero as confidence in the correct class increases.
    Intuitively, this scaling factor can automatically down-weight the contribution
    of easy examples during training and rapidly focus the model on hard examples
    (more information can be found at [https://paperswithcode.com/method/focal-loss](https://paperswithcode.com/method/focal-loss)).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 焦点损失（见图5.3）是一种动态缩放的交叉熵损失，其中缩放因子随着对正确类别的信心增加而衰减到零。直观上，这个缩放因子可以自动降低训练过程中简单示例的贡献，并快速将模型集中在困难示例上（更多信息可以在[https://paperswithcode.com/method/focal-loss](https://paperswithcode.com/method/focal-loss)找到）。
- en: '![figure](../Images/CH05_F03_Babushkin.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F03_Babushkin.png)'
- en: 'Figure 5.3 The suggested focal loss function focuses more on misclassified
    examples while reducing the relative loss for well-classified examples (source:
    Lin et al.).'
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.3 建议的焦点损失函数更关注误分类示例，同时减少对正确分类示例的相对损失（来源：林等人）。
- en: Originally, this loss was introduced for the object detection problem specific
    to computer vision, and later, the approach expanded to many other domains, including
    those unrelated to images, like audio or natural language processing. The most
    distant application of the focal loss we have found has been introduced in the
    paper “Can Natural Language Processing Help Differentiate Inflammatory Intestinal
    Diseases in China?” (Tong et al.; [https://mng.bz/aV9X](https://mng.bz/aV9X)),
    which confirms how ideas spread across domains.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，这种损失函数是为计算机视觉中特定于对象检测的问题引入的，后来，该方法扩展到许多其他领域，包括与图像无关的领域，如音频或自然语言处理。我们发现的焦点损失最远的应用是在论文“自然语言处理能否帮助区分中国的炎症性肠病？”（Tong等人；[https://mng.bz/aV9X](https://mng.bz/aV9X)）中介绍的，这证实了思想在不同领域之间的传播。
- en: 'In some cases, a reasonable solution will be to combine multiple losses for
    a single model. The need for such an approach may arise with complex problems,
    often multimodal and often associated with multiple concurrent datasets. We will
    not provide many details on using combined loss functions here as it is research-heavy,
    but we would like to give some examples:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，合理的解决方案可能是将多个损失函数结合用于单个模型。这种方法的必要性可能出现在复杂问题中，这些问题通常是多模态的，并且通常与多个并发数据集相关联。在这里，我们不会提供太多关于使用组合损失函数的细节，因为它研究密集，但我们愿意给出一些例子：
- en: “Authentic Volumetric Avatars from a Phone Scan” (Cao et al.; [https://dl.acm.org/doi/abs/10.1145/3528223.3530143](https://dl.acm.org/doi/abs/10.1145/3528223.3530143)).
    The authors combined three families of losses (segmentation, reconstruction, perceptual).
    Generative computer vision models are often subject to considering combined losses.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “从手机扫描中生成逼真的体积型虚拟人”（Cao等人；[https://dl.acm.org/doi/abs/10.1145/3528223.3530143](https://dl.acm.org/doi/abs/10.1145/3528223.3530143)）。作者结合了三种损失函数家族（分割、重建、感知）。生成计算机视觉模型通常需要考虑组合损失。
- en: “Highly Accurate Protein Structure Prediction with AlphaFold” (Jumper et al.;
    [https://www.nature.com/articles/s41586-021-03819-2](https://www.nature.com/articles/s41586-021-03819-2)).
    The famous AlphaFold 2 model predicts 3D shapes of proteins from their genetic
    sequence with impressive accuracy. That’s a huge thing for the biotech world,
    and it uses multiple auxiliary losses under the hood. For example, a masked language
    modeling objective, the one that is likely to be inspired by a loss function used
    in BERT-like architectures, is a popular family of natural language processing
    models.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “使用AlphaFold进行高度精确的蛋白质结构预测”（Jumper等人；[https://www.nature.com/articles/s41586-021-03819-2](https://www.nature.com/articles/s41586-021-03819-2)）。著名的AlphaFold
    2模型能够以令人印象深刻的准确性从蛋白质的遗传序列中预测其3D形状。这对生物技术界来说是一个巨大的进步，它在其内部使用了多个辅助损失函数。例如，一个掩码语言模型的目标，可能是受到BERT类似架构中使用的损失函数的启发，是自然语言处理模型中流行的一类。
- en: '“GrokNet: Unified Computer Vision Model Trunk and Embeddings for Commerce”
    (Bell et al.; [https://mng.bz/Xxr6](https://mng.bz/Xxr6)). This is a jewel among
    combined loss examples we can recall. The authors aim to build a single model
    to rule multiple problems, so they used 7 goods datasets and 83 (80 categorical
    and 3 embedding) losses!'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “GrokNet：用于商业的统一计算机视觉模型主干和嵌入”（Bell等人；[https://mng.bz/Xxr6](https://mng.bz/Xxr6)）。这是我们能够回忆起的组合损失示例中的瑰宝。作者的目标是构建一个可以解决多个问题的单一模型，因此他们使用了7个商品数据集和83（80个分类和3个嵌入）损失函数！
- en: In general, multiple losses are usually used either to help models’ convergence
    or to solve multiple adjustment problems with a single model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，多个损失函数要么用于帮助模型收敛，要么用于使用单个模型解决多个调整问题。
- en: While loss functions help set up and fine-tune accuracy and efficiency and minimize
    errors for your system while training, metrics are used to evaluate its performance
    within a certain set of parameters.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当损失函数有助于设置和微调准确性、效率，并在训练过程中最小化错误时，度量标准则用于评估其在一定参数集内的性能。
- en: 5.2 Metrics
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 度量标准
- en: The loss function we optimize and the metric we use to assess our model’s performance
    can be very different from each other. Recall that the end goal of the demand
    forecast system for Supermegaretail in chapter 4 was to reduce the gap between
    delivered and sold items, making it as narrow as possible while avoiding an out-of-stock
    situation. If we try to visualize the pipeline, it might look like figure 5.4.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们优化的损失函数和用于评估模型性能的度量标准可能彼此非常不同。回想一下，在第4章中，Supermegaretail的需求预测系统的最终目标是减少交付和销售物品之间的差距，使其尽可能窄，同时避免缺货情况。如果我们尝试可视化这个流程，它可能看起来像图5.4。
- en: We know that a proper loss function is essential, but what about metrics? Can’t
    we pick some standard metrics, assess a variety of models, choose the best, deploy
    it, and estimate potential success through A/B tests?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道合适的损失函数是必不可少的，但关于指标呢？我们能不能选择一些标准指标，评估各种模型，选择最好的，部署它，并通过 A/B 测试来估计潜在的成功？
- en: '![figure](../Images/CH05_F04_Babushkin.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH05_F04_Babushkin.png)'
- en: Figure 5.4 A general-purpose pipeline for a demand forecast system that perfectly
    fits the Supermegaretail case
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.4 一个适用于需求预测系统的一般性管道，完美契合超级大零售案例
- en: Unfortunately, no. Choosing the right set of metrics has to follow just as carefully
    an elaboration as selecting loss functions. Even more, while the set of popular
    losses is finite, there is always an opportunity to tailor a custom metric for
    a specific business domain. Choosing the wrong metric, in its turn, can cause
    misguided optimization when we set our model to train for irrelevant values, which
    eventually leads to poor performance in real-world scenarios. As a result, we
    have to roll back several steps in model development, resulting in a significant
    waste of time and resources. But even choosing the right metric for your ML system
    will not guarantee the project’s success.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 很遗憾，不行。选择正确的指标集必须像选择损失函数一样仔细。更重要的是，虽然流行的损失函数集是有限的，但总有机会为特定的业务领域定制一个指标。选择错误的指标，反过来，当我们设置我们的模型训练无关值时，会导致误导性的优化，最终导致在实际场景中的性能不佳。结果，我们不得不在模型开发中回滚几步，导致时间和资源的巨大浪费。但即使为您的机器学习系统选择了正确的指标，也不能保证项目的成功。
- en: Campfire story from Valerii
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 瓦列里营火故事
- en: 'Some time ago, I was developing an ML system for a bank that regularly encountered
    the problem of nonpaying debtors. The system we were preparing had two main goals:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，我为一家经常遇到不付款债务人问题的银行开发了一个机器学习系统。我们准备好的系统有两个主要目标：
- en: Reduce the number of delinquent payments
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少逾期付款的数量
- en: Make customers more responsive
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让客户更加响应
- en: As a metric, we chose the conversion rate of clients from nonpayers to payers.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择将客户从非付款者转变为付款者的转化率作为指标。
- en: 'The first thing we did was to implement a system of promised payments that
    worked as follows. Let’s say Mr. Smith gets a call from the bank: “Mr. Smith,
    you haven’t paid your loan on time. Can we expect you to pay the required amount
    within three days?” “Oh, of course, I will, I will,” says Mr. Smith. The people
    at the bank hang up and check the “promised to pay” box. But then Mr. Smith would
    break the promise and not pay anything.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先实施了一个承诺支付系统，其工作方式如下。假设史密斯先生接到银行的电话：“史密斯先生，您没有按时支付您的贷款。我们能否期待您在三天内支付所需金额？”
    “哦，当然，我会的，我会的，”史密斯先生说。银行的人挂断电话并勾选“承诺支付”框。但然后史密斯先生就会违背承诺，一分钱也不付。
- en: The conversion rate by the time we started our work was 0.5, which means cases
    like that were occurring half the time. It’s not that bad but definitely not brilliant.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始工作时，转化率为 0.5，这意味着这种情况发生了一半。这不算太糟糕，但绝对不算出色。
- en: Given the attitude of people to such calls from banks and their desire to hang
    up as soon as possible, broken promises are a very common case. But the fact is,
    it’s a stick with two ends. On the one hand, the client won’t find it pleasant
    to talk to the bank, especially if they did not initiate the conversation. But
    the bank also isn’t interested in futile communication, having to overspend on
    call centers and employees.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到人们对银行此类电话的态度以及他们尽快挂断电话的愿望，违约承诺是一个非常常见的案例。但事实是，这是一个双刃剑。一方面，客户可能不会觉得和银行交谈愉快，尤其是如果他们没有发起对话的话。但银行也对无用的沟通不感兴趣，不得不在呼叫中心和员工身上花费过多的资金。
- en: As a solution, we built a system to predict the probability of clients agreeing
    to make their payment and fulfilling it. And we replaced human calls with text
    messages. This spared us from having to call our customers and talk them into
    making promises. The system was also supposed to predict customer behavior.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 作为解决方案，我们建立了一个系统来预测客户同意支付并履行承诺的概率。我们用短信取代了人工电话。这样我们就不用打电话给我们的客户，说服他们做出承诺。该系统还应该预测客户行为。
- en: At the validation stage, the system showed a conversion rate of 0.9—almost twice
    as high as manual work! Two weeks later and in combat conditions, however, the
    conversion plummeted to 0.35, and we had only a week until making a report to
    our vice president.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证阶段，系统显示的转化率为0.9——几乎是人工操作的近两倍！然而，两周后，在实战条件下，转化率骤降至0.35，而我们只剩下了一周的时间向副总裁提交报告。
- en: 'Something had obviously gone wrong, and we needed to figure out what it was.
    We examined how this metric worked before, and it was pretty simple: if the client
    had promised to pay the debt on a certain day of the month but did not do it within
    3 days, they were marked as debtors. Why was it 3 days? The answer is that the
    gap between an actual operation and getting information about this operation in
    the bank’s database was 3 days.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 显然出了些问题，我们需要找出原因。我们回顾了之前这个指标是如何工作的，它相当简单：如果客户承诺在某个月的一天偿还债务，但3天内没有这样做，他们就会被标记为债务人。为什么是3天？答案是，实际操作与在银行数据库中获得关于此操作信息之间的差距是3天。
- en: Let’s say you are supposed to make your next loan payment by EOD March 1\. At
    the end of the day, March 1, you go to the bank after work and pay the required
    amount. On March 2, a system checks the database and sees that the payment has
    not been made (no wonder, as the information will not reach it until March 4).
    “Looks like we have a delinquent,” the system thinks and initiates a text message
    because, according to the data collected by the system, you have a high probability
    (90%!) of paying the required amount after receiving the message. Later on March
    2, you get a text message from the bank asking you to pay the loan. “They must
    have got something wrong. I’ll let them know I’ve already paid,” you think and
    start filling out the form in the reply message. The problem is that the form
    does not allow you to enter a payment due date earlier than the current date.
    You can only specify that you will pay on March 2 or later. But you already paid
    on March 1\. What do you do? You indicate that you paid on March 2 and submit
    the form. Three days later, the system checks the list of nonpayers, opens your
    profile, and sees that you promised to pay on March 2 but haven’t done that within
    3 days from this date.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你应在3月1日EOD（截至当日）支付下一笔贷款。在3月1日当天工作结束后，你下班后去银行支付所需金额。到了3月2日，系统检查数据库并发现尚未支付（难怪，因为信息要到3月4日才能到达）。系统认为：“看起来我们有逾期未付款项了，”并启动了一条短信，因为根据系统收集的数据，你收到短信后支付所需金额的概率很高（90%！）。3月2日稍后，你收到了银行发来的要求你支付贷款的短信。“他们肯定搞错了。我会告诉他们我已经支付了，”你想，并开始填写回复短信中的表格。问题是，这个表格不允许你输入早于当前日期的还款日期。你只能指定你将在3月2日或之后支付。但你已经在3月1日支付了。你该怎么办？你表明你在3月2日支付了，并提交了表格。三天后，系统检查了非付款者名单，打开你的个人资料，看到你承诺在3月2日支付，但在此日期后的3天内并未支付。
- en: When we reconfigured the system, the conversion rate almost reached the initial
    value, getting as high as 0.8, but the interim problems we faced show how reaching
    your metrics can be hindered by flaws in the overall system behavior.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们重新配置系统时，转化率几乎达到了初始值，高达0.8，但我们在过程中遇到的问题显示了达到你的指标可能会受到整体系统行为缺陷的阻碍。
- en: 'On the surface, a framework for picking the right metric is very straightforward:
    choose the one that is closest to the final goal. However, as the next campfire
    story will show, it might be very tricky to do. You can try either finding that
    metric yourself or using some outside help. The following are some options we
    recommend considering:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 表面上，选择正确指标框架的方法非常直接：选择最接近最终目标的那个。然而，正如接下来的篝火故事将展示的，这可能非常棘手。你可以尝试自己找到这个指标，或者寻求一些外部帮助。以下是我们推荐考虑的一些选项：
- en: If you’re lucky enough to have a hierarchy of metrics, which we will cover later
    on in this chapter, use it to navigate to the metric you need.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你很幸运，有一个指标层级，我们将在本章后面讨论，请使用它来导航到你需要的数据指标。
- en: Some companies have a dedicated department working on metrics; if that is the
    case, use their help.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些公司有一个专门负责指标的部门；如果是这样的话，请使用他们的帮助。
- en: If neither of these two options is the case, you might use product managers
    and data scientists to develop the best metric.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果这两种情况都不适用，你可能需要使用产品经理和数据科学家来开发最佳的指标。
- en: If the problem you’re set to solve is similar to a problem solved before and
    the solution proved to be solid and efficient, it is natural to transfer metrics
    from one project to another with certain modifications, if necessary.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你打算解决的问题类似于以前解决的问题，并且解决方案被证明是稳固和高效的，那么自然地，如果需要，可以从一个项目转移到另一个项目，并对其进行某些修改。
- en: If you have an A/B testing team, they also usually have enough knowledge to
    select or create a metric.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有一个A/B测试团队，他们通常也具备足够的知识来选择或创建一个度量标准。
- en: 'If you don’t have the luxury of having the things mentioned here, you can do
    the following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有这里提到的事情的奢侈，你可以做以下事情：
- en: Refer to the goals section in the design and align with it (it is essential
    to refresh what the end goals are, not how you remembered them). Knowing your
    goals will help you understand which metrics will help you achieve those goals
    or at least help you discard obviously inappropriate metrics.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考设计中的目标部分并与之对齐（重要的是要刷新最终目标是什么，而不是你如何记住它们）。了解你的目标将帮助你理解哪些度量标准将帮助你实现这些目标，或者至少帮助你排除明显不合适的度量标准。
- en: Try to decompose the end goal by writing a map similar to the hierarchy of metrics
    (see section 5.2.2). It will probably take more than one stage to achieve, but
    this kind of exercise will help you break down your big goal into several smaller
    components, each with its own metric. Having many small parts on hand will help
    assemble the greater whole.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试通过编写类似于度量标准层次结构的地图来分解最终目标。这可能需要超过一个阶段才能实现，但这种练习将帮助你将你的大目标分解成几个较小的组成部分，每个部分都有自己的度量标准。拥有许多小部分在手将有助于组装更大的整体。
- en: Find the best metrics describing the success of each stage.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到描述每个阶段成功最佳表现的度量标准。
- en: If something is hard to measure directly, replace it with proxy metrics (see
    section 5.2.2). Proxy metrics will allow you to gather necessary and very important
    information before your system goes into release.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果某些东西难以直接衡量，可以用代理度量标准来代替（参见5.2.2节）。代理度量标准将允许你在系统发布之前收集必要且非常重要的信息。
- en: With this map, pick the metric that either represents the most critical stage
    or summarizes the map in the best possible way.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用这张地图，选择最能代表最关键阶段或以最佳方式总结地图的度量标准。
- en: In the next campfire story, we will review the canonical binary classification
    problem.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个篝火故事中，我们将回顾经典的二元分类问题。
- en: Campfire story from Valerii
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Valerii的篝火故事
- en: Recently, I had a conversation with a friend of mine regarding the evaluation
    of fraud models. Fraud models usually try to solve binary classification tasks
    where 0 is nonfraud and 1 is fraud.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我和我的一个朋友就欺诈模型的评估进行了交谈。欺诈模型通常试图解决二元分类任务，其中0表示非欺诈，1表示欺诈。
- en: No metric is ideal, and it always depends on the final goal. However, when we
    speak about fraud models, we usually want to maintain a ratio of fraud to legit
    transactions of some level. If we had 10 times more transactions, it would be
    okay to have 10 times more fraud, but not 20 or 30 times more. In other words,
    we want to have a probabilistic model.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 没有度量标准是理想的，这总是取决于最终目标。然而，当我们谈论欺诈模型时，我们通常希望保持欺诈交易与合法交易的一定比例。如果我们有10倍多的交易，那么有10倍多的欺诈是可以接受的，但不是20倍或30倍。换句话说，我们希望有一个概率模型。
- en: Also, fraud usually belongs to the class imbalance problem, and that balance
    is not stable through time. One day the ratio can be 1:100 (outburst of fraudulent
    transactions), the next day, 1:1000 (an ordinary day), and the day after, 1:10,000
    (fraudsters took a vacation).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，欺诈通常属于类别不平衡问题，而且这种平衡在时间上是不稳定的。有一天比率可能是1:100（欺诈交易激增），第二天，1:1000（普通一天），第三天，1:10,000（欺诈者休假了）。
- en: The most popular set of metrics for this family of models is precision and recall,
    which may not be the best choice.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型族最流行的度量标准集是精确度和召回率，这可能不是最佳选择。
- en: 'The problem with precision is that its calculations take both classes into
    account:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度的问题在于其计算同时考虑了两个类别：
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-0x.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![侧边栏图像](../Images/babushkin-ch5-eqs-0x.png)'
- en: Imagine that we have a model that has a probability of 95% to predict that fraud
    is fraud (true positive [TP]) and 5% to predict that nonfraud is fraud (false
    positive [FP]).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个模型，它有95%的概率预测欺诈是欺诈（真阳性[TP]），5%的概率预测非欺诈是欺诈（假阳性[FP]）。
- en: 'Let’s review three scenarios where P is the number of positive samples and
    N is the number of negative samples:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾三个场景，其中P是正样本的数量，N是负样本的数量：
- en: P = 10,000, N = 10,000,
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P = 10,000, N = 10,000，
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-1x.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![sidebar figure](../Images/babushkin-ch5-eqs-1x.png)'
- en: P = 100,000, N = 10,000,
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P = 100,000, N = 10,000,
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-2x.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![sidebar figure](../Images/babushkin-ch5-eqs-2x.png)'
- en: P = 1000, N = 10,000,
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P = 1000, N = 10,000,
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-3x.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![sidebar figure](../Images/babushkin-ch5-eqs-3x.png)'
- en: As you can see, the class balance affected the metric significantly even when
    nothing else changed.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，即使其他什么都没有改变，类别平衡也会对指标产生显著影响。
- en: 'Now let’s take a look at recall (Recall = TP/(TP+FN) = TP/P = True Positive
    Rate [TPR]) and examine the same three scenarios:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看召回率（召回率 = TP/(TP+FN) = TP/P = 真正例率 [TPR]）并检查相同的三个场景：
- en: P = 10,000, N = 10,000,
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P = 10,000, N = 10,000,
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-4bx.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![sidebar figure](../Images/babushkin-ch5-eqs-4bx.png)'
- en: P = 100,000, N = 10,000,
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P = 100,000, N = 10,000,
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-4x.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![sidebar figure](../Images/babushkin-ch5-eqs-4x.png)'
- en: P = 1000, N = 10,000,
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P = 1000, N = 10,000,
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-5x.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![sidebar figure](../Images/babushkin-ch5-eqs-5x.png)'
- en: In this case, the class balance didn’t affect the metric at all.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，类别平衡根本不影响指标。
- en: There is also a metric called specificity that can replace precision:![inline
    figure](../Images/babushkin-ch5-eqs-6x.png)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个称为特异性的指标可以替代精确率：![inline figure](../Images/babushkin-ch5-eqs-6x.png)
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-7x.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![sidebar figure](../Images/babushkin-ch5-eqs-7x.png)'
- en: 'The same three examples show the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的三个例子显示了以下内容：
- en: P = 10,000, N = 10,000,
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P = 10,000, N = 10,000,
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-8x.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![sidebar figure](../Images/babushkin-ch5-eqs-8x.png)'
- en: P = 100,000, N = 10,000,
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P = 100,000, N = 10,000,
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-8x.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![sidebar figure](../Images/babushkin-ch5-eqs-8x.png)'
- en: P = 1000, N = 10,000,
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P = 1000, N = 10,000,
- en: '![sidebar figure](../Images/babushkin-ch5-eqs-8x.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![sidebar figure](../Images/babushkin-ch5-eqs-8x.png)'
- en: Recall and specificity do not change because of class imbalance, as these metrics
    are class-balance insensitive.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 由于类别不平衡，召回率和特异率不会改变，因为这些指标对类别平衡不敏感。
- en: 'Initially, my friend created a notebook ([https://mng.bz/5Ov8](https://mng.bz/5Ov8))
    to prove me wrong. The following code demonstrates his train of thought:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我的朋友创建了一个笔记本([https://mng.bz/5Ov8](https://mng.bz/5Ov8))来证明我是错的。以下代码展示了他的思路：
- en: '[PRE2]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'He devised two models with the following metrics:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 他设计了两个具有以下指标的模型：
- en: A has 20 false positives, and 80% of the fraud is caught.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A有20个误报，并且80%的欺诈被捕获。
- en: B has 920 false positives, and 80% of the fraud is caught.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B有920个误报，并且80%的欺诈被捕获。
- en: 'Then he tried his two models in three scenarios with different numbers of transactions
    and fraud cases. In scenario 1, the number of transactions was 100,000\. Overall,
    there were 100 fraud cases, so the class balance was 1:1,000:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 然后他在三个不同交易数量和欺诈案件数量的场景中尝试了他的两个模型。在场景1中，交易数量为100,000。总体来说，有100起欺诈案件，因此类别平衡为1:1,000：
- en: '[PRE3]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In scenario 2, he used the same metrics as in scenario 1\. The number of transactions
    was 100,000\. Overall, there were 10 fraud cases, so the class balance was 1:10,000:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在场景2中，他使用了与场景1相同的指标。交易数量为100,000。总体来说，有10起欺诈案件，因此类别平衡为1:10,000：
- en: '[PRE4]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In scenario 3, he again used the same metrics and 100,000 transactions. Overall,
    there were 1,000 fraud cases, so the class balance was 1:100:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在场景3中，他又使用了相同的指标和100,000笔交易。总体来说，有1,000起欺诈案件，因此类别平衡为1:100：
- en: '[PRE5]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Model A is better according to both the receiver operating characteristic area
    under the curve (ROC AUC) and precision-recall AUC (PR AUC) metrics. Model B is
    a bad model but still gets a very good FPR (0.0092), even though, if it were put
    into production, the predictions would be rubbish (920 out of 1,000 fraud predictions
    would be incorrect). Precision allows us to see this. It’s just 0.08 for model
    B, so we’d never even think about putting it close to production.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 根据接收者操作特征曲线下面积（ROC AUC）和精确率-召回率AUC（PR AUC）指标，模型A表现更好。模型B是一个糟糕的模型，但仍然得到了一个非常好的FPR（0.0092），即使如果将其投入生产，预测结果将是垃圾（1000个欺诈预测中有920个是错误的）。精确率使我们能够看到这一点。对于模型B来说，它只有0.08，所以我们永远不会考虑将其接近生产环境。
- en: What is the fallacy here?
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的谬误是什么？
- en: First, model B has an FPR of 0.0092, which is 46 times higher than model A,
    with its FPR of 0.0002\. There is no good or bad FPR. It depends on your volume,
    and even a slight difference might turn out to be huge. For example, 0.99 has
    a 10 times higher case ratio than 0.999 (1:100 vs. 1:1000).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，模型B的FPR为0.0092，是模型A的FPR（0.0002）的46倍。没有好的或坏的FPR。它取决于你的量级，即使是微小的差异也可能变得很大。例如，0.99的案例比率比0.999（1:100与1:1000）高10倍。
- en: But even in the notebook example, while precision is only 10 times worse, the
    FPR of model B is 46 times worse; it’s hard to call this a very good FPR.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 但即使在笔记本示例中，虽然精确率只有10倍糟糕，模型B的FPR却糟糕了46倍；这很难称得上是一个非常好的FPR。
- en: As you can see from the previous calculations and the notebook, precision shows
    a very different number when there is a shift in class balance, even when the
    model’s performance stays the same. In contrast, both TPR and FPR remain unchanged.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从前面的计算和笔记本中看到的那样，当类别平衡发生变化时，精确率会显示一个非常不同的数字，即使模型的性能保持不变。相比之下，TPR和FPR保持不变。
- en: How do we combine this information and apply it to pick proper metrics?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何结合这些信息并将其应用于选择合适的指标？
- en: In one of the companies we worked for, we had a goal to reduce spam and fraudulent
    behavior with more than 100,000,000,000 events per day. We set specificity to
    be at least 0.999999 (Specificity = TNR = 1 – FPR [in other words, we were okay
    to have one false positive per 1 million events]) and maximized recall (TPR) at
    that specificity rate. This proved to be more beneficial than using a standard
    recall-precision pair, given the volatile nature of underlying data.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们服务的一家公司中，我们的目标是每天处理超过1000亿个事件以减少垃圾邮件和欺诈行为。我们将特异性设置为至少0.999999（特异性 = TNR =
    1 – FPR，换句话说，我们对于每100万个事件中有一个误报是可以接受的）并在此特异性率下最大化召回率（TPR）。这证明比使用标准的召回率-精确率对更有益，考虑到底层数据的波动性。
- en: Some cases, however, force you to improvise in order to find the metric that
    will be able to obtain a required behavior pattern from your system.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有些情况迫使你必须即兴发挥，以找到能够从你的系统中获得所需行为模式的指标。
- en: Campfire story from Arseny
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 阿尔谢尼的篝火故事
- en: 'I worked for a manufacturing optimization company and needed to improve a defect
    in its detection system, but in the midst of the process, another problem emerged:
    the metrics were not sensitive enough. The datasets required for running the planned
    scenario were too small—only 10 to 20 defective samples per customer product.
    And we couldn’t get any more data because there were simply no more existing defective
    units. The defect ratio was just too low, thanks to the high engineering quality.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾为一家制造优化公司工作，需要改进其检测系统中的缺陷，但在过程中，另一个问题出现了：指标不够敏感。运行计划场景所需的数据集太小——每个客户产品只有10到20个有缺陷的样本。而且我们无法获取更多数据，因为根本不存在更多的现有有缺陷单元。缺陷率太低，多亏了高工程品质。
- en: 'Besides the dataset size, our customers weren’t interested in intermediate
    results (e.g., how calibrated the defect probability of our model was). Their
    judgment was very straightforward. For the sake of simplicity, let me frame it
    like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据集大小外，我们的客户对中间结果不感兴趣（例如，我们的模型中缺陷概率的校准程度如何）。他们的判断非常直接。为了简单起见，让我这样描述：
- en: There are 10 defective units and N regular units.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有10个有缺陷的单元和N个常规单元。
- en: An ideal scenario is to have 0 errors.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理想的情况是没有任何错误。
- en: 1 false positive or 1 false negative is good enough.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1个误报或1个漏报已经足够好。
- en: Otherwise, the system is unusable.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，系统将无法使用。
- en: 'Most of my attempts to improve the system as is were fruitless, until at some
    point I decided to design a custom continuous metric that utilized the internal
    metrics and had reasonable thresholds. The metric appeared very discrete:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我尝试改进现有系统的多数努力都徒劳无功，直到某个时刻我决定设计一个定制的连续指标，该指标利用了内部指标并设置了合理的阈值。这个指标看起来非常离散：
- en: “0” would mean “perfect system.”
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “0”意味着“完美的系统”。
- en: “1” would be “good enough.”
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “1”代表“足够好”。
- en: “2” would stand for “garbage.”
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “2”代表“垃圾”。
- en: With this metric in place, I was able to start improving the system gradually,
    step by step, while being confident that I was moving in the right direction.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个指标到位后，我能够逐步、逐步地改进系统，同时有信心我在正确的方向上前进。
- en: After a series of minor improvements, the cumulative effect transformed the
    system from “garbage” to “good enough” and from “good enough” to “perfect” for
    multiple customers.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一系列的小幅改进，累积效应将系统从“垃圾”转变为“足够好”，再从“足够好”转变为对多个客户来说的“完美”。
- en: One important factor in the success of your ML system will always be its consistency.
    To achieve this, there is a separate category of metrics, which we cover in the
    following section.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的机器学习系统成功中，一个重要因素始终是其一致性。为了实现这一点，存在一个单独的指标类别，我们将在下一节中介绍。
- en: 5.2.1 Consistency metrics
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 一致性指标
- en: In applied ML, a model that has a consistent output when presented with slightly
    perturbed inputs is often desired. This property, known in different subfields
    as consistency, robustness, stability, or smoothness, can be formally defined
    as the requirement that the model be invariant under certain transformations,
    such that the difference between the model’s output on the original input and
    the model’s output on the perturbed input tends toward zero. In other words, we
    can express this property mathematically as
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用ML中，当模型面对略微干扰的输入时，通常希望模型有一致的输出。这个属性在不同的子领域中被称为一致性、鲁棒性、稳定性或平滑性，可以形式化地定义为模型在特定变换下不变的要求，即模型在原始输入和干扰输入上的输出差异趋向于零。换句话说，我们可以将这个属性数学上表达为
- en: '![figure](../Images/babushkin-ch5-eqs-9x.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/babushkin-ch5-eqs-9x.png)'
- en: where *f* represents the model, *x* represents the original input, and *eps*
    represents the perturbation applied to the input. Consistency metrics are not
    commonly discussed in academic ML but are an important consideration in practical
    applications where small changes to the input can have significant effects on
    the model’s output from the product perspective.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *f* 代表模型，*x* 代表原始输入，而 *eps* 代表应用于输入的干扰。一致性指标在学术ML中通常不常讨论，但在实际应用中，输入的微小变化可能会对模型输出产生重大影响，因此这是一个重要的考虑因素。
- en: Perturbations can be different. For example, for a solid computer vision model,
    a minor change of lighting usually should not change model outputs, or a sentiment
    analysis model should not be sensitive to changing words with synonyms. We will
    talk about such perturbations and invariants in more detail later, when discussing
    ML system testing in chapter 10.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 干扰可能不同。例如，对于一个固态计算机视觉模型，轻微的光照变化通常不应该改变模型输出，或者情感分析模型不应该对同义词的变化敏感。我们将在第10章讨论ML系统测试时，更详细地讨论这类干扰和不变性。
- en: 'There’s another similar property: when the model is retrained (e.g., with the
    addition of new data or even with other seeds), we expect it to produce the same
    or close outputs, given that inputs remain unchanged. For an antifraud system,
    it is not acceptable if the same user is considered fraudulent today, legitimate
    tomorrow, and a fraudster again next week:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 另有一个类似的属性：当模型重新训练（例如，通过添加新数据或使用其他种子）时，我们期望它在输入保持不变的情况下产生相同或接近的输出。对于一个反欺诈系统，如果同一个用户今天被认为是欺诈者，明天是合法用户，下周又再次被认为是欺诈者，这是不可接受的：
- en: '![figure](../Images/babushkin-ch5-eqs-10x.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/babushkin-ch5-eqs-10x.png)'
- en: When the model outputs are different over time, the release of a new model (which
    should be a routine procedure for most ML systems) may affect the downstream system
    or end users of the system, disturbing their common usage scenarios. People rarely
    like unexpected changes in their tools and environment.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型输出随时间变化时，新模型的发布（对于大多数ML系统来说应该是一个常规程序）可能会影响下游系统或系统的最终用户，扰乱他们的常见使用场景。人们很少喜欢工具和环境中的意外变化。
- en: Such properties can be as important as default features we expect from a model
    (such as accurate predictions) because they shape expectations. As we discussed
    in earlier chapters, if a model can’t be trusted, its utility is reduced. Thus,
    we need specific metrics to measure this kind of behavior.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这些属性可能和我们对模型期望的默认特征（如准确的预测）一样重要，因为它们塑造了期望。正如我们在前面的章节中讨论的，如果一个模型不可信，它的效用就会降低。因此，我们需要特定的指标来衡量这种行为。
- en: 'Luckily, we formulated these properties strictly enough, so the biggest open
    question left is to estimate a proper type of noise or perturbation for the preceding
    formulas: what are the invariants, and how are the conditions expected to change
    over time?'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们把这些属性严格地表述出来，所以剩下的最大未解问题是估计前述公式中适当的噪声或干扰类型：什么是不变性，以及预期的条件如何随时间变化？
- en: With these estimations in place, you can attach your regular metrics to estimate
    consistency. For example, for the search engine example (Photostock Inc.), we
    don’t want a document to change its rank for some query between releases of your
    system, and so the consistency metric could be a variance of ranks for the pair
    (query, document) over some time over corpora of documents and queries. Obviously,
    the less the variance is, the better it is for the system. Still, you can’t forget
    about ill-posed situations—say, a dummy constant model tends to provide the lowest
    variance, but that’s not the consistency ML engineers usually hunt for.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些估计到位后，你可以将常规度量标准附加到估计一致性上。例如，对于搜索引擎示例（Photostock Inc.），我们不希望文档在系统发布之间因某些查询而改变其排名，因此一致性度量标准可以是（查询，文档）对在一段时间内文档和查询语料库中的排名方差。显然，方差越小，对系统越好。然而，你也不能忘记处理不明确的情况——比如说，一个虚拟常数模型往往提供最低的方差，但这并不是机器学习工程师通常追求的一致性。
- en: Consistency is often an important property of an ML system (see figure 5.5).
    If it’s the case for your system, consider adding a metric reflecting how your
    system responds to the changes to input data, training data, or training procedure
    tweaks.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性通常是机器学习系统的一个重要属性（见图5.5）。如果你的系统是这样，考虑添加一个度量标准，反映你的系统如何对输入数据、训练数据或训练过程调整的变化做出响应。
- en: '![figure](../Images/CH05_F05_Babushkin.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F05_Babushkin.png)'
- en: Figure 5.5 New model releases are fairly consistent when estimating the probability
    (P) of the user (U) being fraudulent (F).
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.5 新模型发布在估计用户（U）欺诈（F）的概率（P）时相当一致。
- en: Eventually, you will be able to form a single metrics system based on a clear
    hierarchy of offline and online metrics.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，你将能够基于清晰的离线和在线度量标准层次结构形成一个单一的度量系统。
- en: 5.2.2 Offline and online metrics, proxy metrics, and hierarchy of metrics
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 离线和在线度量标准、代理度量标准和度量标准层次结构
- en: Setting and improving appropriate metrics is an important step in building an
    efficient ML system. But even that is not our end goal, as we have to go one level
    deeper into the rabbit hole. When we had a plan to reduce spam and fraudulent
    behavior, the goal was not to have the highest recall at a given specificity.
    It was to improve the user experience by lowering the number of spam messages
    and making it safer by reducing the risk of fraudulent behavior.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 设置和改进适当的度量标准是构建高效机器学习系统的重要步骤。但即使这样，也不是我们的最终目标，因为我们还需要深入一层。当我们有计划减少垃圾邮件和欺诈行为时，目标并不是在给定的特异性下达到最高的召回率。而是通过减少垃圾邮件的数量，降低欺诈行为的风险，从而改善用户体验。
- en: In the Supermegaretail case, the goal was to reduce losses due to out-of-stock
    and overstock situations, which can be expressed in cash equivalent, but not mean
    absolute error (MAE), mean square error (MSE), weighted mean absolute percentage
    error (wMAPE), weighted absolute percentage error (WAPE), or any other metric.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在Supermegaretail案例中，目标是减少因缺货和过剩情况导致的损失，这可以用现金等价物来表示，但不能用绝对误差（MAE）、均方误差（MSE）、加权平均绝对百分比误差（wMAPE）、加权绝对百分比误差（WAPE）或其他任何度量标准来表示。
- en: In other words, the metric we used to assess the model during the training/testing/validation
    stages and the final metrics are rarely the same (see table 5.1).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们在训练/测试/验证阶段以及最终评估模型时使用的度量标准通常并不相同（见表5.1）。
- en: The previously discussed set is also called *offline metrics* because we can
    apply and calculate them without deploying the model into production. In contrast,
    some metrics, usually our goal metrics, can be calculated only after implementing
    the system and using its output in the business. And although sometimes offline
    and online metrics might coincide, we still have to assess them differently. The
    most common way to evaluate online metrics (change/improvement) is through A/B
    testing.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 之前讨论的集合也被称为*离线度量标准*，因为我们可以在不将模型部署到生产环境中时应用和计算它们。相比之下，一些度量标准，通常是我们的目标度量标准，只能在实施系统并使用其业务输出后才能计算。尽管有时离线和在线度量标准可能一致，但我们仍然必须分别评估它们。评估在线度量标准（变化/改进）的最常见方式是通过A/B测试。
- en: 'We use offline metrics for a simple reason: we can use them before deploying
    the system. This method is quick and reproducible, and it doesn’t require an expensive
    model deployment process. Offline metrics must have one quality: they must be
    a good predictor of online metrics. In other words, an increase or decrease in
    offline metrics has to be either strongly correlated or proportional to an increase/decrease
    in online metrics. Offline metrics play the role of proxy metrics for online metrics
    and can be used as efficient predictors of online metrics.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用离线指标的原因很简单：我们可以在部署系统之前使用它们。这种方法快速且可重复，而且不需要昂贵的模型部署过程。离线指标必须具备一个特点：它们必须是对在线指标的良好预测器。换句话说，离线指标的增加或减少必须与在线指标的增加/减少有强烈的关联性或成比例。离线指标充当在线指标的代理指标，可以用作在线指标的效率预测器。
- en: Table 5.1 Examples of offline and online metrics
  id: totrans-169
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.1 离线和在线指标示例
- en: '| Offline metrics | Online metrics |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 离线指标 | 在线指标 |'
- en: '| --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Recall at given specificity for spam message classification  | Number of
    user complaints about spam messages  |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 对于垃圾邮件消息分类的给定特定性召回率 | 用户对垃圾邮件消息的投诉数量 |'
- en: '| Quantiles of 1.5, 25, 50, 75, 95, and 99  | Value of expired items, total
    sales  |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 1.5、25、50、75、95和99的百分位数 | 过期商品的价值，总销售额 |'
- en: '| Mean reciprocal rank, normalized discounted cumulative gain  | Click-through
    rate on search engine result page  |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 均值倒数排名，归一化折现累积增益 | 搜索引擎结果页面的点击率 |'
- en: But if we can find offline metrics that are strongly correlated with our online
    metrics with the improvement being transitive, we can do the same for offline
    metrics. Let’s use an example to review this.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们能找到与我们的在线指标有强烈关联且改进具有传递性的离线指标，我们也可以对离线指标做同样的事情。让我们用一个例子来回顾这一点。
- en: Imagine that we are building a recommender system for an eCommerce website.
    Our final goal is to increase gross merchandise value (GMV; this is a metric that
    measures the total value of sales over a given period). Unfortunately, as mentioned
    already, this is not something we can measure until we deploy our system into
    production and run A/B tests. We believe that increasing the number of items purchased
    will increase GMV. To achieve that, we want to increase the conversion rate by
    providing users with an offer that has a higher chance of being purchased (assuming
    this will increase the overall number of purchased items).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们正在为一家电子商务网站构建一个推荐系统。我们的最终目标是增加总商品交易额（GMV；这是一个衡量给定期间内销售总价值的指标）。不幸的是，正如之前提到的，这并不是我们可以在将系统部署到生产环境中并运行A/B测试之前测量的东西。我们相信，增加购买商品的数量将增加GMV。为了实现这一点，我们希望通过提供有更高购买可能性的优惠来提高转化率（假设这将增加购买商品的总数量）。
- en: 'On average, 3% of offers end up being clicked, and 3% of those lead to a purchase:
    3% times 3% means that if we show 10,000 offers, only 9 will lead to a purchase.
    This has two adverse, interconnected consequences:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 平均而言，3%的优惠被点击，其中3%导致购买：3%乘以3%意味着如果我们展示10,000个优惠，只有9个会导致购买。这有两个相互关联的负面影响：
- en: Low amount of class 1 data (purchase), huge class imbalance
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类1数据（购买）数量少，类别不平衡严重
- en: Increased A/B test duration
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加A/B测试的持续时间
- en: For example, for A/B tests with a 9/10,000 ratio of success to attempts, we
    would need 100 times more data than for the 90/10,000 ratio (quadratic dependency
    between a minimum detectable effect and a number of samples; please see the following
    for an example).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于成功率与尝试次数比为9/10,000的A/B测试，我们需要比90/10,000的比率多100倍的数据（最小可检测效应与样本数量之间的二次依赖性；请参阅以下示例）。
- en: 'To mitigate that, we can use a proxy metric, click-through rate (CTR), with
    the following context in mind:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻这种情况，我们可以使用一个代理指标，点击率（CTR），同时考虑到以下背景：
- en: No purchase can be made without a click. We can expect a positive correlation
    between the CTRs and conversion rates (CRs) and even calculate it.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有点击就无法进行购买。我们可以预期CTR（点击率）与CR（转化率）之间存在正相关，甚至可以计算出它。
- en: There are 33.3 times more clicks than purchases, meaning that we will have 33.3
    times more training data for class 1 of the system, and A/B tests will become
    1,111 (33.(3)^2) times faster. (To be precise, we can expect that variance will
    change as well, as ![equation image](../Images/eq-chapter-5-173-1.png), so with
    ![equation image](../Images/eq-chapter-5-173-2.png), var = 0.000899 and with ![equation
    image](../Images/eq-chapter-5-173-3.png), var = 0.0291, meaning that overall we
    will increase the speed of convergence by ![equation image](../Images/eq-chapter-5-173-4.png)
    times.)
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击次数比购买次数多33.3倍，这意味着我们将有33.3倍的训练数据用于系统的第1类，A/B测试将快1,111（33.3^2）倍。（为了精确起见，我们可以预期方差也会发生变化，如![equation
    image](../Images/eq-chapter-5-173-1.png)，所以根据![equation image](../Images/eq-chapter-5-173-2.png)，var
    = 0.000899，根据![equation image](../Images/eq-chapter-5-173-3.png)，var = 0.0291，这意味着总体上我们将通过![equation
    image](../Images/eq-chapter-5-173-4.png)倍增加收敛速度。）
- en: Using CTR instead of CR helps us iterate faster and with higher sensitivity,
    both offline (estimating metrics and loss is easier with more data for the class
    of interest) and online (at least partly through A/B testing).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CTR而不是CR可以帮助我们更快、更敏感地迭代，无论是在离线（对于感兴趣类别的数据，估计指标和损失更容易）还是在在线（至少部分通过A/B测试）。
- en: 'We can represent this in the following relation:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用以下关系表示：
- en: CTR → CR → (overall number of purchased items) → GMV
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CTR → CR →（购买物品的总数）→ GMV
- en: 'We can further generalize this by building a hierarchy of metrics:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过构建一组指标层次结构进一步概括：
- en: The global, company-wide metric is revenue.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 全局、公司范围内的指标是收入。
- en: Global revenue (GMV) is composed of the revenue from different products, including
    the product we are responsible for.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 全球收入（GMV）由不同产品的收入组成，包括我们负责的产品。
- en: Our product revenue is affected by
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的产品收入受以下因素影响
- en: Average purchase price
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均购买价格
- en: Purchase frequency
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 购买频率
- en: Number of users (they are interconnected and have mutual influence, thus dotted
    lines)
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户数量（它们相互关联并相互影响，因此用虚线表示）
- en: Purchase frequency is affected by CR.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 购买频率受CR影响。
- en: The conversion rate is affected by CTR.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转化率受CTR影响。
- en: A hierarchy of metrics (see figure 5.6) facilitates finding proper proxy metrics.
    Even though creating it lies outside the scope of designing an ML system, it will
    be handy to have one in place and refer to it during the design process. Using
    a common ground helps prove the choice and reduces the risk of failure.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一组指标层次结构（见图5.6）有助于找到合适的代理指标。尽管创建它超出了设计机器学习系统的范围，但在设计过程中拥有一个现成的指标体系并参考它将非常方便。使用共同的基础有助于证明选择并降低失败的风险。
- en: '![figure](../Images/CH05_F06_Babushkin.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F06_Babushkin.png)'
- en: Figure 5.6 Hierarchy of metrics
  id: totrans-198
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.6 指标层次结构
- en: 'A hierarchy of metrics is especially important when the system gets mature
    enough so that some metrics can be contradictory. A friend of ours once told us
    a short anecdote about building a recommendation system: a variant that demonstrated
    higher engagement by internal users (they preferred new recommendations over previous
    versions) appeared to be way less profitable on a wider audience.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当系统足够成熟，以至于某些指标可能相互矛盾时，一组指标层次结构尤为重要。我们的一位朋友曾经告诉我们一个关于构建推荐系统的简短轶事：一个内部用户参与度更高的变体（他们更喜欢新推荐而不是旧版本）在更广泛的受众中似乎利润较低。
- en: A hierarchy of metrics and proxy metrics concepts are connected to the multicomponent
    losses we discussed earlier. For example, when building this recommender engine
    for Supermegaretail, we can tailor a specific loss function that will consider
    multiple levels of user activity (clicks, purchases, total amount of purchased
    items) and balance our interest between metrics.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 一组指标和代理指标的概念与我们之前讨论的多组件损失相关。例如，当为Supermegaretail构建这个推荐引擎时，我们可以定制一个特定的损失函数，该函数将考虑多个级别的用户活动（点击、购买、购买物品的总数）并在指标之间平衡我们的利益。
- en: Campfire story from Arseny
  id: totrans-201
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 来自阿列克谢的篝火故事
- en: Once I worked on a brand-new product feature based on computer vision. The proposed
    solution was broken down into components, with each component and subcomponent
    carefully annotated with metrics. Due to the innovative nature of the feature,
    the metrics were custom—mostly ratios between various possible outcomes. We designed
    the metrics hierarchy in collaboration with a product executive. After several
    experiments aimed at moving the needle for one of the metrics, I developed a gut
    feeling that it was imbalanced. To test this, I ran an adversarial experiment
    by replacing the model predictions with random noise generated with specific parameters.
    Surprisingly, the random model scored perfectly! The metric was originally designed
    to favor recall over precision, but such an extreme imbalance was clearly not
    desirable, so we had to redesign it as soon as possible.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我曾基于计算机视觉开发了一个全新的产品功能。提出的解决方案被分解为组件，每个组件和子组件都仔细标注了指标。由于该功能的创新性，指标是定制的——主要是各种可能结果之间的比率。我们与产品高管合作设计了指标层次结构。在针对一个指标进行多次实验以推动其进展后，我产生了直觉，认为它是不平衡的。为了测试这一点，我通过用具有特定参数生成的随机噪声替换模型预测来运行了一个对抗性实验。令人惊讶的是，随机模型得分完美！该指标最初是为了在召回率和精确率之间进行权衡而设计的，但如此极端的不平衡显然是不理想的，因此我们必须尽快重新设计它。
- en: '5.3 Design document: Adding losses and metrics'
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 设计文档：添加损失和指标
- en: 'Starting in chapter 4, we began to introduce design documents for two fictional
    cases: Supermegaretail and PhotoStock Inc. Here we continue to elaborate on the
    development of ML solutions for each case and cover the selection of loss functions
    and losses. We start with Supermegaretail followed by PhotoStock Inc.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 从第四章开始，我们开始介绍两个虚构案例的设计文档：Supermegaretail和PhotoStock Inc. 在这里，我们继续详细阐述每个案例的机器学习解决方案的开发，并涵盖损失函数和损失的选择。我们首先介绍Supermegaretail，然后是PhotoStock
    Inc.
- en: 5.3.1 Metrics and loss functions for Supermegaretail
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 Supermegaretail的指标和损失函数
- en: Let’s refresh our memory on the Supermegaretail case. There, we were to reduce
    the gap between delivered and sold items, making it as narrow as possible while
    avoiding an out-of-stock situation with a specific service-level agreement (SLA)
    to be specified further.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重温一下Supermegaretail案例。在那里，我们的目标是减少交付和销售物品之间的差距，使其尽可能小，同时避免因特定的服务等级协议（SLA）而出现缺货情况。
- en: 'Design document: Supermegaretail'
  id: totrans-207
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设计文档：Supermegaretail
- en: II. Metrics and losses
  id: totrans-208
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II. 指标和损失
- en: i. Metrics
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: i. 指标
- en: Before picking up a metric on our own, it makes sense to do some preliminary
    research. Fortunately, there are many papers related to this problem, but the
    one that stands out is “Evaluating Predictive Count Data Distributions in Retail
    Sales Forecasting” by Stephen Kolassa ([https://mng.bz/eVl9](https://mng.bz/eVl9)).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们自行选择指标之前，进行一些初步研究是有意义的。幸运的是，有许多与这个问题相关的论文，但最突出的是Stephen Kolassa的“在零售销售预测中评估预测计数数据分布”([https://mng.bz/eVl9](https://mng.bz/eVl9))。
- en: Let’s recall the project goal, which is to reduce the gap between delivered
    and sold items, making it as narrow as possible while avoiding an out-of-stock
    situation with a specific SLA to be specified further. To do that, we plan to
    forecast the demand for a specific item in a specific store during a particular
    period using an ML system.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下项目目标，即减少交付和销售物品之间的差距，使其尽可能小，同时避免因特定服务等级协议（SLA）而出现缺货情况。为此，我们计划使用机器学习系统来预测特定商店在特定期间内对特定物品的需求。
- en: 'In this case, this paper’s abstract looks like an almost perfect fit:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例中，这篇论文的摘要看起来几乎完美匹配：
- en: 'Massive increases in computing power and new database architectures allow data
    to be stored and processed at increasingly finer granularities, yielding count
    data time series with lower and lower counts. These series can no longer be dealt
    with using approximative methods appropriate for continuous probability distributions.
    In addition, it is not sufficient to calculate point forecasts alone: we need
    to forecast the entire (discrete) predictive distributions, particularly for supply
    chain forecasting and inventory control, but also for other planning processes.'
  id: totrans-213
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 计算能力的巨大提升和新数据库架构使得数据可以以越来越细的粒度存储和处理，从而产生了计数数据时间序列，其计数越来越低。这些序列不能再使用适用于连续概率分布的近似方法来处理。此外，仅仅计算点预测是不够的：我们需要预测整个（离散）预测分布，特别是对于供应链预测和库存控制，但也包括其他规划过程。
- en: (Count data is an integer-valued time series. It is essential for the supply
    chain forecasting we are facing, where most products are sold in units.) With
    that in mind, we can briefly review this paper (within the following lettered
    list) and pick the metrics that are most appropriate for our end goal.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: （计数数据是整数值的时间序列。对于我们所面临的供应链预测来说，这是至关重要的，因为大多数产品都是以单位销售的。）考虑到这一点，我们可以简要回顾这篇论文（以下字母列表中），并挑选出最适合我们最终目标的指标。
- en: A. Measures based on absolute errors
  id: totrans-215
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: A. 基于绝对误差的度量
- en: MAE optimizes the median; the weighted mean absolute percentage error (wMAPE)
    is MAE divided by the mean of the out-of-sample realizations, and the mean absolute
    scaled error is obtained by dividing the MAE by the in-sample MAE of the random
    walk forecast.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: MAE优化了中位数；加权平均绝对百分比误差（wMAPE）是MAE除以样本外实现值的平均值，通过将MAE除以随机游走预测的样本内MAE，可以得到平均绝对缩放误差。
- en: Optimizing for the median does not differ much from optimizing for the mean
    in a symmetric predictive distribution. However, the predictive distributions
    appropriate for low-volume count data are usually far from symmetric, and this
    distinction makes a difference in such cases and yields biased forecasts.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在对称预测分布中，优化中位数与优化均值没有太大区别。然而，适用于低量计数数据的预测分布通常远非对称，这种区别在这种情况下会产生差异，并导致有偏预测。
- en: B. Percentage errors
  id: totrans-218
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: B. 百分比误差
- en: The mean absolute percentage error (MAPE) is undefined if any future realization
    is zero, so it is singularly unsuitable for count data.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任何未来的实现值为零，则平均绝对百分比误差（MAPE）未定义，因此它对于计数数据来说特别不合适。
- en: The symmetric MAPE is a “symmetrized” version of the MAPE, which is defined
    if the point forecasts and actuals are not both zero at all future time points.
    However, in any period with a zero actual, its contribution is 2, regardless of
    the point forecast, making it unsuitable for count data.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 对称的MAPE是对MAPE的“对称化”版本，如果点预测和实际值在所有未来时间点都不是零，则定义。然而，在任何一个实际值为零的时期，无论点预测如何，其贡献都是2，这使得它对于计数数据来说不合适。
- en: C. Measures based on squared errors
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: C. 基于平方误差的度量
- en: Minimizing the squared error leads naturally to an unbiased point forecast.
    However, the MSE is unsuitable for intermittent-demand items because it is sensitive
    to very high forecast errors. The same argument stands for nonintermittent count
    data.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化平方误差自然会引导到无偏的点预测。然而，由于对非常高的预测误差敏感，MSE（均方误差）不适用于间歇性需求项目。同样的论点也适用于非间歇性计数数据。
- en: D. Relative errors
  id: totrans-223
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: D. 相对误差
- en: Prominent variations are the median relative absolute error and the geometric
    mean relative absolute error.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 显著的变化是中位数相对绝对误差和几何平均相对绝对误差。
- en: 'In the specific context of forecasting count data, these suffer from two main
    weaknesses:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测计数数据的特定背景下，这些度量存在两个主要弱点：
- en: Relative errors commonly compare absolute errors. As such, they are subject
    to the same criticism as MAE-based errors, as detailed earlier.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相对误差通常与绝对误差进行比较。因此，它们与基于MAE（平均绝对误差）的误差一样，受到相同的批评，如前所述。
- en: On a period-by-period basis, simple benchmarks such as the naive random walk
    may forecast without errors, and thus, this period’s relative error would be undefined
    because of a division by zero.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个时期的基础上，简单的基准，如简单的随机游走，可能没有错误地预测，因此，这个时期的相对误差由于除以零而未定义。
- en: E. Rate-based errors
  id: totrans-228
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: E. 基于率的误差
- en: 'Kourentzes (2014) recently suggested two new error measures for the intermittent
    demand: MSR and MAR, which aim to assess whether an intermittent demand point
    forecast captures the average demand correctly over an increasing period of time.
    This is an interesting suggestion, but one property of these measures is that
    they implicitly weigh the short-term future more heavily than the mid- to long-term
    future. One could argue that this is exactly what we want to do while forecasting,
    but even then, a case could be made that such weighting should be explicit—by
    using an appropriate weighting scheme when averaging over future time periods.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Kourentzes（2014）最近提出了两种新的间歇性需求误差度量：MSR和MAR，旨在评估间歇性需求点预测是否在增加的时间段内正确地捕捉了平均需求。这是一个有趣的建议，但这些度量中的一个特性是它们隐含地更重视短期未来而不是中到长期未来。有人可能会说，这正是我们在预测时想要做的，但即使如此，也可以提出这样的加权应该明确——通过在平均未来时间期间使用适当的加权方案来实现。
- en: F. Scaled errors
  id: totrans-230
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: F. 缩放误差
- en: Petropoulos and Kourentzes (2015) suggest a scaled version of the MSE, the sMSE,
    which is the mean over squared errors that have been scaled by the squared average
    actuals over the forecast horizon. The sMSE is well-defined unless all actuals
    are zero, is minimized by the expectation of *f,* and, due to the scaling, can
    be compared between different time series. In addition (again because of the scaling),
    it is not quite as sensitive to high-forecast errors as the MSE. Specifically,
    it is more robust to dramatic underforecasts, although it is still sensitive to
    large overforecasts.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Petropoulos和Kourentzes（2015）建议使用MSE的缩放版本，即sMSE，它是通过预测期内的实际值的平方平均值缩放的平方误差的平均值。sMSE除非所有实际值都是零，否则是良好定义的，通过*f*的期望最小化，并且由于缩放，可以比较不同时间序列。此外（同样由于缩放），它对高预测误差的敏感性不如MSE。具体来说，它对剧烈的低预测更为稳健，尽管它对高预测误差仍然敏感。
- en: G. Functionals and loss functions
  id: totrans-232
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: G. 功能和损失函数
- en: An alternative way of looking at forecasts concentrates on point forecasts that
    are functionals of the predictive distribution. One could argue that a retailer
    aims at a certain level of service (say 95%) and that therefore they are only
    interested in the corresponding quantile of the predictive distribution. This
    would then be elicited with appropriate loss functions or scoring rules. This
    approach is closely related to the idea of considering forecasts as part of a
    stock control system. From this perspective, quantile forecasts are used as inputs
    to standard stock control strategies, and the quality of the forecasts is assessed
    by valuing the total stock position over time and weighing it against out-of-stocks.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种看待预测的方法是集中在预测分布的功能性点预测。可以争论说，零售商的目标是达到一定的服务水平（比如说95%），因此他们只对预测分布的相应分位数感兴趣。这可以通过适当的损失函数或评分规则来得出。这种方法与将预测视为库存控制系统一部分的想法密切相关。从这个角度来看，分位数预测被用作标准库存控制策略的输入，预测的质量通过评估随时间变化的库存总价值并权衡缺货来评估。
- en: Though the authors did not see this as the best solution and proposed an alternative,
    the last paragraph of the paper is quite promising. Not only does it make sense
    from a business perspective to predict different quantiles to uphold SLA, but
    it is desirable from the point of view of having the loss function equal to the
    metric. Thus, quantile metrics for quantiles of 1.5, 25, 50, 75, 95, and 99 look
    like a proper choice. Moreover, suppose we need to pay more attention to a specific
    SKU, item group, or cluster. In that case, quantile metrics support the calculation
    of object/group weights (for example, item price).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管作者们认为这不是最佳解决方案并提出了一个替代方案，但论文的最后一段相当有前景。从商业角度来看，预测不同的分位数以维持服务水平协议（SLA）是有意义的，而且从损失函数等于指标的角度来看也是可取的。因此，对于1.5、25、50、75、95和99的分位数，分位数指标看起来是一个合适的选择。此外，如果我们需要更多地关注特定的SKU、商品组或聚类。在这种情况下，分位数指标支持计算对象/组权重（例如，商品价格）。
- en: i.ii. Metrics to pick
  id: totrans-235
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: i.ii. 选择指标
- en: Quantile metrics for quantiles of 1.5, 25, 50, 75, 95, and 99 both as is and
    with weights equal to SKU price and an additional penalty for underforecasting
    or overforecasting if deemed necessary are calculated as point estimates with
    95% confidence intervals (using bootstrap or cross-validation). In addition, we
    can further transform this metric, representing it not as an absolute value but
    as an absolute percentage error at a given quantile. All consideration from the
    Petropoulos and Kourentzes article regarding percentage errors have to be taken
    into account. Ultimately, a set of experiments will help to decide a final form.
    We will probably have both, as it makes sense to check both absolute values in
    money/pcs and percentage error.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 对于1.5、25、50、75、95和99的分位数，以及与SKU价格相等的权重和必要的额外惩罚（如果认为有必要）的分位数指标，都计算为点估计值，并带有95%的置信区间（使用自助法或交叉验证）。此外，我们可以进一步转换这个指标，将其表示为给定分位数的绝对百分比误差。必须考虑Petropoulos和Kourentzes文章中关于百分比误差的所有考虑。最终，一系列实验将有助于决定最终形式。我们可能两者都会使用，因为检查绝对值（金钱/件数）和百分比误差都是有意义的。
- en: Online metrics of interest during A/B test are
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在A/B测试期间感兴趣的在线指标是
- en: Revenue—expected to increase
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收入——预期会增加
- en: Level of stock—expected to decrease or maintain the same
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 库存水平——预期会下降或保持不变
- en: Margin—expected to increase
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利润率——预期会增加
- en: '![figure](../Images/babushkin-ch5-eqs-15x.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/babushkin-ch5-eqs-15x.png)'
- en: Alpha—coefficient used in quantile-based losses
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alpha——用于基于分位数的损失系数
- en: W—Weights
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: W—权重
- en: I—Indicator function
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: I—指示函数
- en: A—Model output
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A—模型输出
- en: T—Label
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T—标签
- en: ii. Loss functions
  id: totrans-247
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ii. 损失函数
- en: With metrics equal to our loss functions, it is straightforward to pick the
    latter. We will train six models using a quantile loss of 1.5, 25, 50, 75, 95,
    and 99, resulting in six different models, providing us with various guarantees
    for the corresponding quantile of the predictive distribution.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 当指标等于我们的损失函数时，选择后者是直接的。我们将使用1.5、25、50、75、95和99的量级损失来训练六个模型，从而产生六个不同的模型，为我们提供对预测分布相应量级的各种保证。
- en: As a second line of experimentation, we will additionally review the Tweedie
    loss function. Tweedie distributions are a family of probability distributions,
    including the purely continuous normal, gamma, and inverse Gaussian distributions;
    the purely discrete scaled Poisson distribution; and the class of compound Poisson–gamma
    distributions that have positive mass at zero but are otherwise continuous. These
    qualities make it an attractive candidate for our Count data.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 作为实验的第二阶段，我们还将审查Tweedie损失函数。Tweedie分布是一族概率分布，包括纯连续的正态分布、伽马分布和逆高斯分布；纯离散的缩放泊松分布；以及具有零点正质量的复合泊松-伽马分布，其他方面都是连续的。这些特性使其成为我们计数数据的理想候选者。
- en: 5.3.2 Metrics and loss functions for PhotoStock Inc.
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 PhotoStock Inc.的指标和损失函数
- en: Next up is the PhotoStock Inc. design document, where a whole different set
    of losses and metrics should be applied based on the nature of the business case
    and the problem to be solved. In the case of PhotoStock Inc., we were hired to
    build a modern search tool that can find the most relevant shots based on customers’
    text queries while providing excellent performance and displaying the most relevant
    images in stock.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是PhotoStock Inc.的设计文档，其中应根据业务案例的性质和要解决的问题应用一套完全不同的损失和指标。在PhotoStock Inc.的情况下，我们被雇佣来构建一个现代搜索工具，该工具可以根据客户的文本查询找到最相关的照片，同时提供卓越的性能并显示最相关的库存图片。
- en: 'Design document: PhotoStock Inc.'
  id: totrans-252
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设计文档：PhotoStock Inc.
- en: II. Metrics and loss functions
  id: totrans-253
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II. 指标和损失函数
- en: i. Metrics
  id: totrans-254
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: i. 指标
- en: 'When choosing metrics for a new PhotoStock search engine, we should keep in
    mind the expected behavior of the system, which includes the following:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择新的PhotoStock搜索引擎的指标时，我们应该记住系统的预期行为，包括以下内容：
- en: Users click on links in search results, with higher results getting more clicks.
    This behavior can be reflected in the CTR metric, which evaluates how many users
    click on search results.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户点击搜索结果中的链接，结果越靠前，点击越多。这种行为可以通过CTR指标反映出来，该指标评估了多少用户点击了搜索结果。
- en: Users purchase images they find via search. This behavior can be reflected in
    the CR metric, which evaluates how many clicks lead to purchase.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户通过搜索购买图片。这种行为可以通过CR指标反映出来，该指标评估了多少点击导致了购买。
- en: Users see diverse suggestions on the search engine result page (SERP). There
    are no ready-to-go solutions here because we don’t have a solid definition of
    diversity. Let’s discuss it later with the UX team. As a baseline, we can use
    the number of different categories of images represented on SERP as a measure
    of diversity. In the future, we should research other companies’ experiences—Airbnb’s
    paper “Learning to Rank Diversely at Airbnb” ([https://arxiv.org/abs/2210.07774](https://arxiv.org/abs/2210.07774)).
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户在搜索引擎结果页面（SERP）上看到各种建议。这里没有现成的解决方案，因为我们没有对多样性有一个明确定义。让我们稍后与用户体验团队讨论这个问题。作为一个基线，我们可以使用在SERP上表示的不同图像类别的数量作为多样性的衡量标准。在未来，我们应该研究其他公司的经验——Airbnb的论文“在Airbnb学习如何进行多样性排序”([https://arxiv.org/abs/2210.07774](https://arxiv.org/abs/2210.07774))。
- en: Search results look reasonable from the human perspective. This behavior can
    be reflected in the metric of human evaluation, which displays how many users
    think that search results are reasonable.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从人类的角度来看，搜索结果看起来是合理的。这种行为可以通过人类评估指标反映出来，该指标显示有多少用户认为搜索结果是合理的。
- en: CTR and CR are online metrics, which means that they can only be measured when
    the system is live. Diversity is an unsupervised offline metric, which means that
    it doesn’t require any additional data and can be measured on a regular basis
    at no cost. Human evaluation, on the other hand, is a supervised offline metric,
    which means that it requires additional data (human evaluation) and thus takes
    time and effort to collect.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 点击率（CTR）和转化率（CR）是在线指标，这意味着它们只能在系统运行时进行测量。多样性是一个无监督的离线指标，这意味着它不需要任何额外的数据，并且可以定期免费测量。另一方面，人工评估是一个监督的离线指标，这意味着它需要额外的数据（人工评估），因此收集数据需要时间和精力。
- en: To introduce offline proxy metrics for CTR and CR, we can use classic metrics
    for ranking problems, such as mean reciprocal rank (MRR) and normalized discounted
    cumulative gain (NDCG). MRR is a metric that calculates the average of the reciprocal
    ranks for a given set of results, which is a measure of the mean of the inverse
    of the rank for the first relevant result. NDCG is a metric that calculates the
    average of discounted cumulative gains (DCGs) for a given set of results, which
    is a measure of the sum of relevance scores taken from the first N results divided
    by the ideal DCG. In its turn, DCG is the sum of relevance scores among the first
    N results in the order of decreasing relevance.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 为了引入CTR和CR的离线代理指标，我们可以使用经典的排序问题指标，如平均倒数排名（MRR）和归一化折现累积增益（NDCG）。MRR是一个计算给定结果集的倒数排名平均值的指标，它是第一个相关结果的排名倒数平均值的一个度量。NDCG是一个计算给定结果集的折现累积增益（DCG）平均值的指标，它是从第一个N个结果中取出的相关性分数的总和除以理想的DCG。而DCG是按照相关性递减的顺序在前N个结果中的相关性分数的总和。
- en: Both MRR and NDCG require a list of relevant results for each query to calculate
    the metrics. We can use the same list of relevant results for both MRR and NDCG,
    but we need to create this list using crowdsourcing to ensure that it is representative
    of the results that users are likely to see. While MRR may be appropriate as an
    offline metric for CTR, it may not be a good proxy for CR because a crowdsourced
    list of relevant results is not representative of the real purchase data. Therefore,
    to accurately measure CR, we should consider using real purchase data. However,
    for the first version of the system, we may only be able to monitor CR online
    using A/B tests and a gradual rollout.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: MRR和NDCG都需要为每个查询提供一个相关结果列表来计算指标。我们可以为MRR和NDCG使用相同的列表，但我们需要通过众包来创建这个列表，以确保它能够代表用户可能看到的结果。虽然MRR可能适合作为CTR的离线指标，但它可能不是CR的良好代理，因为众包的相关结果列表不能代表真实的购买数据。因此，为了准确测量CR，我们应该考虑使用真实的购买数据。然而，对于系统的第一个版本，我们可能只能通过A/B测试和逐步推出在线监控CR。
- en: 'To summarize, here’s how we can divide metrics:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，以下是我们可以如何划分指标的方法：
- en: 'Fast offline metrics: MRR, NDCG, diversity'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速离线指标：MRR、NDCG、多样性
- en: 'Slow offline metrics: human evaluation'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 慢速离线指标：人工评估
- en: 'Online metrics: CTR, CR'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线指标：点击率（CTR）、转化率（CR）
- en: ii. Losses
  id: totrans-267
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ii. 损失
- en: To use loss functions for training a search engine, it is important to consider
    available data and desired outcomes. In this case, the three main aspects we would
    like to optimize for are clicks, purchases, and diversity.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用损失函数来训练搜索引擎，重要的是要考虑可用的数据和期望的结果。在这种情况下，我们希望优化的三个主要方面是点击、购买和多样性。
- en: For the clicks and purchases aspect, we can use binary cross-entropy loss as
    a measure of success. However, it’s important to note that the data for clicks
    and purchases may be imbalanced, meaning that there may be more examples of one
    class than the other. In such cases, it may be beneficial to use a loss function
    that is more robust to class imbalance, such as focal loss or other loss functions
    designed for this purpose.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 对于点击和购买方面，我们可以使用二元交叉熵损失作为成功度的衡量标准。然而，需要注意的是，点击和购买的数据可能存在不平衡，这意味着某一类别的示例可能比另一类多。在这种情况下，使用对类别不平衡更鲁棒的损失函数可能更有益，例如焦点损失或其他为此目的设计的损失函数。
- en: Focal loss is a loss function that was introduced in the paper “Focal Loss for
    Dense Object Detection” ([https://arxiv.org/abs/1708.02002v2](https://arxiv.org/abs/1708.02002v2)).
    It is a generalization of a binary cross-entropy loss commonly used in classification
    tasks. The key difference between a focal loss and a binary cross-entropy loss
    is that focal loss down-weights easy examples, which are those examples that are
    classified correctly with high confidence. This is useful in cases where the data
    is imbalanced, as it helps the model to focus on the hard examples, which are
    typically more important for improving the overall performance of the model, so
    it seems relevant for the PhotoStock search engine.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 焦点损失（Focal Loss）是在论文“Focal Loss for Dense Object Detection”（[https://arxiv.org/abs/1708.02002v2](https://arxiv.org/abs/1708.02002v2)）中提出的一种损失函数。它是分类任务中常用二元交叉熵损失函数的推广。焦点损失与二元交叉熵损失的关键区别在于，焦点损失降低了容易样本的权重，这些样本被以高置信度正确分类。这在数据不平衡的情况下很有用，因为它有助于模型关注困难样本，这些样本通常对提高模型的整体性能更为重要，因此对于PhotoStock搜索引擎来说似乎相关。
- en: As for the diversity aspect, we can add a term to the loss function that penalizes
    the similarity in results. One potential way to do this is to use the entropy
    of the category distribution of the results as a measure of diversity. However,
    this approach may not always be feasible, so the diversity loss should be considered
    optional.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 关于多样性方面，我们可以在损失函数中添加一个惩罚结果相似性的项。一种潜在的方法是使用结果类别分布的熵作为多样性的度量。然而，这种方法可能并不总是可行，因此多样性损失应被视为可选的。
- en: Overall, the final loss function can be written as
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，最终的损失函数可以写成
- en: '![figure](../Images/babushkin-ch5-eqs-16x.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/babushkin-ch5-eqs-16x.png)'
- en: Here, alpha, beta, and gamma are represented as hyperparameters that control
    the relative importance of the three components. These hyperparameters can be
    tuned to find the optimal balance between the three aspects.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，alpha、beta和gamma被表示为超参数，它们控制着三个组件的相对重要性。这些超参数可以被调整以找到三个方面的最佳平衡。
- en: 5.3.3 Wrap up
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.3 总结
- en: The examples from these two design documents show how important it is to choose
    the right metrics and loss functions. Just like any other key element in building
    an ML system, metrics and loss functions should coincide with the goals of your
    project. And if you feel there’s more time needed to define the appropriate parameters,
    please find a few days in your schedule to do it so you don’t have to roll back
    a few miles in a month or more.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个设计文档中的示例展示了选择正确的指标和损失函数有多么重要。就像构建ML系统中的任何其他关键元素一样，指标和损失函数应与你的项目目标相一致。如果你觉得需要更多时间来定义适当的参数，请在你的日程中安排几天时间来做这件事，这样你就不必在一个月或更长时间内退回几步。
- en: The next chapter covers data gathering, datasets, the difference between data
    and metadata, and how to achieve a healthy data pipeline.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章涵盖了数据收集、数据集、数据与元数据之间的区别，以及如何实现健康的数据管道。
- en: Summary
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Don’t fall into the temptation of using time-tested loss functions just because
    they worked on your previous project(s).
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要因为它们在之前的（项目）中有效而陷入使用经过时间考验的损失函数的诱惑。
- en: A loss function must be globally continuous and differentiable.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失函数必须全局连续且可导。
- en: Loss selection is an important step, but it is even more crucial with deep learning-based
    systems.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失函数的选择是一个重要的步骤，但在基于深度学习的系统中，它甚至更为关键。
- en: Consider applying consistency metrics when small changes to the inputs can have
    significant effects on the output of your model from the product perspective.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑在输入的小变化可能对模型输出产生重大影响时应用一致性指标，从产品角度来看。
- en: Offline metrics can be applied before putting your project into production and
    play the role of proxy metrics for online metrics.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在将项目投入生产之前，可以应用离线指标，并充当在线指标的代理指标。
- en: Make sure to have the hierarchy of metrics at hand, as it will be useful while
    working on the design of your system.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保手头有指标层次结构，因为它在系统设计过程中将非常有用。
