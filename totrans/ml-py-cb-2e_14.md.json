["```py\n# Load libraries\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import datasets\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create decision tree classifier object\ndecisiontree = DecisionTreeClassifier(random_state=0)\n\n# Train model\nmodel = decisiontree.fit(features, target)\n```", "```py\n# Make new observation\nobservation = [[ 5,  4,  3,  2]]\n\n# Predict observation's class\nmodel.predict(observation)\n```", "```py\narray([1])\n```", "```py\n# View predicted class probabilities for the three classes\nmodel.predict_proba(observation)\n```", "```py\narray([[0., 1., 0.]])\n```", "```py\n# Create decision tree classifier object using entropy\ndecisiontree_entropy = DecisionTreeClassifier(\n    criterion='entropy', random_state=0)\n\n# Train model\nmodel_entropy = decisiontree_entropy.fit(features, target)\n```", "```py\n# Load libraries\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import datasets\n\n# Load data with only two features\ndiabetes = datasets.load_diabetes()\nfeatures = diabetes.data\ntarget = diabetes.target\n\n# Create decision tree regressor object\ndecisiontree = DecisionTreeRegressor(random_state=0)\n\n# Train model\nmodel = decisiontree.fit(features, target)\n```", "```py\n# Make new observation\nobservation = [features[0]]\n\n# Predict observation's value\nmodel.predict(observation)\n```", "```py\narray([151.])\n```", "```py\n# Create decision tree classifier object using MAE\ndecisiontree_mae = DecisionTreeRegressor(criterion=\"absolute_error\",\n  random_state=0)\n\n# Train model\nmodel_mae = decisiontree_mae.fit(features, target)\n```", "```py\n# Load libraries\nimport pydotplus\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import datasets\nfrom IPython.display import Image\nfrom sklearn import tree\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create decision tree classifier object\ndecisiontree = DecisionTreeClassifier(random_state=0)\n\n# Train model\nmodel = decisiontree.fit(features, target)\n\n# Create DOT data\ndot_data = tree.export_graphviz(decisiontree,\n                                out_file=None,\n                                feature_names=iris.feature_names,\n                                class_names=iris.target_names)\n\n# Draw graph\ngraph = pydotplus.graph_from_dot_data(dot_data)\n\n# Show graph\nImage(graph.create_png())\n```", "```py\n# Create PDF\ngraph.write_pdf(\"iris.pdf\")\n```", "```py\nTrue\n```", "```py\n# Create PNG\ngraph.write_png(\"iris.png\")\n```", "```py\nTrue\n```", "```py\n# Load libraries\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create random forest classifier object\nrandomforest = RandomForestClassifier(random_state=0, n_jobs=-1)\n\n# Train model\nmodel = randomforest.fit(features, target)\n```", "```py\n# Make new observation\nobservation = [[ 5,  4,  3,  2]]\n\n# Predict observation's class\nmodel.predict(observation)\n```", "```py\narray([1])\n```", "```py\n# Create random forest classifier object using entropy\nrandomforest_entropy = RandomForestClassifier(\n    criterion=\"entropy\", random_state=0)\n\n# Train model\nmodel_entropy = randomforest_entropy.fit(features, target)\n```", "```py\n# Load libraries\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import datasets\n\n# Load data with only two features\ndiabetes = datasets.load_diabetes()\nfeatures = diabetes.data\ntarget = diabetes.target\n\n# Create random forest regressor object\nrandomforest = RandomForestRegressor(random_state=0, n_jobs=-1)\n\n# Train model\nmodel = randomforest.fit(features, target)\n```", "```py\n# Load libraries\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create random forest classifier object\nrandomforest = RandomForestClassifier(\n    random_state=0, n_estimators=1000, oob_score=True, n_jobs=-1)\n\n# Train model\nmodel = randomforest.fit(features, target)\n\n# View out-of-bag-error\nrandomforest.oob_score_\n```", "```py\n0.9533333333333334\n```", "```py\n# Load libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create random forest classifier object\nrandomforest = RandomForestClassifier(random_state=0, n_jobs=-1)\n\n# Train model\nmodel = randomforest.fit(features, target)\n\n# Calculate feature importances\nimportances = model.feature_importances_\n\n# Sort feature importances in descending order\nindices = np.argsort(importances)[::-1]\n\n# Rearrange feature names so they match the sorted feature importances\nnames = [iris.feature_names[i] for i in indices]\n\n# Create plot\nplt.figure()\n\n# Create plot title\nplt.title(\"Feature Importance\")\n\n# Add bars\nplt.bar(range(features.shape[1]), importances[indices])\n\n# Add feature names as x-axis labels\nplt.xticks(range(features.shape[1]), names, rotation=90)\n\n# Show plot\nplt.show()\n```", "```py\n# View feature importances\nmodel.feature_importances_\n```", "```py\narray([0.09090795, 0.02453104, 0.46044474, 0.42411627])\n```", "```py\n# Load libraries\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\nfrom sklearn.feature_selection import SelectFromModel\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create random forest classifier\nrandomforest = RandomForestClassifier(random_state=0, n_jobs=-1)\n\n# Create object that selects features with importance greater\n# than or equal to a threshold\nselector = SelectFromModel(randomforest, threshold=0.3)\n\n# Create new feature matrix using selector\nfeatures_important = selector.fit_transform(features, target)\n\n# Train random forest using most important features\nmodel = randomforest.fit(features_important, target)\n```", "```py\n# Load libraries\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Make class highly imbalanced by removing first 40 observations\nfeatures = features[40:,:]\ntarget = target[40:]\n\n# Create target vector indicating if class 0, otherwise 1\ntarget = np.where((target == 0), 0, 1)\n\n# Create random forest classifier object\nrandomforest = RandomForestClassifier(\n    random_state=0, n_jobs=-1, class_weight=\"balanced\")\n\n# Train model\nmodel = randomforest.fit(features, target)\n```", "```py\n# Calculate weight for small class\n110/(2*10)\n```", "```py\n5.5\n```", "```py\n# Calculate weight for large class\n110/(2*100)\n```", "```py\n0.55\n```", "```py\n# Load libraries\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import datasets\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create decision tree classifier object\ndecisiontree = DecisionTreeClassifier(random_state=0,\n                                      max_depth=None,\n                                      min_samples_split=2,\n                                      min_samples_leaf=1,\n                                      min_weight_fraction_leaf=0,\n                                      max_leaf_nodes=None,\n                                      min_impurity_decrease=0)\n\n# Train model\nmodel = decisiontree.fit(features, target)\n```", "```py\n# Load libraries\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn import datasets\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create adaboost tree classifier object\nadaboost = AdaBoostClassifier(random_state=0)\n\n# Train model\nmodel = adaboost.fit(features, target)\n```", "```py\n# Load libraries\nimport xgboost as xgb\nfrom sklearn import datasets, preprocessing\nfrom sklearn.metrics import classification_report\nfrom numpy import argmax\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create dataset\nxgb_train = xgb.DMatrix(features, label=target)\n\n# Define parameters\nparam = {\n    'objective': 'multi:softprob',\n    'num_class': 3\n}\n\n# Train model\ngbm = xgb.train(param, xgb_train)\n\n# Get predictions\npredictions = argmax(gbm.predict(xgb_train), axis=1)\n\n# Get a classification report\nprint(classification_report(target, predictions))\n```", "```py\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        50\n           1       1.00      0.96      0.98        50\n           2       0.96      1.00      0.98        50\n\n    accuracy                           0.99       150\n   macro avg       0.99      0.99      0.99       150\nweighted avg       0.99      0.99      0.99       150\n```", "```py\n# Load libraries\nimport lightgbm as lgb\nfrom sklearn import datasets, preprocessing\nfrom sklearn.metrics import classification_report\nfrom numpy import argmax\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Create dataset\nlgb_train = lgb.Dataset(features, target)\n\n# Define parameters\nparams = {\n    'objective': 'multiclass',\n    'num_class': 3,\n    'verbose': -1,\n}\n\n# Train model\ngbm = lgb.train(params, lgb_train)\n\n# Get predictions\npredictions = argmax(gbm.predict(features), axis=1)\n\n# Get a classification report\nprint(classification_report(target, predictions))\n```", "```py\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        50\n           1       1.00      1.00      1.00        50\n           2       1.00      1.00      1.00        50\n\n    accuracy                           1.00       150\n   macro avg       1.00      1.00      1.00       150\nweighted avg       1.00      1.00      1.00       150\n```"]