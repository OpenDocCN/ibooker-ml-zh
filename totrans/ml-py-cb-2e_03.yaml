- en: Chapter 3\. Data Wrangling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 3.0 Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Data wrangling* is a broad term used, often informally, to describe the process
    of transforming raw data into a clean, organized format ready for use. For us,
    data wrangling is only one step in preprocessing our data, but it is an important
    step.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common data structure used to “wrangle” data is the dataframe, which
    can be both intuitive and incredibly versatile. Dataframes are tabular, meaning
    that they are based on rows and columns like you would see in a spreadsheet. Here
    is a dataframe created from data about passengers on the *Titanic*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29.00 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2.00 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Allison, Mr Hudson Joshua Creighton | 1st | 30.00 | male | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Allison, Mrs Hudson JC (Bessie Waldo Daniels) | 1st | 25.00 | female
    | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Allison, Master Hudson Trevor | 1st | 0.92 | male | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: There are three important things to notice in this dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: First, in a dataframe each row corresponds to one observation (e.g., a passenger)
    and each column corresponds to one feature (gender, age, etc.). For example, by
    looking at the first observation we can see that Miss Elisabeth Walton Allen stayed
    in first class, was 29 years old, was female, and survived the disaster.
  prefs: []
  type: TYPE_NORMAL
- en: Second, each column contains a name (e.g., `Name`, `PClass`, `Age`) and each
    row contains an index number (e.g., `0` for the lucky Miss Elisabeth Walton Allen).
    We will use these to select and manipulate observations and features.
  prefs: []
  type: TYPE_NORMAL
- en: Third, two columns, `Sex` and `SexCode`, contain the same information in different
    formats. In `Sex`, a woman is indicated by the string `female`, while in `SexCode`,
    a woman is indicated by using the integer `1`. We will want all our features to
    be unique, and therefore we will need to remove one of these columns.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will cover a wide variety of techniques to manipulate dataframes
    using the pandas library with the goal of creating a clean, well-structured set
    of observations for further preprocessing.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Creating a Dataframe
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to create a new dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'pandas has many methods for creating a new DataFrame object. One easy method
    is to instantiate a `DataFrame` using a Python dictionary. In the dictionary,
    each key is a column name and the value is a list, where each item corresponds
    to a row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | Age | Driver |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Jacky Jackson | 38 | True |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Steven Stevenson | 25 | False |'
  prefs: []
  type: TYPE_TB
- en: 'It’s easy to add new columns to any dataframe using a list of values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | Age | Driver | Eyes |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Jacky Jackson | 38 | True | Brown |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Steven Stevenson | 25 | False | Blue |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: pandas offers what can feel like an infinite number of ways to create a DataFrame.
    In the real world, creating an empty DataFrame and then populating it will almost
    never happen. Instead, our DataFrames will be created from real data we have loaded
    from other sources (e.g., a CSV file or database).
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Getting Information about the Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to view some characteristics of a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the easiest things we can do after loading the data is view the first
    few rows using `head`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'We can also take a look at the number of rows and columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We can get descriptive statistics for any numeric columns using `describe`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Age | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| count | 756.000000 | 1313.000000 | 1313.000000 |'
  prefs: []
  type: TYPE_TB
- en: '| mean | 30.397989 | 0.342727 | 0.351866 |'
  prefs: []
  type: TYPE_TB
- en: '| std | 14.259049 | 0.474802 | 0.477734 |'
  prefs: []
  type: TYPE_TB
- en: '| min | 0.170000 | 0.000000 | 0.000000 |'
  prefs: []
  type: TYPE_TB
- en: '| 25% | 21.000000 | 0.000000 | 0.000000 |'
  prefs: []
  type: TYPE_TB
- en: '| 50% | 28.000000 | 0.000000 | 0.000000 |'
  prefs: []
  type: TYPE_TB
- en: '| 75% | 39.000000 | 1.000000 | 1.000000 |'
  prefs: []
  type: TYPE_TB
- en: '| max | 71.000000 | 1.000000 | 1.000000 |'
  prefs: []
  type: TYPE_TB
- en: 'Additionally, the `info` method can show some helpful information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After we load some data, it’s a good idea to understand how it’s structured
    and what kind of information it contains. Ideally, we would view the full data
    directly. But with most real-world cases, the data could have thousands to hundreds
    of thousands to millions of rows and columns. Instead, we have to rely on pulling
    samples to view small slices and calculating summary statistics of the data.
  prefs: []
  type: TYPE_NORMAL
- en: In our solution, we are using a toy dataset of the passengers of the *Titanic*.
    Using `head`, we can look at the first few rows (five by default) of the data.
    Alternatively, we can use `tail` to view the last few rows. With `shape` we can
    see how many rows and columns our DataFrame contains. With `describe` we can see
    some basic descriptive statistics for any numerical column. And, finally, `info`
    displays a number of helpful data points about the DataFrame, including index
    and column data types, non-null values, and memory usage.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that summary statistics do not always tell the full story.
    For example, pandas treats the columns `Survived` and `SexCode` as numeric columns
    because they contain 1s and 0s. However, in this case the numerical values represent
    categories. For example, if `Survived` equals 1, it indicates that the passenger
    survived the disaster. For this reason, some of the summary statistics provided
    don’t make sense, such as the standard deviation of the `SexCode` column (an indicator
    of the passenger’s gender).
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Slicing DataFrames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to select a specific subset data or slices of a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use `loc` or `iloc` to select one or more rows or values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use `:` to define the slice of rows we want, such as selecting the second,
    third, and fourth rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Allison, Mr Hudson Joshua Creighton | 1st | 30.0 | male | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Allison, Mrs Hudson JC (Bessie Waldo Daniels) | 1st | 25.0 | female |
    0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'We can even use it to get all rows up to a point, such as all rows up to and
    including the fourth row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Allison, Mr Hudson Joshua Creighton | 1st | 30.0 | male | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Allison, Mrs Hudson JC (Bessie Waldo Daniels) | 1st | 25.0 | female |
    0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'DataFrames do not need to be numerically indexed. We can set the index of a
    DataFrame to any value where the value is unique to each row. For example, we
    can set the index to be passenger names and then select rows using a name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All rows in a pandas DataFrame have a unique index value. By default, this
    index is an integer indicating the row position in the DataFrame; however, it
    does not have to be. DataFrame indexes can be set to be unique alphanumeric strings
    or customer numbers. To select individual rows and slices of rows, pandas provides
    two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`loc` is useful when the index of the DataFrame is a label (e.g., a string).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`iloc` works by looking for the position in the DataFrame. For example, `iloc[0]`
    will return the first row regardless of whether the index is an integer or a label.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is useful to be comfortable with both `loc` and `iloc` since they will come
    up a lot during data cleaning.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Selecting Rows Based on Conditionals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to select DataFrame rows based on some condition.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This can be done easily in pandas. For example, if we wanted to select all
    the women on the *Titanic*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: Take a moment to look at the format of this solution. Our conditional statement
    is `dataframe['Sex'] == 'female'`; by wrapping that in `dataframe[]` we are telling
    pandas to “select all the rows in the DataFrame where the value of `dataframe['Sex']`
    is `'female'`.” These conditions result in a pandas series of booleans.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiple conditions are easy as well. For example, here we select all the rows
    where the passenger is a female 65 or older:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 73 | Crosby, Mrs Edward Gifford (Catherine Elizabet... | 1st | 69.0 | female
    | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Conditionally selecting and filtering data is one of the most common tasks in
    data wrangling. You rarely want all the raw data from the source; instead, you
    are interested in only some subset of it. For example, you might only be interested
    in stores in certain states or the records of patients over a certain age.
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Sorting Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to sort a dataframe by the values in a column.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the pandas `sort_values` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 763 | Dean, Miss Elizabeth Gladys (Millvena) | 3rd | 0.17 | female | 1 |
    1 |'
  prefs: []
  type: TYPE_TB
- en: '| 751 | Danbom, Master Gilbert Sigvard Emanuel | 3rd | 0.33 | male | 0 | 0
    |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: During data analysis and exploration, it’s often useful to sort a DataFrame
    by a particular column or set of columns. The `by` argument to `sort_values` takes
    a list of columns by which to sort the DataFrame and will sort based on the order
    of column names in the list.
  prefs: []
  type: TYPE_NORMAL
- en: By default, the `ascending` argument is set to `True`, so it will sort the values
    lowest to highest. If we wanted the oldest passengers instead of the youngest,
    we could set it to `False`.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Replacing Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to replace values in a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The pandas `replace` method is an easy way to find and replace values. For
    example, we can replace any instance of `"female"` in the `Sex` column with `"Woman"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also replace multiple values at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also find and replace across the entire `DataFrame` object by specifying
    the whole dataframe instead of a single column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29 | female | One | One |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2 | female | 0 | One |'
  prefs: []
  type: TYPE_TB
- en: '`replace` also accepts regular expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | First | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | First | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`replace` is a tool we use to replace values. It is simple and yet has the
    powerful ability to accept regular expressions.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.7 Renaming Columns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to rename a column in a pandas DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Rename columns using the `rename` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | Passenger Class | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'Notice that the `rename` method can accept a dictionary as a parameter. We
    can use the dictionary to change multiple column names at once:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | Passenger Class | Age | Gender | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using `rename` with a dictionary as an argument to the `columns` parameter
    is my preferred way to rename columns because it works with any number of columns.
    If we want to rename all columns at once, this helpful snippet of code creates
    a dictionary with the old column names as keys and empty strings as values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 3.8 Finding the Minimum, Maximum, Sum, Average, and Count
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to find the min, max, sum, average, or count of a numeric column.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'pandas comes with some built-in methods for commonly used descriptive statistics
    such as `min`, `max`, `mean`, `sum`, and `count`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to the statistics used in the solution, pandas offers variance (`var`),
    standard deviation (`std`), kurtosis (`kurt`), skewness (`skew`), standard error
    of the mean (`sem`), mode (`mode`), median (`median`), value counts, and a number
    of others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, we can also apply these methods to the whole DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 3.9 Finding Unique Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to select all unique values in a column.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use `unique` to view an array of all unique values in a column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, `value_counts` will display all unique values with the number
    of times each value appears:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Both `unique` and `value_counts` are useful for manipulating and exploring
    categorical columns. Very often in categorical columns there will be classes that
    need to be handled in the data wrangling phase. For example, in the *Titanic*
    dataset, `PClass` is a column indicating the class of a passenger’s ticket. There
    were three classes on the *Titanic*; however, if we use `value_counts` we can
    see a problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: While almost all passengers belong to one of three classes as expected, a single
    passenger has the class `*`. There are a number of strategies for handling this
    type of issue, which we will address in [Chapter 5](ch05.xhtml#handling-categorical-data),
    but for now just realize that “extra” classes are common in categorical data and
    should not be ignored.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, if we simply want to count the number of unique values, we can use
    `nunique`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 3.10 Handling Missing Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to select missing values in a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`isnull` and `notnull` return booleans indicating whether a value is missing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | Aubert, Mrs Leontine Pauline | 1st | NaN | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | Barkworth, Mr Algernon H | 1st | NaN | male | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Missing values are a ubiquitous problem in data wrangling, yet many underestimate
    the difficulty of working with missing data. pandas uses NumPy’s `NaN` (Not a
    Number) value to denote missing values, but it is important to note that `NaN`
    is not fully implemented natively in pandas. For example, if we wanted to replace
    all strings containing `male` with missing values, we get an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'To have full functionality with `NaN` we need to import the NumPy library first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Oftentimes a dataset uses a specific value to denote a missing observation,
    such as `NONE`, `-999`, or `..`. The pandas `read_csv` function includes a parameter
    allowing us to specify the values used to indicate missing values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: We can also use the pandas `fillna` function to impute the missing values of
    a column. Here, we show the places where `Age` is null using the `isna` function
    and then fill those values with the mean age of passengers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | Aubert, Mrs Leontine Pauline | 1st | NaN | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | Aubert, Mrs Leontine Pauline | 1st | 30.397989 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 3.11 Deleting a Column
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to delete a column from your DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The best way to delete a column is to use `drop` with the parameter `axis=1`
    (i.e., the column axis):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'You can also use a list of column names as the main argument to drop multiple
    columns at once:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'If a column does not have a name (which can sometimes happen), you can drop
    it by its column index using `dataframe.columns`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`drop` is the idiomatic method of deleting a column. An alternative method
    is `del dataframe[''Age'']`, which works most of the time but is not recommended
    because of how it is called within pandas (the details of which are outside the
    scope of this book).'
  prefs: []
  type: TYPE_NORMAL
- en: 'I recommend that you avoid using the pandas `inplace=True` argument. Many pandas
    methods include an `inplace` parameter that, when set to `True`, edits the DataFrame
    directly. This can lead to problems in more complex data processing pipelines
    because we are treating the DataFrames as mutable objects (which they technically
    are). I recommend treating DataFrames as immutable objects. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we are not mutating the DataFrame `dataframe` but instead are
    making a new DataFrame that is an altered version of `dataframe` called `dataframe_name_dropped`.
    If you treat your DataFrames as immutable objects, you will save yourself a lot
    of headaches down the road.
  prefs: []
  type: TYPE_NORMAL
- en: 3.12 Deleting a Row
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to delete one or more rows from a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use a boolean condition to create a new DataFrame excluding the rows you want
    to delete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Allison, Mrs Hudson JC (Bessie Waldo Daniels) | 1st | 25.00 | female
    | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While technically you can use the `drop` method (for example, `dataframe.drop([0,
    1], axis=0)` to drop the first two rows), a more practical method is simply to
    wrap a boolean condition inside `dataframe[]`. This enables us to use the power
    of conditionals to delete either a single row or (far more likely) many rows at
    once.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use boolean conditions to easily delete single rows by matching a unique
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Allison, Mr Hudson Joshua Creighton | 1st | 30.0 | male | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'We can even use it to delete a single row by specifying the row index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Allison, Mr Hudson Joshua Creighton | 1st | 30.0 | male | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 3.13 Dropping Duplicate Rows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to drop duplicate rows from your DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use `drop_duplicates`, but be mindful of the parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Allison, Miss Helen Loraine | 1st | 2.0 | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A keen reader will notice that the solution didn’t actually drop any rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'This is because `drop_duplicates` defaults to dropping only rows that match
    perfectly across all columns. Because every row in our DataFrame is unique, none
    will be dropped. However, often we want to consider only a subset of columns to
    check for duplicate rows. We can accomplish this using the `subset` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Allen, Miss Elisabeth Walton | 1st | 29.0 | female | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Allison, Mr Hudson Joshua Creighton | 1st | 30.0 | male | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'Take a close look at the preceding output: we told `drop_duplicates` to only
    consider any two rows with the same value for `Sex` to be duplicates and to drop
    them. Now we are left with a DataFrame of only two rows: one woman and one man.
    You might be asking why `drop_duplicates` decided to keep these two rows instead
    of two different rows. The answer is that `drop_duplicates` defaults to keeping
    the first occurrence of a duplicated row and dropping the rest. We can control
    this behavior using the `keep` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1307 | Zabour, Miss Tamini | 3rd | NaN | female | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1312 | Zimmerman, Leo | 3rd | 29.0 | male | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'A related method is `duplicated`, which returns a boolean series denoting whether
    a row is a duplicate or not. This is a good option if you don’t want to simply
    drop duplicates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 3.14 Grouping Rows by Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to group individual rows according to some shared value.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`groupby` is one of the most powerful features in pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '| Sex | Age | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| female | 29.396424 | 0.666667 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| male | 31.014338 | 0.166863 | 0.0 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`groupby` is where data wrangling really starts to take shape. It is very common
    to have a DataFrame where each row is a person or an event and we want to group
    them according to some criterion and then calculate a statistic. For example,
    you can imagine a DataFrame where each row is an individual sale at a national
    restaurant chain and we want the total sales per restaurant. We can accomplish
    this by grouping rows by individual restaurants and then calculating the sum of
    each group.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Users new to `groupby` often write a line like this and are confused by what
    is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Why didn’t it return something more useful? The reason is that `groupby` needs
    to be paired with some operation that we want to apply to each group, such as
    calculating an aggregate statistic (e.g., mean, median, sum). When talking about
    grouping we often use shorthand and say “group by gender,” but that is incomplete.
    For grouping to be useful, we need to group by something and then apply a function
    to each of those groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Notice `Name` added after the `groupby`? That is because particular summary
    statistics are meaningful only to certain types of data. For example, while calculating
    the average age by gender makes sense, calculating the total age by gender does
    not. In this case, we group the data into survived or not, and then count the
    number of names (i.e., passengers) in each group.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also group by a first column, then group that grouping by a second column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 3.15 Grouping Rows by Time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to group individual rows by time periods.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use `resample` to group rows by chunks of time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Sale_Amount |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-06-11 | 86423 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-06-18 | 101045 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-06-25 | 100867 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-07-02 | 100894 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-07-09 | 100438 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-07-16 | 10297 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our standard *Titanic* dataset does not contain a datetime column, so for this
    recipe we have generated a simple DataFrame where each row is an individual sale.
    For each sale we know its date and time and its dollar amount (this data isn’t
    realistic because the sales take place precisely 30 seconds apart and are exact
    dollar amounts, but for the sake of simplicity let’s pretend).
  prefs: []
  type: TYPE_NORMAL
- en: 'The raw data looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Sale_Amount |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-06-06 00:00:00 | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-06-06 00:00:30 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-06-06 00:01:00 | 7 |'
  prefs: []
  type: TYPE_TB
- en: Notice that the date and time of each sale is the index of the DataFrame; this
    is because `resample` requires the index to be a datetime-like value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `resample` we can group the rows by a wide array of time periods (offsets)
    and then we can calculate statistics on each time group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Sale_Amount |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-06-11 | 5.001331 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-06-25 | 5.007738 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-07-09 | 4.993353 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-07-23 | 4.950481 |'
  prefs: []
  type: TYPE_TB
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Sale_Amount |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-06-30 | 72000 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-07-31 | 28000 |'
  prefs: []
  type: TYPE_TB
- en: 'You might notice that in the two outputs the datetime index is a date even
    though we are grouping by weeks and months, respectively. The reason is that by
    default `resample` returns the label of the right “edge” (the last label) of the
    time group. We can control this behavior using the `label` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Sale_Amount |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-05-31 | 72000 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017-06-30 | 28000 |'
  prefs: []
  type: TYPE_TB
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[List of pandas time offset aliases](https://oreil.ly/BURbR)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3.16 Aggregating Operations and Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to aggregate an operation over each column (or a set of columns) in
    a dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the pandas `agg` method. Here, we can easily get the minimum value of every
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes, we want to apply specific functions to specific sets of columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Age | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| mean | 30.397989 | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| min | NaN | 0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| max | NaN | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: 'We can also apply aggregate functions to groups to get more specific, descriptive
    statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '| PClass | Survived | Count |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | * | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1st | 0 | 129 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 1st | 1 | 193 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 2nd | 0 | 160 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 2nd | 1 | 119 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 3rd | 0 | 573 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 3rd | 1 | 138 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Aggregate functions are especially useful during exploratory data analysis to
    learn information about different subpopulations of data and the relationship
    between variables. By grouping the data and applying aggregate statistics, you
    can view patterns in the data that may prove useful during the machine learning
    or feature engineering process. While visual charts are also helpful, it’s often
    useful to have such specific, descriptive statistics as a reference to better
    understand the data.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[pandas agg documentation](https://oreil.ly/5xing)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3.17 Looping over a Column
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to iterate over every element in a column and apply some action.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can treat a pandas column like any other sequence in Python and loop over
    it using the standard Python syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In addition to loops (often called `for` loops), we can also use list comprehensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: Despite the temptation to fall back on `for` loops, a more Pythonic solution
    would use the pandas `apply` method, described in [Recipe 3.18](#applying-a-function-over-all-elements-in-a-column).
  prefs: []
  type: TYPE_NORMAL
- en: 3.18 Applying a Function over All Elements in a Column
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to apply some function over all elements in a column.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use `apply` to apply a built-in or custom function on every element in a column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`apply` is a great way to do data cleaning and wrangling. It is common to write
    a function to perform some useful operation (separate first and last names, convert
    strings to floats, etc.) and then map that function to every element in a column.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.19 Applying a Function to Groups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You have grouped rows using `groupby` and want to apply a function to each group.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Combine `groupby` and `apply`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '| Sex | Name | PClass | Age | Sex | Survived | SexCode |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| female | 462 | 462 | 288 | 462 | 462 | 462 |'
  prefs: []
  type: TYPE_TB
- en: '| male | 851 | 851 | 468 | 851 | 851 | 851 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [Recipe 3.18](#applying-a-function-over-all-elements-in-a-column) I mentioned
    `apply`. `apply` is particularly useful when you want to apply a function to groups.
    By combining `groupby` and `apply` we can calculate custom statistics or apply
    any function to each group separately.
  prefs: []
  type: TYPE_NORMAL
- en: 3.20 Concatenating DataFrames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to concatenate two DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use `concat` with `axis=0` to concatenate along the row axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '|  | id | first | last |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | Alex | Anderson |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 2 | Amy | Ackerman |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 3 | Allen | Ali |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 4 | Billy | Bonder |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 5 | Brian | Black |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 6 | Bran | Balwner |'
  prefs: []
  type: TYPE_TB
- en: 'You can use `axis=1` to concatenate along the column axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '|  | id | first | last | id | first | last |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | Alex | Anderson | 4 | Billy | Bonder |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 2 | Amy | Ackerman | 5 | Brian | Black |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 3 | Allen | Ali | 6 | Bran | Balwner |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Concatenating is not a word you hear much outside of computer science and programming,
    so if you have not heard it before, do not worry. The informal definition of *concatenate*
    is to glue two objects together. In the solution we glued together two small DataFrames
    using the `axis` parameter to indicate whether we wanted to stack the two DataFrames
    on top of each other or place them side by side.
  prefs: []
  type: TYPE_NORMAL
- en: 3.21 Merging DataFrames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to merge two DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To inner join, use `merge` with the `on` parameter to specify the column to
    merge on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '|  | employee_id | name | total_sales |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 3 | Alice Bees | 23456 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 4 | Tim Horton | 2512 |'
  prefs: []
  type: TYPE_TB
- en: '`merge` defaults to inner joins. If we want to do an outer join, we can specify
    that with the `how` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '|  | employee_id | name | total_sales |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | Amy Jones | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 2 | Allen Keys | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 3 | Alice Bees | 23456.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 4 | Tim Horton | 2512.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 5 | NaN | 2345.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 6 | NaN | 1455.0 |'
  prefs: []
  type: TYPE_TB
- en: 'The same parameter can be used to specify left and right joins:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '|  | employee_id | name | total_sales |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | Amy Jones | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 2 | Allen Keys | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 3 | Alice Bees | 23456.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 4 | Tim Horton | 2512.0 |'
  prefs: []
  type: TYPE_TB
- en: 'We can also specify the column name in each DataFrame to merge on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '|  | employee_id | name | total_sales |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 3 | Alice Bees | 23456 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 4 | Tim Horton | 2512 |'
  prefs: []
  type: TYPE_TB
- en: If, instead of merging on two columns, we want to merge on the indexes of each
    DataFrame, we can replace the `left_on` and `right_on` parameters with `left_index=True`
    and `right_index=True`.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data we need to use is often complex; it doesn’t always come in one piece.
    Instead, in the real world, we’re usually faced with disparate datasets from multiple
    database queries or files. To get all that data into one place, we can load each
    data query or data file into pandas as individual DataFrames and then merge them
    into a single DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: This process might be familiar to anyone who has used SQL, a popular language
    for doing merging operations (called *joins*). While the exact parameters used
    by pandas will be different, they follow the same general patterns used by other
    software languages and tools.
  prefs: []
  type: TYPE_NORMAL
- en: There are three aspects to specify with any `merge` operation. First, we have
    to specify the two DataFrames we want to merge. In the solution, we named them
    `dataframe_employees` and `dataframe_sales`. Second, we have to specify the name(s)
    of the columns to merge on—​that is, the columns whose values are shared between
    the two DataFrames. For example, in our solution both DataFrames have a column
    named `employee_id`. To merge the two DataFrames we will match the values in each
    DataFrame’s `employee_id` column. If these two columns use the same name, we can
    use the `on` parameter. However, if they have different names, we can use `left_on`
    and `right_on`.
  prefs: []
  type: TYPE_NORMAL
- en: What is the left and right DataFrame? The left DataFrame is the first one we
    specified in `merge`, and the right DataFrame is the second one. This language
    comes up again in the next sets of parameters we will need.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last aspect, and most difficult for some people to grasp, is the type of
    merge operation we want to conduct. This is specified by the `how` parameter.
    `merge` supports the four main types of joins:'
  prefs: []
  type: TYPE_NORMAL
- en: Inner
  prefs: []
  type: TYPE_NORMAL
- en: Return only the rows that match in both DataFrames (e.g., return any row with
    an `employee_id` value appearing in both `dataframe_employees` and `dataframe_sales`).
  prefs: []
  type: TYPE_NORMAL
- en: Outer
  prefs: []
  type: TYPE_NORMAL
- en: Return all rows in both DataFrames. If a row exists in one DataFrame but not
    in the other DataFrame, fill NaN values for the missing values (e.g., return all
    rows in both `dataframe_employee` and `dataframe_sales`).
  prefs: []
  type: TYPE_NORMAL
- en: Left
  prefs: []
  type: TYPE_NORMAL
- en: Return all rows from the left DataFrame but only rows from the right DataFrame
    that match with the left DataFrame. Fill `NaN` values for the missing values (e.g.,
    return all rows from `dataframe_employees` but only rows from `dataframe_sales`
    that have a value for `employee_id` that appears in `dataframe_employees`).
  prefs: []
  type: TYPE_NORMAL
- en: Right
  prefs: []
  type: TYPE_NORMAL
- en: Return all rows from the right DataFrame but only rows from the left DataFrame
    that match with the right DataFrame. Fill `NaN` values for the missing values
    (e.g., return all rows from `dataframe_sales` but only rows from `dataframe_employees`
    that have a value for `employee_id` that appears in `dataframe_sales`).
  prefs: []
  type: TYPE_NORMAL
- en: If you did not understand all of that, I encourage you to play around with the
    `how` parameter in your code and see how it affects what `merge` returns.
  prefs: []
  type: TYPE_NORMAL
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[A Visual Explanation of SQL Joins](https://oreil.ly/J1A4u)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[pandas documentation: Merge, join, concatenate and compare](https://oreil.ly/eNalU)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
