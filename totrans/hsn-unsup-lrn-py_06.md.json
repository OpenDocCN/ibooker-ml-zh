["```py\n# Load datasets\ncurrent_path = os.getcwd()\nfile = '\\\\datasets\\\\credit_card_data\\\\credit_card.csv'\ndata = pd.read_csv(current_path + file)\n\ndataX = data.copy().drop(['Class'],axis=1)\ndataY = data['Class'].copy()\n\nfeaturesToScale = dataX.columns\nsX = pp.StandardScaler(copy=True)\ndataX.loc[:,featuresToScale] = sX.fit_transform(dataX[featuresToScale])\n\nX_train, X_test, y_train, y_test = \\\n    train_test_split(dataX, dataY, test_size=0.33, \\\n                    random_state=2018, stratify=dataY)\n```", "```py\ndef anomalyScores(originalDF, reducedDF):\n    loss = np.sum((np.array(originalDF)-np.array(reducedDF))**2, axis=1)\n    loss = pd.Series(data=loss,index=originalDF.index)\n    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n    return loss\n```", "```py\ndef plotResults(trueLabels, anomalyScores, returnPreds = False):\n    preds = pd.concat([trueLabels, anomalyScores], axis=1)\n    preds.columns = ['trueLabel', 'anomalyScore']\n    precision, recall, thresholds = \\\n        precision_recall_curve(preds['trueLabel'],preds['anomalyScore'])\n    average_precision = \\\n        average_precision_score(preds['trueLabel'],preds['anomalyScore'])\n\n    plt.step(recall, precision, color='k', alpha=0.7, where='post')\n    plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.0])\n\n    plt.title('Precision-Recall curve: Average Precision = \\\n {0:0.2f}'.format(average_precision))\n\n    fpr, tpr, thresholds = roc_curve(preds['trueLabel'], \\\n                                     preds['anomalyScore'])\n    areaUnderROC = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n    plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic: \\\n Area under the curve = {0:0.2f}'.format(areaUnderROC))\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    if returnPreds==True:\n        return preds\n```", "```py\ndef scatterPlot(xDF, yDF, algoName):\n    tempDF = pd.DataFrame(data=xDF.loc[:,0:1], index=xDF.index)\n    tempDF = pd.concat((tempDF,yDF), axis=1, join=\"inner\")\n    tempDF.columns = [\"First Vector\", \"Second Vector\", \"Label\"]\n    sns.lmplot(x=\"First Vector\", y=\"Second Vector\", hue=\"Label\", \\\n               data=tempDF, fit_reg=False)\n    ax = plt.gca()\n    ax.set_title(\"Separation of Observations using \"+algoName)\n```", "```py\n# 30 principal components\nfrom sklearn.decomposition import PCA\n\nn_components = 30\nwhiten = False\nrandom_state = 2018\n\npca = PCA(n_components=n_components, whiten=whiten, \\\n          random_state=random_state)\n\nX_train_PCA = pca.fit_transform(X_train)\nX_train_PCA = pd.DataFrame(data=X_train_PCA, index=X_train.index)\n\nX_train_PCA_inverse = pca.inverse_transform(X_train_PCA)\nX_train_PCA_inverse = pd.DataFrame(data=X_train_PCA_inverse, \\\n                                   index=X_train.index)\n\nscatterPlot(X_train_PCA, y_train, \"PCA\")\n```", "```py\nanomalyScoresPCA = anomalyScores(X_train, X_train_PCA_inverse)\npreds = plotResults(y_train, anomalyScoresPCA, True)\n```", "```py\npreds.sort_values(by=\"anomalyScore\",ascending=False,inplace=True)\ncutoff = 350\npredsTop = preds[:cutoff]\nprint(\"Precision: \",np.round(predsTop. \\\n            anomalyScore[predsTop.trueLabel==1].count()/cutoff,2))\nprint(\"Recall: \",np.round(predsTop. \\\n            anomalyScore[predsTop.trueLabel==1].count()/y_train.sum(),2))\n```", "```py\nPrecision: 0.75\nRecall: 0.8\nFraud Caught out of 330 Cases: 264\n```", "```py\n# Sparse PCA\nfrom sklearn.decomposition import SparsePCA\n\nn_components = 27\nalpha = 0.0001\nrandom_state = 2018\nn_jobs = -1\n\nsparsePCA = SparsePCA(n_components=n_components, \\\n                alpha=alpha, random_state=random_state, n_jobs=n_jobs)\n\nsparsePCA.fit(X_train.loc[:,:])\nX_train_sparsePCA = sparsePCA.transform(X_train)\nX_train_sparsePCA = pd.DataFrame(data=X_train_sparsePCA, index=X_train.index)\n\nscatterPlot(X_train_sparsePCA, y_train, \"Sparse PCA\")\n```", "```py\nX_train_sparsePCA_inverse = np.array(X_train_sparsePCA). \\\n    dot(sparsePCA.components_) + np.array(X_train.mean(axis=0))\nX_train_sparsePCA_inverse = \\\n    pd.DataFrame(data=X_train_sparsePCA_inverse, index=X_train.index)\n\nanomalyScoresSparsePCA = anomalyScores(X_train, X_train_sparsePCA_inverse)\npreds = plotResults(y_train, anomalyScoresSparsePCA, True)\n```", "```py\n# Kernel PCA\nfrom sklearn.decomposition import KernelPCA\n\nn_components = 27\nkernel = 'rbf'\ngamma = None\nfit_inverse_transform = True\nrandom_state = 2018\nn_jobs = 1\n\nkernelPCA = KernelPCA(n_components=n_components, kernel=kernel, \\\n                gamma=gamma, fit_inverse_transform= \\\n                fit_inverse_transform, n_jobs=n_jobs, \\\n                random_state=random_state)\n\nkernelPCA.fit(X_train.iloc[:2000])\nX_train_kernelPCA = kernelPCA.transform(X_train)\nX_train_kernelPCA = pd.DataFrame(data=X_train_kernelPCA, \\\n                                 index=X_train.index)\n\nX_train_kernelPCA_inverse = kernelPCA.inverse_transform(X_train_kernelPCA)\nX_train_kernelPCA_inverse = pd.DataFrame(data=X_train_kernelPCA_inverse, \\\n                                         index=X_train.index)\n\nscatterPlot(X_train_kernelPCA, y_train, \"Kernel PCA\")\n```", "```py\n# Gaussian Random Projection\nfrom sklearn.random_projection import GaussianRandomProjection\n\nn_components = 27\neps = None\nrandom_state = 2018\n\nGRP = GaussianRandomProjection(n_components=n_components, \\\n                               eps=eps, random_state=random_state)\n\nX_train_GRP = GRP.fit_transform(X_train)\nX_train_GRP = pd.DataFrame(data=X_train_GRP, index=X_train.index)\n\nscatterPlot(X_train_GRP, y_train, \"Gaussian Random Projection\")\n```", "```py\n# Sparse Random Projection\n\nfrom sklearn.random_projection import SparseRandomProjection\n\nn_components = 27\ndensity = 'auto'\neps = .01\ndense_output = True\nrandom_state = 2018\n\nSRP = SparseRandomProjection(n_components=n_components, \\\n        density=density, eps=eps, dense_output=dense_output, \\\n                                random_state=random_state)\n\nX_train_SRP = SRP.fit_transform(X_train)\nX_train_SRP = pd.DataFrame(data=X_train_SRP, index=X_train.index)\n\nscatterPlot(X_train_SRP, y_train, \"Sparse Random Projection\")\n```", "```py\n# Mini-batch dictionary learning\nfrom sklearn.decomposition import MiniBatchDictionaryLearning\n\nn_components = 28\nalpha = 1\nbatch_size = 200\nn_iter = 10\nrandom_state = 2018\n\nminiBatchDictLearning = MiniBatchDictionaryLearning( \\\n    n_components=n_components, alpha=alpha, batch_size=batch_size, \\\n    n_iter=n_iter, random_state=random_state)\n\nminiBatchDictLearning.fit(X_train)\nX_train_miniBatchDictLearning = \\\n    miniBatchDictLearning.fit_transform(X_train)\nX_train_miniBatchDictLearning = \\\n    pd.DataFrame(data=X_train_miniBatchDictLearning, index=X_train.index)\n\nscatterPlot(X_train_miniBatchDictLearning, y_train, \\\n            \"Mini-batch Dictionary Learning\")\n```", "```py\n# Independent Component Analysis\n\nfrom sklearn.decomposition import FastICA\n\nn_components = 27\nalgorithm = 'parallel'\nwhiten = True\nmax_iter = 200\nrandom_state = 2018\n\nfastICA = FastICA(n_components=n_components, \\\n    algorithm=algorithm, whiten=whiten, max_iter=max_iter, \\\n    random_state=random_state)\n\nX_train_fastICA = fastICA.fit_transform(X_train)\nX_train_fastICA = pd.DataFrame(data=X_train_fastICA, index=X_train.index)\n\nX_train_fastICA_inverse = fastICA.inverse_transform(X_train_fastICA)\nX_train_fastICA_inverse = pd.DataFrame(data=X_train_fastICA_inverse, \\\n                                       index=X_train.index)\n\nscatterPlot(X_train_fastICA, y_train, \"Independent Component Analysis\")\n```", "```py\n# PCA on Test Set\nX_test_PCA = pca.transform(X_test)\nX_test_PCA = pd.DataFrame(data=X_test_PCA, index=X_test.index)\n\nX_test_PCA_inverse = pca.inverse_transform(X_test_PCA)\nX_test_PCA_inverse = pd.DataFrame(data=X_test_PCA_inverse, \\\n                                  index=X_test.index)\n\nscatterPlot(X_test_PCA, y_test, \"PCA\")\n```", "```py\n# Independent Component Analysis on Test Set\nX_test_fastICA = fastICA.transform(X_test)\nX_test_fastICA = pd.DataFrame(data=X_test_fastICA, index=X_test.index)\n\nX_test_fastICA_inverse = fastICA.inverse_transform(X_test_fastICA)\nX_test_fastICA_inverse = pd.DataFrame(data=X_test_fastICA_inverse, \\\n                                      index=X_test.index)\n\nscatterPlot(X_test_fastICA, y_test, \"Independent Component Analysis\")\n```", "```py\nX_test_miniBatchDictLearning = miniBatchDictLearning.transform(X_test)\nX_test_miniBatchDictLearning = \\\n    pd.DataFrame(data=X_test_miniBatchDictLearning, index=X_test.index)\n\nscatterPlot(X_test_miniBatchDictLearning, y_test, \\\n            \"Mini-batch Dictionary Learning\")\n```"]