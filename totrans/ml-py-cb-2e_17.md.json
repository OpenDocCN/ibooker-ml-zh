["```py\n# Load libraries\nfrom sklearn.svm import LinearSVC\nfrom sklearn import datasets\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Load data with only two classes and two features\niris = datasets.load_iris()\nfeatures = iris.data[:100,:2]\ntarget = iris.target[:100]\n\n# Standardize features\nscaler = StandardScaler()\nfeatures_standardized = scaler.fit_transform(features)\n\n# Create support vector classifier\nsvc = LinearSVC(C=1.0)\n\n# Train model\nmodel = svc.fit(features_standardized, target)\n```", "```py\n# Load library\nfrom matplotlib import pyplot as plt\n\n# Plot data points and color using their class\ncolor = [\"black\" if c == 0 else \"lightgrey\" for c in target]\nplt.scatter(features_standardized[:,0], features_standardized[:,1], c=color)\n\n# Create the hyperplane\nw = svc.coef_[0]\na = -w[0] / w[1]\nxx = np.linspace(-2.5, 2.5)\nyy = a * xx - (svc.intercept_[0]) / w[1]\n\n# Plot the hyperplane\nplt.plot(xx, yy)\nplt.axis(\"off\"), plt.show();\n```", "```py\n# Create new observation\nnew_observation = [[ -2,  3]]\n\n# Predict class of new observation\nsvc.predict(new_observation)\n```", "```py\narray([0])\n```", "```py\n# Load libraries\nfrom sklearn.svm import SVC\nfrom sklearn import datasets\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Set randomization seed\nnp.random.seed(0)\n\n# Generate two features\nfeatures = np.random.randn(200, 2)\n\n# Use an XOR gate (you don't need to know what this is) to generate\n# linearly inseparable classes\ntarget_xor = np.logical_xor(features[:, 0] > 0, features[:, 1] > 0)\ntarget = np.where(target_xor, 0, 1)\n\n# Create a support vector machine with a radial basis function kernel\nsvc = SVC(kernel=\"rbf\", random_state=0, gamma=1, C=1)\n\n# Train the classifier\nmodel = svc.fit(features, target)\n```", "```py\n# Plot observations and decision boundary hyperplane\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\n\ndef plot_decision_regions(X, y, classifier):\n    cmap = ListedColormap((\"red\", \"blue\"))\n    xx1, xx2 = np.meshgrid(np.arange(-3, 3, 0.02), np.arange(-3, 3, 0.02))\n    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    plt.contourf(xx1, xx2, Z, alpha=0.1, cmap=cmap)\n\n    for idx, cl in enumerate(np.unique(y)):\n        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n                    alpha=0.8, c=cmap(idx),\n                    marker=\"+\", label=cl)\n```", "```py\n# Create support vector classifier with a linear kernel\nsvc_linear = SVC(kernel=\"linear\", random_state=0, C=1)\n\n# Train model\nsvc_linear.fit(features, target)\n```", "```py\nSVC(C=1, kernel='linear', random_state=0)\n```", "```py\n# Plot observations and hyperplane\nplot_decision_regions(features, target, classifier=svc_linear)\nplt.axis(\"off\"), plt.show();\n```", "```py\n# Create a support vector machine with a radial basis function kernel\nsvc = SVC(kernel=\"rbf\", random_state=0, gamma=1, C=1)\n\n# Train the classifier\nmodel = svc.fit(features, target)\n```", "```py\n# Plot observations and hyperplane\nplot_decision_regions(features, target, classifier=svc)\nplt.axis(\"off\"), plt.show();\n```", "```py\n# Load libraries\nfrom sklearn.svm import SVC\nfrom sklearn import datasets\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Load data\niris = datasets.load_iris()\nfeatures = iris.data\ntarget = iris.target\n\n# Standardize features\nscaler = StandardScaler()\nfeatures_standardized = scaler.fit_transform(features)\n\n# Create support vector classifier object\nsvc = SVC(kernel=\"linear\", probability=True, random_state=0)\n\n# Train classifier\nmodel = svc.fit(features_standardized, target)\n\n# Create new observation\nnew_observation = [[.4, .4, .4, .4]]\n\n# View predicted probabilities\nmodel.predict_proba(new_observation)\n```", "```py\narray([[0.00541761, 0.97348825, 0.02109414]])\n```", "```py\n# Load libraries\nfrom sklearn.svm import SVC\nfrom sklearn import datasets\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Load data with only two classes\niris = datasets.load_iris()\nfeatures = iris.data[:100,:]\ntarget = iris.target[:100]\n\n# Standardize features\nscaler = StandardScaler()\nfeatures_standardized = scaler.fit_transform(features)\n\n# Create support vector classifier object\nsvc = SVC(kernel=\"linear\", random_state=0)\n\n# Train classifier\nmodel = svc.fit(features_standardized, target)\n\n# View support vectors\nmodel.support_vectors_\n```", "```py\narray([[-0.5810659 ,  0.42196824, -0.80497402, -0.50860702],\n       [-1.52079513, -1.67737625, -1.08231219, -0.86427627],\n       [-0.89430898, -1.4674418 ,  0.30437864,  0.38056609],\n       [-0.5810659 , -1.25750735,  0.09637501,  0.55840072]])\n```", "```py\nmodel.support_\n```", "```py\narray([23, 41, 57, 98], dtype=int32)\n```", "```py\nmodel.n_support_\n```", "```py\narray([2, 2], dtype=int32)\n```", "```py\n# Load libraries\nfrom sklearn.svm import SVC\nfrom sklearn import datasets\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Load data with only two classes\niris = datasets.load_iris()\nfeatures = iris.data[:100,:]\ntarget = iris.target[:100]\n\n# Make class highly imbalanced by removing first 40 observations\nfeatures = features[40:,:]\ntarget = target[40:]\n\n# Create target vector indicating if class 0, otherwise 1\ntarget = np.where((target == 0), 0, 1)\n\n# Standardize features\nscaler = StandardScaler()\nfeatures_standardized = scaler.fit_transform(features)\n\n# Create support vector classifier\nsvc = SVC(kernel=\"linear\", class_weight=\"balanced\", C=1.0, random_state=0)\n\n# Train classifier\nmodel = svc.fit(features_standardized, target)\n```"]