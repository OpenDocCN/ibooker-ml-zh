<html><head></head><body><div data-pdf-bookmark="Part III. Ranking" data-type="part" epub:type="part" id="ranking">&#13;
<h1><span class="label">Part III. </span>Ranking</h1>&#13;
&#13;
<div class="partintro"><blockquote>&#13;
<p><em>What are the appropriate candidates for a given recommendation? Which of these candidates is the best? What about the 10 best?</em></p></blockquote>&#13;
&#13;
<p>Sometimes the best recommender system is simply item availability, but in the majority of cases, you’re hoping to capture subtle signals about user preference to deliver excellent recommendations among potentially millions of options. Personalization is the name of the game; while we previously focused on item-item similarity with respect to external meaning, we need to start attempting to infer user taste and desire.</p>&#13;
&#13;
<p>We’d also better start making this an ML task eventually. Beyond discussions of features and architectures, we’ll need to define the objective functions. At first blush, the objective for recommendations is the simple binary “Did they like it?”—so maybe we’re simply predicting the outcome of a Bernoulli trial. However, as we discussed in the introduction, there are a variety of ways to get the signal about how much they liked it. Moreover, recommendation systems in most cases grant one kindness: you get multiple shots on goal. Usually you get to recommend a few options, so we are very interested in predictions of which things they’ll like the most. In this part of the book, we’ll take all that you’ve learned and start getting numbers out. We’ll also talk about explicit loss functions used to train and evaluate your models.</p>&#13;
</div>&#13;
</div></body></html>