["```py\n>>> from sklearn.base import (\n...     BaseEstimator,\n...     TransformerMixin,\n... )\n>>> from sklearn.pipeline import Pipeline\n\n>>> def tweak_titanic(df):\n...     df = df.drop(\n...         columns=[\n...             \"name\",\n...             \"ticket\",\n...             \"home.dest\",\n...             \"boat\",\n...             \"body\",\n...             \"cabin\",\n...         ]\n...     ).pipe(pd.get_dummies, drop_first=True)\n...     return df\n\n>>> class TitanicTransformer(\n...     BaseEstimator, TransformerMixin\n... ):\n...     def transform(self, X):\n...         # assumes X is output\n...         # from reading Excel file\n...         X = tweak_titanic(X)\n...         X = X.drop(column=\"survived\")\n...         return X\n...\n...     def fit(self, X, y):\n...         return self\n\n>>> pipe = Pipeline(\n...     [\n...         (\"titan\", TitanicTransformer()),\n...         (\"impute\", impute.IterativeImputer()),\n...         (\n...             \"std\",\n...             preprocessing.StandardScaler(),\n...         ),\n...         (\"rf\", RandomForestClassifier()),\n...     ]\n... )\n```", "```py\n>>> from sklearn.model_selection import (\n...     train_test_split,\n... )\n>>> X_train2, X_test2, y_train2, y_test2 = train_test_split(\n...     orig_df,\n...     orig_df.survived,\n...     test_size=0.3,\n...     random_state=42,\n... )\n\n>>> pipe.fit(X_train2, y_train2)\n>>> pipe.score(X_test2, y_test2)\n0.7913486005089059\n```", "```py\n>>> params = {\n...     \"rf__max_features\": [0.4, \"auto\"],\n...     \"rf__n_estimators\": [15, 200],\n... }\n\n>>> grid = model_selection.GridSearchCV(\n...     pipe, cv=3, param_grid=params\n... )\n>>> grid.fit(orig_df, orig_df.survived)\n```", "```py\n>>> grid.best_params_\n{'rf__max_features': 0.4, 'rf__n_estimators': 15}\n>>> pipe.set_params(**grid.best_params_)\n>>> pipe.fit(X_train2, y_train2)\n>>> pipe.score(X_test2, y_test2)\n0.7913486005089059\n```", "```py\n>>> metrics.roc_auc_score(\n...     y_test2, pipe.predict(X_test2)\n... )\n0.7813688715131023\n```", "```py\n>>> from sklearn.pipeline import Pipeline\n\n>>> reg_pipe = Pipeline(\n...     [\n...         (\n...             \"std\",\n...             preprocessing.StandardScaler(),\n...         ),\n...         (\"lr\", LinearRegression()),\n...     ]\n... )\n>>> reg_pipe.fit(bos_X_train, bos_y_train)\n>>> reg_pipe.score(bos_X_test, bos_y_test)\n0.7112260057484934\n```", "```py\n>>> reg_pipe.named_steps[\"lr\"].intercept_\n23.01581920903956\n>>> reg_pipe.named_steps[\"lr\"].coef_\narray([-1.10834602,  0.80843998,  0.34313466,\n 0.81386426, -1.79804295,  2.913858  ,\n -0.29893918, -2.94251148,  2.09419303,\n -1.44706731, -2.05232232,  1.02375187,\n -3.88579002])_\n```", "```py\n>>> from sklearn import metrics\n>>> metrics.mean_squared_error(\n...     bos_y_test, reg_pipe.predict(bos_X_test)\n... )\n21.517444231177205\n```", "```py\n>>> pca_pipe = Pipeline(\n...     [\n...         (\n...             \"std\",\n...             preprocessing.StandardScaler(),\n...         ),\n...         (\"pca\", PCA()),\n...     ]\n... )\n>>> X_pca = pca_pipe.fit_transform(X)\n```", "```py\n>>> pca_pipe.named_steps[\n...     \"pca\"\n... ].explained_variance_ratio_\narray([0.23917891, 0.21623078, 0.19265028,\n 0.10460882, 0.08170342, 0.07229959,\n 0.05133752, 0.04199068])\n>>> pca_pipe.named_steps[\"pca\"].components_[0]\narray([-0.63368693,  0.39682566,  0.00614498,\n 0.11488415,  0.58075352, -0.19046812,\n -0.21190808, -0.09631388])\n```"]