<html><head></head><body><section data-pdf-bookmark="Chapter 7. Autoencoders" data-type="chapter" epub:type="chapter"><div class="chapter" id="Chapter_7">&#13;
<h1><span class="label">Chapter 7. </span>Autoencoders</h1>&#13;
&#13;
&#13;
<p>The<a data-primary="unsupervised learning" data-secondary="shallow neural networks" data-type="indexterm" id="ULshallow07"/> first six chapters of this book explored how to use unsupervised learning to perform dimensionality reduction and clustering, and the concepts we covered helped us build applications to detect anomalies and segment groups based on similarity.</p>&#13;
&#13;
<p>However, unsupervised<a data-primary="feature extraction" data-type="indexterm" id="idm140637542498080"/><a data-primary="feature extraction" data-see="also autoencoders" data-type="indexterm" id="idm140637542497344"/> learning is capable of a lot more. One area that unsupervised learning excels in is <em>feature extraction</em>, which is a method used to generate a new feature representation from an original set of features; the new feature representation<a data-primary="learned representation" data-type="indexterm" id="idm140637542495744"/> is called a <em>learned representation</em> and is used to improve performance on supervised learning problems. In other words, feature extraction is an unsupervised means to a supervised end.</p>&#13;
&#13;
<p>Autoencoders<a data-primary="autoencoders" data-secondary="overview of" data-type="indexterm" id="idm140637542493920"/><a data-primary="feedforward networks" data-type="indexterm" id="idm140637542492912"/> are one such form of feature extraction. They use a <em>feedforward, nonrecurrent neural network</em> to perform<a data-primary="representation learning" data-type="indexterm" id="idm140637542491664"/> <em>representation learning</em>. Representation learning is a core part of an entire branch of machine learning involving neural networks.</p>&#13;
&#13;
<p>In autoencoders—which are a form of representation learning—each layer of the neural network learns a representation of the original features, and subsequent layers build on the representation learned by the preceding layers. Layer by layer, the autoencoder learns increasingly complicated representations from simpler ones, building what is known as a hierarchy of concepts that become more and more abstract.</p>&#13;
&#13;
<p>The<a data-primary="generalization error" data-type="indexterm" id="idm140637542489024"/> output layer is the final newly learned representation of the original features. This learned representation can then be used as input into a supervised learning model with the objective of improving the generalization error.</p>&#13;
&#13;
<p>But before we get too far ahead of ourselves, let’s begin by introducing neural networks and the Python frameworks TensorFlow and Keras.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Neural Networks" data-type="sect1"><div class="sect1" id="idm140637542487248">&#13;
<h1>Neural Networks</h1>&#13;
&#13;
<p>At<a data-primary="autoencoders" data-secondary="neural networks and" data-type="indexterm" id="Aneural07"/> their very essence, neural networks perform representation learning, where each layer of the neural network learns a representation from the previous layer. By building more nuanced and detailed representations layer by layer, neural networks can accomplish pretty amazing tasks such as computer vision, speech recognition, and machine translation.</p>&#13;
&#13;
<p>Neural networks<a data-primary="neural networks" data-secondary="shallow and deep" data-type="indexterm" id="idm140637542483360"/> come in two forms—shallow and deep. Shallow networks have few layers, and deep networks have many layers. Deep learning gets its name from the deep (many-layered) neural networks it deploys. Shallow neural networks are not particularly powerful since the degree of representation learning is limited by the low number of layers. Deep learning, on the other hand, is incredibly powerful and is currently one of the hottest areas in machine learning.</p>&#13;
&#13;
<p>To<a data-primary="machine learning" data-secondary="classic vs. using neural networks" data-type="indexterm" id="idm140637542481376"/> be clear, shallow and deep learning using neural networks are just a part of the entire machine learning ecosystem. The major difference between machine learning using neural networks and classical machine learning is that a lot of the feature representation is automatically performed in the neural networks case and is hand-designed in classical machine learning.</p>&#13;
&#13;
<p>Neural networks<a data-primary="neural networks" data-secondary="layers of" data-type="indexterm" id="idm140637542479280"/><a data-primary="input layers" data-type="indexterm" id="idm140637542478272"/><a data-primary="hidden layers" data-type="indexterm" id="idm140637542477600"/><a data-primary="output layers" data-type="indexterm" id="idm140637542476928"/> have an <em>input layer</em>, one or many <em>hidden layers</em>, and an <em>output layer</em>. The number of hidden layers defines just how <em>deep</em> the neural network is. You can view these hidden layers as intermediate computations; these hidden layers together allow the entire neural network to perform complex function approximation.</p>&#13;
&#13;
<p>Each layer<a data-primary="neural networks" data-secondary="nodes in" data-type="indexterm" id="idm140637542473680"/><a data-primary="nodes" data-type="indexterm" id="idm140637542472672"/><a data-primary="neurons" data-type="indexterm" id="idm140637542472000"/><a data-primary="units" data-type="indexterm" id="idm140637542471328"/> has a certain number of <em>nodes</em> (also known as <em>neurons</em> or <em>units</em>) that comprise the layer. The nodes of each layer are then connected to the nodes of the next layer. During the training process, the neural network determines the optimal weights to assign to each node.</p>&#13;
&#13;
<p>In addition to adding more layers, we can add more nodes to a neural network to increase the capacity of the neural network to model complex relationships. These<a data-primary="activation functions" data-type="indexterm" id="idm140637542468192"/><a data-primary="neural networks" data-secondary="activation functions and" data-type="indexterm" id="idm140637542467520"/> nodes are fed into an <em>activation function</em>, which determines what value of the current layer is fed into the next layer of the neural network. Common activation functions<a data-primary="linear activation function" data-type="indexterm" id="idm140637542465824"/><a data-primary="sigmoid activation function" data-type="indexterm" id="idm140637542465104"/><a data-primary="hyperbolic tangent (tanh) activation function" data-type="indexterm" id="idm140637542464416"/><a data-primary="rectified linear unit (ReLU) activation function" data-type="indexterm" id="idm140637542463648"/> include <em>linear</em>, <em>sigmoid</em>, <em>hyperbolic tangent</em>, and <em>rectified linear unit (ReLU)</em> activation functions. The<a data-primary="softmax activation function" data-type="indexterm" id="idm140637542461008"/> final activation function is usually the <em>softmax function</em>, which outputs a class probability that the input observation falls in. This is pretty typical for classification type problems.</p>&#13;
&#13;
<p>Neural networks<a data-primary="neural networks" data-secondary="bias nodes in" data-type="indexterm" id="idm140637542459488"/><a data-primary="bias nodes" data-type="indexterm" id="idm140637542458480"/> may also have <em>bias nodes</em>; these nodes are always constant values and, unlike the normal nodes, are not connected to the previous layer. Rather, they allow the output of an activation function to be shifted lower or higher. With<a data-primary="neural networks" data-secondary="supervised and unsupervised learning in" data-type="indexterm" id="idm140637542457040"/> the hidden layers—including the nodes, bias nodes, and activation functions—the neural network is trying to learn the right function approximation to use to map the input layer to the output layer.</p>&#13;
&#13;
<p>In the case of supervised learning problems, this is pretty straightforward. The input layer represents the features that are fed into the neural network, and the output layer represents the label assigned to each observation. During the training process, the neural network determines which <em>weights</em> across the neural network help minimize the error between its predicted label for each observation and the true label. In unsupervised learning problems, the neural network learns representations of the input layer via the various hidden layers but is not guided by labels.</p>&#13;
&#13;
<p>Neural networks<a data-primary="neural networks" data-secondary="benefits and drawbacks of" data-type="indexterm" id="idm140637542453936"/> are incredibly powerful and are capable of modeling complex nonlinear relationships to a degree that classicial machine learning algorithms struggle with. In general, this is a great characteristic of neural networks, but there is a potential risk. Because neural networks can model such complex nonlinear relationships, they are also much more prone to overfitting, which we should be aware of and address when designing machine learning applications using neural networks.<sup><a data-type="noteref" href="ch07.html#idm140637542452288" id="idm140637542452288-marker">1</a></sup></p>&#13;
&#13;
<p>Although there are multiple types of neural networks<a data-primary="convolutional neural networks (CNNs)" data-type="indexterm" id="idm140637542451248"/><a data-primary="recurrent neural networks" data-type="indexterm" id="idm140637542450528"/> such as <em>recurrent neural networks</em> in which data can flow in any direction (used for speech recognition and machine translation) and <em>convolutional neural networks</em> (used for computer vision), we will focus on the more straightforward<a data-primary="feedforward networks" data-type="indexterm" id="idm140637542448752"/> feedforward neural network in which data moves in just one direction: forward.</p>&#13;
&#13;
<p>We<a data-primary="hyperparameter optimization" data-type="indexterm" id="idm140637542447568"/><a data-primary="neural networks" data-secondary="hyperparameter optimization" data-type="indexterm" id="idm140637542446768"/> also must perform a lot more hyperparameter optimization to get neural networks to perform well—including the choice of the cost function, the algorithm to minimize the loss, the type of initialization for the starting weights, the number of iterations to use to train the neural network (i.e., number of epochs), the number of observations to feed in before each weight update (i.e., batch size), and the step size to move the weights in (i.e., learning rate) during the training process.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="TensorFlow" data-type="sect2"><div class="sect2" id="idm140637542445040">&#13;
<h2>TensorFlow</h2>&#13;
&#13;
<p>Before<a data-primary="neural networks" data-secondary="TensorFlow and" data-type="indexterm" id="idm140637542443504"/><a data-primary="TensorFlow" data-secondary="development of" data-type="indexterm" id="idm140637542442496"/> we introduce autoencoders, let’s explore <em>TensorFlow</em>, the primary library we will use to build neural networks. TensorFlow is an open source software library for high-performance numerical computation and was initially developed by the Google Brain team for internal Google use. In November 2015, it was released as open source software.<sup><a data-type="noteref" href="ch07.html#idm140637542440736" id="idm140637542440736-marker">2</a></sup></p>&#13;
&#13;
<p>TensorFlow<a data-primary="TensorFlow" data-secondary="benefits of" data-type="indexterm" id="idm140637542439008"/> is available across many operating systems (including Linux, macOS, Windows, Android, and iOS) and can run on multiple CPUs and GPUs, making the software very scalable for fast performance and deployable to most users across desktop, mobile, web, and cloud.</p>&#13;
&#13;
<p>The beauty of TensorFlow is that users can define a neural network—or, more generally, a graph of computations—in Python, and can take the neural network and run it using C++ code, which is much faster than Python.</p>&#13;
&#13;
<p>TensorFlow<a data-primary="parallelization" data-type="indexterm" id="idm140637542436560"/> is also able to <em>parallelize</em> the computations, breaking down the entire series of operations into separate chunks and running them in parallel across multiple CPUs and GPUs. Performance like this is a very important consideration for large-scale machine learning applications like those that Google runs for its core operations such as search.</p>&#13;
&#13;
<p>While there are other open source libraries capable of similar feats, TensorFlow has become the most popular, partly due to Google’s brand.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="TensorFlow example" data-type="sect3"><div class="sect3" id="idm140637542434240">&#13;
<h3>TensorFlow example</h3>&#13;
&#13;
<p>Before<a data-primary="TensorFlow" data-secondary="example application" data-type="indexterm" id="idm140637542432672"/> we move ahead, let’s build a TensorFlow graph and run a computation. We will import TensorFlow, define a few variables using the TensorFlow API (which resembles the Scikit-Learn API we’ve used in previous chapters), and then compute the <span class="keep-together">values</span> for those variables:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">tensorflow</code> <code class="kn">as</code> <code class="nn">tf</code>&#13;
&#13;
<code class="n">b</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mi">50</code><code class="p">)</code>&#13;
<code class="n">x</code> <code class="o">=</code> <code class="n">b</code> <code class="o">*</code> <code class="mi">10</code>&#13;
<code class="n">y</code> <code class="o">=</code> <code class="n">x</code> <code class="o">+</code> <code class="n">b</code>&#13;
&#13;
<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>&#13;
    <code class="n">result</code> <code class="o">=</code> <code class="n">y</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code>&#13;
    <code class="k">print</code><code class="p">(</code><code class="n">result</code><code class="p">)</code></pre>&#13;
&#13;
<p>It is important to realize that there are two phases here. First, we construct the computation graph, defining b, x, and y. Then, we execute the graph by calling<a data-primary="tf.Session()" data-type="indexterm" id="idm140637545017952"/><a data-primary="TensorFlow" data-secondary="tf.Session()" data-type="indexterm" id="idm140637542401024"/> <code>tf.Session()</code>. Until we call this, no computations are being executed by the CPU and/or GPU. Rather, only the instructions for the computations are being stored. Once you execute this block of code, you will see the result of “550” as expected.</p>&#13;
&#13;
<p>Later on, we will build actual neural networks using TensorFlow.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Keras" data-type="sect2"><div class="sect2" id="idm140637542398800">&#13;
<h2>Keras</h2>&#13;
&#13;
<p>Keras is<a data-primary="neural networks" data-secondary="Keras and" data-type="indexterm" id="idm140637542335696"/><a data-primary="Keras" data-secondary="overview of" data-type="indexterm" id="idm140637542334688"/> an open source software library and provides a high-level API that runs on top of TensorFlow. It provides a much more user-friendly interface for TensorFlow, allowing data scientists and researchers to experiment faster and more easily than if they had to work directly with the TensorFlow commands. Keras was also primarily authored by a Google engineer, Francois Chollet.</p>&#13;
&#13;
<p>When we start building models using TensorFlow, we will work hands-on with Keras and explore its advantages.<a data-primary="" data-startref="Aneural07" data-type="indexterm" id="idm140637542332720"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Autoencoder: The Encoder and the Decoder" data-type="sect1"><div class="sect1" id="idm140637542486624">&#13;
<h1>Autoencoder: The Encoder and the Decoder</h1>&#13;
&#13;
<p>Now<a data-primary="autoencoders" data-secondary="encoder and decoder in" data-type="indexterm" id="idm140637542330112"/> that we’ve introduced neural networks and the popular libraries to work with them in Python—TensorFlow and Keras—let’s build an autoencoder, one of the simplest unsupervised learning neural networks.</p>&#13;
&#13;
<p>An<a data-primary="encoders" data-type="indexterm" id="idm140637542328368"/><a data-primary="decoders" data-type="indexterm" id="idm140637542327632"/> autoencoder comprises two parts, an <em>encoder</em> and a <em>decoder</em>. The encoder converts the input set of features into a different representation—via representation learning—and the decoder converts this newly learned representation to the original format.</p>&#13;
&#13;
<p>The core concept of an autoencoder is similar to the concept of dimensionality reduction we studied in <a data-type="xref" href="ch03.html#Chapter_3">Chapter 3</a>. Similar to dimensionality reduction, an autoencoder does not memorize the original observations and features, which would be what is known<a data-primary="identity function" data-type="indexterm" id="idm140637542324272"/> as the <em>identity function</em>. If it learned the exact identity function, the autoencoder would not be useful. Rather, autoencoders must approximate the original observations as closely as possible—but not exactly—using a newly learned representation; in other words, the autoencoder learns an approximation of the identity function.</p>&#13;
&#13;
<p>Since the autoencoder is constrained, it is forced to learn the most salient properties of the original data, capturing the underlying structure of the data; this is similar to what happens in dimensionality reduction. The constraint is a very important attribute of autoencoders—the constraint forces the autoencoder to intelligently choose which important information to capture and which irrelevant or less important information to discard.</p>&#13;
&#13;
<p>Autoencoders<a data-primary="autoencoders" data-secondary="applications for" data-type="indexterm" id="idm140637542321440"/> have been around for decades, and, as you may suspect already, they have been used widely for dimensionality reduction and automatic feature engineering/learning. Today, they are often used to build <em>generative models</em> such as <em>generative adversarial networks</em>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Undercomplete Autoencoders" data-type="sect1"><div class="sect1" id="idm140637542319120">&#13;
<h1>Undercomplete Autoencoders</h1>&#13;
&#13;
<p>In<a data-primary="autoencoders" data-secondary="undercomplete" data-type="indexterm" id="idm140637542317584"/> the autoencoder, we care most about the encoder because this component is the one that learns a new representation of the original data. This new representation is the new set of features derived from the original set of features and observations.</p>&#13;
&#13;
<p>We will refer to the encoder function of the autoencoder as <em>h = f(x)</em>, which takes in the original observations <em>x</em> and uses the newly learned representation captured in function <em>f</em> to output <em>h</em>. The decoder function that reconstructs the original observations using the encoder function is <em>r = g(h)</em>.</p>&#13;
&#13;
<p>As you can see, the decoder function feeds in the encoder’s output <em>h</em> and reconstructs the observations, known as <em>r</em>, using its reconstruction function <em>g</em>. If done correctly, <em>g(f(x))</em> will not be exactly equal to <em>x</em> everywhere but will be close enough.</p>&#13;
&#13;
<p>How do we restrict the encoder function to approximate <em>x</em> so that it is forced to learn only the most salient properties of <em>x</em> without copying it exactly?</p>&#13;
&#13;
<p>We can constrain the encoder function’s output, <em>h</em>, to have fewer dimensions than <em>x</em>. This is known<a data-primary="undercomplete autoencoders" data-type="indexterm" id="idm140637542308128"/> as an <em>undercomplete</em> autoencoder since the encoder’s dimensions are fewer than the original input dimensions. This is again similar to what happens in dimensionality reduction, where we take in the original input dimensions and reduce them to a much smaller set.</p>&#13;
&#13;
<p>Constrained<a data-primary="loss functions" data-type="indexterm" id="idm140637542306112"/> in this manner, the autoencoder attempts to minimize a <em>loss function</em> we define such that the reconstruction error—after the decoder reconstructs the observations approximately using the encoder’s output—is as small as possible. It is <span class="keep-together">important</span> to realize that the hidden layers are where the dimensions are constrained. In other words, the output of the encoder has fewer dimensions than the original input. But the output of the decoder is the reconstructed original data and, therefore, has the same number of dimensions as the original input.</p>&#13;
&#13;
<p>When the decoder is linear and the loss function is the mean squared error, an undercomplete autoencoder learns the same sort of new representation as PCA, a form of dimensionality reduction we introduced in <a data-type="xref" href="ch03.html#Chapter_3">Chapter 3</a>. However, if the encoder and decoder functions are nonlinear, the autoencoder can learn much more complex nonlinear representations. This is what we care about most. But be warned—if the autoencoder is given too much capacity and latitude to model complex, nonlinear representations, it will simply memorize/copy the original observations instead of extracting the most salient information from them. Therefore, we must restrict the autoencoder meaningfully enough to prevent this from happening.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Overcomplete Autoencoders" data-type="sect1"><div class="sect1" id="idm140637542301552">&#13;
<h1>Overcomplete Autoencoders</h1>&#13;
&#13;
<p>If<a data-primary="autoencoders" data-secondary="overcomplete" data-type="indexterm" id="idm140637542300288"/><a data-primary="overcomplete autoencoders" data-type="indexterm" id="idm140637542299280"/> the encoder learns a representation in a greater number of dimensions than the original input dimensions, the autoencoder is considered <em>overcomplete</em>. Such autoencoders simply copy the original observations and are not forced to efficiently and compactly capture information about the original distribution in a way that undercomplete autoencoders are. That<a data-primary="regularization" data-type="indexterm" id="idm140637542297696"/> being said, if we employ some form of <em>regularization</em>, which penalizes the neural network for learning unnecessarily complex functions, overcomplete autoencoders can be used successfully for dimensionality reduction and automatic feature engineering.</p>&#13;
&#13;
<p>Compared<a data-primary="regularized overcomplete autoencoders" data-type="indexterm" id="idm140637542295856"/> to undercomplete autoeconders, <em>regularized overcomplete autoencoders</em> are harder to design successfully but are potentially more powerful because they can learn more complex—but not overly complex—representations that better approximate the original observations without copying them precisely.</p>&#13;
&#13;
<p>In a nutshell, autoencoders that perform well are those that learn new representations that approximate the original obsevations close enough but not exactly. To do this, the autoencoder essentially learns a new probability distribution.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Dense vs. Sparse Autoencoders" data-type="sect1"><div class="sect1" id="idm140637542293360">&#13;
<h1>Dense vs. Sparse Autoencoders</h1>&#13;
&#13;
<p>If<a data-primary="autoencoders" data-secondary="dense versus sparse autoencoders" data-type="indexterm" id="idm140637542292016"/> you recall, in <a data-type="xref" href="ch03.html#Chapter_3">Chapter 3</a> we had both dense (the normal) and sparse versions of dimensionality reduction algorithms. Autoencoders work similarly. So far, we’ve discussed just the normal autoencoder that outputs a dense final matrix such that a handful of features have the most salient information that has been captured about the original data. However, we may instead want to output a sparse final matrix such that the information captured is more well-distributed across the features that the autoencoder learns.</p>&#13;
&#13;
<p>To<a data-primary="reconstruction error" data-type="indexterm" id="idm140637542288864"/><a data-primary="sparsity penalty" data-type="indexterm" id="idm140637542288128"/> do this, we need to include not just a <em>reconstruction error</em> as part of the autoencoder but also a <em>sparsity penalty</em> so that the autoencoder must take the sparsity of the final matrix into consideration. Sparse autoencoders are generally overcomplete—the hidden layers have more units than the number of input features with the caveat that only a small fraction of the hidden units are allowed to be active at the same time. When<a data-primary="sparse autoencoders" data-type="indexterm" id="idm140637542286128"/> defined in this way, a <em>sparse autoencoder</em> will output a final matrix that has many more zeros embedded throughout and the information captured will be better distributed across the features learned.</p>&#13;
&#13;
<p>For<a data-primary="dense encoders" data-type="indexterm" id="idm140637542284448"/> certain machine learning applications, sparse autoencoders have better performance and also learn somewhat different representations than the normal (dense) autoencoders would. Later, we will work with real examples to see the difference between these two types of autoencoders.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Denoising Autoencoder" data-type="sect1"><div class="sect1" id="idm140637542283040">&#13;
<h1>Denoising Autoencoder</h1>&#13;
&#13;
<p>As<a data-primary="autoencoders" data-secondary="denoising autoencoder" data-type="indexterm" id="idm140637542281744"/><a data-primary="denoising autoencoders" data-secondary="overview of" data-type="indexterm" id="idm140637542280736"/> you know by now, autoencoders are capable of learning new (and improved) representations from the original input data, capturing the most salient elements but <span class="keep-together">disregarding</span> the noise in the original data.</p>&#13;
&#13;
<p>In some cases, we may want the autoencoder we design to more aggressively ignore the noise in the data, especially if we suspect the original data is corrupted to some degree. Imagine recording a conversation between two people at a noisy coffee shop in the middle of the day. We would want to isolate the conversation (the signal) from the background chatter (the noise). Or, imagine a dataset of images that are grainy or distorted due to low resolution or some blurring effect. We want to isolate the core image (the signal) from the distortion (the noise).</p>&#13;
&#13;
<p>For these problems, we can design a <em>denoising autoencoder</em> that receives the corrupted data as input and is trained to output the original, uncorrupted data as best as possible. Of course, while this is not easy to do, this is clearly a very powerful application of autoencoders to solve real-world problems.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Variational Autoencoder" data-type="sect1"><div class="sect1" id="idm140637542276432">&#13;
<h1>Variational Autoencoder</h1>&#13;
&#13;
<p>So<a data-primary="variational autoencoders" data-type="indexterm" id="idm140637542274864"/><a data-primary="autoencoders" data-secondary="variational autoencoders" data-type="indexterm" id="idm140637542274064"/> far, we have discussed the use of autoencoders to learn new representations of the original input data (via the encoder) to minimize the reconstruction error between the newly reconstructed data (via the decoder) and the original input data.</p>&#13;
&#13;
<p>In these examples, the encoder is of a fixed size, <em>n</em>, where <em>n</em> is typically smaller than the number of original dimensions—in other words, we train an undercomplete autoencoder. Or <em>n</em> may be larger than the number of original dimensions—an overcomplete autoencoder—but constrained using a regularization penalty, a sparsity penalty, etc. But in all these cases, the encoder outputs a single vector of a fixed size <em>n</em>.</p>&#13;
&#13;
<p>An alternative autoencoder known as the <em>variational autoencoder</em> has an encoder that outputs two vectors instead of one: a vector of means, <em>mu</em>, and a vector of standard deviations, <em>sigma</em>. These two vectors form random variables such that the <em>ith</em> element of <em>mu</em> and <em>sigma</em> corresponds to the <em>mean</em> and <em>standard deviation</em> of the <em>ith</em> random variable. By forming this stochastic output via its encoder, the variational autoencoder is able to sample across a continuous space based on what it has learned from the input data.</p>&#13;
&#13;
<p>The variational autoencoder is not confined to just the examples it has trained on but can generalize and output new examples even if it may have never seen precisely similar ones before. This is incredibly powerful because now the variational autoencoders can generate new synthetic data that appears to belong in the distribution the variational autoencoder has learned from the original input data. Advances like this have led to an entirely new and trending field in unsupervised learning known as generative modeling, which includes <em>generative adversarial networks</em>. With these models, it is possible to generate synthetic images, speech, music, art, etc., opening up a world of possibilities for AI-generated data.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm140637542263808">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>In this chapter, we introduced neural networks and the popular open source libraries, TensorFlow and Keras. We also explored autoencoders and their ability to learn new representations from original input data. Variations include sparse autoencoders, denoising autoencoders, and variational autoencoders, among others.</p>&#13;
&#13;
<p>In <a data-type="xref" href="ch08.html#Chapter_8">Chapter 8</a>, we will build hands-on applications using the techniques we have discussed in this chapter.</p>&#13;
&#13;
<p>Before we proceed, let’s revisit why<a data-primary="automatic feature extraction, importance of" data-type="indexterm" id="idm140637542259888"/><a data-primary="automatic feature extraction, importance of" data-see="also autoencoders; feature extraction" data-type="indexterm" id="idm140637542259152"/><a data-primary="autoencoders" data-secondary="benefits of" data-type="indexterm" id="idm140637542258112"/> automatic feature extraction is so important. Without the ability to automatically extract features, data scientists and machine learning engineers would have to design by hand features that might be important in solving real-world problems. This is very time-consuming and would dramatically limit progress in the field of AI.</p>&#13;
&#13;
<p>In fact, until Geoffrey Hinton and other researchers developed methods to automatically learn new features using neural networks—launching the deep learning revolution starting in 2006—problems involving computer vision, speech recognition, machine translation, etc., remained largely intractable.</p>&#13;
&#13;
<p>Once autoencoders and other variations of neural networks were used to automatically extract features from input data, a lot of these problems became solvable, leading to some major breakthroughs in machine learning over the past decade.</p>&#13;
&#13;
<p>You will see the power of automatic feature extraction in the hands-on application of autoencoders in <a data-type="xref" href="ch08.html#Chapter_8">Chapter 8</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm140637542452288"><sup><a href="ch07.html#idm140637542452288-marker">1</a></sup> This process is known as regularization.</p><p data-type="footnote" id="idm140637542440736"><sup><a href="ch07.html#idm140637542440736-marker">2</a></sup> For more on TensorFlow, consult the <a href="https://www.tensorflow.org/">website</a>.</p></div></div></section></body></html>