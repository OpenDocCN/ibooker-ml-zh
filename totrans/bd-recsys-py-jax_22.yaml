- en: Chapter 17\. Sequential Recommenders
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬17ç«  é¡ºåºæ¨è
- en: 'In our journey so far, youâ€™ve learned about a variety of features that appear
    as explicit or as latent components in the recommendation problem. One kind of
    feature, which has appeared implicitly, is the history of previous recommendations
    and interactions. You may wish to protest here: â€œAll of the work weâ€™ve done so
    far considers the previous recommendations and interactions! Weâ€™ve even learned
    about prequential training data.â€'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬è¿„ä»Šçš„æ—…ç¨‹ä¸­ï¼Œæ‚¨å·²ç»äº†è§£äº†å‡ºç°åœ¨æ¨èé—®é¢˜ä¸­çš„å„ç§æ˜¾å¼æˆ–æ½œåœ¨çš„ç‰¹å¾ã€‚ä¸€ç§å·²ç»éšå«å‡ºç°çš„ç‰¹å¾æ˜¯ä»¥å‰çš„æ¨èå’Œäº¤äº’å†å²ã€‚æ‚¨å¯èƒ½æƒ³åœ¨è¿™é‡Œæå‡ºå¼‚è®®ï¼šâ€œåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬æ‰€åšçš„æ‰€æœ‰å·¥ä½œéƒ½è€ƒè™‘äº†ä»¥å‰çš„æ¨èå’Œäº¤äº’ï¼æˆ‘ä»¬ç”šè‡³å­¦ä¹ äº†å…³äºé¢„æµ‹è®­ç»ƒæ•°æ®çš„å†…å®¹ã€‚â€
- en: 'That is true, but it fails to account for more explicit relationships between
    the *sequence of recommendations leading up to the inference request*. Letâ€™s look
    at an example to distinguish the two. Your video-streaming website knows that
    youâ€™ve previously seen all of Darren Aronofskyâ€™s films, so when *The Whale* is
    released, the website is very likely to recommend it. But this type of recommendation
    is different from one you might receive after finishing episode 10 of *Succession*.
    You may have been watching Aronofsky films over a long time periodâ€”*Pi* many years
    ago and *Black Swan* earlier this year. But you have been watching an episode
    of *Succession* each night this week, and your entire recent history is made up
    of Logan Roy. This latter example is a sequential recommendation problem: using
    the most recent ordered list of interactions to predict what youâ€™ll enjoy next.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯çœŸçš„ï¼Œä½†å®ƒæœªèƒ½è€ƒè™‘åˆ°å…³äº*å¯¼è‡´æ¨ç†è¯·æ±‚çš„æ¨èåºåˆ—*ä¹‹é—´æ›´æ˜ç¡®çš„å…³ç³»ã€‚è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªä¾‹å­æ¥åŒºåˆ†è¿™ä¸¤è€…ã€‚æ‚¨çš„è§†é¢‘æµç½‘ç«™çŸ¥é“æ‚¨ä»¥å‰çœ‹è¿‡è¾¾ä¼¦Â·é˜¿ä¼¦è¯ºå¤«æ–¯åŸºçš„æ‰€æœ‰ç”µå½±ï¼Œå› æ­¤å½“*The
    Whale*å‘å¸ƒæ—¶ï¼Œè¯¥ç½‘ç«™å¾ˆå¯èƒ½ä¼šæ¨èå®ƒã€‚ä½†è¿™ç§ç±»å‹çš„æ¨èä¸æ‚¨åœ¨è§‚çœ‹*Succession*ç¬¬10é›†ä¹‹åå¯èƒ½æ”¶åˆ°çš„æ¨èä¸åŒã€‚æ‚¨å¯èƒ½å·²ç»åœ¨é•¿æ—¶é—´å†…è§‚çœ‹äº†é˜¿ä¼¦è¯ºå¤«æ–¯åŸºçš„ç”µå½±â€”â€”*Pi*æ˜¯å¤šå¹´å‰ï¼Œ*Black
    Swan*åˆ™æ˜¯ä»Šå¹´æ—©äº›æ—¶å€™ã€‚ä½†æ‚¨æœ¬å‘¨æ¯æ™šéƒ½åœ¨è§‚çœ‹*Succession*çš„ä¸€é›†ï¼Œå¹¶ä¸”æ‚¨æ•´ä¸ªæœ€è¿‘çš„å†å²è®°å½•éƒ½æ˜¯å…³äºæ´›æ ¹Â·ç½—ä¼Šã€‚åä¸€ç§æƒ…å†µæ˜¯ä¸€ä¸ªé¡ºåºæ¨èé—®é¢˜ï¼šæ ¹æ®æœ€è¿‘çš„æœ‰åºäº¤äº’åˆ—è¡¨é¢„æµ‹æ‚¨ä¸‹ä¸€ä¸ªå¯èƒ½å–œæ¬¢çš„å†…å®¹ã€‚
- en: In terms of the modeling objective, the recommenders weâ€™ve seen use pairwise
    relationships between potential recommendations and historical interactions. Sequential
    recommendation aims to predict usersâ€™ next actions based on the sequential interactions
    in the past that may be of much higher *order*â€”i.e., combinations of interactions
    among three or more items. Most sequential recommendation models involve sequential
    data-mining techniques such as Markov chains, recurrent neural networks (RNNs),
    and self-attention. These models usually take into consideration short-term user
    behavior and are less sensitive, even oblivious, to the global user preferences
    that have stabilized over time.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å°±å»ºæ¨¡ç›®æ ‡è€Œè¨€ï¼Œæˆ‘ä»¬æ‰€è§è¿‡çš„æ¨èç³»ç»Ÿä½¿ç”¨äº†æ½œåœ¨çš„æ¨èå’Œå†å²äº¤äº’ä¹‹é—´çš„æˆå¯¹å…³ç³»ã€‚é¡ºåºæ¨èçš„ç›®æ ‡æ˜¯åŸºäºè¿‡å»çš„é¡ºåºäº¤äº’æ¥é¢„æµ‹ç”¨æˆ·çš„ä¸‹ä¸€ä¸ªåŠ¨ä½œï¼Œè¿™äº›äº¤äº’å¯èƒ½æ›´é«˜é˜¶â€”â€”å³ä¸‰ä¸ªæˆ–æ›´å¤šé¡¹ä¹‹é—´çš„äº¤äº’ç»„åˆã€‚å¤§å¤šæ•°é¡ºåºæ¨èæ¨¡å‹æ¶‰åŠé¡ºåºæ•°æ®æŒ–æ˜æŠ€æœ¯ï¼Œå¦‚é©¬å°”å¯å¤«é“¾ã€é€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’Œè‡ªæ³¨æ„åŠ›ã€‚è¿™äº›æ¨¡å‹é€šå¸¸è€ƒè™‘çŸ­æœŸç”¨æˆ·è¡Œä¸ºï¼Œå¯¹éšæ—¶é—´ç¨³å®šçš„å…¨å±€ç”¨æˆ·åå¥½ç”šè‡³æ— è§†ã€‚
- en: Initial work in sequential recommendations focused on modeling the transitions
    between successive items. These used Markov chains and translation-based methods.
    As deep learning methods showed more and more promise in modeling sequential dataâ€”such
    as their biggest success in NLPâ€”there have been many attempts to use neural network
    architectures to model sequential dynamics of a userâ€™s interaction history. Early
    successes in this direction include GRU4Rec using an RNN to model usersâ€™ sequential
    interactions. Recently, transformer architectures have demonstrated superior performance
    for sequential data modeling. The transformer architecture lends itself to efficient
    parallelization and is effective at modeling long-range sequences.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: é¡ºåºæ¨èçš„æœ€åˆå·¥ä½œé›†ä¸­äºå»ºæ¨¡è¿ç»­é¡¹ç›®ä¹‹é—´çš„è¿‡æ¸¡ã€‚è¿™äº›æ–¹æ³•ä½¿ç”¨äº†é©¬å°”å¯å¤«é“¾å’ŒåŸºäºè½¬æ¢çš„æ–¹æ³•ã€‚éšç€æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨å»ºæ¨¡é¡ºåºæ•°æ®æ–¹é¢è¡¨ç°å‡ºè¶Šæ¥è¶Šå¤šçš„æ½œåŠ›â€”â€”ä¾‹å¦‚å®ƒä»¬åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„æœ€å¤§æˆåŠŸâ€”â€”äººä»¬å¼€å§‹å°è¯•ä½¿ç”¨ç¥ç»ç½‘ç»œæ¶æ„æ¥å»ºæ¨¡ç”¨æˆ·äº¤äº’å†å²çš„é¡ºåºåŠ¨æ€ã€‚åœ¨è¿™æ–¹é¢çš„æ—©æœŸæˆåŠŸåŒ…æ‹¬ä½¿ç”¨RNNæ¥æ¨¡æ‹Ÿç”¨æˆ·çš„é¡ºåºäº¤äº’çš„GRU4Recã€‚æœ€è¿‘ï¼Œå˜å‹å™¨æ¶æ„å±•ç¤ºäº†ä¼˜è¶Šçš„é¡ºåºæ•°æ®å»ºæ¨¡æ€§èƒ½ã€‚å˜å‹å™¨æ¶æ„é€‚åˆæœ‰æ•ˆçš„å¹¶è¡ŒåŒ–ï¼Œå¹¶ä¸”åœ¨å»ºæ¨¡é•¿åºåˆ—æ–¹é¢éå¸¸æœ‰æ•ˆã€‚
- en: Markov Chains
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é©¬å°”å¯å¤«é“¾
- en: Despite mining for relationships to historical recommendations, the models weâ€™ve
    been considering often fail to capture sequential patterns in user behavior, thereby
    disregarding the chronological order of user interactions. To address this shortcoming,
    sequential recommender systems were developed, incorporating techniques like Markov
    chains to model the temporal dependencies between items.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡åœ¨å†å²æ¨èä¸­å¯»æ‰¾å…³ç³»ï¼Œæˆ‘ä»¬æ‰€è€ƒè™‘çš„æ¨¡å‹é€šå¸¸æœªèƒ½æ•æ‰ç”¨æˆ·è¡Œä¸ºçš„é¡ºåºæ¨¡å¼ï¼Œå› æ­¤å¿½ç•¥äº†ç”¨æˆ·äº’åŠ¨çš„æ—¶é—´é¡ºåºã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç¼ºç‚¹ï¼Œå¼€å‘äº†é¡ºåºæ¨èç³»ç»Ÿï¼Œå…¶ä¸­åŒ…æ‹¬ä½¿ç”¨é©¬å°”å¯å¤«é“¾ç­‰æŠ€æœ¯æ¥å»ºæ¨¡é¡¹ç›®ä¹‹é—´çš„æ—¶é—´ä¾èµ–å…³ç³»ã€‚
- en: A *Markov chain* is a stochastic model that operates on the principle of *memorylessness*.
    It models the probability of transitioning from one state to anotherâ€”given the
    current stateâ€”without considering the sequence of preceding events. Markov chains
    model the sequential behavior of users by considering each state as an item, and
    the transition probabilities as the likelihood of a user interacting with a certain
    item after the current one.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*é©¬å°”å¯å¤«é“¾*æ˜¯ä¸€ç§éšæœºæ¨¡å‹ï¼ŒåŸºäº*æ— è®°å¿†æ€§*åŸåˆ™è¿ä½œã€‚å®ƒæ¨¡æ‹Ÿäº†ä»ä¸€ä¸ªçŠ¶æ€è½¬ç§»åˆ°å¦ä¸€ä¸ªçŠ¶æ€çš„æ¦‚ç‡â€”â€”åœ¨ç»™å®šå½“å‰çŠ¶æ€çš„æƒ…å†µä¸‹â€”â€”è€Œä¸è€ƒè™‘å…ˆå‰äº‹ä»¶çš„é¡ºåºã€‚é©¬å°”å¯å¤«é“¾é€šè¿‡å°†æ¯ä¸ªçŠ¶æ€è§†ä¸ºä¸€ä¸ªé¡¹ï¼Œå°†è½¬æ¢æ¦‚ç‡è§†ä¸ºç”¨æˆ·åœ¨å½“å‰é¡¹ä¹‹åä¸æŸä¸ªé¡¹äº’åŠ¨çš„å¯èƒ½æ€§ï¼Œæ¥å»ºæ¨¡ç”¨æˆ·çš„é¡ºåºè¡Œä¸ºã€‚'
- en: The first-order Markov chain, in which the future state depends solely on the
    current state, was a common strategy in early sequential recommenders. Despite
    its simplicity, the first-order Markov chain is effective in capturing short-term,
    item-to-item transition patterns, improving the quality of recommendations over
    nonsequential methods.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€é˜¶é©¬å°”å¯å¤«é“¾ï¼Œå³æœªæ¥çŠ¶æ€ä»…ä¾èµ–äºå½“å‰çŠ¶æ€çš„æ¨¡å‹ï¼Œåœ¨æ—©æœŸçš„é¡ºåºæ¨èç³»ç»Ÿä¸­æ˜¯ä¸€ç§å¸¸è§ç­–ç•¥ã€‚å°½ç®¡ç®€å•ï¼Œç¬¬ä¸€é˜¶é©¬å°”å¯å¤«é“¾æœ‰æ•ˆåœ°æ•æ‰åˆ°äº†çŸ­æœŸçš„ã€é¡¹åˆ°é¡¹çš„è½¬æ¢æ¨¡å¼ï¼Œä»è€Œæé«˜äº†æ¨èè´¨é‡ï¼Œè¶…è¿‡äº†éåºåˆ—æ–¹æ³•ã€‚
- en: Take, for example, our preceding *Succession* example. If youâ€™re using only
    a first-order Markov chain, a really great heuristic would be â€œWhat is the next
    episode in the series, if itâ€™s a series; otherwise, fall back on a collaborative
    filtering (CF) model.â€ You can see that for a huge percentage of watch hours,
    this naive first-order chain would simply tell the user to watch the next episode
    of a show. Not particularly enlightening, but a good sign. When you abstract this
    out further, you start to get more powerful methods.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¾ä¾‹æ¥è¯´ï¼Œæˆ‘ä»¬å‰é¢çš„*Succession*ç¤ºä¾‹ã€‚å¦‚æœä»…ä½¿ç”¨ä¸€é˜¶é©¬å°”å¯å¤«é“¾ï¼Œä¸€ä¸ªéå¸¸å¥½çš„å¯å‘å¼æ–¹æ³•æ˜¯â€œå¦‚æœæ˜¯ç³»åˆ—çš„è¯ï¼Œä¸‹ä¸€é›†æ˜¯ä»€ä¹ˆï¼›å¦åˆ™ï¼Œé€€å›åˆ°ååŒè¿‡æ»¤ï¼ˆCFï¼‰æ¨¡å‹ã€‚â€
    ä½ å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äºå¤§éƒ¨åˆ†çš„è§‚çœ‹æ—¶é—´ï¼Œè¿™ä¸ªç®€å•çš„ä¸€é˜¶é“¾ä¼šå‘Šè¯‰ç”¨æˆ·ç®€å•åœ°è§‚çœ‹ç³»åˆ—çš„ä¸‹ä¸€é›†ã€‚è¿™å¹¶ä¸æ˜¯ç‰¹åˆ«å¯å‘å¼ï¼Œä½†æ˜¯æ˜¯ä¸€ä¸ªå¥½è¿¹è±¡ã€‚å½“ä½ è¿›ä¸€æ­¥æŠ½è±¡æ—¶ï¼Œä½ å¼€å§‹å¾—åˆ°æ›´å¼ºå¤§çš„æ–¹æ³•ã€‚
- en: 'The first-order assumption does not always hold in real-world applications,
    as user behavior is often influenced by a longer history of interactions. To overcome
    this limitation, higher-order Markov chains look further back: the next state
    is determined by a set of previous states, providing a richer model of user behavior.
    Nevertheless, itâ€™s crucial to select the appropriate order, as too high an order
    may lead to overfitting and sparsity of the transition matrix.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç¬¬ä¸€é˜¶æ®µçš„å‡è®¾å¹¶ä¸æ€»æ˜¯æˆç«‹ï¼Œå› ä¸ºç”¨æˆ·è¡Œä¸ºé€šå¸¸å—åˆ°è¾ƒé•¿å†å²äº’åŠ¨çš„å½±å“ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é™åˆ¶ï¼Œæ›´é«˜é˜¶çš„é©¬å°”å¯å¤«é“¾å‘å‰çœ‹æ›´è¿œï¼šä¸‹ä¸€ä¸ªçŠ¶æ€ç”±ä¸€ç»„å…ˆå‰çŠ¶æ€å†³å®šï¼Œæä¾›äº†æ›´ä¸°å¯Œçš„ç”¨æˆ·è¡Œä¸ºæ¨¡å‹ã€‚ç„¶è€Œï¼Œé€‰æ‹©é€‚å½“çš„é˜¶æ•°è‡³å…³é‡è¦ï¼Œå› ä¸ºé˜¶æ•°è¿‡é«˜å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆå’Œè½¬ç§»çŸ©é˜µçš„ç¨€ç–æ€§ã€‚
- en: Order-Two Markov Chain
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: äºŒé˜¶é©¬å°”å¯å¤«é“¾
- en: 'Letâ€™s consider an example of an *order-two Markov chain* model using the weather.
    Assume we have three states: sunny ( <math alttext="upper S"><mi>S</mi></math>
    ), cloudy ( <math alttext="upper C"><mi>C</mi></math> ), and rainy ( <math alttext="upper
    R"><mi>R</mi></math> ).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ä¸€ä¸ªå…³äºä½¿ç”¨å¤©æ°”çš„*äºŒé˜¶é©¬å°”å¯å¤«é“¾*æ¨¡å‹çš„ç¤ºä¾‹ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸‰ä¸ªçŠ¶æ€ï¼šæ™´å¤©ï¼ˆ <math alttext="upper S"><mi>S</mi></math>
    ï¼‰ã€å¤šäº‘ï¼ˆ <math alttext="upper C"><mi>C</mi></math> ï¼‰å’Œé›¨å¤©ï¼ˆ <math alttext="upper R"><mi>R</mi></math>
    ï¼‰ã€‚
- en: In an order-two Markov chain, the weather of today ( <math alttext="t"><mi>t</mi></math>
    ) would depend on the weather of yesterday ( <math alttext="t minus 1"><mrow><mi>t</mi>
    <mo>-</mo> <mn>1</mn></mrow></math> ) and the day before yesterday ( <math alttext="t
    minus 2"><mrow><mi>t</mi> <mo>-</mo> <mn>2</mn></mrow></math> ). The transition
    probability can be denoted as <math alttext="upper P left-parenthesis upper S
    Subscript t Baseline vertical-bar upper S Subscript t minus 1 Baseline comma upper
    S Subscript t minus 2 Baseline right-parenthesis"><mrow><mi>P</mi> <mo>(</mo>
    <msub><mi>S</mi> <mi>t</mi></msub> <mo>|</mo> <msub><mi>S</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>,</mo> <msub><mi>S</mi> <mrow><mi>t</mi><mo>-</mo><mn>2</mn></mrow></msub>
    <mo>)</mo></mrow></math> .
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨äºŒé˜¶é©¬å°”å¯å¤«é“¾ä¸­ï¼Œä»Šå¤©çš„å¤©æ°”ï¼ˆ <math alttext="t"><mi>t</mi></math> ï¼‰å°†å–å†³äºæ˜¨å¤©ï¼ˆ <math alttext="t
    minus 1"><mrow><mi>t</mi> <mo>-</mo> <mn>1</mn></mrow></math> ï¼‰å’Œå‰å¤©ï¼ˆ <math alttext="t
    minus 2"><mrow><mi>t</mi> <mo>-</mo> <mn>2</mn></mrow></math> ï¼‰çš„å¤©æ°”ã€‚è½¬ç§»æ¦‚ç‡å¯ä»¥è¡¨ç¤ºä¸º <math
    alttext="upper P left-parenthesis upper S Subscript t Baseline vertical-bar upper
    S Subscript t minus 1 Baseline comma upper S Subscript t minus 2 Baseline right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <msub><mi>S</mi> <mi>t</mi></msub> <mo>|</mo> <msub><mi>S</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>,</mo> <msub><mi>S</mi> <mrow><mi>t</mi><mo>-</mo><mn>2</mn></mrow></msub>
    <mo>)</mo></mrow></math> ã€‚
- en: 'The Markov chain can be defined by a transition matrix that provides the probabilities
    of transitioning from one state to another. However, because weâ€™re dealing with
    an order-two Markov chain, we would have a transition tensor instead. For simplicity,
    letâ€™s say we have the following transition probabilities:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: é©¬å°”å¯å¤«é“¾å¯ä»¥ç”±è½¬ç§»çŸ©é˜µæ¥å®šä¹‰ï¼Œè¯¥çŸ©é˜µæä¾›äº†ä»ä¸€ä¸ªçŠ¶æ€è½¬ç§»åˆ°å¦ä¸€ä¸ªçŠ¶æ€çš„æ¦‚ç‡ã€‚ä½†æ˜¯ï¼Œå› ä¸ºæˆ‘ä»¬å¤„ç†çš„æ˜¯äºŒé˜¶é©¬å°”å¯å¤«é“¾ï¼Œæˆ‘ä»¬å°†æœ‰ä¸€ä¸ªè½¬ç§»å¼ é‡ã€‚ä¸ºç®€å•èµ·è§ï¼Œè®©æˆ‘ä»¬å‡è®¾æˆ‘ä»¬æœ‰ä»¥ä¸‹è½¬ç§»æ¦‚ç‡ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column upper P left-parenthesis upper
    S vertical-bar upper S comma upper S right-parenthesis 2nd Column equals 0.7 comma
    upper P left-parenthesis upper C vertical-bar upper S comma upper S right-parenthesis
    equals 0.2 comma upper P left-parenthesis upper R vertical-bar upper S comma upper
    S right-parenthesis equals 0.1 comma 2nd Row 1st Column upper P left-parenthesis
    upper S vertical-bar upper S comma upper C right-parenthesis 2nd Column equals
    0.3 comma upper P left-parenthesis upper C vertical-bar upper S comma upper C
    right-parenthesis equals 0.4 comma upper P left-parenthesis upper R vertical-bar
    upper S comma upper C right-parenthesis equals 0.3 comma 3rd Row 1st Column Blank
    2nd Column ellipsis EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mrow><mi>P</mi> <mo>(</mo> <mi>S</mi> <mo>|</mo> <mi>S</mi>
    <mo>,</mo> <mi>S</mi> <mo>)</mo></mrow></mtd> <mtd><mrow><mo>=</mo> <mn>0</mn>
    <mo>.</mo> <mn>7</mn> <mo>,</mo> <mi>P</mi> <mo>(</mo> <mi>C</mi> <mo>|</mo> <mi>S</mi>
    <mo>,</mo> <mi>S</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>2</mn> <mo>,</mo>
    <mi>P</mi> <mo>(</mo> <mi>R</mi> <mo>|</mo> <mi>S</mi> <mo>,</mo> <mi>S</mi> <mo>)</mo>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>1</mn> <mo>,</mo></mrow></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><mi>P</mi> <mo>(</mo> <mi>S</mi> <mo>|</mo> <mi>S</mi>
    <mo>,</mo> <mi>C</mi> <mo>)</mo></mrow></mtd> <mtd><mrow><mo>=</mo> <mn>0</mn>
    <mo>.</mo> <mn>3</mn> <mo>,</mo> <mi>P</mi> <mo>(</mo> <mi>C</mi> <mo>|</mo> <mi>S</mi>
    <mo>,</mo> <mi>C</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>4</mn> <mo>,</mo>
    <mi>P</mi> <mo>(</mo> <mi>R</mi> <mo>|</mo> <mi>S</mi> <mo>,</mo> <mi>C</mi> <mo>)</mo>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>3</mn> <mo>,</mo></mrow></mtd></mtr> <mtr><mtd><mo>...</mo></mtd></mtr></mtable></math>
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column upper P left-parenthesis upper
    S vertical-bar upper S comma upper S right-parenthesis 2nd Column equals 0.7 comma
    upper P left-parenthesis upper C vertical-bar upper S comma upper S right-parenthesis
    equals 0.2 comma upper P left-parenthesis upper R vertical-bar upper S comma upper
    S right-parenthesis equals 0.1 comma 2nd Row 1st Column upper P left-parenthesis
    upper S vertical-bar upper S comma upper C right-parenthesis 2nd Column equals
    0.3 comma upper P left-parenthesis upper C vertical-bar upper S comma upper C
    right-parenthesis equals 0.4 comma upper P left-parenthesis upper R vertical-bar
    upper S comma upper C right-parenthesis equals 0.3 comma 3rd Row 1st Column Blank
    2nd Column ellipsis EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mrow><mi>P</mi> <mo>(</mo> <mi>S</mi> <mo>|</mo> <mi>S</mi>
    <mo>,</mo> <mi>S</mi> <mo>)</mo></mrow></mtd> <mtd><mrow><mo>=</mo> <mn>0</mn>
    <mo>.</mo> <mn>7</mn> <mo>,</mo> <mi>P</mi> <mo>(</mo> <mi>C</mi> <mo>|</mo> <mi>S</mi>
    <mo>,</mo> <mi>S</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>2</mn> <mo>,</mo>
    <mi>P</mi> <mo>(</mo> <mi>R</mi> <mo>|</mo> <mi>S</mi> <mo>,</mo> <mi>S</mi> <mo>)</mo>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>1</mn> <mo>,</mo></mrow></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><mi>P</mi> <mo>(</mo> <mi>S</mi> <mo>|</mo> <mi>S</mi>
    <mo>,</mo> <mi>C</mi> <mo>)</mo></mrow></mtd> <mtd><mrow><mo>=</mo> <mn>0</mn>
    <mo>.</mo> <mn>3</mn> <mo>,</mo> <mi>P</mi> <mo>(</mo> <mi>C</mi> <mo>|</mo> <mi>S</mi>
    <mo>,</mo> <mi>C</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>4</mn> <mo>,</mo>
    <mi>P</mi> <mo>(</mo> <mi>R</mi> <mo>|</mo> <mi>S</mi> <mo>,</mo> <mi>C</mi> <mo>)</mo>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>3</mn> <mo>,</mo></mrow></mtd></mtr> <mtr><mtd><mo>...</mo></mtd></mtr></mtable></math>
- en: You can visualize these probabilities in a three-dimensional cube. The first
    two dimensions represent the state of today and yesterday, and the third dimension
    represents the possible states of tomorrow.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨ä¸€ä¸ªä¸‰ç»´ç«‹æ–¹ä½“ä¸­å¯è§†åŒ–è¿™äº›æ¦‚ç‡ã€‚å‰ä¸¤ä¸ªç»´åº¦è¡¨ç¤ºä»Šå¤©å’Œæ˜¨å¤©çš„çŠ¶æ€ï¼Œç¬¬ä¸‰ä¸ªç»´åº¦è¡¨ç¤ºæ˜å¤©çš„å¯èƒ½çŠ¶æ€ã€‚
- en: If the weather was sunny for the last two days and we want to predict the weather
    for tomorrow, we would look at the transition probabilities starting with <math
    alttext="left-parenthesis upper S comma upper S right-parenthesis"><mrow><mo>(</mo>
    <mi>S</mi> <mo>,</mo> <mi>S</mi> <mo>)</mo></mrow></math> , which are <math alttext="upper
    P left-parenthesis upper S vertical-bar upper S comma upper S right-parenthesis
    equals 0.7"><mrow><mi>P</mi> <mo>(</mo> <mi>S</mi> <mo>|</mo> <mi>S</mi> <mo>,</mo>
    <mi>S</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>7</mn></mrow></math>
    , <math alttext="upper P left-parenthesis upper C vertical-bar upper S comma upper
    S right-parenthesis equals 0.2"><mrow><mi>P</mi> <mo>(</mo> <mi>C</mi> <mo>|</mo>
    <mi>S</mi> <mo>,</mo> <mi>S</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>2</mn></mrow></math>
    , and <math alttext="upper P left-parenthesis upper R vertical-bar upper S comma
    upper S right-parenthesis equals 0.1"><mrow><mi>P</mi> <mo>(</mo> <mi>R</mi> <mo>|</mo>
    <mi>S</mi> <mo>,</mo> <mi>S</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>1</mn></mrow></math>
    . Therefore, according to our model, thereâ€™s a 70% chance that it will be sunny,
    a 20% chance that it will be cloudy, and a 10% chance that it will be rainy.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœè¿‡å»ä¸¤å¤©çš„å¤©æ°”æ˜¯æ™´æœ—çš„ï¼Œå¹¶ä¸”æˆ‘ä»¬æƒ³é¢„æµ‹æ˜å¤©çš„å¤©æ°”ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹ä» <math alttext="left-parenthesis upper S comma
    upper S right-parenthesis"><mrow><mo>(</mo> <mi>S</mi> <mo>,</mo> <mi>S</mi> <mo>)</mo></mrow></math>
    å¼€å§‹çš„è½¬ç§»æ¦‚ç‡ï¼Œåˆ†åˆ«æ˜¯ <math alttext="upper P left-parenthesis upper S vertical-bar upper
    S comma upper S right-parenthesis equals 0.7"><mrow><mi>P</mi> <mo>(</mo> <mi>S</mi>
    <mo>|</mo> <mi>S</mi> <mo>,</mo> <mi>S</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo>
    <mn>7</mn></mrow></math> ã€<math alttext="upper P left-parenthesis upper C vertical-bar
    upper S comma upper S right-parenthesis equals 0.2"><mrow><mi>P</mi> <mo>(</mo>
    <mi>C</mi> <mo>|</mo> <mi>S</mi> <mo>,</mo> <mi>S</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn>
    <mo>.</mo> <mn>2</mn></mrow></math> å’Œ <math alttext="upper P left-parenthesis
    upper R vertical-bar upper S comma upper S right-parenthesis equals 0.1"><mrow><mi>P</mi>
    <mo>(</mo> <mi>R</mi> <mo>|</mo> <mi>S</mi> <mo>,</mo> <mi>S</mi> <mo>)</mo> <mo>=</mo>
    <mn>0</mn> <mo>.</mo> <mn>1</mn></mrow></math> ã€‚å› æ­¤ï¼Œæ ¹æ®æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæœ‰ 70% çš„å¯èƒ½æ˜¯æ™´å¤©ï¼Œ20% çš„å¯èƒ½æ˜¯å¤šäº‘ï¼Œ10%
    çš„å¯èƒ½æ˜¯é›¨å¤©ã€‚
- en: The probabilities in the transition matrix (or tensor) are typically estimated
    from data. If you have a historical record of the weather for several years, you
    can count the number of times each transition occurs and divide by the total number
    of transitions to estimate the probability.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è½¬ç§»çŸ©é˜µï¼ˆæˆ–å¼ é‡ï¼‰ä¸­çš„æ¦‚ç‡é€šå¸¸æ˜¯æ ¹æ®æ•°æ®ä¼°è®¡çš„ã€‚å¦‚æœæ‚¨æœ‰å‡ å¹´å¤©æ°”çš„å†å²è®°å½•ï¼Œæ‚¨å¯ä»¥è®¡ç®—æ¯ä¸ªè½¬ç§»å‘ç”Ÿçš„æ¬¡æ•°ï¼Œå¹¶é™¤ä»¥æ€»è½¬ç§»æ¬¡æ•°æ¥ä¼°è®¡æ¦‚ç‡ã€‚
- en: This is only a basic demonstration of an order-two Markov chain. In real applications,
    the states might be much more numerous and the transition matrix much larger,
    but the principles remain the same.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯ä¸€ä¸ªäºŒé˜¶é©¬å°”å¯å¤«é“¾çš„åŸºæœ¬æ¼”ç¤ºã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒçŠ¶æ€å¯èƒ½æ›´å¤šï¼Œè½¬ç§»çŸ©é˜µå¯èƒ½æ›´å¤§ï¼Œä½†åŸåˆ™ä»ç„¶ç›¸åŒã€‚
- en: Other Markov Models
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…¶ä»–é©¬å°”å¯å¤«æ¨¡å‹
- en: A more advanced Markovian approach is the *Markov decision process* (*MDP*),
    which extends the Markov chain by introducing actions and rewards. In the context
    of recommender systems, each action could represent a recommendation, and the
    reward could be the userâ€™s response to the recommendation. By incorporating user
    feedback, the MDP can learn more personalized recommendation strategies.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´é«˜çº§çš„é©¬å°”å¯å¤«æ–¹æ³•æ˜¯*é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹*ï¼ˆ*MDP*ï¼‰ï¼Œé€šè¿‡å¼•å…¥åŠ¨ä½œå’Œå¥–åŠ±æ‰©å±•äº†é©¬å°”å¯å¤«é“¾ã€‚åœ¨æ¨èç³»ç»Ÿçš„èƒŒæ™¯ä¸‹ï¼Œæ¯ä¸ªåŠ¨ä½œå¯ä»¥ä»£è¡¨ä¸€ä¸ªæ¨èï¼Œå¥–åŠ±å¯ä»¥æ˜¯ç”¨æˆ·å¯¹æ¨èçš„å“åº”ã€‚é€šè¿‡æ•´åˆç”¨æˆ·åé¦ˆï¼ŒMDP
    å¯ä»¥å­¦ä¹ æ›´ä¸ªæ€§åŒ–çš„æ¨èç­–ç•¥ã€‚
- en: MDPs are defined by a tuple <math alttext="left-parenthesis upper S comma upper
    A comma upper P comma upper R right-parenthesis"><mrow><mo>(</mo> <mi>S</mi> <mo>,</mo>
    <mi>A</mi> <mo>,</mo> <mi>P</mi> <mo>,</mo> <mi>R</mi> <mo>)</mo></mrow></math>
    , where <math alttext="upper S"><mi>S</mi></math> is the set of states, <math
    alttext="upper A"><mi>A</mi></math> is the set of actions, <math alttext="upper
    P"><mi>P</mi></math> is the state transition probability matrix, and <math alttext="upper
    R"><mi>R</mi></math> is the reward function.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: MDPs è¢«å®šä¹‰ä¸ºä¸€ä¸ªå››å…ƒç»„ <math alttext="left-parenthesis upper S comma upper A comma upper
    P comma upper R right-parenthesis"><mrow><mo>(</mo> <mi>S</mi> <mo>,</mo> <mi>A</mi>
    <mo>,</mo> <mi>P</mi> <mo>,</mo> <mi>R</mi> <mo>)</mo></mrow></math> ï¼Œå…¶ä¸­ <math
    alttext="upper S"><mi>S</mi></math> æ˜¯çŠ¶æ€é›†åˆï¼Œ <math alttext="upper A"><mi>A</mi></math>
    æ˜¯åŠ¨ä½œé›†åˆï¼Œ <math alttext="upper P"><mi>P</mi></math> æ˜¯çŠ¶æ€è½¬ç§»æ¦‚ç‡çŸ©é˜µï¼Œ <math alttext="upper
    R"><mi>R</mi></math> æ˜¯å¥–åŠ±å‡½æ•°ã€‚
- en: 'Letâ€™s use a simplified MDP for a movie recommender system as an example:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»¥ç”µå½±æ¨èç³»ç»Ÿçš„ç®€åŒ–MDPä¸ºä¾‹ï¼š
- en: States ( <math alttext="upper S"><mi>S</mi></math> )
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: çŠ¶æ€ï¼ˆ <math alttext="upper S"><mi>S</mi></math> ï¼‰
- en: 'These could represent the genres of movies a user has watched in the past.
    For simplicity, letâ€™s say we have three states: Comedy ( <math alttext="upper
    C"><mi>C</mi></math> ), Drama ( <math alttext="upper D"><mi>D</mi></math> ), and
    Action ( <math alttext="upper A"><mi>A</mi></math> ).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¯ä»¥ä»£è¡¨ç”¨æˆ·è¿‡å»è§‚çœ‹çš„ç”µå½±ç±»å‹ã€‚ä¸ºç®€å•èµ·è§ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸‰ç§çŠ¶æ€ï¼šå–œå‰§ï¼ˆ <math alttext="upper C"><mi>C</mi></math>
    ï¼‰ã€å‰§æƒ…ç‰‡ï¼ˆ <math alttext="upper D"><mi>D</mi></math> ï¼‰å’ŒåŠ¨ä½œç‰‡ï¼ˆ <math alttext="upper A"><mi>A</mi></math>
    ï¼‰ã€‚
- en: Actions ( <math alttext="upper A"><mi>A</mi></math> )
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ¨ä½œï¼ˆ <math alttext="upper A"><mi>A</mi></math> ï¼‰
- en: 'These could represent the movies that can be recommended. For this example,
    letâ€™s say we have five actions (movies): Movies 1, 2, 3, 4, and 5.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¯ä»¥ä»£è¡¨å¯ä»¥æ¨èçš„ç”µå½±ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å‡è®¾æœ‰äº”ä¸ªåŠ¨ä½œï¼ˆç”µå½±ï¼‰ï¼šç”µå½± 1ã€2ã€3ã€4 å’Œ 5ã€‚
- en: Transition probabilities ( <math alttext="upper P"><mi>P</mi></math> )
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿‡æ¸¡æ¦‚ç‡ï¼ˆ <math alttext="upper P"><mi>P</mi></math> ï¼‰
- en: This represents the likelihood of transitioning from one state to another, given
    a specific action. For instance, if the user just watched a Drama ( <math alttext="upper
    D"><mi>D</mi></math> ) and we recommend Movie 3 (which is an Action movie), the
    transition probability <math alttext="upper P left-parenthesis upper A vertical-bar
    upper D comma upper M o v i e Baseline 3 right-parenthesis"><mrow><mi>P</mi> <mo>(</mo>
    <mi>A</mi> <mo>|</mo> <mi>D</mi> <mo>,</mo> <mi>M</mi> <mi>o</mi> <mi>v</mi> <mi>i</mi>
    <mi>e</mi> <mn>3</mn> <mo>)</mo></mrow></math> might be 0.6, indicating a 60%
    chance the user will watch another Action movie.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¡¨ç¤ºåœ¨ç»™å®šç‰¹å®šåŠ¨ä½œçš„æƒ…å†µä¸‹ï¼Œä»ä¸€ä¸ªçŠ¶æ€è¿‡æ¸¡åˆ°å¦ä¸€ä¸ªçŠ¶æ€çš„å¯èƒ½æ€§ã€‚ä¾‹å¦‚ï¼Œå¦‚æœç”¨æˆ·åˆšçœ‹è¿‡ä¸€éƒ¨å‰§æƒ…ç‰‡ï¼ˆ <math alttext="upper D"><mi>D</mi></math>
    ï¼‰ï¼Œæˆ‘ä»¬æ¨èç”µå½± 3ï¼ˆè¿™æ˜¯ä¸€éƒ¨åŠ¨ä½œç‰‡ï¼‰ï¼Œè¿‡æ¸¡æ¦‚ç‡ <math alttext="upper P left-parenthesis upper A vertical-bar
    upper D comma upper M o v i e Baseline 3 right-parenthesis"><mrow><mi>P</mi> <mo>(</mo>
    <mi>A</mi> <mo>|</mo> <mi>D</mi> <mo>,</mo> <mi>M</mi> <mi>o</mi> <mi>v</mi> <mi>i</mi>
    <mi>e</mi> <mn>3</mn> <mo>)</mo></mrow></math> å¯èƒ½ä¸º 0.6ï¼Œè¡¨ç¤ºç”¨æˆ·å†æ¬¡è§‚çœ‹åŠ¨ä½œç‰‡çš„æ¦‚ç‡ä¸º 60%ã€‚
- en: Rewards ( <math alttext="upper R"><mi>R</mi></math> )
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å¥–åŠ±ï¼ˆ <math alttext="upper R"><mi>R</mi></math> ï¼‰
- en: This is the feedback from the user after taking an action (recommendation).
    Letâ€™s assume for simplicity that a userâ€™s click on a recommended movie gives a
    reward of +1 and no click is a reward of 0.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç”¨æˆ·åœ¨é‡‡å–è¡ŒåŠ¨ï¼ˆæ¨èï¼‰åçš„åé¦ˆã€‚ä¸ºç®€å•èµ·è§ï¼Œå‡è®¾ç”¨æˆ·ç‚¹å‡»æ¨èçš„ç”µå½±ä¼šå¾—åˆ° +1 çš„å¥–åŠ±ï¼Œæ²¡æœ‰ç‚¹å‡»åˆ™ä¸º 0 çš„å¥–åŠ±ã€‚
- en: The aim of the recommender system in this context is to learn a policy <math
    alttext="pi colon upper S right-arrow upper A"><mrow><mi>Ï€</mi> <mo>:</mo> <mi>S</mi>
    <mo>â†’</mo> <mi>A</mi></mrow></math> that maximizes the expected cumulative reward.
    A policy dictates which action the agent (the recommender system) should take
    in each state.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨èç³»ç»Ÿçš„ç›®æ ‡æ˜¯å­¦ä¹ ä¸€ä¸ªç­–ç•¥ <math alttext="pi colon upper S right-arrow upper A"><mrow><mi>Ï€</mi>
    <mo>:</mo> <mi>S</mi> <mo>â†’</mo> <mi>A</mi></mrow></math>ï¼Œä»¥æœ€å¤§åŒ–é¢„æœŸç´¯ç§¯å¥–åŠ±ã€‚ç­–ç•¥æŒ‡å¯¼ä»£ç†ï¼ˆæ¨èç³»ç»Ÿï¼‰åœ¨æ¯ä¸ªçŠ¶æ€ä¸‹åº”è¯¥é‡‡å–çš„è¡ŒåŠ¨ã€‚
- en: This policy can be learned via reinforcement learning algorithms, such as Q-learning
    or policy iteration, which essentially learn the value of taking an action in
    a state (i.e., recommending a movie after the user has watched a certain genre),
    considering the immediate reward and the potential future rewards.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç­–ç•¥å¯ä»¥é€šè¿‡å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå¦‚Q-learningæˆ–ç­–ç•¥è¿­ä»£ï¼‰æ¥å­¦ä¹ ï¼Œè¿™äº›ç®—æ³•æœ¬è´¨ä¸Šæ˜¯å­¦ä¹ åœ¨çŠ¶æ€ä¸­é‡‡å–è¡ŒåŠ¨çš„ä»·å€¼ï¼ˆä¾‹å¦‚ï¼Œåœ¨ç”¨æˆ·è§‚çœ‹æŸç§ç±»å‹ç”µå½±åæ¨èç”µå½±ï¼‰ï¼Œè€ƒè™‘å³æ—¶å¥–åŠ±å’Œæ½œåœ¨çš„æœªæ¥å¥–åŠ±ã€‚
- en: The main challenge in a real-world recommender system scenario is that both
    the state and action spaces are extremely large, and the transition dynamics and
    reward function can be complex and difficult to estimate accurately. But, the
    principles demonstrated in this simple example remain the same.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç°å®ä¸–ç•Œçš„æ¨èç³»ç»Ÿåœºæ™¯ä¸­ï¼Œä¸»è¦æŒ‘æˆ˜åœ¨äºçŠ¶æ€å’ŒåŠ¨ä½œç©ºé—´éƒ½éå¸¸å¤§ï¼Œè€Œè¿‡æ¸¡åŠ¨æ€å’Œå¥–åŠ±å‡½æ•°å¯èƒ½å¤æ‚ä¸”éš¾ä»¥å‡†ç¡®ä¼°è®¡ã€‚ä½†æ˜¯ï¼Œè¿™ä¸ªç®€å•ç¤ºä¾‹ä¸­å±•ç¤ºçš„åŸåˆ™ä¾ç„¶é€‚ç”¨ã€‚
- en: Despite the promising performance of Markov chain-based recommender systems,
    several challenges remain. The *memorylessness* assumption of the Markov chain
    may not hold in certain scenarios where long-term dependencies exist. Furthermore,
    most Markov chain models treat user-item interactions as binary events (either
    interaction or no interaction), which oversimplifies the variety of interactions
    users may have with items, such as browsing, clicking, and purchasing.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡åŸºäºé©¬å°”å¯å¤«é“¾çš„æ¨èç³»ç»Ÿè¡¨ç°å‡ºæœ‰å¸Œæœ›çš„æ€§èƒ½ï¼Œä»ç„¶å­˜åœ¨ä¸€äº›æŒ‘æˆ˜ã€‚é©¬å°”å¯å¤«é“¾çš„*æ— è®°å¿†*å‡è®¾åœ¨å­˜åœ¨é•¿æœŸä¾èµ–å…³ç³»çš„æŸäº›æƒ…æ™¯ä¸­å¯èƒ½ä¸æˆç«‹ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°é©¬å°”å¯å¤«é“¾æ¨¡å‹å°†ç”¨æˆ·-é¡¹ç›®äº¤äº’è§†ä¸ºäºŒè¿›åˆ¶äº‹ä»¶ï¼ˆäº¤äº’æˆ–æ— äº¤äº’ï¼‰ï¼Œè¿™ç®€åŒ–äº†ç”¨æˆ·å¯èƒ½ä¸é¡¹ç›®è¿›è¡Œçš„å„ç§äº¤äº’ï¼Œä¾‹å¦‚æµè§ˆã€ç‚¹å‡»å’Œè´­ä¹°ã€‚
- en: Next, weâ€™ll cover neural networks. Weâ€™ll see how some architectures youâ€™re likely
    familiar with can be relevant to learning a sequential recommender task.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä»‹ç»ç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬å°†çœ‹åˆ°ä½ å¯èƒ½ç†Ÿæ‚‰çš„ä¸€äº›ä½“ç³»ç»“æ„å¦‚ä½•ä¸å­¦ä¹ é¡ºåºæ¨èä»»åŠ¡ç›¸å…³ã€‚
- en: RNN and CNN Architectures
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RNNå’ŒCNNä½“ç³»ç»“æ„
- en: '*Recurrent neural networks* (RNNs) are a type of neural network architecture
    designed to recognize patterns in sequences of data, such as text, speech, or
    time series data. These networks are *recurrent* in that the outputs from one
    step in the sequence are fed back into the network as inputs while processing
    the next step. This gives RNNs a form of memory, which is helpful for tasks like
    language modeling, where each word depends on the previous words.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¾ªç¯ç¥ç»ç½‘ç»œ*ï¼ˆRNNsï¼‰æ˜¯ä¸€ç§è®¾è®¡ç”¨äºè¯†åˆ«æ•°æ®åºåˆ—ä¸­æ¨¡å¼çš„ç¥ç»ç½‘ç»œä½“ç³»ç»“æ„ï¼Œä¾‹å¦‚æ–‡æœ¬ã€è¯­éŸ³æˆ–æ—¶é—´åºåˆ—æ•°æ®ã€‚è¿™äº›ç½‘ç»œåœ¨*å¾ªç¯*ä¸­ï¼Œå³åºåˆ—ä¸­ä¸€ä¸ªæ­¥éª¤çš„è¾“å‡ºè¢«åé¦ˆåˆ°ç½‘ç»œä½œä¸ºä¸‹ä¸€ä¸ªæ­¥éª¤å¤„ç†æ—¶çš„è¾“å…¥ã€‚è¿™èµ‹äºˆäº†RNNsä¸€ç§è®°å¿†å½¢å¼ï¼Œå¯¹äºåƒè¯­è¨€å»ºæ¨¡è¿™æ ·çš„ä»»åŠ¡éå¸¸æœ‰å¸®åŠ©ï¼Œå…¶ä¸­æ¯ä¸ªè¯ä¾èµ–äºå‰é¢çš„è¯ã€‚'
- en: At each time step, an RNN takes in an input (like a word in a sentence) and
    produces an output (like a prediction of the next word). It also updates its internal
    state, which is a representation of what it has â€œseenâ€ last in the sequence. This
    internal state is passed back into the network when processing the next input.
    As a result, the network can use information from previous steps to influence
    its predictions for the current step. This is what allows RNNs to effectively
    process sequential data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ï¼ŒRNNæ¥æ”¶ä¸€ä¸ªè¾“å…¥ï¼ˆä¾‹å¦‚å¥å­ä¸­çš„ä¸€ä¸ªå•è¯ï¼‰å¹¶ç”Ÿæˆä¸€ä¸ªè¾“å‡ºï¼ˆä¾‹å¦‚ä¸‹ä¸€ä¸ªå•è¯çš„é¢„æµ‹ï¼‰ã€‚å®ƒè¿˜æ›´æ–°å†…éƒ¨çŠ¶æ€ï¼Œè¿™æ˜¯å…¶åœ¨åºåˆ—ä¸­â€œçœ‹åˆ°â€çš„å†…å®¹çš„è¡¨ç¤ºã€‚è¿™ä¸ªå†…éƒ¨çŠ¶æ€åœ¨å¤„ç†ä¸‹ä¸€ä¸ªè¾“å…¥æ—¶è¢«ä¼ å›ç½‘ç»œã€‚å› æ­¤ï¼Œç½‘ç»œå¯ä»¥åˆ©ç”¨å…ˆå‰æ­¥éª¤çš„ä¿¡æ¯æ¥å½±å“å½“å‰æ­¥éª¤çš„é¢„æµ‹ã€‚è¿™å°±æ˜¯RNNæœ‰æ•ˆå¤„ç†åºåˆ—æ•°æ®çš„åŸå› ã€‚
- en: '[GRU4Rec](https://oreil.ly/OwEFj) used recurrent neural networks to model session-based
    recommendations in one of the first applications of neural network architectures
    to the recommendation problem. A *session* refers to a single contiguous period
    of user interaction, like time spent on a page without the user navigating away
    or turning off their computer.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[GRU4Rec](https://oreil.ly/OwEFj) ä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œæ¥å»ºæ¨¡åŸºäºä¼šè¯çš„æ¨èï¼Œåœ¨æ¨èé—®é¢˜çš„ç¥ç»ç½‘ç»œä½“ç³»ç»“æ„ä¸­æ˜¯æœ€æ—©çš„åº”ç”¨ä¹‹ä¸€ã€‚*ä¼šè¯*æŒ‡çš„æ˜¯ç”¨æˆ·äº¤äº’çš„å•ä¸€è¿ç»­æœŸé—´ï¼Œä¾‹å¦‚åœ¨é¡µé¢ä¸ŠèŠ±è´¹çš„æ—¶é—´ï¼Œè€Œæ²¡æœ‰ç”¨æˆ·å¯¼èˆªç¦»å¼€æˆ–å…³é—­è®¡ç®—æœºã€‚'
- en: 'Here we will see a dramatic advantage of sequential recommendation systems:
    most traditional recommendation methods rely on an explicit user ID to build a
    user-interest profile. However, session-based recommendations operate over anonymous
    user sessions that are often quite short to allow for a profile modeling. Moreover,
    a lot of variance can occur in user motivations in different sessions. A solution
    via user-agnostic recommendation that works for such recommendation situations
    is an item-based model in which an item-item similarity matrix is calculated based
    on items co-occurring within a single session. This precomputed similarity matrix
    is employed at runtime to recommend the most similar item to the one last clicked.
    This approach has obvious limitations such as relying only on the last clicked
    item. To this end, GRU4Rec uses all the items in the session and models the session
    as a sequence of items. The task of recommending items to be added translates
    to the prediction of the next item in the sequence.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæˆ‘ä»¬å°†çœ‹åˆ°é¡ºåºæ¨èç³»ç»Ÿçš„ä¸€ä¸ªæ˜¾è‘—ä¼˜åŠ¿ï¼šå¤§å¤šæ•°ä¼ ç»Ÿæ¨èæ–¹æ³•ä¾èµ–äºæ˜¾å¼çš„ç”¨æˆ· ID æ¥æ„å»ºç”¨æˆ·å…´è¶£æ¨¡å‹ã€‚ç„¶è€Œï¼ŒåŸºäºä¼šè¯çš„æ¨èç³»ç»Ÿæ“ä½œåŒ¿åç”¨æˆ·ä¼šè¯ï¼Œè¿™äº›ä¼šè¯é€šå¸¸éå¸¸çŸ­ï¼Œä»¥å…è®¸è¿›è¡Œä¸ªäººèµ„æ–™å»ºæ¨¡ã€‚æ­¤å¤–ï¼Œåœ¨ä¸åŒä¼šè¯ä¸­ç”¨æˆ·åŠ¨æœºå¯èƒ½ä¼šæœ‰å¾ˆå¤§çš„å˜åŒ–ã€‚é’ˆå¯¹è¿™ç§æ¨èæƒ…å†µçš„æ— å…³ç”¨æˆ·æ¨èçš„è§£å†³æ–¹æ¡ˆæ˜¯åŸºäºé¡¹ç›®çš„æ¨¡å‹ï¼Œå…¶ä¸­è®¡ç®—äº†åœ¨å•ä¸ªä¼šè¯ä¸­å…±ç°çš„é¡¹ç›®çš„é¡¹ç›®-é¡¹ç›®ç›¸ä¼¼æ€§çŸ©é˜µã€‚è¿™ä¸ªé¢„å…ˆè®¡ç®—çš„ç›¸ä¼¼æ€§çŸ©é˜µåœ¨è¿è¡Œæ—¶ç”¨äºæ¨èæœ€ç›¸ä¼¼çš„ä¸Šä¸€ä¸ªç‚¹å‡»çš„é¡¹ç›®ã€‚è¿™ç§æ–¹æ³•æ˜¾ç„¶æœ‰æ˜æ˜¾çš„å±€é™æ€§ï¼Œæ¯”å¦‚ä»…ä¾èµ–äºæœ€åç‚¹å‡»çš„é¡¹ç›®ã€‚ä¸ºæ­¤ï¼ŒGRU4Rec
    ä½¿ç”¨ä¼šè¯ä¸­çš„æ‰€æœ‰é¡¹ç›®ï¼Œå¹¶å°†ä¼šè¯å»ºæ¨¡ä¸ºé¡¹ç›®åºåˆ—ã€‚æ¨èè¦æ·»åŠ çš„é¡¹ç›®çš„ä»»åŠ¡è½¬åŒ–ä¸ºé¢„æµ‹åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªé¡¹ç›®ã€‚
- en: Unlike the small fixed-size vocabulary of languages, recommendation systems
    are required to reason over a large number of items that grows over time as more
    items are added. To handle this concern, pairwise ranking losses (e.g., BPR) are
    considered. GRU4Rec is further extended in [GRU4Rec+](https://oreil.ly/Y17DB),
    which utilizes a new loss function specifically designed for gains in top-*k*
    recommendation. These loss functions blend deep learning and LTR to address neural
    recommendation settings.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸åŒäºè¯­è¨€çš„å°å›ºå®šå¤§å°è¯æ±‡è¡¨ï¼Œæ¨èç³»ç»Ÿéœ€è¦å¤„ç†éšç€æ·»åŠ æ›´å¤šé¡¹ç›®è€Œé€æ¸å¢é•¿çš„å¤§é‡é¡¹ç›®ã€‚ä¸ºäº†å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œè€ƒè™‘äº†æˆå¯¹æ’åæŸå¤±ï¼ˆä¾‹å¦‚ï¼ŒBPRï¼‰ã€‚GRU4Rec
    è¿›ä¸€æ­¥åœ¨ [GRU4Rec+](https://oreil.ly/Y17DB) ä¸­è¿›è¡Œäº†æ‰©å±•ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨äº†ä¸“é—¨è®¾è®¡ç”¨äºé¡¶éƒ¨ *k* æ¨èå¢ç›Šçš„æ–°æŸå¤±å‡½æ•°ã€‚è¿™äº›æŸå¤±å‡½æ•°èåˆäº†æ·±åº¦å­¦ä¹ å’ŒLTRï¼Œä»¥è§£å†³ç¥ç»æ¨èè®¾ç½®ä¸­çš„é—®é¢˜ã€‚
- en: A different approach to neural networks for recommendations adopted CNNs for
    sequential recommendation. We wonâ€™t cover the basics of CNNs here, but you can
    consult [â€œHow Do Convolutional Neural Networks Work?â€](https://oreil.ly/-jEiE)
    by Brandon Rohrer for the essentials.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºæ¨èçš„ç¥ç»ç½‘ç»œçš„å¦ä¸€ç§æ–¹æ³•é‡‡ç”¨äº†CNNç”¨äºé¡ºåºæ¨èã€‚æˆ‘ä»¬ä¸ä¼šåœ¨è¿™é‡Œä»‹ç»CNNçš„åŸºç¡€çŸ¥è¯†ï¼Œä½†æ‚¨å¯ä»¥å‚è€ƒ Brandon Rohrer çš„ [â€œHow
    Do Convolutional Neural Networks Work?â€](https://oreil.ly/-jEiE) æ¥äº†è§£åŸºæœ¬å†…å®¹ã€‚
- en: 'Letâ€™s discuss one method that has shown a lot of success, [CosRec](https://oreil.ly/wlCdN),
    as visualized in [FigureÂ 17-1](#CosRecImage). This method (and others) starts
    with a structure similar to that of our MF used throughout most of the book: a
    user-item matrix. We assume that there are two latent factor matrices, <math alttext="upper
    E Subscript script upper I"><msub><mi>E</mi> <mi>â„</mi></msub></math> and <math
    alttext="upper E Subscript script upper U"><msub><mi>E</mi> <mi>ğ’°</mi></msub></math>
    , but letâ€™s first focus on the item matrix.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è®¨è®ºä¸€ç§è¡¨ç°å‡ºäº†å¾ˆå¤§æˆåŠŸçš„æ–¹æ³•ï¼Œ[CosRec](https://oreil.ly/wlCdN)ï¼Œå¦‚ [FigureÂ 17-1](#CosRecImage)
    æ‰€ç¤ºã€‚è¿™ç§æ–¹æ³•ï¼ˆåŠå…¶ä»–æ–¹æ³•ï¼‰ä»¥ç±»ä¼¼äºæœ¬ä¹¦å¤§éƒ¨åˆ†å†…å®¹ä¸­ä½¿ç”¨çš„MFç»“æ„å¼€å§‹ï¼šä¸€ä¸ªç”¨æˆ·-é¡¹ç›®çŸ©é˜µã€‚æˆ‘ä»¬å‡è®¾æœ‰ä¸¤ä¸ªæ½œåœ¨å› å­çŸ©é˜µï¼Œ<math alttext="upper
    E Subscript script upper I"><msub><mi>E</mi> <mi>â„</mi></msub></math> å’Œ <math
    alttext="upper E Subscript script upper U"><msub><mi>E</mi> <mi>ğ’°</mi></msub></math>ï¼Œä½†è®©æˆ‘ä»¬é¦–å…ˆå…³æ³¨é¡¹ç›®çŸ©é˜µã€‚
- en: 'Each vector in the item matrix is an embedding vector for a single item, but
    we wish to encode sequences: take sequences of length <math alttext="upper L"><mi>L</mi></math>
    and collect those embedding vectors. We now have an <math alttext="upper L times
    upper D"><mrow><mi>L</mi> <mo>Ã—</mo> <mi>D</mi></mrow></math> matrix with a row
    per each item in the sequence. Take adjacent rows as pairs and concatenate them
    for each vector in a three-tensor; this effectively captures the sequence as a
    series of pairwise transitions. This three-tensor can be passed through a vectorized
    2D CNN to yield a vector (of length <math alttext="upper L"><mi>L</mi></math>
    ) that is concatenated with the original user vector and fed through a fully connected
    layer. Finally, binary cross-entropy is our loss function to attempt to predict
    the best recommendation.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: é¡¹ç›®çŸ©é˜µä¸­çš„æ¯ä¸ªå‘é‡éƒ½æ˜¯å•ä¸ªé¡¹ç›®çš„åµŒå…¥å‘é‡ï¼Œä½†æˆ‘ä»¬å¸Œæœ›ç¼–ç åºåˆ—ï¼šå–é•¿åº¦ä¸º<math alttext="upper L"><mi>L</mi></math>çš„åºåˆ—ï¼Œå¹¶æ”¶é›†è¿™äº›åµŒå…¥å‘é‡ã€‚ç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ª<math
    alttext="upper L times upper D"><mrow><mi>L</mi> <mo>Ã—</mo> <mi>D</mi></mrow></math>çŸ©é˜µï¼Œæ¯ä¸ªåºåˆ—ä¸­çš„é¡¹ç›®éƒ½æœ‰ä¸€è¡Œã€‚å°†ç›¸é‚»è¡Œä½œä¸ºå¯¹ï¼Œå¹¶ä¸ºä¸‰ç»´å¼ é‡ä¸­çš„æ¯ä¸ªå‘é‡è¿æ¥å®ƒä»¬ï¼›è¿™æœ‰æ•ˆåœ°æ•è·äº†åºåˆ—ä½œä¸ºä¸€ç³»åˆ—æˆå¯¹è½¬æ¢ã€‚è¿™ä¸ªä¸‰ç»´å¼ é‡å¯ä»¥é€šè¿‡çŸ¢é‡åŒ–çš„äºŒç»´CNNä¼ é€’ï¼Œç”Ÿæˆä¸€ä¸ªå‘é‡ï¼ˆé•¿åº¦ä¸º<math
    alttext="upper L"><mi>L</mi></math> ï¼‰ï¼Œè¿™ä¸ªå‘é‡ä¸åŸå§‹ç”¨æˆ·å‘é‡è¿æ¥å¹¶é€šè¿‡å®Œå…¨è¿æ¥çš„å±‚ä¼ é€’ã€‚æœ€åï¼ŒäºŒå…ƒäº¤å‰ç†µæ˜¯æˆ‘ä»¬çš„æŸå¤±å‡½æ•°ï¼Œè¯•å›¾é¢„æµ‹æœ€ä½³æ¨èã€‚
- en: '![CosRec CNN Architecture from Yan et. al. 2019](assets/brpj_1701.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![æ¥è‡ªYanç­‰äºº2019å¹´çš„CosRec CNNæ¶æ„](assets/brpj_1701.png)'
- en: Figure 17-1\. CosRec CNN
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾17-1ã€‚CosRec CNN
- en: Attention Architectures
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ³¨æ„åŠ›æ¶æ„
- en: A term that is commonly associated with neural networks and that may ring a
    bell for you by now is *attention*. This is because transformers, in particular
    the kind that appear in large language models (LLMs) like the generalized pretrained
    transformer, have become a central focus among AI users.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªä¸ç¥ç»ç½‘ç»œå¸¸è§ç›¸å…³çš„æœ¯è¯­ï¼Œç°åœ¨å¯èƒ½è®©ä½ æœ‰æ‰€è€³é—»çš„æ˜¯*æ³¨æ„åŠ›*ã€‚è¿™æ˜¯å› ä¸ºå˜å‹å™¨ï¼Œç‰¹åˆ«æ˜¯å‡ºç°åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„é‚£ç§ï¼Œå¦‚å¹¿ä¹‰é¢„è®­ç»ƒå˜å‹å™¨ï¼Œå·²æˆä¸ºäººå·¥æ™ºèƒ½ç”¨æˆ·çš„ä¸­å¿ƒå…³æ³¨ç‚¹ã€‚
- en: We will give an extremely brief, and less technical, introduction to self-attention
    and the transformer here. For a more complete guide on transformers, consult the
    excellent overview in [â€œTransformers from Scratchâ€](https://oreil.ly/4PSx-) by
    Brandon Rohrer.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨è¿™é‡Œæä¾›ä¸€ä¸ªæä¸ºç®€è¦ä¸”ä¸å¤ªæŠ€æœ¯æ€§çš„è‡ªæˆ‘å…³æ³¨å’Œå˜å‹å™¨ä»‹ç»ã€‚è¦äº†è§£æ›´è¯¦ç»†çš„å˜å‹å™¨æŒ‡å—ï¼Œè¯·å‚é˜…Brandon Rohreræ’°å†™çš„ä¼˜ç§€æ¦‚è¿°[â€œä»é›¶å¼€å§‹çš„å˜å‹å™¨â€](https://oreil.ly/4PSx-)ã€‚
- en: 'First, letâ€™s state the key differentiating assumption about a transformer model:
    the embeddings are positional. Weâ€™re hoping to learn not only one embedding for
    every item but also an embedding for every item-position pair. Therefore, when
    an article is the first in a session and the last in a session, those two instances
    are treated as *two separate items*.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬é˜æ˜å…³äºå˜å‹å™¨æ¨¡å‹çš„ä¸€ä¸ªå…³é”®åŒºåˆ«æ€§å‡è®¾ï¼šåµŒå…¥æ˜¯æœ‰ä½ç½®çš„ã€‚æˆ‘ä»¬å¸Œæœ›ä¸ä»…ä¸ºæ¯ä¸ªé¡¹ç›®å­¦ä¹ ä¸€ä¸ªåµŒå…¥ï¼Œè€Œä¸”ä¸ºæ¯ä¸ªé¡¹ç›®-ä½ç½®å¯¹å­¦ä¹ ä¸€ä¸ªåµŒå…¥ã€‚å› æ­¤ï¼Œå½“ä¸€ç¯‡æ–‡ç« æ˜¯ä¼šè¯ä¸­çš„ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªæ—¶ï¼Œè¿™ä¸¤ä¸ªå®ä¾‹è¢«è§†ä¸º*ä¸¤ä¸ªç‹¬ç«‹çš„é¡¹ç›®*ã€‚
- en: Another important notion is stacking. When building transformers, we often think
    of the architecture as a layer cake, with sections stacked on top of one another.
    The key components are the embeddings, the self-attention layer, the skip-addition,
    and the feed-forward layer. The most complicated operations happen in self-attention,
    so letâ€™s focus on that first. We just discussed the positional embeddings, which
    are sent as a sequence of these embedding vectors; recall that a transformer is
    a sequence-to-sequence model! The skip-addition means that we push the embedding
    forward *around* the self-attention layer (and the feed-forward layer above) and
    add it to the positional output of the attention layer. The feed-forward layer
    is an unexciting multilayer perceptron that stays in the positional columns and
    uses a ReLU or GeLU activation.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªé‡è¦çš„æ¦‚å¿µæ˜¯å †å ã€‚åœ¨æ„å»ºå˜å‹å™¨æ—¶ï¼Œæˆ‘ä»¬ç»å¸¸å°†æ¶æ„æƒ³è±¡æˆä¸€å±‚ä¸€å±‚å †å çš„å±‚è›‹ç³•ã€‚å…³é”®ç»„ä»¶åŒ…æ‹¬åµŒå…¥ã€è‡ªæˆ‘å…³æ³¨å±‚ã€è·³è·ƒæ·»åŠ å’Œå‰é¦ˆå±‚ã€‚æœ€å¤æ‚çš„æ“ä½œå‘ç”Ÿåœ¨è‡ªæˆ‘å…³æ³¨ä¸­ï¼Œå› æ­¤è®©æˆ‘ä»¬é¦–å…ˆä¸“æ³¨äºè¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬åˆšåˆšè®¨è®ºäº†ä½ç½®åµŒå…¥ï¼Œå®ƒä»¬è¢«å‘é€ä¸ºè¿™äº›åµŒå…¥å‘é‡çš„åºåˆ—ï¼›è¯·è®°ä½ï¼Œå˜å‹å™¨æ˜¯ä¸€ä¸ªåºåˆ—åˆ°åºåˆ—æ¨¡å‹ï¼è·³è·ƒæ·»åŠ æ„å‘³ç€æˆ‘ä»¬å°†åµŒå…¥å‘å‰*ç¯ç»•*è‡ªæˆ‘å…³æ³¨å±‚ï¼ˆå’Œä¸Šé¢çš„å‰é¦ˆå±‚ï¼‰ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°æ³¨æ„åŠ›å±‚çš„ä½ç½®è¾“å‡ºä¸Šã€‚å‰é¦ˆå±‚æ˜¯ä¸€ä¸ªä¸èµ·çœ¼çš„å¤šå±‚æ„ŸçŸ¥å™¨ï¼Œç•™åœ¨ä½ç½®åˆ—ä¸­ï¼Œå¹¶ä½¿ç”¨ReLUæˆ–GeLUæ¿€æ´»å‡½æ•°ã€‚
- en: ReLU Versus GeLU
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ReLUä¸GeLU
- en: ReLU (Rectified Linear Unit) is an activation function defined as <math alttext="f
    left-parenthesis x right-parenthesis equals max left-parenthesis 0 comma x right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mo form="prefix" movablelimits="true">max</mo>
    <mo>(</mo> <mn>0</mn> <mo>,</mo> <mi>x</mi> <mo>)</mo></mrow></math> . GeLU (Gaussian
    Error Linear Unit) is another activation function approximated as <math alttext="f
    left-parenthesis x right-parenthesis equals 0.5 x left-parenthesis 1 plus hyperbolic
    tangent left-parenthesis StartRoot StartFraction 2 Over pi EndFraction EndRoot
    left-parenthesis x plus 0.044715 x cubed right-parenthesis right-parenthesis right-parenthesis"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mn>0</mn> <mo>.</mo>
    <mn>5</mn> <mi>x</mi> <mfenced close=")" open="(" separators=""><mn>1</mn> <mo>+</mo>
    <mo form="prefix">tanh</mo> <mfenced close=")" open="(" separators=""><msqrt><mfrac><mn>2</mn>
    <mi>Ï€</mi></mfrac></msqrt> <mfenced close=")" open="(" separators=""><mi>x</mi>
    <mo>+</mo> <mn>0</mn> <mo>.</mo> <mn>044715</mn> <msup><mi>x</mi> <mn>3</mn></msup></mfenced></mfenced></mfenced></mrow></math>
    , inspired by the Gaussian cumulative distribution function. The intuition behind
    GeLU is that it tends to allow small values of <math alttext="x"><mi>x</mi></math>
    to pass through while smoothly saturating extreme values, potentially enabling
    better gradient flow for deep models. Both functions introduce nonlinearity in
    neural networks, with GeLU often demonstrating improved learning dynamics over
    ReLU in certain contexts.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ReLUï¼ˆä¿®æ­£çº¿æ€§å•å…ƒï¼‰æ˜¯ä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼Œå®šä¹‰ä¸º<math alttext="f left-parenthesis x right-parenthesis
    equals max left-parenthesis 0 comma x right-parenthesis"><mrow><mi>f</mi> <mo>(</mo>
    <mi>x</mi> <mo>)</mo> <mo>=</mo> <mo form="prefix" movablelimits="true">max</mo>
    <mo>(</mo> <mn>0</mn> <mo>,</mo> <mi>x</mi> <mo>)</mo></mrow></math>ã€‚GeLUï¼ˆé«˜æ–¯è¯¯å·®çº¿æ€§å•å…ƒï¼‰æ˜¯å¦ä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼Œè¿‘ä¼¼ä¸º<math
    alttext="f left-parenthesis x right-parenthesis equals 0.5 x left-parenthesis
    1 plus hyperbolic tangent left-parenthesis StartRoot StartFraction 2 Over pi EndFraction
    EndRoot left-parenthesis x plus 0.044715 x cubed right-parenthesis right-parenthesis
    right-parenthesis"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mi>x</mi> <mfenced close=")" open="("
    separators=""><mn>1</mn> <mo>+</mo> <mo form="prefix">tanh</mo> <mfenced close=")"
    open="(" separators=""><msqrt><mfrac><mn>2</mn> <mi>Ï€</mi></mfrac></msqrt> <mfenced
    close=")" open="(" separators=""><mi>x</mi> <mo>+</mo> <mn>0</mn> <mo>.</mo> <mn>044715</mn>
    <msup><mi>x</mi> <mn>3</mn></msup></mfenced></mfenced></mfenced></mrow></math>ï¼Œå—åˆ°é«˜æ–¯ç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„å¯å‘ã€‚GeLUçš„ç›´è§‰æ˜¯ï¼Œå®ƒå€¾å‘äºè®©å°å€¼çš„<math
    alttext="x"><mi>x</mi></math>é€šè¿‡ï¼ŒåŒæ—¶å¹³æ»‘é¥±å’Œæç«¯å€¼ï¼Œå¯èƒ½ä½¿æ·±åº¦æ¨¡å‹çš„æ¢¯åº¦æµæ›´å¥½ã€‚è¿™ä¸¤ä¸ªå‡½æ•°éƒ½åœ¨ç¥ç»ç½‘ç»œä¸­å¼•å…¥éçº¿æ€§ï¼ŒGeLUåœ¨æŸäº›æƒ…å†µä¸‹é€šå¸¸å±•ç¤ºå‡ºæ¯”ReLUæ›´å¥½çš„å­¦ä¹ åŠ¨æ€ã€‚
- en: 'Here are some quick tips on self-attention:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰å…³äºè‡ªæ³¨æ„åŠ›çš„ä¸€äº›å¿«é€Ÿæç¤ºï¼š
- en: The idea behind self-attention is that everything in the sequence affects everything
    else, in some manner.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è‡ªæ³¨æ„åŠ›èƒŒåçš„æ€æƒ³æ˜¯åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½ä»¥æŸç§æ–¹å¼å½±å“ç€å…¶ä»–æ‰€æœ‰å…ƒç´ ã€‚
- en: The self-attention layer is learning four weight matrices per head.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è‡ªæ³¨æ„åŠ›å±‚æ¯ä¸ªå¤´éƒ¨å­¦ä¹ å››ä¸ªæƒé‡çŸ©é˜µã€‚
- en: The heads are in 1-1 correspondence with the sequence length.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤´éƒ¨ä¸åºåˆ—é•¿åº¦ä¸€ä¸€å¯¹åº”ã€‚
- en: We often call the weight matrices <math alttext="upper Q comma upper K comma
    upper O comma upper V"><mrow><mi>Q</mi> <mo>,</mo> <mi>K</mi> <mo>,</mo> <mi>O</mi>
    <mo>,</mo> <mi>V</mi></mrow></math> . Both <math alttext="upper Q"><mi>Q</mi></math>
    and <math alttext="upper K"><mi>K</mi></math> get crossed with the positional
    embedding, but <math alttext="upper O"><mi>O</mi></math> and <math alttext="upper
    V"><mi>V</mi></math> are first crossed into an embedding-dimension-sized square
    matrix before dotting with the embedding. <math alttext="upper Q ModifyingAbove
    upper E With dot"><mrow><mi>Q</mi> <mover accent="true"><mi>E</mi> <mo>Ë™</mo></mover></mrow></math>
    and <math alttext="upper K ModifyingAbove upper E With dot"><mrow><mi>K</mi> <mover
    accent="true"><mi>E</mi> <mo>Ë™</mo></mover></mrow></math> multiply to create the
    eponymous *attention* matrix, over which we take a row-wise softmax to get the
    attention vector.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç»å¸¸å°†æƒé‡çŸ©é˜µç§°ä¸º<math alttext="upper Q comma upper K comma upper O comma upper V"><mrow><mi>Q</mi>
    <mo>,</mo> <mi>K</mi> <mo>,</mo> <mi>O</mi> <mo>,</mo> <mi>V</mi></mrow></math>ã€‚<math
    alttext="upper Q"><mi>Q</mi></math>å’Œ<math alttext="upper K"><mi>K</mi></math>éƒ½ä¸ä½ç½®åµŒå…¥ç›¸ä¹˜ï¼Œä½†<math
    alttext="upper O"><mi>O</mi></math>å’Œ<math alttext="upper V"><mi>V</mi></math>åœ¨ä¸åµŒå…¥è¿›è¡Œç‚¹ä¹˜ä¹‹å‰é¦–å…ˆè¢«äº¤å‰ä¸ºä¸€ä¸ªåµŒå…¥ç»´åº¦å¤§å°çš„æ–¹é˜µã€‚<math
    alttext="upper Q ModifyingAbove upper E With dot"><mrow><mi>Q</mi> <mover accent="true"><mi>E</mi>
    <mo>Ë™</mo></mover></mrow></math>å’Œ<math alttext="upper K ModifyingAbove upper E
    With dot"><mrow><mi>K</mi> <mover accent="true"><mi>E</mi> <mo>Ë™</mo></mover></mrow></math>ç›¸ä¹˜åˆ›å»ºäº†åŒåçš„*æ³¨æ„*çŸ©é˜µï¼Œæˆ‘ä»¬å¯¹å…¶è¿›è¡Œé€è¡Œsoftmaxæ“ä½œä»¥è·å¾—æ³¨æ„åŠ›å‘é‡ã€‚
- en: Some normalizations exist, but weâ€™ll disregard them as inessential for understanding.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€äº›è§„èŒƒåŒ–å­˜åœ¨ï¼Œä½†æˆ‘ä»¬ä¼šå¿½ç•¥å®ƒä»¬ï¼Œå› ä¸ºå¯¹äºç†è§£æ¥è¯´å¹¶ä¸é‡è¦ã€‚
- en: When we want to speak accurately but briefly about attention, we usually say,
    â€œIt takes a sequence of positional embeddings and mushes them all together to
    learn how theyâ€™re related.â€
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬æƒ³å‡†ç¡®è€Œç®€è¦åœ°è°ˆè®ºæ³¨æ„åŠ›æ—¶ï¼Œé€šå¸¸ä¼šè¯´ï¼šâ€œå®ƒé‡‡ç”¨ä¸€ç³»åˆ—ä½ç½®åµŒå…¥å¹¶å°†å®ƒä»¬å…¨éƒ¨æ··åˆåœ¨ä¸€èµ·ï¼Œä»¥å­¦ä¹ å®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚â€
- en: Self-Attentive Sequential Recommendation
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªæ³¨æ„åŠ›é¡ºåºæ¨è
- en: '[SASRec](https://oreil.ly/aKKzg) is the first transformer model weâ€™ll consider.
    This autoregressive sequential model (similar to a causal language model) predicts
    the next user interaction from past user interactions. Inspired by the success
    of the transformer models in sequential mining tasks, the self-attention-based
    architecture is used for sequential recommendation.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[SASRec](https://oreil.ly/aKKzg)æ˜¯æˆ‘ä»¬å°†è€ƒè™‘çš„ç¬¬ä¸€ä¸ªTransformeræ¨¡å‹ã€‚è¿™ç§è‡ªå›å½’é¡ºåºæ¨¡å‹ï¼ˆç±»ä¼¼äºå› æœè¯­è¨€æ¨¡å‹ï¼‰ä»è¿‡å»çš„ç”¨æˆ·äº’åŠ¨ä¸­é¢„æµ‹ä¸‹ä¸€ä¸ªç”¨æˆ·äº’åŠ¨ã€‚å—Transformeræ¨¡å‹åœ¨é¡ºåºæŒ–æ˜ä»»åŠ¡ä¸­æˆåŠŸçš„å¯å‘ï¼ŒåŸºäºè‡ªæ³¨æ„åŠ›çš„æ¶æ„ç”¨äºé¡ºåºæ¨èã€‚'
- en: When we say that the SASRec model is trained in an autoregressive manner, we
    mean that the self-attention is allowed to attend to only the earlier positions
    in the sequence; looking into the future is not permitted. In terms of the mushing
    we referenced earlier, think of this as only mushing forward the influence. Some
    people call this â€œcausalâ€ because it respects the causal arrow of time. The model
    also allows for a learnable positional encoding, which means that the updates
    carry down to the embedding layer. This model uses two transformer blocks.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬è¯´SASRecæ¨¡å‹æ˜¯ä»¥è‡ªå›å½’æ–¹å¼è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬æŒ‡çš„æ˜¯è‡ªæ³¨æ„åŠ›å…è®¸ä»…å…³æ³¨åºåˆ—ä¸­è¾ƒæ—©çš„ä½ç½®ï¼›ä¸å…è®¸å‘æœªæ¥çœ‹ã€‚åœ¨æˆ‘ä»¬ä¹‹å‰æåˆ°çš„æ··åˆæœ¯è¯­ä¸­ï¼Œå¯ä»¥å°†å…¶è§†ä¸ºä»…å‘å‰æ¨è¿›å½±å“ã€‚æœ‰äº›äººç§°ä¹‹ä¸ºâ€œå› æœâ€ï¼Œå› ä¸ºå®ƒå°Šé‡æ—¶é—´çš„å› æœç®­å¤´ã€‚è¯¥æ¨¡å‹è¿˜å…è®¸å¯å­¦ä¹ çš„ä½ç½®ç¼–ç ï¼Œè¿™æ„å‘³ç€æ›´æ–°ä¼šä¼ é€’åˆ°åµŒå…¥å±‚ã€‚è¯¥æ¨¡å‹ä½¿ç”¨ä¸¤ä¸ªTransformerå—ã€‚
- en: BERT4Rec
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BERT4Rec
- en: Inspired by the BERT model in NLP, [BERT4Rec](https://oreil.ly/SH9ON) improves
    upon SASRec by training a bidirectional masked sequential (language) model.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å—BERTæ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å¯å‘ï¼Œ[BERT4Rec](https://oreil.ly/SH9ON)é€šè¿‡è®­ç»ƒåŒå‘æ©ç é¡ºåºï¼ˆè¯­è¨€ï¼‰æ¨¡å‹æ”¹è¿›äº†SASRecã€‚
- en: 'While BERT uses a masked language model for pretraining word embeddings, BERT4Rec
    uses this architecture to train end-to-end recommendation systems. It tries to
    predict the masked items in the user-interaction sequence. Similar to the original
    BERT model, the self-attention is bidirectional: it can look at both past and
    future interactions in the action sequence. To prevent leakage of future information
    and to emulate the realistic settings, only the last item in the sequence is masked
    during inference. Using item masking, BERT4Rec outperforms SASRec. However, a
    drawback of the BERT4Rec model is that it is quite compute intensive and requires
    much more training time.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶BERTåœ¨é¢„è®­ç»ƒè¯åµŒå…¥æ—¶ä½¿ç”¨æ©ç è¯­è¨€æ¨¡å‹ï¼Œä½†BERT4Recä½¿ç”¨æ­¤æ¶æ„è®­ç»ƒç«¯åˆ°ç«¯çš„æ¨èç³»ç»Ÿã€‚å®ƒè¯•å›¾é¢„æµ‹ç”¨æˆ·äº’åŠ¨åºåˆ—ä¸­çš„æ©ç é¡¹ç›®ã€‚ä¸åŸå§‹BERTæ¨¡å‹ç±»ä¼¼ï¼Œè‡ªæ³¨æ„åŠ›æ˜¯åŒå‘çš„ï¼šå®ƒå¯ä»¥æŸ¥çœ‹è¡ŒåŠ¨åºåˆ—ä¸­çš„è¿‡å»å’Œæœªæ¥äº’åŠ¨ã€‚ä¸ºäº†é˜²æ­¢æœªæ¥ä¿¡æ¯çš„æ³„æ¼å¹¶æ¨¡æ‹ŸçœŸå®çš„è®¾ç½®ï¼Œåœ¨æ¨æ–­è¿‡ç¨‹ä¸­åªæ©ç›–åºåˆ—ä¸­çš„æœ€åä¸€ä¸ªé¡¹ç›®ã€‚ä½¿ç”¨é¡¹ç›®æ©ç ï¼ŒBERT4Recä¼˜äºSASRecã€‚ç„¶è€Œï¼ŒBERT4Recæ¨¡å‹çš„ç¼ºç‚¹æ˜¯è®¡ç®—å¯†é›†å‹ï¼Œéœ€è¦æ›´é•¿çš„è®­ç»ƒæ—¶é—´ã€‚
- en: Recency Sampling
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœ€è¿‘é‡‡æ ·
- en: Sequential recommendation and the adoption of transformer architecture in these
    tasks has seen a lot of interest recently. These deep neural network models like
    BERT4Rec and SASRec have shown improved performance over traditional approaches.
    However, these models suffer from slow training problems. A recently published
    paperâ€”ha ha, get itâ€”addresses the question of improving training efficiency while
    achieving state-of-the-art performance. See [â€œEffective and Efficient Training
    for Sequential Recommendation Using Recency Samplingâ€](https://oreil.ly/yV4ro)
    by Aleksandr Petrov and Craig Macdonald for details.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘ï¼Œé¡ºåºæ¨èå’Œåœ¨è¿™äº›ä»»åŠ¡ä¸­é‡‡ç”¨Transformeræ¶æ„å¼•èµ·äº†å¾ˆå¤§çš„å…´è¶£ã€‚åƒBERT4Recå’ŒSASRecè¿™æ ·çš„æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹æ˜¾ç¤ºå‡ºæ¯”ä¼ ç»Ÿæ–¹æ³•æ›´å¥½çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å­˜åœ¨è®­ç»ƒé€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚æœ€è¿‘å‘è¡¨çš„ä¸€ç¯‡è®ºæ–‡â€”â€”å“ˆå“ˆï¼Œæ˜ç™½äº†å§â€”â€”è§£å†³äº†å¦‚ä½•åœ¨å®ç°æœ€å…ˆè¿›æ€§èƒ½çš„åŒæ—¶æé«˜è®­ç»ƒæ•ˆç‡çš„é—®é¢˜ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚è§Aleksandr
    Petrovå’ŒCraig Macdonaldçš„[â€œä½¿ç”¨æœ€è¿‘é‡‡æ ·è¿›è¡Œé¡ºåºæ¨èçš„æœ‰æ•ˆå’Œé«˜æ•ˆè®­ç»ƒâ€](https://oreil.ly/yV4ro)ã€‚
- en: The two training paradigms weâ€™ve just described for sequential models are autoregressive,
    which tries to predict the next item in the user-interaction sequence, and masked,
    which tries to predict masked items in the interaction sequence. The autoregressive
    approach doesnâ€™t use the beginning of the sequence as labels in the training process,
    and thus valuable information is lost. The masked approach, on the other hand,
    is only weakly related to the end goal of the sequential recommendation.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆšåˆšæè¿°çš„ç”¨äºé¡ºåºæ¨¡å‹çš„ä¸¤ç§è®­ç»ƒèŒƒå¼æ˜¯è‡ªå›å½’å’Œæ©ç ã€‚è‡ªå›å½’è¯•å›¾é¢„æµ‹ç”¨æˆ·äº¤äº’åºåˆ—ä¸­çš„ä¸‹ä¸€é¡¹ï¼Œè€Œæ©ç åˆ™è¯•å›¾é¢„æµ‹äº¤äº’åºåˆ—ä¸­çš„æ©ç é¡¹ã€‚è‡ªå›å½’æ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸ä½¿ç”¨åºåˆ—å¼€å¤´ä½œä¸ºæ ‡ç­¾ï¼Œå› æ­¤ä¸¢å¤±äº†å®è´µçš„ä¿¡æ¯ã€‚å¦ä¸€æ–¹é¢ï¼Œæ©ç æ–¹æ³•ä¸é¡ºåºæ¨èçš„æœ€ç»ˆç›®æ ‡å…³è”è¾ƒå¼±ã€‚
- en: The paper by Petrov and Macdonald proposes a recency-based sampling of positive
    examples from the sequences to build the training data. The sampling is designed
    to give more recent interactions higher chances of being sampled. However, because
    of the probabilistic nature of the sampling mechanism, even the oldest of the
    interactions have nonzero chances of being chosen. An exponential function is
    employed as a sampling routine that interpolates between the masking-based sampling,
    where each interaction has equal probability of being sampled, and autoregressive
    sampling, where items from the end of the sequence are sampled. This showed superior
    performance in sequential recommendation tasks while requiring much less training
    time. Compare this approach to some of the other examples where we saw sampling
    provide significant improvements in training recommender systems!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Petrov å’Œ Macdonald çš„è®ºæ–‡æå‡ºäº†åŸºäºæœ€è¿‘æ€§çš„æ­£ä¾‹é‡‡æ ·ç­–ç•¥ï¼Œç”¨äºæ„å»ºè®­ç»ƒæ•°æ®ã€‚è¯¥é‡‡æ ·è®¾è®¡æ—¨åœ¨ä½¿æœ€è¿‘çš„äº¤äº’å…·æœ‰æ›´é«˜çš„é‡‡æ ·æœºä¼šã€‚ç„¶è€Œï¼Œç”±äºé‡‡æ ·æœºåˆ¶çš„æ¦‚ç‡æ€§è´¨ï¼Œå³ä½¿æ˜¯æœ€è€çš„äº¤äº’ä¹Ÿæœ‰éé›¶çš„è¢«é€‰ä¸­æœºä¼šã€‚é‡‡ç”¨æŒ‡æ•°å‡½æ•°ä½œä¸ºé‡‡æ ·ä¾‹ç¨‹ï¼Œè¯¥å‡½æ•°åœ¨åŸºäºæ©ç çš„é‡‡æ ·ï¼ˆæ¯ä¸ªäº¤äº’å…·æœ‰ç›¸ç­‰çš„è¢«é‡‡æ ·æ¦‚ç‡ï¼‰å’Œè‡ªå›å½’é‡‡æ ·ï¼ˆä»åºåˆ—æœ«å°¾é‡‡æ ·é¡¹ç›®ï¼‰ä¹‹é—´è¿›è¡Œæ’å€¼ã€‚åœ¨é¡ºåºæ¨èä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ï¼ŒåŒæ—¶éœ€è¦è¿œä½äºå¸¸è§„è®­ç»ƒçš„æ—¶é—´ã€‚å°†è¿™ç§æ–¹æ³•ä¸å…¶ä»–é‡‡æ ·å¸¦æ¥æ˜¾è‘—æ”¹è¿›çš„ä¾‹å­è¿›è¡Œæ¯”è¾ƒï¼
- en: Merging Static and Sequential
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆå¹¶é™æ€å’Œé¡ºåº
- en: 'Pinterest recently released [â€œRethinking Personalized Ranking at Pinterest:
    An End-to-End Approachâ€](https://oreil.ly/r_kPN) by Jiajing Xu et al. describing
    its personalized recommendation system, which is built to leverage raw user actions.
    The recommendation task is decomposed into modeling usersâ€™ long-term and short-term
    intentions.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Pinterest æœ€è¿‘å‘å¸ƒäº†ç”± Jiajing Xu ç­‰æ’°å†™çš„[ã€Šåœ¨ Pinterest é‡æ–°æ€è€ƒä¸ªæ€§åŒ–æ’åï¼šä¸€ç§ç«¯åˆ°ç«¯æ–¹æ³•ã€‹](https://oreil.ly/r_kPN)ï¼Œæè¿°äº†å…¶ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨åŸå§‹ç”¨æˆ·è¡Œä¸ºã€‚æ¨èä»»åŠ¡è¢«åˆ†è§£ä¸ºå»ºæ¨¡ç”¨æˆ·é•¿æœŸå’ŒçŸ­æœŸæ„å›¾ã€‚
- en: The process of comprehending long-term user interests is accomplished by training
    an end-to-end embedding model, referred to as PinnerFormer, to learn from a userâ€™s
    historical actions on the platform. These actions are subsequently transformed
    into user embeddings, which are designed for optimization based on anticipated
    long-term future user activities.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è®­ç»ƒä¸€ä¸ªç«¯åˆ°ç«¯åµŒå…¥æ¨¡å‹ PinnerFormer æ¥ç†è§£ç”¨æˆ·çš„é•¿æœŸå…´è¶£ï¼Œè¯¥æ¨¡å‹ä»ç”¨æˆ·åœ¨å¹³å°ä¸Šçš„å†å²è¡Œä¸ºä¸­å­¦ä¹ ã€‚è¿™äº›è¡Œä¸ºéšåè¢«è½¬æ¢ä¸ºç”¨æˆ·åµŒå…¥ï¼Œè®¾è®¡ç”¨äºæ ¹æ®é¢„æœŸçš„é•¿æœŸæœªæ¥ç”¨æˆ·æ´»åŠ¨è¿›è¡Œä¼˜åŒ–ã€‚
- en: This procedure employs an adapted transformer model to operate on usersâ€™ sequential
    actions with the intent to forecast their long-term future activities. Each userâ€™s
    activity is compiled into a sequence, encompassing their actions over a specific
    time window, such as one year. The graph neural networkâ€“based (GNN-based) PinnerSage
    embeddings, in conjunction with relevant metadata (for example, the type of action,
    the timestamp, and so forth), are used to add features to each action in the sequence.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è¿‡ç¨‹åˆ©ç”¨è°ƒæ•´åçš„ Transformer æ¨¡å‹å¤„ç†ç”¨æˆ·çš„é¡ºåºè¡Œä¸ºï¼Œæ—¨åœ¨é¢„æµ‹ä»–ä»¬çš„é•¿æœŸæœªæ¥æ´»åŠ¨ã€‚æ¯ä½ç”¨æˆ·çš„æ´»åŠ¨è¢«ç¼–åˆ¶æˆä¸€ä¸ªåºåˆ—ï¼ŒåŒ…æ‹¬ä»–ä»¬åœ¨ç‰¹å®šæ—¶é—´çª—å£å†…çš„è¡Œä¸ºï¼Œå¦‚ä¸€å¹´ã€‚åŸºäºå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰çš„
    PinnerSage åµŒå…¥ï¼Œç»“åˆç›¸å…³çš„å…ƒæ•°æ®ï¼ˆä¾‹å¦‚è¡Œä¸ºç±»å‹ã€æ—¶é—´æˆ³ç­‰ï¼‰ï¼Œç”¨äºä¸ºåºåˆ—ä¸­çš„æ¯ä¸ªè¡Œä¸ºæ·»åŠ ç‰¹å¾ã€‚
- en: Distinct from traditional sequential modeling tasks and sequential recommendation
    systems, PinnerFormer is designed to predict extended future user activities rather
    than the immediately subsequent action. This objective is achieved by training
    the model to foresee a userâ€™s positive future interactions over a window of 14
    days following the embeddingâ€™s generation. In comparison, traditional sequential
    models would anticipate only the subsequent action.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ä¼ ç»Ÿçš„é¡ºåºå»ºæ¨¡ä»»åŠ¡å’Œé¡ºåºæ¨èç³»ç»Ÿä¸åŒï¼ŒPinnerFormeræ—¨åœ¨é¢„æµ‹å»¶è¿Ÿæœªæ¥çš„ç”¨æˆ·æ´»åŠ¨ï¼Œè€Œä¸æ˜¯ç«‹å³åç»­çš„åŠ¨ä½œã€‚é€šè¿‡è®­ç»ƒæ¨¡å‹åœ¨ç”ŸæˆåµŒå…¥åçš„14å¤©çª—å£å†…é¢„è§ç”¨æˆ·çš„ç§¯ææœªæ¥äº’åŠ¨æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä¼ ç»Ÿçš„é¡ºåºæ¨¡å‹åªä¼šé¢„æœŸä¸‹ä¸€ä¸ªåŠ¨ä½œã€‚
- en: This alternate approach allows for the embedding generation to occur offline
    in a batch-processing mode, resulting in significant reductions in infrastructure
    needs. In contrast to most traditional sequential modeling systems, which operate
    in real time and incur substantial computational and infrastructure costs, these
    embeddings can be produced in batches (for instance, on a daily basis) rather
    than every time a user performs an action.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ›¿ä»£æ–¹æ³•å…è®¸åµŒå…¥ç”Ÿæˆä»¥ç¦»çº¿æ‰¹å¤„ç†æ¨¡å¼è¿›è¡Œï¼Œä»è€Œæ˜¾è‘—å‡å°‘äº†åŸºç¡€è®¾æ–½éœ€æ±‚ã€‚ä¸å¤§å¤šæ•°ä¼ ç»Ÿçš„å®æ—¶é¡ºåºå»ºæ¨¡ç³»ç»Ÿç›¸æ¯”ï¼Œåè€…è¿è¡Œæˆæœ¬é«˜æ˜‚ï¼Œéœ€è¦å¤§é‡è®¡ç®—å’ŒåŸºç¡€è®¾æ–½æ”¯æŒï¼Œè¿™äº›åµŒå…¥å¯ä»¥æ‰¹é‡ç”Ÿæˆï¼ˆä¾‹å¦‚ï¼Œæ¯å¤©ä¸€æ¬¡ï¼‰ï¼Œè€Œä¸æ˜¯æ¯æ¬¡ç”¨æˆ·æ‰§è¡ŒåŠ¨ä½œæ—¶éƒ½ç”Ÿæˆã€‚
- en: A dense all-action loss is introduced in this methodology to facilitate batch
    training of the model. The objective here is not to predict the immediate next
    action but rather all the actions the user will undertake over the subsequent
    <math alttext="k"><mi>k</mi></math> days. The aim is to predict all occurrences
    of a userâ€™s positive interactions at intervals such as <math alttext="upper T
    plus 3"><mrow><mi>T</mi> <mo>+</mo> <mn>3</mn></mrow></math> , <math alttext="upper
    T plus 8"><mrow><mi>T</mi> <mo>+</mo> <mn>8</mn></mrow></math> , and <math alttext="upper
    T plus 12"><mrow><mi>T</mi> <mo>+</mo> <mn>12</mn></mrow></math> , thereby compelling
    the system to learn long-term intentions. While traditionally the last actionâ€™s
    embedding is used to make the prediction, the dense all-action loss employs randomly
    selected positions in the action sequence, and the corresponding embedding is
    used to predict all actions for each of those positions.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–¹æ³•è®ºå¼•å…¥äº†å¯†é›†å…¨åŠ¨ä½œæŸå¤±ï¼Œä»¥ä¾¿æ‰¹é‡è®­ç»ƒæ¨¡å‹ã€‚è¿™é‡Œçš„ç›®æ ‡ä¸æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ªå³æ—¶åŠ¨ä½œï¼Œè€Œæ˜¯é¢„æµ‹ç”¨æˆ·åœ¨æ¥ä¸‹æ¥çš„ <math alttext="k"><mi>k</mi></math>
    å¤©å†…å°†æ‰§è¡Œçš„æ‰€æœ‰åŠ¨ä½œã€‚å…¶ç›®çš„æ˜¯é¢„æµ‹ç”¨æˆ·åœ¨é—´éš”å¦‚ <math alttext="upper T plus 3"><mrow><mi>T</mi> <mo>+</mo>
    <mn>3</mn></mrow></math> ã€<math alttext="upper T plus 8"><mrow><mi>T</mi> <mo>+</mo>
    <mn>8</mn></mrow></math> å’Œ <math alttext="upper T plus 12"><mrow><mi>T</mi> <mo>+</mo>
    <mn>12</mn></mrow></math> çš„æ‰€æœ‰ç§¯æäº’åŠ¨ï¼Œä»è€Œä¿ƒä½¿ç³»ç»Ÿå­¦ä¹ é•¿æœŸæ„å›¾ã€‚è™½ç„¶ä¼ ç»Ÿä¸Šä¼šä½¿ç”¨æœ€åä¸€ä¸ªåŠ¨ä½œçš„åµŒå…¥æ¥è¿›è¡Œé¢„æµ‹ï¼Œä½†å¯†é›†å…¨åŠ¨ä½œæŸå¤±ä¼šåœ¨åŠ¨ä½œåºåˆ—ä¸­éšæœºé€‰æ‹©ä½ç½®ï¼Œå¹¶ä½¿ç”¨ç›¸åº”çš„åµŒå…¥æ¥é¢„æµ‹æ¯ä¸ªä½ç½®çš„æ‰€æœ‰åŠ¨ä½œã€‚
- en: Based on offline and online experimental results, the use of dense all-action
    loss to train for long-term user actions has significantly bridged the gap between
    batch generation and real-time generation of user embeddings. Moreover, to accommodate
    usersâ€™ short-term interests, the transformer model retrieves the most recent actions
    for each user in real time, processing them along with the long-term user embeddings.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºçº¿ä¸‹å’Œçº¿ä¸Šå®éªŒç»“æœï¼Œä½¿ç”¨å¯†é›†å…¨åŠ¨ä½œæŸå¤±æ¥è®­ç»ƒé•¿æœŸç”¨æˆ·è¡Œä¸ºæ˜¾è‘—åœ°å¼¥åˆäº†æ‰¹å¤„ç†ç”Ÿæˆå’Œç”¨æˆ·åµŒå…¥å®æ—¶ç”Ÿæˆä¹‹é—´çš„å·®è·ã€‚æ­¤å¤–ï¼Œä¸ºäº†é€‚åº”ç”¨æˆ·çš„çŸ­æœŸå…´è¶£ï¼Œå˜å‹å™¨æ¨¡å‹å®æ—¶æ£€ç´¢æ¯ä¸ªç”¨æˆ·çš„æœ€æ–°åŠ¨ä½œï¼Œå°†å…¶ä¸é•¿æœŸç”¨æˆ·åµŒå…¥ä¸€èµ·å¤„ç†ã€‚
- en: Summary
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: 'Transformers and sequential recommendation systems are really at the cutting
    edge of modern recommenders. These days, most research in recommendation systems
    is in the area of sequential datasets, and the hottest recommenders are using
    longer and longer sequences for prediction. Two important projects are worthy
    of attention:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Transformerså’Œé¡ºåºæ¨èç³»ç»Ÿç¡®å®å¤„äºç°ä»£æ¨èç³»ç»Ÿçš„å‰æ²¿ã€‚å¦‚ä»Šï¼Œå¤§å¤šæ•°æ¨èç³»ç»Ÿçš„ç ”ç©¶é›†ä¸­åœ¨é¡ºåºæ•°æ®é›†é¢†åŸŸï¼Œæœ€çƒ­é—¨çš„æ¨èç³»ç»Ÿä½¿ç”¨è¶Šæ¥è¶Šé•¿çš„åºåˆ—è¿›è¡Œé¢„æµ‹ã€‚æœ‰ä¸¤ä¸ªé‡è¦çš„é¡¹ç›®å€¼å¾—å…³æ³¨ï¼š
- en: Transformers4Rec
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers4Rec
- en: 'This open source project is geared toward scalable transformer models by the
    NVIDIA Merlin team. For more details, see [â€œTransformers4Rec: Bridging the Gap
    Between NLP and Sequential/Session-Based Recommendationâ€](https://oreil.ly/jwWBq)
    by Gabriel de Souza Pereira Moreira et al.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥å¼€æºé¡¹ç›®ç”±NVIDIA Merlinå›¢é˜Ÿè®¾è®¡çš„å¯æ‰©å±•å˜å‹å™¨æ¨¡å‹ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…Gabriel de Souza Pereira Moreiraç­‰äººçš„
    [â€œTransformers4Recï¼šåœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œé¡ºåº/ä¼šè¯å¼æ¨èä¹‹é—´æ¶èµ·çš„æ¡¥æ¢â€](https://oreil.ly/jwWBq) ã€‚
- en: Monolith
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Monolith
- en: 'Also known as the TikTok For You page recommender, this is one of the most
    popular and exciting recommendation systems at this time. It is a fundamentally
    sequential recommender, with some elegant hybrid approaches. [â€œMonolith: Real-Time
    Recommendation System with Collisionless Embedding Tableâ€](https://oreil.ly/EADgK)
    by Zhuoran Liu et al. covers the architectural considerations.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä¹Ÿè¢«ç§°ä¸º TikTok For You é¡µé¢æ¨èç³»ç»Ÿï¼Œè¿™æ˜¯å½“å‰æœ€å—æ¬¢è¿å’Œä»¤äººå…´å¥‹çš„æ¨èç³»ç»Ÿä¹‹ä¸€ã€‚å®ƒæ˜¯ä¸€ç§åŸºæœ¬çš„åºè´¯æ¨èç³»ç»Ÿï¼Œå…·æœ‰ä¸€äº›ä¼˜é›…çš„æ··åˆæ–¹æ³•ã€‚[â€œMonolith:
    å®æ—¶æ¨èç³»ç»Ÿä¸æ— ç¢°æ’åµŒå…¥è¡¨â€](https://oreil.ly/EADgK) ç”±åˆ˜å“ç„¶ç­‰äººæ’°å†™ï¼Œæ¶µç›–äº†æ¶æ„ä¸Šçš„è€ƒè™‘ã€‚'
- en: Our final step before this book concludes is to consider a few approaches to
    recommendations. These donâ€™t build exactly on top of what weâ€™ve done but will
    use some of what weâ€™ve done and introduce a few new ideas. Letâ€™s sprint to the
    finish!
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ä¹¦ç»“æŸä¹‹å‰ï¼Œæˆ‘ä»¬çš„æœ€åä¸€æ­¥æ˜¯è€ƒè™‘ä¸€äº›æ¨èæ–¹æ³•ã€‚è¿™äº›æ–¹æ³•å¹¶ä¸å®Œå…¨å»ºç«‹åœ¨æˆ‘ä»¬å·²ç»åšè¿‡çš„åŸºç¡€ä¸Šï¼Œä½†ä¼šåˆ©ç”¨æˆ‘ä»¬å·²ç»åšè¿‡çš„ä¸€äº›å·¥ä½œï¼Œå¹¶å¼•å…¥ä¸€äº›æ–°çš„æƒ³æ³•ã€‚è®©æˆ‘ä»¬å†²åˆºåˆ°ç»ˆç‚¹å§ï¼
