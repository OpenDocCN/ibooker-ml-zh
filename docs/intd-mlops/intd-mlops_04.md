# 第三章：MLOps 的关键特性

Mark Treveil

MLOps 影响组织中许多不同的角色，反过来又影响机器学习生命周期的许多部分。本章以高层次介绍 MLOps 的五个关键组成部分（开发、部署、监控、迭代和治理），作为第四章至第八章的基础，这些章节深入探讨了这些组成部分的技术细节和要求。

# 机器学习入门

要理解 MLOps 的关键特性，首先必须了解机器学习的工作原理，并熟悉其特定性。尽管作为 MLOps 的一部分经常被忽视，但算法选择（或者说机器学习模型的构建方式）最终可以直接影响 MLOps 的流程。

机器学习的核心是计算机算法的科学，这些算法能够从经验中自动学习和改进，而不是被明确地程序化。这些算法分析样本数据（称为训练数据），构建能够进行预测的软件模型。

例如，图像识别模型可以通过搜索图像中区分每种电表的关键模式来识别电表类型。另一个例子是保险推荐模型，它可能根据类似客户的先前行为，建议现有特定客户最有可能购买的附加保险产品。

面对未见数据，无论是照片还是客户，ML 模型利用其从先前数据学到的知识进行预测，假设未见数据与先前数据有某种关联，以此做出最佳预测。

ML 算法使用各种数学技术，模型可以采用多种不同的形式，从简单的决策树到逻辑回归算法，再到更复杂的深度学习模型（详情见“什么是机器学习模型？”）。

# 模型开发

让我们更深入地了解整个 ML 模型开发过程，以便更全面地理解其各个组成部分，所有这些部分在部署后都可能对 MLOps 产生影响。

## 建立业务目标

开发机器学习模型的过程通常从业务目标开始，可以简单到将欺诈交易降低到小于 0.1%，或者具备识别社交媒体照片上人物面部的能力。业务目标自然伴随着性能目标、技术基础设施要求和成本约束；所有这些因素都可以作为关键绩效指标（KPI），最终能够监控在生产中模型的业务表现。

重要的是要认识到，机器学习项目不是孤立进行的。它们通常是更大项目的一部分，反过来又影响技术、流程和人员。这意味着建立目标的一部分还包括变更管理，这甚至可能为如何构建机器学习模型提供一些指导。例如，所需的透明度程度将强烈影响算法选择，并可能推动提供预测及解释的需要，以便将预测转化为业务层面的有价值决策。

## 数据来源与探索性数据分析

在明确业务目标的情况下，是时候邀请领域专家和数据科学家一起开始开发机器学习模型的旅程了。这从寻找合适的输入数据开始。寻找数据听起来简单，但在实践中，这可能是旅程中最艰难的部分。

寻找构建机器学习模型所需数据的关键问题包括：

+   有哪些相关数据集可用？

+   这些数据是否足够准确可靠？

+   利益相关者如何获取这些数据？

+   通过结合多个数据源，可以获取哪些数据属性（称为*特征*）？

+   这些数据是否可以实时获取？

+   是否需要使用“地面真实性”标记一些数据，或者无监督学习是否合理？如果是，这将在时间和资源方面造成多大成本？

+   应该使用什么平台？

+   模型部署后数据如何更新？

+   模型本身的使用是否会降低数据的代表性？

+   与业务目标一起建立的关键绩效指标（KPI），如何进行度量？

数据治理的限制带来了更多问题，包括：

+   选定的数据集能否用于此目的？

+   使用条款是什么？

+   是否有必要对必须被删除或匿名化的个人身份信息（PII）进行处理？

+   是否有法律上不能在此业务背景下使用的特征，比如性别？

+   少数族群的代表性是否足够，使模型在每个群体上表现等效？

由于数据是驱动机器学习算法的基本成分，因此在尝试训练模型之前，建立对数据模式的理解总是有帮助的。探索性数据分析（EDA）技术可以帮助建立关于数据的假设，识别数据清理需求，并指导选择可能重要的特征的过程。EDA 可以通过可视化进行直观洞察，如果需要更严谨，则可以进行统计分析。

## 特征工程与选择

EDA 自然地引导到特征工程和特征选择。特征工程是将来自选定数据集的原始数据转化为更好地代表待解决问题的“特征”的过程。“特征”是固定大小的数字数组，因为这是 ML 算法唯一理解的对象。特征工程包括数据清洗，这可能是 ML 项目中时间消耗最大的部分。详情请参阅“特征工程与选择”。

## 训练与评估

在通过特征工程和选择准备数据之后，下一步是训练。训练和优化新的 ML 模型的过程是迭代的；可以测试多种算法，可以自动生成特征，可以调整特征选择，可以调整算法超参数。除了或者说正是因为其迭代的性质，训练也是 ML 模型生命周期中在计算能力方面最为密集的步骤。

在迭代过程中跟踪每个实验的结果变得非常复杂。对数据科学家来说，没有能力重新创建最佳结果是非常令人沮丧的，因为他们无法记住精确的配置。实验跟踪工具可以极大简化记忆数据、特征选择和模型参数以及性能指标的过程。这些使得可以并列比较实验，突显性能上的差异。

决定最佳解决方案需要定量标准（如准确率或平均误差）和关于算法可解释性或部署易用性的定性标准。

## 可重复性

虽然许多实验可能是短暂的，但模型的重要版本需要保存以备可能的后续使用。这里的挑战是可重复性，这是实验科学中一个重要的概念。在机器学习中，目标是保存关于模型开发环境的足够信息，以便可以从头开始复制模型并得到相同的结果。

没有可重复性，数据科学家很难自信地迭代模型，更糟糕的是，他们不太可能将模型交给 DevOps，看看实验室中创建的内容是否能够在生产中忠实地复制。真正的可重复性需要对所有涉及的资产和参数进行版本控制，包括用于训练和评估模型的数据，以及软件环境的记录（详见“版本管理与可重复性”）。

## 负责任的 AI

能够复现模型只是操作化挑战的一部分；DevOps 团队还需要理解如何验证模型（即模型的作用是什么，如何进行测试，预期结果是什么？）。那些处于高度监管行业的人可能需要记录更多的细节，包括模型的构建过程和调优过程。在关键情况下，模型可能会被独立重新编码和重建。

文档仍然是解决这种沟通挑战的标准方案。自动化模型文档生成，即工具自动创建与任何训练模型相关的文档，可以减少工作负担。但在几乎所有情况下，仍需手工编写一些文档来解释所做的选择。

ML 模型由于其统计性质的基本特性，难以理解是其一个基本结果。虽然模型算法配备了标准性能指标来评估其效果，但这些指标并不能解释预测是如何做出的。理解“如何”对于检查模型或帮助更好地设计特征非常重要，并且可能需要确保已满足公平性要求（例如性别、年龄或种族等特征）。这是解释性的领域，与负责任的人工智能（如第一章所讨论的那样），并将在第四章中进一步详细讨论。

随着全球对无限制 AI 影响的关注增加，解释性技术变得越来越重要。它们提供了减少不确定性和帮助预防意外后果的方法。目前最常用的技术包括：

+   部分依赖图，研究特征对预测结果的边际影响。

+   子群体分析，即分析模型如何处理特定子群体的分析，这是许多公平性分析的基础。

+   个体模型预测，例如[Shapley 值](https://oreil.ly/OC8OK)，解释每个特征值如何影响特定预测。

+   假设分析，帮助 ML 模型用户理解预测对其输入的敏感性。

正如我们在本节中所见，即使模型开发非常早期，仍然是一个重要的地方来融合 MLOps 实践。在模型开发阶段进行的任何 MLOps 工作将使模型在后续更易管理（特别是推向生产时）。

# 生产化和部署

将模型推向生产并部署是 MLOps 的关键组成部分，它面临与开发模型完全不同的一组技术挑战。这是软件工程师和 DevOps 团队的领域，管理数据科学家与这些团队之间信息交流的组织挑战不容小觑。正如在第一章中提到的，如果团队之间缺乏有效的协作，推迟或部署失败是不可避免的。

## 模型部署类型和内容

要了解这些阶段中发生了什么，有助于退后一步并问一问：究竟要投入生产的是什么，模型由什么组成？通常有两种类型的模型部署：

模型即服务，或实时评分模型

通常模型会部署到一个简单的框架中，以提供 REST API 端点（API 访问资源所需执行任务的方式），实时响应请求。

嵌入式模型

在这里，模型被打包成一个应用程序，然后发布。一个常见的例子是提供批处理请求的应用程序。

被部署的模型包含的内容取决于所选择的技术，但通常包括一组代码（通常是 Python、R 或 Java）和数据工件。其中任何一个都可能对运行时和软件包有版本依赖性，需要与生产环境中匹配，因为使用不同版本可能会导致模型预测不同。

降低对生产环境依赖的一种方法是将模型导出为便携格式，如 PMML、PFA、ONNX 或 POJO。这些旨在提高系统间模型的可移植性并简化部署。然而，它们也带来了一些成本：每种格式只支持有限的算法范围，有时便携模型的行为与原始模型略有不同。是否使用便携格式应基于对技术和业务背景的深入理解做出选择。

## 模型部署要求

那么在完成模型开发和物理部署之间的生产过程中，需要解决哪些问题呢？有一件事是确定的：快速、自动化的部署始终优于繁重的过程。

对于短寿命周期、自助式应用，通常不需要太担心测试和验证。如果可以通过诸如 Linux cgroups 之类的技术安全地限制模型的最大资源需求，那么完全自动化的单步推送至生产环境可能完全足够。在使用这种轻量级部署模式时，甚至可以通过像 Flask 这样的框架处理简单的用户界面。除了集成数据科学和机器学习平台外，一些业务规则管理系统也可能允许基本 ML 模型的某种自主部署。

在面向客户、任务关键的使用案例中，需要一个更强大的 CI/CD 流水线。这通常包括：

1.  确保所有编码、文档和签署标准都得到满足

1.  在接近生产环境中重新创建模型

1.  重新验证模型的准确性

1.  执行可解释性检查

1.  确保满足所有治理要求

1.  检查任何数据工件的质量

1.  在负载下测试资源使用情况

1.  嵌入到更复杂的应用程序中，包括集成测试

在严格管制的行业（例如金融和制药业），治理和监管检查将会非常严格，并且可能需要手动干预。MLOps 的愿望与 DevOps 一样，就是尽可能地自动化 CI/CD 流水线。这不仅加快了部署过程，还能进行更广泛的回归测试，并减少部署中出错的可能性。

# 监控

一旦模型部署到生产环境中，它能够持续良好地运行至关重要。但良好的性能对不同的人意味着不同的事情，特别是对 DevOps 团队、数据科学家和业务而言。

## DevOps 的关注点

DevOps 团队的关注点非常熟悉，包括诸如：

+   模型是否能够快速完成工作？

+   它是否在合理的内存和处理时间范围内运行？

这是传统的 IT 性能监控，而 DevOps 团队已经知道如何做得很好了。在这方面，ML 模型的资源需求与传统软件并没有太大的不同。

计算资源的可扩展性可能是一个重要考虑因素，例如，如果你正在生产环境中重新训练模型。深度学习模型比简单的决策树具有更高的资源需求。但总体而言，DevOps 团队在监控和管理资源方面的现有专业知识可以轻松应用于 ML 模型。

## 数据科学家的关注点

数据科学家对监控 ML 模型感兴趣是出于一个更具挑战性的原因：它们可能会随时间而退化，因为 ML 模型实际上是对它们训练数据的模型。这不是传统软件面临的问题，但它是机器学习固有的。ML 数学建立了对训练数据中重要模式的简明表达，希望这能很好地反映现实世界。如果训练数据很好地反映了现实世界，那么模型应该是准确的，因此是有用的。

但现实世界并不停留。六个月前用于构建欺诈检测模型的训练数据不会反映出最近三个月开始出现的新类型欺诈行为。如果某个网站开始吸引越来越年轻的用户群体，那么生成广告的模型可能会生成越来越不相关的广告。在某一点上，性能将变得不可接受，需要重新训练模型。模型需要多快重新训练取决于现实世界的变化速度以及模型需要多准确，但同样重要的是，取决于构建和部署更好模型的难易程度。

但首先，数据科学家如何判断模型的性能正在恶化呢？这并不总是容易。有两种常见方法，一种基于真相，另一种基于输入漂移。

### 真相

真相（ground truth），简而言之，是模型被要求解决的问题的正确答案，例如，“这笔信用卡交易实际上是欺诈的吗？” 通过了解模型所做预测的所有真相，可以评估该模型的表现如何。

有时候，在预测之后可以迅速获取真相，例如，在决定向用户展示哪些广告的模型中。用户可能在几秒钟内点击广告，或者根本不点击。然而，在许多用例中，获取真相要慢得多。如果一个模型预测某笔交易是欺诈的，如何确认这一点？在某些情况下，确认可能只需要几分钟，例如给持卡人打电话。但是，如果模型认为交易正常，实际上并非如此怎么办？最好的希望是当持卡人查看他们的月度交易记录时，他们会报告这些问题，但这可能会延迟一个月或完全不发生。

在欺诈的例子中，真相不能让数据科学团队每天准确监测性能。如果情况需要快速反馈，那么输入漂移可能是一个更好的方法。

### 输入漂移

输入漂移基于一个原则，即如果模型训练的数据准确反映了现实世界，模型才能准确预测。因此，如果最近请求与部署模型的训练数据之间的比较显示出明显差异，那么模型的性能可能会受到损害。这就是输入漂移监测的基础。这种方法的美妙之处在于，用于此测试的所有数据已经存在，因此无需等待真相或任何其他信息。

识别漂移是可适应的 MLOps 策略中最重要的组成部分之一，也是能够为组织的企业 AI 努力带来敏捷性的组成部分。第七章 将更深入地探讨数据科学家在模型监控方面的关注点。

## 业务关注点

业务对监控有全面的观点，其中一些关注点可能包括以下问题：

+   模型为企业带来了价值吗？

+   模型的益处是否超过开发和部署它的成本？（如何衡量这一点？）

原始业务目标确定的关键绩效指标是这一过程的一部分。在可能的情况下，这些应该自动监控，但这很少是微不足道的。在我们之前的示例中，将欺诈率降低到交易的 0.1%以下的目标取决于建立基础事实。但即使是这样监控，也无法回答一个问题：业务的净收益是多少美元？

这是软件的古老挑战，随着对机器学习支出的不断增加，数据科学家展示价值的压力只会增加。在缺乏“美元计量器”的情况下，有效监控业务关键绩效指标是最佳选择（参见“设计和管理实验”）。在这里选择基线很重要，理想情况下应允许区分 ML 子项目的价值，而不是全局项目的价值。例如，可以通过基于主题专业知识的基于规则的决策模型评估 ML 性能，以区分决策自动化和 ML 本身的贡献。

# 迭代与生命周期

开发和部署改进版本的模型是 MLOps 生命周期中必不可少的部分，也是更具挑战性的部分之一。有各种原因可以开发新的模型版本，其中之一是由于模型漂移导致模型性能下降，正如前一节所讨论的。有时需要反映精炼的业务目标和关键绩效指标，而其他时候，只是数据科学家提出了更好的设计模型的方法。

## 迭代

在某些快速变化的业务环境中，每天都会有新的训练数据可用。通常会自动化每日重新训练和重新部署模型，以确保模型尽可能准确地反映最近的经验。

重新使用最新训练数据重新训练现有模型是迭代新模型版本的最简单情况。但即使没有特征选择或算法变化，仍然存在许多陷阱。特别是：

+   新的训练数据看起来如预期吗？通过预定义的指标和检查自动验证新数据至关重要。

+   数据完整且一致吗？

+   特征的分布是否与先前训练集中的分布大致相似？请记住，目标是优化模型，而不是根本性地改变它。

构建新模型版本后的下一步是将指标与当前的实时模型版本进行比较。为此，需要在相同的开发数据集上评估两个模型，无论是先前版本还是最新版本。如果指标和检查表明两个模型之间存在较大差异，则不应重新部署自动化脚本，并应寻求手动干预。

即使在“简单”的自动化重新训练场景中使用新的训练数据，也需要基于评分数据协调（在可用时与真实情况一致）、数据清理和验证、先前的模型版本以及一系列经过深思熟虑的检查来创建多个开发数据集。在其他情景下重新训练可能会更加复杂，从而使自动化部署变得不太可能。

举例来说，考虑到由于重要的输入漂移而进行的重新训练。如何改进模型？如果有新的训练数据可用，那么使用这些数据进行重新训练是具有最高成本效益比的行动，而且可能足够了。然而，在获取真实情况速度较慢的环境中，可能没有太多新的标记数据。

本案例需要数据科学家的直接干预，他们需要理解漂移的原因，并找出如何调整现有的训练数据以更准确地反映最新的输入数据。评估通过这些更改生成的模型是困难的。数据科学家必须花时间评估情况——这段时间随着建模债务的增加而增加——并估计对性能的潜在影响，并设计定制的缓解措施。例如，去除特定特征或对现有的训练数据行进行抽样可能会导致调整更好的模型。

## 反馈循环

在大型企业中，DevOps 最佳实践通常规定，实时模型评分环境和模型重新训练环境是分开的。因此，在重新训练环境中评估新模型版本可能会受到影响。

缓解这种不确定性的一种方法是影子测试，其中新模型版本与现有模型一起部署到实时环境中。所有实时评分由现任模型版本处理，但每个新请求将由新模型版本再次评分并记录结果，但不返回给请求者。一旦足够的请求由两个版本评分，结果就可以进行统计比较。影子评分还为 SME（专家小组成员）提供了更多关于模型未来版本的可见性，因此可能允许更平稳的过渡。

在先前讨论的广告生成模型中，无法确定模型选择的广告是好是坏，除非允许最终用户点击它们。在这种情况下，影子测试的好处有限，而 A/B 测试更为常见。

在 A/B 测试中，两个模型都部署到实时环境中，但输入请求被分配到两个模型之间。每个请求只由其中一个模型处理，而不是两个都处理。两个模型的结果被记录以供分析（但不是针对同一请求）。从 A/B 测试中得出统计上显著的结论需要仔细规划测试过程。

第七章将更详细地介绍 A/B 测试的操作方法，但预览时，最简单形式的 A/B 测试通常被称为固定时间段测试。这是因为在寻找统计上显著的结论时，必须等到测试了事先精心确定的样本数量。在测试完成之前窥视结果是不可靠的。然而，如果测试在商业环境中实时运行，每一个糟糕的预测都可能花费金钱，因此不能早期停止测试可能会很昂贵。

贝叶斯，特别是多臂老虎机测试，越来越受欢迎，作为“频率主义者”固定时间段测试的替代方案，旨在更快地得出结论。多臂老虎机测试是自适应的：决定模型之间分配的算法根据实时结果进行调整，并减少表现不佳模型的工作负载。虽然多臂老虎机测试更复杂，但可以降低将流量发送到表现不佳模型的业务成本。

# 治理

治理是对企业施加的一系列控制措施，以确保其履行对所有利益相关者的责任，从股东和员工到公众和国家政府。这些责任包括财务、法律和道德义务。这三者的基础是公平原则。

法律义务是最容易理解的。在机器学习出现之前，企业就受到法规的约束。许多法规针对特定行业；例如，金融法规旨在保护公众和更广泛的经济免受金融管理和欺诈的危害，而制药行业必须遵守规则以保障公众健康。商业实践受到更广泛的立法影响，以保护社会中的弱势群体，并确保在性别、种族、年龄或宗教等标准上的公平竞争。

最近，全球各国政府已经实施了保护公众免受企业使用个人数据影响的法规。2016 年的欧盟通用数据保护条例（GDPR）和 2018 年的加州消费者隐私法案（CCPA）代表了这一趋势，它们对完全依赖数据的机器学习的影响巨大。例如，GDPR 试图保护个人数据免受工业滥用，并旨在限制可能对个人造成的歧视。

现在，各国政府开始特别关注机器学习，希望减少其使用可能带来的负面影响。欧盟正在领先，计划制定法律来定义各种形式人工智能的可接受使用方式。这并不一定意味着减少使用；例如，可能会推动面部识别技术的有益应用，目前受数据隐私法规限制。但显然的是，企业在应用机器学习时将不得不注意更多的监管。

企业是否关心超越法定法规的对社会的道德责任？答案越来越是肯定的，如当前环境、社会和治理（ESG）绩效指标的发展所示。信任对消费者至关重要，缺乏信任对业务不利。随着公众在这一议题上的活跃参与增加，企业正在探讨负责任人工智能的理念，即道德、透明和可问责的人工智能技术应用。股东也重视信任，机器学习风险的全面披露正在逐步实现。

将良好的治理应用于 MLOps 是具有挑战性的。这些过程复杂，技术不透明，对数据的依赖性是基础性的。MLOps 中的治理倡议大体上可以分为两类：

数据治理

确保适当使用和管理数据的框架

过程治理

使用明确定义的流程确保在模型生命周期的正确阶段处理所有治理考虑，并且保持完整和准确的记录

## 数据治理

数据治理关注正在使用的数据，特别是模型训练的数据，并且可以解决如下问题：

+   数据的来源是什么？

+   原始数据是如何收集的，使用条款是什么？

+   数据是否准确且更新？

+   是否存在个人身份信息（PII）或其他敏感数据不应使用？

机器学习项目通常涉及大量的流水线，包括数据清洗、组合和转换步骤。理解数据衍生线在特征级别尤为复杂，但对于遵守类似 GDPR 的法规却是必不可少的。团队——乃至更广泛的组织，因为这对其顶层也很重要——如何确保没有使用个人身份信息来训练给定模型？对数据进行匿名化或伪匿名化并非总是管理个人信息的充分解决方案。如果这些过程执行不正确，仍然可能单独识别出个人及其数据，与 GDPR 的要求相违背。³

尽管数据科学家的初衷最好，模型中可能会意外地产生不恰当的偏见。一个机器学习招聘模型曾因识别某些全女子学校在公司高层管理中代表性不足而著名，这反映了该组织历史上男性的主导地位。⁴ 关键在于基于经验进行预测是一种强大的技术，但有时其后果不仅是适得其反，还可能违法。

目前能够解决这些问题的数据治理工具还处于初期阶段。大多数工具集中在回答数据衍生线的两个问题上：

+   这个数据集的信息来源是什么，以及这告诉我如何使用它？

+   这个数据集如何使用，如果我对其进行某些更改，对下游有何影响？

在真实世界的数据准备流水线中，两个问题都不容易全面准确地回答。例如，如果数据科学家编写了一个 Python 函数来处理多个输入数据集并输出一个单一数据集，那么如何确保新数据集中每个单元格的信息来源？

## 流程治理

流程治理专注于规范 MLOps 流程中的步骤，并与之相关联的行动。通常这些行动包括审查、签字以及文档等支持材料的获取。其目的有两个：

+   确保每个与治理相关的考虑在正确的时间做出并得到正确执行。例如，模型在所有验证检查都通过之前不应部署到生产环境。

+   以便从严格的 MLOps 流程之外进行监督。审计员、风险管理人员、合规官员以及整个业务都有兴趣能够在后期跟踪进展和审查决策。

流程治理的有效实施是困难的：

+   机器学习生命周期的正式流程很少能准确定义。对整个过程的理解通常分散在参与其中的多个团队之间，往往没有一个人能全面理解整体。

+   要成功应用这一流程，每个团队都必须全力采纳。

+   如果某些用例中的流程过于繁重，团队们肯定会绕过它，很多好处也将会丧失。

如今，流程治理在传统上具有繁重的监管和合规负担的组织中最为普遍，如金融领域。在这些领域之外，这种情况则比较罕见。随着机器学习渗透到商业活动的各个领域，并且对负责任的 AI 日益关注，我们将需要针对所有企业可行的新的和创新的解决方案来解决这个问题。

# 总结思考

通过对 MLOps 所需功能和受影响流程的概述，显然这不是数据团队——甚至整个数据驱动组织可以忽视的事情。这也不是一个勾掉清单上项目的事项（“是的，我们在做 MLOps！”），而是技术、流程和人员之间复杂的相互作用，需要纪律和时间才能正确执行。

后续章节将深入探讨 MLOps 中每个 ML 模型生命周期组件的作用，展示每个组件如何实现以更接近理想的 MLOps 实施。

¹ 描述蓝绿部署技术需要比我们这里提供的空间更多。更多信息请参阅[Martin Fowler 的博客](https://oreil.ly/Uuobx)。

² 深入了解[GDPR 和 CCPA 之间的区别](https://oreil.ly/zS7o6)。

³ 关于匿名化、伪匿名化以及它们为何不能解决所有数据隐私问题的更多信息，请参阅[*数据隐私合规数据项目实施指南* by Dataiku](https://oreil.ly/bK1Yu)。

⁴ 2018 年，亚马逊因其针对女性的偏见而声名狼藉地[废除了一款 AI 招聘工具](https://oreil.ly/tI5Sy)。
