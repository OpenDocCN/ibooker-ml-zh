# 序言

著名统计学家乔治·博克斯曾经著名地说过：“所有模型都是错误的，但有些是有用的。”承认这一事实构成有效风险管理的基础。在机器学习日益自动化我们生活中重要决策的世界中，模型失败的后果可能是灾难性的。采取刻意措施来减轻风险并避免意外伤害至关重要。

在 2008 年金融危机之后，监管机构和金融机构意识到管理模型风险以确保银行安全的重要性，完善了模型风险管理（MRM）的实践。随着人工智能和机器学习的广泛应用，MRM 原则正在被应用于管理其风险。美国国家标准与技术研究院的 AI 风险管理框架作为这一演变的例证。从高级管理监督到政策和程序，包括组织结构和激励措施，正确治理和控制整个过程对于促进模型风险管理文化至关重要。

在《面向高风险应用的机器学习》中，霍尔、柯蒂斯和潘迪提出了一个框架，用于将机器学习应用于重大决策。通过记录的模型失败案例和新兴法规提供了令人信服的证据，强调了强有力的治理和文化的重要性。不幸的是，这些原则在非受监管行业，如银行之外，仍然很少被实施。该书涵盖了重要的主题，包括模型透明性、治理、安全性、偏见管理等。

在机器学习中，仅进行性能测试是不够的，因为非常不同的模型可能由于模型多样性而具有相同的性能。模型还必须具有可解释性、安全性和公平性。这是第一本强调固有可解释模型及其最近的发展和应用的书籍，特别是在模型影响个人的情况下，如消费金融领域。在这些场景中，解释性人工智能（XAI）事后解释方法通常面临重大挑战。

开发可靠和安全的机器学习系统还需要严格评估模型的弱点。本书提供了两个详尽的示例以及模型调试方法论，包括通过错误或残差切片识别模型缺陷，评估输入数据损坏下模型的鲁棒性，评估模型输出的可靠性或不确定性，以及通过压力测试测试模型在分布变化下的弹性。这些对于在高风险环境中开发和部署机器学习至关重要。

机器学习模型有潜力通过自动化迅速且规模化地对历史上被边缘化的群体造成不成比例的伤害。偏见的模型决策对受保护群体产生有害影响，持续加剧社会和经济差距。本书将教读者如何通过社会技术视角解决模型公平性问题。作者还详细研究了模型去偏差技术的影响，并就如何在不同受监管行业应用这些技术提供了实用建议。

*《高风险应用的机器学习》* 是一本实用、主观和及时的书籍。各类读者都能在这个充满挑战的主题中找到丰富的见解，无论你是一名数据科学家，希望更好地理解你的模型，还是一名负责确保符合现有标准的经理，或者是一名试图改进组织风险控制的高管。

Agus Sudjianto，博士

威尔斯法格（Wells Fargo）公司模型风险负责人，执行副总裁（EVP）
