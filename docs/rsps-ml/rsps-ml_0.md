# 前言

机器学习（ML）坐落在商业应用、统计学和计算机科学的交汇处。在其大约 60 年的历史中，它经历了几波炒作和失望。这是一个庞大而技术性强的主题，也是一种强大的商业技术。然而，与其他强大的技术一样，它既带来机遇也带来挑战。它可以是工具，也可以是武器。它可以带来收入，并且在某些情况下，可以改变组织。但它也可能失败、遭到攻击，并引发重大事件。从我们的角度来看，大多数机器学习社区似乎过于关注 ML 的炒作和优势。当我们只关注技术的优势时，我们就背弃了必须解决的明显现实。也许这就是为什么我们觉得写一篇名为*负责任的机器学习*的报告有些奇怪。毕竟，我们不经常听到“负责任”的航空或“负责任”的核能。责任和风险缓解通常已经融入我们对这些技术的概念中，但显然对于机器学习尚未发生。这可能是因为我们知道商业喷气客机或核反应堆出现故障或受到攻击时会发生什么，但作为一个社区，我们对糟糕的 ML 的后果尚不确定。

如果是这样，这就暴露出从业者社区的不作为。尽管 ML 失败和攻击的后果刚刚开始进入新闻报道，但如果你知道在哪里找，你已经可以找到超过 1,000 个[AI 事件的公开报告](https://oreil.ly/zy35H)。此外，[政府](https://oreil.ly/vdpja)和[公众](https://oreil.ly/5TEBp)对诡异和歧视性 ML 的认识也在增加。深挖 ML 炒作的表面之下，你将发现整个 AI 事件世界、AI 监管的待定和 ML 风险缓解工具。本报告介绍了这个世界。由于有很多问题需要涵盖，我们不会对任何主题深入探讨。我们希望感兴趣的读者能参与并探索我们的参考资料，了解现实世界的影响和真正的人类后果。我们也希望所呈现的材料的数量和多样性能够对读者思考 ML 的方式留下不可磨灭的印象。

我们将风险缓解和机器学习采纳策略的讨论分成三大章节：人员、流程和技术。人员和流程章节（第二章和第三章）描述了人们可以采取的行动，以及组织可以采用的流程来缓解机器学习风险并增加机器学习的采纳率。这两章旨在面向非技术人员。虽然它不包括数学公式，但技术章节（第四章）需要一些机器学习的技术背景，可能更适合机器学习从业者及其一线管理者。同样重要的是，我们要说的是，我们正在解决的机器学习风险是复杂的、未解决的，并且具有交叉性。考虑到机器学习系统的复杂性及其与世界的互动方式，没有完全解决 ML 系统风险的万能方案。

此外，印刷报告的连续性意味着我们逐一解决风险和缓解策略。事实上，风险和策略本质上是相互关联的：遵从性、歧视、不稳定性、隐私和安全风险是相关的，采取的行动也是如此。由于组织的部署通常是机器学习风险变得真实的地方，适当的风险缓解是机器学习成功的关键问题。尽管不完美，我们希望您会发现提议的策略对减少风险并最大化机器学习在您的组织中的长期价值是有帮助且可行的。
