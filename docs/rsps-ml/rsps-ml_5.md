# 第五章：以负责任的机器学习创新驱动价值

> “远远最大的危险是人们过早地得出对人工智能的理解结论。”
> 
> Eliezer Yudkowsky

“为什么 87%的数据科学项目最终未能投入生产？”近期一篇[《VentureBeat》文章](https://oreil.ly/7XQr2)提出了这个问题。对于许多公司来说，将机器学习模型投入生产是衡量机器学习风险的关键时刻。对许多人而言，构建模型的整体目的在于最终部署它进行实时预测，其他任何目的都会被视为失败。对其他公司来说，机器学习模型的最终目标可以简单地是即席预测、估值、分类或警报。本短章旨在提供公司在采纳和从机器学习中获取价值时应注意的关键概念概述。一般来说，对于企业而言，基于预测算法做出重要决策会带来更为重大的影响，而不仅仅是进行试验或原型探索性机器学习活动。

# 信任与风险

对于采用人工智能的智能组织来说，通常会有两个主要问题：“我如何能够信任这个模型？”和“它有多大风险？”这些对公司在将机器学习模型投入生产之前问的关键问题。然而，需要理解的是，这些问题的答案之间存在一个正反馈效应。你对一个机器学习系统的风险了解得越多，你就能越信任它。我们经常发现，高管和领导们会迫不及待地问：“风险是什么？”而数据科学从业者更专注于：“我能相信这个预测吗？”但最终，他们问的是同一个问题。

首先，需要分析的最明显的指标是一个给定的机器学习模型可能表现出的风险。以下是决策者需要询问有关机器学习部署的几个问题的几个问题：

+   模型的质量如何？（准确性、AUC/ROC、F1）

+   错误结果的成本是多少？

    +   还有次要成本考虑吗？法律或合规问题？客户生命周期价值？运营风险？品牌或声誉风险？对终端用户或公众的伤害？

    +   我们是否实时监控模型的准确性、歧视性、隐私或安全问题？

    +   我们是否有具体的人工智能事件响应计划？

+   这个模型正在做多少预测？

    +   这些预测的速度是多少？你的公司需要多快地响应错误或异常情况？

    +   这个模型对你的公司有多大的重要性？

到目前为止，没有关于 ML 风险的银弹。在数据科学和 ML 风险方面，真正的细微差别主要源于了解预测出错时会发生什么。出于同样的原因，设计和开发 ML 系统时，深入的领域知识或背景上下文至关重要。错误预测的下行风险不仅仅是损失利润或增加成本，而是企业需要严格分析的多层考虑因素。乔治·博克斯的统计引用“所有模型都是错误的，但有些是有用的”，应该成为拥有 ML 的组织的一个起点。了解您的模型将会出错，并彻底理解这对您的组织意味着什么。

# 信号与简洁

最近几年 ML 和 AI 领域的热潮很大程度上归因于深度神经网络和高性能计算的推动。最初的大想法是，适当调整的深度学习模型在有足够数据支持下，可以超越其他任何方法。这个想法的问题在于，这些模型可以说是所有领先方法中最黑盒的。这带来了一个折衷：为了简洁性（信号），我是否需要牺牲准确性？要牺牲多少？然而，新的研究表明，在表格数据和诸如 XNN 和 EBM 等方法中，这种折衷可能很小。目前而言，白盒方法在标准业务数据源上的准确性可以与其黑盒对应物相媲美。请记住，解释性可以围绕 ML 系统实施各种风险缓解过程：改进有效挑战、更好的文档编制、客户申诉以及更多模型调试。如果您作为业务领导者面对一个您的团队无法解释的 ML 系统，这是一个重要的警告信号。您可以同时兼顾信号和简洁，特别是对于最常见的传统数据挖掘问题。

# 负责任机器学习的未来

在过去几年中，对于更好理解和信任我们的机器学习系统有了更多的需求，这是一件非常好的事情。在欧洲和亚洲的某些地区，政府在组织部署机器学习时更积极要求考虑这些因素。在美国，负责任的机器学习主要是由数据科学家、研究人员和行业从业者的基层推动，旨在促进 AI 和机器学习领域的负责任创新。无论如何，目标都是增强消费者信任，并推动该领域的更好实践。我们相信，在未来，机器学习的责任性将继续发展和改进，特别是在美国政府机构的严格监管下。随着基层压力和未来的法规压力增加，组织不能简单地打勾认为负责任的机器学习问题已解决。我们希望组织能不断改进其实践，以更好地理解和信任他们的机器学习系统，直到负责任的机器学习变成普通的机器学习。

# 进一步阅读

[英国 ICO AI 审计框架](https://oreil.ly/RDdNa)

[新加坡 PDPC 模型 AI 治理框架](https://oreil.ly/1UOSP)

[Berryville Institute 互动式机器学习风险评估](https://oreil.ly/EXYuN)

# 致谢

感谢我们在 H2O.ai 的同事，尤其是 Ingrid Burton。感谢 O’Reilly Media 的 Michele Cronin、Michelle Houston、Beth Kelly、Mike Loukides 和 Rebecca Novack。同时也感谢我们更广泛的数据科学社区的同事 Andrew Burt、Hannes Hapke、Catherine Nelson 和 Nicholas Schimdt。

# 关于作者

**Patrick Hall** 是 bnh.ai 的首席科学家，这是一家专注于数据分析和人工智能的精品法律公司。Patrick 还是乔治·华盛顿大学决策科学系的客座教授，并担任 H2O.ai 的顾问。

**Navdeep Gill** 是 H2O.ai 的高级数据科学家和软件工程师，主要专注于负责任的机器学习。Navdeep 还为 H2O.ai 在 GPU 加速机器学习、自动化机器学习以及核心 H2O-3 机器学习平台方面做出了贡献。

**Ben Cox** 是 H2O.ai 的产品营销总监，负责负责任的 AI 市场研究和思想领导。在加入 H2O.ai 之前，Ben 在安永、耐克和 NTT 数据的高知名度团队中担任数据科学角色。
