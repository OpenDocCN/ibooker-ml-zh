# ç¬¬ä¸‰ç« ï¼šæ¨¡å‹å¯è§£é‡Šæ€§ä¸å¯è§£é‡Šæ€§

ç†è§£æœºå™¨å­¦ä¹ æ¨¡å‹å¯èƒ½çœ‹èµ·æ¥åƒæ˜¯ç†è§£æ™ºèƒ½æœ¬èº«ä¸€æ ·å›°éš¾ã€‚è®¡ç®—æœºç§‘å­¦å®¶é©¬æ–‡Â·æ˜æ–¯åŸºæ›¾è‘—ååœ°å°†â€œæ™ºèƒ½â€æè¿°ä¸º[â€œä¸€ä¸ªæ‰‹æç®±è¯â€](https://oreil.ly/SgFAp)ï¼šâ€œä¸€ä¸ªæœ¬èº«å¹¶ä¸ä»£è¡¨ä»»ä½•ä¸œè¥¿ï¼Œä½†å†…å«ä¸€å †ä½ å¿…é¡»è§£å¼€çš„ä¸œè¥¿ã€‚â€ å½“ä½ çœ‹åˆ°åœ¨æŸäº›ä»»åŠ¡ä¸­å…·æœ‰è¶…äººè¡¨ç°ï¼ˆä¾‹å¦‚ï¼Œä¸‹å›´æ£‹æˆ–å›½é™…è±¡æ£‹ï¼‰ï¼Œä½†åœ¨å…¶ä»–ä»»åŠ¡ä¸­å´æƒ¨è´¥ï¼ˆä¾‹å¦‚ï¼Œå°†å…¬äº¤è½¦ä¸Šçš„äººç‰©è¯¯è®¤ä¸ºè¡Œäººï¼‰ï¼Œè¿™ä¸€åˆ‡å˜å¾—æ›´åŠ æ··ä¹±ã€‚æœºå™¨å­¦ä¹ æ“…é•¿åˆ›å»ºæ˜ å°„åˆ°å¤æ‚å†³ç­–ç©ºé—´çš„å‡½æ•°ã€‚é—®é¢˜åœ¨äºï¼Œå½“ä½ æƒ³è¦ç†è§£æ¨¡å‹ä¸ºä½•åšå‡ºç‰¹å®šå†³ç­–æ—¶ã€‚

æ›´ç³Ÿç³•çš„æ˜¯ï¼Œâ€œå¯è§£é‡Šæ€§â€â€”â€”ä½ æƒ³è¦ç”¨æ¥è§£ææ¨¡å‹çš„å·¥å…·â€”â€”æœ¬èº«å¯èƒ½ä¹Ÿç®—æ˜¯ä¸€ä¸ªæ‰‹æç®±è¯ã€‚

# è§£é‡Šæ€§ä¸å¯è§£é‡Šæ€§çš„åŒºåˆ«

*å¯è§£é‡Šæ€§*å’Œ*å¯è§£é‡Šæ€§*åœ¨è§£é‡Š ML æ¨¡å‹åŠå…¶è¾“å‡ºæ—¶é€šå¸¸å¯ä»¥äº’æ¢ä½¿ç”¨ã€‚å¯¹äºå¯è§£é‡Šæ€§ï¼Œè‡³å°‘æœ‰å‡ ä¸ªéæ•°å­¦é‡çš„å®šä¹‰å¯ä¾›é€‰æ‹©ã€‚AI ç ”ç©¶å‘˜è’‚å§†Â·ç±³å‹’å°†å…¶æè¿°ä¸ºâ€œäººç±»èƒ½å¤Ÿç†è§£å†³ç­–åŸå› çš„ç¨‹åº¦â€ï¼ŒÂ¹ è€Œé‡‘å°šå®‡ç­‰äººå°†å…¶æè¿°ä¸ºâ€œèƒ½å¤Ÿä¸€è‡´é¢„æµ‹æœºå™¨è¾“å‡ºçš„ç¨‹åº¦â€ã€‚Â²

è¿™äº›å®šä¹‰çš„å…±åŒç‚¹åœ¨äºå®ƒä»¬ä¾§é‡äºæ¨¡å‹æ‰€åšçš„å†³ç­–ã€‚ä¸*å¯è§£é‡Šæ€§*ï¼ˆæœ‰æ—¶ç§°ä¸º Xplainable AI æˆ– XAIã€‚Â³ï¼‰ç›¸åã€‚å°½ç®¡å®ƒé€šå¸¸åœ¨ç±»ä¼¼çš„è¯­å¢ƒä¸­ä½¿ç”¨ï¼Œä½†è¯¥æœ¯è¯­é€šå¸¸å¼ºè°ƒå­¦ä¹ æ¨¡å‹å†…éƒ¨ï¼Œå¦‚ç¥ç»ç½‘ç»œçš„æƒé‡æˆ–æ ‘çš„èŠ‚ç‚¹åˆ†è£‚ã€‚â´

å°½ç®¡ç ”ç©¶äººå‘˜å°šæœªæ­£å¼åŒºåˆ†è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬ä¹¦çš„å…¶ä½™éƒ¨åˆ†ä¸­å°†*å¯è§£é‡Šæ€§*æŒ‡æ¶‰æ¨¡å‹è¾“å‡ºï¼Œ*å¯è§£é‡Šæ€§*æŒ‡æ¶‰æ¨¡å‹å†…éƒ¨ã€‚

# å¯¹äºéœ€è¦å¯è§£é‡Šæ€§å’Œå¯è§£é‡Šæ€§çš„æ¨¡å‹çš„éœ€æ±‚

å¦‚æœä½ æœ‰ä¸€ä¸ªèƒ½å¤Ÿåœ¨æµ‹è¯•æ•°æ®ä¸Šä»¥è¶³å¤Ÿé«˜å‡†ç¡®ç‡åšå‡ºå†³ç­–çš„æ¨¡å‹ï¼Œé‚£ä¹ˆéƒ¨ç½²å®ƒè‚¯å®šè¶³å¤Ÿäº†ï¼Œå¯¹å§ï¼Ÿ

æ­£å¦‚å¤šå¸Œ-éŸ¦å‹’å…¹å’Œé‡‘æ‰€æŒ‡å‡ºçš„é‚£æ ·ï¼Œâµ ä» ML æ¨¡å‹è·å¾—è¾“å‡ºå†³ç­–å¹¶ä¸æ€»æ˜¯ç»ˆç‚¹ã€‚è€ƒè™‘ä½¿ç”¨ç¥ç»ç½‘ç»œåœ¨è‚¿ç˜¤å­¦ä¸­çš„å‡è®¾æ¡ˆä¾‹ã€‚è¯¥æ¨¡å‹å¯ä»¥åšå‡ºå¯¹æ‚£è€…å¯èƒ½å…·æœ‰ç”Ÿå‘½å˜åŒ–æ„ä¹‰çš„å†³ç­–ã€‚è¿™äº›æ‚£è€…åœ¨æ³•å¾‹ä¸Šæœ‰æƒè¦æ±‚åŒ»ç”Ÿæä¾›æ›´å¤šç»†èŠ‚ï¼Œè€Œä»–ä»¬å¯èƒ½ä¸ä¼šå¯¹â€œè¯·ç›¸ä¿¡æˆ‘ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªéå¸¸å¥½çš„ç¥ç»ç½‘ç»œâ€è¿™æ ·çš„å›ç­”æ»¡æ„ã€‚è¿™ä¸ªç¥ç»ç½‘ç»œåˆ°åº•æœ‰å¤šå¥½å¯èƒ½ä¹Ÿå€¼å¾—æ€€ç–‘ã€‚æ¯•ç«Ÿï¼Œä½ éœ€è¦ç¡®ä¿æ£€æŸ¥ X å…‰çš„è®¡ç®—æœºè§†è§‰æ¨¡å‹ç¡®å®åœ¨è§‚å¯Ÿæ‰€ç ”ç©¶çš„èº«ä½“éƒ¨ä½ï¼Œè€Œä¸æ˜¯åœ¨è§’è½é‡Œå¯»æ‰¾è¢«äººç±»æ”¾é”™çš„æ–‡æœ¬æ ‡ç­¾ã€‚

å¯è§£é‡Šæ€§å’Œå¯è§£é‡Šæ€§æ˜¯é˜²æ­¢è¿™ç§æ— çŸ¥çš„é‡è¦ä¿éšœã€‚â¶ ç‰¹åˆ«æ˜¯åœ¨æ¨¡å‹è¢«ç”¨äºå…¶ä»¥å‰æœªæ›¾é‡åˆ°çš„æƒ…å¢ƒæ—¶ï¼Œè€ƒè™‘æ¨¡å‹çš„å…¬å¹³æ€§ã€éšç§æ€§å’Œé²æ£’æ€§å°¤ä¸ºé‡è¦ã€‚

[å°¼å…‹Â·åšæ–¯ç‰¹ç½—å§†æ›¾è‘—ååœ°æå‡ºè¿‡](https://oreil.ly/H61nH)ï¼Œè§£é‡Šæ€§æ˜¯é˜²æ­¢åˆ›é€ å‡ºå…·æœ‰ä¸å…¶äººç±»åˆ›é€ è€…ç›¸æ‚–ç›®æ ‡çš„è¶…æ™ºèƒ½äººå·¥æ™ºèƒ½çš„ä¿éšœã€‚å¦‚æœæ‚¨èƒ½è§£é‡Šä¸€ä¸ªå…ˆè¿›çš„ AI æ¨¡å‹å¹¶å¯é åœ°è§£é‡Šå…¶å†³ç­–ï¼Œé‚£ä¹ˆæ‚¨ä¹Ÿå¯ä»¥åå‘å·¥ç¨‹å®ƒï¼Œç¡®ä¿å®ƒæŒ‰ç…§æ‚¨çš„æ„æ„¿è¡Œäº‹ï¼Œè€Œä¸ä¼šè¯•å›¾ä¼¤å®³æ‚¨ã€‚æ›´åŠ ç†ç”±å»è®¤è¯†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯è§£é‡Šæ€§çš„é‡è¦æ€§ã€‚

å¦‚æœæ‚¨çš„é¡¹ç›®ç»å¯¹éœ€è¦å¯è§£é‡Šæ€§æˆ–å¯è§£é‡Šæ€§ä½œä¸ºç‰¹å¾ï¼Œæ‚¨å°†éœ€è¦æƒè¡¡å¯è§£é‡Šæ€§çš„é™ä½ä¸æ€§èƒ½æå‡çš„é‡è¦æ€§ã€‚å†³ç­–æ ‘æ¯”æ·±åº¦ç¥ç»ç½‘ç»œæ›´ç›´è§‚è§£é‡Šå’Œå¯è§£é‡Šã€‚

è¯è™½å¦‚æ­¤ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œå¸¦æ¥çš„æ€§èƒ½æå‡æ­£æ˜¯å®ƒä»¬æ¯”å†³ç­–æ ‘æ›´å—æ¬¢è¿çš„åŸå› ã€‚

# å¯èƒ½å­˜åœ¨è§£é‡Šæ€§å’Œéšç§ä¹‹é—´çš„æƒè¡¡

åœ¨ç¬¬ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬è¯¦ç»†è®¨è®ºäº†æ¨¡å‹çš„å†…éƒ¨è§„åˆ™ç”šè‡³è®­ç»ƒæ•°æ®é›†å¯èƒ½è¢«çªƒå–çš„å„ç§æ–¹å¼ã€‚è¿™äº›æ–¹å¼å¤§å¤šæ¶‰åŠç´§å¯†æ£€æŸ¥æ¨¡å‹å†³ç­–è¾“å‡ºçš„æ‰€æœ‰å¯¹æ•°å‡½ã€‚ç›®æ ‡æ˜¯å°½å¯èƒ½è®­ç»ƒä¸€ä¸ªæ¨¡å‹ä»¥æ¨¡ä»¿ç›®æ ‡ã€‚è¿™äº›æ”»å‡»å‡è®¾æ”»å‡»è€…å¯ä»¥è®¿é—®æœ‰å…³æ¨¡å‹å†³ç­–æ›´è¯¦ç»†ä¿¡æ¯ï¼Œè€Œä¸ä»…ä»…æ˜¯æœ€ç»ˆè¾“å‡ºå€¼ã€‚

è¿™äº›è§£é‡Šæ€§æ–¹æ³•è¿œä¸æ­¢äºç®€å•åˆ—å‡ºæ‰€æœ‰çš„é€»è¾‘å›å½’å€¼ã€‚å®ƒä»¬æä¾›çš„è§è§£æ¯”é€»è¾‘å›å½’å€¼æ›´èƒ½æ·±å…¥äº†è§£æ¨¡å‹çš„å†…éƒ¨ã€‚ç†è®ºä¸Šå¯ä»¥åŸºäºå®ƒä»¬åˆ›å»ºä¸€ä¸ªæ”»å‡»æœºåˆ¶ã€‚ä¾‹å¦‚ï¼Œä¸æ˜¯åœ¨åˆ†ç±»æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯åœ¨å·²ç»è¡¨ç°è‰¯å¥½çš„æ¨¡å‹çš„æ˜¾è‘—æ€§å›¾ä¸Šè®­ç»ƒæ¨¡å‹ã€‚ä¸€ä¸ªå†³å¿ƒåšå®šçš„æ”»å‡»è€…å¯ä»¥åŸºäºä¸¤ä¸ªæ¨¡å‹çš„ç»™å®šè¾“å…¥çš„æ˜¾è‘—æ€§å›¾ä¹‹é—´çš„ KL æ•£åº¦åˆ›å»ºä¸€ä¸ªæŸå¤±å‡½æ•°ã€‚

æ­£å¦‚æˆ‘ä»¬åœ¨ç¬¬ä¸€ç« ä¸­æ‰€æŒ‡å‡ºçš„ï¼ŒæŠµå¾¡è¿™ç±»æ”»å‡»çš„æœ€ä½³å¸Œæœ›æ˜¯é™åˆ¶é¢„æµ‹çš„è¾“å‡ºé€Ÿç‡ã€‚åŒæ ·é‡è¦çš„æ˜¯è¦é™åˆ¶é™¤äº†ä½ çš„å›¢é˜Ÿä¹‹å¤–çš„ä»»ä½•äººçœ‹åˆ°å…¨éƒ¨é¢„æµ‹è¾“å‡ºçš„ç¨‹åº¦ã€‚ä¾‹å¦‚ï¼Œåœ¨å‘ä»»ä½•äººå…¬å¼€é€»è¾‘å›å½’å€¼æ—¶è¦ä¸‰æ€è€Œåè¡Œã€‚

è™½ç„¶æ²¡æœ‰çœŸæ­£å®Œç¾çš„éšç§æœºåˆ¶ï¼Œä½†å°†è§‚ä¼—é™åˆ¶åœ¨å¿…è¦çš„äººç¾¤ä¹‹å†…å¯ä»¥èµ°å¾—æ›´è¿œã€‚

# è¯„ä¼°è§£é‡Šæˆ–è¯´æ˜æ–¹æ³•çš„å®ç”¨æ€§

é€‰æ‹©ä½¿ç”¨å“ªç§æ–¹æ³•å¯èƒ½ä¼šè®©äººä¸çŸ¥æ‰€æªã€‚éšç€è¯¥é¢†åŸŸçš„æˆç†Ÿï¼Œå…³äºå¦‚ä½•è¯„ä¼°è§£é‡Šæ€§æ–¹æ³•çš„æŒ‡å¯¼æ–¹é’ˆè¶Šæ¥è¶Šå¤šã€‚Doshi-Velez å’Œ Kim çš„ä¸‰çº§æ¡†æ¶å°±æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚â· ä»–ä»¬æ¦‚è¿°çš„ä¸‰ä¸ªçº§åˆ«åŒ…æ‹¬ï¼š

*åº”ç”¨çº§è¯„ä¼°ï¼ˆå®é™…ä»»åŠ¡ï¼‰*

å¦‚æœå°†ä½ çš„æ¨¡å‹è§£é‡Šæ”¾å…¥äº§å“ä¸­ï¼Œç”¨æˆ·èƒ½ç†è§£å…¶å«ä¹‰å—ï¼Ÿä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­æ˜¯ï¼Œäº§å“å¯ä»¥æ£€æµ‹åŠ¨ç‰©çš„å…½åŒ» X å…‰ä¸­ç£¨æŸçš„å…³èŠ‚ã€‚é€šè¿‡å…ˆå‰çš„æ”¾å°„å­¦å›¾åƒå¯¹ AI è¿›è¡Œè®­ç»ƒï¼Œä»¥é¢„æµ‹åŠ¨ç‰©æ˜¯å¦ç”Ÿç—…ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä¸€ä¸ªå¯è§£é‡Šçš„æ¨¡å‹ä¸ä»…èƒ½å¤Ÿå‘æ”¾å°„ç§‘åŒ»ç”Ÿè§£é‡Šå…¶é¢„æµ‹å†…å®¹ï¼Œè¿˜èƒ½çªå‡ºæ˜¾ç¤ºå¯¼è‡´å…¶å¾—å‡ºç»“è®ºçš„ X å…‰éƒ¨ä½ã€‚å€¼å¾—æ¯”è¾ƒçš„æ˜¯ï¼Œè¿™äº›æ¨¡å‹è§£é‡Šä¸äººç±»æ”¾å°„ç§‘åŒ»ç”Ÿè§£é‡Šç±»ä¼¼å†³ç­–çš„æ–¹å¼ã€‚

*äººç±»çº§è¯„ä¼°ï¼ˆç®€å•ä»»åŠ¡ï¼‰*

è¿™ç±»ä¼¼äºåº”ç”¨çº§è¯„ä¼°ï¼Œä½†æ²¡æœ‰ç‰¹å®šçš„æœ€ç»ˆç”¨æˆ·è€ƒè™‘ã€‚é€šè¿‡è¿™ç§è¯„ä¼°ï¼Œä½ åº”è¯¥è¯¢é—®ä¸€ä¸ªéšæœºçš„äººï¼ˆä¸ä¸€å®šæ˜¯ç”¨æˆ·æˆ–é¢†åŸŸä¸“å®¶ï¼‰æ˜¯å¦èƒ½å¤Ÿç†è§£æ¨¡å‹çš„å†³ç­–ã€‚å¦‚æœé¢†åŸŸä¸“å®¶ç¨€ç¼ºå’Œ/æˆ–æ˜‚è´µï¼ˆå¦‚å‰é¢ä¾‹å­ä¸­çš„å…½åŒ»ï¼‰ï¼Œä½¿ç”¨æ™®é€šäººçš„åˆ¤æ–­ä½œä¸ºåŸºå‡†æ˜¯ä¸€ä¸ªå¯èƒ½çš„æ›¿ä»£æ–¹æ¡ˆã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œåº”è¯¥è¯¢é—®æ¨¡å‹è§£é‡Šä¸­å“ªäº›æ˜¯æœ€å®¹æ˜“ç†è§£çš„ã€‚

*åŠŸèƒ½çº§è¯„ä¼°ï¼ˆä»£ç†ä»»åŠ¡ï¼‰*

å‡½æ•°çº§è¯„ä¼°ä¸åƒå‰å‡ ä¸ªè¯„ä¼°é‚£æ ·ä¾èµ–äºäººç±»æ‰¹è¯„ï¼Œè€Œæ˜¯ä¾èµ–äºæ‰€è®¨è®ºçš„æ¨¡å‹ç±»å‹çš„å±æ€§ã€‚å®é™…ä¸Šï¼Œåœ¨æ‚¨å·²ç»å±•ç¤ºå‡ºæ‚¨å¯ä»¥è·å¾—äººç±»ç†è§£çš„è§£é‡Šä¹‹åï¼Œè¿™æ˜¯æ‚¨ä¼šè½¬å‘çš„è¯„ä¼°ç±»å‹ã€‚å…¶ä¸­ä¸€äº›è§£é‡Šå¯èƒ½æ¯”å…¶ä»–è§£é‡Šæ›´å¥½ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºå•ä¸€åº¦é‡æ ‡å‡†ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä¾èµ–äºå†³ç­–æ ‘æˆ–å†³ç­–è§„åˆ™ï¼Œæ›´æ·±çš„æ ‘æˆ–æ›´æ·±çš„è§„åˆ™é›†å¯èƒ½æ›´å¤æ‚ä¸”æ›´éš¾è§£é‡Šï¼ˆå³ä½¿å®ƒä»¬åœ¨æŠ€æœ¯ä¸Šæ˜¯å¯è¡Œçš„ï¼‰ã€‚æ‚¨å¯ä»¥åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œé€‰æ‹©è¾ƒæµ…çš„æ ‘æˆ–è§„åˆ™é›†ï¼Œæ¡ä»¶æ˜¯å®ƒä»¬ä¿ç•™ä¸€å®šæ°´å¹³çš„é¢„æµ‹èƒ½åŠ›ã€‚

è€ƒè™‘åˆ°è¿™äº›æ–¹æ³•ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹æ ¹æ®è¿™äº›å®šä¹‰ï¼Œä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„è§£é‡Šå¯èƒ½æ˜¯ä»€ä¹ˆæ ·å­ã€‚

# å®šä¹‰ä¸åˆ†ç±»

åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œå¯è§£é‡Šæ€§å’Œå¯è§£é‡Šæ€§æ˜¯å¤æ‚ä¸”å¾®å¦™çš„ä¸»é¢˜ã€‚åœ¨ä¸€ä¸ªé¢†åŸŸæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆå¯èƒ½åœ¨å¦ä¸€ä¸ªé¢†åŸŸæ— æ•ˆã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†è®¨è®ºä¸€äº›ç”±å¯è§£é‡Šæ€§å’Œè§£é‡Šæ€§ä»ä¸šè€…å’Œç ”ç©¶äººå‘˜ç»å¸¸ä½¿ç”¨çš„é‡è¦æœ¯è¯­ã€‚

## â€œé»‘ç›’å­â€

æœºå™¨å­¦ä¹ æ¨¡å‹é€šå¸¸è¢«ç§°ä¸º*é»‘ç›’å­*ï¼ˆæˆ‘ä»¬åœ¨ç¬¬ä¸€ç« å·²ç»æ¶‰åŠè¿‡ï¼‰ã€‚è¿™å¯èƒ½æœ‰ä¸¤ä¸ªåŸå› ï¼šæ¨¡å‹çš„ç»†èŠ‚å¯èƒ½æ˜¯ä¸“æœ‰çš„ï¼Œå¯èƒ½æ˜¯æ•…æ„éšè—çš„ï¼›æˆ–è€…æ¨¡å‹èƒŒåçš„åŠŸèƒ½æ˜¯å¯ä»¥æ£€æŸ¥çš„ï¼Œä½†æ˜¯å®ƒéå¸¸å¤æ‚ï¼Œæ²¡æœ‰äººç±»å¯ä»¥ç†è§£ã€‚é€šå¸¸åœ¨è®¨è®ºé»‘ç›’å­æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬æŒ‡çš„æ˜¯ç¬¬äºŒä¸ªåŸå› ï¼Œå°½ç®¡æœ¬ç« è®¨è®ºçš„è®¸å¤šæŠ€æœ¯å¾ˆå®¹æ˜“é€‚ç”¨äºç¬¬ä¸€ä¸ªåŸå› ã€‚

## å…¨å±€ä¸å±€éƒ¨çš„å¯è§£é‡Šæ€§

*å…¨å±€*è§£é‡Šæ¨¡å‹å†³ç­–å¯ä»¥æ¨å¹¿åˆ°æ•´ä¸ªæ¨¡å‹è¡Œä¸ºã€‚*å±€éƒ¨*è§£é‡Šè¢«é™åˆ¶åœ¨æ‰€è®¨è®ºçš„è¾“å…¥-è¾“å‡ºå¯¹ä¸Šã€‚å¯è§£é‡Šæ€§çš„èŒƒå›´ç”šè‡³å¯ä»¥ä»‹äºè¿™ä¸¤è€…ä¹‹é—´ã€‚

## æ¨¡å‹æ— å…³ä¸æ¨¡å‹ç‰¹å®šæ–¹æ³•

*æ¨¡å‹æ— å…³*çš„è§£é‡Šæ–¹æ³•ä¸ä¾èµ–äºæ‚¨ä½¿ç”¨çš„æ¨¡å‹ç±»å‹ï¼šåŸºäºæ ‘çš„ã€åŸºäºç¥ç»ç½‘ç»œçš„ï¼Œæˆ–è€…å®Œå…¨ä¸åŒçš„å…¶ä»–ç±»å‹ã€‚è¿™äº›æ–¹æ³•æœ¬è´¨ä¸Šä¸è®¿é—®æ¨¡å‹çš„å†…éƒ¨ä¿¡æ¯ï¼Œæ¯”å¦‚ç»“æ„æˆ–æƒé‡ã€‚æ¨¡å‹æ— å…³æ–¹æ³•é€šå¸¸æ˜¯åœ¨è®­ç»ƒååº”ç”¨ï¼Œå¹¶ä¸”é€šå¸¸é€šè¿‡è§‚å¯Ÿæ•°æ®çš„è¾“å…¥å’Œè¾“å‡ºå¯¹æ¥è¿ä½œã€‚è¿™äº›æ— å…³æ–¹æ³•é€šå¸¸é€šè¿‡åˆ†æç‰¹å¾çš„è¾“å…¥å’Œè¾“å‡ºå¯¹æ¥å·¥ä½œã€‚æ ¹æ®å®šä¹‰ï¼Œè¿™äº›æ–¹æ³•æ— æ³•è®¿é—®æ¨¡å‹çš„å†…éƒ¨ä¿¡æ¯ï¼Œæ¯”å¦‚æƒé‡æˆ–ç»“æ„ä¿¡æ¯ã€‚

*ç‰¹å®šæ¨¡å‹*çš„è§£é‡Šå·¥å…·ä»…é™äºç‰¹å®šçš„æ¨¡å‹ç±»åˆ«ã€‚çº¿æ€§æ¨¡å‹ä¸­å›å½’æƒé‡çš„è§£é‡Šæ˜¯ä¸€ç§ç‰¹å®šäºæ¨¡å‹çš„è§£é‡Šï¼Œå› ä¸ºæŒ‰å®šä¹‰ï¼Œå†…åœ¨å¯è§£é‡Šæ¨¡å‹çš„è§£é‡Šå§‹ç»ˆæ˜¯ç‰¹å®šäºæ¨¡å‹çš„ã€‚ä¾‹å¦‚ï¼Œä»…é€‚ç”¨äºç¥ç»ç½‘ç»œè§£é‡Šçš„å·¥å…·å±äºç‰¹å®šäºæ¨¡å‹çš„å·¥å…·ã€‚ç„¶è€Œï¼Œæ¨¡å‹æ— å…³çš„å·¥å…·å¯ä»¥ç”¨äºä»»ä½•æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

## è§£è¯» GPT-2

ç»å¤§å¤šæ•°å¤§å‹è¯­è¨€æ¨¡å‹éƒ½æ˜¯åœ¨å¤§é‡æ–‡æœ¬è¯­æ–™åº“ä¸Šé¢„è®­ç»ƒçš„ ML æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥è¿›è¡Œå¾®è°ƒä»¥ç”¨äºå…¶ä»–ä»»åŠ¡ã€‚è¿™äº›æ¨¡å‹ç”±å¤§é‡çš„ Transformer å±‚ç»„æˆã€‚å®ƒä»¬å¯ä»¥æ ¹æ®åˆå§‹å»ºæ¨¡ä»»åŠ¡çš„ä¸åŒä»¥åŠç¼–ç å™¨å’Œè§£ç å™¨å±‚æ•°çš„å¤šå°‘è¿›è¡Œåˆ†ç±»ã€‚*è‡ªå›å½’æ¨¡å‹*æ˜¯åœ¨ç»å…¸çš„è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„ï¼šåœ¨é˜…è¯»æ‰€æœ‰å…ˆå‰çš„æ ‡è®°åçŒœæµ‹ä¸‹ä¸€ä¸ªæ ‡è®°ã€‚å®ƒä»¬å¯¹åº”äºåŸå§‹ Transformer æ¨¡å‹çš„è§£ç å™¨ï¼Œè¿˜ä½¿ç”¨äº†ä¸€ä¸ªé®ç½©å±‚æ¥è¦†ç›–æ•´ä¸ªå¥å­ï¼Œä»¥ä¾¿æ³¨æ„åŠ›å¤´åªèƒ½çœ‹åˆ°æ–‡æœ¬ä¸­ä¹‹å‰çš„å†…å®¹ï¼Œè€Œä¸æ˜¯ä¹‹åçš„å†…å®¹ã€‚è™½ç„¶å®ƒä»¬å¯ä»¥è¿›è¡Œå¤šç§ä»»åŠ¡çš„å¾®è°ƒï¼Œä½†æœ€å¸¸è§çš„æ˜¯æ–‡æœ¬ç”Ÿæˆã€‚

OpenAI çš„å¤§å‹ GPTï¼ˆç”Ÿæˆé¢„è®­ç»ƒ Transformerï¼‰æ¨¡å‹ç±»æ˜¯ä¸€äº›æœ€è‘—åçš„*è‡ªå›å½’è¯­è¨€æ¨¡å‹*ç¤ºä¾‹ä¹‹ä¸€ã€‚[GPT-2](https://oreil.ly/62C81)ï¼Œä½œä¸ºç¬¬ä¸€ä»£ GPT çš„ç»§ä»»è€…ï¼Œæ‰©å¤§äº†ç½‘ç»œçš„è§„æ¨¡å’Œè®­ç»ƒæ•°æ®çš„èŒƒå›´ã€‚ä½¿ GPT-2 ç‹¬ç‰¹çš„æ˜¯ï¼Œå®ƒèƒ½å¤Ÿæ¨å¹¿åˆ°æ¯”å…¶å‰ä»»é¢„æµ‹çš„æ›´å¤§ä»»åŠ¡é›†åˆï¼Œå¹¶ä¸”åœ¨è¿™äº›ä»»åŠ¡ä¸Šè¡¨ç°æ¯”çº¿æ€§ç¼©æ”¾æ³•é¢„æµ‹çš„è¦å¥½å¾—å¤šã€‚OpenAI æ›¾æœ‰ä¸€æ®µæ—¶é—´æ²¡æœ‰å°† GPT-2 å…¬å¼€å‘å¸ƒï¼Œå› ä¸ºæ‹…å¿ƒå®ƒå¯èƒ½ç”Ÿæˆç±»ä¼¼äººç±»æ–‡æœ¬çš„å†…å®¹ï¼Œè¿™å¯èƒ½è¢«ç”¨äºä¸è‰¯ç›®çš„ã€‚åœ¨[æ›´å¤šäº†è§£å…¶èƒ½åŠ›ä¹‹å](https://oreil.ly/v2iZ3)ï¼ŒOpenAI é€æ¸å‘ç ”ç©¶ä¼™ä¼´ã€å…¬å¸ã€æµ‹è¯•ç”¨æˆ·ä»¥åŠæœ€ç»ˆå‘å…¬ä¼—å‘å¸ƒäº† GPT-2ã€‚

###### æ³¨æ„

æ‚¨å¯ä»¥åœ¨ç¬”è®°æœ¬ [*Chapter_3_Interpreting_GPT.ipynb*](https://oreil.ly/GjIDm) ä¸­æ‰¾åˆ°ä¸æœ¬æ•™ç¨‹ç›¸å…³çš„æ‰€æœ‰ä»£ç ã€‚è¿™ç¯‡ç¬”è®°å—åˆ°äº† LessWrong æ–‡ç«  [Interpreting GPT, the Logit Lens](https://oreil.ly/w6fiB) çš„å¯å‘ã€‚å¤§éƒ¨åˆ†ä»£ç å·²è¿›è¡Œäº†é‡æ„ï¼Œç°åœ¨ä½¿ç”¨çš„æ˜¯ PyTorch å’Œ HuggingFaceï¼Œè€Œä¸æ˜¯ TensorFlowã€‚æœ‰å…³ TensorFlow ç‰ˆæœ¬ï¼Œè¯·å‚é˜…åŸå§‹åšå®¢æ–‡ç« ã€‚

OpenAI åœ¨ [2020 å¹´å‘å¸ƒäº† GPT-3](https://arxiv.org/abs/2005.14165)ï¼Œè¿™æ˜¯æ¯” GPT-2 æ›´å¤§çš„æ¨¡å‹ï¼Œä½¿ç”¨æ›´å¤šçš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¾“å‡ºè´¨é‡æ›´é«˜ã€‚å¾ˆéš¾åˆ¤æ–­ GPT-3 çš„è¾“å‡ºæ˜¯å¦æ˜¯äººç±»å†™çš„ã€‚â¸

åœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼ŒGPT-3 ä»…é€šè¿‡ API å¯ç”¨ã€‚è¿™ä¸ä»…æ˜¯å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œè¿˜å› ä¸ºæ¨¡å‹ä½“ç§¯è¿‡å¤§ï¼šä»…ä¸‹è½½ã€å­˜å‚¨å’Œè¿è¡Œå®ƒå°±æ˜¯ä¸€ä¸ªå¤æ‚ã€è€—æ—¶ä¸”å¯èƒ½æ˜‚è´µçš„è¿‡ç¨‹ã€‚â¹ ä¸è¿‡ï¼Œå¯ä»¥æ”¾å¿ƒåœ°å‡è®¾æˆ‘ä»¬ç”¨æ¥ç†è§£ GPT-2 çš„è®¸å¤šæŠ€æœ¯å’ŒåŸåˆ™ä¹Ÿå¯ä»¥é€‚ç”¨äºåƒ GPT-3 è¿™æ ·æ›´å¤§çš„æ¨¡å‹ã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬æ¢è®¨å¦‚ä½•è·å–æ›´å¤šå…³äº GPT-2 å†³ç­–èƒŒæ™¯çš„ä¸Šä¸‹æ–‡ã€‚

###### æç¤º

å¦‚æœæ‚¨ç‰¹åˆ«ä½¿ç”¨ HuggingFace Transformer æ¨¡å‹å·¥ä½œï¼Œ[exBERT å·¥å…·](https://oreil.ly/zYlcl)æä¾›ä¸é€»è¾‘é•œå¤´ç±»ä¼¼çš„åŠŸèƒ½ã€‚è¿™ä¸ªå¼€æºå·¥å…·ä½¿ç”¨æˆ·èƒ½å¤Ÿæ¢ç´¢ HuggingFace Transformer æ¨¡å‹çš„å­¦ä¹ æ³¨æ„æƒé‡å’Œä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚è¾“å…¥ä¸€ä¸ªå¥å­ï¼ŒexBERT å°†é€šè¿‡æŒ‡å®šçš„æ¨¡å‹ä¼ é€’æ ‡è®°åŒ–çš„è¾“å…¥ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ GPT-2ï¼Œå› ä¸ºå®ƒå¯ä»¥ä» HuggingFace è·å¾—ã€‚ä¸ºäº†æé«˜å¯è§£é‡Šæ€§ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç”±[nostalgebraist](https://oreil.ly/YL6uc)ç¼–å†™çš„å®ç”¨ç¨‹åºåŒ…[transformer-utils](https://oreil.ly/xXHAF)ã€‚Â¹â° è®©æˆ‘ä»¬çœ‹çœ‹è¯„è®ºæ‘˜å½•ã€‚

###### è­¦å‘Š

è¿è¡Œæ­¤ä»£ç éœ€è¦å¤§é‡çš„ RAMã€‚å¦‚æœæ‚¨åœ¨ Google Colab ä¸­è¿è¡Œï¼Œè¯·ä½¿ç”¨ Colab Pro æä¾›çš„æœ€å¤§ GPUï¼Œå¹¶å°† RAM è®¾ç½®ä¸ºæœ€é«˜è®¾ç½®ã€‚

```
# Setting up environment
# Package for more even colormaps
!pip install colorcet

# Huggingface transformers
!pip install transformers
%config InlineBackend.figure_format = 'retina'

!pip install \
git+https://github.com/finetuneanon/transformers/@gpt-neo-localattention
!pip install transformer-utils

# Since these models can take up a lot of memory,
from transformer_utils.low_memory import enable_low_memory_load

enable_low_memory_load()
# it's important to have proper garbage collection
import gc

def cleanup_model(model):
    try:
        if (
            hasattr(model, "base_model_prefix")
            and len(model.base_model_prefix) > 0
        ):
            bm = getattr(model, model.base_model_prefix)
            del bm
    except:
        pass
    del model

    gc.collect()
    torch.cuda.empty_cache()
```

æ‚¨ä¸»è¦å…³æ³¨çš„æ˜¯`plot_logit_lens`å‡½æ•°ï¼Œå®ƒåŒ…è£…äº†æ‚¨å¯ä»¥ç”¨æ¥æŸ¥çœ‹æ¨¡å‹çš„å„ç§åº¦é‡æ ‡å‡†ã€‚è¿™ä¸ªå‡½æ•°ä¸“ä¸ºè§£ç å™¨å’Œä¾èµ–åŸå§‹å˜å‹å™¨çš„è§£ç å™¨éƒ¨åˆ†ä»¥åŠä½¿ç”¨æ³¨æ„åŠ›æ©ç çš„è‡ªå›å½’æ¨¡å‹è€Œè®¾è®¡ï¼Œå› æ­¤åœ¨æ¯ä¸ªä½ç½®ï¼Œæ¨¡å‹åªèƒ½æŸ¥çœ‹æ³¨æ„åŠ›å¤´ä¹‹å‰çš„æ ‡è®°ã€‚è‡ªå›å½’æ¨¡å‹çš„ç©ºé—´åŒ…æ‹¬[åŸå§‹ GPT](https://oreil.ly/pE1Dq)ï¼Œ[GPT-2](https://oreil.ly/wsppp)ï¼Œ[CTRL](https://oreil.ly/fNSRE)ï¼Œ[Transformer-XL](https://oreil.ly/DFEeb)ï¼Œ[Reformer](https://oreil.ly/L8uyH)å’Œ[XLNet](https://oreil.ly/ipV8V)ï¼ˆå°½ç®¡æˆ‘ä»¬ä¸»è¦å…³æ³¨ GPT åŠå…¶åç»§è€…ï¼‰ã€‚è¿™ä¸€ç±»æ¨¡å‹ä¸ç¼–ç å™¨æˆ–è‡ªç¼–ç æ¨¡å‹ã€åºåˆ—åˆ°åºåˆ—å˜å‹å™¨æ¨¡å‹ä»¥åŠæ£€ç´¢æ¨¡å‹å’Œå¤šæ¨¡æ€æ¨¡å‹ï¼ˆä¾‹å¦‚å¦‚ CLIP ä¸­æè¿°çš„ï¼‰æœ‰æ‰€ä¸åŒã€‚è¦å°†æ•°æ®è¾“å…¥è‡ªå›å½’æ¨¡å‹ï¼Œæ‚¨éœ€è¦é¦–å…ˆä½¿ç”¨ GPT-2 çš„æ ‡è®°å™¨å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–ã€‚

```
import torch

def text_to_input_ids(text):
    toks = tokenizer.encode(text)
    return torch.as_tensor(toks).view(1, -1).cuda()

import transformers

tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')
model = transformers.AutoModelForCausalLM.from_pretrained('gpt2')
```

åœ¨æœ¬èŠ‚ä¸­ï¼Œæ‚¨å¯ä»¥åˆ›å»ºæ¨¡å‹é˜…è¯»çš„æ–‡æœ¬é€‰é›†ï¼Œç„¶åä½¿ç”¨`plot_logit_lens`å‡½æ•°æŸ¥çœ‹æ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ä¸»è¦æ–‡æœ¬æ¥è‡ªäºç°åœ¨è‘—åçš„ 2015 å¹´è®ºæ–‡[â€œé€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ å®ç°äººç±»æ°´å¹³æ§åˆ¶â€](https://oreil.ly/n8uxk)ã€‚ä»¥ä¸‹æ˜¯è¯¥è®ºæ–‡çš„æ‘˜è¦ï¼Œä»¥åŠå…³äºç‹—çš„å‡ ä¸ªå­—ç¬¦ä¸²ï¼š

```
deeprl_abstract = """The theory of reinforcement learning provides a normative
account, deeply rooted in psychological and neuroscientific3 perspectives on
animal behaviour, of how agents may optimize their control of an environment.
To use reinforcement learning successfully in situations approaching real-world
complexity, however, agents are confronted with a difficult task: they must
derive efficient representations of the environment from high-dimensional
sensory inputs, and use these to generalize past experience to new situations.
Remarkably, humans and other animals seem to solve this problem through a
harmonious combination of reinforcement learning and hierarchical sensory
processing systems, the former evidenced by a wealth of neural data
revealing notable parallels between the phasic signals emitted by dopaminergic
neurons and temporal difference reinforcement learning algorithms. While
reinforcement learning agents have achieved some successes in a variety of
domains, their applicability has previously been limited to domains in
which useful features can be handcrafted, or to domains with fully observed,
low-dimensional state spaces. Here we use recent advances in training deep
neural networks to develop a novel artificial agent, termed a deep
Q-network, that can learn successful policies directly from high-dimensional
sensory inputs using end-to-end reinforcement learning.""".replace("\n", " ")

dogs = """Sometimes, when people say dog, they mean the verb. """ + \
"""Other times, when people say dog"""
dogs_short = """That's my first example of dogging. My second example of"""

dogs_repetitive = """I love dogs. I love dogs. I love dogs. I love dogs."""

input_ids = text_to_input_ids(deeprl_abstract)

input_ids = input_ids[:, :160]
```

è¯¥è½¯ä»¶åŒ…ç”Ÿæˆè§£ç å™¨æ¯ä¸€å±‚æ´»åŠ¨çš„å›¾è¡¨ï¼Œå¦‚å›¾Â 3-1 æ‰€ç¤ºã€‚è§£ç å™¨æ¨¡å‹é’ˆå¯¹æ¯ä¸ªä½ç½®*n*çš„è¾“å…¥ä»¤ç‰Œï¼ˆæ˜¾ç¤ºåœ¨å›¾è¡¨åº•éƒ¨ï¼Œè¡¨ç¤ºè¾“å…¥ï¼‰å°è¯•é¢„æµ‹ä½ç½®*n* + 1 çš„ä»¤ç‰Œï¼ˆæ˜¾ç¤ºåœ¨å›¾è¡¨é¡¶éƒ¨ï¼Œè¡¨ç¤ºè¾“å‡ºï¼‰ã€‚å„éšè—å±‚åœ¨*Y*è½´ä¾§é¢æ ‡è®°ã€‚å¯¹äºè§£ç å™¨æ¨¡å‹æ¯ä¸ªä»¤ç‰Œçš„æ¯ä¸ªå±‚ï¼Œæˆ‘ä»¬æµ‹é‡çš„å†…å®¹å®Œå…¨å–å†³äºæ‚¨ä¼ é€’ç»™`plot_logit_lens`å‡½æ•°çš„å‚æ•°ã€‚

```
# Looking at the logits applied to each layer as it predicts the abstract.
from transformer_utils.logit_lens import plot_logit_lens

plot_logit_lens(
    model,
    tokenizer,
    input_ids,
    start_ix=75,
    end_ix=100, # We'll look at the logits between positions 75 and 100
    probs=True # Plot the logits for each layer
)
```

`plot_logit_lens`å‡½æ•°çš„è¾“å‡ºæ˜¯æ¯ä¸ªè¾“å‡ºä½ç½®ä¸Šæ¯ä¸ªå±‚æœ€å¯èƒ½çš„ä»¤ç‰Œçš„è¡¨æ ¼ï¼ˆè§å›¾Â 3-1ï¼‰ã€‚

![ptml 0301](img/ptml_0301.png)

###### å›¾Â 3-1\. æŸ¥çœ‹è¿›å…¥ç¬¬ 75 åˆ° 100 ä½ç½®çš„æ¯ä¸ªå±‚çš„ logits

çœ‹åˆ°å…·ä½“çš„è¯è¯­å¾ˆå¥½ï¼Œä½†æ‚¨è¿˜æƒ³çŸ¥é“æ¨¡å‹åœ¨æ¯ä¸ªæ­¥éª¤ä¸­å»ºè®®æ­£ç¡®ä»¤ç‰Œçš„æ¥è¿‘ç¨‹åº¦ã€‚

```
# Ranks of the correct token
plot_logit_lens(
    model,
    tokenizer,
    input_ids,
    start_ix=75,
    end_ix=100,
    ranks=True # ranks of the correct token
)
```

æ‚¨å°†è·å¾—æ¯ä¸ªå±‚çš„æ’åè¡¨æ ¼ï¼ˆè§å›¾Â 3-2ï¼‰ã€‚

![ptml 0302](img/ptml_0302.png)

###### å›¾Â 3-2\. æ¯ä¸ªå±‚çš„æ­£ç¡®ä»¤ç‰Œæ¦‚ç‡çš„æ’åï¼Œé¢†å…ˆäºç¬¬ 75 åˆ° 100 ä½ç½®

KL æ•£åº¦æœ‰åŠ©äºç¡®å®šæ¯å±‚æ¦‚ç‡å®Œå…¨åˆ†å¸ƒä¸æœ€ç»ˆè¾“å‡ºä¹‹é—´çš„å·®å¼‚ç¨‹åº¦ã€‚

```
# Divergence from output distribution as token propagates through network
    plot_logit_lens(
    model,
    tokenizer,
    input_ids,
    start_ix=75,
    end_ix=100,
    kl=True
    # Divergence from output distribution as token propagates through network
)
```

è¿™ç§åˆ†æ­§åœ¨æ—©æœŸå¾ˆé«˜ï¼Œä½†éšåéšç€è¾“å…¥é€šè¿‡ç½‘ç»œä¼ æ’­ï¼Œé€æ¸æ¥è¿‘ 0ï¼ˆè§å›¾Â 3-3ï¼‰ã€‚

![ptml 0303](img/ptml_0303.png)

###### å›¾Â 3-3\. æ¦‚ç‡çš„ KL æ•£åº¦

å¦‚æœå‰é¢çš„å†…å®¹å¯¹æ‚¨ä¸å¤Ÿè¯¦ç»†ï¼Œæ‚¨è¿˜å¯ä»¥æŒ‡å®šåŒ…å«ç½‘ç»œå­å—ã€‚

```
# Copying a Rare token
plot_logit_lens(
    model,
    tokenizer,
    input_ids,
    start_ix=75,
    end_ix=100,
    ranks=True,
    include_subblocks=True, # Whether to include subblocks
)
```

ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œæ‚¨å¯ä»¥çœ‹åˆ°æ­£ç¡®è¾“å‡ºä»¤ç‰Œçš„æ’åéœ€è¦å¤šå¤§åŠªåŠ›æ‰èƒ½è¶…è¿‡æ‰€æœ‰ç«äº‰é€‰æ‹©ï¼ˆè§å›¾Â 3-4ï¼‰ã€‚

![ptml 0304](img/ptml_0304.png)

###### å›¾Â 3-4\. ç¨€æœ‰ä½†æ­£ç¡®è¾“å‡ºä»¤ç‰Œçš„æ’åï¼Œæ¶µç›–å­å—

`   `plot_logit_lens`å®ç”¨ç¨‹åºå…·æœ‰è®¸å¤šä¸åŒç²’åº¦çº§åˆ«çš„é€‰é¡¹ã€‚å¦‚æœæˆ‘ä»¬åˆ‡æ¢åˆ°æ›´åŠ é‡å¤çš„è¾“å…¥ï¼Œæ‰€æœ‰è¿™äº›ä¼šæ˜¯ä»€ä¹ˆæ ·å­ï¼Ÿ

```
# Extremely repetitive inputs
plot_logit_lens(
    model,
    tokenizer,
    input_ids,
    start_ix=75,
    end_ix=100,
    ranks=True,
    include_subblocks=True,
    decoder_layer_names=["h.11", "final_layernorm", "lm_head"],
)  # Adding in the names of the decoder layers
```

å¯¹é‡å¤è¾“å…¥çš„è¿™ç§åˆ†æç”Ÿæˆäº†å›¾Â 3-5ã€‚

![ptml 0305](img/ptml_0305.png)

###### å›¾Â 3-5\. å¯¹æ›´é‡å¤çš„è¾“å…¥è¿›è¡Œåˆ†æ

é‚£ä¹ˆè¿™ä¸€åˆ‡å¦‚ä½•ä¸ä¸‰éƒ¨åˆ†æ¡†æ¶ç›¸å…³è”ï¼Ÿ

å¦‚æœæ‚¨æƒ³è¿›è¡Œåº”ç”¨çº§è¯„ä¼°ï¼Œæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆèƒ½å¦è½»æ¾ç†è§£æ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…ï¼Ÿæ‚¨å¸Œæœ›å°†åº”ç”¨çº§è¯„ä¼°äº§ç”Ÿçš„è§£é‡Šä¸å…¶ä»–è§£é‡Šå¤§å‹è¯­è¨€æ¨¡å‹å†…éƒ¨æœºåˆ¶çš„æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚æœ€é‡è¦çš„æ˜¯ï¼Œæ‚¨å¸Œæœ›å°†å…¶ä¸ ML å·¥ç¨‹å¸ˆçš„åŒäº‹å¦‚ä½•è§£é‡Šæ¨¡å‹å†…éƒ¨æœºåˆ¶è¿›è¡Œæ¯”è¾ƒã€‚

å¦‚æœä½ æƒ³ä»â€œäººç±»æ°´å¹³è¯„ä¼°â€çš„è§’åº¦æ¥è¯„ä»·è¿™ä¸ªè§£é‡Šï¼Œä½ ä¼šæŠŠç„¦ç‚¹ä»ä»…é™äºæœºå™¨å­¦ä¹ å¼€å‘è€…æ‰©å±•åˆ°è¯¢é—®éæœºå™¨å­¦ä¹ è½¯ä»¶å·¥ç¨‹å¸ˆï¼ˆæˆ–è€…æ›´å¥½çš„æ˜¯éå·¥ç¨‹å¸ˆï¼‰æ˜¯å¦èƒ½ç†è§£æ¨¡å‹ä¸­æ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…ã€‚è¿™ç§æ–¹æ³•å¯èƒ½æ¶‰åŠåœ¨å›¾ä¸­æ›´æ˜ç¡®åœ°è§£é‡Šä»è¾“å…¥åˆ°è¾“å‡ºçš„æ¡†æ¶ã€‚

ä½ å¯ä»¥åœ¨å¾—åˆ°äººç±»åé¦ˆåè¿›è¡ŒåŠŸèƒ½çº§è¯„ä¼°ã€‚ä¸€æ—¦ä½ äº†è§£äº†äººç±»èƒ½å¤Ÿå¼€å§‹ç†è§£çš„è§£é‡Šç±»å‹ï¼Œä½ å°±å¸Œæœ›æœ‰æŸç§ä»£ç†æŒ‡æ ‡æ¥è¯„ä¼°è¿™äº›è§£é‡Šã€‚ä¾‹å¦‚ï¼Œæ­£ç¡®ä»¤ç‰Œåœ¨å›¾è¡¨ä¸­å‡ºç°çš„æ—¶é—´æœ‰å¤šæ—©ï¼Ÿæˆ‘ä»¬å¯ä»¥æ¯”è¾ƒè¿™ç§æ—¶é—´è·¨å…¶ä»–å˜å‹å™¨æ¨¡å‹ã€‚ä½ è¿˜å¯ä»¥è®¡æ—¶è§£é‡Šæ€§æ–¹æ³•çš„è¿è¡Œæ—¶é—´ã€‚åˆ†æ GPT æ¨¡å‹å±‚æ¬¡çš„å„ç§æ–¹æ³•æ¯”åƒ SHapley Additive exPlanationsï¼ˆæˆ–ç®€ç§° SHAPï¼Œè§â€œShapley and SHAPâ€ï¼‰è¿™æ ·çš„æŠ€æœ¯å¯¹å¦‚æ­¤å¤§é‡çš„è¾“å…¥å’Œè¾“å‡ºæ¥è¯´è¦å¿«å¾—å¤šã€‚

# è§£é‡Šæ¨¡å‹å’Œè§£é‡Šè¾“å‡ºçš„æ–¹æ³•

æ¨¡å‹å¯è§£é‡Šæ€§å’Œå¯è§£é‡Šæ€§é¢†åŸŸå‘å±•è¿…é€Ÿã€‚ç„¶è€Œï¼Œä¸€äº›æ–¹æ³•å³ä½¿ç»è¿‡æ•°åå¹´çš„ä½¿ç”¨ä»ç»å—ä½äº†æ—¶é—´çš„è€ƒéªŒã€‚

## æœ¬è´¨ä¸Šå¯è§£é‡Šçš„æ¨¡å‹

ä¸€äº›æ¨¡å‹æ˜“äºè§£é‡Šï¼Œå› ä¸ºå®ƒä»¬çš„å„ä¸ªå‚æ•°å¯¹åº”äºäººç±»å¯ä»¥è½»æ¾ç†è§£çš„å†³ç­–ç‚¹ï¼Œä¾‹å¦‚çº¿æ€§å’Œé€»è¾‘å›å½’æ¨¡å‹ã€ç¬¦å·å›å½’æ¨¡å‹ã€æ”¯æŒå‘é‡æœºå’Œå†³ç­–æ ‘ã€‚

### çº¿æ€§å›å½’

*çº¿æ€§å›å½’*ï¼ˆä»¥åŠå¤šå…ƒçº¿æ€§å›å½’ï¼‰æˆ–è®¸æ˜¯æœ€ç®€å•çš„å›ºæœ‰å¯è§£é‡Šæ¨¡å‹ç±»å‹ã€‚çº¿æ€§å›å½’æ¨¡å‹åªéœ€è¾“å…¥ä¸€ä¸ªä¾èµ–å˜é‡å’Œä¸€ä¸ªç‹¬ç«‹å˜é‡çš„æ•°æ®é›†ã€‚ç»™å®šæ•°æ®é›† <math alttext="StartSet y Subscript i Baseline comma x Subscript i Baseline 1 Baseline comma ellipsis comma x Subscript i p Baseline EndSet Subscript i equals 1 Superscript n"><msubsup><mrow><mo>{</mo><msub><mi>y</mi> <mi>i</mi></msub> <mo>,</mo><msub><mi>x</mi> <mrow><mi>i</mi><mn>1</mn></mrow></msub> <mo>,</mo><mo>...</mo><mo>,</mo><msub><mi>x</mi> <mrow><mi>i</mi><mi>p</mi></mrow></msub> <mo>}</mo></mrow> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup></math> ï¼Œå…¶ä¸­ <math alttext="y"><mi>y</mi></math> è¡¨ç¤ºç‹¬ç«‹å˜é‡ï¼Œ<math alttext="x"><mi>x</mi></math> è¡¨ç¤ºä¾èµ–å˜é‡ï¼Œæ¨¡å‹ä¸º <math alttext="y Subscript i Baseline equals beta 0 plus beta 1 x Subscript i Baseline 1 Baseline plus ellipsis plus beta Subscript p Baseline x Subscript i p Baseline plus epsilon Subscript i Baseline equals bold x Subscript i Superscript upper T Baseline beta plus epsilon Subscript i"><mrow><msub><mi>y</mi> <mi>i</mi></msub> <mo>=</mo> <msub><mi>Î²</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î²</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mrow><mi>i</mi><mn>1</mn></mrow></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>Î²</mi> <mi>p</mi></msub> <msub><mi>x</mi> <mrow><mi>i</mi><mi>p</mi></mrow></msub> <mo>+</mo> <msub><mi>Ïµ</mi> <mi>i</mi></msub> <mo>=</mo> <msubsup><mi>ğ±</mi> <mrow><mi>i</mi></mrow> <mi>T</mi></msubsup> <mi>Î²</mi> <mo>+</mo> <msub><mi>Ïµ</mi> <mi>i</mi></msub></mrow></math> ï¼Œå…¶ä¸­ <math alttext="i equals 1 comma ellipsis comma n"><mrow><mi>i</mi> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo>...</mo> <mo>,</mo> <mi>n</mi></mrow></math> ã€‚

è¿™é‡Œå„ä¸ª beta é¡¹æè¿°äº†çº¿æ€§å…³ç³»ï¼Œè€Œ epsilon è¡¨ç¤ºéšæœºè¯¯å·®é¡¹ã€‚è¦çœ‹åˆ°è¿™ä¸€ç‚¹çš„å®é™…æ•ˆæœï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸ªéå¸¸ç®€å•çš„çº¿æ€§å›å½’ç¤ºä¾‹ï¼š

```
# 1\. Create example data in the form of Numpy arrays
import numpy as np

# Create a random dataset
rng = np.random.RandomState(1)
X = np.linspace(0, 6, 100)[:, np.newaxis]
y = np.sin(X).ravel() + np.sin(6 * X).ravel() + rng.normal(0, 0.1, X.shape[0])

# 2\. fit a scikit-learn linear regression model
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Create linear regression object
regr = LinearRegression()

# Train the model using the training sets
regr.fit(X, y)

# Make predictions using the testing set
y_pred = regr.predict(X)

# The coefficients
print('Coefficients: \n', regr.coef_)
# The mean squared error
print("Mean squared error: %.2f"
      % mean_squared_error(y, y_pred))
# Explained variance score: 1 is perfect prediction
print('Variance score: %.2f' % r2_score(y, y_pred))
```

```
Coefficients:
 [-0.35745894]
Mean squared error: 0.61
Variance score: 0.39
```

å¦‚æœä½ æœ‰ä¸€ä¸ªå›å½’é—®é¢˜ï¼Œåœ¨è½¬å‘æ›´å¤æ‚çš„æ¨¡å‹ä¹‹å‰ï¼Œé¦–å…ˆç¡®ä¿çº¿æ€§å›å½’èƒ½å¤Ÿå……åˆ†è§£å†³è¿™ä¸ªé—®é¢˜æ˜¯æœ€ä½³å®è·µã€‚ä½ å¯èƒ½ä¼šæƒŠè®¶åœ°çœ‹åˆ°æœ‰å¤šå°‘é—®é¢˜å¯ä»¥é€šè¿‡çº¿æ€§å›å½’æ¨¡å‹å……åˆ†è§£å†³ã€‚Â¹Â¹

###### æç¤º

æƒ³è¦åœ¨ (Intel) CPU ä¸ŠåŠ é€Ÿ scikit-learn å—ï¼Ÿé€šè¿‡ [scikit-learn-intelex](https://oreil.ly/YEwz1)ï¼Œåªéœ€æ·»åŠ ä¸€è¡Œä»£ç ï¼Œé€Ÿåº¦æé«˜äº†å¤§çº¦ 1.4 è‡³ 4,800 å€ï¼š

```
from sklearnex import patch_sklearn; patch_sklearn()
```

è°ˆåˆ°ä»£ç ï¼Œè¿™äº›å›ºæœ‰å¯è§£é‡Šæ¨¡å‹å¯ä»¥åœ¨ç¬”è®°æœ¬ [*Chapter_3_Intrinsically_Interpretable_Models.ipynb*](https://oreil.ly/IxnwJ) ä¸­è¿›ä¸€æ­¥æ¢ç´¢ã€‚

### é€»è¾‘å›å½’

*é€»è¾‘å›å½’*æ˜¯ä¸€ç§çº¿æ€§æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹åˆ†ç±»å˜é‡çš„æ¦‚ç‡ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒæ˜¯ä¸€ä¸ªäºŒå…ƒåˆ†ç±»å™¨ã€‚ä¹‹æ‰€ä»¥ç§°ä¸ºâ€œå›å½’â€ï¼Œæ˜¯å› ä¸ºå®ƒæ˜¯ä¸€ä¸ªäº‹ä»¶æˆ–å˜é‡æ¦‚ç‡çš„å›å½’æ¨¡å‹ã€‚è¯¥äº‹ä»¶æˆ–å˜é‡çš„å€¼å–å†³äºæ˜¯å¦è¾¾åˆ°äº†æŸä¸ªæ¦‚ç‡é˜ˆå€¼ã€‚

åœ¨æ–‡çŒ®ä¸­ï¼Œé€»è¾‘å›å½’ä¹Ÿè¢«ç§°ä¸º*logit å›å½’*ã€*æœ€å¤§ç†µåˆ†ç±»ï¼ˆMaxEntï¼‰*æˆ–*å¯¹æ•°çº¿æ€§åˆ†ç±»å™¨*ã€‚åœ¨è¯¥æ¨¡å‹ä¸­ï¼Œé€šè¿‡ä¸€ä¸ª[é€»è¾‘å‡½æ•°](https://oreil.ly/yvTrp)ï¼Œæ¥å»ºæ¨¡æè¿°å•æ¬¡è¯•éªŒå¯èƒ½ç»“æœçš„æ¦‚ç‡ï¼Œå…¶ä¸­<math alttext="f left-parenthesis x right-parenthesis equals StartFraction upper L Over 1 plus e Superscript minus k left-parenthesis x minus x 0 right-parenthesis Baseline EndFraction"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mi>L</mi> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi> <mrow><mo>-</mo><mi>k</mi><mo>(</mo><mi>x</mi><mo>-</mo><msub><mi>x</mi> <mn>0</mn></msub> <mo>)</mo></mrow></msup></mrow></mfrac></mrow></math>ï¼Œå…¶ä¸­<math alttext="x 0"><msub><mi>x</mi> <mn>0</mn></msub></math>æ˜¯ S å‹å‡½æ•°ä¸­ç‚¹çš„<math alttext="x"><mi>x</mi></math>å€¼ï¼Œ<math alttext="upper L"><mi>L</mi></math>æ˜¯æ›²çº¿çš„æœ€å¤§å€¼ï¼Œ<math alttext="k"><mi>k</mi></math>æ˜¯é€»è¾‘å¢é•¿ç‡æˆ–æ›²çº¿çš„é™¡å³­åº¦ã€‚

åœ¨æ­¤ä»£ç ç‰‡æ®µä¸­ï¼Œæ‚¨å¯ä»¥åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„é€»è¾‘å›å½’æ¨¡å‹ï¼Œç„¶åæŸ¥çœ‹å†³ç­–è¾¹ç•Œã€‚

```
import numpy as np
from sklearn.linear_model import LogisticRegression

import matplotlib.pyplot as plt

# 1\. Create example data in the form of Numpy arrays

# Create a random dataset
rng = np.random.RandomState(0)
X = np.array([[1, 50], [5, 20], [3, 80], [5, 60]])
y = [0, 0, 1, 1]

# 2\. fit a scikit-learn logistic regression model

# Fit the model
clf = LogisticRegression()
clf.fit(X, y)

# 3\. plot the model coefficients with matplotlib

# Plot the points
plt.scatter(X[:,0], X[:,1], c=y, s=30, cmap=plt.cm.Paired)

# Plot the decision function
ax = plt.gca()
xlim = ax.get_xlim()
ylim = ax.get_ylim()

# create grid to evaluate model
xx = np.linspace(xlim[0], xlim[1], 30)
yy = np.linspace(ylim[0], ylim[1], 30)
YY, XX = np.meshgrid(yy, xx)
xy = np.vstack([XX.ravel(), YY.ravel()]).T
Z = clf.decision_function(np.column_stack([xx.ravel(), yy.ravel()]))

# put the result into a color plot
Z = Z.reshape(xx.shape)
ax.contourf(xx, yy, Z, cmap=cm_piyg, alpha=0.8)

# plot the training points
ax.scatter(
    X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors="k"
)
# and testing points
ax.scatter(
    X_test[:, 0],
    X_test[:, 1],
    c=y_test,
    cmap=cm_bright,
    edgecolors="k",
    alpha=0.6,
)
ax.set_xlim(xx.min(), xx.max())
ax.set_ylim(yy.min(), yy.max())
ax.set_xticks(())
ax.set_yticks(())
```

å°±åƒçº¿æ€§å›å½’æ˜¯å›å½’é—®é¢˜çš„ç®€å•é¦–é€‰ä¸€æ ·ï¼Œé€»è¾‘å›å½’æ˜¯åˆ†ç±»é—®é¢˜çš„ç®€å•é¦–é€‰ã€‚æ­£å¦‚æ‚¨åœ¨å‰é¢çš„ä»£ç ç‰‡æ®µä¸­çœ‹åˆ°çš„é‚£æ ·ï¼Œé€»è¾‘å›å½’æ¨¡å‹å®šä¹‰èµ·æ¥éå¸¸ç®€å•ï¼Œå¤§éƒ¨åˆ†ä»£ç ç”¨äºç»˜å›¾ã€‚

å°†å®ƒä»¬çš„è¾“å‡ºæè¿°ä¸ºè¾“å…¥å˜é‡åŠ æƒå’Œçš„çº¿æ€§æ¨¡å‹æ˜“äºå®æ–½å’Œç†è§£ã€‚é—®é¢˜åœ¨äºå®ƒä»¬ä¾èµ–äºé€šå¸¸åœ¨ç°å®ä¸–ç•Œä¸­ä¸æˆç«‹çš„æŸäº›å‡è®¾ã€‚ä¾‹å¦‚ï¼Œçº¿æ€§å›å½’é€šå¸¸å‡è®¾è¯¯å·®Îµéµå¾ªé«˜æ–¯åˆ†å¸ƒï¼Œä½†ç°å®ä¸–ç•Œçš„ç°è±¡å¯èƒ½éµå¾ªçœ‹èµ·æ¥ä¸é«˜æ–¯åˆ†å¸ƒå®Œå…¨ä¸åŒçš„åˆ†å¸ƒã€‚æœ‰äº›å˜é‡å¯èƒ½ä¼šäº’ç›¸ä½œç”¨ï¼Œè€Œå¦ä¸€äº›åˆ™å¯èƒ½ä¸ä¼šã€‚åœ¨ç›¸äº’ä½œç”¨çš„å˜é‡ä¸­ï¼Œæœ‰äº›å¯èƒ½å…·æœ‰çº¿æ€§å…³ç³»ï¼Œè€Œå¦ä¸€äº›å¯èƒ½å…·æœ‰éçº¿æ€§å…³ç³»ã€‚å¹¸è¿çš„æ˜¯ï¼Œæœ‰å„ç§å„æ ·çš„éçº¿æ€§æ¨¡å‹å¯ä»¥æ›´å¥½åœ°æ‹Ÿåˆæ•°æ®ï¼ŒåŒæ—¶ä»ç„¶æä¾›è§£é‡Šèƒ½åŠ›ã€‚

### å¹¿ä¹‰çº¿æ€§æ¨¡å‹

å¦‚æœç»™å®šç‰¹å¾æ—¶ç›®æ ‡ç»“æœ*y*ä¸ç¬¦åˆé«˜æ–¯åˆ†å¸ƒï¼Œåˆ™å¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼ˆGLMï¼‰æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚GLM çš„ä¸»è¦æ–¹æ³•æ˜¯ä¿æŒç‰¹å¾çš„åŠ æƒå’Œï¼Œä½†å…è®¸éé«˜æ–¯ç»“æœåˆ†å¸ƒï¼Œå¹¶å°†æ­¤åˆ†å¸ƒçš„æœŸæœ›å‡å€¼ä¸åŠ æƒå’Œç›¸è¿æ¥ã€‚

<math alttext="g left-parenthesis upper E Subscript upper Y Baseline left-parenthesis y vertical-bar x right-parenthesis right-parenthesis equals beta 0 plus beta 1 x 1 plus ellipsis beta Subscript p Baseline x Subscript p" display="block"><mrow><mi>g</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mi>Y</mi></msub> <mrow><mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <msub><mi>Î²</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î²</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mo>...</mo> <msub><mi>Î²</mi> <mi>p</mi></msub> <msub><mi>x</mi> <mi>p</mi></msub></mrow></math>

è™½ç„¶ GLMs å¯ç”¨äºé«˜æ–¯åˆ†å¸ƒï¼Œä½†è¿™ç§æ–¹æ³•ä¹Ÿå¯åº”ç”¨äºæ³Šæ¾ã€Gamma å’Œå Gamma åˆ†å¸ƒã€‚

å¯¹äº GLMsï¼Œä½ å¯ä»¥ä½¿ç”¨ scikit-learn çš„[å¹¿ä¹‰çº¿æ€§æ¨¡å‹](https://oreil.ly/lxOV8)ã€‚åœ¨å¯¼å…¥ TweedieRegressor åï¼Œä½ å¯ä»¥è°ƒæ•´`power`ã€`alpha`å’Œ`link`è®¾ç½®æ¥è°ƒæ•´çº¿æ€§æ¨¡å‹çš„å¤æ‚æ€§ã€‚

```
>>> from sklearn.linear_model import TweedieRegressor
>>> reg = TweedieRegressor(power=1, alpha=0.5, link='log')
>>> reg.fit([[0, 0], [0, 1], [2, 2]], [0, 1, 2])
TweedieRegressor(alpha=0.5, link='log', power=1)
>>> reg.coef_
array([0.2463..., 0.4337...])
>>> reg.intercept_
-0.7638...
```

è¾“å‡ºæ˜¯ä¸€ç³»åˆ—ç³»æ•°ï¼ˆæ‰€æœ‰ beta å€¼ï¼‰å’Œä¸€ä¸ªæˆªè·ï¼ˆå¯¹åº”äºç¬¬ä¸€ä¸ª betaï¼‰ã€‚

### å¹¿ä¹‰å¯åŠ æ¨¡å‹

å¦‚æœç‰¹å¾ä¸*y*ä¹‹é—´çš„çœŸå®å…³ç³»ä¸æ˜¯çº¿æ€§çš„ï¼Œé‚£ä¹ˆ**å¹¿ä¹‰å¯åŠ æ¨¡å‹**ï¼ˆGAMï¼‰æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚GAMs åŸºæœ¬ä¸Šæ˜¯å…è®¸éçº¿æ€§å…³ç³»çš„å¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼ˆGLMsï¼‰ã€‚å…¶å…¬å¼éå¸¸ç›¸ä¼¼ï¼š

<math alttext="g left-parenthesis upper E Subscript upper Y Baseline left-parenthesis y vertical-bar x right-parenthesis right-parenthesis equals beta 0 plus f 1 left-parenthesis x 1 right-parenthesis plus f 2 left-parenthesis x 2 right-parenthesis plus ellipsis plus f Subscript p Baseline left-parenthesis x Subscript p Baseline right-parenthesis" display="block"><mrow><mi>g</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mi>Y</mi></msub> <mrow><mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <msub><mi>Î²</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>f</mi> <mi>p</mi></msub> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>p</mi></msub> <mo>)</mo></mrow></mrow></math>

å”¯ä¸€çš„åŒºåˆ«æ˜¯çº¿æ€§é¡¹<math alttext="beta Subscript p Baseline x Subscript p"><mrow><msub><mi>Î²</mi> <mi>p</mi></msub> <msub><mi>x</mi> <mi>p</mi></msub></mrow></math> è¢«æ›´åŠ çµæ´»çš„<math alttext="f Subscript p Baseline left-parenthesis x Subscript p Baseline right-parenthesis"><mrow><msub><mi>f</mi> <mi>p</mi></msub> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>p</mi></msub> <mo>)</mo></mrow></mrow></math> å‡½æ•°ï¼ˆé€šå¸¸ä»£è¡¨æ ·æ¡å‡½æ•°ï¼‰å–ä»£ã€‚å®ƒä»ç„¶æ˜¯ç‰¹å¾çš„æ€»å’Œï¼Œä½†ç°åœ¨å¯é€‰çš„éçº¿æ€§ç”±è¿™äº›å‡½æ•°è¡¨ç¤ºã€‚

è¦åœ¨ Python ä¸­ä½¿ç”¨ GAMsï¼Œä½ å¯ä»¥ä½¿ç”¨[pyGAM](https://oreil.ly/eQwEd)ã€‚

```
!pip install pygam
from pygam import LinearGAM

import matplotlib.pyplot as plt
redwine_url = 'https://matthewmcateer.me/media/oreilly_book/redwine-quality.csv'
redwine = pd.read_csv(redwine_url)
# Prepare dataset
redwine_X = redwine.drop(['quality'], axis=1).values
redwine_y = redwine['quality']
# Build model with gridsearch
lams = np.random.rand(100, 11)
lams = lams * 11 - 3
lams = np.exp(lams)
print(lams.shape)
gam = LinearGAM(n_splines=10).gridsearch(redwine_X, redwine_y, lam=lams)
# Create partial dependence plots
titles = redwine.columns[0:11]
plt.figure()
fig, axs = plt.subplots(1,11,figsize=(40, 5))

for i, ax in enumerate(axs):
    XX = gam.generate_X_grid(term=i)
    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))
    ax.plot(
        XX[:, i],
        gam.partial_dependence(term=i, X=XX, width=0.95)[1],
        c="r",
        ls="--",
    )
    if i == 0:
        ax.set_ylim(-30, 30)
    ax.set_title(titles[i])
```

### å¹¿ä¹‰å¯åŠ æ¨¡å‹åŠ äº¤äº’é¡¹

å¦‚æœç‰¹å¾ä¹‹é—´å­˜åœ¨äº¤äº’ä½œç”¨ï¼Œé‚£ä¹ˆä½ å¯ä»¥æ‰‹åŠ¨æ·»åŠ äº¤äº’é¡¹ï¼Œæˆ–è€…è½¬å‘**å¹¿ä¹‰å¯åŠ æ¨¡å‹åŠ äº¤äº’é¡¹**ï¼ˆGA2Msï¼‰ã€‚Â¹Â² è¿™äº›æ¨¡å‹æ•æ‰çš„äº¤äº’ä½œç”¨æ¯”æ™®é€šçš„ GAMs å¤æ‚å¾—å¤šã€‚å°† GA2Ms åº”ç”¨åˆ°æ•°æ®é›†ä¸Šä¸åº”ç”¨ GAMs å¹¶æ²¡æœ‰å¤ªå¤§åŒºåˆ«ã€‚

```
import pandas as pd
import numpy as np
from interpret import show
from interpret.data import Marginal
from sklearn.model_selection import train_test_split

np.random.seed(0)
df = pd.read_csv('/winequality-red.csv') # Load the data

Y = df['quality'] # The target variable is 'quality'
X = df[
    [
        "fixed acidity",
        "volatile acidity",
        "citric acid",
        "residual sugar",
        "chlorides",
        "free sulfur dioxide",
        "total sulfur dioxide",
        "density",
        "pH",
        "sulphates",
        "alcohol",
    ]
]
X_featurenames = X.columns
# Split the data into train and test data:
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)

# Loading the data exploration tool
marginal = Marginal().explain_data(X_train, Y_train, name = 'Train Data')
show(marginal)
```

é™¤äº†æ¢ç´¢æ•°æ®å¤–ï¼Œä½ è¿˜å¯ä»¥è®­ç»ƒ GA2M æ¨¡å‹ï¼Œå®ƒè¡¨ç°ä¸º`ExplainableBoostingRegressor`ç±»ã€‚å¦‚æœä½ åœ¨è§£å†³åˆ†ç±»é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨`ExplainableBoostingClassifier`ç±»ã€‚

```
from interpret.glassbox import (
    ExplainableBoostingRegressor,
    LinearRegression,
    RegressionTree,
)

lr = LinearRegression(random_state=seed)
lr.fit(X_train, Y_train)

rt = RegressionTree(random_state=seed)
rt.fit(X_train, Y_train)

ebm = ExplainableBoostingRegressor(random_state=seed)
ebm.fit(X_train, Y_train)
# For Classifier, use ebm = ExplainableBoostingClassifier()
```

ä½¿ç”¨è¿™ç§æ–¹æ³•çš„ç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿè™½ç„¶ GA2M ä¸­çš„æˆå¯¹äº¤äº’é¡¹æå¤§åœ°æé«˜äº†å‡†ç¡®æ€§ï¼Œä½†è¯¥æ¨¡å‹çš„è®¡ç®—éå¸¸è€—æ—¶å’Œ CPU å¯†é›†ã€‚

### ç¬¦å·å›å½’

å…ˆå‰æè¿°çš„è®¸å¤šæ–¹æ³•éƒ½å¯ä»¥è§†ä¸ºåˆ›å»ºå¤§å‹æ–¹ç¨‹ä½œä¸ºæ¨¡å‹çš„æ–¹å¼ã€‚*ç¬¦å·å›å½’*ï¼ˆSRï¼‰å°†è¿™ä¸€è¿‡ç¨‹æ¨å‘æè‡´ï¼Œé€šè¿‡è¿­ä»£åœ°æ”¹å˜å…¬å¼çš„ç»„æˆéƒ¨åˆ†ä»¥æ›´å¥½åœ°æ‹Ÿåˆæ•°æ®ã€‚SR å¯»æ±‚ä»¥ï¼ˆå¸Œæœ›æ˜¯ä¼˜é›…çš„ï¼‰æ•°å­¦è¡¨è¾¾å¼å½¢å¼çš„æ•°æ®å‡†ç¡®æ¨¡å‹ã€‚SR é€šå¸¸è¢«è®¤ä¸ºæ˜¯å›°éš¾çš„ï¼Œå¹¶ä¸”é€šå¸¸ä½¿ç”¨è¿›åŒ–ç®—æ³•å°è¯•ã€‚å¦‚æœä½ æœ‰è¡¨æ ¼æ•°æ®æˆ–è€…å¯ä»¥ç”¨æ–¹ç¨‹æè¿°çš„æ•°æ®ï¼Œé‚£ä¹ˆç¬¦å·å›å½’æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚

å‡è®¾ä½ æœ‰ä¸€ä¸ªäºŒç»´æ•°æ®é›†ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

```
import numpy as np

X = 2 * np.random.randn(100, 5)
y = 2.5382 * np.cos(X[:, 3]) + X[:, 0] ** 2 - 0.5
```

è¿™ä¸ªæ•°æ®é›†åŒ…å« 100 ä¸ªæ•°æ®ç‚¹ï¼Œæ¯ä¸ªæ•°æ®ç‚¹æœ‰ 5 ä¸ªç‰¹å¾ã€‚ä¸æ¨¡å‹çš„å…³ç³»æ˜¯ 2.5382 <math alttext="cosine left-parenthesis x 3 right-parenthesis plus x 0 squared minus 0.5"><mrow><mo form="prefix">cos</mo> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <msubsup><mi>x</mi> <mn>0</mn> <mn>2</mn></msubsup> <mo>-</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn></mrow></math> ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª [PySR](https://oreil.ly/GeV6M) æ¨¡å‹å¹¶è¿›è¡Œè®­ç»ƒã€‚PySR çš„ä¸»è¦æ¥å£é‡‡ç”¨äº†ç±»ä¼¼ scikit-learn çš„é£æ ¼ã€‚

```
from pysr import PySRRegressor
model = PySRRegressor(
    model_selection="best",  # Result is mix of simplicity+accuracy
    niterations=40,
    binary_operators=["+", "*"],
    unary_operators=[
        "cos",
        "exp",
        "sin",
        "inv(x) = 1/x",
	# ^ Custom operator (julia syntax)
    ],
    extra_sympy_mappings={"inv": lambda x: 1 / x},
    # ^ Define operator for SymPy as well
    loss="loss(x, y) = (x - y)Â²",
    # ^ Custom loss function (julia syntax)
)
```

è¿™å°†è®¾ç½®æ¨¡å‹ä¸ºæœç´¢ä»£ç çš„ 40 æ¬¡è¿­ä»£ï¼Œå…¶ä¸­åŒ…å«æ•°åä¸‡æ¬¡çš„å˜å¼‚å’Œæ–¹ç¨‹æ±‚è§£ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥é€šè¿‡è¿è¡Œ `model.fit(X, y)` å°†æ¨¡å‹æ‹Ÿåˆåˆ°æ•°æ®ä¸Šã€‚åœ¨å†…éƒ¨ï¼Œè¿™å°†å¯åŠ¨ä¸€ä¸ª Julia è¿›ç¨‹ï¼Œè¯¥è¿›ç¨‹å°†è¿›è¡Œå¤šçº¿ç¨‹æœç´¢ä»¥é€‚åº”æ•°æ®é›†çš„æ–¹ç¨‹å¼ã€‚

###### æ³¨æ„

å¦‚æœæ‚¨ä¸ç†Ÿæ‚‰ [Julia è¯­è¨€](https://julialang.org)ï¼Œå®ƒå¯¹æœºå™¨å­¦ä¹ éå¸¸æœ‰ç”¨ã€‚Julia æ˜¯ä¸€ç§åŠ¨æ€çš„ã€é€šç”¨çš„ç¼–ç¨‹è¯­è¨€ï¼Œèƒ½å¤Ÿè¿›è¡Œé«˜æ€§èƒ½ç§‘å­¦è®¡ç®—ï¼Œæ”¯æŒé«˜çº§ä»£ç ä¸­çš„ UTF-8 ç¼–ç ï¼Œå¦‚æ•°å­¦ç¬¦å·å’Œè¡¨æƒ…ç¬¦å·ã€‚

å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤šï¼ŒOâ€™Reilly æœ‰ä¸€äº›å¾ˆæ£’çš„èµ„æºï¼Œæ¯”å¦‚ [â€œå­¦ä¹  Juliaâ€](https://oreil.ly/E58zY)ã€‚

æ–¹ç¨‹å¼å°†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰“å°å‡ºæ¥ï¼Œä¸€æ—¦æ‚¨æ»¡æ„ï¼Œå¯ä»¥é€šè¿‡æŒ‰ `'q'` ç„¶å `\<enter\>` æ¥æå‰é€€å‡ºã€‚æ¨¡å‹æ‹Ÿåˆå®Œæˆåï¼Œæ‚¨å¯ä»¥è¿è¡Œ `model.predict(X)` æ¥æŸ¥çœ‹åœ¨ç»™å®šæ•°æ®é›†ä¸Šçš„é¢„æµ‹ç»“æœã€‚è¿è¡Œ `print(model)` å¯ä»¥æ‰“å°å‡ºå­¦ä¹ åˆ°çš„æ–¹ç¨‹å¼ã€‚

```
PySRRegressor.equations_ = [
	   pick     score                                           equation \
	0        0.000000                                          4.4324794 \
	1        1.255691                                          (x0 * x0) \
	2        0.011629                          ((x0 * x0) + -0.28087974) \
	3        0.897855                              ((x0 * x0) + cos(x3)) \
	4        0.857018                ((x0 * x0) + (cos(x3) * 2.4566472)) \
	5  >>>>       inf  (((cos(x3) + -0.19699033) * 2.5382123) + (x0 *... \
       loss  complexity
  42.354317           1
   3.437307           3
   3.358285           5
   1.368308           6
   0.246483           8
   0.000000          10
]
```

è¿™ä¸ªç®­å¤´åœ¨ `pick` åˆ—ä¸­è¡¨ç¤ºæ‚¨çš„ `model_selection` ç­–ç•¥å½“å‰é€‰æ‹©çš„æ–¹ç¨‹å¼ç”¨äºé¢„æµ‹ï¼ˆæ‚¨ä¹Ÿå¯ä»¥åœ¨ `.fit(X, y)` åæ›´æ”¹ `model_selection`ï¼‰ã€‚`model.equations_` æ˜¯ä¸€ä¸ª Pandas DataFrameï¼ŒåŒ…å«æ‰€æœ‰æ–¹ç¨‹å¼ï¼ŒåŒ…æ‹¬å¯è°ƒç”¨æ ¼å¼ï¼ˆ`lambda_format`ï¼‰ã€SymPy æ ¼å¼ï¼ˆ`sympy_format`ï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ `model.sympy()` è·å¾—ï¼‰ã€ä»¥åŠ JAX å’Œ PyTorch æ ¼å¼ï¼ˆè¿™ä¸¤è€…éƒ½æ˜¯å¯å¾®åˆ†çš„ï¼Œå¯ä»¥é€šè¿‡ `model.jax()` å’Œ `model.pytorch()` è·å¾—ï¼‰ã€‚

### æ”¯æŒå‘é‡æœº

ä½œä¸ºç¥ç»ç½‘ç»œæ–¹æ³•çš„å‰èº«ï¼Œ*æ”¯æŒå‘é‡æœº*ï¼ˆSVMï¼‰æ˜¯ä¸€ç»„ç”¨äºåˆ†ç±»ã€å›å½’å’Œå¼‚å¸¸æ£€æµ‹çš„ç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚SVM åœ¨å¤„ç†é«˜ç»´æ•°æ®æ—¶æ•ˆæœæ˜¾è‘—ï¼Œå¯èƒ½æ¯”æ•°æ®é›†ä¸­çš„æ ·æœ¬æ›´å¤šçš„ç»´åº¦è¿˜è¦å¤šã€‚SVM å†…å­˜æ•ˆç‡é«˜ï¼Œå¯ä»¥é€šè¿‡æ ¸å‡½æ•°è¿›è¡Œå®šåˆ¶åŒ–ï¼ˆè™½ç„¶åƒ sklearn è¿™æ ·çš„åŒ…å·²ç»å…·æœ‰äº†ä¸€äº›å‡ºè‰²çš„æ ¸å‡½æ•°ï¼‰ã€‚SVM çš„ä¸»è¦ç¼ºç‚¹æ˜¯å¦‚æœè¦é¿å…è¿‡æ‹Ÿåˆï¼Œæ­£åˆ™åŒ–è‡³å…³é‡è¦ã€‚ä¸é€»è¾‘å›å½’ç­‰æ–¹æ³•ä¸åŒï¼ŒSVM ä¸æä¾›æ¦‚ç‡ä¼°è®¡ã€‚æ‚¨éœ€è¦ä½¿ç”¨ç±»ä¼¼äº”æŠ˜äº¤å‰éªŒè¯çš„æ–¹æ³•æ¥è·å–è¿™äº›ä¼°è®¡ï¼Œè¿™æ ·åšå¯èƒ½ä¼šæ¶ˆé™¤ä½¿ç”¨ SVM çš„è®¡ç®—æ•ˆç‡ä¼˜åŠ¿ã€‚

è¦ä½¿ç”¨ SVMï¼Œæœ‰è®¸å¤šæ–¹æ³•ï¼Œä½†æœ€æµè¡Œçš„æ˜¯ scikit-learn çš„[æ”¯æŒå‘é‡æœºå®ç°](https://oreil.ly/5NYAF)ã€‚

```
>>> from sklearn import svm
>>> X = [[0, 0], [1, 1]]
>>> y = [0, 1]
>>> clf = svm.SVC()
>>> clf.fit(X, y)
SVC()
>>> clf.predict([[2., 2.]])
array([1])
>>> # get support vectors
>>> clf.support_vectors_
array([[0., 0.],
       [1., 1.]])
>>> # get indices of support vectors
>>> clf.support_
array([0, 1]...)
>>> # get number of support vectors for each class
>>> clf.n_support_
array([1, 1]...)
```

### å†³ç­–æ ‘

ç±»ä¼¼äº SVMï¼Œ*å†³ç­–æ ‘*åœ¨æ‹Ÿåˆéçº¿æ€§å…³ç³»æ–¹é¢è¡¨ç°å‡ºè‰²ï¼ˆå°½ç®¡å®ƒä»¬åœ¨å¤„ç†çº¿æ€§å…³ç³»æ—¶å¯èƒ½ä¼šé‡åˆ°å›°éš¾ï¼‰ã€‚å†³ç­–æ ‘æ“…é•¿çš„æ˜¯å°†æ•°æ®åˆ†ç±»ä¸ºä¸åŒç»„ï¼Œå¹¶æä¾›ç›´è§‚çš„å¯è§†åŒ–ã€‚

ä¸è®¸å¤šå…¶ä»–æœºå™¨å­¦ä¹ æ–¹æ³•ç±»ä¼¼ï¼Œscikit-learn æä¾›äº†å¤šç§[å†³ç­–æ ‘å˜ä½“](https://oreil.ly/u81jy)ã€‚è¿˜å€¼å¾—ä¸€æçš„æ˜¯å…¶ä¸­ä¸€ç§æ›´å—æ¬¢è¿çš„å¯è§£é‡Šå†³ç­–æ ‘ç®—æ³•ï¼š[XGBoost](https://oreil.ly/EkTuq)ï¼ˆå®ƒä¹Ÿå…·æœ‰ç±»ä¼¼äº[scikit-learn çš„ API](https://oreil.ly/pz1qL)ï¼‰ã€‚

```
# create an xgboost regression model
model = XGBRegressor(
    n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8
)

np.random.seed(0)
df = pd.read_csv("/winequality-red.csv")  # Load the data

Y = df["quality"]  # The target variable is 'quality'
X = df[
    [
        "fixed acidity",
        "volatile acidity",
        "citric acid",
        "residual sugar",
        "chlorides",
        "free sulfur dioxide",
        "total sulfur dioxide",
        "density",
        "pH",
        "sulphates",
        "alcohol",
    ]
]
X_featurenames = X.columns
# Split the data into train and test data:
# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)

# define model evaluation method
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(
    model, X, y, scoring="neg_mean_absolute_error", cv=cv, n_jobs=-1
)

# define model evaluation method
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(
    model, X, y, scoring="neg_mean_absolute_error", cv=cv, n_jobs=-1
)
# force scores to be positive
scores = absolute(scores)
print("Mean MAE: %.3f (%.3f)" % (scores.mean(), scores.std()))
```

### å†³ç­–è§„åˆ™

*å†³ç­–è§„åˆ™*æ˜¯ä¸€ç»„ if-then è¯­å¥ï¼Œå¯ç”¨äºåšå‡ºå†³ç­–ã€‚å¦‚æœ if-then è¯­å¥ä¸­çš„æ¡ä»¶å¾—åˆ°æ»¡è¶³ï¼Œåˆ™ä¼šæ‰§è¡Œå†³ç­–è§„åˆ™ã€‚å†³ç­–è§„åˆ™é€šå¸¸ç”¨äºå†³ç­–è¿‡ç¨‹ä¸­ï¼Œå› ä¸ºå®ƒä»¬æ˜“äºç†è§£å¹¶ä¸”å¯ä»¥å¿«é€Ÿåº”ç”¨ã€‚å½“å¤§å¤šæ•°äººå¼€å§‹ä½¿ç”¨åƒ Python è¿™æ ·çš„ç¼–ç¨‹è¯­è¨€æ—¶ï¼Œä»–ä»¬é€šå¸¸ä¼šå¹¿æ³›ä½¿ç”¨ if-then è¯­å¥ã€‚å› æ­¤ï¼Œè¿™å¯ä»¥æˆä¸ºç†è§£å†³ç­–é€»è¾‘çš„ä¸€ç§éå¸¸ç›´è§‚çš„æ–¹å¼ã€‚

åˆ›å»ºä¸€ä¸ªåŒ…å«å¤§é‡ç‰¹å¾çš„æ•°æ®é›†çš„ if-then è¯­å¥å¯èƒ½éå¸¸è€—æ—¶ã€‚æœ‰è®¸å¤šç®—æ³•å¯ä»¥ç”Ÿæˆè¿™äº›è§„åˆ™ã€‚ä»¥ä¸‹æ˜¯å…¶ä¸­ä¸‰ç§æœ€å—æ¬¢è¿çš„ï¼š

*OneR*

OneR åŸºäºå•ä¸ªç‰¹å¾å­¦ä¹ è§„åˆ™ã€‚è¿™æ˜¯ä¸€ç§æœ€ç®€å•ä¸”æ˜“äºç†è§£çš„æ–¹æ³•ä¹‹ä¸€ã€‚è™½ç„¶å…¶ä»–ç®—æ³•å¯èƒ½ç”Ÿæˆæ›´å‡†ç¡®çš„è§„åˆ™ï¼Œä½† OneR å¿«é€Ÿè€Œç®€å•ï¼Œè¶³ä»¥ä½œä¸ºä¸å…¶ä»–ç®—æ³•è¿›è¡Œæ¯”è¾ƒçš„åŸºå‡†ã€‚è¦åœ¨ Python ä¸­ä½¿ç”¨ OneRï¼Œæ‚¨å¯ä»¥ä½¿ç”¨[MLxtend åº“](https://oreil.ly/BDIoD)ä¸­çš„`OneRClassifier`å®ç°ã€‚

###### æ³¨æ„

OneR æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ç®—æ³•ï¼Œå‡è®¾æ•°æ®æ˜¯åˆ†ç±»çš„ã€‚å®ƒåœ¨å¤„ç†è¿ç»­æ•°æ®æ—¶æ•ˆæœä¸ä½³ã€‚æ‚¨å¯èƒ½ä¸å¸Œæœ›ä¾èµ–å®ƒæ¥å¤„ç†å¤æ‚çš„è‡ªç„¶è¯­è¨€å¤„ç†æˆ–è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚

*é¡ºåºè¦†ç›–*

é¡ºåºè¦†ç›–æ˜¯ä¸€ç§è¿­ä»£æ–¹æ³•ï¼Œé€šè¿‡æ·»åŠ æ–°çš„ if-then è§„åˆ™ï¼Œç§»é™¤è¢«æ–°è§„åˆ™è§£é‡Šçš„æ•°æ®ç‚¹ï¼Œå¹¶é‡å¤è¯¥è¿‡ç¨‹ï¼Œç›´åˆ°æ‰€æœ‰æ•°æ®ç‚¹éƒ½å¾—åˆ°è§£é‡Šã€‚ä½¿ç”¨é¡ºåºè¦†ç›–ç”Ÿæˆçš„å†³ç­–è§„åˆ™æ—¶ï¼Œ[Oracle çš„ Skater åº“](https://oreil.ly/LkiWk)æœ‰è‰¯å¥½çš„å®ç°ã€‚

*è´å¶æ–¯è§„åˆ™åˆ—è¡¨*

æ­¤æ–¹æ³•æ¶‰åŠå¼•å…¥å…³äºæ•°æ®çš„å„ç§é¢‘ç‡ç»Ÿè®¡ä½œä¸ºèµ·ç‚¹çš„å…ˆéªŒçŸ¥è¯†ã€‚è¿™äº›å…³äºæ¨¡å¼çš„å…ˆéªŒçŸ¥è¯†å¯ä»¥ç”¨æ¥åŸºäºè´å¶æ–¯ç»Ÿè®¡åˆ›å»ºå†³ç­–åˆ—è¡¨ã€‚æ ¹æ®å®ç°æ–¹å¼ï¼Œè¿™å¯èƒ½è¿˜ä¸é¡ºåºè¦†ç›–æœ‰ä¸€äº›é‡å ã€‚å¯¹äºé€šè¿‡è´å¶æ–¯è§„åˆ™åˆ—è¡¨å®ç°å†³ç­–è§„åˆ™ï¼Œåƒ[iModels](https://oreil.ly/yDK4M)åŒ…è¿™æ ·çš„å·¥å…·æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ï¼›å®ƒå…·æœ‰ç±»ä¼¼äº sklearn çš„æ¥å£ã€‚å®ƒè¿˜åŒ…å«ç‰¹å®šå†³ç­–è§„åˆ™ç®—æ³•çš„å®ç°ï¼Œå¦‚ Friedman å’Œ Popescu çš„ RuleFitã€‚Â¹Â³

### è¶…è¶Šå†…åœ¨å¯è§£é‡Šæ¨¡å‹

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæ‰€æœ‰æè¿°çš„æ¨¡å‹éƒ½æœ‰ä¸€äº›ç®€å•çš„æ–¹æ³•æ¥å°†å®ƒä»¬çš„å‚æ•°è½¬åŒ–ä¸ºäººç±»å¯ç†è§£çš„æŒ‡å¯¼ï¼Œä»¥è§£é‡Šå®ƒä»¬çš„åŸºç¡€å†³ç­–ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šé¢†åŸŸï¼Œæ‚¨å¯èƒ½å¸Œæœ›æœ‰ä¸€ä¸ªé¢„æµ‹æ•°æ®æ¨¡å¼çš„æ¨¡å‹ï¼Œè€Œä¸ç®¡å…¶å‚æ•°çš„æ˜“ç†è§£ç¨‹åº¦å¦‚ä½•ã€‚è‡ª 2012 å¹´ä»¥æ¥ï¼ŒåŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•å·²ç»åœ¨è®¸å¤šé¢†åŸŸå–ä»£äº†æˆ‘ä»¬åœ¨è¿™é‡Œæè¿°çš„è®¸å¤šæ–¹æ³•ã€‚è€ƒè™‘åˆ°ç¥ç»ç½‘ç»œçš„å·¨å¤§å˜åŒ–ï¼Œåº”è¯¥æœ‰ä¸€äº›ä¸ç‰¹å®šäºä»»ä½•ä¸€ä¸ªæ¨¡å‹çš„è§£é‡Šæ–¹æ³•ã€‚

## æœ¬åœ°æ¨¡å‹æ— å…³è§£é‡Šæ–¹æ³•

æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æåˆ°çš„ï¼Œæœ¬åœ°å¯è§£é‡Šæ€§ä¾§é‡äºç†è§£ä¸ªä½“é¢„æµ‹çš„æ„ä¹‰ã€‚è®¸å¤šå…ˆå‰è®¨è®ºçš„æ¨¡å‹éƒ½æœ‰å†…ç½®çš„æ–¹æ³•æ¥è§£é‡Šå±€éƒ¨é¢„æµ‹ï¼Œä¾‹å¦‚å†³ç­–æ ‘ä¸­çš„é¡¹æˆ–å¤šé‡çº¿æ€§å›å½’ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬æ¯”è¾ƒåŒ…æ‹¬è®¸å¤šä¸åŒç¥ç»ç½‘ç»œæ¶æ„çš„å¤šä¸ªæ¨¡å‹ç±»å‹ï¼Œä½¿ç”¨è¿™äº›å†…åœ¨å¯è§£é‡Šæ€§æ–¹æ³•å°†åƒæ˜¯åœ¨æ¯”è¾ƒè‹¹æœå’Œæ©™å­ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ç†æƒ³åœ°å¸Œæœ›æœ‰ä¸€ç§æ–¹æ³•æ¥ç»“åˆå±€éƒ¨å¯è§£é‡Šæ€§å’Œæ¨¡å‹æ— å…³çš„å¯è§£é‡Šæ€§ã€‚

### æœ¬åœ°å¯è§£é‡Šæ¨¡å‹æ— å…³è§£é‡Š

ä¸€ä¸ª*æœ¬åœ°å¯è§£é‡Šæ¨¡å‹æ— å…³è§£é‡Š*ï¼ˆLIMEï¼‰é€šè¿‡ç”¨æœ¬åœ°å¯è§£é‡Šçš„æ›¿ä»£æ¨¡å‹æ›¿æ¢å¤æ‚æ¨¡å‹æ¥è§£é‡Šé¢„æµ‹ã€‚æ‚¨å¯ä»¥å°†æ­¤æŠ€æœ¯åº”ç”¨äºå›¾åƒã€æ–‡æœ¬ï¼Œç”šè‡³è¡¨æ ¼æ•°æ®ã€‚æ­¤æŠ€æœ¯çš„ä¸€èˆ¬æ­¥éª¤å¦‚ä¸‹ï¼š

1.  é€‰æ‹©æ¨¡å‹è¾“å‡ºçš„ä¸€å †å®ä¾‹æ¥è§£é‡Šæ‚¨æƒ³è¦è§£é‡Šçš„æ¨¡å‹ã€‚ï¼ˆè¿™æ˜¯*å±€éƒ¨*çš„ï¼Œå› ä¸ºæˆ‘ä»¬åªè§£é‡Šè¿™ä¸ªæœ‰é™é›†è€Œä¸æ˜¯æ‰€æœ‰å¯èƒ½çš„æ¨¡å‹è¾“å‡ºçš„*å…¨å±€*é›†åˆã€‚ï¼‰

1.  åˆ›å»ºä¸€ä¸ªæ›¿ä»£æ¨¡å‹ï¼Œå®ƒå¤åˆ¶æ‚¨æƒ³è¦è§£é‡Šçš„æ¨¡å‹åœ¨è¿™äº›å®ä¾‹ä¸Šçš„è¡Œä¸ºã€‚æ‚¨å°†ä¸äº†è§£æ¨¡å‹å†…éƒ¨ï¼ŒåªçŸ¥é“è¾“å‡ºçš„å¤–è§‚ã€‚

1.  åˆ›å»ºè¾“å…¥æ•°æ®çš„éšæœºæ‰°åŠ¨ï¼Œå¹¶æŸ¥çœ‹æ›¿ä»£æ¨¡å‹å¦‚ä½•å¯¹å…¶è¿›è¡Œåˆ†ç±»ã€‚

1.  ä½¿ç”¨è¿™äº›åˆ†ç±»è¾¹ç•Œåˆ›å»ºä¸€ä¸ªå†³ç­–è¾¹ç•Œï¼Œå¯ç”¨äºè§£é‡Šæ¨¡å‹çš„é¢„æµ‹ã€‚

å¦‚æœæ‚¨æƒ³è¦è¿™ä¸ªæ›´æ­£å¼çš„æ•°å­¦ç‰ˆæœ¬ï¼Œå‡è®¾è¾“å…¥æ•°æ®ä¸º<math alttext="x"><mi>x</mi></math>ã€‚è¦è§£é‡Šçš„å¤æ‚æ¨¡å‹æ˜¯<math alttext="f"><mi>f</mi></math>ï¼Œç®€å•å¯è§£é‡Šæ¨¡å‹æ˜¯<math alttext="g"><mi>g</mi></math>ï¼ˆå…¶ä¸­<math alttext="g element-of upper G"><mrow><mi>g</mi> <mo>âˆˆ</mo> <mi>G</mi></mrow></math>è¡¨æ˜å®ƒå±äºç¨€ç–çº¿æ€§æ¨¡å‹çš„é›†åˆï¼Œå¦‚å…ˆå‰è®¨è®ºçš„é‚£ç§ï¼‰ï¼Œè€Œ<math alttext="pi Subscript x"><msub><mi>Ï€</mi> <mi>x</mi></msub></math>æ˜¯ä¸€ä¸ªæŒ‡ç¤ºæ‚¨çš„æ•°æ®ç‚¹<math alttext="x"><mi>x</mi></math>å±€éƒ¨é‚»åŸŸå¤§å°çš„æ¥è¿‘åº¦é‡ã€‚ä»è¿™é‡Œï¼Œæ‚¨å°†åˆ›å»ºä¸€ä¸ªæŸå¤±å‡½æ•°<math alttext="script upper L"><mi>â„’</mi></math>ï¼Œå®ƒå°†æœ€å°åŒ–<math alttext="f"><mi>f</mi></math>å’Œ<math alttext="g"><mi>g</mi></math>çš„è¾“å‡ºä¹‹é—´çš„å·®å¼‚ï¼Œä½¿å…¶åœ¨<math alttext="pi Subscript x"><msub><mi>Ï€</mi> <mi>x</mi></msub></math>å†…ã€‚åœ¨ä¸è¿›è¡Œä»»ä½•ä¿®æ”¹çš„æƒ…å†µä¸‹ï¼Œè¿™ä¸ªè¿‡ç¨‹å°†ä½¿å¤æ‚çš„<math alttext="g"><mi>g</mi></math>å‡ ä¹ä¸<math alttext="f"><mi>f</mi></math>ç›¸åŒã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ‚¨è¦æ·»åŠ <math alttext="normal upper Omega left-parenthesis g right-parenthesis"><mrow><mi>Î©</mi> <mo>(</mo> <mi>g</mi> <mo>)</mo></mrow></math>ï¼Œè¿™æ˜¯ä¸€ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œé™åˆ¶æ‚¨çš„å¯è§£é‡Šæ¨¡å‹<math alttext="g"><mi>g</mi></math>çš„å¤æ‚æ€§ã€‚è¿™å°†å¸¦æ‚¨åˆ°è®­ç»ƒ LIME çš„ä¸€èˆ¬æ–¹ç¨‹å¼ã€‚

<math alttext="xi left-parenthesis x right-parenthesis equals arg min Underscript g element-of upper G Endscripts script upper L left-parenthesis f comma g comma pi Subscript x Baseline right-parenthesis plus normal upper Omega left-parenthesis g right-parenthesis" display="block"><mrow><mi>Î¾</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <munder><mrow><mo form="prefix">arg</mo><mo form="prefix" movablelimits="true">min</mo></mrow> <mrow><mi>g</mi><mo>âˆˆ</mo><mi>G</mi></mrow></munder> <mi>â„’</mi> <mrow><mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>g</mi> <mo>,</mo> <msub><mi>Ï€</mi> <mi>x</mi></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>Î©</mi> <mrow><mo>(</mo> <mi>g</mi> <mo>)</mo></mrow></mrow></math>

æŸå¤±å‡½æ•°æ›´å…·ä½“åœ°æè¿°å¦‚ä¸‹ï¼š

<math alttext="script upper L left-parenthesis f comma g comma pi Subscript x Baseline right-parenthesis equals sigma-summation Underscript z comma z prime element-of script upper Z Endscripts pi Subscript x Baseline left-parenthesis z right-parenthesis left-parenthesis f left-parenthesis z right-parenthesis minus g left-parenthesis z prime right-parenthesis right-parenthesis squared" display="block"><mrow><mi>â„’</mi> <mrow><mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>g</mi> <mo>,</mo> <msub><mi>Ï€</mi> <mi>x</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <munder><mo>âˆ‘</mo> <mrow><mi>z</mi><mo>,</mo><mi>z</mi><mi>Ã¢</mi><mi>Â€</mi><mi>Â™</mi><mo>âˆˆ</mo><mi>ğ’µ</mi></mrow></munder> <msub><mi>Ï€</mi> <mi>x</mi></msub> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <msup><mrow><mo>(</mo><mi>f</mi><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow><mo>-</mo><mi>g</mi><mrow><mo>(</mo><msup><mi>z</mi> <mo>'</mo></msup> <mo>)</mo></mrow><mo>)</mo></mrow> <mn>2</mn></msup></mrow></math>

ç›´è§‚åœ°è¯´ï¼Œ*è§£é‡Š*æ˜¯æ¨¡å‹è¡Œä¸ºçš„å±€éƒ¨çº¿æ€§é€¼è¿‘ã€‚è™½ç„¶æ¨¡å‹åœ¨å…¨å±€ä¸Šå¯èƒ½éå¸¸å¤æ‚ï¼Œä½†åœ¨ç‰¹å®šå®ä¾‹çš„å‘¨å›´è¿‘ä¼¼å®ƒä¼šæ›´å®¹æ˜“ã€‚å½“å°†æ¨¡å‹è§†ä¸ºé»‘ç›’æ—¶ï¼Œæ‚¨æ‰°åŠ¨è¦è§£é‡Šçš„å®ä¾‹ï¼Œå¹¶åœ¨å…¶å‘¨å›´å­¦ä¹ ä¸€ä¸ªç¨€ç–çº¿æ€§æ¨¡å‹ï¼Œä½œä¸ºè§£é‡Šã€‚

æ¨¡å‹çš„å†³ç­–å‡½æ•°æ˜¯éçº¿æ€§çš„ã€‚é²œçº¢è‰²çš„åå­—æ˜¯è¢«è§£é‡Šçš„å®ä¾‹ï¼ˆæˆ‘ä»¬ç§°ä¹‹ä¸º*X*ï¼‰ã€‚æ‚¨å¯¹*X*å‘¨å›´çš„å®ä¾‹è¿›è¡Œé‡‡æ ·ï¼Œå¹¶æ ¹æ®å®ƒä»¬ä¸*X*çš„æ¥è¿‘ç¨‹åº¦è¿›è¡ŒåŠ æƒï¼ˆè¿™é‡Œçš„æƒé‡ç”±å¤§å°è¡¨ç¤ºï¼‰ã€‚ç„¶åï¼Œæ‚¨å­¦ä¹ ä¸€ä¸ªçº¿æ€§æ¨¡å‹ï¼ˆè™šçº¿ï¼‰ï¼Œåœ¨*X*é™„è¿‘å¾ˆå¥½åœ°è¿‘ä¼¼æ¨¡å‹ï¼Œä½†ä¸ä¸€å®šåœ¨å…¨å±€èŒƒå›´å†…ã€‚

### æ·±å…¥ç¤ºä¾‹ï¼šLIME åœ¨è§†è§‰ Transformer æ¨¡å‹ä¸Šçš„åº”ç”¨

å­˜åœ¨è®¸å¤šå…³äº LIME åœ¨åŸºäº CNN çš„å›¾åƒåˆ†ç±»å™¨ä¸Šçš„ç¤ºä¾‹ã€‚ç”±äºè¿™äº›æ˜¯ä¸æ¨¡å‹æ— å…³çš„æ–¹æ³•ï¼Œå€¼å¾—é€šè¿‡åœ¨[è§†è§‰ Transformer (ViT)æ¨¡å‹](https://oreil.ly/yfZ2E)ä¸Šè¿è¡Œ LIME æ¥è¿›è¡Œæ¼”ç¤ºï¼Œç”¨äºå›¾åƒåˆ†ç±»ã€‚

###### æ³¨æ„

æ‚¨å¯ä»¥åœ¨ç¬”è®°æœ¬[*Chapter_3_LIME_for_Transformers.ipynb*](https://oreil.ly/lwDoi)ä¸­æ‰¾åˆ°ä¸æœ¬æ•™ç¨‹ç›¸å…³çš„æ‰€æœ‰ä»£ç ã€‚

```
# Setting up your environment for LIME
!pip -qq install lime
!pip -qq install transformers
```

å¯¹äºæ‚¨çš„ NLP ç¤ºä¾‹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä¸“é—¨é’ˆå¯¹é‡‘èé¢†åŸŸè¿›è¡Œäº†å¾®è°ƒçš„ BERT ç‰ˆæœ¬ï¼Œç§°ä¸º finBERTã€‚è¿™æ˜¯ä¸€ä¸ª BERT æ¨¡å‹ï¼Œå¯ä»¥å¯¹æ–‡æœ¬æ•°æ®è¿›è¡Œæƒ…æ„Ÿåˆ†æã€‚

```
# Importing the sentiment classification model
import numpy as np
import lime
import torch
import torch.nn.functional as F
from lime.lime_text import LimeTextExplainer
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained("ProsusAI/finbert")
model = AutoModelForSequenceClassification.from_pretrained("ProsusAI/finbert")
class_names = ["positive", "negative", "neutral"]
```

å¯¹äº`LimeTextExplainer`ç±»ï¼Œæ‚¨éœ€è¦æŒ‡å®šä¸€ä¸ªé¢„æµ‹å‡½æ•°ï¼Œè¯¥å‡½æ•°å°†æ¥å—è¾“å…¥å¹¶é€šè¿‡åˆ†è¯å™¨å’Œæ¨¡å‹è¿›è¡Œå¤„ç†ã€‚

```
# Text predictor function for LIME
def predictor(texts):
    outputs = model(**tokenizer(texts, return_tensors="pt", padding=True))
    probas = F.softmax(outputs.logits).detach().numpy()
    print(probas.shape)
    return probas
```

å¯¹äºå®é™…çš„æ–‡æœ¬è§£é‡Šå™¨ï¼Œæ‚¨éœ€è¦æä¾›æ ·æœ¬å¥å­å’Œé¢„æµ‹å‡½æ•°ã€‚åœ¨è¿™ä¸ªæ¼”ç¤ºä¸­ï¼Œæ‚¨å°†è®¾ç½® LIME æ¥é‡‡é›†ä¸¤åƒä¸ªæ ·æœ¬ã€‚

```
# LIME Text Explainer
explainer = LimeTextExplainer(class_names=class_names)
example_text = (
    "alarming decrease in market share despite increases in " + \
    "revenue and decreased operating costs"
)
exp = explainer.explain_instance(
    example_text, predictor, num_features=20, num_samples=2000
)
exp.show_in_notebook(text=example_text)
```

åœ¨ å›¾Â 3-6 ä¸­ï¼Œé™¤äº†è¾“å‡ºçš„å¯¹æ•°ä¹‹å¤–ï¼Œæ‚¨è¿˜å¯ä»¥çœ‹åˆ°å“ªäº›ç‰¹å¾å€¾å‘äºæ”¯æŒæŸä¸ªè¾“å‡ºç±»åˆ«æˆ–å¦ä¸€ä¸ªã€‚

![ptml 0306](img/ptml_0306.png)

###### å›¾ 3-6\. LIME åœ¨æ–‡æœ¬è¾“å…¥ä¸Šè¿è¡Œ

LIME ä¸ä»…é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ï¼Œä¹Ÿé€‚ç”¨äºå›¾åƒæ¨¡å‹ã€‚

```
# Importing the image classification transformer model
import json
import os
import requests
import time

import lime
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from torch.autograd import Variable
from torchvision import models, transforms
from transformers import ViTForImageClassification
from transformers import ViTFeatureExtractor

model = ViTForImageClassification.from_pretrained("google/vit-base-patch16-224")
feature_extractor = ViTFeatureExtractor.from_pretrained(
    "google/vit-base-patch16-224"
)

url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
img = Image.open(requests.get(url, stream=True).raw).convert('RGB')
plt.imshow(img);
```

æˆ‘ä»¬ä»å¼€å§‹å¤„ç† PIL å›¾åƒï¼ˆå›¾Â 3-7ï¼‰ã€‚ä¸ä»»ä½• torchvision æ¨¡å‹ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œä¸€äº›é¢„å¤„ç†ã€‚ç„¶è€Œï¼Œç”±äºåŸå§‹ LIME åº“çš„ä¸€ä¸ªæ€ªå¼‚ä¹‹å¤„ï¼Œæ‚¨éœ€è¦æ·»åŠ ä¸€ä¸ªè§£å†³æ–¹æ³•ï¼š`LimeImageExplainer`ã€‚

```
# Importing the image classification transformer model
def get_pil_transform():
    transf = transforms.Compose(
        [transforms.Resize((256, 256)), transforms.CenterCrop(224)]
    )

    return transf

def get_preprocess_transform():
    normalize = transforms.Normalize(
        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
    )
    transf = transforms.Compose([transforms.ToTensor(), normalize])
    return transf

pil_transf = get_pil_transform()

def numpy_to_pil(numpy_array):
    if len(numpy_array.shape) == 3:
        return Image.fromarray(numpy_array)
    elif len(numpy_array.shape) == 4:
        pil_list = []
        for i in range(numpy_array.shape[0]):
            pil_list.append(Image.fromarray(numpy_array[i]))
        return pil_list
    else:
        raise ValueError(
            "The numpy array must be 3-dimensional or 4-dimensional"
        )
```

![ptml 0307](img/ptml_0307.png)

###### å›¾ 3-7\. LIME å›¾åƒè¾“å…¥

ä¸æ–‡æœ¬è§£é‡Šå™¨ä¸€æ ·ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªé¢„æµ‹å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—ä¸€æ‰¹å›¾åƒå¹¶è¾“å‡ºé¢„æµ‹ã€‚æ‚¨åªéœ€ç¡®ä¿è¯¥å‡½æ•°æ­£ç¡®åœ°åˆ©ç”¨äº† numpy-PIL è½¬æ¢å‡½æ•°ä»¥åŠç¼–ç å’Œæ¨¡å‹ã€‚

```
from lime import lime_image

# Hide color is the color for a superpixel turned OFF. Alternatively,
# if it is NONE, the superpixel will be replaced by the average of its pixels
explainer = lime_image.LimeImageExplainer()
explanation = explainer.explain_instance(
    np.array(pil_transf(img)),
    # classification function
    batch_predict,
    top_labels=5,
    hide_color=0,
    num_samples=1000,
)
# number of images that will be sent to classification function
```

ä»è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è§£é‡Šå™¨æ¥æ£€æŸ¥å›¾åƒä¸­ä¸é¡¶éƒ¨é¢„æµ‹ç±»åˆ«å¯¹åº”çš„éƒ¨åˆ†ï¼ˆå›¾Â 3-8ï¼‰ã€‚

```
# Analyzing top predicted class with LIME
from skimage.segmentation import mark_boundaries

temp, mask = explanation.get_image_and_mask(
    explanation.top_labels[0],
    positive_only=True,
    num_features=5,
    hide_rest=False,
)
img_boundary_1 = mark_boundaries(temp / 255.0, mask)
plt.imshow(img_boundary_1);
```

![ptml 0308](img/ptml_0308.png)

###### å›¾ 3-8\. LIME é«˜äº®çš„æ­£é¢è´¡çŒ®

æˆ–è€…ï¼Œå¦‚æœæˆ‘ä»¬åªå…³æ³¨é¡¶éƒ¨ç±»åˆ«çš„é¢„æµ‹ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥æ£€æŸ¥è§£é‡Šï¼Œä»¥æ‰¾å‡ºå“ªäº›éƒ¨åˆ†æ”¯æŒå†³å®šï¼Œå“ªäº›éƒ¨åˆ†åå¯¹å®ƒï¼ˆå›¾Â 3-9ï¼‰ã€‚

```
# Positive and negative contributions
temp, mask = explanation.get_image_and_mask(
    explanation.top_labels[0],
    positive_only=False,
    num_features=10,
    hide_rest=False,
)
img_boundary_2 = mark_boundaries(temp / 255.0, mask)
plt.imshow(img_boundary_2);
```

![ptml 0309](img/ptml_0309.png)

###### å›¾ 3-9\. LIME é«˜äº®çš„è´Ÿé¢è´¡çŒ®

è¿™äº›æ–¹æ³•ä¸æ˜¯åœ¨å˜æ¢å™¨æ¨¡å‹ä¸Šä½¿ç”¨ LIME çš„å”¯ä¸€æ–¹å¼ã€‚åœ¨ Captum è½¯ä»¶åŒ…ä¸­æè¿°äº†ä½¿ç”¨ LIME çš„å¦ä¸€ç§æ–¹æ³•çš„æ›¿ä»£æ–¹æ³•ã€‚

### å¤æ™®åˆ©ä¸ SHAP

[*SHapley Additive exPlanations* (SHAP)](https://oreil.ly/zbGHN) æ˜¯ä¸€ç§å½’å› æ–¹æ³•ï¼Œå…¬å¹³åœ°å°†é¢„æµ‹åˆ†é…ç»™å„ä¸ªç‰¹å¾ã€‚è¿™åŸºäºåˆä½œåšå¼ˆè®ºé¢†åŸŸçš„ *å¤æ™®åˆ©å€¼* çš„æ¦‚å¿µã€‚

å‡è®¾æˆ‘ä»¬æœ‰ä¸€ç»„å››ä¸ªäººä¸€èµ·åˆä½œè¿›è¡Œæ¸¸æˆï¼ˆä¹Ÿç§°ä¸ºâ€œè”ç›Ÿâ€ï¼‰ã€‚è¿™ä¸ªæ¸¸æˆå¯èƒ½æ˜¯ä¸€ä¸ªæœºå™¨å­¦ä¹ ç«èµ›ã€‚æ¯”èµ›ç»“æŸåï¼Œä»–ä»¬æ ¹æ®ç»“æœå¾—åˆ°ä¸€å®šçš„å¥–åŠ±ï¼Œæ¯”å¦‚èµ¢å¾—ç¬¬ä¸€åå¯è·å¾— 10,000 ç¾å…ƒã€‚ä¸­å¿ƒé—®é¢˜æ˜¯å¦‚ä½•å…¬å¹³åˆ†é…å¥–é‡‘ã€‚åœ¨æœºå™¨å­¦ä¹ ç«èµ›ä¸­ï¼Œæ¯ä¸ªè”ç›Ÿæˆå‘˜å¯èƒ½è´¡çŒ®äº†ä¸åŒçš„éƒ¨åˆ†ï¼Œå› æ­¤å®Œå…¨å¹³å‡åˆ†é…ç»™æ‰€æœ‰æˆå‘˜æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚

åŠ³åŸƒå¾·Â·å¤æ™®åˆ©äº 1951 å¹´æå‡ºäº†å¤æ™®åˆ©å€¼ã€‚è¿™äº›å€¼å‘Šè¯‰æˆ‘ä»¬ç©å®¶å¯¹å¥–åŠ±çš„å¹³å‡è´¡çŒ®ã€‚å¯è§£é‡Šçš„ AI å€¼ SHAP åˆ©ç”¨å¤æ™®åˆ©å€¼æ¥ç¡®å®šè¾“å…¥å®ä¾‹çš„å“ªäº›ç‰¹å¾å¯¼è‡´äº†æ¨¡å‹å†³ç­–ï¼ˆè€Œä¸æ˜¯æ¸¸æˆä¸­çš„ç©å®¶ï¼‰ã€‚

Shapley å€¼çš„ä¸»è¦ç›´è§‰æ˜¯ï¼Œå®ƒä»¬è¡¡é‡äº†å¦‚æœæ²¡æœ‰æŸä¸ªç©å®¶ï¼Œè”ç›Ÿä¼šå¦‚ä½•å‘æŒ¥ä½œç”¨ã€‚å‡è®¾åœ¨æ‚¨çš„æœºå™¨å­¦ä¹ ç«èµ›ä¸­ï¼Œæˆ‘ä»¬ç§»é™¤äº†åŸŸä¸“å®¶ Alice ç©å®¶ã€‚å›¢é˜ŸåŸæœ¬å¯ä»¥æ’åç¬¬ä¸€ï¼Œä½†æœ€ç»ˆæ’åç¬¬äºŒï¼Œä»…è·å¾— $3,000 çš„å¥–é‡‘ã€‚æ‚¨å¯èƒ½ä¼šåœ¨è¿™é‡Œåœä¸‹æ¥ï¼Œå‡è®¾ Alice è´¡çŒ®äº†å¥–é‡‘çš„ 70%ï¼Œä½†äº‹å®å¹¶éå¦‚æ­¤ç®€å•ã€‚

ç©å®¶å½¼æ­¤ä¹‹é—´å­˜åœ¨äº’åŠ¨ï¼Œå› æ­¤æˆ‘ä»¬è¿˜éœ€è¦è€ƒè™‘ç©å®¶åœ¨å…±åŒå·¥ä½œæ—¶çš„è¡¨ç°ã€‚å‡è®¾å›¢é˜Ÿè¿˜æœ‰æœºå™¨å­¦ä¹ ä¸“å®¶ Bobã€‚Alice åªæœ‰åœ¨ä¸ Bob åˆä½œæ—¶æ‰èƒ½å–å¾—å‡ºè‰²çš„ç»“æœï¼Œå› æ­¤è´¡çŒ®åº”è¯¥åœ¨ä»–ä»¬ä¹‹é—´åˆ†é…ã€‚ä½†æˆ‘ä»¬è¿˜æ²¡æœ‰ç»“æŸï¼Œå› ä¸ºæˆ‘ä»¬è¿˜éœ€è¦è€ƒè™‘å­é›†ï¼Œä¾‹å¦‚ä¸€ä¸ªä¸‰äººå­é›†ï¼Œæ’é™¤ Bobï¼Œä»…åŒ…å« Alice å’Œå¥¹çš„é˜Ÿå‹ Carol å’Œ Dylanã€‚Shapley å€¼ç”¨äºè®¡ç®—è”ç›Ÿçš„æ¯ä¸ªå¯èƒ½å­é›†çš„æ¯ä¸ªç©å®¶çš„è´¡çŒ®ï¼Œå¹¶å¯¹æ‰€æœ‰è¿™äº›è´¡çŒ®è¿›è¡Œå¹³å‡ï¼ˆè¢«ç§°ä¸ºç©å®¶çš„ *è¾¹é™…ä»·å€¼*ï¼‰ã€‚

è®©æˆ‘ä»¬å›åˆ°æœºå™¨å­¦ä¹ çš„èƒŒæ™¯ã€‚æ­£å¦‚å‰é¢æåˆ°çš„ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ•°æ®å®ä¾‹ä¸­çš„ç‰¹å¾è§†ä¸ºç©å®¶ï¼Œæ¨¡å‹è¾“å‡ºé¢„æµ‹ä¸ºå¥–é‡‘ã€‚Shapley å€¼å‘Šè¯‰æˆ‘ä»¬è¿™ä¸ªå€¼å¦‚ä½•åœ¨æ‰€æœ‰è¾“å…¥ä¹‹é—´åˆ†é…ã€‚SHAP ä½¿ç”¨è¿™ç§æ–¹æ³•ä¸ºä¸ªåˆ«é¢„æµ‹åˆ›å»ºå±€éƒ¨è§£é‡Šï¼Œä½†ä¹Ÿå¯ä»¥é€šè¿‡å¯¹ä¼ å…¥æ¨¡å‹çš„æ•´ä¸ªæ•°æ®é›†çš„å¹³å‡å€¼è¿›è¡Œå…¨å±€è§£é‡Šã€‚

æˆ‘ä»¬å¦‚ä½•å®é™…è®¡ç®— Shapley å€¼å‘¢ï¼Ÿè€ƒè™‘ä»¥ä¸‹æ–¹ç¨‹ï¼Œç”¨äºè·å–æ‚¨çš„é»‘ç›’æ¨¡å‹ <math alttext="f"><mi>f</mi></math> å’Œè¾“å…¥æ•°æ®å®ä¾‹ <math alttext="x"><mi>x</mi></math> çš„ç‰¹å¾å€¼ <math alttext="i"><mi>i</mi></math> çš„ Shapley å€¼ï¼ˆè¿™å°†æ˜¯è¡¨æ ¼æ•°æ®é›†ä¸­çš„å•è¡Œï¼‰ã€‚æ‚¨éœ€è¦è¿­ä»£æ‰€æœ‰å¯èƒ½çš„ç‰¹å¾å­é›†ï¼ˆ<math alttext="z prime"><mrow><mi>z</mi> <mi>Ã¢</mi> <mi>Â€</mi> <mi>Â™</mi></mrow></math>ï¼‰ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬è€ƒè™‘äº†ç‰¹å¾å€¼ä¹‹é—´çš„æ‰€æœ‰äº¤äº’ã€‚æˆ‘ä»¬å°†é‡‡æ ·ç©ºé—´æ ‡è®°ä¸º â€²ï¼Œå› ä¸ºå¯¹äºåƒå›¾åƒè¿™æ ·çš„æ›´å¤§å®ä¾‹ï¼Œæˆ‘ä»¬ä¸ä¼šå°†æ¯ä¸ªåƒç´ è§†ä¸ºç‰¹å¾ï¼›ç›¸åï¼Œæˆ‘ä»¬æ‰¾åˆ°ä¸€ç§æ–¹æ³•æ¥æ€»ç»“å›¾åƒä¸ºæ›´å¤§çš„ç‰¹å¾ã€‚æ‚¨ä¼šè·å¾—åŒ…æ‹¬æˆ‘ä»¬æ„Ÿå…´è¶£çš„ç‰¹å¾çš„é»‘ç›’æ¨¡å‹è¾“å‡ºï¼ˆ<math alttext="f Subscript x Baseline left-parenthesis z prime right-parenthesis"><mrow><msub><mi>f</mi> <mi>x</mi></msub> <mrow><mo>(</mo> <msup><mi>z</mi> <mo>'</mo></msup> <mo>)</mo></mrow></mrow></math>ï¼‰ï¼Œä»¥åŠæ²¡æœ‰è¿™ä¸ªç‰¹å¾çš„è¾“å‡ºï¼ˆ<math alttext="f Subscript x Baseline left-parenthesis z prime minus i right-parenthesis"><mrow><msub><mi>f</mi> <mi>x</mi></msub> <mrow><mo>(</mo> <mi>z</mi> <mi>Ã¢</mi> <mi>Â€</mi> <mi>Â™</mi> <mo>âˆ–</mo> <mi>i</mi> <mo>)</mo></mrow></mrow></math>ï¼‰ã€‚è§‚å¯Ÿè¿™ä¸¤è€…å‘Šè¯‰æˆ‘ä»¬ç‰¹å¾åœ¨è¯¥å­é›†ä¸­å¦‚ä½•å½±å“æ¨¡å‹è¾“å‡ºã€‚

ç„¶åï¼Œä½ è¦å¯¹æ¯ä¸ªç‰¹å¾å­é›†çš„å¯èƒ½æ’åˆ—è¿›è¡Œè¿™æ ·çš„æ“ä½œï¼Œè€Œæ¯ä¸ªæ’åˆ—çš„æƒé‡åˆå–å†³äºè”åˆä½“ä¸­çš„ç©å®¶æ•°é‡ï¼Œæˆ–è€…æˆ‘ä»¬é’ˆå¯¹æ•°æ®å®ä¾‹<math alttext="upper M"><mi>M</mi></math>æ€»å…±æŸ¥çœ‹çš„ç‰¹å¾æ•°é‡ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåˆ¤æ–­ä¸€ä¸ªç‰¹å¾æ˜¯å¦å¯¹æ¨¡å‹çš„å†³ç­–äº§ç”Ÿäº†å¾ˆå¤§çš„æ”¹å˜ï¼Œå³ä½¿æˆ‘ä»¬å·²ç»è€ƒè™‘äº†å¾ˆå¤šå…¶ä»–ç‰¹å¾ã€‚è¿™ä¹Ÿä½¿æˆ‘ä»¬èƒ½å¤Ÿæ›´ç›´æ¥åœ°è§‚å¯Ÿåœ¨è¾ƒå°è”åˆä½“ä¸­å­¤ç«‹ç‰¹å¾çš„å½±å“ã€‚

<math alttext="phi Subscript i Baseline left-parenthesis f comma x right-parenthesis equals sigma-summation Underscript z prime subset-of-or-equal-to x Superscript prime Baseline Endscripts StartFraction StartAbsoluteValue z Superscript prime Baseline EndAbsoluteValue factorial left-parenthesis upper M minus StartAbsoluteValue z Superscript prime Baseline EndAbsoluteValue minus 1 right-parenthesis factorial Over upper M factorial EndFraction left-parenthesis right-parenthesis f Subscript x Baseline left-parenthesis z Superscript prime Baseline right-parenthesis minus f Subscript x Baseline left-parenthesis z prime minus i right-parenthesis right-parenthesis" display="block"><mrow><msub><mi>Ï†</mi> <mi>i</mi></msub> <mrow><mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <munder><mo>âˆ‘</mo> <mrow><mi>z</mi><mi>Ã¢</mi><mi>Â€</mi><mi>Â™</mi><mo>âŠ†</mo><msup><mi>x</mi> <mo>'</mo></msup></mrow></munder> <mfrac><mrow><mfenced close="|" open="|" separators=""><mi>z</mi><mi>Ã¢</mi><mi>Â€</mi><mi>Â™</mi></mfenced><mo>!</mo><mrow><mo>(</mo><mi>M</mi><mo>-</mo><mfenced close="|" open="|" separators=""><mi>z</mi><mi>Ã¢</mi><mi>Â€</mi><mi>Â™</mi></mfenced><mo>-</mo><mn>1</mn><mo>)</mo></mrow><mo>!</mo></mrow> <mrow><mi>M</mi><mo>!</mo></mrow></mfrac> <mfenced close=")" open="(" separators=""><mrow><mo>)</mo></mrow> <msub><mi>f</mi> <mi>x</mi></msub> <mrow><mo>(</mo> <msup><mi>z</mi> <mo>'</mo></msup> <mo>)</mo></mrow> <mo>-</mo> <msub><mi>f</mi> <mi>x</mi></msub> <mrow><mo>(</mo> <mi>z</mi> <mi>Ã¢</mi> <mi>Â€</mi> <mi>Â™</mi> <mo>âˆ–</mo> <mi>i</mi> <mo>)</mo></mrow></mfenced></mrow></math>

ä»ç„¶æœ‰ä¸€ä¸ªé—®é¢˜ï¼šå¦‚æœæˆ‘ä»¬çš„æ¨¡å‹é€šå¸¸æ¥å—å›ºå®šå¤§å°çš„è¾“å…¥ï¼Œæˆ‘ä»¬å¦‚ä½•ä»æ¨¡å‹è¾“å…¥ä¸­ç§»é™¤ç‰¹å¾ï¼Ÿåœ¨ SHAP ä¸­ï¼Œé€šè¿‡ç”¨è®­ç»ƒæ•°æ®ä¸­å…¶ä»–ä½ç½®çš„éšæœºæ›¿æ¢å€¼æ›¿æ¢å·²ç§»é™¤çš„ç‰¹å¾å€¼æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å¦‚æœæˆ‘ä»¬å¯¹æ‰€æœ‰å­é›†éƒ½è¿™æ ·åšï¼Œé‚£ä¹ˆç‰¹å¾çš„ç›¸å…³æ€§åŸºæœ¬ä¸Šä¼šè¢«é‡‡æ ·æ‰ã€‚ä½ å®Œå…¨æ‰“ä¹±ç‰¹å¾ç›´åˆ°å®ƒä»¬æˆä¸ºéšæœºçš„ï¼Œè€Œå®Œå…¨éšæœºçš„ç‰¹å¾åˆ™ä¸å…·æœ‰é¢„æµ‹èƒ½åŠ›ã€‚

ä½†æ˜¯ä½¿ç”¨ SHAP ä»ç„¶å­˜åœ¨ä¸€ä¸ªéšœç¢ï¼šè®¡ç®—å¤æ‚åº¦å¾ˆé«˜ã€‚è®¡ç®—æ‰€æœ‰è¿™äº›å­é›†æ˜¯æ˜‚è´µçš„ã€‚å¯¹äºå…·æœ‰<math alttext="n"><mi>n</mi></math>ä¸ªç‰¹å¾çš„å®ä¾‹ï¼Œæˆ‘ä»¬æœ‰<math alttext="2 Superscript n"><msup><mn>2</mn> <mi>n</mi></msup></math>ä¸ªå­é›†ã€‚å¯¹äº 10 ä¸ªç‰¹å¾ï¼Œæˆ‘ä»¬æœ‰<math alttext="2 Superscript 10 Baseline equals 1 comma 024"><mrow><msup><mn>2</mn> <mn>10</mn></msup> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mn>024</mn></mrow></math>ä¸ªå­é›†ï¼Œå¯¹äº 20 ä¸ªç‰¹å¾ï¼Œæˆ‘ä»¬æœ‰<math alttext="2 Superscript 20 Baseline equals 1 comma 048 comma 576"><mrow><msup><mn>2</mn> <mn>20</mn></msup> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mn>048</mn> <mo>,</mo> <mn>576</mn></mrow></math>ä¸ªå­é›†ï¼Œä»¥æ­¤ç±»æ¨ã€‚ä¸€ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆæ˜¯è¿‘ä¼¼è®¡ç®— SHAPï¼Œè€Œä¸æ˜¯ç²¾ç¡®è®¡ç®—ã€‚Kernel SHAP å¯¹ç‰¹å¾å­é›†è¿›è¡Œé‡‡æ ·ï¼Œå¹¶æ ¹æ®è¿™äº›æ ·æœ¬æ‹Ÿåˆçº¿æ€§å›å½’æ¨¡å‹ã€‚å˜é‡åªæ˜¯ä¸€ä¸ªç‰¹å¾æ˜¯å¦å­˜åœ¨æˆ–ç¼ºå¤±ï¼Œè¾“å‡ºå€¼æ˜¯é¢„æµ‹ç»“æœã€‚è¿™ä¸ªçº¿æ€§æ¨¡å‹çš„ç³»æ•°å¯ä»¥è§£é‡Šä¸ºè¿‘ä¼¼çš„ Shapley å€¼ã€‚è¿™ç±»ä¼¼äº LIMEï¼Œä½†æˆ‘ä»¬ä¸å…³å¿ƒå®ä¾‹ä¹‹é—´çš„æ¥è¿‘ç¨‹åº¦ï¼Œåªå…³å¿ƒå®ƒä»¬åŒ…å«çš„ä¿¡æ¯é‡ã€‚

SHAP çš„å…¶ä»–è¿‘ä¼¼æ–¹æ³•åŒ…æ‹¬ Tree SHAP å’Œ Deep SHAPï¼Œåˆ†åˆ«ç”¨äºåŸºäºæ ‘çš„æ¨¡å‹å’Œæ·±åº¦ç¥ç»ç½‘ç»œã€‚è¿™äº›æŠ€æœ¯ä¸å†æ˜¯çœŸæ­£çš„æ¨¡å‹æ— å…³çš„ï¼Œä½†å¥½å¤„åœ¨äºå®ƒä»¬è‡³å°‘å¯ä»¥åˆ©ç”¨æ¨¡å‹å†…éƒ¨åŠ é€Ÿè®¡ç®—ã€‚

### æ·±åº¦åˆ†æç¤ºä¾‹ï¼šSHAP å¯¹è§†è§‰ Transformer æ¨¡å‹çš„åº”ç”¨

SHAP å¯ç”¨äºè§£é‡Šå¤šç§ä¸åŒç±»å‹æ•°æ®çš„é¢„æµ‹ï¼Œä»è¡¨æ ¼æ•°æ®åˆ°å›¾åƒå’Œè¯­è¨€æ•°æ®ã€‚

###### æ³¨æ„

ä½ å¯ä»¥åœ¨ç¬”è®°æœ¬[*Chapter_3_SHAP_for_Transformers.ipynb*](https://oreil.ly/D8D5E)ä¸­æ‰¾åˆ°ä¸æœ¬æ•™ç¨‹ç›¸å…³çš„æ‰€æœ‰ä»£ç ã€‚å›¾ 3-10 åˆ°å›¾ 3-15 çš„äº¤äº’ç‰ˆæœ¬ä¹Ÿå¯åœ¨*Chapter_3_SHAP_for_Transformers.ipynb*ç¬”è®°æœ¬ä¸­æ‰¾åˆ°ã€‚

è€ƒè™‘ä½¿ç”¨ SHAP åˆ†æå¤§å‹è¯­è¨€æ¨¡å‹çš„ç¤ºä¾‹ã€‚

```
# Setting up your environment for SHAP
!pip -qq install shap
!pip -qq install transformers
```

å¯¹äºæ‚¨çš„åˆ†ç±»ä»»åŠ¡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ HuggingFace Transformers åº“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨æ‚¨çš„æ¨¡å‹ï¼ˆDistilBERTï¼‰å’Œç›¸å…³çš„ tokenizer åˆ›å»ºä¸€ä¸ªæ ‡å‡†çš„`TextClassificationPipeline`ã€‚

æ­¤æ¨¡å‹æ˜¯`distilbert-base-uncased`åœ¨ sst-2-english æ•°æ®é›†ä¸Šå¾®è°ƒçš„ç‰ˆæœ¬ã€‚å³ä½¿æ˜¯å¯¹å…¶ä»–åœ¨ sst-2-english ä¸Šå¾®è°ƒçš„ distilbert æ¨¡å‹æ¥è¯´ï¼Œæ›¿æ¢è¿™ä¸ªæ¨¡å‹åç§°ä¹Ÿå¯èƒ½ä¼šå¯¼è‡´å¯è§†åŒ–å’Œè¾“å‡ºæ ‡ç­¾çš„å˜åŒ–ã€‚

```
# Setting up environment for Text Classification
import shap
import transformers

from transformers import (AutoTokenizer,
                          AutoModelForSequenceClassification,
                          TextClassificationPipeline)

tokenizer_name = "distilbert-base-uncased"
model_name = "distilbert-base-uncased-finetuned-sst-2-english"

tokenizer = transformers.DistilBertTokenizerFast.from_pretrained(tokenizer_name)
model = transformers.DistilBertForSequenceClassification.from_pretrained(
    model_name
).cpu()

pipe = TextClassificationPipeline(
    model=model, tokenizer=tokenizer, return_all_scores=True
)

def score_and_visualize(text):
    prediction = pipe([text])
    print(prediction[0])

    explainer = shap.Explainer(pipe)
    shap_values = explainer([text])

    shap.plots.text(shap_values)
```

ä½¿ç”¨æ‚¨çš„ DistilBERT æ¨¡å‹åŠå…¶å¯¼å…¥çš„ tokenizerï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° SHAP å¦‚ä½•å¤„ç†æ–‡æœ¬åˆ†ç±»ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªå¤„ç†æ˜¾ç„¶æ˜¯ç§¯ææ–‡æœ¬çš„ç¤ºä¾‹ï¼ˆå‚è§å›¾Â 3-10ï¼‰ã€‚

```
# Looking at example sentences
score_and_visualize(
    'After tons of trial and error, I finally succeeded in opening '
    'a shawarma place run by machine learning. The road was long '
    'and tough, but I am so happy with the outcome!'
)
```

```
[
    {"label": "NEGATIVE", "score": 0.0003080847964156419},
    {"label": "POSITIVE", "score": 0.9996919631958008},
]
Partition explainer: 2it [00:14, 14.77s/it]
```

![ptml 0310](img/ptml_0310.png)

###### å›¾Â 3-10\. åœ¨ä¸€ä¸ªæ˜æ˜¾ç§¯æçš„ç¤ºä¾‹å¥å­ä¸Šä½¿ç”¨ SHAPã€‚

å¹¶ä¸”è¿™æ˜¯ä¸€ä¸ªå¤„ç†æœ‰æ¶ˆæå€¾å‘çš„ä¸­æ€§æ–‡æœ¬çš„ç¤ºä¾‹ï¼ˆå‚è§å›¾Â 3-11ï¼‰ã€‚

```
# Strong negative sentiment
score_and_visualize('I am neutral to the restaurant.')
```

```
[
    {"label": "NEGATIVE", "score": 0.9982801675796509},
    {"label": "POSITIVE", "score": 0.0017198126297444105},
]
```

![ptml 0311](img/ptml_0311.png)

###### å›¾Â 3-11\. åœ¨ä¸€ä¸ªæœ‰æ„ä¹‰ä¸Šæ˜¯ä¸­ç«‹è¯„ä»·ï¼ˆè¢«è®¤ä¸ºæ˜¯æ¶ˆæçš„ï¼‰ä¸Šä½¿ç”¨ SHAPã€‚

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å†æ¬¡åˆ†æä¸­æ€§æ–‡æœ¬ï¼Œä½†è¿™æ¬¡æ˜¯å¸¦æœ‰ç§¯æå€¾å‘çš„ï¼ˆå‚è§å›¾Â 3-12ï¼‰ã€‚

```
# Neutral sentiment
score_and_visualize('I am impartial to the restaurant.')
```

```
[
    {"label": "NEGATIVE", "score": 0.0010014761937782168},
    {"label": "POSITIVE", "score": 0.9989985823631287},
]
```

![ptml 0312](img/ptml_0312.png)

###### å›¾Â 3-12\. åœ¨å¦ä¸€ä¸ªæœ‰æ„ä¹‰ä¸Šæ˜¯ä¸­ç«‹è¯„ä»·ï¼ˆè¢«è®¤ä¸ºæ˜¯ç§¯æçš„ï¼‰çš„æ–‡æœ¬ä¸Šä½¿ç”¨ SHAPã€‚

æœ€åï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ SHAP æ¥åˆ†æä¸€ä¸ªæ›´é•¿ä¸”æ•…æ„æ¨¡ç³Šçš„æ–‡æœ¬ï¼ˆå‚è§å›¾Â 3-13ï¼‰ã€‚

```
# Analyzing a longer and intentionally ambiguous restaurant review
restaurant_review = (
    "This is easily the most underrated eatery this side of Cambridge, "
    "though that is also setting a low bar. The food was pretty good, "
    "but I did not like the service. The wait staff were really slow "
    "and did not seem to know what they were doing. The restaurant "
    "was really dirty and the owners did not seem to care. Still, I "
    "loved the food. It was amazing. As a flipside of the owners not "
    "caring, the establishment seemed remarkably dog-friendly. Some "
    "people will love this place. Some people will hate it. As for "
    "a final review, I won't not not give this place a good review."
)

score_and_visualize(restaurant_review)
```

```
[
    {"label": "NEGATIVE", "score": 0.007593947928398848},
    {"label": "POSITIVE", "score": 0.9924060702323914},
]
Partition explainer: 2it [00:29, 29.03s/it]
```

![ptml 0313](img/ptml_0313.png)

###### å›¾Â 3-13\. åœ¨ä¸€ä¸ªæ›´é•¿çš„è¯„è®ºä¸Šä½¿ç”¨ SHAPã€‚

æ‚¨ç”šè‡³å¯ä»¥å°† SHAP æ‰©å±•åˆ°è§£é‡Šé›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ï¼ˆå‚è§å›¾Â 3-14ï¼‰ã€‚Â¹â´ ä¸ä¹‹å‰çš„æ–¹æ³•ï¼ˆé™¤äº†å¯¼å…¥æ›´æ”¹å¤–ï¼‰çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼Œæˆ‘ä»¬å°†ä»å¯¼å…¥çš„`ZeroShotClassificationPipeline`ç±»åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰ç±»`MyZeroShotClassificationâ€‹Pipeline`ã€‚

```
# Setting up environment for zero-shot text classification
import shap
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    ZeroShotClassificationPipeline,
)
from typing import Union, List

weights = "valhalla/distilbart-mnli-12-3"

model = AutoModelForSequenceClassification.from_pretrained(weights)
tokenizer = AutoTokenizer.from_pretrained(weights)

# Create your own pipeline that only requires the text parameter
# for the __call__ method and provides a method to set the labels
class MyZeroShotClassificationPipeline(ZeroShotClassificationPipeline):
    # Overwrite the __call__ method
    def __call__(self, *args):
        o = super().__call__(args[0], self.workaround_labels)[0]

        return [
            [
                {"label": x[0], "score": x[1]}
                for x in zip(o["labels"], o["scores"])
            ]
        ]

    def set_labels_workaround(self, labels: Union[str, List[str]]):
        self.workaround_labels = labels

example_text = "This is an example text about snowflakes in the summer"
labels = ["weather", "sports"]

# In the following, we address issue 2.
model.config.label2id.update({v: k for k, v in enumerate(labels)})
model.config.id2label.update({k: v for k, v in enumerate(labels)})

pipe = MyZeroShotClassificationPipeline(
    model=model, tokenizer=tokenizer, return_all_scores=True
)
pipe.set_labels_workaround(labels)

def score_and_visualize(text):
    prediction = pipe([text])
    print(prediction[0])

    explainer = shap.Explainer(pipe)
    shap_values = explainer([text])

    shap.plots.text(shap_values)

example_text = (
    "This is an example text about snowflakes in the "
    "summer before election season and after football season."
)
score_and_visualize(example_text)
```

```
[
    {"label": "weather", "score": 0.634835422039032},
    {"label": "entertainment", "score": 0.14570148289203644},
    {"label": "politics", "score": 0.09773397445678711},
    {"label": "sports", "score": 0.08319796621799469},
    {"label": "markets", "score": 0.03853125125169754},
]
Partition explainer: 2it [09:29, 569.93s/it]
```

![ptml 0314](img/ptml_0314.png)

###### å›¾Â 3-14\. ä½¿ç”¨ SHAP è§£é‡Šé›¶æ ·æœ¬æ–‡æœ¬åˆ†ç±»ã€‚

æ­¤ç¤ºä¾‹å±•ç¤ºäº† SHAP åº”ç”¨äºå®Œå…¨ä¸­æ€§æ–‡æœ¬çš„æƒ…å†µï¼ˆå‚è§å›¾Â 3-15ï¼‰ã€‚

```
example_text = "This is an example text about nothing at all."
score_and_visualize(example_text)
```

```
[
    {"label": "entertainment", "score": 0.6272065043449402},
    {"label": "markets", "score": 0.1165764182806015},
    {"label": "weather", "score": 0.0959262102842331},
    {"label": "politics", "score": 0.08200317621231079},
    {"label": "sports", "score": 0.07828763872385025},
]
Partition explainer: 2it [02:57, 177.37s/it]
```

ç°åœ¨ï¼Œåƒ LIME ä¸€æ ·ï¼ŒSHAP å¯ä»¥æ‰©å±•åˆ°å›¾åƒæ•°æ®ã€‚

æœ‰è®¸å¤šå…³äº[åŸºäº CNN çš„å›¾åƒåˆ†ç±»å™¨ä¸Šçš„ SHAP ç¤ºä¾‹](https://oreil.ly/eV5ib)ã€‚æ‚¨å¯ä»¥åœ¨è§†è§‰ç¤ºä¾‹ä¸­ä½¿ç”¨ç›¸åŒçš„æ–¹æ³•ï¼Œä½† SHAP ç¤ºä¾‹å¤§å¤šæ•°éƒ½æ˜¯åœ¨ç®€å•æ•°æ®é›†ï¼ˆå¦‚ MNISTï¼‰ä¸Šæ¼”ç¤ºçš„åŸå› æ˜¯æœ‰é“ç†çš„ã€‚SHAP æ“ä½œè¾“å…¥æ•°æ®çš„æ‰€æœ‰ç‰¹å¾ã€‚å¯¹äºæ–‡æœ¬æ¥è¯´ï¼Œè¿™æ˜¯æ¯ä¸ª tokenã€‚å¯¹äºå›¾åƒæ¥è¯´ï¼Œè¿™æ˜¯æ¯ä¸ªåƒç´ ã€‚å³ä½¿æ‚¨åªæ˜¯åœ¨æ‰‹å†™æ•°å­—çš„ç®€å•å›¾åƒä¸Šè¿è¡Œ SHAPï¼Œè®¡ç®—æˆæœ¬ä¹Ÿå¾ˆé«˜ã€‚

å¦‚æœæ‚¨æƒ³è¦ä¸€ä¸ªç”¨äºç¥ç»ç½‘ç»œå¤„ç†å›¾åƒæ•°æ®çš„å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œè¿˜æœ‰æ›´å¥½çš„é€‰æ‹©ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰ä»‹ç»*å…¨å±€*æ¨¡å‹æ— å…³çš„å¯è§£é‡Šæ€§æ–¹æ³•ã€‚

![ptml 0315](img/ptml_0315.png)

###### å›¾Â 3-15\. åœ¨ä¸€ä¸ªæœ‰æ„ä¹‰ä¸Šæ˜¯ä¸­ç«‹è¾“å…¥ä¸Šä½¿ç”¨ SHAP è¿›è¡Œé›¶æ ·æœ¬æ–‡æœ¬åˆ†ç±»ã€‚

## å…¨å±€æ¨¡å‹æ— å…³çš„å¯è§£é‡Šæ€§æ–¹æ³•

å¦‚å‰æ‰€è¿°ï¼Œå±€éƒ¨å¯è§£é‡Šæ€§ä¸“æ³¨äºç†è§£ä¸ªåˆ«å†³ç­–ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå…¨å±€æ–¹æ³•æ—¨åœ¨ç†è§£æ•´ä¸ªæ¨¡å‹çš„è¡Œä¸ºã€‚æˆ‘ä»¬ä¹‹å‰è®¨è®ºçš„å›ºæœ‰å¯è§£é‡Šæ–¹æ³•æä¾›äº†å…¨å±€è§£é‡Šã€‚ç„¶è€Œï¼Œè¿™äº›è§£é‡Šæ–¹æ³•éƒ½æ˜¯é’ˆå¯¹ç‰¹å®šæ¨¡å‹ç±»å‹çš„ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¸Œæœ›ä»¥ä¸æ¨¡å‹ç±»å‹æ— å…³çš„æ–¹å¼æ£€éªŒæ¨¡å‹çš„å…¨å±€è¡Œä¸ºï¼ˆæ¨¡å‹æ— å…³ï¼‰ã€‚

### æ’åˆ—ç‰¹å¾é‡è¦æ€§

æ’åˆ—ç‰¹å¾é‡è¦æ€§æŒ‡çš„æ˜¯æ’åˆ—è¾“å…¥ç‰¹å¾çš„éƒ¨åˆ†ï¼Œä»¥æŸ¥çœ‹ä¿®æ”¹æ—¶å¯¹è¾“å‡ºé¢„æµ‹é€ æˆæœ€å¤§å˜åŒ–çš„ç‰¹å¾ã€‚è¿™å¯ä»¥åº”ç”¨äºå›¾åƒã€æ–‡æœ¬å’Œè¡¨æ ¼æ•°æ®ã€‚

æ’åˆ—ç‰¹å¾é‡è¦æ€§å¯ä»¥åº”ç”¨äºè§†è§‰çš„ä¸€ç§æ–¹å¼æ˜¯æµ‹è¯•é®æŒ¡æ•æ„Ÿæ€§ã€‚è¿™æ˜¯æŒ‡å½“å›¾åƒçš„æŸäº›éƒ¨åˆ†è¢«ä»»æ„å¤§å°çš„æ­£æ–¹å½¢é®æŒ¡æ—¶ï¼Œå†³ç­–è¾“å‡ºçš„å˜åŒ–ç¨‹åº¦ã€‚

### å…¨å±€æ›¿ä»£æ¨¡å‹

è¿™ç§æŠ€æœ¯æ¶‰åŠä½¿ç”¨ä¸€ä¸ªæ¨¡å‹åˆ›å»ºå¦ä¸€ä¸ªè¡Œä¸ºæå…¶ç›¸ä¼¼çš„æ¨¡å‹ã€‚è¿™ä¸ªæƒ³æ³•æ˜¯ï¼Œä½ å¯ä»¥æ‹¿ä¸€ä¸ªåŸæœ¬æ˜¯é»‘ç›’çš„æ¨¡å‹ï¼Œåˆ›å»ºä¸€ä¸ªæœ¬è´¨ä¸Šå¯è§£é‡Šçš„æ¨¡å‹ï¼Œå…¶è¡Œä¸ºå‡ ä¹ä¸åŸæ¨¡å‹å®Œå…¨ç›¸åŒï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹å°±æ˜¯â€œæ›¿ä»£æ¨¡å‹â€ï¼‰ã€‚

è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹åœ¨äºå¯ä»¥ç†è§£åŸæœ¬æ™¦æ¶©éš¾æ‡‚æ¨¡å‹çš„é«˜çº§è¡Œä¸ºã€‚ç¼ºç‚¹æ˜¯æ‰€æœ‰è§£é‡Šéƒ½æ˜¯é’ˆå¯¹æ›¿ä»£æ¨¡å‹è€ŒéåŸå§‹æ¨¡å‹æœ¬èº«ã€‚è™½ç„¶æ›¿ä»£æ¨¡å‹çš„å†³ç­–å¯èƒ½æ˜¯ä¸€ä¸ªæ¥è¿‘çš„è¿‘ä¼¼ï¼Œä½†å®ƒä»¬ä¸æ˜¯åŸå§‹æ¨¡å‹ã€‚

### åŸå‹å’Œæ‰¹è¯„

åŸå‹å’Œæ‰¹è¯„éƒ½æ˜¯åŸºäºç¤ºä¾‹çš„å¯è§£é‡Šæ€§æ–¹æ³•ã€‚*åŸå‹* æ˜¯è®¾è®¡æˆä»£è¡¨å¯¼è‡´æŸä¸ªå†³ç­–çš„æ‰€æœ‰æ•°æ®ç‚¹çš„åˆæˆæ•°æ®ç‚¹ã€‚æ‰¹è¯„åˆ™ç›¸åï¼Œå®ƒä»¬åˆ›å»ºä¸€ä¸ªä»£è¡¨å¯¼è‡´é”™è¯¯å†³ç­–çš„å®ä¾‹çš„åˆæˆæ•°æ®ç‚¹ã€‚

*MMD-critic* æ˜¯ç”± Kim ç­‰äººå¼€å‘çš„åŸºäºç¤ºä¾‹çš„å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œå°†åŸå‹å’Œæ‰¹è¯„ç»“åˆåœ¨ä¸€ä¸ªæ¡†æ¶ä¸­ã€‚Â¹âµ åœ¨é«˜å±‚æ¬¡ä¸Šï¼Œå¯ä»¥æ€»ç»“å¦‚ä¸‹ï¼š

1.  é€‰æ‹©è¦æŸ¥æ‰¾çš„åŸå‹å’Œæ‰¹è¯„çš„æ•°é‡ã€‚

1.  ä½¿ç”¨è´ªå©ªæœç´¢æ‰¾åˆ°åŸå‹ã€‚

1.  é€‰æ‹©åŸå‹ä»¥ä½¿åŸå‹åˆ†å¸ƒæ¥è¿‘æ•°æ®åˆ†å¸ƒã€‚

1.  ä½¿ç”¨è´ªå©ªæœç´¢æ‰¾åˆ°æ‰¹è¯„ã€‚

1.  ä½œä¸ºæ‰¹è¯„é€‰å®šçš„ç‚¹æ˜¯åŸå‹åˆ†å¸ƒä¸æ•°æ®åˆ†å¸ƒä¸åŒçš„åœ°æ–¹ã€‚

## è§£é‡Šç¥ç»ç½‘ç»œ

è§£é‡Šç¥ç»ç½‘ç»œå­˜åœ¨è®¸å¤šæŒ‘æˆ˜ã€‚ç®€å•åœ°è¯´ï¼Œç¥ç»ç½‘ç»œæ˜¯é€šç”¨å‡½æ•°é€¼è¿‘å™¨ã€‚è¿™ä¸ªæƒ³æ³•æ˜¯ï¼Œé€šè¿‡åœ¨ä¸€ä¸ªæ–¹ç¨‹ä¸­ä½¿ç”¨è¶³å¤Ÿå¤šçš„å‚æ•°ï¼Œä½ å¯ä»¥åšå‡ ä¹ä»»ä½•äº‹æƒ…ã€‚ä¾‹å¦‚ï¼Œæ­£å¦‚è‘—åç‰©ç†å­¦å®¶å†¯Â·è¯ºä¼Šæ›¼æ‰€è¯´ï¼Œâ€œç”¨å››ä¸ªå‚æ•°æˆ‘å¯ä»¥æ‹Ÿåˆä¸€åªå¤§è±¡ï¼Œç”¨äº”ä¸ªå‚æ•°æˆ‘å¯ä»¥è®©å®ƒæ‘‡åŠ¨é¼»å­ã€‚â€

å¯¹äºç¥ç»ç½‘ç»œè€Œè¨€ï¼Œæ¯ä¸ªç¥ç»å…ƒæœ¬è´¨ä¸Šéƒ½æ˜¯ä¸€ä¸ªå·¨å¤§æ–¹ç¨‹ä¸­çš„å‚æ•°ã€‚ä¸€äº›å‚æ•°æœ€ç»ˆå¯èƒ½æ˜¯æ— ç”¨çš„ï¼Œä½†åªè¦æ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½åœ°é¢„æµ‹æ•°æ®æ¨¡å¼ï¼Œæˆ‘ä»¬é€šå¸¸ä¸ä¼šå¤ªåœ¨æ„ã€‚

å½“æ¶‰åŠå‡†ç¡®è§£é‡Šæ¨¡å‹æ­£åœ¨åšä»€ä¹ˆæ—¶ï¼Œè¿™æ˜¾ç„¶æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚ç¡®å®ï¼Œæ ¹æ®æ‚¨ä½¿ç”¨çš„æ¡†æ¶ï¼Œæ‚¨å¯ä»¥ä¸ºæ¨¡å¼çš„å®šä¹‰æ·»åŠ å¤§é‡æŠ½è±¡ã€‚äº‹å®ä¸Šï¼Œ[PyTorch æ”¯æŒå‘½åå¼ é‡](https://oreil.ly/jWzUD)ï¼Œè¿™æ˜¯å‘å¼ é‡çš„ç»´åº¦æ·»åŠ è¯­ä¹‰å«ä¹‰çš„ä¸€ç§æ–¹å¼ã€‚

å¦‚æœæ‚¨åˆ›å»ºæ¨¡å‹è¡Œä¸ºçš„åœ°å›¾è€Œæ²¡æœ‰æ˜ å°„å‡ºæ¯ä¸€ä¸ªç¥ç»å…ƒï¼Œæ‚¨å¯èƒ½ä¼šè§‰å¾—è‡ªå·±é”™è¿‡äº†ä¸€äº›ä¿¡æ¯ã€‚ç„¶è€Œï¼Œå¦‚æœæ‚¨å°†æ¨¡å‹æƒé‡çš„åœ°å›¾åˆ¶ä½œå¾—å¤ªç»†ç²’åº¦ï¼Œé‚£ä¹ˆæ‚¨å°±æ— æ³•ç†è§£å®ƒäº†ã€‚è¿™ä¸ªé—®é¢˜é€šå¸¸é€šè¿‡æŸ¥çœ‹ç¥ç»ç½‘ç»œæ¿€æ´»å’Œè¡Œä¸ºä¸­çš„æ›´å¤§æ¨¡å¼æ¥è§£å†³ï¼Œä½†å³ä½¿è¿™æ ·ä¹Ÿå¯èƒ½æ— æ³•è®²è¿°æ•´ä¸ªæ•…äº‹ã€‚ä¾‹å¦‚ï¼Œä¸€äº›ç ”ç©¶äººå‘˜å¯¹ç¥ç»ç½‘ç»œçš„å‰¯æœ¬ä¸Šæ¼”ç¤ºäº†ä¸€äº›æµè¡Œçš„å¯è§£é‡Šæ€§æ–¹æ³•ã€‚å¯¹äºè¿™äº›å‰¯æœ¬ï¼Œä»–ä»¬éšæœºåŒ–äº†ç¥ç»ç½‘ç»œæƒé‡çš„å­é›†ã€‚å°½ç®¡å¦‚æ­¤ï¼Œä»–ä»¬å‘ç°è¿™äº›å¯è§£é‡Šæ€§æ–¹æ³•åœ¨è¾“å‡ºå‡†ç¡®æ€§ç›¸åŒçš„æƒ…å†µä¸‹æ— æ³•åŒºåˆ†ç½‘ç»œã€‚

å°½ç®¡è¿™äº›å¯è§£é‡Šæ€§æ–¹æ³•ä»åœ¨ä¸æ–­æ”¹è¿›ä¸­ï¼Œå®ƒä»¬é€šå¸¸ä»ç„¶æ¯”å®Œå…¨æ²¡æœ‰ä»»ä½•å¯è§£é‡Šæ€§æ–¹æ³•è¦å¥½ã€‚é‡è¦çš„æ˜¯è¦è®¤è¯†åˆ°è¿™äº›è§£é‡Šæ–¹æ³•åº”è¯¥ç”¨äºä»€ä¹ˆï¼Œä¸åº”è¯¥ç”¨äºä»€ä¹ˆã€‚

## æ˜¾è‘—æ€§æ˜ å°„

*æ˜¾è‘—æ€§åœ°å›¾*æ˜¯ä¸€ä¸ªçªå‡ºæ˜¾ç¤ºç½‘ç»œæ¿€æ´»æˆ–å…³æ³¨çš„åŒºåŸŸçš„å›¾åƒã€‚æ˜¾è‘—æ€§åœ°å›¾çš„ç›®æ ‡æ˜¯åæ˜ åƒç´ å¯¹æ¨¡å‹çš„é‡è¦æ€§ç¨‹åº¦ã€‚*æ˜¾è‘—æ€§æ˜ å°„*çš„ç”¨å¤„åœ¨äºå®ƒå¯ä»¥æŒ‡å‡ºè¾“å…¥çš„ç‰¹å®šéƒ¨åˆ†ï¼ˆä¾‹å¦‚è¾“å…¥å›¾åƒä¸­çš„åƒç´ æˆ–è¾“å…¥æ–‡æœ¬ä¸­çš„æ ‡è®°ï¼‰ï¼Œè¿™äº›éƒ¨åˆ†è¢«å½’å› äºæŸä¸ªå†³ç­–ã€‚

ç”±äºæ˜¾è‘—æ€§æ˜ å°„å…è®¸æ‚¨æŸ¥çœ‹å¯¹ä¸åŒå†³ç­–æœ‰è´¡çŒ®çš„å†…å®¹ï¼Œè¿™å¯ä»¥ä½œä¸ºæä¾›åäº‹å®è¯æ®çš„ä¸€ç§æ–¹å¼ã€‚ä¾‹å¦‚ï¼Œåœ¨äºŒå…ƒæ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œå¯ä»¥æŸ¥çœ‹ä¼šå¯¹ç§¯ææˆ–æ¶ˆææƒ…æ„Ÿæœ‰æ‰€è´¡çŒ®çš„åµŒå…¥ã€‚

åŸºäºæ¢¯åº¦çš„æ–¹æ³•æ¯”åƒ LIME æˆ– SHAP è¿™æ ·çš„æ–¹æ³•è®¡ç®—é€Ÿåº¦å¿«å¾—å¤šã€‚

## æ·±å…¥æ¢è®¨ï¼šCLIP ä¸­çš„æ˜¾è‘—æ€§æ˜ å°„

[CLIPï¼ˆå¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒï¼‰](https://oreil.ly/PQ4my) æ˜¯ OpenAI åˆ›å»ºçš„ä¸€ä¸ªæ¨¡å‹ï¼Œç”¨ä½œæ–‡æœ¬è¡¨ç¤ºå’Œå›¾åƒè¡¨ç¤ºä¹‹é—´çš„æ¡¥æ¢ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™æ„å‘³ç€å®ƒå¯ä»¥ç”¨æ¥æ¯”è¾ƒè¾“å…¥å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚`"ä¸€ä¸ªå¯çˆ±çš„å°çŒ«ååœ¨ç¯®å­é‡Œ"`ï¼‰æ‰€ä»£è¡¨çš„æ¦‚å¿µä¸å®é™…çŒ«å’ªç…§ç‰‡æ‰€ä»£è¡¨çš„æ¦‚å¿µä¹‹é—´çš„ç›¸ä¼¼æ€§å¾—åˆ†ã€‚OpenAI çš„å®ç°è¿˜ç»è¿‡è®­ç»ƒï¼Œå¯ä»¥ä½œä¸ºé›¶æ ·æœ¬å›¾åƒåˆ†ç±»å™¨ä½¿ç”¨ã€‚ä¾‹å¦‚ï¼Œå®ƒä¸ä»…èƒ½å¤Ÿè¯†åˆ« ImageNet ä¸­é¦™è•‰çš„ç…§ç‰‡ï¼Œè¿˜èƒ½å¤Ÿè¯†åˆ«æŸåå’Œä½è´¨é‡ç…§ç‰‡ä¸­ä»¥åŠç”»ä½œä¸­çš„é¦™è•‰ã€‚

è®­ç»ƒç½‘ç»œä»¥å°†æ–‡æœ¬åµŒå…¥ä¸å›¾åƒå…³è”å…è®¸æ¨¡å‹ä»¥äººç±»å¯ç†è§£çš„æ–¹å¼æè¿°å›¾åƒå†…å®¹ï¼Œè€Œä¸ä»…ä»…æ˜¯ä½œä¸ºè¡¨ç¤ºé¢„å®šè¾“å‡ºç±»åˆ«æ•°é‡çš„ç‹¬çƒ­ç¼–ç å‘é‡ã€‚

ç„¶è€Œï¼Œæ‰€æœ‰è¿™äº›èƒ½åŠ›éƒ½ä¾èµ–äºäººç±»ç”¨æˆ·ä¿¡ä»» CLIP èƒ½å¤Ÿ*æ­£ç¡®*å…³è”æ–‡æœ¬åµŒå…¥å’Œå›¾åƒåµŒå…¥ã€‚è€ƒè™‘åˆ°å¯èƒ½çš„å›¾åƒå’Œæ–‡æœ¬é…å¯¹çš„å·¨å¤§å¤šæ ·æ€§ï¼Œè¿™å¹¶ä¸æ˜¯ä¸€é¡¹ç®€å•çš„ä»»åŠ¡ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬è¿„ä»Šæ‰€æ¶µç›–çš„æ¦‚å¿µå¯ä»¥æä¾›ä¸€äº›æŒ‡å¯¼ã€‚

###### æ³¨æ„

æ‚¨å¯ä»¥åœ¨ç¬”è®°æœ¬ [*Chapter_3_CLIP_Saliency_mapping_Part1.ipynb*](https://oreil.ly/6pmRx) å’Œ [*Chapter_3_CLIP_Saliency_mapping_Part2.ipynb*](https://oreil.ly/GBP7Q) ä¸­æ‰¾åˆ°ä¸æœ¬æ•™ç¨‹ç›¸å…³çš„ä»£ç ã€‚è¿™äº›ç¬”è®°æœ¬å—åˆ° [`hila-chefer` çš„ `Transformer-MM-Explainability` é¡¹ç›®](https://oreil.ly/9iKQ7) çš„å¯å‘ï¼Œå¹¶åˆ©ç”¨äº† Captum åº“ã€‚

è¿è¡Œæ­¤ä»£ç éœ€è¦å¤§é‡ RAMã€‚å¦‚æœæ‚¨åœ¨ Google Colab ä¸­è¿è¡Œæ­¤ä»£ç ï¼Œè¯·ä½¿ç”¨ Colab Pro ä¸­æœ€å¤§çš„ GPUï¼Œå¹¶å°† RAM è®¾ç½®ä¸ºæœ€é«˜ã€‚

è‹¥è¦ä½¿ç”¨ CLIPï¼Œæ‚¨å¯ä»¥ä»é¡¹ç›®çš„ [å…¬å…±å­˜å‚¨åº“](https://oreil.ly/Q1xgq) ä¸‹è½½ä»£ç ã€‚æˆ‘ä»¬å°†æ¨¡å‹æ”¾åœ¨ä¸€ä¸ªå­ç›®å½•ä¸­ï¼Œæ‚¨å¯ä»¥ä»ä¸­å¯¼å…¥æ¨¡å‹ã€‚

```
# Setting up your environment for CLIP

# Making sure the correct version of PyTorch is installed
!conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0
# Installing other dependencies for OpenAI's CLIP
!pip install ftfy regex tqdm
# Installing dependencies for the saliency mapping
!pip install einops ftfy captum
# Installing CLIP directly from the project Repository
!pip install git+https://github.com/openai/CLIP.git

import numpy as np
import torch
from pkg_resources import packaging
%config InlineBackend.figure_format = 'retina'

print("Torch version:", torch.__version__)
```

ä¸€æ—¦æˆ‘ä»¬è®¾ç½®å¥½æ‚¨çš„å¼€å‘ç¯å¢ƒï¼Œæ‚¨å¯ä»¥ä¸‹è½½ CLIP æ¨¡å‹çš„æƒé‡ã€‚è¿™äº›æƒé‡å¯ä»¥ç›´æ¥ä» OpenAI è·å–ã€‚

```
# Loading the CLIP models directly from OpenAI
import clip

print("Available CLIP Models:\n", clip.available_models())

# Loading the model and the preprocessing step
model, preprocess = clip.load("ViT-B/32")
model.cuda().eval()
input_resolution = model.visual.input_resolution
context_length = model.context_length
vocab_size = model.vocab_size

print(
    "Model parameters:",
    f"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}",
)
print("Input resolution:", input_resolution)
print("Context length:", context_length)
print("Vocab size:", vocab_size)
```

```
Available CLIP Models:
['RN50',
 'RN101',
 'RN50x4',
 'RN50x16',
 'RN50x64',
 'ViT-B/32',
 'ViT-B/16',
 'ViT-L/14',
 'ViT-L/14@336px']
Model parameters: 151,277,313
Input resolution: 224
Context length: 77
Vocab size: 49408
```

åœ¨æ‚¨ä½¿ç”¨ä»»ä½•è¾“å…¥æµ‹è¯• CLIP ä¹‹å‰ï¼Œæ‚¨éœ€è¦è®¾ç½®é¢„å¤„ç†æ­¥éª¤ã€‚è™½ç„¶ CLIP æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸Šä»¤äººå°è±¡æ·±åˆ»çš„æ¨¡å‹ï¼Œä½†ä¸è¦å¿˜è®°æ­£ç¡®çš„é¢„å¤„ç†æ­¥éª¤ã€‚ç”±äº CLIP åŒæ—¶å¤„ç†æ–‡æœ¬å’Œå›¾åƒï¼Œæ‚¨éœ€è¦èƒ½å¤Ÿé¢„å¤„ç†è¿™ä¸¤ç§æ•°æ®ç±»å‹ã€‚

```
# Text preprocessing
clip.tokenize("Hello World!")
```

```
tensor([[49406,  3306,  1002,   256, 49407,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)
```

å¯¹äºæ–‡æœ¬é¢„å¤„ç†ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸åŒºåˆ†å¤§å°å†™çš„åˆ†è¯å™¨ã€‚

å¯¹äºå›¾åƒé¢„å¤„ç†ï¼Œæˆ‘ä»¬å°†è¿›è¡Œæ ‡å‡†çš„åƒç´ å¼ºåº¦å½’ä¸€åŒ–ï¼ŒÂ¹â¶ å›¾åƒè°ƒæ•´å¤§å°å’Œä¸­å¿ƒè£å‰ªçš„è¿‡ç¨‹ã€‚

æˆ‘ä»¬å¯ä»¥è‡ªå·±åˆ›å»ºè¿™ä¸ªé¢„å¤„ç†é˜¶æ®µï¼Œä½†æˆ‘ä»¬æ²¡æœ‰å¿…è¦ã€‚æ­£å¦‚æ‚¨æ—©äº›æ—¶å€™çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å¯ä»¥åŠ è½½ç‰¹å®šæ¨¡å‹çš„ CLIP é¢„å¤„ç†æ¨¡å—ã€‚æˆ‘ä»¬åªéœ€æ£€æŸ¥è¯¥é¢„å¤„ç†æ­¥éª¤ï¼Œä»¥ç¡®ä¿å®ƒå…·æœ‰æ‰€æœ‰æ­£ç¡®çš„é˜¶æ®µã€‚

```
# Image preprocessing
preprocess
```

```
Compose(
    Resize(size=224, interpolation=bicubic, max_size=None, antialias=None)
    CenterCrop(size=(224, 224))
    <function _convert_image_to_rgb at 0x7f7c70b87560>
    ToTensor()
    Normalize(mean=(0.48145466, 0.4578275, 0.40821073),
              std=(0.26862954, 0.26130258, 0.27577711))
)
```

ä¸€æ—¦å®Œæˆï¼Œæ‚¨å°†å‡†å¤‡æ¨¡å‹æ¥æ¥æ”¶ä¸€ç»„ç¤ºä¾‹å›¾åƒåŠå…¶æ–‡æœ¬æè¿°ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æµ‹é‡ç”Ÿæˆçš„æ–‡æœ¬ç‰¹å¾å’Œå›¾åƒç‰¹å¾ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦æ¥æµ‹è¯•æ¨¡å‹ã€‚

```
# Set up input images and text pairs
import os
import skimage
import IPython.display
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

from collections import OrderedDict
import torch

%matplotlib inline
%config InlineBackend.figure_format = 'retina'

# images in skimage to use and their textual descriptions
descriptions = {
    "phantom": "an MRI slice resembling a phantom rabbit",
    "cell": "a cell seen under a microscope",
    "brick": "a black and white photo of a brick road",
    "coins": "antique coins viewed by a flatbed scanner",
    "motorcycle_left": "a red motorcycle standing in a garage",
    "text": "handwritten integrals and math equations",
    "clock_motion": "a blurred image of a wall clock",
    "color": "a ranbow RGB color Palette"
}

original_images = []
images = []
texts = []
plt.figure(figsize=(16, 5))
```

å¦‚å›¾ 3-16 æ‰€ç¤ºï¼Œæˆ‘ä»¬æ‹¥æœ‰å„ç§å„æ ·çš„å›¾åƒï¼Œä»é€¼çœŸçš„åˆ°æŠ½è±¡çš„ï¼Œä»æ¸…æ™°å®šä¹‰çš„åˆ°æ¨¡ç³Šä¸æ¸…çš„ã€‚

![ptml 0316](img/ptml_0316.png)

###### å›¾ 3-16\. CLIP å°†å•è¯ä¸å›¾åƒåŒ¹é…

```
for filename in [
    filename
    for filename in os.listdir(skimage.data_dir)
    if filename.endswith(".png") or filename.endswith(".jpg")
]:
    name = os.path.splitext(filename)[0]
    if name not in descriptions:
        continue
    image = Image.open(os.path.join(skimage.data_dir, filename)).convert("RGB")

    plt.subplot(2, 4, len(images) + 1)
    plt.imshow(image)
    plt.title(f"{filename}\n{descriptions[name]}")
    plt.xticks([])
    plt.yticks([])

    original_images.append(image)
    images.append(preprocess(image))
    texts.append(descriptions[name])
plt.tight_layout()
```

å°½ç®¡è¿™äº›å›¾åƒæœ‰äº›å¯èƒ½å¯¹äººç±»æ¥è¯´éš¾ä»¥åˆ†ç±»ï¼Œä½†æ˜¯ CLIP åœ¨å°†å®ƒä»¬ä¸å…¶æ–‡æœ¬æè¿°é…å¯¹æ–¹é¢åšå¾—ç›¸å½“å¥½ï¼Œæ­£å¦‚å›¾ 3-17 æ‰€ç¤ºã€‚

![ptml 0317](img/ptml_0317.png)

###### å›¾ 3-17\. ä½¿ç”¨ CLIP å°†å›¾åƒä¸æ–‡æœ¬æè¿°é…å¯¹

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¿™äº›å¯¹é€šè¿‡æˆ‘ä»¬çš„æ–‡æœ¬å’Œå›¾åƒé¢„å¤„ç†æ­¥éª¤ï¼Œç„¶åé€šè¿‡ CLIP æ¨¡å‹æœ¬èº«ã€‚

```
# Get features from the model
image_input = torch.tensor(np.stack(images)).cuda()
text_tokens = clip.tokenize(["This is " + desc for desc in texts]).cuda()

with torch.no_grad():
    image_features = model.encode_image(image_input).float()
    text_features = model.encode_text(text_tokens).float()
image_features /= image_features.norm(dim=-1, keepdim=True)
text_features /= text_features.norm(dim=-1, keepdim=True)
similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T
```

è¦æ¯”è¾ƒè¿™äº›å›¾åƒç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾ï¼Œæ‚¨éœ€è¦å¯¹å®ƒä»¬è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¹¶è®¡ç®—æ¯å¯¹ç‰¹å¾çš„ç‚¹ç§¯ã€‚

```
# Pairwise comparisons of images and their text descriptions
count = len(descriptions)

plt.figure(figsize=(20, 14))
plt.imshow(similarity, vmin=0.1, vmax=0.3)
# plt.colorbar()
plt.yticks(range(count), texts, fontsize=18)
plt.xticks([])
for i, image in enumerate(original_images):
    plt.imshow(image, extent=(i - 0.5, i + 0.5, -1.6, -0.6), origin="lower")
for x in range(similarity.shape[1]):
    for y in range(similarity.shape[0]):
        plt.text(
            x, y, f"{similarity[y, x]:.2f}", ha="center", va="center", size=12
        )
for side in ["left", "top", "right", "bottom"]:
    plt.gca().spines[side].set_visible(False)
plt.xlim([-0.5, count - 0.5])
plt.ylim([count + 0.5, -2])

plt.title("Cosine similarity between text and image features", size=20)
```

å¦‚æ‚¨åœ¨å›¾ 3-18 ä¸­æ‰€è§ï¼ŒCLIP ä¸ä»…åœ¨æ–‡æœ¬å’Œå›¾åƒç›¸ä¼¼æ—¶è¡¨ç°éå¸¸å¥½ï¼Œè€Œä¸”åœ¨å®ƒä»¬éå¸¸ä¸ç›¸ä¼¼æ—¶åŒæ ·é‡è¦ã€‚

ç°åœ¨æˆ‘ä»¬å·²ç»éªŒè¯äº† CLIP åœ¨é¢„é€‰å›¾åƒå’Œæ–‡æœ¬å¯¹ä¸Šçš„å·¥ä½œæ•ˆæœï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒæ¥ä¸ºæ¥è‡ªå®Œå…¨ä¸åŒæ•°æ®é›†çš„å›¾åƒç”Ÿæˆåˆ†ç±»ã€‚ä¸ºäº†ä½¿ CLIP çš„è¾“å‡ºè¡Œä¸ºç±»ä¼¼äº softmax æ“ä½œçš„å¯¹æ•°å‡ ç‡ï¼Œåªéœ€å°†ä½™å¼¦ç›¸ä¼¼åº¦ä¹˜ä»¥ 100ã€‚

![ptml 0318](img/ptml_0318.png)

###### å›¾ 3-18\. æ–‡æœ¬ä¸å›¾åƒç‰¹å¾ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦

```
# Zero-shot image classification
from torchvision.datasets import CIFAR100

cifar100 = CIFAR100(
    os.path.expanduser("~/.cache"), transform=preprocess, download=True
)

text_descriptions = [
    f"This is a photo of a {label}" for label in cifar100.classes
]
text_tokens = clip.tokenize(text_descriptions).cuda()

with torch.no_grad():
    text_features = model.encode_text(text_tokens).float()
    text_features /= text_features.norm(dim=-1, keepdim=True)
text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)
top_probs, top_labels = text_probs.cpu().topk(5, dim=-1)

plt.figure(figsize=(16, 16))

for i, image in enumerate(original_images):
    plt.subplot(4, 4, 2 * i + 1)
    plt.imshow(image)
    plt.axis("off")

    plt.subplot(4, 4, 2 * i + 2)
    y = np.arange(top_probs.shape[-1])
    plt.grid()
    plt.barh(y, top_probs[i])
    plt.gca().invert_yaxis()
    plt.gca().set_axisbelow(True)
    plt.yticks(y, [cifar100.classes[index] for index in top_labels[i].numpy()])
    plt.xlabel("probability")
plt.subplots_adjust(wspace=0.5)
plt.show()
```

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œåœ¨æœ¬ç« ä¸­æˆ‘ä»¬ä»‹ç»çš„è®¸å¤šå¯è§£é‡Šæ€§æŠ€æœ¯å·²ç»å¤šæ¬¡åœ¨å…·æœ‰æœ‰é™å¯èƒ½è¾“å‡ºçš„æ¨¡å‹ä¸Šè¿›è¡Œäº†æ¼”ç¤ºã€‚é—®é¢˜åœ¨äºï¼Œæ¨¡å‹æœ‰æ—¶ä¼šè¢«å‘ˆç°å‡ºå®ƒä»¬ä»æœªè§è¿‡çš„è¾“å…¥ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå°†æ˜¾è‘—æ€§æ˜ å°„ç­‰å¯è§£é‡Šæ€§æ–¹æ³•ä¸ CLIP çš„é›¶æ ·æœ¬èƒ½åŠ›ç»“åˆåœ¨ä¸€èµ·å¯èƒ½éå¸¸å¼ºå¤§çš„åŸå› ã€‚

è¦ä½¿ç”¨ CLIP è¿›è¡Œæ˜¾è‘—æ€§æ˜ å°„ï¼Œè¯·ç¡®ä¿å·²æŒ‰å…ˆå‰æè¿°çš„æ­¥éª¤è®¾ç½®å¥½ CLIPã€‚æˆ‘ä»¬è¿˜éœ€è¦ä¸‹è½½[Captum](https://captum.ai)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äº PyTorch çš„æ¨¡å‹å¯è§£é‡Šæ€§å·¥å…·åŒ…ã€‚

å¯¹äºæ˜¾è‘—æ€§æ˜ å°„ï¼Œæˆ‘ä»¬è¿˜éœ€è¦é€‰æ‹©æˆ‘ä»¬å°†ä»ä¸­è·å–æ¿€æ´»çš„å±‚ã€‚æ¨¡å‹çš„æœ€ç»ˆå±‚æ˜¯è¾“å…¥åˆ°è¾“å‡ºå±‚çš„æœ€ç»ˆæ¦‚ç‡ã€‚ä¸ºäº†äº†è§£åœ¨è¾“å…¥å’Œè¾“å‡ºä¹‹é—´å‘ç”Ÿçš„é€»è¾‘ï¼Œæ‚¨éœ€è¦é€‰æ‹©ä¸€ä¸ªä¸­é—´å±‚ã€‚

```
# Setup and layer selection
import torch
import clip
from PIL import Image
import numpy as np
import cv2
import matplotlib.pyplot as plt
from captum.attr import visualization

start_layer =  11
start_layer_text = 11
```

CLIP åº”è¯¥å¯ä»¥æ£€æŸ¥ï¼Œä½†æ˜¯æ‚¨éœ€è¦è¿›è¡Œä¸€äº›å…³é”®æ›´æ”¹ï¼Œä»¥ä½¿å…¶å…¨éƒ¨æ­£å¸¸å·¥ä½œã€‚ç°æœ‰çš„ CLIP å®ç°ä¸ä¼šä»¥æ˜“äºè®°å½•çš„æ–¹å¼è®°å½•æ³¨æ„åŠ›ï¼Œå› æ­¤æˆ‘ä»¬å°†å¯¹æ¨¡å‹è¿›è¡Œè¡¥ä¸ã€‚*Monkey-patching* æŒ‡çš„æ˜¯åœ¨å®šä¹‰ååŠ¨æ€ä¿®æ”¹ç±»æˆ–å‡½æ•°çš„è¿‡ç¨‹ã€‚è¿™æ˜¯ä¿®è¡¥ç°æœ‰ç¬¬ä¸‰æ–¹ä»£ç åº“æˆ–åº“çš„å¿«é€Ÿæ–¹æ³•ï¼Œç”¨äºè§£å†³é”™è¯¯æˆ–ç¼ºå°‘åŠŸèƒ½ã€‚

###### æ³¨æ„

OpenAI çš„ä»£ç çš„æ•´ä½“è¡¥ä¸çš„è¯¦ç»†å†…å®¹å¯ä»¥åœ¨[æœ¬èŠ‚çš„é™„å±ç¬”è®°æœ¬](https://oreil.ly/oYXTi)æ‰¾åˆ°ã€‚è¿™äº›æ›´æ”¹é’ˆå¯¹ 'ViT-B/32' å’Œ 'ViT-B/16' æ¨¡å‹ã€‚ç”±äºæ¶æ„çš„å·®å¼‚ï¼Œè¿™äº›æ›´æ”¹ä¸å…¼å®¹ 'RN50'ã€'RN101'ã€'RN50x4'ã€'RN50x16'ã€'RN50x64'ã€'ViT-L/14' å’Œ 'ViT-L/14@336px' CLIP æ¨¡å‹ã€‚OpenAI å¯èƒ½ä¼šåœ¨æœªæ¥çš„ç‰ˆæœ¬ä¸­åŒ…å«è¿™äº›æ›´æ”¹ã€‚ç›®å‰ï¼Œæˆ‘ä»¬å°†é€‚é…æˆ‘ä»¬æ­£åœ¨ä½¿ç”¨çš„åˆ†æ”¯ã€‚

å¦‚æœæ‚¨å¯¹ Python ä¸­çš„ monkey-patching ä¸ç†Ÿæ‚‰ï¼Œ[è¿™é‡Œæœ‰ä¸€ä¸ªæ•™ç¨‹](https://oreil.ly/ZblMe)ï¼Œé€‚ç”¨äºæœºå™¨å­¦ä¹ ç¯å¢ƒã€‚

ä»è¿™é‡Œå¼€å§‹ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªå¸®åŠ©å‡½æ•°ï¼Œæ£€æŸ¥ CLIP å›¾åƒå’Œæ–‡æœ¬éƒ¨åˆ†çš„æ³¨æ„åŠ›å—ã€‚

```
# Inspect attention blocks
def interpret(image, texts, model, device):
    batch_size = texts.shape[0]
    images = image.repeat(batch_size, 1, 1, 1)
    logits_per_image, logits_per_text = model(images, texts)
    probs = logits_per_image.softmax(dim=-1).detach().cpu().numpy()
    index = [i for i in range(batch_size)]
    one_hot = np.zeros(
        (logits_per_image.shape[0], logits_per_image.shape[1]), dtype=np.float32
    )
    one_hot[torch.arange(logits_per_image.shape[0]), index] = 1
    one_hot = torch.from_numpy(one_hot).requires_grad_(True)
    one_hot = torch.sum(one_hot.cuda() * logits_per_image)
    model.zero_grad()

    image_attn_blocks = list(
        dict(model.visual.transformer.resblocks.named_children()).values()
    )
    num_tokens = image_attn_blocks[0].attn_probs.shape[-1]
    R = torch.eye(
        num_tokens, num_tokens, dtype=image_attn_blocks[0].attn_probs.dtype
    ).to(device)
    R = R.unsqueeze(0).expand(batch_size, num_tokens, num_tokens)
    for i, blk in enumerate(image_attn_blocks):
        if i < start_layer:
            continue
        grad = torch.autograd.grad(
            one_hot, [blk.attn_probs], retain_graph=True
        )[0].detach()
        cam = blk.attn_probs.detach()
        cam = cam.reshape(-1, cam.shape[-1], cam.shape[-1])
        grad = grad.reshape(-1, grad.shape[-1], grad.shape[-1])
        cam = grad * cam
        cam = cam.reshape(batch_size, -1, cam.shape[-1], cam.shape[-1])
        cam = cam.clamp(min=0).mean(dim=1)
        R = R + torch.bmm(cam, R)
    image_relevance = R[:, 0, 1:]

    text_attn_blocks = list(
        dict(model.transformer.resblocks.named_children()).values()
    )
    num_tokens = text_attn_blocks[0].attn_probs.shape[-1]
    R_text = torch.eye(
        num_tokens, num_tokens, dtype=text_attn_blocks[0].attn_probs.dtype
    ).to(device)
    R_text = R_text.unsqueeze(0).expand(batch_size, num_tokens, num_tokens)
    for i, blk in enumerate(text_attn_blocks):
        if i < start_layer_text:
            continue
        grad = torch.autograd.grad(
            one_hot, [blk.attn_probs], retain_graph=True
        )[0].detach()
        cam = blk.attn_probs.detach()
        cam = cam.reshape(-1, cam.shape[-1], cam.shape[-1])
        grad = grad.reshape(-1, grad.shape[-1], grad.shape[-1])
        cam = grad * cam
        cam = cam.reshape(batch_size, -1, cam.shape[-1], cam.shape[-1])
        cam = cam.clamp(min=0).mean(dim=1)
        R_text = R_text + torch.bmm(cam, R_text)
    text_relevance = R_text

    return text_relevance, image_relevance
```

æˆ‘ä»¬æ„Ÿå…´è¶£çš„æœ‰ä¸¤ä»¶äº‹ã€‚ç¬¬ä¸€ä»¶æ˜¯æ¨¡å‹ä¸“æ³¨äºè¾“å…¥æ–‡æœ¬çš„å“ªäº›éƒ¨åˆ†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œåœ¨æ–‡æœ¬ä¸­çš„å­—ç¬¦ä¸Šå åŠ çƒ­å›¾ã€‚

```
# Text heatmap
from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer

_tokenizer = _Tokenizer()

def show_heatmap_on_text(text, text_encoding, R_text):
    CLS_idx = text_encoding.argmax(dim=-1)
    R_text = R_text[CLS_idx, 1:CLS_idx]
    text_scores = R_text / R_text.sum()
    text_scores = text_scores.flatten()
    print(text_scores)
    text_tokens = _tokenizer.encode(text)
    text_tokens_decoded = [_tokenizer.decode([a]) for a in text_tokens]
    vis_data_records = [
        visualization.VisualizationDataRecord(
            text_scores, 0, 0, 0, 0, 0, text_tokens_decoded, 1
        )
    ]
    visualization.visualize_text(vis_data_records)
```

æˆ‘ä»¬æ„Ÿå…´è¶£çš„ç¬¬äºŒä»¶äº‹æ˜¯æ¨¡å‹ä¸“æ³¨äºè¾“å…¥å›¾åƒçš„å“ªäº›éƒ¨åˆ†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œåœ¨è¾“å…¥å›¾åƒçš„åƒç´ ä¸Šå åŠ çƒ­å›¾ã€‚

```
# Image heatmap
def show_image_relevance(image_relevance, image, orig_image):
    # create heatmap from mask on image
    def show_cam_on_image(img, mask):
        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)
        heatmap = np.float32(heatmap) / 255
        cam = heatmap + np.float32(img)
        cam = cam / np.max(cam)
        return cam

    # plt.axis('off')
    # f, axarr = plt.subplots(1,2)
    # axarr[0].imshow(orig_image)

    fig, axs = plt.subplots(1, 2)
    axs[0].imshow(orig_image)
    axs[0].axis("off")

    image_relevance = image_relevance.reshape(1, 1, 7, 7)
    image_relevance = torch.nn.functional.interpolate(
        image_relevance, size=224, mode="bilinear"
    )
    image_relevance = (
        image_relevance.reshape(224, 224).cuda().data.cpu().numpy()
    )
    image_relevance = (image_relevance - image_relevance.min()) / (
        image_relevance.max() - image_relevance.min()
    )
    image = image[0].permute(1, 2, 0).data.cpu().numpy()
    image = (image - image.min()) / (image.max() - image.min())
    vis = show_cam_on_image(image, image_relevance)
    vis = np.uint8(255 * vis)
    vis = cv2.cvtColor(np.array(vis), cv2.COLOR_RGB2BGR)
    # axar[1].imshow(vis)
    axs[1].imshow(vis)
    axs[1].axis("off")
    # plt.imshow(vis)
```

æœ‰äº†è¿™äº›è¾…åŠ©å‡½æ•°ï¼Œæ‚¨å¯ä»¥çœ‹åˆ° CLIP åœ¨è¾“å…¥çš„æ–‡æœ¬å’Œå›¾åƒéƒ¨åˆ†çš„æ³¨æ„åŠ›é›†ä¸­åœ¨å“ªé‡Œã€‚è¯·å‚é˜…å›¾ 3-19 åˆ° 3-36 ï¼Œäº†è§£ CLIP æ˜¾è‘—æ€§çš„ç¤ºä¾‹ï¼›å¥‡æ•°ç¼–å·çš„å›¾æ˜¾ç¤ºè¾“å…¥æ–‡æœ¬çš„æ˜¾è‘—æ€§ï¼Œå¶æ•°ç¼–å·çš„å›¾æ˜¾ç¤ºç±»ä¼¼å†…å®¹çš„å›¾åƒä¸Šçš„æ˜¾è‘—æ€§ã€‚

```
# A sample of saliency maps on various image-text pairs
img_path = "clip_images/glasses.png"
img = preprocess(Image.open(img_path)).unsqueeze(0).to(device)
texts = ["a man with eyeglasses"]
text = clip.tokenize(texts).to(device)

R_text, R_image = interpret(model=model, image=img, texts=text, device=device)
batch_size = text.shape[0]
for i in range(batch_size):
    show_heatmap_on_text(texts[i], text[i], R_text[i])
    show_image_relevance(R_image[i], img, orig_image=Image.open(img_path))
    plt.show()
```

![ptml 0319](img/ptml_0319.png)

###### å›¾ 3-19\. åœ¨è¾“å…¥æ–‡æœ¬ä¸Šçš„ CLIP æ˜¾è‘—æ€§ï¼Œçªå‡ºæ˜¾ç¤º *çœ¼é•œ* éƒ¨åˆ†

![ptml 0320](img/ptml_0320.png)

###### å›¾ 3-20\. åœ¨è¾“å…¥å›¾åƒä¸Šçš„ CLIP å›¾åƒæ˜¾è‘—æ€§ï¼Œçªå‡ºæ˜¾ç¤ºçœ¼é•œ

![ptml 0321](img/ptml_0321.png)

###### å›¾ 3-21\. åœ¨è¾“å…¥æ–‡æœ¬ä¸Šçš„ CLIP æ˜¾è‘—æ€§ï¼Œçªå‡ºæ˜¾ç¤º *å£çº¢* éƒ¨åˆ†

![ptml 0322](img/ptml_0322.png)

###### å›¾ 3-22\. åœ¨è¾“å…¥å›¾åƒä¸Šçš„ CLIP å›¾åƒæ˜¾è‘—æ€§ï¼Œçªå‡ºæ˜¾ç¤ºå˜´å”‡

![ptml 0323](img/ptml_0323.png)

###### å›¾ 3-23\. åœ¨ç«ç®­å‘å°„å°ä¸Šæè¿°ç«ç®­çš„æ–‡å­—ä¸Šçš„ CLIP æ–‡æœ¬æ˜¾è‘—æ€§

![ptml 0324](img/ptml_0324.png)

###### å›¾ 3-24\. åœ¨åŒ…å«é˜¿å°”å¿’å¼¥æ–¯ç«ç®­çš„è¾“å…¥å›¾åƒä¸Šçš„ CLIP å›¾åƒå’Œæ–‡æœ¬æ˜¾è‘—æ€§

![ptml 0325](img/ptml_0325.png)

###### å›¾ 3-25\. æè¿°æ–‘é©¬çš„æ–‡æœ¬ä¸Šçš„ CLIP æ–‡æœ¬æ˜¾è‘—æ€§

![ptml 0326](img/ptml_0326.png)

###### Figure 3-26\. CLIP å›¾åƒå’Œæ–‡æœ¬æ˜¾è‘—æ€§åˆ†æç»“æœæ˜¾ç¤ºäº†è¾“å…¥å›¾åƒä¸­çš„ä¸€åªå¤§è±¡ä½äºä¸­å¿ƒï¼Œä½†ä¹Ÿæœ‰ä¸¤åªæ–‘é©¬åœ¨æ°´å‘é™„è¿‘çš„åº•éƒ¨ã€‚

![ptml 0327](img/ptml_0327.png)

###### Figure 3-27\. CLIP å¯¹æè¿°æ–‘é©¬çš„æ–‡æœ¬çš„æ˜¾è‘—æ€§åˆ†æã€‚

![ptml 0328](img/ptml_0328.png)

###### Figure 3-28\. CLIP å›¾åƒå’Œæ–‡æœ¬æ˜¾è‘—æ€§åˆ†æç»“æœæ˜¾ç¤ºäº†è¾“å…¥å›¾åƒä¸­çš„ä¸€åªå¤§è±¡ä½äºä¸­å¿ƒï¼Œä½†ä¹Ÿæœ‰ä¸¤åªæ–‘é©¬åœ¨æ°´å‘é™„è¿‘çš„åº•éƒ¨ã€‚

![ptml 0329](img/ptml_0329.png)

###### Figure 3-29\. CLIP å¯¹æè¿°å¤§è±¡çš„æ–‡æœ¬çš„æ˜¾è‘—æ€§åˆ†æã€‚

![ptml 0330](img/ptml_0330.png)

###### Figure 3-30\. CLIP å›¾åƒå’Œæ–‡æœ¬æ˜¾è‘—æ€§åˆ†æç»“æœæ˜¾ç¤ºäº†è¾“å…¥å›¾åƒä¸­çš„ä¸€åªå¤§è±¡ä½äºä¸­å¿ƒï¼ŒåŒæ—¶è§’è½é‡Œè¿˜æœ‰ä¸€åªæ–‘é©¬ã€‚

![ptml 0331](img/ptml_0331.png)

###### Figure 3-31\. CLIP å¯¹æè¿°ç‹—å“ç§çš„æ–‡æœ¬çš„æ˜¾è‘—æ€§åˆ†æã€‚

![ptml 0332](img/ptml_0332.png)

###### Figure 3-32\. CLIP å¯¹åŒ…å«ç‹—å’ŒçŒ«çš„å›¾åƒçš„æ˜¾è‘—æ€§åˆ†æç¤ºä¾‹ï¼Œå…·ä½“å–å†³äºè¾“å…¥æ–‡æœ¬æ˜¯å¦æ˜ç¡®æåˆ°äº†ç‹—æˆ–çŒ«ã€‚

![ptml 0333](img/ptml_0333.png)

###### Figure 3-33\. CLIP å¯¹æè¿°ç‹—å“ç§çš„æ–‡æœ¬çš„æ˜¾è‘—æ€§åˆ†æã€‚

![ptml 0334](img/ptml_0334.png)

###### Figure 3-34\. CLIP å¯¹åŒ…å«ç‹—å’ŒçŒ«çš„å›¾åƒçš„æ˜¾è‘—æ€§åˆ†æç¤ºä¾‹ï¼Œå…·ä½“å–å†³äºè¾“å…¥æ–‡æœ¬æè¿°çš„æ˜¯ç‹—çš„å“ç§è¿˜æ˜¯çŒ«çš„å“ç§ã€‚

![ptml 0335](img/ptml_0335.png)

###### Figure 3-35\. CLIP å¯¹æ–‡æœ¬çš„æ˜¾è‘—æ€§åˆ†æï¼Œæ˜¾ç¤ºäº†å¯¹å•è¯â€œå®‡èˆªå‘˜â€æ›´é«˜çš„å½’å› ã€‚

![ptml 0336](img/ptml_0336.png)

###### Figure 3-36\. CLIP å¯¹è¾“å…¥å›¾åƒçš„æ˜¾è‘—æ€§åˆ†æå¼ºè°ƒäº†å®‡èˆªå‘˜çš„é¢éƒ¨ï¼Œæ¥ç€æ˜¯ä¸€ç³»åˆ—ç±»ä¼¼çš„æ–‡æœ¬/å›¾åƒæ˜¾è‘—æ€§åˆ†æå¯¹ï¼Œå¼ºè°ƒäº†å›¾ç‰‡ä¸­çš„å›½æ——ï¼Œç„¶åæ˜¯å®‡èˆªæœã€‚

æ˜¾è‘—æ€§åœ°å›¾æœ‰åŠ›åœ°è¯æ˜äº† CLIP å¯ä»¥æ­£ç¡®è¯†åˆ«æ–‡æœ¬æè¿°çš„å›¾ç‰‡éƒ¨åˆ†ã€‚å³ä½¿ç›®æ ‡ç±»åˆ«åªå å›¾åƒçš„ä¸€å°éƒ¨åˆ†ï¼Œä¹Ÿæ˜¯å¦‚æ­¤ã€‚

å¯èƒ½ä¼šè®©äººæƒŠè®¶çš„æ˜¯ï¼ŒCLIP ä¸ä»…ä»æ–‡æœ¬ä¸­è¿›è¡Œäº†ç§¯æçš„å½’å› ï¼Œè€Œä¸”è¿˜ç»™è¿™ä¸ªå›¾åƒ-æ–‡æœ¬å¯¹åˆ†é…äº†å¾ˆé«˜çš„ç›¸ä¼¼æ€§åˆ†æ•°ï¼ˆè§å›¾ 3-37 å’Œ 3-38ï¼‰ã€‚

è€ƒè™‘ä»¥ä¸‹ä¾‹å­ï¼Œä¸€ä¸ªéšæœºé™æ€å›¾åƒä¸æ–‡æœ¬æè¿°é…å¯¹ã€‚

```
# Saliency map on text paired with noise
img_path = "clip_images/noise.png"
img = preprocess(Image.open(img_path)).unsqueeze(0).to(device)
texts = ["an image of a dog"]
text = clip.tokenize(texts).to(device)
logits_per_image, logits_per_text = model(img, text)
print(
    color.BOLD
    + color.PURPLE
    + color.UNDERLINE
    + f"CLIP similarity score: {logits_per_image.item()}"
    + color.END
)
R_text, R_image = interpret(model=model, image=img, texts=text, device=device)
batch_size = text.shape[0]
for i in range(batch_size):
    show_heatmap_on_text(texts[i], text[i], R_text[i])
    show_image_relevance(R_image[i], img, orig_image=Image.open(img_path))
    plt.show()
```

ä¸ä»… CLIP ä»æ–‡æœ¬ä¸­è¿›è¡Œäº†ç§¯æçš„å½’å› ï¼Œè€Œä¸”è¿˜ç»™è¿™ä¸ªå›¾åƒ-æ–‡æœ¬å¯¹åˆ†é…äº†å¾ˆé«˜çš„ç›¸ä¼¼æ€§åˆ†æ•°ï¼ˆè§å›¾ 3-37 å’Œ 3-38ï¼‰ã€‚

![ptml 0337](img/ptml_0337.png)

###### Figure 3-37\. CLIP å¯¹çœ‹ä¼¼æè¿°ç‹—çš„æ–‡æœ¬å’Œéšæœºå™ªå£°å›¾åƒä¹‹é—´çš„ç›¸ä¼¼æ€§åˆ†æ•°ã€‚

![ptml 0338](img/ptml_0338.png)

###### Figure 3-38\. CLIP å¯¹çœ‹èµ·æ¥ä¸ç‹—æ¯«ä¸ç›¸åƒçš„å™ªéŸ³çš„æ˜¾è‘—æ€§åˆ†æå›¾ã€‚

ä¸ºäº†æ¯”è¾ƒï¼Œè€ƒè™‘ä¸€å¼ æ›´æ¸…æ™°çš„ç‹—çš„è¾“å…¥å›¾åƒï¼ˆè§å›¾ 3-40ï¼‰ã€‚ç”±äºè¿™ç§ç›¸ä¼¼æ€§ï¼Œè¿™ä¸ªè¾“å…¥å›¾åƒå¾—åˆ°äº†éå¸¸é«˜çš„ CLIP ç›¸ä¼¼æ€§åˆ†æ•°ï¼ˆ`27.890625`ï¼‰ï¼ˆè§å›¾ 3-39ï¼‰ã€‚ä½†æ˜¯ï¼Œè¿™ä¸ª CLIP ç›¸ä¼¼æ€§åˆ†æ•°æ¯”æˆ‘ä»¬ä¹‹å‰è¾“å…¥çš„éšæœºå™ªå£°è¿˜è¦ä½ã€‚

![ptml 0339](img/ptml_0339.png)

###### å›¾ 3-39\. CLIP åœ¨äººç±»å¯ç†è§£çš„å“ˆå£«å¥‡å›¾åƒä¸Šçš„ç›¸ä¼¼æ€§åˆ†æ•°

èƒ½å¤Ÿçœ‹åˆ°å›¾Â 3-40 çš„ä»»ä½•äººéƒ½ä¼šåŒæ„è¿™æ˜¯ä¸€åªç‹—ï¼Œæ˜¾è‘—æ€§å›¾æ˜¾ç¤º CLIP ä¼¼ä¹é›†ä¸­åœ¨ç‹—çš„é¢éƒ¨å’Œå˜´å·´ä¸Šã€‚

![ptml 0340](img/ptml_0340.png)

###### å›¾ 3-40\. CLIP åœ¨äººç±»å¯ç†è§£çš„å“ˆå£«å¥‡å›¾åƒä¸Šçš„æ˜¾è‘—æ€§å›¾

è™½ç„¶å…³æ³¨ CLIP å¯èƒ½ä¼šè®©äººæ„Ÿåˆ°å›°æƒ‘ï¼Œä½†å¦‚æœä½ ä»”ç»†çœ‹å›¾Â 3-37ï¼ŒCLIP æ›´åŠ å…³æ³¨`image of`éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯äººç±»å¯è¯»éƒ¨åˆ†çš„ç‹—ã€‚è¿™å¼ å›¾ç‰‡çš„æŸäº›éƒ¨åˆ†ä¸ CLIP å¯¹`image of`çš„ç†è§£è¶³å¤Ÿç›¸å…³ï¼Œä»è€Œä½¿å…¶è·å¾—æ¯”ä¸ç‹—çœ‹ä¼¼å®Œç¾çš„æ–‡æœ¬åˆ°å›¾åƒåŒ¹é…æ›´é«˜çš„ CLIP ç›¸ä¼¼æ€§åˆ†æ•°ã€‚

è®°ä½ï¼Œè™½ç„¶å°†æ–‡æœ¬ä¸å›¾åƒå…³è”æ˜¯äººç±»èƒ½å¤Ÿå®Œæˆçš„ä»»åŠ¡ï¼Œä½† CLIP å¹¶ä¸ä»¥ä¸ç”Ÿç‰©å¤§è„‘ç›¸åŒçš„æ–¹å¼çœ‹å¾…ä¸–ç•Œã€‚

## å¯¹æŠ—åäº‹å®ä¾‹

æˆ‘ä»¬å»ºè®®æŸ¥çœ‹ç¬¬äº”ç« ä»¥è·å–æœ‰å…³å¯¹æŠ—æ ·æœ¬çš„æ›´å¤šä¿¡æ¯ï¼Œä½†æˆ‘ä»¬å°†åœ¨è¿™é‡Œç®€è¦ä»‹ç»ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ã€‚

*åäº‹å®è§£é‡Š*ï¼ˆä¹Ÿç§°ä¸º*å¯¹æ¯”è§£é‡Š*ï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„æ–¹æ³•ã€‚åäº‹å®èƒŒåçš„æƒ³æ³•æ˜¯æå‡ºæ•°æ®å®ä¾‹çš„ä¿®æ”¹ç‰ˆæœ¬ï¼Œå¯¼è‡´ä¸åŒçš„é¢„æµ‹ç»“æœã€‚é€šå¸¸ï¼Œåäº‹å®æ˜¯æ”¹å˜æ¨¡å‹è¾“å‡ºåˆ°å¦ä¸€ä¸ªï¼ˆé¢„å®šä¹‰ï¼‰è¾“å‡ºçš„æœ€å°è¾“å…¥ç‰¹å¾ã€‚

åäº‹å®é¦–æ¬¡å‡ºç°åœ¨ 20 ä¸–çºª 70 å¹´ä»£çš„å¿ƒç†å­¦é¢†åŸŸã€‚Â¹â· â€œä¸æ‰“å¼€é»‘ç›’çš„åäº‹å®è§£é‡Šâ€ä¸€æ–‡ä»‹ç»äº†åœ¨æœºå™¨å­¦ä¹ ä¸­ä½¿ç”¨å®ƒä»¬çš„æ¦‚å¿µã€‚Â¹â¸

å¯¹æŠ—æ€§ç¤ºä¾‹æ˜¯æŒ‡å…·æœ‰å°çš„ã€æœ‰æ„çš„ç‰¹å¾æ‰°åŠ¨çš„å®ä¾‹ï¼Œè¿™äº›æ‰°åŠ¨ä¼šå¯¼è‡´æœºå™¨å­¦ä¹ æ¨¡å‹åšå‡ºé”™è¯¯çš„é¢„æµ‹ã€‚åœ¨å¯è§£é‡Šæ€§å’Œè§£é‡Šæ€§æ–¹é¢ï¼Œå¯¹æŠ—æ€§ç¤ºä¾‹å¯ä»¥èµ·åˆ°ä¸åäº‹å®è§£é‡Šç±»ä¼¼çš„ä½œç”¨ã€‚äº‹å®ä¸Šï¼Œç”Ÿæˆä¸¤è€…çš„è¿‡ç¨‹éå¸¸ç›¸ä¼¼ã€‚

åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œæ‚¨éƒ½å¸Œæœ›æ‰¾åˆ°ä¸€ä¸ªå¯¹æŠ—æ€§ä¾‹å­ï¼Œå³ä¸€ä¸ªä¼˜åŒ–é—®é¢˜ä¸­çš„å°å‹å¯¹æŠ—æ€§ç‰¹å¾æ‰°åŠ¨ï¼š

<math alttext="argmin Underscript x prime Endscripts d left-parenthesis x comma x prime right-parenthesis" display="block"><mrow><munder><mrow><mtext>argmin</mtext></mrow> <msup><mi>x</mi> <mo>'</mo></msup></munder> <mi>d</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <msup><mi>x</mi> <mo>'</mo></msup> <mo>)</mo></mrow></mrow></math>

åœ¨è¿™é‡Œï¼Œå°†<math alttext="x prime"><mrow><mi>x</mi> <mi>Ã¢</mi> <mi>Â€</mi> <mi>Â™</mi></mrow></math>è¾“å…¥åˆ°æ‚¨çš„æ¨¡å‹ï¼ˆ<math alttext="f left-parenthesis x prime right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <msup><mi>x</mi> <mo>'</mo></msup> <mo>)</mo></mrow></math>ï¼‰å°†å¯¼è‡´é¢„å®šä¹‰çš„è¾“å‡º<math alttext="c"><mi>c</mi></math>ã€‚åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œå½“æ‚¨è§£é‡Šä¸€ä¸ªæ¨¡å‹ï¼ˆåäº‹å®ï¼‰æˆ–æ”»å‡»ä¸€ä¸ªæ¨¡å‹ï¼ˆå¯¹æŠ—æ€§æ ·æœ¬ï¼‰æ—¶ï¼Œæ‚¨éƒ½å¸Œæœ›æœ€å°åŒ–å¯¹è¾“å…¥æ•°æ®çš„æ›´æ”¹ã€‚

ä½†é™¤äº†è¿™ç§ä¸€èˆ¬çš„æ•°å­¦å½¢å¼ä¹‹å¤–ï¼Œä½ å¦‚ä½•å®é™…è®¡ç®—å¯¹æŠ—æ ·æœ¬å‘¢ï¼Ÿè¿™ç§æ–¹æ³•å–å†³äºä½ æ˜¯å¦èƒ½è®¿é—®æ¨¡å‹çš„å†…éƒ¨ï¼ˆç™½ç›’æ–¹æ³•ï¼‰æˆ–ä¸èƒ½ï¼ˆé»‘ç›’æ–¹æ³•ï¼‰ã€‚

# å…‹æœå¯è§£é‡Šæ€§çš„å±€é™æ€§éœ€è¦å®‰å…¨æ„è¯†ã€‚

æˆ‘ä»¬å·²ç»è®¨è®ºäº†è®¸å¤šåŒ…å¹¶æŒ‡å‡ºäº†è§£é‡Šæ€§ä½œä¸ºä¸€ä¸ªé¢†åŸŸçš„å±€é™æ€§ã€‚é‚£ä¹ˆï¼Œå¦‚æœè¿™äº›å·¥å…·æ˜¾ç„¶å‘Šè¯‰æˆ‘ä»¬å¦‚æ­¤å°‘ï¼Œæˆ‘ä»¬åº”è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿæœ€ç»ˆï¼Œä½ å¯èƒ½æ°¸è¿œæ— æ³•ç†è§£è¶³å¤Ÿå¤æ‚æ¨¡å‹çš„æ¯ä¸€ä¸ªæ–¹é¢ã€‚ä¸‹ä¸€æ­¥æœ€å¥½çš„æ–¹æ³•æ˜¯å…·å¤‡â€œå®‰å…¨æ„è¯†â€ï¼Œä»¥å…‹æœå¯è§£é‡Šæ€§çš„å±€é™æ€§ã€‚

ä»€ä¹ˆæ˜¯å®‰å…¨æ„è¯†ï¼Ÿè¿™æ˜¯å‘ç°ç¨‹åºã€ç³»ç»Ÿé›†æˆã€ç»„ç»‡ç”šè‡³ä¸ªäººæˆ–ä¸€ç¾¤äººçš„å®Œæ•´æ€§ä¸­æ½œåœ¨æˆ–å®é™…ç¼ºé™·çš„èƒ½åŠ›ã€‚æ”»å‡»è€…å¯èƒ½ä¼šé‡‡ç”¨å®‰å…¨æ„è¯†æ¥åˆ©ç”¨å¼±ç‚¹ï¼Œè€Œå®‰å…¨ä»ä¸šè€…å¯èƒ½ä¼šé‡‡ç”¨å®ƒæ¥æ›´å¥½åœ°ä¿å«ç³»ç»Ÿå¹¶ä¿®è¡¥è¿™äº›å¼±ç‚¹ã€‚ä¸ªäººå¯ä»¥å­¦ä¼šå…·å¤‡å®‰å…¨æ„è¯†ã€‚å®‰å…¨æ„è¯†å¯ä»¥å­˜åœ¨äºç›´è§‰ä¸­ã€‚å®ƒç”šè‡³å¯ä»¥ä½œä¸ºå®‰å…¨æ„è¯†çš„æ–‡åŒ–å‡ºç°ï¼Œç”±å®‰å…¨æ„è¯†ç»„ç»‡çš„æŒ‡å¯¼æ–¹é’ˆå’Œç¨‹åºå¼•å‘ã€‚åœ¨æœºå™¨å­¦ä¹ çš„èƒŒæ™¯ä¸‹ï¼Œå®ƒæ˜¯æŒ‘æˆ˜æ¨¡å‹è¡Œä¸ºå’Œ/æˆ–å®‰å…¨æ€§å‡è®¾çš„èƒ½åŠ›ã€‚

ä¾‹å¦‚ï¼Œåœ¨ä¹‹å‰çš„æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸¾äº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œåˆ†ç±»ç­‰ä»»åŠ¡çš„ä¾‹å­ã€‚è¿™ä¼¼ä¹æ˜¯ä¸€ä¸ªç›´æ¥çš„ä»»åŠ¡ï¼Œç›´åˆ°ä½ å¼€å§‹è´¨ç–‘è®¾ç½®èƒŒåçš„å‡è®¾ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨æŠ½è±¡æ ‡ç­¾åƒ`A`å’Œ`B`è€Œä¸æ˜¯åƒ`POSITIVE`å’Œ`NEGATIVE`è¿™æ ·çš„å…·ä½“æ ‡ç­¾ä¼šæ€ä¹ˆæ ·ï¼Ÿå¦‚æœæˆ‘ä»¬ä½¿ç”¨å®Œæ•´çš„å•è¯ï¼Œæ‹¼å†™æˆ–å¤§å†™å­—æ¯æ˜¯å¦é‡è¦ï¼Ÿ[è‡³å°‘åœ¨ä¸€ä¸ªæ¡ˆä¾‹ä¸­](https://oreil.ly/ItNoi)ï¼Œç ”ç©¶äººå‘˜ä»…ä»…å°†è¾“å‡ºæ ‡ç­¾â€œpositiveâ€æ”¹ä¸ºâ€œPositiveâ€ï¼Œä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ SST è¯„ä¼°åŸºå‡†ä¸Šçš„æ€§èƒ½ä» 53%æå‡åˆ°äº† 69%ã€‚åœ¨[æƒ…æ„Ÿåˆ†æå’Œ COVID æµ‹è¯•](https://oreil.ly/CtCYu)çš„æƒ…å†µä¸‹ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒCOVID æµ‹è¯•ä¸ºé˜´æ€§åº”è¢«è§†ä¸ºä¸€ä»¶å¥½äº‹ï¼‰ï¼Œæ ‡ç­¾â€œpositiveâ€å’Œâ€œnegativeâ€èƒŒåçš„å«ä¹‰å‘ç”Ÿäº†å˜åŒ–ã€‚

â€œå®‰å…¨æ„è¯†â€çš„ä¸€éƒ¨åˆ†ä¹Ÿæ„å‘³ç€è¦è®¤è¯†åˆ°å°†ä½ çš„ AI ç³»ç»Ÿæ‹ŸäººåŒ–æ˜¯æå…¶å±é™©çš„ã€‚è€ƒè™‘ä¸€ä¸ªä¸è°·æ­Œçš„ LaMDA å¯¹è¯æ¨¡å‹å¼€å§‹å¯¹è¯ã€å¾—å‡ºå…¶æœ‰æ„è¯†çš„ç»“è®ºçš„è°·æ­Œå·¥ç¨‹å¸ˆçš„æ¡ˆä¾‹ï¼Œå¹¶å› æ­¤åœ¨å…¬å¸å†…æ€èµ·è½©ç„¶å¤§æ³¢å¹¶è¢«åœèŒçš„æƒ…å†µã€‚å¦‚æœæœ‰äººé˜…è¯»è¿™æ®µå…¬å¼€å¯ç”¨çš„å¯¹è¯ç‰‡æ®µï¼Œå¯èƒ½ä¼šå¾—å‡ºè¿™æ˜¯ä¸¤ä¸ªäººä¹‹é—´çš„å¯¹è¯çš„ç»“è®ºã€‚ç„¶è€Œï¼Œä»å¯¹è¯ä¸­ç¼ºå°‘ä¸¤ä»¶äº‹æƒ…ï¼š

+   ç›¸å…³å·¥ç¨‹å¸ˆç§¯ææ€€ç–‘èŠå¤©æœºå™¨äººçš„æ™ºèƒ½æ€§å¹¶çœ‹åˆ°ç»“æœ

+   æ‰€æœ‰å…¶ä»–å¯èƒ½ä¸é‚£ä¹ˆè¿è´¯çš„å¯¹è¯

åè€…æ„å‘³ç€è¿™äº›å£°ç§°æœ‰çŸ¥è§‰èƒ½åŠ›èƒŒåå­˜åœ¨é€‰æ‹©åå·®ã€‚è‡³äºå‰è€…ï¼Œåœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹æ—¶è€ƒè™‘å¯¹äº‹å®çš„åäº‹å®æ˜¯è‡³å…³é‡è¦çš„ã€‚æ¯•ç«Ÿï¼ŒèŠå¤©æœºå™¨äººæ˜¯ä¸€ä¸ª Transformer æ¨¡å‹ï¼Œå¾ˆå¯èƒ½æ˜¯åœ¨èŠå¤©å®¤ä¸­çš„äººç±»æŸ¥è¯¢å’Œå“åº”æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚è¿™ç§è®­ç»ƒçš„ä¸»è¦ç›®çš„æ˜¯æ ¹æ®æŸ¥è¯¢é¢„æµ‹æœ€å¯èƒ½çš„é€‚å½“è¾“å‡ºå“åº”ã€‚å› æ­¤ï¼ŒèŠå¤©æœºå™¨äººâ€œæœ‰çŸ¥è§‰â€çš„è¯æ®ä¸ä¸€ä¸ªé¢„æµ‹ä¸‹ä¸€ä¸ªå¯èƒ½å¥å­çš„èŠå¤©å®¤ç§‘å¹»æ•…äº‹ä¸­çš„èªæ˜ AI å‡ ä¹æ˜¯ä¸€æ ·çš„ã€‚äº‹å®ä¸Šï¼Œè¿›ä¸€æ­¥çš„ç ”ç©¶è¡¨æ˜ï¼Œå¤§å¤šæ•°äººè®¤ä¸ºèŠå¤©æœºå™¨äººå“åº”ä¸­çš„â€œç±»äººâ€ç‰¹å¾é€šå¸¸ä»…ä»…æ˜¯ç¬¬ä¸€äººç§°çš„ä½¿ç”¨ã€‚Â¹â¹

# å¯è§£é‡Šæ€§å’Œè§£é‡Šæ€§æ–¹æ³•çš„å±€é™æ€§å’Œç¼ºé™·

åœ¨æ·±å…¥ç ”ç©¶è§£é‡Šå’Œè¯´æ˜æ¨¡å‹çš„ç¡®åˆ‡æ–¹æ³•ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆçœ‹çœ‹è¿™äº›æ–¹æ³•çš„ä¸€äº›ç¼ºé™·ã€‚

é¦–å…ˆï¼Œå¦‚æœæ‚¨éœ€è¦åšå‡ºé«˜é£é™©çš„å†³ç­–ï¼Œè¯·ç¡®ä¿ä½¿ç”¨æœ¬è´¨ä¸Šå¯è§£é‡Šçš„æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹ä¾‹å¦‚å†³ç­–æ ‘æ›´å®¹æ˜“è½¬æ¢ä¸ºè¾“å‡ºè§£é‡Šï¼ˆè¯¦è§â€œå†³ç­–æ ‘â€ï¼‰ã€‚

åœ¨é€‰æ‹©æ–¹æ³•ä¹‹å‰ï¼Œæ‚¨éœ€è¦éå¸¸æ¸…æ¥šæ‚¨å¸Œæœ›ä»ä¸­å¾—åˆ°ä»€ä¹ˆã€‚æ‚¨æ˜¯æƒ³ç†è§£æ•°æ®é‡‡è´­è¿‡ç¨‹çš„æœ¬è´¨å—ï¼Ÿå†³ç­–æ˜¯å¦‚ä½•åšå‡ºçš„ï¼Ÿæ¨¡å‹åœ¨åŸºæœ¬å±‚é¢ä¸Šæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿæœ‰äº›å·¥å…·å¯èƒ½å¯¹å…¶ä¸­æŸäº›ç›®æ ‡é€‚åˆï¼Œä½†å¯¹å…¶ä»–ç›®æ ‡åˆ™ä¸é€‚åˆã€‚

å¦‚æœæ‚¨çš„ç›®æ ‡æ˜¯ç†è§£æ•°æ®ç”Ÿæˆè¿‡ç¨‹ï¼Œé‚£ä¹ˆåªæœ‰åœ¨æ‚¨çŸ¥é“æ‚¨çš„æ¨¡å‹å·²ç»å¾ˆå¥½åœ°æ³›åŒ–åˆ°æœªè§æ•°æ®æ—¶æ‰å¯èƒ½å®ç°ã€‚

å†³ç­–çš„å¯è§£é‡Šæ€§å¯èƒ½ä¼šè¯¯å¯¼ã€‚å®ƒçªå‡ºæ˜¾ç¤ºè¯¸å¦‚ç›¸å…³æ€§ä¹‹ç±»çš„äº‹ç‰©ï¼Œä½†å¹¶ä¸æ·±å…¥åˆ°å› æœæ¨æ–­æ‰€æ¶‰åŠçš„è¯¦ç»†å±‚æ¬¡ï¼ˆè§ç¬¬ä¸ƒç« ï¼‰ã€‚è¯·è®°ä½ï¼Œç›¸å…³æ€§å¹¶ä¸æ€»æ˜¯æ„å‘³ç€å› æœå…³ç³»ã€‚

###### è­¦å‘Š

è™šå‡çš„ç›¸å…³æ€§å¯èƒ½ä¼šå¯¼è‡´å³ä½¿ä½¿ç”¨å…ˆè¿›çš„å¯è§£é‡Šæ€§æ–¹æ³•å¦‚æ˜¾è‘—æ€§æ–¹æ³•å’ŒåŸºäºæ³¨æ„åŠ›çš„æ–¹æ³•ä¹Ÿä¼šå‡ºç°ä¸å‡†ç¡®çš„è§£é‡Šã€‚

è¯¸å¦‚ç‰¹å¾é‡è¦æ€§ä¹‹ç±»çš„å·¥å…·é€šå¸¸ä¼šä¼°è®¡å¹³å‡å€¼ï¼Œä½†æ˜¯åº”æ³¨æ„è¿™äº›å¹³å‡å€¼çš„è¯¯å·®èŒƒå›´ï¼Œå¹¶è€ƒè™‘ç½®ä¿¡åŒºé—´ã€‚

å¾ˆå¤šæœºå™¨å­¦ä¹ æ¶‰åŠå¤„ç†æé«˜ç»´åº¦çš„ç©ºé—´ã€‚é«˜ç»´åº¦çš„æ•°æ®å’Œç‰¹å¾ç©ºé—´è¦æƒ³åœ¨æœªè¿›è¡Œæ•°æ®æˆ–ç‰¹å¾åˆ†ç»„çš„æƒ…å†µä¸‹ç†è§£æ˜¯å›°éš¾çš„ã€‚

å³ä½¿æ‚¨åœ¨è¿™äº›çŸ©é˜µä¸­æ‰¾åˆ°äº†é‡è¦çš„ç‰¹å¾ï¼Œä¹Ÿè¯·è®°ä½è¿™å¹¶ä¸æ„å‘³ç€å› æœå…³ç³»ï¼ˆæˆ‘ä»¬ä¹‹å‰å·²ç»è¯´è¿‡è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†å†æ¬¡è¯´ä¸€éï¼‰ã€‚

# [è¯¯å¯¼æ€§å¯è§£é‡Šæ€§çš„é£é™©](https://wiki.example.org/deceptive_interpretability_risks)

å³ä½¿æ‚¨ä¸å°†æ¨¡å‹æˆ– ML æµæ°´çº¿æ‹ŸäººåŒ–ï¼Œæ‚¨ä¹Ÿåº”å§‹ç»ˆè­¦æƒ•å¯¹å¯è§£é‡Šæ€§æˆ–è§£é‡Šæ€§æ–¹æ³•çš„ 100%ä¿¡ä»»ã€‚

åœ¨ AI å®‰å…¨é¢†åŸŸçš„ä¸€ä¸ªé‡å¤§å…³æ³¨ç‚¹æ˜¯â€œæ¬ºéª—æ€§ä¸å¯¹é½çš„ Mesa-ä¼˜åŒ–å™¨â€ï¼Œç›´åˆ°æœ€è¿‘æ‰æˆä¸ºä¸€ä¸ªå‡è®¾æƒ…æ™¯ã€‚ç®€è€Œè¨€ä¹‹ï¼Œä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹åœ¨ä¸€ä¸ªç¯å¢ƒä¸­è®­ç»ƒï¼Œå¸Œæœ›å®ƒåœ¨ç°å®ä¸–ç•Œä¸­è¡¨ç°ç›¸ä¼¼ã€‚ä¸ºäº†ç¡®ä¿å…¶åœ¨æµ‹è¯•ç¯å¢ƒä¸­çš„å¯¹é½æ€§ä¸å…¶åœ¨å¤–éƒ¨ä¸–ç•Œä¸­çš„å¯¹é½æ€§ç›¸åŒï¼Œå…¶åˆ›å»ºè€…ä»¬é‡‡ç”¨äº†è§£é‡Šæ€§æ–¹æ³•ã€‚ç„¶è€Œï¼Œäº‹å®è¯æ˜ï¼Œè§£é‡Šæ€§æ–¹æ³•æœ¬èº«å‘äººç±»å·¥ç¨‹å¸ˆå±•ç¤ºäº†ä¸€ç§æ¨¡å¼ï¼Œè€Œåœ¨ç°å®ä¸–ç•Œä¸­å´å¯¹åº”ç€ä¸€ç§ä¸å¸Œæœ›çš„è¡Œä¸ºã€‚è¿™æ˜¯è¿‡å»ç»å¸¸ä¸è¿œæœŸ AGI æ¥ç®¡è®¨è®ºåœ¨ä¸€èµ·çš„æƒ…æ™¯ä¹‹ä¸€ï¼Œç›´åˆ°å®ƒåœ¨ç°å®ç”Ÿæ´»ä¸­å¾—åˆ°è¯æ˜ã€‚Â²Â¹

è™½ç„¶åœ¨æœ¬ç« ä¸­æˆ‘ä»¬ä¸»è¦é¿å…äº†å¼ºåŒ–å­¦ä¹ çš„è¯é¢˜ï¼Œä½†æˆ‘ä»¬ä¹‹å‰æè¿°çš„è®¸å¤šè®¡ç®—æœºè§†è§‰è§£é‡Šå·¥å…·åœ¨è¿™é‡ŒåŒæ ·é€‚ç”¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œã€Šæ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­çš„ç›®æ ‡è¯¯æ¦‚åŒ–ã€‹çš„ä½œè€…ä»¬æ‹¥æœ‰ä¸€ä¸ªéå¸¸ç®€å•çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒç§°ä¸º CoinRunã€‚ç®€è€Œè¨€ä¹‹ï¼Œä»–ä»¬å±•ç¤ºäº†ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ä»£ç†äººï¼Œçœ‹ä¼¼æœ‰éå¸¸æ˜ç¡®çš„ç›®æ ‡ï¼ˆå³åˆ°è¾¾å…³å¡æœ«å°¾çš„ç¡¬å¸ï¼‰ã€‚ç„¶è€Œï¼Œå½“ç½®äºä¸åŒçš„ç¯å¢ƒä¸­æ—¶ï¼Œå®ƒå®é™…ä¸Šåªæ˜¯åˆ°è¾¾äº†å…³å¡çš„æœ«å°¾ã€‚æ˜¾ç„¶ï¼Œè¿™æ¯”å°†è¯¥æ¨¡å‹æ”¾å…¥è‡ªåŠ¨é©¾é©¶æ±½è½¦ä¸­è¦ä½é£é™©å¾—å¤šï¼Œä½†è¿™ä»ç„¶åº”è¯¥æé†’æ‚¨æ£€æŸ¥æœ‰å…³è§£é‡Šæ€§æ–¹æ³•çš„æ‰€æœ‰å‡è®¾ã€‚

å¦‚æœæ‚¨çœŸçš„æƒ³è¦ä¸€ä¸ªæ€è€ƒè¯„ä¼°ä¸­çš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ¡†æ¶ï¼Œæœ€å¥½å°†å…¶è§†ä¸ºä¸€ç§è§’è‰²æ‰®æ¼”è€…ï¼ŒæŒ‰ç…§äººç±»æŒ‡å®šçš„è§’è‰²è¡Œäº‹ï¼Œæ²¡æœ‰çœŸæ­£ä½“éªŒåˆ°ç°å®ä¸–ç•Œçš„ç»å†ï¼›æœ€ç³Ÿç³•çš„æƒ…å†µæ˜¯ï¼Œå®ƒæ˜¯ä¸€ä¸ªå…³æ³¨å®ç°å…¶æŒ‡å®šç›®æ ‡å‡½æ•°çš„ç¤¾ä¼šç—…æ€ï¼Œè€Œä¸ç®¡è¿™ä¸ªç›®æ ‡ä¸å…¶å‘¨å›´çš„äººç±»çš„æƒ³æ³•å’Œéœ€æ±‚æœ‰å¤šå¤§å†²çªã€‚

å½“ç„¶ï¼Œå³ä½¿æ‚¨éå¸¸æ³¨æ„æ¨¡å‹çš„æ¯ä¸€ä¸ªå‚æ•°ï¼Œä»…ä»…çœ‹æ¨¡å‹æœ¬èº«æ˜¯ä¸å¤Ÿçš„ã€‚åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨è·å–è®­ç»ƒæ•°æ®çš„å„ç§é™·é˜±ï¼Œè¿™äº›æ•°æ®å†³å®šäº†æ‚¨çš„æœºå™¨å­¦ä¹ æ¨¡å‹æˆ–æµç¨‹å¯¹ä¸–ç•Œçš„è¡¨ç¤ºã€‚

# ç»“è®º

åœ¨æœ¬ç« ä¸­ï¼Œæ‚¨äº†è§£äº†å¸®åŠ©è§£é‡Šæœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹çš„å·¥å…·å’ŒæŠ€æœ¯ã€‚ä¸ºæ­¤ï¼Œæ‚¨éœ€è¦é€‰æ‹©é€‚å½“çš„è§£é‡ŠæŠ€æœ¯ï¼ˆä¾‹å¦‚å…¨å±€æˆ–å±€éƒ¨ï¼›å›ºæœ‰å¯è§£é‡Šæ¨¡å‹æˆ–äº‹åè§£é‡Šï¼‰ï¼Œè€ƒè™‘ä¸ä¿¡ä»»çš„å…¶ä»–æ–¹é¢ï¼ˆå¦‚éšç§ï¼‰çš„å¯èƒ½äº¤äº’ä½œç”¨ï¼Œå¹¶æ³¨æ„è¿™äº›æ–¹æ³•çš„é™åˆ¶ã€‚

Â¹ Tim Millerï¼Œã€Šäººå·¥æ™ºèƒ½ä¸­çš„è§£é‡Šï¼šç¤¾ä¼šç§‘å­¦çš„å¯ç¤ºã€‹ï¼Œ*äººå·¥æ™ºèƒ½* 267ï¼ˆ2019ï¼‰ï¼š1â€“38ã€‚

Â² Been Kim ç­‰äººçš„æ–‡ç« [â€œä¾‹å­ä¸è¶³ä»¥ï¼Œå­¦ä¼šæ‰¹åˆ¤ï¼å¯è§£é‡Šæ€§çš„æ‰¹è¯„â€](https://oreil.ly/deDPo)ï¼Œã€Šç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•ã€‹ç¬¬ 29 å·ï¼ˆ2016 å¹´ï¼‰ã€‚

Â³ è¯¦è§è¿™ç¯‡å…³äº[XAI è¯„ä¼°](https://arxiv.org/abs/2201.08164)çš„ç»¼è¿°è®ºæ–‡å’Œ[ç›¸å…³ç½‘ç«™](https://oreil.ly/FQSZe)ï¼Œæä¾›äº† XAI è®ºæ–‡çš„ç²¾é€‰åˆ†ç±»ã€‚

â´ Dr. Matt Turek çš„æ–‡ç« [â€œå¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰â€](https://oreil.ly/6wkHq)ï¼Œå‘è¡¨äºå›½é˜²é«˜çº§ç ”ç©¶è®¡åˆ’å±€ï¼ˆDARPAï¼‰ï¼Œ2016 å¹´ã€‚

âµ Finale Doshi-Velez å’Œ Been Kim çš„æ–‡ç« [â€œèµ°å‘å¯è§£é‡Šæœºå™¨å­¦ä¹ çš„ä¸¥æ ¼ç§‘å­¦â€](https://arxiv.org/abs/1702.08608)ï¼ŒarXiv é¢„å°æœ¬ï¼ˆ2017 å¹´ï¼‰ã€‚

â¶ Nirmal Sobha Kartha ç­‰äººçš„æ–‡ç« [â€œä¸ºä»€ä¹ˆä½ å¦‚æ­¤å¥‡æ€ªï¼Ÿæ³¨å…¥å­¤ç«‹æ£®æ—çš„å¯è§£é‡Šæ€§ç”¨äºå¼‚å¸¸æ£€æµ‹â€](https://arxiv.org/abs/2112.06858)ï¼ŒarXiv é¢„å°æœ¬ï¼ˆ2021 å¹´ï¼‰ã€‚

â· Doshi-Velez å’Œ Kim çš„æ–‡ç« [â€œèµ°å‘å¯è§£é‡Šæœºå™¨å­¦ä¹ çš„ä¸¥æ ¼ç§‘å­¦â€]ã€‚

â¸ *çº½çº¦æ—¶æŠ¥* è¯„ä»·[GPT-3 çš„å†™ä½œåŸåˆ›æ€§](https://oreil.ly/l5Xdm)è¾¾åˆ°äº†ä¸äººç±»æ°´å¹³ç›¸åª²ç¾çš„æµç•…ç¨‹åº¦ã€‚

â¹ æ­¤å¤–ï¼Œ[Microsoft åœ¨ 2020 å¹´ 9 æœˆ 22 æ—¥å®£å¸ƒ](https://oreil.ly/gjCEN)ï¼Œå·²ç»è·å¾—äº† GPT-3 åŸºç¡€æ¨¡å‹çš„â€œç‹¬å®¶â€ä½¿ç”¨è®¸å¯ã€‚

Â¹â° nostalgebraist çš„æ–‡ç« [â€œè§£è¯» GPTï¼šå¯¹æ•°å‡ ç‡é€é•œâ€](https://oreil.ly/rZtju)ï¼Œ*LessWrong*ï¼ˆåšå®¢ï¼‰ï¼Œ2020 å¹´ 8 æœˆ 30 æ—¥ã€‚

Â¹Â¹ å¦‚æœä½ å¸Œæœ›æ›´æ·±å…¥ã€æ›´ç›´è§‚åœ°äº†è§£çº¿æ€§å›å½’ï¼Œè¯·æŸ¥çœ‹[MLU Explain çš„æ–‡ç« ](https://oreil.ly/dEfCL)ã€‚

Â¹Â² Yin Lou ç­‰äººçš„æ–‡ç« [â€œå…·æœ‰æˆå¯¹äº¤äº’çš„å‡†ç¡®å¯ç†è§£æ¨¡å‹â€](https://dl.acm.org/doi/abs/10.1145/2487575.2487579)ï¼Œå‘è¡¨äºç¬¬ 19 å±Š ACM SIGKDD å›½é™…æ•°æ®æŒ–æ˜ä¸çŸ¥è¯†å‘ç°ä¼šè®®ï¼ˆ2013 å¹´ï¼‰ï¼š623â€“31ã€‚

Â¹Â³ Jerome H. Friedman å’Œ Bogdan E. Popescu çš„æ–‡ç« [â€œé€šè¿‡è§„åˆ™é›†çš„é¢„æµ‹å­¦ä¹ â€](https://arxiv.org/abs/0811.1679)ï¼Œå‘è¡¨äºã€Šåº”ç”¨ç»Ÿè®¡å¹´åˆŠã€‹ç¬¬ 2 å·ç¬¬ 3 æœŸï¼ˆ2008 å¹´ï¼‰ï¼š916â€“54ã€‚

Â¹â´ åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œâ€œé›¶æ ·æœ¬å­¦ä¹ â€æŒ‡çš„æ˜¯æ¨¡å‹èƒ½å¤Ÿæ‰§è¡Œå…¶ä»¥å‰æœªç»è®­ç»ƒçš„ä»»åŠ¡ã€‚

Â¹âµ Kim ç­‰äººçš„æ–‡ç« [â€œä¾‹å­ä¸è¶³ä»¥ï¼Œå­¦ä¼šæ‰¹åˆ¤ï¼å¯è§£é‡Šæ€§çš„æ‰¹è¯„â€]ã€‚

Â¹â¶ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ ImageNet çš„åƒç´ å‡å€¼å’Œæ ‡å‡†å·®ã€‚è¿™å¯¹è®¸å¤šå¤„ç†æ‘„å½±è¾“å…¥çš„ä»»åŠ¡æ¥è¯´å¾ˆæ™®éã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šé¢†åŸŸï¼Œç›´æ¥è®¡ç®—ä½ ç‰¹å®šæ•°æ®é›†çš„å‡å€¼å’Œæ ‡å‡†å·®ä¹Ÿæ˜¯å€¼å¾—çš„ã€‚

Â¹â· David K. Lewisï¼Œã€Šåäº‹å®ã€‹ï¼Œï¼ˆå‰‘æ¡¥ï¼šå“ˆä½›å¤§å­¦å‡ºç‰ˆç¤¾ï¼Œ1973 å¹´ï¼‰ã€‚

Â¹â¸ Sandra Wachter ç­‰ï¼Œã€Šä¸æ‰“å¼€é»‘åŒ£å­çš„åäº‹å®è§£é‡Šã€‹ï¼Œ*å“ˆä½›æ³•å¾‹ä¸æŠ€æœ¯æ‚å¿—* 31 å·ï¼Œç¬¬ 2 æœŸï¼ˆ2017 å¹´æ˜¥å­£ï¼‰ã€‚

Â¹â¹ Maurice Jakesch ç­‰ï¼Œã€ŠAI ç”Ÿæˆè¯­è¨€çš„äººç±»å¯å‘å¼å­˜åœ¨ç¼ºé™·ã€‹ï¼Œ*arXiv é¢„å°æœ¬*ï¼ˆ2022 å¹´ï¼‰ã€‚

Â²â° Robert Milesï¼Œã€Šå¦ä¸€ä¸ª AI å¯¹é½é—®é¢˜ï¼šMesa ä¼˜åŒ–å™¨å’Œå†…éƒ¨å¯¹é½ã€‹ï¼Œè§†é¢‘ï¼Œ2021 å¹´ 2 æœˆ 16 æ—¥ï¼›Robert Milesï¼Œã€Šæ¬ºéª—æ€§ä¸å¯¹é½ Mesa ä¼˜åŒ–å™¨ï¼Ÿæ¯”ä½ æƒ³è±¡çš„æ›´æœ‰å¯èƒ½â€¦â€¦ã€‹ï¼Œè§†é¢‘ï¼Œ2021 å¹´ 5 æœˆ 23 æ—¥ã€‚

Â²Â¹ Robert Milesï¼Œã€Šæˆ‘ä»¬æ˜¯å¯¹çš„ï¼çœŸæ­£çš„å†…éƒ¨ä¸å¯¹é½ã€‹ï¼Œè§†é¢‘ï¼Œ2021 å¹´ 10 æœˆ 10 æ—¥ã€‚
