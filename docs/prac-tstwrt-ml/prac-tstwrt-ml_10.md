# 附录 B. 其他可解释性和解释性工具包

许多库在一个统一的框架下包含了可解释性和可解释性技术。其中一些难以分类的工具包括：

+   [Meta's HiPlot](https://oreil.ly/sc6o5)

+   [iModels](https://oreil.ly/SJtGJ)

+   [Omni 可解释 AI（OmniXAI）](https://oreil.ly/q5L4I)

# 可解释性或公平建模包

除了本章早期讨论的固有可解释性模型的一般类别外，以下是一些因其本质而可解释的模型工具：

+   贝叶斯案例模型（2014 年），可以从[Duke Interpretable ML Lab](https://oreil.ly/BnzXd)下载

+   [贝叶斯或与门（2017）](https://oreil.ly/ENecK)¹

+   [贝叶斯规则列表（BRL）](https://oreil.ly/vMzgG)

+   [可解释提升机器（EBM）/ GA2M](https://oreil.ly/wMKxi)

+   [Optimal Sparse Decision Trees](https://oreil.ly/J74Y7)²

+   [XGBoost Monotonic](https://oreil.ly/EuHRb)

+   [基于规则的表示学习器](https://oreil.ly/giZKb)³

+   [pySS3](https://oreil.ly/BQJNX)

+   [Risk-SLIM](https://oreil.ly/vwOLq)

+   [sklearn-expertsys](https://oreil.ly/rxlCA)

+   [skope-rules](https://oreil.ly/rAYpw)

+   [超稀疏线性整数模型（SLIMs）](https://oreil.ly/DK9uI)

+   [tensorflow/lattice](https://oreil.ly/rLCnQ)⁴

+   [“这看起来像那样”](https://oreil.ly/b6hhG)⁵

# 其他用于一般可解释性的 Python 包

还有更多用于解释模型和决策的通用工具：

+   [acd](https://oreil.ly/ttG1V)

+   [AI Fairness 360](https://oreil.ly/BRLBu)

+   [AI Explainability 360](https://oreil.ly/mgklQ)

+   [ALEPython](https://oreil.ly/K6AVe)

+   [Aletheia](https://oreil.ly/sX3UM)

+   [allennlp](https://oreil.ly/P48tS)

+   [Alibi](https://oreil.ly/F3vaH)

+   [anchor](https://oreil.ly/2m0VK)

+   [casme](https://oreil.ly/uCsyS)

+   [captum](https://oreil.ly/aB3Ec)

+   [checklist](https://oreil.ly/SHYDR)

+   [contextual-AI](https://oreil.ly/BhgxZ)

+   [对比解释（箔树）](https://oreil.ly/sKEpf)

+   [counterfit](https://oreil.ly/Qq1Hh)

+   [dalex](https://oreil.ly/a6WUT)

+   [DeepExplain](https://oreil.ly/YzwSC)⁶

+   [deeplift](https://oreil.ly/5wdJW)

+   [deepvis](https://oreil.ly/aYdSg)⁷

+   [DiCE](https://oreil.ly/6psFD)

+   [ecco](https://oreil.ly/3eLYy)

+   [eli5](https://oreil.ly/cJKz7)

+   [explainerdashboard](https://oreil.ly/6BhYa)

+   [foolbox](https://oreil.ly/VTuQe)

+   [Grad-CAM（GitHub 主题）](https://oreil.ly/C7v9W)

+   [gplearn](https://oreil.ly/L5XMH)

+   [hate-functional-tests](https://oreil.ly/adgLq)

+   [iNNvestigate 神经网络](https://oreil.ly/X2e23)

+   [Integrated-Gradients](https://oreil.ly/S1DsD)

+   [interpret](https://oreil.ly/TvbpB)

+   [interpret_with_rules](https://oreil.ly/W0Uwo)

+   [imodels](https://oreil.ly/U9t8K)

+   [Keras-vis](https://oreil.ly/qCesj)

+   [keract](https://oreil.ly/noOby)

+   [L2X](https://oreil.ly/MuGyI)

+   [lime](https://oreil.ly/ov991)

+   [lit](https://oreil.ly/wRA51)

+   [lofo-importance](https://oreil.ly/OvSxX)

+   [lrp_toolbox](https://oreil.ly/MH6Sf)

+   [MindsDB](https://oreil.ly/AcbYM)

+   [MLextend](https://oreil.ly/wqGFX)

+   [OptBinning](https://oreil.ly/4awhW)

+   [PDPbox](https://oreil.ly/IomoW)

+   [pyBreakDown](https://oreil.ly/gnYm6)

+   [PyCEbox](https://oreil.ly/S7oUd)

+   [pymc3](https://oreil.ly/cFFOd)

+   [pytorch-innvestigate](https://oreil.ly/nrY9x)

+   [rationale](https://oreil.ly/bYMVa)

+   [RISE](https://oreil.ly/boIn8)

+   [sage](https://oreil.ly/xMp3p)

+   [SALib](https://oreil.ly/ie6Ob)

+   [Skater](https://oreil.ly/sTZMV)

+   [tensorflow/cleverhans](https://oreil.ly/JLVJ7)

+   [tensorflow/lucid](https://oreil.ly/1F0i5)

+   [tensorflow/fairness-indicators](https://oreil.ly/iIo4x)

+   [tensorflow/model-analysis](https://oreil.ly/5exci):

+   [tensorflow/tcav](https://oreil.ly/Q5iAb)

+   [tensorfuzz](https://oreil.ly/8bCZo)

+   [TensorWatch](https://oreil.ly/oUGVb)

+   [TextFooler](https://oreil.ly/dZA6z)

+   [tf-explain](https://oreil.ly/sBtir)

+   [treeinterpreter](https://oreil.ly/AeULo)

+   [woe](https://oreil.ly/i0MQT)

+   [xai](https://oreil.ly/dtgKo)

+   [xdeep](https://oreil.ly/uz28K)

+   [yellowbrick](https://oreil.ly/N9r9e)

¹ Tong Wang 等人，《一种用于可解释分类学习规则集的贝叶斯框架》，[*机器学习研究杂志* 18 卷，第 1 期（2017 年）：2357–93](https://oreil.ly/98-8k)。

² Xiyang Hu 等人，《最佳稀疏决策树》，[*第 33 届神经信息处理系统（NeurIPS 2019）*，2019 年 4 月 29 日](https://arxiv.org/abs/1904.12847)。

³ Zhuo Wang 等人，《可扩展的基于规则的表示学习用于可解释分类》，[*NeurIPS 2021；可解释机器学习；神经符号人工智能*，2021 年 9 月 30 日](https://arxiv.org/abs/2109.15103)。

⁴ Maya Gupta 等人，《单调校准的插值查找表》，[*机器学习研究杂志* 17 卷，第 109 期（2016 年）](https://oreil.ly/W87tM)。

⁵ Chaofan Chen 等人，《这看起来像那个：用于可解释图像识别的深度学习》，[*神经信息处理系统进展（NeurIPS 2019）*，2018 年 6 月 27 日](https://arxiv.org/abs/1806.10574v5)。

⁶ Marco Ancona 等人，《朝着更好理解基于梯度的深度神经网络归因方法》，[*ICLR 2018 会议论文集*，2018 年 2 月 15 日](https://oreil.ly/lsg2s)。

⁷ Jason Yosinski 等人，《通过深度可视化理解神经网络》，[*第 31 届国际机器学习会议深度学习研讨会*，2015 年 6 月 26 日](https://oreil.ly/xDvhy)。
