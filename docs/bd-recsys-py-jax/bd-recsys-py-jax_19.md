# 第十五章 偏见在推荐系统中的体现

在本书中，我们花了很多时间剖析如何改进我们的推荐，使它们更个性化、更相关于单个用户。在这个过程中，你已经了解到用户和用户人物之间的潜在关系编码了关于共享偏好的重要信息。不幸的是，所有这些都有一个严重的缺点：偏见。

对于我们讨论的目的，我们将谈论推荐系统中两种最重要的偏见：

+   过于冗余或自相似的推荐集

+   AI 系统学到的刻板印象

首先，我们将深入探讨推荐输出中多样性的关键要素。尽管推荐系统为用户提供相关的选择至关重要，但确保各种推荐也是至关重要的。多样性不仅防止了过度专业化，还促进了新颖和意外的发现，丰富了整体用户体验。

相关性与多样性之间的平衡是微妙而棘手的。这种平衡挑战着算法不仅仅是简单地重复用户的过去行为，而且鼓励探索新的领域，希望提供更全面积极的内容体验。

这种偏见主要是一个技术挑战；我们如何满足多样化推荐和高度相关推荐的多重目标？

我们将把推荐系统中的内在和外在偏见视为潜在的但常常不经意的重要后果，这是由基础算法和它们所学习的数据引起的。数据收集或算法设计中的系统性偏见可能导致有偏见的输出，从而引发道德和公平性问题。此外，它们可能会形成闭环或过滤泡沫，限制用户接触更广泛范围的内容，无意中加强现有的信念。

在本章结束时，我们将讨论这些风险，并提供更多学习资源。我们不是 AI 公平性和偏见方面的专家，但所有机器学习从业者都应该了解并认真考虑这些话题。我们的目标是提供一个介绍和指引。

# 推荐多样化

我们对抗偏见的第一个投资是明确地在我们的推荐输出中针对更多的多样性。我们将简要介绍您可能追求的许多目标中的两个：列表内多样性和意外推荐。

*列表内多样性*试图确保在单个推荐列表中存在各种类型的项目。这个想法是尽量减少推荐项目之间的相似性，以减少过度专业化并鼓励探索。在一组推荐中的高列表内多样性增加了用户接触到许多他们可能喜欢的项目的机会；然而，对于任何特定的兴趣，推荐将会更浅，降低了召回率。

*意外推荐*对用户来说既惊喜又有趣。这些通常是用户可能独立发现或系统中普遍不太受欢迎的物品。通过注入非显而易见或意想不到的选择，即使这些选择与用户的亲和力得分相对较低，也可以在推荐过程中引入意外性，以提高整体的意外性。在理想情况下，这些意外选择相对于其流行度的其他物品具有较高的亲和力，因此它们是“外部选择中的精品”。

## 提高多样性

现在我们有了多样性的度量标准，我们可以明确地尝试去改善它们。重要的是，通过将多样性指标作为我们目标之一，我们可能会在诸如召回率或 NDCG 等方面牺牲性能。把这看作是一个帕累托问题或者在追求多样性时强加一个排名度量性能的下限可能是有用的。

###### 注意

在*帕累托问题*中，你经常需要权衡两个优先级。在许多机器学习领域，以及更普遍的应用数学中，某些结果存在自然的紧张关系。在推荐系统中，推荐多样性是帕累托问题的一个重要例子，但这并不是唯一的情况。在第十四章中，你简要了解了全局优化，这是权衡的一个极端案例。

改进多样性度量的一个简单方法是*重新排序*：这是一个后处理步骤，其中最初检索到的推荐列表被重新排序以增强多样性。各种重新排序算法不仅考虑相关性分数，还考虑推荐列表中物品之间的不相似性。重新排序是一种可以操作任何外部损失函数的策略，因此将其用于多样性是一个直接的方法。

另一种策略是打破我们在“推荐系统评估的倾向性加权”部分讨论的推荐反馈的封闭循环。就像多臂老虎机问题一样，*探索-利用的权衡*可以在选择利用模型知道用户喜欢的内容和探索不太确定但可能获得更高回报的选项之间进行选择。通过偶尔选择*探索*并推荐不太明显的选择，可以在推荐系统中使用这种权衡来确保多样性。为了实现这样的系统，我们可以使用亲和力作为奖励估计值，使用倾向性作为利用度量。

而不是使用这些后验策略，一个替代方法是*将多样性作为学习过程中的一个目标*或在损失函数中包含一个多样性正则化项。包括成对相似性的多目标损失可以帮助模型学习多样化的推荐集合。您之前看到过，各种正则化可以指导训练过程以最小化某些行为。一个可以显式使用的正则化项是*推荐间的相似性*；推荐中每个嵌入向量的点积可以近似表示这种自相似性。让 <math alttext="script upper R equals left-parenthesis upper R 1 comma upper R 2 comma ellipsis comma upper R Subscript k Baseline right-parenthesis"><mrow><mi>ℛ</mi> <mo>=</mo> <mo>(</mo> <msub><mi>R</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>R</mi> <mn>2</mn></msub> <mo>,</mo> <mo>...</mo> <mo>,</mo> <msub><mi>R</mi> <mi>k</mi></msub> <mo>)</mo></mrow></math> 成为推荐的嵌入列表，然后将 <math alttext="script upper R"><mi>ℛ</mi></math> 视为一个列矩阵——其中每行都是一个推荐。计算 <math alttext="script upper R"><mi>ℛ</mi></math> 的格拉姆矩阵将产生所有点积相似性计算，因此我们可以通过适当的超参数权重来通过这个项进行正则化。请注意，这与我们先前的格拉姆矩阵正则化不同，因为这种情况下我们只考虑个别查询的推荐。

最后，我们可以利用多个领域的排名来提高推荐的多样性。通过整合各种排名措施，推荐系统可以建议用户“模式”之外的项目，从而扩展推荐范围。围绕多模态推荐存在着活跃的学科，Pinterest 的 [PinnerSage 论文](https://oreil.ly/KOQK2) 就是一个特别引人注目的实现。在许多关于多模态推荐的作品中，检索步骤返回的推荐列表中有太多接近用户查询向量的推荐。这强制了检索列表中的自相似性。多模态强制使用多个查询向量来处理每个请求，从而实现内置的多样性。

让我们从另一个角度看待项目的自相似性，并考虑如何利用项目之间的成对关系来实现这一目标。

## 应用投资组合优化

*投资组合优化*，这是从金融中借鉴的概念，可以是增强推荐系统多样性的有效方法。这里的目标是创建一个平衡关键参数（相关性和多样性）的“投资组合”推荐项目列表。

在其核心，投资组合优化关乎风险（在我们的案例中是相关性）和回报（多样性）。以下是将此优化应用于推荐系统的基本方法：

1.  制定一个项目表示，以便空间中的距离是相似性的良好度量。这与我们先前讨论过的构建良好潜在空间的理念一致。

1.  计算项目之间的成对距离。您可以通过使用丰富您的潜在空间的任何距离度量来完成此操作。重要的是要计算检索到的所有项目之间的这些成对距离，并准备考虑回报。请注意，如何聚合这些距离分布可能是微妙的。

1.  评估检索集的亲和力。请注意，校准后的亲和力分数表现更好，因为它们提供了对回报的更现实的估计。

1.  解决优化问题。解决问题将为每个项目产生一个权重，平衡关联性和多样性之间的权衡。具有更高权重的项目在关联性和多样性方面更有价值，应优先考虑放在推荐列表中。从数学上讲，问题看起来是这样的：

    <math alttext="less-than u l c l a s s equals quotation-mark s i m p l e l i s t quotation-mark greater-than less-than l i greater-than upper M a x i m i z e left-parenthesis w Superscript upper T Baseline asterisk r minus lamda asterisk w Superscript upper T Baseline asterisk upper C asterisk w right-parenthesis less-than slash l i greater-than less-than slash u l greater-than" display="block"><mrow><mi>M</mi> <mi>a</mi> <mi>x</mi> <mi>i</mi> <mi>m</mi> <mi>i</mi> <mi>z</mi> <mi>e</mi> <mo>(</mo> <msup><mi>w</mi> <mi>T</mi></msup> <mo>*</mo> <mi>r</mi> <mo>-</mo> <mi>λ</mi> <mo>*</mo> <msup><mi>w</mi> <mi>T</mi></msup> <mo>*</mo> <mi>C</mi> <mo>*</mo> <mi>w</mi> <mo>)</mo></mrow></math>

    这里，<math alttext="w"><mi>w</mi></math>是表示权重的向量（即推荐列表中每个项目的比例），<math alttext="r"><mi>r</mi></math>是关联性分数向量，<math alttext="upper C"><mi>C</mi></math>是协方差矩阵（捕获多样性），<math alttext="lamda"><mi>λ</mi></math>是平衡关联性和多样性的参数。约束条件是权重的总和等于 1。

    记住，超参数<math alttext="lamda"><mi>λ</mi></math>在关联性和多样性之间进行权衡。这使其成为该过程的关键部分，并可能根据系统及其用户的具体需求进行实验或调整。这可以通过诸如 Weights & Biases 等许多包的超参数优化来直接进行。

# 多目标函数

多样性的另一个相关方法是基于多目标损失进行排名。与排名阶段纯粹的个性化亲和力不同，引入第二（或更多！）排名项可以显著提高多样性。

这里最简单的方法类似于您在第 14 章学到的：硬排名。可能适用于多样性的业务规则是将每个项目类别限制为仅一个项目。这是多目标排名的最简单情况，因为按照分类列排序并选择每组中的最大值将实现相对于该协变量的显式多样性。让我们转向更微妙的内容。

在[“为基于查询的推荐拼接空间”](https://oreil.ly/OREt2)中，本书的一位作者与共同作者 Ian Horn 合作实现了一个多目标推荐系统，该系统在解决图像检索问题时平衡了个性化和关联性。

目标是为用户上传的图像中与衣物相似的服装提供个性化推荐。这意味着存在两个潜在空间：

+   个性化服装到用户的潜在空间

+   服装图像的潜在空间

要解决这个问题，我们首先需要做出一个决定：在相关性方面，什么更重要？个性化还是图像相似性？因为产品围绕着照片上传体验，我们选择了图像相似性。然而，我们还需要考虑另一个事实：每个上传的图像包含多件服装。正如在计算机视觉中流行的那样，我们首先将模型分割成几个单独的项目，然后将每个项目视为其自身的查询（我们称之为*锚点项目*）。这意味着我们的图像相似性检索是多模态的，因为我们使用了几个不同的查询向量进行搜索。在我们收集完所有这些数据后，我们需要进行最终排名——一个关于图像相似性和个性化的多目标排名。我们优化的损失函数如下所示：

<math alttext="s Subscript i Baseline equals alpha times left-parenthesis 1 minus d Subscript i Baseline right-parenthesis plus left-parenthesis 1 minus alpha right-parenthesis times a Subscript i" display="block"><mrow><msub><mi>s</mi> <mi>i</mi></msub> <mo>=</mo> <mi>α</mi> <mo>×</mo> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <msub><mi>d</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>+</mo> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>α</mi> <mo>)</mo></mrow> <mo>×</mo> <msub><mi>a</mi> <mi>i</mi></msub></mrow></math>

<math alttext="alpha"><mi>α</mi></math> 是一个超参数，表示权重，<math alttext="d Subscript i"><msub><mi>d</mi> <mi>i</mi></msub></math> 是图像距离，而 <math alttext="a Subscript i"><msub><mi>a</mi> <mi>i</mi></msub></math> 是个性化的参数。我们通过实验来学习 α。最后一步是施加一些严格的排名规则，以确保每个推荐来自每个锚点。

所以让我们总结一下：

1.  我们使用两个潜在空间的距离来提供排名。

1.  我们通过图像分割进行了多模态检索。

1.  我们只使用了其中一个排名来检索。

1.  我们的最终排名是多目标的，利用了所有我们的潜在空间和业务逻辑。

这使得我们的推荐在一定程度上是*多样化*的，因为它们在与不同项目对应的查询的几个领域中实现了相关性。

# 谓词下推

在服务期间，您可能会很高兴并且舒适地应用这些指标——毕竟，这是本书的这一部分的标题——但在我们离开这个话题之前，我们应该讨论一个可能会带来严重后果的边缘情况。当您从第十四章中强制施加严格规则以及本章早些时候讨论的多样性期望，并进行一些多目标排名时，有时您会得出……没有推荐。

假设你开始通过检索 *k* 个项目，但在足够多的满足业务规则的多样化组合之后，实际上没有任何剩余项目了。你可能会说：“我只是多检索一些项目；让我们增加 *k*！”但这会带来一些严重问题：它可能会显著增加延迟，降低匹配质量，并扰乱你的排名模型，该模型更适合较低基数集。

一个常见的经验，特别是在多样性方面，是检索的不同模式具有极大不同的匹配分数。举一个我们时尚推荐器世界的例子：所有牛仔裤可能比我们拥有的任何衬衫都更匹配，但如果您正在寻找多样化的服装类别进行推荐，无论 *k* 有多大，您可能会错过衬衫。

这个问题的一个解决方案是*谓词下推*。这种优化技术用于数据库，特别是在数据检索的上下文中。谓词下推的主要思想是尽早在数据检索过程中进行数据过滤，以减少后续查询执行计划中需要处理的数据量。

对于传统数据库，例如“将我的查询的`where`子句应用于数据库以减少 I/O。”，谓词下推可以通过显式地首先拉取相关列以检查`where`子句，然后获取通过的行 ID，再执行其余查询，来实现此目的。

这如何帮助我们的案例呢？简单来说，如果你的向量存储还具有向量的特征，你可以将特征比较作为检索的一部分。让我们举一个过于简单的例子：假设你的项目有一个名为`color`的分类特征，为了获得良好的多样化推荐，你希望在你的五个推荐中有至少三种颜色的好组合。为了实现这一点，你可以在你的存储中的每种颜色上进行 top-*k*搜索（缺点是你的检索增加了*C*倍，其中*C*是存在的颜色数量），然后在这些集合的并集上进行排名和多样性评估。这有很高的可能性能够在最终推荐中符合你的多样性规则。这是很棒的！我们期望检索的延迟相对较低，因此如果我们知道在哪里查找，这种额外的检索负担并不糟糕。

如果你的向量存储为所需的过滤器设置得当，这种优化技术可以应用于相当复杂的谓词。

# 公平性

一般而言，机器学习中的公平性是一个非常微妙的主题，短小的摘要往往难以服务。以下主题至关重要，我们建议您考虑这里包含的强大参考资料：

推动

公平性不需要仅仅是“所有结果的等概率”，它可以在特定协变量的背景下公平。通过推荐者进行推动，即推荐项目以强调某些行为或购买模式，可以增加公平性。考虑 Spotify 的 Karlijn Dinnissen 和 Christine Bauer 关于使用推动来改善音乐推荐中性别表示的工作。

滤泡效应

滤泡效应是极端协同过滤的一个不利方面：一组用户开始喜欢类似的推荐，系统学习到他们应该接收类似的推荐，这种反馈循环会持续下去。要深入了解这一概念及缓解策略，可以参考 Zhaolin Gao 等人的《“缓解过滤泡效应同时保持相关性”》。

高风险

并非所有的 AI 应用在风险上都是相等的。一些领域在 AI 系统的保护不力时尤其有害。有关最高风险情况和缓解措施的一般概述，请参阅 Patrick Hall 等人(O’Reilly)的[*Machine Learning for High-Risk Applications*](https://learning.oreilly.com/library/view/machine-learning-for/9781098102425/)。

可信度

可解释性模型是 AI 风险应用的一种流行的缓解策略。虽然可解释性并不能*解决*问题，但它经常提供了一条向识别和解决问题的路径。关于这一点的深入探讨，Yada Pruksachatkun 等人(O’Reilly)的[*Practicing Trustworthy Machine Learning*](https://learning.oreilly.com/library/view/practicing-trustworthy-machine/9781098120269/)提供了工具和技术。

推荐中的公平性

由于推荐系统显然容易受到人工智能公平性问题的影响，关于这个主题已经有很多文章写作。每个主要社交媒体巨头都设有从事 AI 安全工作的团队。其中一个特别亮点是由 Rumman Chowdhury 领导的 Twitter 负责 AI 团队。您可以阅读 Alfred Ng 的文章["Can Auditing Eliminate Bias from Algorithms?"](https://oreil.ly/uvFep)了解团队的工作。

# 总结

虽然这些技术提供了增强多样性的途径，但重要的是要记住在多样性和相关性之间取得平衡。使用的确切方法或方法组合可能会因具体用例、可用数据、用户群体的复杂性以及收集反馈的类型而有所不同。在实施推荐系统时，请考虑哪些方面在解决多样性问题中最为关键。
