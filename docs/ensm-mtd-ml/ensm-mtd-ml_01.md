# 第一部分 集成的基础

你可能听说过很多关于“随机森林”、“XGBoost”或“梯度提升”的事情。似乎总有人在使用其中之一来构建酷炫的应用或赢得 Kaggle 竞赛。你有没有想过这究竟是怎么回事？

事实上，所有的喧嚣都是关于**集成方法**，这是一种强大的机器学习范式，它已经进入到了医疗保健、金融、保险、推荐系统、搜索以及许多其他领域的各种应用中。

这本书将带你进入集成方法的广阔世界，这一部分将帮助你入门。用《音乐之声》中无可比拟的朱莉·安德鲁斯的话来说，

让我们从一开始，

一个非常好的开始地方。

当你阅读时，你从 A-B-C 开始。

当你进行集成时，你从拟合与复杂度开始。

这本书的第一部分将温和地介绍集成方法，结合一些关于拟合与复杂度（或更正式地称为偏差-方差权衡）的直觉和理论。然后，你将从头开始构建你的第一个集成模型。

当你完成这本书的这一部分后，你会明白为什么集成模型通常比单个模型更好，为什么你应该关注它们。
