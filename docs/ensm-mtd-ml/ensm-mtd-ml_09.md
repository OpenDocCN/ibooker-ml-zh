# 第三部分：野外的集成：将集成方法适应你的数据

数据科学家的世界是一个充满狂野和危险的领域。我们必须应对不同类型的数据，例如计数、类别和字符串，这些数据中充满了缺失值和噪声。我们被要求为不同类型的任务构建预测模型：二元分类、多类分类、回归和排名。

我们必须谨慎构建我们的机器学习管道并预处理我们的数据，以避免数据泄露。它们必须准确、快速、健壮，并且值得传播（好吧，最后一个可能不是必需的）。经过这一切，我们最终得到的模型可能确实能完成它们被训练的任务，但最终是没有人理解的黑盒。

在本书的最后一部分，你将学习如何应对这些挑战，凭借上一部分书中提供的集成方法武器库，以及一些新的集成方法。这是你从正在训练的集成者到经验丰富的野外数据世界集成者的最后一站。

第七章涵盖了回归任务的集成学习方法，你将学习如何适应不同的集成方法来处理连续和计数标签。

第八章涵盖了具有非数值特征的集成学习方法，你将学习在集成之前或期间如何编码类别和字符串值特征。你还将了解在预处理过程中（有时以其他方式）出现的两个普遍问题——数据泄露和预测偏移——以及它们如何经常干扰我们准确评估模型性能的能力。此外，第八章还介绍了一种名为有序提升的梯度提升变体，以及一个名为 CatBoost 的强大梯度提升包，它与 LightGBM 和 XGBoost 类似。

第九章涵盖了令人兴奋的新领域——可解释人工智能，它寻求创建人类可以理解和信任的模型。虽然本章从集成方法的角度进行介绍，但本章涵盖的许多可解释方法（例如，代理模型、LIME 和 SHAP）可以应用于任何机器学习模型。第九章还介绍了可解释提升机，这是一种专门设计为直接可解释的集成方法类型。

本书这一部分涵盖了集成方法的进阶主题，并基于第二部分的一些关键概念，特别是梯度提升。如有需要，不要犹豫，随时回到第二部分进行复习或参考。
