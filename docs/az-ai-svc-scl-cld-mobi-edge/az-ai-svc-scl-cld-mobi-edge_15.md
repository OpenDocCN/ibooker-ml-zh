# 第十一章：为国际组织大规模翻译多种语言

虽然许多 Azure 机器学习和认知服务应用程序侧重于商业和消费服务，但它们也是政府和其他公共机构的重要工具。机器学习驱动的工具可以帮助这些组织更高效地运作，消除瓶颈并加快常见流程。微软一直在推动这些方法，例如其 AI for Good 计划。

微软人工智能工具的一个重要作用是通过提供快速自动翻译的工具来消除不同国籍之间的障碍。如果你使用过 PowerPoint 中的字幕工具或智能手机上的 Translator 应用程序，你正在使用围绕 Azure 语音识别和翻译服务构建的工具。我们已经看过如何在你的应用程序中使用它们，在第四章中展示了语音识别工具如何将语音转换为文本，翻译工具如何将这些文本从一种语言翻译为另一种语言，以及神经语音模型如何从翻译后的文本中提供自然语音。

# 为国际议会提供翻译

我们使用这些工具的许多方式是为了支持个人，翻译菜单或帮助在陌生城市中搭乘出租车。但是，如果我们需要为大量使用专业词汇的多语种工作人员提供近实时的转录，会怎么样呢？这是微软工程团队必须解决的问题，以便为欧洲议会构建原型翻译服务，基于我们在第四章中探讨过的同一认知服务 API 和工具。

像欧洲议会这样的跨国机构使用多种语言工作，代表来自 27 个国家的代表讲述 24 种不同的语言，并且有超过 4,000 名口译员。由于没有官方语言，演讲需要实时转录和翻译，以便发言者可以在辩论期间回应演讲，同时创建官方记录。这意味着需要连接到议会的声音和录音系统，自动检测语言并随着语言变化即时更改转录模型。

# 连接现有音视频（AV）系统

由于竞标性质的关系，直接连接音响系统并不可行，因此系统必须通过使用 MPEG-DASH 的 Web API 工作。这增加了复杂性，因为 MPEG-DASH 提供自适应速率音频数据，而 Azure 认知服务输入则期望以 60K 赫兹编码的脉冲编码调制（PCM）音频流。音频系统还提供了 25 种不同的流，每种语言一种以及来自议会楼层的主音频轨道。

微软系统首先需要识别直播流，然后分离视频和音频信号，再将音频轨道转码为 PCM。一旦分离，两个流需要进行时间编码，以便将生成的转录与视频流同步，然后将其提供给最终用户。由于要求延迟不超过七秒，系统处理数据转换并传递转录和翻译字幕的时间有限。

云原生开发技术被证明是合适的，使用微服务架构来处理初始信号处理，使用熟悉的开源工具如 FFmpeg 来管理转码，然后将转换后的音频流传递给认知服务翻译工具。实时协议 SignalR 用于将生成的字幕返回到门户，同时带有时间编码的偏移量，用于将文本与原始视频流对齐。延迟保持较低，整个过程不超过两秒。

# 使用专用语音识别处理特定词汇

由于存在大量专用词汇，微软的认知服务团队努力为 24 种所需语言交付一组定制语言模型，使用演讲数据集来训练这些模型。项目的一个团队负责处理转录模型，另一个团队负责翻译。这些模型通过它们的 BLEU 分数进行评估，该分数显示它们的结果与人工翻译有多接近，以及它们的词错误率。这些模型需要超过最低分数水平。

一旦训练完成，定制模型通过 Azure 中的私有端点提供，拥有自己的计算资源。这种方法与使用认知服务的任何人可用的方法没有区别；微软使用的工具是平台内置的标准工具。

服务团队面临的最大问题是入口音频流的质量以及整体音频管道的长度。每个处理步骤都会增加延迟，因此需要尽量减少步骤数。作为来源的可变比特率网络流也会增加额外的延迟。例如，32K 流量可能会降至 5K，然后再回升到 100K，最终回归到其标准速率。尽管原型使用软件编码将流转换为 Azure 兼容格式，但实际上硬件解决方案将具有更好的性能，并将延迟保持在最低水平。

软件团队还发现，他们最初基于容器的设计比使用虚拟机来托管微服务更慢。这是因为容器无法访问 GPU 资源，而 Azure 提供了 GPU 虚拟机。从无服务器容器主机切换到基础设施即服务会增加运营成本，但性能提升显著。与使用基于硬件的音频编码器一样，处理有限的延迟预算意味着要充分利用硬件带来的所有优势。

# 从专业原型到通用应用

同样的基本系统已被白标，用于不同的环境。目前，另一国际机构的一个当前概念验证正在设计中，用于处理会议室内的音频，使用流行的 Audinate Dante AV 协议。在这里，音频和视频通过以太网传输，使用虚拟声卡处理 Dante 音频流。这意味着重新编写音频处理器以处理备用流格式。

在 AV 系统中，这里运行的是一个在 PC 上运行的.NET 应用程序，通过以太网接收音频信号，使用 Audinate 提供的虚拟声卡获取音频通道。该应用程序将音频数据转换为字节数组，然后可以根据要求同步或异步地传递给 Azure。输出数据通过 Web 门户传递，呈现为转录或实时语音到语音翻译。实时语音系统设计成可以定义单一输出语言，确保流始终是用户选择的语言。例如，法语发言者可以选择母语，所有翻译结果都将以法语呈现。

要翻译流，首先需要识别正在使用的语言，然后通过适当的认知服务 API 处理流。在议会和委员会会议中，发言人和语言频繁变换是一个问题。系统需要能够在语言变换发生时立即检测到，以确保转录始终使用正确的语言。虽然目标是涵盖全部 24 种语言，但最初只启用了 10 种。

# 在限制条件下工作

当从像这样的服务概念验证转向全面运营时，需要考虑很多因素。虽然该系统在规模上能够工作，但还未完全调整以实现全面运营。这样的系统需要与消费者服务有所不同，因为它需要检测并删除语音习惯和停顿。还要确保考虑到语言的地区变化，并理解底层服务的默认设置是非常重要的。

例如，在欧洲工作时，翻译葡萄牙语需要使用 PT-PT，而不是默认的 PT-BR，因为巴西葡萄牙语已经与原始语言分道扬镳。还需要更有针对性的词汇表和可以根据上下文切换的模型。关于经济的议会会议将使用与渔业政策或国际援助有很大不同的术语。

还有一些需要考虑的约束条件：需要 GPU 启用的虚拟机将限制可以运行此类服务的 Azure 区域。在不受支持的区域工作可能会增加额外的延迟，这种延迟可能会因直接连接到 Azure 的网络连接而不可预测地变化。同样重要的是，在所有系统中坚持使用相同的硬件 SKU，因为不同的处理器代数对机器学习数据的处理方式不同。例如，高效的 BFLOAT 指令仅在最近的服务器 CPU 中受支持。更换到旧版 CPU 将影响模型的准确性。

或许最令人感兴趣的是微软在交付一套能够以极低延迟和高准确率处理多语言翻译的工具时所采用的方法，它使用现成的 API 和工具。这里没有专门的研究软件；即使使用自定义的语音模型，也是使用任何人都可以使用的相同 API 和门户进行构建和训练。即使底层的微服务模型也是一种常见的云原生设计模式，利用生产环境的 Azure 虚拟机镜像和硬件。

这样的翻译工具曾经是科幻，但现在作为 API 的标准技术已经普及，采用常见的设计模式。这些工具任何人都可以使用；关键在于微软如何将它们与现有的 AV 系统集成。这种方法同样适用于其他环境。
