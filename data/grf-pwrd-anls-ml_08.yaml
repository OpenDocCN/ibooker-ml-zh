- en: Chapter 6\. Analyzing Connections for Deeper Insight
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。分析连接以获得更深入的洞察
- en: In the preceding chapters, we learned that representing data as a graph gives
    us the power to look more deeply and broadly across our data so we can answer
    questions more accurately and with more insight. We’ve looked at several use cases
    to see examples of how to model data as a graph and how to query it. Now we want
    to take a more methodical look at graph analytics. What do we mean when we say
    graph analytics? What are some specific techniques we can use for graph analytics?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们了解到将数据表示为图表使我们能够更深入、更广泛地查看数据，从而能够更准确和更有洞察力地回答问题。我们看了几个用例，以了解如何将数据建模为图表以及如何查询它。现在我们希望更系统地查看图分析。当我们说图分析时，我们指的是什么？我们可以使用哪些具体的技术来进行图分析？
- en: 'After completing this chapter, you should be able to:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章后，您应能够：
- en: Define graph analytics and describe what distinguishes it from general data
    analytics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义图分析并描述其与一般数据分析的区别
- en: Understand graph analytics’ requirements and some key methods, including breadth-first
    search and parallel processing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解图分析的要求和一些关键方法，包括广度优先搜索和并行处理
- en: Define several categories of graph algorithms that are useful for analytics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义几种对分析有用的图算法类别
- en: List a few algorithms within each category and give examples of real-world uses
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出每个类别中的几种算法，并举例说明其在现实世界中的用途
- en: Understanding Graph Analytics
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解图分析
- en: Let’s start by defining data analytics in general. *Data analytics* is making
    useful observations and drawing conclusions about a body of data to help people
    understand the significance of the data. Analytics transforms data into useful
    insights. Graph analytics does the same thing, except that the structure of the
    data affects which data we will examine and in what order. Connections are a form
    of data, and the connections drive the course of the analysis.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一般定义数据分析开始。*数据分析*是对数据集进行有用观察并得出结论，以帮助人们理解数据的重要性。分析将数据转化为有用的见解。图分析也是如此，只不过数据的结构影响我们将检查哪些数据以及以何种顺序检查。连接是一种数据形式，连接驱动分析的进程。
- en: 'Another distinguishing aspect of graph analytics is that it is good for addressing
    questions *about* the connections. You could ask what the shortest chain of connections
    is between Customer A and Customer B in a tabular set of data, but you are much
    better equipped to perform that analysis if your data is a graph. We can summarize
    our thoughts as follows:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图分析的另一个显著特点是它非常适合回答关于连接的问题。在表格数据集中，您可以询问客户A和客户B之间的最短连接链路是什么，但如果您的数据是图形式式的，您将更好地完成这种分析。我们可以总结我们的思考如下：
- en: Graph analytics is making observations and drawing conclusions *on* connected
    data and *about* connected data.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图分析是对连接数据进行观察和得出结论的过程。
- en: Requirements for Analytics
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析要求
- en: To make an observation about a body of data, it’s obvious that we have to examine
    all of that data or the rel evant subset and that there will be some form of computation
    involved. If our data collection contains all sales transactions for a certain
    year, a simple analysis would be to compute the total sales for each month and
    then to see if the sales are trending upward, downward, or moving in a more complex
    way. If the data is organized into a table, then we imagine scanning down the
    table, reading each row. We also imagine that we need some place to hold our results—the
    monthly sales. In fact, we’ll probably want to keep a running total as we read
    each row and add its sales to one of the monthly sums.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要对数据集作出观察，显然我们必须检查所有数据或相关子集，并且这将涉及某种形式的计算。如果我们的数据集包含某一年的所有销售交易，简单的分析可以是计算每个月的总销售额，然后查看销售趋势是上升、下降还是以更复杂的方式移动。如果数据组织成表格，那么我们可以想象扫描表格，逐行阅读。我们还需要一个地方来保存结果——每月销售额。事实上，当我们阅读每一行并将其销售额添加到一个月总额时，我们可能希望保持一个累计总数。
- en: 'Graph analytics has similar requirements: reading all the relevant data, performing
    calculations and decisions on each data point, holding temporary results, and
    reporting final results. The primary difference between graph analytics and tabular
    analytics is that the graph’s connections affect both the nature of the data items
    and the order in which we scan the data. There are also choices of methodology
    or architecture that can make the computations and memory storage more efficient.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图分析有类似的要求：阅读所有相关数据，对每个数据点执行计算和决策，保存临时结果，并报告最终结果。图分析与表格分析的主要区别在于，图的连接不仅影响数据项的性质，还影响我们扫描数据的顺序。还有一些方法论或架构的选择可以使计算和内存存储更加高效。
- en: Graph Traversal Methods
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图遍历方法
- en: In graph analytics, we follow the connections that lead us from one data point
    to the next. Using the metaphor of the graph being a network of walking paths,
    it’s common to say that we *walk* or *traverse* the graph. At first, it may seem
    that you want to follow a chain of connections, the way an individual would walk.
    However, when you look at the task you are trying to accomplish, it turns out
    that it may make more sense to explore all the one-hop direct connections from
    your present position one at a time, before following a connection of a connection.
    Following a chain of connections is called *depth-first search (DFS)*, and looking
    at all of your direct connections before moving to the next tier of connections
    is called *breadth-first search (BFS)*. We mentioned these briefly in [Chapter 2](ch02.html#connect_and_explore_data).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在图分析中，我们跟随连接从一个数据点到下一个数据点。用图作为行走路径网络的比喻，我们常说我们*走*或*遍历*图。起初，看起来你可能想要跟随一系列连接，就像一个人会走的方式。然而，当你看看你要完成的任务时，结果可能更合理的是依次探索当前位置的直接连接，然后再跟随连接的连接。跟随一系列连接称为*深度优先搜索（DFS）*，在移动到下一个层级连接之前查看所有直接连接称为*广度优先搜索（BFS）*。我们在[第2章](ch02.html#connect_and_explore_data)中简要提到了这些。
- en: 'The following workflow explains both BFS and DFS. The difference is in the
    order in which work gets processed, reflected in the order of vertices in the
    `Places_to_Explore` list:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下工作流程解释了BFS和DFS。区别在于处理工作的顺序，反映在`Places_to_Explore`列表中顶点的顺序：
- en: Put the source vertex into a processing list called `Places_to_Explore`. As
    a list, it has an order, front to back.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将源顶点放入名为`Places_to_Explore`的处理列表中。作为列表，它有一个顺序，从前到后。
- en: Remove the first vertex from the front of the `Places_to_Explore` list. If that
    vertex is marked as `Already_Visited`, then skip steps 3 and 4.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`Places_to_Explore`列表的前端移除第一个顶点。如果该顶点已标记为`Already_Visited`，则跳过步骤3和4。
- en: Perform whatever work you want to do for each vertex, such as checking whether
    a value matches your search query. Now mark the vertex as `Already_Visited`.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行你希望对每个顶点执行的任何工作，比如检查一个值是否匹配你的搜索查询。现在将顶点标记为`Already_Visited`。
- en: From the current vertex, get a list of all of its connected edges. If BFS, add
    that list to the *end* of the `Places_to_Explore` list (queue). If DFS, add that
    list to the front of the `Places_to_Explore` list (stack).
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从当前顶点获取所有连接边的列表。如果是BFS，则将该列表添加到`Places_to_Explore`列表（队列）的*末尾*。如果是DFS，则将该列表添加到`Places_to_Explore`列表（栈）的*前面*。
- en: Repeat steps 2 to 4 until the `Places_to_Explore` list is empty.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤2到4，直到`Places_to_Explore`列表为空为止。
- en: With BFS, we follow a “fair” system in which every newly encountered vertex
    goes to the back of the line. As a consequence, vertices get processed level by
    level, all the vertices one hop from the source, then all the vertices two hops
    from the sources, and so on. With DFS, we follow a “greedy” system, which processes
    one child of the source and then puts its neighbors at the front of the line instead
    of at the back.^([1](ch06.html#ch01fn11)) That means that in the third step, one
    lucky vertex that is three hops from the source will get attention. In [Figure 6-1](#overview_of_breadth_first_search_left_p),
    we see an example of BFS and DFS. Initially, only vertex 1 has a number. The other
    numbers are assigned in the order of visit.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用BFS时，我们遵循一个“公平”的系统，即每遇到的新顶点都排到队列的尾部。因此，顶点逐级处理，从源顶点开始的一跳所有顶点，然后是两跳顶点，依此类推。使用DFS时，我们遵循一个“贪婪”的系统，处理源的一个子节点，然后将其邻居放在列表的前面而不是后面。^([1](ch06.html#ch01fn11))
    这意味着在第三步中，一个幸运的距离源三跳的顶点将得到关注。在[图6-1](#overview_of_breadth_first_search_left_p)中，我们看到BFS和DFS的示例。最初，只有顶点1有一个数字。其他数字按访问顺序分配。
- en: '![Overview of breadth-first search (BFS) versus depth-first search (DFS) methods](assets/gpam_0601.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![广度优先搜索（BFS）与深度优先搜索（DFS）方法的概述](assets/gpam_0601.png)'
- en: Figure 6-1\. Overview of breadth-first search (BFS) versus depth-first search
    (DFS) methods
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-1\. 广度优先搜索（BFS）与深度优先搜索（DFS）方法概述
- en: BFS is superior when you are looking for something as close as possible to the
    ground truth best answer. Shortest path algorithms use BFS. DFS can be good if
    you expect the answer to be multihop and there are many paths that satisfy the
    task.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当你希望尽可能接近地面真实最佳答案时，BFS更为优越。最短路径算法使用BFS。如果期望答案为多跳并且存在满足任务的许多路径，则DFS可能更合适。
- en: If we intend to explore the entire graph and we have only one worker to process
    information, then BFS and DFS have roughly equivalent efficiency. However, if
    parallel processing is available, then BFS wins out almost every time.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打算探索整个图并且只有一个工作者来处理信息，那么BFS和DFS的效率大致相当。然而，如果有并行处理可用，则几乎每次都是BFS胜出。
- en: Parallel Processing
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行处理
- en: '*Parallel rocessing* is being able to do two or more tasks at the same time
    to cut down on latency, that is, the total time from start to finish. To benefit
    from parallel processing, the overall task needs to be able to be split into multiple
    subtasks that can be performed independently (“parallelizable”), and you must
    have multiple processors. In addition, there is some management work to know how
    to split the task and then merge the separate results into a final result.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*并行处理*是能够同时执行两个或更多任务以减少延迟，即从开始到完成的总时间。要从并行处理中受益，整体任务需要能够分解成多个可以独立执行的子任务（“可并行化”），并且必须有多个处理器。此外，还需进行一些管理工作，以了解如何分割任务，然后将分开的结果合并成最终结果。'
- en: BFS and parallel processing go well together. Most graph analytics tasks that
    use BFS can be performed more efficiently with parallel processing. Imagine you
    want to create a detailed map of a road network. You have a troop of surveyors
    (multiple processors) who all start at Point A. At every fork in the road, you
    split up your troops to get the work done faster (BFS with parallel processing).
    With software, you have an advantage over the physical world. When one processor
    is finished with its current task, it can jump to anywhere in the data network
    where it is needed for the next task.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: BFS和并行处理很好地结合在一起。大多数使用BFS的图分析任务可以通过并行处理更有效地执行。想象一下，你想创建一个道路网络的详细地图。你有一队勘测员（多个处理器），他们都从点A开始。在每个路口，你分开你的队伍以更快地完成工作（BFS与并行处理）。在软件中，你比物理世界更有优势。当一个处理器完成当前任务后，它可以跳到数据网络中任何需要进行下一个任务的地方。
- en: Aggregation
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚合
- en: 'One of the fundamental tasks in analytics is *aggregation*: taking a set of
    values, performing some operation on them, and producing a single result that
    characterizes the set. The most common aggregation functions are count, sum, and
    average.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析中的一个基本任务是*聚合*：获取一组值，对它们进行某些操作，并产生一个描述该集合的单一结果。最常见的聚合函数包括计数、求和和平均值。
- en: 'Consider this analysis of purchase behavior: given a **`Customer-Purchases-Products`**
    graph, find the three most purchased products that are bought within one week
    after Product X and in the same product family as Product X. Here is how we can
    solve it with graph analytics:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑购买行为分析：在给定**`客户-购买-产品`**图中，找出在产品X购买后一周内购买的三种最常购买的与产品X同一产品家族的产品。以下是我们如何使用图分析解决这个问题：
- en: Start at the vertex representing Product X.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从代表产品X的顶点开始。
- en: Traverse along **`Purchases`** edges to find all the **`Customers`** who purchased
    Product X. At each of those traversal paths, note the purchase date.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 沿着**`购买`**边遍历，找到所有购买了产品X的**`客户`**。在每条这样的遍历路径上，记录购买日期。
- en: From each of those **`Customers`**, scan their other **`Purchases`** edges for
    the one-week time window starting from that purchase date. For every **`Product`**
    that fits in that time window, add it to a global data structure, which allows
    adding new items and also updating the count of such items.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从每个**`客户`**那里，扫描他们其他**`购买`**边，查找从那次购买日期开始的一周时间窗口内符合条件的每个**`产品`**，并将其添加到一个全局数据结构中，允许添加新项目并更新这些项目的计数。
- en: Sort the global counts to find the three most popular follow-up purchases.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对全局计数进行排序，找到三种最受欢迎的后续购买。
- en: 'Let’s analyze that workflow and what would be needed:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下工作流程和所需的内容：
- en: Starting from a single vertex, we used BFS for two hops, filtering the second
    hop by a date range determined by the first hop. BFS requires bookkeeping (the
    `Places_to_Explore` list mentioned previously). You’ve already seen in previous
    chapters how the GSQL language has built-in support, using a `SELECT-FROM-ACCUM`
    statement and saving the result of one level of traversal as the vertex set result
    of that statement.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从单个顶点开始，我们使用 BFS 进行两次跳数，通过第一次跳数确定的日期范围过滤第二次跳数。BFS 需要记账（前面提到的 `Places_to_Explore`
    列表）。在之前的章节中，您已经看到了 GSQL 语言如何内置支持，使用 `SELECT-FROM-ACCUM` 语句并将一级遍历的结果保存为该语句的顶点集结果。
- en: 'Each path of the BFS needs to temporarily keep track of its own time window.
    The math is simple here: add seven days to a given timestamp. GSQL has local variables
    that can perform the task of temporarily holding data for later analysis.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个 BFS 的路径都需要临时跟踪自己的时间窗口。数学很简单：在给定时间戳上加七天。GSQL 提供了本地变量，可以执行临时保存数据以供后续分析的任务。
- en: 'The main aggregation work is collecting the follow-up purchases and finding
    which are the three most popular. We need a global data structure that each processing
    agent can access to add a new item. The simplest data structure would be a list
    that can hold duplicate instances of the same item. After we finish looking for
    follow-up purchases, we would then need to read through the list to see how many
    times each item is mentioned and to sort the counts to get the top three. A more
    sophisticated way would be to use a *map* that holds data pairs: productID:count.
    This would require support for two operations: insert a new productID and increment
    a count. If we want to use parallel BFS, we need to be able to support concurrent
    inserts and increments. After getting the final counts, we need to sort to get
    the top three.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主要的聚合工作是收集后续购买，并找出其中最受欢迎的三个。我们需要一个全局的数据结构，每个处理代理都可以访问以添加新项。最简单的数据结构可能是一个列表，可以保存相同项目的重复实例。在查找后续购买完成后，我们需要遍历列表，看每个项目被提及的次数，并对计数进行排序以获取前三名。更复杂的方法是使用一个
    *映射*，它保存数据对：productID:count。这将需要支持两个操作：插入新的 productID 和增加计数。如果我们想使用并行 BFS，我们需要支持并发插入和增加操作。获取最终计数后，我们需要排序以获取前三名。
- en: The GSQL language provides built-in support for parallel aggregation using objects
    called accumulators. Accumulators can be global or per vertex. Accumulators can
    hold scalar values, like a sum or average, or they can hold collections, like
    a list, set, map, or heap. For this example of finding the most popular follow-up
    purchases, a global `MapAccum` would satisfy most of the work.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: GSQL 语言提供了对并行聚合的内置支持，使用称为累加器的对象。累加器可以是全局的或每个顶点的。累加器可以保存标量值，如总和或平均值，也可以保存集合，如列表、集合、映射或堆。对于查找最受欢迎的后续购买的示例，一个全局的
    `MapAccum` 将满足大部分工作需求。
- en: Using Graph Algorithms for Analytics
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用图算法进行分析
- en: 'Some analytics tasks require writing custom database queries: the question
    being asked is unique and quite specific to the dataset and use case. In other
    cases, the analytical question is fairly common. Having a library of standard
    analytical tools, with parameters so they can be adjusted to specific datasets
    and tasks, can be very useful. For graph analytics, we have such a toolkit; it’s
    a *graph algorithm library*, or *graph data science library*, as they are sometimes
    known. Earlier in the book, we described graph algorithms as a type of graph query,
    used a similarity algorithm, and mentioned a few other algorithm types like shortest
    path. We’ve intentionally kept their use to a minimum until this chapter, where
    we can go into depth.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一些分析任务需要编写定制的数据库查询：所提出的问题在数据集和用例中是独特的。在其他情况下，分析问题是相当常见的。拥有一套标准分析工具库，可以根据特定数据集和任务进行调整，这将非常有用。对于图分析，我们有这样一套工具包；它是一个
    *图算法库* 或 *图数据科学库*，有时也被称为。在本书的早期章节中，我们描述了图算法作为图查询的一种类型，使用了相似度算法，并提到了一些其他算法类型，如最短路径。直到本章，我们才有意保持它们的使用最少。
- en: Graph Algorithms as Tools
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作为工具的图算法
- en: First, let’s define the term *algorithm*. An algorithm is an unambiguous, step-by-step,
    and finite set of instructions to perform a specific task. Think of an algorithm
    like a precise recipe. When you have an algorithm for a task, you know the task
    is achievable. For a subclass called *deterministic algorithms*, the same input
    always yields the same output, no matter who performs the algorithm or when. Algorithms
    aren’t just for analytics. For example, there’s an algorithm for storing your
    color and font size preferences for an ereader, and a companion algorithm for
    applying your preferences every time you start the reader. Those aren’t really
    analytical tasks, but they are tasks nonetheless.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义术语*算法*。算法是一个明确的、逐步的、有限的指令集，用于执行特定的任务。把算法想象成一个精确的配方。当你有一个任务的算法时，你知道这个任务是可以完成的。对于一个称为*确定性算法*的子类，相同的输入总是产生相同的输出，无论是谁执行算法或何时执行。算法不仅仅是用于分析。例如，有一个算法用于存储您电子阅读器的颜色和字体大小偏好，以及一个伴随算法，每次启动阅读器时应用您的偏好。这些虽然不是真正的分析任务，但它们也是任务。
- en: When we say *graph algorithms*, however, it suggests more than just “algorithms
    about graphs.” First, the term usually implies algorithms that are *generic* in
    the sense that they are designed to work on a whole class of graphs—say, any graph
    with undirected edges—rather than only graphs with certain schema and semantic
    details, such as banking transaction graphs. Second, the term *graph algorithms*
    often refers to solutions for *analytical* tasks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我们说*图算法*时，它不仅仅是指“关于图的算法”。首先，该术语通常意味着通用算法，这些算法设计用于处理整个类别的图，比如任何带有无向边的图，而不仅仅是具有特定模式和语义细节的图，例如银行交易图。其次，术语*图算法*通常指解决*分析*任务的解决方案。
- en: By focusing on generic analytical tasks, graph algorithms become excellent tools
    for graph analytics. Over the years, theorists and data analysts have identified
    a number of common and generic analytical tasks for graphs, and have developed
    algorithms to perform these tasks. A graph algorithm library is a thoughtful collection
    of graph algorithms, able to perform a variety of different tasks. The library
    collection is crafted to span a breadth of useful functions, and hence it is a
    toolkit.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通过专注于通用分析任务，图算法成为图分析的优秀工具。多年来，理论家和数据分析师已经确定了一些常见和通用的图分析任务，并开发了执行这些任务的算法。图算法库是一组精心设计的图算法，能够执行各种不同的任务。该库的收藏被制作以跨越广泛的有用功能，因此它是一个工具包。
- en: Just as with skilled trades like woodworking or automobile repair, data analytics
    requires training and experience to use the tools well. As a graph algorithm user,
    you need to learn what types of tasks you can perform with each algorithm, what
    type of material (data) it is designed for, what is the right way to use it, and
    when not to use it at all. As you grow in sophistication, you will better appreciate
    the trade-offs between algorithms that perform similar functions. You will also
    see innovative ways to use an algorithm and how using algorithms in combination
    can perform more complex and sophisticated tasks than any single algorithm.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 就像木工或汽车维修等熟练工艺一样，数据分析需要训练和经验才能熟练使用工具。作为图算法用户，你需要学习每种算法可以执行的任务类型，它设计用于什么类型的材料（数据），如何正确使用它，以及何时不使用它。随着你的专业水平提高，你会更好地理解执行类似功能的算法之间的权衡。你还会看到使用算法的创新方法以及如何结合使用多个算法来执行比任何单一算法更复杂和精密的任务。
- en: 'Because we are talking about software and data, data analysts have one advantage
    over craftspersons using forged steel tools on wood and metal materials: our tools
    and our materials are extremely malleable. As an algorithm user, it is helpful
    but not essential to understand how an algorithm works. By analogy, you don’t
    need to know how to design a voltmeter in order to measure a battery’s voltage.
    However, if you want to modify an algorithm to better fit your situation, then
    it is necessary to understand that algorithm at least in part.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们谈论的是软件和数据，数据分析师在使用锻造钢工具处理木材和金属材料的工匠之上有一个优势：我们的工具和材料非常易于塑形。作为算法用户，了解算法如何运作虽然有帮助但并非必须。类比而言，你不需要知道如何设计电压表就能测量电池的电压。然而，如果你想修改一个算法以更好地适应你的情况，那么至少在某种程度上了解该算法是必要的。
- en: 'Any user of graph algorithms needs to follow one cautionary note: apply an
    algorithm only to those vertices and edges that are semantically appropriate for
    your desired analysis. Most real-world graphs contain multiple types of vertices
    and edges, each with their own semantic roles. For example, we might have **`Book`**
    and **`Reader`** vertices and **`Bought`**, **`Read`**, and **`Reviewed`** edges.
    While you could run PageRank on the whole graph, the results would not make much
    sense, because it doesn’t make sense to rank **`Books`** and **`Readers`** on
    the same scale. Due to their generic nature, most graph algorithms ignore semantic
    typing. Whether your analysis will be meaningful when types are ignored is something
    that you will have to decide.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 任何使用图算法的用户都需要注意一点：仅将算法应用于与您所需分析的语义相关的顶点和边。大多数现实世界的图包含多种类型的顶点和边，每种都有其自己的语义角色。例如，我们可能有
    **`书籍`** 和 **`读者`** 的顶点以及 **`购买`**，**`阅读`** 和 **`评论`** 的边。虽然您可以在整个图上运行 PageRank，但结果可能毫无意义，因为将
    **`书籍`** 和 **`读者`** 放在同一尺度上并没有意义。由于它们的通用性质，大多数图算法忽略语义类型。当忽略类型时，您的分析是否有意义是您需要决定的事情。
- en: 'We’ve covered a lot of important concepts so far, so let’s summarize:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了许多重要的概念，所以让我们总结一下：
- en: Graph analytics leverages data connections to obtain deeper insights about the
    data.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图分析利用数据连接来深入了解数据。
- en: Breadth-first search, parallel processing, and aggregation are key ingredients
    of efficient graph analytics.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广度优先搜索、并行处理和聚合是有效图分析的关键要素。
- en: Graph algorithms act as tools for common graph analytics tasks.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图算法作为常见图分析任务的工具。
- en: You can perform more complex tasks by using them in combination.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过组合使用它们可以执行更复杂的任务。
- en: Using graph algorithms is a craft. The more you know about the tools and the
    materials, the better a craftsperson you will be.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图算法是一种工艺。你对工具和材料了解得越多，你的工艺水平就越高。
- en: '[Table 6-1](#glossary_of_graph_analytics_and_algorit) shows the key terminologies
    of data analytics and algorithms that we have introduced in this chapter.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 6-1](#glossary_of_graph_analytics_and_algorit) 展示了本章介绍的数据分析和算法的关键术语。'
- en: Table 6-1\. Glossary of graph analytics and algorithm terms
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-1\. 图分析和算法术语表
- en: '| Term | Definition |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 术语 | 定义 |'
- en: '| --- | --- |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Data analytics | The process of analyzing data using statistical methods
    to obtain insights |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 数据分析 | 使用统计方法分析数据以获得洞察 |'
- en: '| Graph analytics | A subset of data analytics that focuses on analyzing relationships
    between entities in a graph |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 图分析 | 专注于分析图中实体之间关系的数据分析子集 |'
- en: '| Algorithm | An unambiguous, step-by-step, and finite set of instructions
    to perform a specific task |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | 一组明确的、逐步的和有限的指令，用于执行特定任务 |'
- en: '| Deterministic algorithm | A subset of algorithms where the same inputs will
    always produce the same results |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 确定性算法 | 一类算法，其相同输入将始终产生相同结果 |'
- en: '| Graph algorithm | A subset of algorithms that are generic for a class of
    graphs and a solution to analyze graph structures |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 图算法 | 一类通用于图类和分析图结构的算法子集 |'
- en: '| Walk/traverse a graph | The process of exploring the vertices and edges of
    the graph in a specific order from the present position |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 遍历/穿越图 | 探索图中顶点和边的过程，按照特定顺序从当前位置进行 |'
- en: Graph Algorithm Categories
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图算法类别
- en: 'Consider a couple more examples of graph analytics tasks:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 再考虑几个图分析任务的例子：
- en: Community ranking
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 社区排名
- en: In a social network, rank subcommunities based on the average number of new
    discussions per member per week.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在社交网络中，根据每位成员每周的平均新讨论次数对子社区进行排名。
- en: Similar patient profiles
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 相似患者档案
- en: Given a patient with certain symptoms, personal background, and treatment to
    date, find similar patients so that successes and setbacks can be compared, leading
    to better overall care.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 给定某患者的特定症状、个人背景和迄今为止的治疗，找到类似的患者，以便比较成功和挫折，从而实现更好的整体护理。
- en: The first task presumes we have well-defined communities. In some cases, we
    want communities defined not by labels but by actual social behavior. We have
    graph algorithms to find communities based on connections and relational behavior.
    The second task presumes we have a way to measure similarity. There is also a
    family of algorithms for graph-based similarity.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个任务假设我们有明确定义的社群。在某些情况下，我们希望社群不是通过标签定义，而是通过实际的社交行为定义。我们有图算法来基于连接和关系行为来找到社群。第二个任务假设我们有一种衡量相似度的方法。还有一类基于图的相似度算法。
- en: 'This section provides an overview of the most common graph algorithms and algorithm
    categories in graph analytics today. We will look at five categories:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 本节概述了今天图分析中最常见的图算法和算法类别。我们将看到五类：
- en: Paths and trees
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径和树
- en: Centrality
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中心性
- en: Community
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社群
- en: Similarity
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相似度
- en: Classification and prediction
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类和预测
- en: Path and tree algorithms
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 路径和树算法
- en: One of the classic graph-based tasks is to find the *shortest path* from one
    vertex to another. Knowing a shortest path is useful not only for finding the
    best delivery and communication routes but also for seeing if persons or processes
    are closely associated. Is this person or organization closely associated with
    parties of concern? We can also use shortest path analysis to check the lineage
    or provenance of a document or other product.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最经典的基于图的任务之一是从一个顶点到另一个顶点找到*最短路径*。知道最短路径不仅有助于找到最佳的传递和通信路线，还有助于查看个人或流程是否紧密相关。这个人或组织是否与关注的方面密切相关？我们还可以使用最短路径分析来检查文档或其他产品的谱系或来源。
- en: 'The task might seem easy, but consider this example: suppose you wanted to
    get in touch with a famous but private person, say Keanu Reeves. It is a personal
    matter, so you can only go through personal contacts, and the fewer intermediary
    contacts, the better. You don’t know which of your acquaintances might know this
    person. Therefore, you ask all of them if they know Mr. Reeves. None of them do,
    so would they please ask their acquaintances? Every contact asks their acquaintances
    to check until finally someone knows Keanu Reeves personally.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这个任务看起来可能很简单，但请考虑这个例子：假设你想联系一个著名但是很私人的人，比如基努·里维斯。这是一件私人事务，所以你只能通过个人联系，中间联系越少越好。你不知道你的熟人中谁可能认识这个人。因此，你询问所有人是否认识里维斯先生。没有人认识他，所以请他们问问他们的熟人？每个联系人都请他们的熟人检查，直到最终有人认识基努·里维斯个人。
- en: This connection-of-a-connection process is exactly how we find shortest paths
    in an unweighted graph. It is in fact breadth-first search. You can see how parallel
    processing would be appropriate. All of your acquaintances can work simultaneously
    to check their acquaintances.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种连接-连接的过程正是我们在无权图中找到最短路径的方式。事实上，这就是广度优先搜索。你可以看到并行处理是合适的。你的所有熟人可以同时工作，检查他们的熟人。
- en: '[Figure 6-2](#unweighted_shortest_path) shows an example. In round 1, you (vertex
    A) check all of your direct connections (B, C, and D). Each of them gets marked
    with a 1\. In round 2, each of these newly visited vertices checks their connections.
    B has two connections (A and E), but only E is new. C has three connections, but
    only F is new. D has no connections that have not been visited before. Therefore,
    E and F are our new “frontier” vertices and are marked with a 2\. In round 3,
    G and H are our frontier vertices. H is in fact Keanu Reeves, so we are done.
    Note that there are two paths: A-B-E-H and A-C-F-H. Also note that while we were
    looking for the path to Keanu Reeves, we also found paths to intermediate vertices
    like E and F.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 6-2](#unweighted_shortest_path) 给出了一个例子。在第一轮中，你（顶点 A）检查所有直接连接（B、C 和 D）。它们每个都被标记为
    1\. 在第二轮中，每个新访问的顶点检查它们的连接。B 有两个连接（A 和 E），但只有 E 是新的。C 有三个连接，但只有 F 是新的。D 没有未被访问过的连接。因此，E
    和 F 是我们的新的“前沿”顶点，并被标记为 2\. 在第三轮中，G 和 H 是我们的前沿顶点。事实上，H 就是基努·里维斯，所以我们完成了。请注意，存在两条路径：A-B-E-H
    和 A-C-F-H。还请注意，虽然我们正在寻找通往基努·里维斯的路径，但我们也找到了通往中间顶点如 E 和 F 的路径。'
- en: '![Unweighted shortest path](assets/gpam_0602.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![无权最短路径](assets/gpam_0602.png)'
- en: Figure 6-2\. Unweighted shortest path
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-2\. 无权最短路径
- en: 'How much compute effort does it take to get our answer? It depends on how close
    our destination happens to be. Computer scientists often look at the worst case
    or average effort. Since our algorithm finds paths to intermediate vertices, what
    if we change that task: find a path starting from one source and to every destination?
    If we traverse every edge in the graph exactly once, we should be able to get
    our answer. Actually, we might need to traverse twice: initially, we attempt A→B,
    then later B→A and discover that we have already been to A. We’ll need to mark
    each vertex as visited, set a distance, and later check that it’s been visited.
    So we have some activities that scale with the number of edges (E), and some that
    scale with the number of vertices (V). So the total amount of effort is on the
    order of E + V. In standard notation, we say it is O(E + V), pronounced “big oh
    E plus V.” In a connected graph, E is always at least as big as V, and we care
    about the biggest factor, so we can simplify it to O(E).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要得到我们的答案需要多少计算工作？这取决于我们的目标离起点有多近。计算机科学家通常考虑最坏情况或平均情况的工作量。由于我们的算法找到中间顶点的路径，如果我们改变任务：从一个起点到每个目标的路径，我们应该能够得到我们的答案。实际上，我们可能需要遍历两次：最初，我们尝试
    A→B，然后稍后 B→A 并发现我们已经到达了 A。我们需要标记每个顶点是否已访问，设置一个距离，稍后检查是否已访问。所以我们有一些活动与边的数量 (E)
    成比例，一些与顶点的数量 (V) 成比例。因此，总工作量大致为 E + V。在标准符号中，我们说它是 O(E + V)，读作“大O E 加 V”。在一个连通图中，E
    至少与 V 一样大，我们关心最大的因素，所以我们可以简化为 O(E)。
- en: What if some connections are better than others? For example, it might be three
    blocks from your house to a store, but some blocks are longer than others. This
    is the *shortest path in a weighted graph* problem. When the edges are weighted,
    we have to proceed more carefully, because a path with more steps might still
    be the less costly one. In [Figure 6-3](#weighted_shortest_path), we have added
    weights to the edges and displayed the first two rounds of a modified search algorithm,
    attributed to computer science pioneer Edsger Dijkstra. First, we initialize every
    vertex with the length of the best-known path. Since we don’t know any paths yet
    (except from A to A), every distance is set to infinity at first. Then in round
    1, we traverse from A to each of its neighbors. We label each of them with the
    actual length of the edge traversed plus the distance from the source of that
    edge back to the starting point. For example, to get to B, the total distance
    is the weight of edge A-B, plus the distance of source A back to the starting
    point, distance(A,A) = 2 + 0 = 2.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有些连接比其他连接更好怎么办？例如，从你家到商店可能有三个街区，但有些街区比其他街区长。这是加权图中的 *最短路径* 问题。当边被赋权值时，我们必须更加小心，因为步数更多的路径可能仍然是成本较低的路径。在
    [图 6-3](#weighted_shortest_path) 中，我们给边赋权值，并展示了修改后的搜索算法的前两轮，这个算法归功于计算机科学先驱艾兹格·迪克斯特拉。首先，我们初始化每个顶点的最佳路径长度。因为我们还不知道任何路径（除了从
    A 到 A），所以每个距离最初都被设为无穷大。然后在第一轮中，我们从 A 遍历到每个邻居顶点。我们用穿过的边的实际长度加上该边从源顶点回到起点的距离来标记它们。例如，要到达
    B，总距离是边 A-B 的权重加上从源点 A 返回起点的距离，即 distance(A,A) = 2 + 0 = 2。
- en: '![Weighted shortest path](assets/gpam_0603.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![加权最短路径](assets/gpam_0603.png)'
- en: Figure 6-3\. Weighted shortest path
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-3\. 加权最短路径
- en: In the next round, we traverse from the frontier vertices to *all* of their
    neighbors. Here we see a difference from the unweighted path algorithm. We consider
    the path from D to C, even though C has been visited before. We see that the path
    A-D-C has a total length of weight(A,D) + distance(D,C) = 2 + 1 = 3\. This is
    less than the length of the path A-C = 4\. C will be marked with the path and
    length of the *shortest* of the several paths found so far. In a weighted graph,
    even after we have found a path, we might need to keep searching to see if there
    is a path with more hops but less total weight. For this reason, finding the shortest
    path in a weighted graph takes more compute effort than in an unweighted graph.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的轮次中，我们从前沿顶点遍历到它们 *所有* 的邻居。这里我们看到与无权路径算法的差异。我们考虑从 D 到 C 的路径，即使 C 之前已经被访问过。我们看到路径
    A-D-C 的总长度为 weight(A,D) + distance(D,C) = 2 + 1 = 3。这比路径 A-C = 4 的长度要小。C 将被标记为到目前为止找到的
    *最短* 路径及其长度。在加权图中，即使找到了一条路径，我们可能需要继续搜索，看看是否有更多跳数但总权重更少的路径。因此，在加权图中找到最短路径比在无权图中需要更多的计算工作。
- en: We’ll consider one more path task, the *minimal spanning tree* (MST) problem.
    In graph theory, a tree is a set of N vertices and exactly N−1 edges that connect
    the vertices. An interesting side effect is that there will be exactly one path
    in the tree to get from each vertex to each other vertex. A minimal spanning tree
    in a weighted graph is a tree that has the least total edge weight. One use of
    MST is to provide connectivity at the lowest total cost, such as paving the least
    amount of road or provisioning the least amount of network cable.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将考虑另一个路径任务，即*最小生成树*（MST）问题。在图论中，树是一组N个顶点和恰好N−1条连接这些顶点的边。一个有趣的副作用是树中将会有一条确切的路径从每个顶点到其他每个顶点。在加权图中，最小生成树是具有最小总边权重的树。MST的一个用途是以最低总成本提供连接性，例如铺设最少的道路或配置最少的网络电缆。
- en: 'There are several algorithms of similar efficiency for solving the MST problem.
    Prim’s algorithm is perhaps the simplest to describe. We’ll use [Figure 6-4](#minimal_spanning_tree)
    as an example:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 解决MST问题有几种类似效率的算法。Prim算法可能是最简单的描述。我们将以[图 6-4](#minimal_spanning_tree)为例：
- en: Make a list of all the edges, sorted by weight.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制作一个按权重排序的所有边的列表。
- en: Pick an edge with least weight (C-D). Every edge we pick becomes part of our
    tree.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择最小权重的边（C-D）。我们选择的每条边都成为我们树的一部分。
- en: 'Pick the lightest edge that has one end in the partial tree and one end not:
    (A-D).'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择具有一个端点在部分树中的最轻的边：(A-D)。
- en: Repeat step 3 until we have a total of N−1 edges.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤3，直到我们总共有N−1条边。
- en: '![Minimal spanning tree](assets/gpam_0604.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![最小生成树](assets/gpam_0604.png)'
- en: Figure 6-4\. Minimal spanning tree
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-4\. 最小生成树
- en: Following these rules, the next selected edges will be A-B, B-E, E-F, and F-H.
    Then we have a tie. Both E-G and H-G have a weight of 3, so either one can be
    used to complete our tree.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些规则，下一个选择的边将是A-B，B-E，E-F和F-H。然后我们有一个平局。E-G和H-G的权重都是3，所以可以使用任何一个来完成我们的树。
- en: Centrality algorithms
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中心度算法
- en: Which is the most centrally located vertex in a graph? That depends on how we
    define centrality. The TigerGraph Graph Data Science (GDS) Library has more than
    10 different centrality algorithms.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中哪个顶点位置最中心？这取决于我们如何定义中心度。TigerGraph图数据科学（GDS）库有超过10种不同的中心度算法。
- en: '*Closeness centrality* scores each vertex based on the average distance from
    it to every other vertex in the graph. Typically, we invert this average distance,
    so that we get higher scores for shorter distances. Closeness centrality matters
    to organizations that want to select the best location for their retail store,
    government office, or distribution center. If they want to minimize the average
    distance that patrons or packages need to travel, they use closeness centrality.
    How do we measure distance? Shortest path algorithms can do this. While there
    are more efficient ways to measure average distance than to calculate every individual
    shortest path, the principle still holds: algorithms can be building blocks for
    solving more complex problems. There are variations of closeness centrality for
    directed graphs and for weighted graphs.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*接近中心度*根据顶点到图中每个其他顶点的平均距离评分。通常我们倒转这个平均距离，以便在距离更短时得到更高的分数。接近中心度对于希望选择最佳位置的组织至关重要，无论是零售店、政府办公室还是配送中心。如果他们希望最小化顾客或包裹需要行进的平均距离，他们就会使用接近中心度。我们如何测量距离？最短路径算法可以做到这一点。虽然有更有效的方法来测量平均距离，而不是计算每个单独的最短路径，但原则仍然成立：算法可以作为解决更复杂问题的基本组成部分。有针对有向图和加权图的接近中心度变体。'
- en: Let’s compute some closeness centralities for the weighted graph in [Figure 6-4](#minimal_spanning_tree).
    Vertices E and F look like they might be near the center. For E, we want the shortest
    path distances to A, B, C, D, F, G, and H. By visual inspection, we see that the
    distances are 4 + 2 + 5 + 6 + 2 + 3 + 4 = 26\. For F, we want distances to A,
    B, C, D, E, G, and H, which are 6 + 4 + 3 + 4 + 2 + 5 + 2 = 26, so it’s a tie.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算[图 6-4](#minimal_spanning_tree)中加权图的一些中心度。顶点E和F看起来可能靠近中心。对于E，我们需要计算到A、B、C、D、F、G和H的最短路径距离。通过目测，我们可以看到距离为4
    + 2 + 5 + 6 + 2 + 3 + 4 = 26\. 对于F，我们需要计算到A、B、C、D、E、G和H的距离，距离分别为6 + 4 + 3 + 4
    + 2 + 5 + 2 = 26，所以它们平局。
- en: '*Harmonic centrality* is a minor variation of closeness centrality. Instead
    of being the inverse of the average distance, harmonic centrality is the average
    (or sum) of the inverse distances. One advantage of harmonic centrality is that
    it can deal with unconnected vertices by saying their distance is infinite, whose
    inverse value is simply zero. This brings up a key point when selecting an algorithm:
    do you need to handle unconnected vertices?'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*谐度中心性*是接近中心性的一个小变种。谐度中心性不是平均距离的倒数，而是距离的倒数的平均（或总和）。谐度中心性的一个优点是，它可以通过将它们的距离视为无穷来处理未连接的顶点，其倒数值简单地为零。这带来了选择算法时的一个关键点：您是否需要处理未连接的顶点？'
- en: '*Betweenness centrality* poses a different situation: suppose you consider
    all the shortest paths in a graph, from each vertex to each other vertex. If there
    are multiple shortest paths (as we saw in [Figure 6-2](#unweighted_shortest_path)),
    consider all of them. Which vertex sits on the most paths? A vertex with high
    betweenness is not necessarily the destination, but it will get a lot of pass-through
    traffic. Whether you are trying to find the best location for a gas station or
    assessing which network routers are most vital, betweenness can be a key measure.
    Again, we see that one algorithm (shortest path) is a building block for another
    (betweenness).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*介数中心性*提出了一个不同的情境：假设您考虑图中所有顶点之间的最短路径，从每个顶点到其他每个顶点。如果存在多条最短路径（正如我们在[图6-2](#unweighted_shortest_path)中看到的），则考虑所有这些路径。哪个顶点位于最多的路径上？具有高介数的顶点不一定是目的地，但它将获得大量的通过流量。无论您是要找出最佳的加油站位置还是评估哪些网络路由器最为关键，介数都可能是一个关键的度量。再次看到，一个算法（最短路径）是另一个算法（介数）的基础构件。'
- en: It might surprise you to know that PageRank can be categorized as a centrality
    algorithm. PageRank was designed to find the most important web pages on the internet.
    More precisely, PageRank measures *referential authority* in which a page’s importance
    increases if more pages point to it or if the authority of those pages is higher.
    Another way of looking at it is the *random surfer* model.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 也许让你惊讶的是，PageRank可以被归类为中心性算法。PageRank旨在找出互联网上最重要的网页。更准确地说，PageRank衡量的是*引用权威*，即如果更多的页面指向某页面或者这些页面的权威性更高，则该页面的重要性会增加。另一种看待它的方式是*随机冲浪者*模型。
- en: Imagine someone is surfing the internet. They start on a random page. Each minute,
    the surfer goes to another page. Most of the time, they follow a link on that
    page to another page; every link has equal probability of being chosen. There
    is a small fixed probability of not following a link and just going directly to
    a random page. After a very long time, what is the probability that the random
    surfer will be on a particular page? The probability is that page’s PageRank score.
    Pages that get visited more often due to the graph’s pattern of connections are
    deemed to have higher centrality. The mathematical magic of PageRank is that the
    rankings aren’t affected by where you start the random walk. Note that PageRank
    is designed for directed graphs, whereas most of the tasks we have looked at so
    far are sensible for either directed or undirected graphs.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 想象有人在互联网上冲浪。他们从一个随机页面开始。每分钟，冲浪者转到另一个页面。大多数时候，他们会点击页面上的链接转到另一页；每个链接被选择的概率相等。还有一小部分固定的概率不会跟随链接，而是直接转到另一个随机页面。经过很长时间后，随机冲浪者会在特定页面的概率是多少？这个概率就是该页面的PageRank分数。由于图的连接模式，被访问频率更高的页面被认为具有更高的中心性。PageRank的数学魔力在于，排名不受开始随机行走的位置影响。请注意，PageRank是针对有向图设计的，而我们迄今看到的大多数任务对有向或无向图都是合理的。
- en: Community algorithms
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 社区算法
- en: Another meaningful analysis of graphs is to understand the implicit groupings
    of vertices, based on how they connect to one another. High levels of interaction
    imply high levels of influence, resilience, or information passing, which is useful
    to understand and predict everything from market segmentation and fraudster behavior
    to group resilience to viral spread of ideas or biological contagions.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图的另一个有意义的分析是理解顶点之间的隐式分组，基于它们如何相互连接。高水平的互动意味着高水平的影响力、韧性或信息传递，这对于理解和预测市场细分、欺诈者行为、群体韧性以及思想或生物传播的病毒性传播等方面非常有用。
- en: There are a number of possible ways to define a community, each with a corresponding
    algorithm or algorithms. We can sort them based on how many connections to the
    community are required to be considered part of the community. At the low end
    of the spectrum, when only a single connection is sufficient to be considered
    part of the community, we call the group a *connected component*, or just *component*
    for short. At the high end for connectivity, when every vertex has a direct connection
    to every other community member, this is a *complete subgraph*. The vertices of
    a complete subgraph constitute a *clique*. In between these extremes are k-cores.
    A *k-core* is a subgraph where every vertex has direct connections to k or more
    other members.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 定义社区的方法有多种，每种方法都对应一个或多个算法。我们可以根据加入社区所需的连接数量将它们排序。在谱的低端，当仅需要一个连接即可被视为社区的一部分时，我们称之为*连通分量*，或简称*组件*。在连接性的高端，当每个顶点都与每个其他社区成员直接连接时，这被称为*完全子图*。完全子图的顶点构成*团*。在这两个极端之间是
    k 核心。*k 核心*是一个子图，其中每个顶点与 k 个或更多其他成员有直接连接。
- en: Note
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: A connected component is a k-core where k = 1\. A clique containing c vertices
    is a k-core where k = (c –1), the largest possible value for k.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 连通分量是 k 核心，其中 k = 1\. 包含 c 个顶点的团是 k 核心，其中 k = (c –1)，这是 k 的最大可能值。
- en: '[Figure 6-5](#community_types_classified_by_density_o) shows these three classes
    of communities applied to the same graph. On the left, every vertex is a member
    of one of three connected components. In the center graph, we have two k-cores
    for k = 2, but four vertices are excluded. On the right, we have two small cliques;
    many vertices do not qualify.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 6-5](#community_types_classified_by_density_o)展示了应用于同一图的这三类社区。在左图中，每个顶点都是三个连通分量中的一个成员。在中心图中，我们有两个
    k = 2 的 k 核心，但有四个顶点被排除在外。在右图中，我们有两个小团；许多顶点不符合资格。'
- en: '![Community types classified by density of connection](assets/gpam_0605.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![通过连接密度分类的社区类型](assets/gpam_0605.png)'
- en: Figure 6-5\. Community types classified by density of connection
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-5\. 通过连接密度分类的社区类型
- en: Any of these definitions can enforce edge directionality; for connected components,
    we even have names for this. If the edges are undirected (or we ignore the directionality),
    then we call it a *weakly connected component* (WCC). If the edges are directed
    and it is possible for each vertex to reach every other vertex by following a
    directed path, then it is a *strongly connected component* (SCC)**.** In [Figure 6-6](#weakly_and_strongly_connected_component),
    we add directionality to the edges of our example graph and see how this can rule
    out some vertices.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些定义都可以强制边的方向性；对于连通分量，我们甚至有相应的名称。如果边是无向的（或者我们忽略方向性），那么我们称之为*弱连接组件*（WCC）。如果边是有向的，并且每个顶点可以通过跟随有向路径到达每个其他顶点，那么它是*强连接组件*（SCC）**。**在[图 6-6](#weakly_and_strongly_connected_component)中，我们为我们的示例图的边添加了方向性，并看到这如何排除一些顶点。
- en: '![Weakly and strongly connected components](assets/gpam_0606.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![弱连接组件和强连接组件](assets/gpam_0606.png)'
- en: Figure 6-6\. Weakly and strongly connected components
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-6\. 弱连接组件和强连接组件
- en: The preceding definitions of community all have strict definitions, but in some
    real-life applications, a more flexible definition is needed. We want communities
    that are *relatively* well connected. To address this, network scientists came
    up with a measure called *modularity*, which looks at relative density, comparing
    the density within communities versus the density of connections between communities.
    This is like looking at the density of streets within cities versus the road density
    between cities. Now imagine the city boundaries are unknown; you just see the
    roads. If you propose a set of city boundaries, modularity will rate how good
    a job you did of maximizing the goal of “dense inside; not dense outside.” Modularity
    is a scoring system, not an algorithm. A modularity-based community algorithm
    finds the community boundaries that produce the highest modularity score.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 上述社区的定义都有严格的定义，但在一些现实应用中，需要更灵活的定义。我们希望社区*相对*连接良好。为了解决这个问题，网络科学家提出了一种称为*模块度*的度量方法，它考虑了相对密度，比较社区内的密度与社区间连接的密度。这就像看城市内街道的密度与城市之间道路密度一样。现在想象一下，城市边界未知；你只能看到道路。如果你提出一组城市边界，模块度将评估你在最大化“内部密集；外部不密集”目标方面的表现。模块度是一个评分系统，而不是一个算法。基于模块度的社区算法找到产生最高模块度分数的社区边界。
- en: 'To measure modularity (Q), we first partition the vertices into a set of communities
    so that every vertex belongs to one community. Then, considering each edge as
    one case, we calculate some totals and averages:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要测量模块度（Q），我们首先将顶点分成一组社区，使得每个顶点属于一个社区。然后，考虑每条边作为一个案例，我们计算一些总数和平均数：
- en: Q = [actual fraction of edges that fall within a community]
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Q = [落在一个社区内的实际边的分数]
- en: ''
  id: totrans-123
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: minus [expected fraction of edges if edges were distributed at random]
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 减去[如果边是随机分布的话，期望的边的分数]
- en: '“Expected” is used in the statistical sense. If you flip a coin many times,
    you expect 50/50 odds of heads versus tails. Modularity can handle weighted edges
    by using weights instead of simple counts:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: “期望”在统计学上有特定含义。如果你抛硬币很多次，你期望头和尾的概率是50/50。模块度可以通过使用权重而不是简单计数来处理加权边：
- en: Q = [average weight of edges that fall within a community]
  id: totrans-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Q = [落在一个社区内的边的平均权重]
- en: ''
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: minus [expected weight of edges if edges were distributed at random]
  id: totrans-128
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 减去[如果边是随机分布的话，期望的边的权重]
- en: Note that the average is taken over the total number of edges. Edges that run
    from one community to another add zero to the numerator and add their weight to
    the denominator. It is designed this way so that edges that run between communities
    hurt your average and lower your modularity score.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，平均数是在总边数上取的。从一个社区到另一个社区的边对分子没有贡献，但对分母有贡献。设计成这样是为了使跨社区的边影响你的平均数并降低模块度得分。
- en: 'What do we mean by “distributed at random”? Each vertex *v* has a certain number
    of edges that connect to it: the *degree* of a vertex is *d*(*v*) = total number
    (or total weight) of *v*’s edges. Imagine that each of these *d*(*v*) edges picks
    a random destination vertex. The bigger *d*(*v*) is, the more likely that one
    or more of those random edges will make a connection to a particular destination
    vertex. The expected (i.e., statistical average) number of connections between
    a vertex *v*1 and a vertex *v*2 can be computed as:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: “随机分布”是什么意思呢？每个顶点 *v* 都有若干条连接到它的边：顶点的 *度* 定义为 *d*(*v*) = *v* 的边的总数（或总权重）。想象一下，这些
    *d*(*v*) 条边中的每一条都随机选择一个目标顶点。顶点 *v* 的度越大，其随机边与特定目标顶点建立连接的可能性越大。顶点 *v*1 和 *v*2 之间的期望（即统计平均）连接数可以计算为：
- en: <math alttext="upper E Subscript r a n d Baseline left-bracket w t left-parenthesis
    v Baseline 1 comma v Baseline 2 right-parenthesis right-bracket equals StartFraction
    d left-parenthesis v Baseline 1 right-parenthesis d left-parenthesis v Baseline
    2 right-parenthesis Over 2 m EndFraction"><mrow><msub><mi>E</mi> <mrow><mi>r</mi><mi>a</mi><mi>n</mi><mi>d</mi></mrow></msub>
    <mrow><mo>[</mo> <mi>w</mi> <mi>t</mi> <mrow><mo>(</mo> <mi>v</mi> <mn>1</mn>
    <mo>,</mo> <mi>v</mi> <mn>2</mn> <mo>)</mo></mrow> <mo>]</mo></mrow> <mo>=</mo>
    <mfrac><mrow><mi>d</mi><mo>(</mo><mi>v</mi><mn>1</mn><mo>)</mo><mi>d</mi><mo>(</mo><mi>v</mi><mn>2</mn><mo>)</mo></mrow>
    <mrow><mn>2</mn><mi>m</mi></mrow></mfrac></mrow></math>
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <math alttext="upper E Subscript r a n d Baseline left-bracket w t left-parenthesis
    v Baseline 1 comma v Baseline 2 right-parenthesis right-bracket equals StartFraction
    d left-parenthesis v Baseline 1 right-parenthesis d left-parenthesis v Baseline
    2 right-parenthesis Over 2 m EndFraction"><mrow><msub><mi>E</mi> <mrow><mi>r</mi><mi>a</mi><mi>n</mi><mi>d</mi></mrow></msub>
    <mrow><mo>[</mo> <mi>w</mi> <mi>t</mi> <mrow><mo>(</mo> <mi>v</mi> <mn>1</mn>
    <mo>,</mo> <mi>v</mi> <mn>2</mn> <mo>)</mo></mrow> <mo>]</mo></mrow> <mo>=</mo>
    <mfrac><mrow><mi>d</mi><mo>(</mo><mi>v</mi><mn>1</mn><mo>)</mo><mi>d</mi><mo>(</mo><mi>v</mi><mn>2</mn><mo>)</mo></mrow>
    <mrow><mn>2</mn><mi>m</mi></mrow></mfrac></mrow></math>
- en: 'where *m* is the total number of edges in the graph. For the mathematically
    inclined, the complete formula for modularity *Q* is:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *m* 是图中总边数。对于数学倾向的人，模块度 *Q* 的完整公式如下：
- en: <math alttext="upper Q equals StartFraction 1 Over 2 m EndFraction sigma-summation
    Underscript i comma j element-of upper G Endscripts left-bracket w t left-parenthesis
    i comma j right-parenthesis minus StartFraction d left-parenthesis i right-parenthesis
    d left-parenthesis j right-parenthesis Over 2 m EndFraction right-bracket delta
    left-parenthesis c o m m left-parenthesis i right-parenthesis comma c o m m left-parenthesis
    j right-parenthesis right-parenthesis"><mstyle displaystyle="true" scriptlevel="0"><mrow><mi>Q</mi>
    <mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>2</mn><mi>m</mi></mrow></mfrac> <munder><mo>∑</mo>
    <mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>∈</mo><mi>G</mi></mrow></munder> <mfenced
    close="]" open="[" separators=""><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo> <mi>i</mi>
    <mo>,</mo> <mi>j</mi> <mo>)</mo></mrow> <mo>-</mo> <mfrac><mrow><mi>d</mi><mo>(</mo><mi>i</mi><mo>)</mo><mi>d</mi><mo>(</mo><mi>j</mi><mo>)</mo></mrow>
    <mrow><mn>2</mn><mi>m</mi></mrow></mfrac></mfenced> <mi>δ</mi> <mrow><mo>(</mo>
    <mi>c</mi> <mi>o</mi> <mi>m</mi> <mi>m</mi> <mrow><mo>(</mo> <mi>i</mi> <mo>)</mo></mrow>
    <mo>,</mo> <mi>c</mi> <mi>o</mi> <mi>m</mi> <mi>m</mi> <mrow><mo>(</mo> <mi>j</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></mstyle></math>
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <math alttext="upper Q equals StartFraction 1 Over 2 m EndFraction sigma-summation
    Underscript i comma j element-of upper G Endscripts left-bracket w t left-parenthesis
    i comma j right-parenthesis minus StartFraction d left-parenthesis i right-parenthesis
    d left-parenthesis j right-parenthesis Over 2 m EndFraction right-bracket delta
    left-parenthesis c o m m left-parenthesis i right-parenthesis comma c o m m left-parenthesis
    j right-parenthesis right-parenthesis"><mstyle displaystyle="true" scriptlevel="0"><mrow><mi>Q</mi>
    <mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>2</mn><mi>m</mi></mrow></mfrac> <munder><mo>∑</mo>
    <mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>∈</mo><mi>G</mi></mrow></munder> <mfenced
    close="]" open="[" separators=""><mi>w</mi> <mi>t</mi> <mrow><mo>(</mo> <mi>i</mi>
    <mo>,</mo> <mi>j</mi> <mo>)</mo></mrow> <mo>-</mo> <mfrac><mrow><mi>d</mi><mo>(</mo><mi>i</mi><mo>)</mo><mi>d</mi><mo>(</mo><mi>j</mi><mo>)</mo></mrow>
    <mrow><mn>2</mn><mi>m</mi></mrow></mfrac></mfenced> <mi>δ</mi> <mrow><mo>(</mo>
    <mi>c</mi> <mi>o</mi> <mi>m</mi> <mi>m</mi> <mrow><mo>(</mo> <mi>i</mi> <mo>)</mo></mrow>
    <mo>,</mo> <mi>c</mi> <mi>o</mi> <mi>m</mi> <mi>m</mi> <mrow><mo>(</mo> <mi>j</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></mstyle></math>
- en: where *wt*(*i*,*j*) is the weight of the edge between *i* and *j*, *comm*(*i*)
    is the community ID of vertex *i*, and <math alttext="delta left-parenthesis a
    comma b right-parenthesis"><mrow><mi>δ</mi> <mo>(</mo> <mi>a</mi> <mo>,</mo> <mi>b</mi>
    <mo>)</mo></mrow></math> is the Kronecker delta function, which equals 1 if *a*
    and *b* are equal and 0 otherwise.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *wt*(*i*,*j*) 是顶点 *i* 和 *j* 之间边的权重，*comm*(*i*) 是顶点 *i* 的社区 ID，<math alttext="delta
    left-parenthesis a comma b right-parenthesis"><mrow><mi>δ</mi> <mo>(</mo> <mi>a</mi>
    <mo>,</mo> <mi>b</mi> <mo>)</mo></mrow></math> 是克罗内克 δ 函数，当 *a* 和 *b* 相等时等于1，否则等于0。
- en: There are a number of algorithms that try to efficiently search for the community
    assignment that yields the highest modularity. [Figure 6-7](#two_possible_community_colorings_for_th)
    shows two possible community groupings, but there is an exponentially large number
    of possible groupings. Therefore, algorithms take some shortcuts and make some
    assumptions to efficiently find a very good answer, if not the best answer.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种算法试图有效地搜索能产生最高模块度的社区分配方案。[图6-7](#two_possible_community_colorings_for_th)展示了两种可能的社区分组，但可能的分组数量呈指数增长。因此，算法采取一些捷径和假设，以有效地找到一个非常好的答案，即使不是最佳答案。
- en: '![Two possible community colorings for the same graph](assets/gpam_0607.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![相同图的两种可能社区着色方案](assets/gpam_0607.png)'
- en: Figure 6-7\. Two possible community colorings for the same graph
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-7\. 相同图的两种可能社区着色方案
- en: The most established modularity optimization algorithm is the *Louvain algorithm*,
    named after the University of Louvain. Louvain starts by considering each individual
    vertex as a community. It then tests each vertex to see if the global modularity
    would be improved by merging it with one of its neighboring communities and treating
    the merged community as a single vertex. After performing one round of mergings,
    it repeats with the new set of larger communities. It stops when merging no longer
    improves the modularity. Several improvements to the speed and clustering quality
    of Louvain have been proposed. The *Leiden algorithm* incorporates many of these
    improvements.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的模块化优化算法是*Louvain算法*，以卢汶大学命名。卢汶算法首先将每个单独的顶点视为一个社区。然后，它测试每个顶点，看看通过将其与相邻社区之一合并并将合并后的社区视为单个顶点是否会提高全局模块度。完成一轮合并后，它会使用新的较大社区集合重复此过程。当合并不再改善模块度时，算法停止。已经提出了多项改进以提高Louvain算法的速度和聚类质量。*Leiden算法*整合了其中许多改进。
- en: Similarity algorithms
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相似性算法
- en: 'What makes two things similar? We usually identify similarities by looking
    at observable or known properties: color, size, function, and so forth. A passenger
    car and a motorcycle are similar because they are both motorized land vehicles
    for one or a few passengers. A motorcycle and a bicycle are similar because they
    are both two-wheeled vehicles. But how do we decide whether a motorcycle is more
    similar to a car or to a bicycle? For that matter, how would we make such decisions
    for a set of persons, products, medical conditions, or financial transactions?
    We need to agree upon a system for measuring similarity. Is there some way that
    we can let the graph itself suggest how to measure similarity?'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 什么使得两个事物相似？通常我们通过观察或已知的属性来识别相似性：颜色、大小、功能等等。乘用车和摩托车之所以相似是因为它们都是为一名或少数乘客提供机动交通的机动车辆。摩托车和自行车之所以相似是因为它们都是两轮车辆。但我们如何决定摩托车更类似于汽车还是自行车？在此之外，对于一组人员、产品、医疗条件或财务交易，我们如何做出这样的决定？我们需要就如何衡量相似性达成一致的系统。有没有一种方法可以让图本身建议如何测量相似性？
- en: 'A graph can give us contextual information to help us decide how to determine
    similarity. Consider the following axiom:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图可以为我们提供上下文信息，帮助我们确定如何确定相似性。考虑以下公理：
- en: An entity is characterized by its properties, its relationships, and its neighborhood.
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 实体由其属性、关系和邻域来描述。
- en: 'Therefore, if two vertices have similar properties, similar relationships,
    and similar neighborhoods, then they should be similar. What do we mean by similar
    neighborhoods? Let’s start with a simpler case—the exact same neighborhood:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果两个顶点具有相似的属性、相似的关系和相似的邻居，则它们应该是相似的。那么什么是相似邻域？我们从一个更简单的情况开始——完全相同的邻域：
- en: Two entities are similar if they connect to the same neighbors.
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果两个实体连接到相同的邻居，则它们是相似的。
- en: In [Figure 6-8](#two_persons_sharing_the_same_neighborho), Person A and Person
    B have three identical types of edges (**`Purchased`**, **`hasAccount`**, and
    **`Knows`**), connecting to the three exact same vertices (Phone model Y, Bank
    Z, and Person C, respectively). It is not necessary, however, to include all types
    of relationships or to give them equal weight. If you care about social networks,
    for example, you can consider only friends. If you care about financial matters,
    you can consider only financial relationships.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 6-8](#two_persons_sharing_the_same_neighborho)中，人员A和人员B有三种相同类型的边缘（**`Purchased`**，**`hasAccount`**和**`Knows`**），分别连接到三个完全相同的顶点（手机型号Y，银行Z和人员C）。然而，并不需要包含所有类型的关系，也不需要赋予它们相同的权重。例如，如果您关心社交网络，可以只考虑朋友关系。如果您关心财务事务，可以只考虑财务关系。
- en: '![Two persons sharing the same neighborhood](assets/gpam_0608.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![两人共享相同邻居](assets/gpam_0608.png)'
- en: Figure 6-8\. Two persons sharing the same neighborhood
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-8\. 两人共享相同邻居
- en: 'To reiterate the difference between community and similarity: all five entities
    in [Figure 6-8](#two_persons_sharing_the_same_neighborho) are part of a connected
    component called *community*. However, we would not say that all five are *similar*
    to one another. The only case of similarity suggested by these relationships is
    Person A being similar to Person B.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了重申社区和相似性之间的区别：在[图 6-8](#two_persons_sharing_the_same_neighborho)中的所有五个实体都是称为*社区*的连通分量的一部分。然而，我们不会说这五个实体互相*相似*。这些关系所暗示的唯一相似性情况是人员A与人员B相似。
- en: Neighborhood similarity
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 邻域相似性
- en: It’s rare to find two entities that have exactly the same neighborhoods. We’d
    like a way to measure and rank the degree of neighborhood similarity. The two
    most common measures for ranking neighborhood similarity are Jaccard similarity
    and cosine similarity. Some others are overlap similarity and Pearson similarity.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 很少能找到两个确切相同邻居的实体。我们希望有一种方法来衡量和排名邻域的相似度。排名邻域相似度的两种最常见的方法是 Jaccard 相似度和余弦相似度。其他一些方法包括重叠相似度和皮尔逊相似度。
- en: Jaccard similarity
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Jaccard 相似度
- en: '*Jaccard similarity* measures the relative overlap between two general sets.
    Suppose you run Bucket List Travel Advisors, and you want to compare your travelers
    to one another based on which destinations they have visited. Jaccard similarity
    would be a good method for you to use; the two sets would be the destinations
    visited by each of two customers being compared. To formulate Jaccard similarity
    in general terms, suppose the two sets are *N*(*a*), the neighborhood of vertex
    *a*, and *N*(*b*), the neighborhood of vertex *b*. Then the Jaccard similarity
    of *a* and *b* is:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*Jaccard 相似度* 用于衡量两个通用集合之间的相对重叠。假设您经营“梦想清单旅行顾问”，您希望根据顾客所访问的目的地来比较他们。Jaccard
    相似度是您可以使用的一种好方法；两个集合将是被比较顾客所访问的目的地。为了在一般情况下阐述 Jaccard 相似度，假设这两个集合分别是 *N*(*a*)，顶点
    *a* 的邻域，和 *N*(*b*)，顶点 *b* 的邻域。那么 *a* 和 *b* 的 Jaccard 相似度为：'
- en: <math display="block"><mtable class="tml-jot tml-align" columnalign="left right
    left right" displaystyle="true" style="width:100%;"><mtr><mtd style="text-align:-webkit-right;"><mrow><mi>j</mi><mi>a</mi><mi>c</mi><mi>c</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo
    form="prefix" stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo
    form="postfix" stretchy="false">)</mo></mrow></mtd><mtd style="text-align:-webkit-left;"><mrow><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mfrac><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>_</mi><mi>o</mi><mi>f</mi><mi>_</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>_</mi><mi>n</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>b</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo
    form="prefix" stretchy="false">(</mo><mi>N</mi><mo form="prefix" stretchy="false">(</mo><mi>a</mi><mo
    form="postfix" stretchy="false">)</mo><mo form="postfix" stretchy="false">)</mo><mo>+</mo><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo
    form="prefix" stretchy="false">(</mo><mi>N</mi><mo form="prefix" stretchy="false">(</mo><mi>b</mi><mo
    form="postfix" stretchy="false">)</mo><mo form="postfix" stretchy="false">)</mo><mo>−</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>_</mi><mi>o</mi><mi>f</mi><mi>_</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>_</mi><mi>n</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>b</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow></mfrac></mstyle></mrow></mtd></mtr><mtr><mtd
    style="text-align:-webkit-left;"><mrow><mo>=</mo><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>_</mi><mi>o</mi><mi>f</mi><mi>_</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>_</mi><mi>n</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>b</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>_</mi><mi>o</mi><mi>f</mi><mi>_</mi><mi>u</mi><mi>n</mi><mi>i</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>_</mi><mi>n</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>b</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow></mfrac></mstyle></mrow></mtd></mtr><mtr><mtd
    style="text-align:-webkit-left;"><mrow><mo>=</mo><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mi>|</mi><mi>N</mi><mo
    form="prefix" stretchy="false">(</mo><mi>a</mi><mo form="postfix" stretchy="false">)</mo><mo>∩</mo><mi>N</mi><mo
    form="prefix" stretchy="false">(</mo><mi>b</mi><mo form="postfix" stretchy="false">)</mo><mi>|</mi></mrow><mrow><mi>|</mi><mi>N</mi><mo
    form="prefix" stretchy="false">(</mo><mi>a</mi><mo form="postfix" stretchy="false">)</mo><mo>∪</mo><mi>N</mi><mo
    form="prefix" stretchy="false">(</mo><mi>b</mi><mo form="postfix" stretchy="false">)</mo><mi>|</mi></mrow></mfrac></mstyle></mrow></mtd></mtr></mtable></math>
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable class="tml-jot tml-align" columnalign="left right
    left right" displaystyle="true" style="width:100%;"><mtr><mtd style="text-align:-webkit-right;"><mrow><mi>j</mi><mi>a</mi><mi>c</mi><mi>c</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo
    form="prefix" stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo
    form="postfix" stretchy="false">)</mo></mrow></mtd><mtd style="text-align:-webkit-left;"><mrow><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mfrac><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>_</mi><mi>o</mi><mi>f</mi><mi>_</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>_</mi><mi>n</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>b</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo
    form="prefix" stretchy="false">(</mo><mi>N</mi><mo form="prefix" stretchy="false">(</mo><mi>a</mi><mo
    form="postfix" stretchy="false">)</mo><mo form="postfix" stretchy="false">)</mo><mo>+</mo><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo
    form="prefix" stretchy="false">(</mo><mi>N</mi><mo form="prefix" stretchy="false">(</mo><mi>b</mi><mo
    form="postfix" stretchy="false">)</mo><mo form="postfix" stretchy="false">)</mo><mo>−</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>_</mi><mi>o</mi><mi>f</mi><mi>_</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>_</mi><mi>n</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>b</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow></mfrac></mstyle></mrow></mtd></mtr><mtr><mtd
    style="text-align:-webkit-left;"><mrow><mo>=</mo><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>_</mi><mi>o</mi><mi>f</mi><mi>_</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>_</mi><mi>n</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>b</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>_</mi><mi>o</mi><mi>f</mi><mi>_</mi><mi>u</mi><mi>n</mi><mi>i</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>_</mi><mi>n</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>b</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow></mfrac></mstyle></mrow></mtd></mtr><mtr><mtd
    style="text-align:-webkit-left;"><mrow><mo>=</mo><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mi>|</mi><mi>N</mi><mo
    form="prefix" stretchy="false">(</mo><mi>a</mi><mo form="postfix" stretchy="false">)</mo><mo>∩</mo><mi>N</mi><mo
    form="prefix" stretchy="false">(</mo><mi>b</mi><mo form="postfix" stretchy="false">)</mo><mi>|</mi></mrow><mrow><mi>|</mi><mi>N</mi><mo
    form="prefix" stretchy="false">(</mo><mi>a</mi><mo form="postfix" stretchy="false">)</mo><mo>∪</mo><mi>N</mi><mo
    form="prefix" stretchy="false">(</mo><mi>b</mi><mo form="postfix" stretchy="false">)</mo><mi>|</mi></mrow></mfrac></mstyle></mrow></mtd></mtr></mtable></math>
- en: The maximum possible score is 1, which occurs if *a* and *b* have exactly the
    same neighbors. The minimum score is 0 if they have no neighbors in common.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 最大可能的分数是1，即如果 *a* 和 *b* 恰好有相同的邻居。最小分数是0，如果它们没有共同的邻居。
- en: 'Consider the following example: three travelers, A, B, and C, have traveled
    to the places shown in [Table 6-2](#dataset_for_jaccard_similarity_examplel).'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下例子：三位旅行者 A、B 和 C，他们去过以下在 [表 6-2](#dataset_for_jaccard_similarity_examplel)
    中显示的地方。
- en: Table 6-2\. Dataset for Jaccard similarity example^([a](ch06.html#ch01fn12))
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-2\. Jaccard 相似度示例的数据集^([a](ch06.html#ch01fn12))
- en: '| Destinations | A | B | C |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 目的地 | A | B | C |'
- en: '| --- | --- | --- | --- |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Amazon Rainforest, Brazil | ✔ | ✔ |   |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 巴西亚马逊雨林 | ✔ | ✔ |   |'
- en: '| Grand Canyon, USA | ✔ | ✔ | ✔ |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 美国大峡谷 | ✔ | ✔ | ✔ |'
- en: '| Great Wall, China | ✔ |   | ✔ |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 中国长城 | ✔ |   | ✔ |'
- en: '| Machu Picchu, Peru | ✔ | ✔ |   |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 秘鲁马丘比丘 | ✔ | ✔ |   |'
- en: '| Paris, France | ✔ |   | ✔ |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 法国巴黎 | ✔ |   | ✔ |'
- en: '| Pyramids, Egypt |   | ✔ |   |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 埃及的金字塔 |   | ✔ |   |'
- en: '| Safari, Kenya |   | ✔ |   |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 肯尼亚的野生动物园 |   | ✔ |   |'
- en: '| Taj Mahal, India |   |   | ✔ |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 印度泰姬陵 |   |   | ✔ |'
- en: '| Uluru, Australia |   | ✔ |   |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 澳大利亚乌鲁鲁 |   | ✔ |   |'
- en: '| Venice, Italy | ✔ |   | ✔ |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 意大利的威尼斯 | ✔ |   | ✔ |'
- en: '| ^([a](ch06.html#ch01fn12-marker)) The use of a table for our small example
    may suggest that a graph structure is not needed. We assume you already decided
    to organize your data as a graph. The table is an easy way to explain Jaccard
    similarity. |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| ^([a](ch06.html#ch01fn12-marker)) 在我们的小例子中使用表格可能暗示不需要图结构。我们假设您已经决定将数据组织为图。表格是解释
    Jaccard 相似度的简单方法。 |'
- en: 'We can use the table’s data to compute Jaccard similarities for each pair of
    travelers:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用表中的数据来计算每对旅行者的 Jaccard 相似度：
- en: 'A and B have three destinations in common (Amazon, Grand Canyon, and Machu
    Picchu). Collectively, they have been to nine destinations: jaccard(A, B) = 3/9
    = 0.33.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A 和 B 有三个共同的目的地（亚马逊、大峡谷和马丘比丘）。他们共同去过九个目的地：jaccard(A, B) = 3/9 = 0.33。
- en: 'B and C have only one destination in common (Grand Canyon). Collectively they
    have been to 10 destinations: jaccard(B, C) = 1/10 = 0.10.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B 和 C 只有一个共同的目的地（大峡谷）。他们共同去过十个目的地：jaccard(B, C) = 1/10 = 0.10。
- en: 'A and C have three destinations in common (Grand Canyon, Paris, and Venice).
    Collectively, they have been to seven destinations: jaccard(A, C) = 3/7 = 0.43.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A 和 C 有三个共同的目的地（大峡谷、巴黎和威尼斯）。他们共同去过七个目的地：jaccard(A, C) = 3/7 = 0.43。
- en: Among these three, A and C are the most similar. As the proprietor, you might
    suggest that C visit some of the places that A has visited, such as the Amazon
    and Machu Picchu. Or you might try to arrange a group tour, inviting both of them
    to somewhere they both have not been to, such as Uluru, Australia.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这三个人中，A 和 C 是最相似的。作为业主，您可能建议 C 参观 A 曾经去过的一些地方，例如亚马逊和马丘比丘。或者您可以尝试安排一次团体旅行，邀请他们两个去他们都没有去过的地方，比如澳大利亚的乌鲁鲁。
- en: Cosine similarity
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 余弦相似度
- en: Cosine similarity measures the alignment of two sequences of numerical characteristics.
    The name comes from the geometric interpretation in which the numerical sequence
    is the entity’s coordinates in space. The data points on the grid (the other type
    of “graph”) in [Figure 6-9](#geometric_interpretation_of_numeric_dat) illustrate
    this interpretation.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度测量两个数值特征序列的对齐程度。其名称来源于几何解释，其中数值序列是实体在空间中的坐标。图中网格上的数据点（另一种“图”类型）在[图 6-9](#geometric_interpretation_of_numeric_dat)中说明了这一解释。
- en: '![Geometric interpretation of numeric data vectors](assets/gpam_0609.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![数值数据向量的几何解释](assets/gpam_0609.png)'
- en: Figure 6-9\. Geometric interpretation of numeric data vectors
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-9。数值数据向量的几何解释
- en: Point A represents an entity whose feature vector is (2,0). B’s feature vector
    is (3,1). Now we see why we call a list of property values a “vector.” The vectors
    for A and B are somewhat aligned. The cosine of the angle between them is their
    similarity score. If two vectors are pointed in exactly the same direction, the
    angle between them is 0; the cosine of their angle is 1\. cos(A,C) is 0 because
    A and C are perpendicular; the vectors (2,0) and (0,2) have nothing in common.
    cos(A,D) is –1 because A and D are pointed in opposite directions. So, cos(*x*,*y*)
    = 1 for two perfectly similar entities, 0 for two perfectly unrelated entities,
    and –1 for two perfectly anticorrelated entities.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 点A代表一个实体，其特征向量为(2,0)。B的特征向量为(3,1)。现在我们明白为什么把属性值列表称为“向量”了。A和B的向量有些对齐。它们之间夹角的余弦值就是它们的相似度分数。如果两个向量指向完全相同的方向，它们之间的角度为0；它们的余弦值为1。cos(A,C)等于0，因为A和C是垂直的；向量(2,0)和(0,2)没有共同之处。cos(A,D)等于–1，因为A和D指向相反的方向。因此，cos(*x*,*y*)
    = 1 表示两个完全相似的实体，等于0表示两个完全不相关的实体，等于–1表示两个完全反相关的实体。
- en: Suppose you have scores across several categories or attributes for a set of
    entities. The scores could be ratings of individual features of products, employees,
    accounts, and so on. Let’s continue the example of Bucket List Travel Advisors.
    This time, each customer has rated their enjoyment of a destination on a scale
    of 1 to 10, so we have numerical values, not just yes/no, shown in [Table 6-3](#dataset_for_cosine_similarity_example).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您对一组实体的几个类别或属性有评分。这些评分可以是产品的各个特性、员工、账户等的评级。让我们继续以 Bucket List Travel Advisors
    为例。这一次，每位客户对他们喜欢的目的地进行了评分，评分范围是1到10，因此我们有数值，不只是是或否，显示在[表 6-3](#dataset_for_cosine_similarity_example)中。
- en: Table 6-3\. Dataset for cosine similarity example
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 表6-3。余弦相似度示例数据集
- en: '| Destination | A | B | C |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 目的地 | A | B | C |'
- en: '| --- | --- | --- | --- |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Amazon Rainforest, Brazil | 8 |   |   |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 巴西亚马逊雨林 | 8 |   |   |'
- en: '| Grand Canyon, USA | 10 | 6 | 8 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 美国大峡谷 | 10 | 6 | 8 |'
- en: '| Great Wall, China | 5 |   | 8 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 中国长城 | 5 |   | 8 |'
- en: '| Machu Picchu, Peru | 8 | 7 |   |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 秘鲁马丘比丘 | 8 | 7 |   |'
- en: '| Paris, France | 9 |   | 4 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 法国巴黎 | 9 |   | 4 |'
- en: '| Pyramids, Egypt |   | 7 |   |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 埃及金字塔 |   | 7 |   |'
- en: '| Safari, Kenya |   | 10 |   |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 肯尼亚的野生动物园 |   | 10 |   |'
- en: '| Taj Mahal, India |   |   | 10 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 印度泰姬陵 |   |   | 10 |'
- en: '| Uluru, Australia |   | 9 |   |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 澳大利亚乌鲁鲁 |   | 9 |   |'
- en: '| Venice, Italy | 7 |   | 10 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 意大利威尼斯 | 7 |   | 10 |'
- en: 'Here are steps for using this table to compute cosine similarity between pairs
    of travelers:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是使用此表格计算旅行者对之间余弦相似度的步骤：
- en: List all the possible neighbors and define a standard order for the list so
    we can form vectors. We will use the top-down order in [Table 6-3](#dataset_for_cosine_similarity_example),
    from Amazon to Venice.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出所有可能的邻居并定义列表的标准顺序，以便我们可以形成向量。我们将使用从亚马逊到威尼斯的自上而下顺序在[表 6-3](#dataset_for_cosine_similarity_example)中的顺序。
- en: If each vertex has D possible neighbors, this gives us vectors of length D.
    For [Table 6-3](#dataset_for_cosine_similarity_example), D = 10\. Each element
    in the vector is either the edge weight, if that vertex is a neighbor, or the
    null score, if it isn’t a neighbor.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果每个顶点有D个可能的邻居，这给了我们长度为D的向量。对于[表 6-3](#dataset_for_cosine_similarity_example)，D
    = 10。向量中的每个元素是边的权重，如果该顶点是邻居，或者是空值分数，如果它不是邻居。
- en: Determining the right null score is required to ensure that your similarity
    scores mean what you want them to mean. If a 0 means someone absolutely hated
    a destination, it is wrong to assign a 0 if someone has not visited a destination.
    A better approach is to *normalize* the scores. You can either normalize by entity
    (traveler), by neighbor/feature (destination), or by both. The idea is to replace
    the empty cells with a default score. You could set the default to be the average
    destination, or you could set it a little lower than that, because not having
    visited a place is a weak vote against that place. For simplicity, we won’t normalize
    the scores; we’ll just use 6 as the default rating. Then traveler A’s vector is
    *Wt*(A) = [8, 10, 5, 8, 9, 6, 6, 6, 6, 7].
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定正确的空值分数是必要的，以确保您的相似性分数意味着您希望它们意味的内容。如果 0 表示某人绝对讨厌一个目的地，那么如果某人没有访问过目的地，赋予 0
    是错误的。更好的方法是*标准化*分数。您可以通过实体（旅行者）、邻居/特征（目的地）或两者同时进行标准化。其思想是用默认分数替换空单元格。您可以将默认值设置为平均目的地，或者您可以将其设置为略低于平均值，因为不访问某个地方相当于对该地方的投票弱。为简单起见，我们不会标准化分数；我们将使用
    6 作为默认评分。那么旅行者 A 的向量是*Wt*(A) = [8, 10, 5, 8, 9, 6, 6, 6, 6, 7]。
- en: 'Then, apply the cosine similarity:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，应用余弦相似度：
- en: <math alttext="c o s i n e left-parenthesis a comma b right-parenthesis equals
    StartFraction upper W t left-parenthesis a right-parenthesis dot upper W left-parenthesis
    b right-parenthesis Over double-vertical-bar upper W t left-parenthesis a right-parenthesis
    double-vertical-bar double-vertical-bar upper W t left-parenthesis b right-parenthesis
    double-vertical-bar EndFraction"><mrow><mi>c</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi>
    <mi>n</mi> <mi>e</mi> <mrow><mo>(</mo> <mi>a</mi> <mo>,</mo> <mi>b</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>W</mi><mi>t</mi><mo>(</mo><mi>a</mi><mo>)</mo><mo>·</mo><mi>W</mi><mo>(</mo><mi>b</mi><mo>)</mo></mrow>
    <mrow><mo>∥</mo><mi>W</mi><mi>t</mi><mo>(</mo><mi>a</mi><mo>)</mo><mo>∥</mo><mo>∥</mo><mi>W</mi><mi>t</mi><mo>(</mo><mi>b</mi><mo>)</mo><mo>∥</mo></mrow></mfrac></mrow></math>
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <math alttext="c o s i n e left-parenthesis a comma b right-parenthesis equals
    StartFraction upper W t left-parenthesis a right-parenthesis dot upper W left-parenthesis
    b right-parenthesis Over double-vertical-bar upper W t left-parenthesis a right-parenthesis
    double-vertical-bar double-vertical-bar upper W t left-parenthesis b right-parenthesis
    double-vertical-bar EndFraction"><mrow><mi>c</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi>
    <mi>n</mi> <mi>e</mi> <mrow><mo>(</mo> <mi>a</mi> <mo>,</mo> <mi>b</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>W</mi><mi>t</mi><mo>(</mo><mi>a</mi><mo>)</mo><mo>·</mo><mi>W</mi><mo>(</mo><mi>b</mi><mo>)</mo></mrow>
    <mrow><mo>∥</mo><mi>W</mi><mi>t</mi><mo>(</mo><mi>a</mi><mo>)</mo><mo>∥</mo><mo>∥</mo><mi>W</mi><mi>t</mi><mo>(</mo><mi>b</mi><mo>)</mo><mo>∥</mo></mrow></mfrac></mrow></math>
- en: ''
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: <math alttext="equals StartFraction sigma-summation Underscript i equals 1 Overscript
    upper D Endscripts upper W t left-parenthesis a right-parenthesis Subscript i
    Baseline upper W t left-parenthesis b right-parenthesis Subscript i Baseline Over
    StartRoot sigma-summation Underscript i equals 1 Overscript upper D Endscripts
    upper W t left-parenthesis a right-parenthesis Subscript i Superscript 2 Baseline
    EndRoot StartRoot sigma-summation Underscript i equals 1 Overscript upper D Endscripts
    upper W t left-parenthesis b right-parenthesis Subscript i Superscript 2 Baseline
    EndRoot EndFraction"><mrow><mo>=</mo> <mfrac><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>D</mi></msubsup> <mi>W</mi><mi>t</mi><msub><mrow><mo>(</mo><mi>a</mi><mo>)</mo></mrow>
    <mi>i</mi></msub> <mi>W</mi><mi>t</mi><msub><mrow><mo>(</mo><mi>b</mi><mo>)</mo></mrow>
    <mi>i</mi></msub></mrow> <mrow><msqrt><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>D</mi></msubsup> <mi>W</mi><mi>t</mi><msubsup><mrow><mo>(</mo><mi>a</mi><mo>)</mo></mrow>
    <mi>i</mi> <mn>2</mn></msubsup></mrow></msqrt> <msqrt><mrow><msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>D</mi></msubsup> <mi>W</mi><mi>t</mi><msubsup><mrow><mo>(</mo><mi>b</mi><mo>)</mo></mrow>
    <mi>i</mi> <mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac></mrow></math>
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <math alttext="equals StartFraction sigma-summation Underscript i equals 1 Overscript
    upper D Endscripts upper W t left-parenthesis a right-parenthesis Subscript i
    Baseline upper W t left-parenthesis b right-parenthesis Subscript i Baseline Over
    StartRoot sigma-summation Underscript i equals 1 Overscript upper D Endscripts
    upper W t left-parenthesis a right-parenthesis Subscript i Superscript 2 Baseline
    EndRoot StartRoot sigma-summation Underscript i equals 1 Overscript upper D Endscripts
    upper W t left-parenthesis b right-parenthesis Subscript i Superscript 2 Baseline
    EndRoot EndFraction"><mrow><mo>=</mo> <mfrac><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>D</mi></msubsup> <mi>W</mi><mi>t</mi><msub><mrow><mo>(</mo><mi>a</mi><mo>)</mo></mrow>
    <mi>i</mi></msub> <mi>W</mi><mi>t</mi><msub><mrow><mo>(</mo><mi>b</mi><mo>)</mo></mrow>
    <mi>i</mi></msub></mrow> <mrow><msqrt><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>D</mi></msubsup> <mi>W</mi><mi>t</mi><msubsup><mrow><mo>(</mo><mi>a</mi><mo>)</mo></mrow>
    <mi>i</mi> <mn>2</mn></msubsup></mrow></msqrt> <msqrt><mrow><msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>D</mi></msubsup> <mi>W</mi><mi>t</mi><msubsup><mrow><mo>(</mo><mi>b</mi><mo>)</mo></mrow>
    <mi>i</mi> <mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac></mrow></math>
- en: '*Wt*(*a*) and *Wt*(*b*) are the neighbor connection weight vectors for *a*
    and *b*, respectively. The numerator goes element by element in the vectors, multiplying
    the weight from a by the weight from *b*, then adding together these products.
    The more that the weights align, the larger the sum we get. The denominator is
    a scaling factor, the Euclidean length of vector *Wt*(*a*) multiplied by the length
    of vector *Wt*(*b*).'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '*Wt*(*a*) 和 *Wt*(*b*) 分别是 *a* 和 *b* 的邻居连接权重向量。分子逐元素在向量中进行，将来自 *a* 的权重乘以来自 *b*
    的权重，然后将这些乘积相加。权重越接近，得到的总和就越大。分母是一个缩放因子，向量 *Wt*(*a*) 的欧几里得长度乘以向量 *Wt*(*b*) 的长度。'
- en: Let’s look at one more use case, people who rate movies, to compare how Jaccard
    and cosine similarity work. In [Figure 6-10](#similarity_of_persons_who_rate_movies),
    we have two persons, A and B, who have each rated three movies. They have both
    rated two of the same movies, *Black Panther* and *Frozen*.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一个使用案例，评分电影的人，来比较 Jaccard 相似性和余弦相似性的工作方式。在[图 6-10](#similarity_of_persons_who_rate_movies)，我们有两个人，A
    和 B，他们各自评价了三部电影。他们都评价了两部相同的电影，*黑豹*和*冰雪奇缘*。
- en: '![Similarity of persons who rate movies](assets/gpam_0610.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![评分电影的人的相似性](assets/gpam_0610.png)'
- en: Figure 6-10\. Similarity of persons who rate movies
  id: totrans-205
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-10\. 评分电影的人的相似性
- en: If we only care about what movies the persons have seen and not about the scores,
    then Jaccard similarity is sufficient and easier to compute. This would also be
    your choice if scores were not available or if the relationships were not numeric.
    The Jaccard similarity is (size of overlap) / (size of total set) = 2 / 4 = 0.5\.
    That seems like a middling score, but if there are hundreds or thousands of possible
    movies they could have seen, then it’s a very high score.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只关心人们看过哪些电影，而不关心评分，那么 Jaccard 相似性就足够了，并且更容易计算。如果分数不可用或者关系不是数值的话，这也将是您的选择。Jaccard
    相似性是（重叠的大小）/（总集大小）= 2 / 4 = 0.5。这看起来像是一个中等分数，但如果可能有数百或数千部可能看过的电影，那么这将是一个非常高的分数。
- en: If we want to take the movie ratings into account to see how similar A’s and
    B’s taste are, we should use cosine similarity. Assuming the null score is 0,
    then A’s neighbor score vector is [5, 4, 3, 0] and B’s is [4, 0, 5, 5]. For cosine
    similarity, the numerator is [5, 4, 3, 0] ⋅ [4, 0, 5, 5] = (5)(4)+(4)(0)+(3)(5)+(0)(5)
    = 35\. The denominator = <math alttext="StartRoot 5 squared plus 4 squared plus
    3 squared plus 0 squared EndRoot StartRoot 4 squared plus 0 squared plus 5 squared
    plus 5 squared EndRoot equals StartRoot 50 EndRoot StartRoot 66 EndRoot equals
    57.446"><mrow><msqrt><mrow><msup><mn>5</mn> <mn>2</mn></msup> <mo>+</mo> <msup><mn>4</mn>
    <mn>2</mn></msup> <mo>+</mo> <msup><mn>3</mn> <mn>2</mn></msup> <mo>+</mo> <msup><mn>0</mn>
    <mn>2</mn></msup></mrow></msqrt> <msqrt><mrow><msup><mn>4</mn> <mn>2</mn></msup>
    <mo>+</mo> <msup><mn>0</mn> <mn>2</mn></msup> <mo>+</mo> <msup><mn>5</mn> <mn>2</mn></msup>
    <mo>+</mo> <msup><mn>5</mn> <mn>2</mn></msup></mrow></msqrt> <mo>=</mo> <msqrt><mn>50</mn></msqrt>
    <msqrt><mn>66</mn></msqrt> <mo>=</mo> <mn>57</mn> <mo>.</mo> <mn>446</mn></mrow></math>
    . The final result is 0.60927\. This again seems like a reasonably good score—not
    strong similarity, but much better than a random pairing.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想考虑电影评分来看A和B的品味有多相似，我们应该使用余弦相似度。假设空分数为0，那么A的邻居分数向量为[5, 4, 3, 0]，B的为[4, 0,
    5, 5]。对于余弦相似度，分子为[5, 4, 3, 0] ⋅ [4, 0, 5, 5] = (5)(4)+(4)(0)+(3)(5)+(0)(5) = 35。分母
    = <math alttext="StartRoot 5平方加4平方加3平方加0平方 EndRoot StartRoot 4平方加0平方加5平方加5平方 EndRoot
    equals StartRoot 50 EndRoot StartRoot 66 EndRoot equals 57.446"><mrow><msqrt><mrow><msup><mn>5</mn>
    <mn>2</mn></msup> <mo>+</mo> <msup><mn>4</mn> <mn>2</mn></msup> <mo>+</mo> <msup><mn>3</mn>
    <mn>2</mn></msup> <mo>+</mo> <msup><mn>0</mn> <mn>2</mn></msup></mrow></msqrt>
    <msqrt><mrow><msup><mn>4</mn> <mn>2</mn></msup> <mo>+</mo> <msup><mn>0</mn> <mn>2</mn></msup>
    <mo>+</mo> <msup><mn>5</mn> <mn>2</mn></msup> <mo>+</mo> <msup><mn>5</mn> <mn>2</mn></msup></mrow></msqrt>
    <mo>=</mo> <msqrt><mn>50</mn></msqrt> <msqrt><mn>66</mn></msqrt> <mo>=</mo> <mn>57</mn>
    <mo>.</mo> <mn>446</mn></mrow></math>。最终结果为0.60927。这似乎是一个合理不错的分数——并非强相似度，但远比随机匹配好得多。
- en: Tip
  id: totrans-208
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Use Jaccard similarity when the features of interest are yes/no or categorical
    variables.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 当感兴趣的特征是是/否或分类变量时，请使用Jaccard相似度。
- en: Use cosine similarity when you have numerical variables. If you have both types,
    you can use cosine similarity and treat your yes/no variables as having values
    1/0.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 当您有数值变量时，请使用余弦相似度。如果您两种都有，您可以使用余弦相似度，并将您的是/否变量视为值1/0。
- en: Role similarity
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 角色相似性
- en: Earlier we said that if two vertices have similar properties, similar relationships,
    and similar neighborhoods, then they should be similar. We first examined the
    situation in which the neighborhoods contained some of the exact same members,
    but let’s look at the more general scenario in which the individual neighbors
    aren’t the *same*, just similar.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们说过，如果两个顶点具有相似的属性、相似的关系和相似的邻居，那么它们应该是相似的。我们首先研究了邻居包含完全相同成员的情况，但让我们看看更一般的情况，即个体邻居不是*相同*的，只是相似的。
- en: Consider a graph of family relationships. One person, Jordan, has two living
    parents and is married to someone who was born in a different country, and they
    have three children together. Another person, Kim, also has two living parents
    and is married to someone born in another country, and together they have four
    children. Jordan and Kim don’t have any neighboring entities (parents, spouses,
    or children) in common. The number of children is similar but not exactly the
    same. Nevertheless, Jordan and Kim are similar because they have similar relationships.
    This is called *role similarity*.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个家庭关系图。一个人，乔丹，有两个活着的父母，并且与一个出生在另一个国家的人结婚，他们共同有三个孩子。另一个人，金，也有两个活着的父母，并且与一个出生在另一个国家的人结婚，他们共同有四个孩子。乔丹和金在共同的邻居实体（父母、配偶或子女）方面没有任何共同点。孩子的数量相似但不完全相同。尽管如此，乔丹和金因为有相似的关系而相似。这被称为*角色相似性*。
- en: Moreover, if Jordan’s spouse and Kim’s spouse are similar, that’s even better.
    If Jordan’s children and Kim’s children are similar in some way (ages, hobbies,
    etc.), that’s even better. You get the idea. Instead of people, these could be
    products, components in a supply chain or power distribution network, or financial
    transactions.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果乔丹的配偶和金的配偶相似，那就更好了。如果乔丹的孩子和金的孩子在某种方式上（年龄、爱好等）相似，那就更好了。你明白了吧。这些可以不是人，而是产品、供应链或电力分布网络中的组件，或者金融交易。
- en: Two entities have similar roles if they have similar relationships to entities,
    which themselves have similar roles.
  id: totrans-215
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果两个实体对实体有相似的关系，并且这些实体本身有相似的角色，则它们具有相似的角色。
- en: 'This is a recursive definition: A and B are similar if their neighbors are
    similar. Where does it stop? What is the base case where we can say for certain
    how much two things are similar?'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个递归定义：如果它们的邻居相似，那么 A 和 B 就是相似的。它何时停止？我们可以确定两者相似的基本情况是什么？
- en: SimRank
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SimRank
- en: 'In their 2002 paper, Glen Jeh and Jennifer Widom proposed SimRank,^([2](ch06.html#ch01fn13))
    which measures similarity by having equal-length paths from A and B both reach
    the same individual. For example, if Jordan and Kim share a grandparent, that
    contributes to their SimRank score. The formal definition of SimRank is:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的2002年论文中，Glen Jeh 和 Jennifer Widom 提出了SimRank^([2](ch06.html#ch01fn13))，通过使得从A和B的等长路径同时到达同一个个体来衡量相似性。例如，如果Jordan和Kim共享一个祖父母，那就会增加它们的SimRank分数。SimRank的正式定义是：
- en: <math alttext="s i m r a n k left-parenthesis a comma b right-parenthesis equals
    StartFraction upper C Over StartAbsoluteValue upper I n left-parenthesis a right-parenthesis
    upper I n left-parenthesis b right-parenthesis EndAbsoluteValue EndFraction sigma-summation
    Underscript u element-of upper I n left-parenthesis a right-parenthesis Endscripts
    sigma-summation Underscript v element-of upper I n left-parenthesis b right-parenthesis
    Endscripts s i m r a n k left-parenthesis upper I n left-parenthesis u right-parenthesis
    comma upper I n left-parenthesis v right-parenthesis right-parenthesis"><mrow><mi>s</mi>
    <mi>i</mi> <mi>m</mi> <mi>r</mi> <mi>a</mi> <mi>n</mi> <mi>k</mi> <mrow><mo>(</mo>
    <mi>a</mi> <mo>,</mo> <mi>b</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mi>C</mi>
    <mrow><mo>|</mo><mi>I</mi><mi>n</mi><mo>(</mo><mi>a</mi><mo>)</mo><mi>I</mi><mi>n</mi><mo>(</mo><mi>b</mi><mo>)</mo><mo>|</mo></mrow></mfrac>
    <munder><mo>∑</mo> <mrow><mi>u</mi><mo>∈</mo><mi>I</mi><mi>n</mi><mo>(</mo><mi>a</mi><mo>)</mo></mrow></munder>
    <munder><mo>∑</mo> <mrow><mi>v</mi><mo>∈</mo><mi>I</mi><mi>n</mi><mo>(</mo><mi>b</mi><mo>)</mo></mrow></munder>
    <mi>s</mi> <mi>i</mi> <mi>m</mi> <mi>r</mi> <mi>a</mi> <mi>n</mi> <mi>k</mi> <mrow><mo>(</mo>
    <mi>I</mi> <mi>n</mi> <mrow><mo>(</mo> <mi>u</mi> <mo>)</mo></mrow> <mo>,</mo>
    <mi>I</mi> <mi>n</mi> <mrow><mo>(</mo> <mi>v</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  id: totrans-219
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <math alttext="s i m r a n k left-parenthesis a comma b right-parenthesis equals
    StartFraction upper C Over StartAbsoluteValue upper I n left-parenthesis a right-parenthesis
    upper I n left-parenthesis b right-parenthesis EndAbsoluteValue EndFraction sigma-summation
    Underscript u element-of upper I n left-parenthesis a right-parenthesis Endscripts
    sigma-summation Underscript v element-of upper I n left-parenthesis b right-parenthesis
    Endscripts s i m r a n k left-parenthesis upper I n left-parenthesis u right-parenthesis
    comma upper I n left-parenthesis v right-parenthesis right-parenthesis"><mrow><mi>s</mi>
    <mi>i</mi> <mi>m</mi> <mi>r</mi> <mi>a</mi> <mi>n</mi> <mi>k</mi> <mrow><mo>(</mo>
    <mi>a</mi> <mo>,</mo> <mi>b</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mi>C</mi>
    <mrow><mo>|</mo><mi>I</mi><mi>n</mi><mo>(</mo><mi>a</mi><mo>)</mo><mi>I</mi><mi>n</mi><mo>(</mo><mi>b</mi><mo>)</mo><mo>|</mo></mrow></mfrac>
    <munder><mo>∑</mo> <mrow><mi>u</mi><mo>∈</mo><mi>I</mi><mi>n</mi><mo>(</mo><mi>a</mi><mo>)</mo></mrow></munder>
    <munder><mo>∑</mo> <mrow><mi>v</mi><mo>∈</mo><mi>I</mi><mi>n</mi><mo>(</mo><mi>b</mi><mo>)</mo></mrow></munder>
    <mi>s</mi> <mi>i</mi> <mi>m</mi> <mi>r</mi> <mi>a</mi> <mi>n</mi> <mi>k</mi> <mrow><mo>(</mo>
    <mi>I</mi> <mi>n</mi> <mrow><mo>(</mo> <mi>u</mi> <mo>)</mo></mrow> <mo>,</mo>
    <mi>I</mi> <mi>n</mi> <mrow><mo>(</mo> <mi>v</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
- en: ''
  id: totrans-220
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <math alttext="s i m r a n k left-parenthesis a comma a right-parenthesis equals
    1"><mrow><mi>s</mi> <mi>i</mi> <mi>m</mi> <mi>r</mi> <mi>a</mi> <mi>n</mi> <mi>k</mi>
    <mo>(</mo> <mi>a</mi> <mo>,</mo> <mi>a</mi> <mo>)</mo> <mo>=</mo> <mn>1</mn></mrow></math>
  id: totrans-221
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <math alttext="s i m r a n k left-parenthesis a comma a right-parenthesis equals
    1"><mrow><mi>s</mi> <mi>i</mi> <mi>m</mi> <mi>r</mi> <mi>a</mi> <mi>n</mi> <mi>k</mi>
    <mo>(</mo> <mi>a</mi> <mo>,</mo> <mi>a</mi> <mo>)</mo> <mo>=</mo> <mn>1</mn></mrow></math>
- en: '*In*(*a*) and *In*(*b*) are the sets of in-neighbors of vertices *a* and *b*,
    respectively; *u* is a member of *In*(*a*); *v* is a member of *In*(*b*); and
    *C* is a constant between 0 and 1 to control the rate at which neighbors’ influence
    decreases as distance from a source vertex increases. Lower values of *C* mean
    a more rapid decrease. SimRank computes an N × N array of similarity scores, one
    for each possible pair of vertices. This differs from cosine and Jaccard similarity,
    which compute a single pair’s score on demand. It is necessary to compute the
    full array of SimRank scores because the value of SimRank(*a*,*b*) depends of
    the SimRank score of pairs of their neighbors (e.g., SimRank(*u*,*v*)), which
    in turn depends on *their* neighbors, and so on. To compute SimRank, you initialize
    the array so that SimRank(*a*,*b*) = 1 if *a* = *b*; otherwise, it is 0\. Then
    calculate a revised set of scores by applying the SimRank equation for each pair
    (*a*,*b*) where the SimRank scores on the right side are from the previous iteration.
    Note that this is like PageRank’s computation, except that we have N × N scores
    instead of just N scores. SimRank has a few weaknesses. It only finds similarity
    if two entities eventually find some vertex that is the same distance from both
    of them. This is too rigid for some cases. It would not work for Jordan and Kim
    unless our graph contained their common relatives.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '*In*(*a*) 和 *In*(*b*) 分别是顶点 *a* 和 *b* 的入邻居集合；*u* 是 *In*(*a*) 的成员；*v* 是 *In*(*b*)
    的成员；*C* 是一个介于 0 和 1 之间的常数，用于控制邻居影响随距离从源顶点增加而减少的速率。较小的 *C* 值意味着更快的减少。SimRank 计算一个
    N × N 的相似性分数数组，每对顶点都有一个。这与余弦相似度和Jaccard相似度不同，后者根据需要计算单个对的分数。需要计算完整的SimRank分数数组，因为SimRank(*a*,*b*)的值取决于它们邻居对的SimRank分数（例如SimRank(*u*,*v*)），而后者又取决于它们的邻居，依此类推。为了计算SimRank，初始化数组使得如果
    *a* = *b*，则SimRank(*a*,*b*) = 1；否则为 0。然后，通过应用SimRank方程计算修订后的分数集，其中右侧的SimRank分数来自先前的迭代。请注意，这类似于PageRank的计算，不同之处在于我们有N
    × N的分数而不仅仅是N个分数。SimRank有一些弱点。它仅在两个实体最终找到某个顶点相同时才找到相似性。这对某些情况来说太严格了。对于Jordan和Kim来说，除非我们的图包含它们的共同亲属，否则它将不起作用。'
- en: RoleSim
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RoleSim
- en: 'To address these shortcomings, Ruoming Jin, Victor E. Lee, and Hui Hong introduced
    RoleSim^([3](ch06.html#ch01fn14)) in 2011\. RoleSim starts with the (over)estimate
    that the similarity between any two entities is the ratio of the sizes of their
    neighborhoods. The initial estimate for RoleSim(Jordan, Kim) would be 5/6\. RoleSim
    then uses the current estimated similarity of their neighbors to make an improved
    guess for the next round. RoleSim is defined as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些缺点，Ruoming Jin、Victor E. Lee 和 Hui Hong 在2011年引入了RoleSim^([3](ch06.html#ch01fn14))。RoleSim从这样一个（过于）估计开始，即任意两个实体之间的相似性是它们邻居规模的比率。RoleSim(Jordan,
    Kim)的初始估计将是 5/6。然后RoleSim利用它们邻居当前的估计相似性来进行下一轮的改进猜测。RoleSim定义如下：
- en: <math alttext="r o l e s i m left-parenthesis a comma b right-parenthesis equals"><mrow><mi>r</mi>
    <mi>o</mi> <mi>l</mi> <mi>e</mi> <mi>s</mi> <mi>i</mi> <mi>m</mi> <mo>(</mo> <mi>a</mi>
    <mo>,</mo> <mi>b</mi> <mo>)</mo> <mo>=</mo></mrow></math> <math alttext="left-parenthesis
    1 minus beta right-parenthesis max Underscript upper M left-parenthesis a comma
    b right-parenthesis Endscripts StartFraction sigma-summation Underscript left-parenthesis
    u comma v right-parenthesis element-of upper M left-parenthesis a comma b right-parenthesis
    Endscripts r o l e s i m left-parenthesis u comma v right-parenthesis Over m a
    x left-parenthesis StartAbsoluteValue upper N left-parenthesis u right-parenthesis
    EndAbsoluteValue comma StartAbsoluteValue upper N left-parenthesis v right-parenthesis
    EndAbsoluteValue right-parenthesis EndFraction plus beta"><mrow><mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <mi>β</mi> <mo>)</mo></mrow> <munder><mo form="prefix" movablelimits="false">max</mo>
    <mrow><mi>M</mi><mo>(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo>)</mo></mrow></munder>
    <mfrac><mrow><msub><mo>∑</mo> <mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo><mo>∈</mo><mi>M</mi><mo>(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo>)</mo></mrow></msub>
    <mi>r</mi><mi>o</mi><mi>l</mi><mi>e</mi><mi>s</mi><mi>i</mi><mi>m</mi><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow></mrow>
    <mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>|</mo><mo>,</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>v</mi><mo>)</mo><mo>|</mo><mo>)</mo></mrow></mfrac>
    <mo>+</mo> <mi>β</mi></mrow></math>
  id: totrans-225
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <math alttext="r o l e s i m left-parenthesis a comma b right-parenthesis equals"><mrow><mi>r</mi>
    <mi>o</mi> <mi>l</mi> <mi>e</mi> <mi>s</mi> <mi>i</mi> <mi>m</mi> <mo>(</mo> <mi>a</mi>
    <mo>,</mo> <mi>b</mi> <mo>)</mo> <mo>=</mo></mrow></math> <math alttext="left-parenthesis
    1 minus beta right-parenthesis max Underscript upper M left-parenthesis a comma
    b right-parenthesis Endscripts StartFraction sigma-summation Underscript left-parenthesis
    u comma v right-parenthesis element-of upper M left-parenthesis a comma b right-parenthesis
    Endscripts r o l e s i m left-parenthesis u comma v right-parenthesis Over m a
    x left-parenthesis StartAbsoluteValue upper N left-parenthesis u right-parenthesis
    EndAbsoluteValue comma StartAbsoluteValue upper N left-parenthesis v right-parenthesis
    EndAbsoluteValue right-parenthesis EndFraction plus beta"><mrow><mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <mi>β</mi> <mo>)</mo></mrow> <munder><mo form="prefix" movablelimits="false">max</mo>
    <mrow><mi>M</mi><mo>(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo>)</mo></mrow></munder>
    <mfrac><mrow><msub><mo>∑</mo> <mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo><mo>∈</mo><mi>M</mi><mo>(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo>)</mo></mrow></msub>
    <mi>r</mi><mi>o</mi><mi>l</mi><mi>e</mi><mi>s</mi><mi>i</mi><mi>m</mi><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow></mrow>
    <mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>|</mo><mo>,</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>v</mi><mo>)</mo><mo>|</mo><mo>)</mo></mrow></mfrac>
    <mo>+</mo> <mi>β</mi></mrow></math>
- en: ''
  id: totrans-226
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <math alttext="r o l e s i m 0 left-parenthesis a comma b right-parenthesis
    equals StartFraction m i n left-parenthesis StartAbsoluteValue upper N left-parenthesis
    u right-parenthesis EndAbsoluteValue comma StartAbsoluteValue upper N left-parenthesis
    v right-parenthesis EndAbsoluteValue right-parenthesis Over m a x left-parenthesis
    StartAbsoluteValue upper N left-parenthesis u right-parenthesis EndAbsoluteValue
    comma StartAbsoluteValue upper N left-parenthesis v right-parenthesis EndAbsoluteValue
    right-parenthesis EndFraction"><mrow><mi>r</mi> <mi>o</mi> <mi>l</mi> <mi>e</mi>
    <mi>s</mi> <mi>i</mi> <msub><mi>m</mi> <mn>0</mn></msub> <mrow><mo>(</mo> <mi>a</mi>
    <mo>,</mo> <mi>b</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mo>(</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>|</mo><mo>,</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>v</mi><mo>)</mo><mo>|</mo><mo>)</mo></mrow>
    <mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>|</mo><mo>,</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>v</mi><mo>)</mo><mo>|</mo><mo>)</mo></mrow></mfrac></mrow></math>
  id: totrans-227
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <math alttext="r o l e s i m 0 left-parenthesis a comma b right-parenthesis
    equals StartFraction m i n left-parenthesis StartAbsoluteValue upper N left-parenthesis
    u right-parenthesis EndAbsoluteValue comma StartAbsoluteValue upper N left-parenthesis
    v right-parenthesis EndAbsoluteValue right-parenthesis Over m a x left-parenthesis
    StartAbsoluteValue upper N left-parenthesis u right-parenthesis EndAbsoluteValue
    comma StartAbsoluteValue upper N left-parenthesis v right-parenthesis EndAbsoluteValue
    right-parenthesis EndFraction"><mrow><mi>r</mi> <mi>o</mi> <mi>l</mi> <mi>e</mi>
    <mi>s</mi> <mi>i</mi> <msub><mi>m</mi> <mn>0</mn></msub> <mrow><mo>(</mo> <mi>a</mi>
    <mo>,</mo> <mi>b</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mo>(</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>|</mo><mo>,</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>v</mi><mo>)</mo><mo>|</mo><mo>)</mo></mrow>
    <mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>|</mo><mo>,</mo><mo>|</mo><mi>N</mi><mo>(</mo><mi>v</mi><mo>)</mo><mo>|</mo><mo>)</mo></mrow></mfrac></mrow></math>
- en: 'The parameter <math alttext="beta"><mi>β</mi></math> is similar to SimRank’s
    *C*. The main difference is the function *M*. *M*(*a*,*b*) is a *bipartite matching*
    between the neighborhoods of *a* and *b*. This is like trying to pair up the three
    children of Jordan with the four children of Kim. *M*(Jordan, Kim) will consist
    of three pairs (and one child left out). Moreover, there are 24 possible matchings.
    For computational purposes (not actual social dynamics), assume that the oldest
    child of Jordan selects a child of Kim; there are four options. The next child
    of Jordan picks from the three remaining children of Kim, and the third child
    of Jordan can choose from the two remaining children of Kim. This yields (4)(3)(2)
    = 24 possibilities. The max term in the equation means that we select the matching
    that yields the highest sum of RoleSim scores for the three chosen pairs. If you
    think of RoleSim as a compatibility score, then we are looking for the combination
    of pairings that gives us the highest total compatibility of partners. You can
    see that this is more computational work than SimRank, but the resulting scores
    have nicer properties:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '参数 <math alttext="beta"><mi>β</mi></math> 类似于 SimRank 的 *C*。主要区别在于函数 *M*。*M*(*a*,*b*)
    是 *a* 和 *b* 的邻域之间的 *二分图匹配*。这就像试图将乔丹的三个孩子与金的四个孩子配对。*M*(乔丹, 金) 将包含三对（还有一个孩子单身）。此外，有
    24 种可能的匹配方式。为了计算方便（并非实际的社会动态），假设乔丹的最大孩子选择金的一个孩子；有四个选择。接下来，乔丹的下一个孩子从金的剩下三个孩子中选择，而第三个孩子可以从金的剩下两个孩子中选择。这会产生
    (4)(3)(2) = 24 种可能性。方程中的最大项意味着我们选择产生三对配对的 RoleSim 分数总和最高的匹配。如果你把 RoleSim 视为兼容性分数，那么我们正在寻找使合作伙伴的总兼容性最高的配对组合。可以看出，这比
    SimRank 更需要计算工作，但是得到的分数具有更好的性质：  '
- en: There is no requirement that the neighborhoods of *a* and *b* ever meet.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不要求 *a* 和 *b* 的邻域必须相遇。
- en: If the neighborhoods of *a* and *b* “look” exactly the same, because they have
    the same size, and each of the neighbors can be paired up so that their neighborhoods
    look the same, and so on, then their RoleSim score will be a perfect 1\. Mathematically,
    this level of similarity is called *automorphic equivalence*.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果*a*和*b*的邻域“看起来”完全相同，因为它们具有相同的大小，并且每个邻居都可以成对地进行匹配，以便它们的邻域看起来相同，依此类推，则它们的RoleSim分数将是完美的1。从数学上讲，这种相似性水平称为*自同构等价*。
- en: Classification and prediction algorithms
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类和预测算法
- en: 'Not only can graph algorithms compute descriptive properties such as centrality
    or similarity, but they also can take on the predictive side of data science.
    One of the most in-demand uses for graph analytics employs vertex classification
    methods to predict whether a particular transaction is fraudulent. We’ll wrap
    up our chapter by looking at a few algorithms for predictive tasks relevant to
    graphs: predicting the class of a vertex and predicting the future success or
    the present existence of a relationship.^([4](ch06.html#ch01fn15)) We often associate
    prediction with guessing the future, but an equally important application is trying
    to predict facts about the current world, acknowledging that our database doesn’t
    know everything.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅可以通过图算法计算描述性属性如中心性或相似性，它们还可以承担数据科学的预测方面。图分析中最受需求的用途之一是使用顶点分类方法预测特定交易是否存在欺诈行为。我们将通过查看几种与图相关的预测任务算法来结束本章：预测顶点的类别和预测关系的未来成功或当前存在。（参见[4](ch06.html#ch01fn15)）。我们常常将预测与猜测未来联系起来，但同样重要的应用是尝试预测关于当前世界的事实，承认我们的数据库并不知道所有事情。
- en: 'Humans navigate the world by constantly performing entity classification. Every
    time we encounter something we have not seen before, our brains try to assign
    it to one of the categories of things we already know. We even classify people,
    which affects how we perceive them. In our minds, we have thousands of categories
    of items, each defined by some key characteristics. We then subconsciously perform
    the duck test: if it looks like a duck, swims like a duck, and quacks like a duck,
    it’s a duck. If we take a more quantitative approach and say that we are trying
    to find the most matches between the properties of some known category and this
    new item, we have just described Jaccard similarity.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 人类通过不断进行实体分类来导航世界。每当我们遇到以前没有见过的东西时，我们的大脑会尝试将其归类为我们已知事物类别之一。我们甚至对人进行分类，这会影响我们如何看待他们。在我们的头脑中，我们有成千上万种物品类别，每种类别由一些关键特征定义。然后我们在潜意识中执行鸭子测试：如果它看起来像鸭子，游泳像鸭子，并且嘎嘎叫像鸭子，那么它就是鸭子。如果我们采取更量化的方法，并说我们试图在某些已知类别的属性与这个新项目之间找到最多匹配，我们刚刚描述了Jaccard相似性。
- en: The natural way to perform classification and prediction in a graph is to leverage
    graph-based similarity. Compute the similarity between the vertex in question
    and other vertices by applying a formula like cosine or Jaccard similarity to
    their neighborhoods. If we have previously performed some modeling, so that we
    have representative exemplars for each class, then we only need to compare to
    the exemplars. Training a machine learning model is one way to obtain these exemplars.
    If we haven’t yet performed this modeling, we can still perform classification.
    We just need to look at more data to discover what categories are out there and
    what their characteristics are. A popular approach is *k-nearest neighbors*, or
    kNN for short.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中执行分类和预测的自然方法是利用基于图的相似性。通过应用诸如余弦或Jaccard相似性的公式，计算待定顶点与其他顶点之间的相似性。如果我们先前进行了某种建模，这样我们就为每个类别有了代表性的示例，那么我们只需要将其与这些示例进行比较。训练机器学习模型是获取这些示例的一种方法。如果我们尚未执行此建模，我们仍然可以进行分类。我们只需要查看更多数据，以发现存在哪些类别及其特征。一种流行的方法是*k-最近邻*，简称kNN。
- en: 'Here is the basic workflow for kNN:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是 kNN 的基本工作流程：
- en: Compute similar scores between the query vertex and other vertices that have
    a known class. If an item’s class is known, we say it is *labeled*. If there are
    too many labeled vertices, we can select a random sample of them.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算查询顶点与已知类别顶点之间的相似分数。如果一个项目的类别已知，我们称其为*标记*。如果有太多已标记的顶点，我们可以选择它们的随机样本。
- en: Select the k most similar vertices, where 1 < k < N.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 k 个最相似的顶点，其中 1 < k < N。
- en: Count the occurrences of each category among the k-nearest vertices. Pick the
    category that occurs the most often.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 统计 k 个最近顶点中每个类别的出现次数。选择出现最多的类别。
- en: For example, if among the 10 persons most similar to Kim, 7 prefer *Star Trek*
    to *Star Wars*, we predict that Kim prefers *Star Trek*.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果在与Kim最相似的10人中，有7人更喜欢*星际迷航*而不是*星球大战*，那么我们预测Kim更喜欢*星际迷航*。
- en: There is no universally ideal value of k. Values that are too small are too
    sensitive to noise. Values that are too big are ignoring the importance of nearness.
    One heuristic is <math alttext="k equals StartRoot upper N EndRoot"><mrow><mi>k</mi>
    <mo>=</mo> <msqrt><mi>N</mi></msqrt></mrow></math> . Another is to perform the
    prediction for a range of values and then to pick the most frequent prediction
    among the many predictions.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 并没有普遍理想的k值。太小的值对噪声过于敏感，而太大的值则忽略了接近性的重要性。一个启发式方法是<math alttext="k equals StartRoot
    upper N EndRoot"><mrow><mi>k</mi> <mo>=</mo> <msqrt><mi>N</mi></msqrt></mrow></math>。另一个方法是对一系列值执行预测，然后从众多预测中选择最频繁的预测。
- en: 'In [Figure 6-11](#using_knn_to_classify_a_vertex), the query vertex is in the
    center, and the distance between a vertex and the center represents the distance
    (inverse similarity) between that vertex and the query vertex. Vertices that are
    shaded have a known class. We have two classes: dark and light. If k = 6, then
    two of those six are dark, and the other four are light. Therefore, we predict
    that the class of the query vertex is light.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图6-11](#using_knn_to_classify_a_vertex)中，查询顶点位于中心，顶点与中心之间的距离表示该顶点与查询顶点之间的距离（逆相似度）。被阴影覆盖的顶点有已知类别。我们有两类：深色和浅色。如果k
    = 6，那么这六个中有两个是深色的，其他四个是浅色的。因此，我们预测查询顶点的类别是浅色的。
- en: '![Using kNN to classify a vertex](assets/gpam_0611.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![使用kNN对顶点进行分类](assets/gpam_0611.png)'
- en: Figure 6-11\. Using kNN to classify a vertex
  id: totrans-243
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-11. 使用kNN对顶点进行分类
- en: 'Link prediction can also make use of graph-based similarity. This task is usually
    more complicated than node classification. First, we are dealing with two vertices
    (the endpoints) instead of one. Moreover, the link might be directional. For the
    general case, we hypothesize, “There is probably an edge of type L from vertex
    A to vertex B, if there is usually an edge of type L from vertices similar to
    A to vertices similar to B.” We can apply cosine or Jaccard similarity to our
    vertices, and then count how often we see edges between pairs of similar vertices.
    The task is simpler if the two endpoints are the same type of vertex: then we
    only need to study one type of vertex.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 链接预测还可以利用基于图的相似性。这个任务通常比节点分类更复杂。首先，我们处理的是两个顶点（端点），而不是一个。此外，链接可能是有方向性的。对于一般情况，我们假设，“如果从与A相似的顶点到与B相似的顶点通常有类型为L的边，那么从顶点A到顶点B可能存在类型为L的边”。我们可以对我们的顶点应用余弦或杰卡德相似度，然后计算我们看到的类似顶点对之间边的频率。如果两个端点是相同类型的顶点，则任务更简单：我们只需要研究一种顶点类型。
- en: 'Different types of relationships may correlate to different types of similarity.
    For example, suppose we are trying to predict a friendship relationship. Friendship
    is often characterized by *homophily*: persons who have a lot in common tend to
    like one another. Jaccard similarity might be appropriate. If homophily is an
    important characteristic, we can skip the step where we look for existing examples
    of edges and just make our prediction based on the two vertices being sufficiently
    similar. For other types of relationships, such as knowing one another or doing
    business together, two vertices belonging to the same community might be a good
    predictor of eventually having a direct relationship.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的关系可能与不同类型的相似性相关。例如，假设我们试图预测友谊关系。友谊通常以*同质性*为特征：有很多共同点的人倾向于彼此喜欢。杰卡德相似度可能是适当的。如果同质性是一个重要特征，我们可以跳过寻找现有边例子的步骤，仅基于两个顶点足够相似来进行预测。对于其他类型的关系，例如相互认识或共同做生意，属于同一个社区的两个顶点可能是最终建立直接关系的一个良好预测因素。
- en: 'Besides Jaccard and cosine, here are some ways to measure vertex similarity
    in the service of link prediction:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 除了杰卡德和余弦之外，在链接预测服务中测量顶点相似性的其他方式包括：
- en: Common neighbors
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 共同邻居
- en: Count the number of neighbors in common. Is this number high?
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 计算共同邻居的数量。这个数字高吗？
- en: Total neighbors
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 总邻居
- en: Count the number of neighbors in common, for neighborhoods to a depth of D hops.
    Is this number high?
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 计算共同邻居的数量，对于深度为D跳的邻域。这个数字高吗？
- en: Same community
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 同一个社区
- en: Are the two vertices already in the same community?
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 两个顶点已经在同一个社区里吗？
- en: 'Using raw counts can be problematic. How much is enough? Jaccard similarity
    normalizes the counts by dividing the count of common neighbors by the total number
    of distinct neighbors among them. Another way to normalize is to think about how
    many neighbors each of the common neighbors has. Suppose A and B are both friends
    with C. If C is friends with only three persons, then your two friendships are
    very significant to C. If C has one thousand friends, then it’s not that significant
    that they have C in common. Adamic and Adar proposed a similarity index^([5](ch06.html#ch01fn16))
    that scales the contribution of each common neighbor by the inverse log of that
    neighbor’s neighborhood size. The smaller the neighborhood, the bigger the contribution
    to similarity:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 使用原始计数可能存在问题。足够多是多少？杰卡德相似度通过将共同邻居的计数除以它们中的不同邻居总数来标准化计数。另一种标准化方法是考虑每个共同邻居拥有多少邻居。假设
    A 和 B 都与 C 为朋友。如果 C 只有三个朋友，那么你们两个与 C 的友谊对 C 来说非常重要。如果 C 有一千个朋友，那么他们共同拥有 C 并不那么重要。阿达米克和阿达尔提出了一种相似性指数^([5](ch06.html#ch01fn16))，它通过邻居的对数倒数来缩放每个共同邻居的贡献。邻居越少，对相似性的贡献越大：
- en: '*S(A,B)* = ∑_(*u ∈ N(A)* ∩ *N(B)* ) 1/(*log N(u)*)'
  id: totrans-254
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*S(A,B)* = ∑_(*u ∈ N(A)* ∩ *N(B)* ) 1/(*log N(u)*)'
- en: All of these similarity algorithms are available in TigerGraph’s GDS Library
    in the Topological Similarity category.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些相似性算法都包含在TigerGraph的GDS库的拓扑相似性类别中。
- en: Chapter Summary
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 章节总结
- en: In this chapter, we articulated a definition of graph analytics, discussed the
    computational requirements for graph analytics, and did an in-depth review of
    graph algorithms, the toolset for graph analytics. Graph analytics is making observations
    and drawing conclusions *on* connected data and *about* connected data. Graph
    analytics can give you more insight into your data than would be possible or practical
    with conventional tabular analytics.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们阐述了图分析的定义，讨论了图分析的计算要求，并深入审视了图算法，这是图分析的工具集。图分析是对连接数据进行观察和得出结论，图分析可以帮助您对数据进行更深入的洞察，这是通过传统表格分析难以实现或不切实际的。
- en: Graph algorithms are handy tools for addressing standard analytical tasks. Major
    categories of graph algorithms for analytics include shortest path, centrality,
    community, similarity, node classification, and link prediction. As with any craft,
    using graph algorithms as tools requires some study and practice to know how to
    make the best use of them.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图算法是处理标准分析任务的便利工具。用于分析的图算法的主要类别包括最短路径、中心性、社区、相似性、节点分类和链接预测。与任何技艺一样，将图算法作为工具使用需要一些学习和实践，以知道如何最好地利用它们。
- en: ^([1](ch06.html#ch01fn11-marker)) DFS prioritization is analogous to primogeniture
    for inheritance of titles, where the firstborn child has priority for inheritance.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch06.html#ch01fn11-marker)) DFS 优先级别类似于遗传称号的长子继承权，即长子有优先继承权。
- en: '^([2](ch06.html#ch01fn13-marker)) Glen Jeh and Jennifer Widom, “SimRank: A
    Measure of Structural-Context Similarity,” *KDD ’02: Proceedings of the Eighth
    ACM SIGKDD International Conference on Knowledge Discovery and Data Mining* (July
    2002): 538–543, [*https://dl.acm.org/doi/10.1145/775047.775126*](https://dl.acm.org/doi/10.1145/775047.775126).'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '^([2](ch06.html#ch01fn13-marker)) Glen Jeh 和 Jennifer Widom，“SimRank: 结构上下文相似性的度量”，*KDD
    ’02: 第八届ACM SIGKDD国际知识发现和数据挖掘会议*（2002年7月）：538–543，[*https://dl.acm.org/doi/10.1145/775047.775126*](https://dl.acm.org/doi/10.1145/775047.775126)。'
- en: '^([3](ch06.html#ch01fn14-marker)) Ruoming Jin, Victor E. Lee, and Hui Hong,
    “Axiomatic Ranking of Network Role Similarity,” *KDD ’11: Proceedings of the 17th
    ACM SIGKDD International Conference on Knowledge Discovery and Data Mining* (August
    2011): 922–930, [*https://doi.org/10.1145/2020408.2020561*](https://doi.org/10.1145/2020408.2020561).'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '^([3](ch06.html#ch01fn14-marker)) Ruoming Jin, Victor E. Lee, 和 Hui Hong，“网络角色相似性的公理化排名”，*KDD
    ’11: 第17届ACM SIGKDD国际知识发现和数据挖掘会议*（2011年8月）：922–930，[*https://doi.org/10.1145/2020408.2020561*](https://doi.org/10.1145/2020408.2020561)。'
- en: ^([4](ch06.html#ch01fn15-marker)) In the academic literature for graph data
    science, these two tasks are usually known as *node classification* and *link
    prediction*.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch06.html#ch01fn15-marker)) 在图数据科学的学术文献中，这两个任务通常被称为*节点分类*和*链接预测*。
- en: '^([5](ch06.html#ch01fn16-marker)) Lada A. Adamic and Eytan Adar, “Friends and
    Neighbors on the Web,” *Social Networks* 25, no. 3 (July 2003): 211–230, [*https://doi.org/10.1016/S0378-8733(03)00009-1*](https://doi.org/10.1016/S0378-8733(03)00009-1).'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '^([5](ch06.html#ch01fn16-marker)) Lada A. Adamic 和 Eytan Adar，《Web上的朋友与邻居》，*社交网络*
    25, no. 3 (2003年7月): 211–230，[*https://doi.org/10.1016/S0378-8733(03)00009-1*](https://doi.org/10.1016/S0378-8733(03)00009-1).'
