- en: Chapter 9\. MLOps and Continuous Delivery for ML (CD4ML)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章《MLOps 和机器学习的持续交付（CD4ML）》
- en: That anxiety makes its appearance is the pivot upon which everything turns.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这种焦虑的出现是决定一切的关键点。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Søren Kierkegaard, *The Concept of Anxiety*
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Søren Kierkegaard，《焦虑的概念》
- en: ''
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*It’s 10:36 a.m. Dana is pairing with Ted, an infrastructure engineer, to deploy
    the new model her team has been working on for several months. The energy in the
    room is mixed with determination and anxiety—it’s a new model for a high-profile
    release. They’ve been testing the model for three weeks, but the next hurdle—deployment
    to production—has typically been fraught with issues and numerous retries.*'
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*上午10:36。Dana 正在与基础设施工程师 Ted 配对，部署她的团队几个月来一直在开发的新模型。房间里充满了决心和焦虑的能量——这是一个备受关注的新模型发布。他们已经对模型进行了三周的测试，但接下来的难关——部署到生产环境——通常充满了问题和多次重试。*'
- en: ''
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*As they navigate the labyrinthine web of deployment scripts, configuration
    files, and infrastructure components, Dana couldn’t help but feel that something
    was amiss. She wasn’t confident that their test dataset was representative of
    what the model would be seeing in production. It didn’t help that the complexity
    of the system was so overwhelming—the sheer number of moving parts made it difficult
    to get a sense of where things might go wrong.*'
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*当他们穿越错综复杂的部署脚本、配置文件和基础设施组件时，Dana 感觉到有些不对劲。她并不确定他们的测试数据集是否代表了模型在生产环境中将要面对的情况。系统的复杂性让人难以置信——如此多的运行部件使得很难判断问题可能出在哪里。*'
- en: ''
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*It’s 12:45 p.m. Dana and Ted completed the last of their deployment procedures
    10 minutes ago, but the trickling stream of alerts is a cruel reminder that something
    has gone awry.*'
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*下午12:45。Dana 和 Ted 十分钟前完成了最后的部署程序，但是零星的警报流让人心烦意乱，提醒他们出了什么问题。*'
- en: ''
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*It’s 7:10 p.m. After hours of troubleshooting, a fix has finally been deployed.
    Dana and Ted exhale relief and finally go home, exhausted.*'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*晚上7:10。经过数小时的故障排除，修复终于部署完成。Dana 和 Ted 松了口气，终于可以回家，精疲力尽。*'
- en: ''
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*A week has passed, and one Tuesday morning Dana hears a scrape-triple-knock
    on her Slack. A message at 8:45 a.m.—it is Sarah from product analytics. She informs
    Dana that online loan applications have dropped by 44% since last Thursday’s release.
    Dana pings Ted right away and they dive into the logs, desperate to understand
    what is causing the sudden downturn.*'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*一周过去了，在一个周二的早晨，Dana 在 Slack 上听到了三声轻敲。上午8:45 的消息——来自产品分析的 Sarah。她告知 Dana 自上周四发布以来，在线贷款申请下降了44%。Dana
    立即联系了 Ted，他们一起深入日志，试图理解是什么原因导致了突然的下降。*'
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*After a thorough investigation, they realize that a key feature that the model
    depends on—loan type—is set as an optional field in the UI. Many users omitted
    this detail, which caused the new model to return unreasonable results, leading
    users to give up on their application midway.*'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*经过彻底调查，他们意识到模型依赖的一个关键特征——贷款类型——在用户界面中被设置为可选字段。许多用户省略了这个细节，导致新模型返回不合理的结果，使用户中途放弃他们的申请。*'
- en: ''
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Dana’s heart sank as she realized the gravity of the situation—the months
    of work that her team put into this high-profile release had gone down the drain.*'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*当 Dana 意识到情况的严重性时，她的心沉到了谷底——她的团队为这个备受关注的发布投入了几个月的工作，却白白浪费了。*'
- en: The emotions we feel when delivering ML solutions are useful signals that we
    should pay attention to. For example, we may feel tedium and general “ugh” when
    doing repetitive manual testing for every pull request or production deployment.
    We may experience anxiety when deploying a large set of changes in code and data
    to production once every two months—so much has changed; who knows what could
    go wrong in this production deployment?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在交付机器学习解决方案时所感受到的情绪是我们应该关注的有用信号。例如，当我们为每一个拉取请求或生产部署做重复的手动测试时，我们可能会感到厌倦和一般的“嗯”。当我们每两个月一次地部署一大批代码和数据变更到生产环境时，我们可能会感到焦虑——这么多东西都变了；谁知道这次生产部署会出什么问题？
- en: In this chapter, we’ll describe two complementary schools of thought that help
    teams reliably and iteratively develop, test, deploy, monitor, and improve ML
    models. The first—MLOps—you have probably heard of. The second—CD4ML—may be new
    to you. By the end of the chapter, however, you should understand the role of
    both. Practiced together, MLOps and CD4ML reduce risks of failures during deployment
    and in production, time-to-feedback, cognitive load, and general stress around
    operating models in production.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将描述两种互补的思想流派，帮助团队可靠且迭代地开发、测试、部署、监控和改进机器学习模型。第一种是MLOps——你可能听说过。第二种是CD4ML——这可能对你来说是新的。然而，在本章结束时，你应该理解两者的作用。实践时，MLOps和CD4ML共同降低了部署和生产中的失败风险、反馈时间、认知负荷以及围绕在生产中操作模型的压力。
- en: MLOps is a fast-advancing field. At the time of writing, there were [more than
    20 books](https://oreil.ly/NSYF4) and even more libraries and platforms in the
    MLOps space. These advances in MLOps tooling and practices are great, yet in our
    experience, they are also insufficient. MLOps literature and practitioners tend
    to focus on “ops-y” components (e.g., infrastructure, model deployment, monitoring,
    tools, platforms), while neglecting the equally important aspects of software
    engineering and sociocultural practices (e.g., test automation, deploying early
    and often, trunk-based development, continuous improvement).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps是一个快速发展的领域。在撰写本文时，MLOps领域已经有[超过20本书](https://oreil.ly/NSYF4)，并且有更多的图书馆和平台。这些MLOps工具和实践的进步是巨大的，但在我们的经验中，它们还不足够。MLOps文献和从业者往往专注于“操作性”的组件（例如基础设施、模型部署、监控、工具、平台），而忽视了同样重要的软件工程和社会文化实践（例如测试自动化、早期频繁部署、基于主干的开发、持续改进）。
- en: CD4ML practices address these latter aspects and help teams ensure that changes
    to their software and ML models are continuously tested and monitored for quality.
    Any changes in code, data, or ML models that satisfy comprehensive quality checks
    can be confidently deployed to production at any time. In our experience, CD4ML
    is an effective risk-control mechanism to detect issues and failures in an ML
    system before production deployments (through tests) and after production deployments
    (through monitoring).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: CD4ML实践解决这些后续方面，并帮助团队确保他们的软件和机器学习模型的更改持续测试和监控以确保质量。任何满足全面质量检查的代码、数据或机器学习模型的更改都可以随时自信地部署到生产环境。根据我们的经验，CD4ML是一个有效的风险控制机制，可以在生产部署之前（通过测试）和之后（通过监控）检测到机器学习系统中的问题和故障。
- en: Research from the book [*Accelerate*](https://oreil.ly/PDlPD) (IT Revolution
    Press) shows that continuous delivery practices enable organizations to achieve
    better technical and business performance by helping teams deliver value reliably
    and respond to changes in market demands more nimbly. In our experience practicing
    CD4ML when working with ML teams, we’ve seen great results^([1](ch09.html#ch01fn37))
    in velocity, responsiveness, cognitive load, satisfaction, and product quality.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 《*加速*》一书的研究（[链接](https://oreil.ly/PDlPD)）（IT Revolution Press）显示，持续交付实践使组织能够通过帮助团队可靠地交付价值，并更灵活地响应市场需求的变化来实现更好的技术和商业表现。在我们与机器学习团队合作时实践CD4ML的经验中，我们在速度、响应能力、认知负荷、满意度和产品质量方面看到了显著的结果^（[1](ch09.html#ch01fn37)）。
- en: 'To that end, this chapter will:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本章将：
- en: Establish the basic building blocks of MLOps
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立MLOps的基本构建块
- en: Outline traps that teams often encounter when implementing MLOps
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概述团队在实施MLOps时经常遇到的陷阱
- en: Complement existing MLOps literature with CD4ML principles and practices
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用CD4ML原则和实践来补充现有的MLOps文献
- en: Explore how CD4ML supports ML governance and Responsible AI
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索CD4ML如何支持机器学习治理和负责任人工智能
- en: If you’re already familiar with MLOps techniques, feel free to skip the [“MLOps
    101”](#mlops_onezeroone) section and jump straight into MLOps smells and how CD4ML
    helps teams address these issues. Now that we’ve set the scene, let’s jump into
    the fundamentals of MLOps and common MLOps traps that teams encounter.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经熟悉MLOps技术，请随时跳过[“MLOps 101”](#mlops_onezeroone)部分，直接进入MLOps陷阱以及CD4ML如何帮助团队解决这些问题。现在，我们已经设置了场景，让我们深入了解MLOps的基础知识和团队经常遇到的常见MLOps陷阱。
- en: 'MLOps: Strengths and Missing Puzzle Pieces'
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps：优势与缺失的拼图
- en: In our experience, CD4ML complements MLOps well by adding a set of principles
    and practices that help ML practitioners shorten feedback loops and improve reliability
    of ML systems (see [Figure 9-1](#cdfourml_complements_mlops_well_by_addi)). In
    this section, we’ll deliver a quick overview of MLOps, and look at some common
    smells that suggest gaps in feedback mechanisms on a model’s path to production.
    In the next section, we’ll look at how CD4ML addresses these gaps.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的经验中，CD4ML通过添加一组原则和实践，帮助ML从业者缩短反馈循环并提高ML系统的可靠性，很好地补充了MLOps（见[图 9-1](#cdfourml_complements_mlops_well_by_addi)）。在本节中，我们将快速概述MLOps，并探讨一些常见的迹象，表明模型在生产过程中反馈机制存在的差距。在下一节中，我们将看看CD4ML如何解决这些差距。
- en: '![](assets/emlt_0902.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/emlt_0902.png)'
- en: Figure 9-1\. CD4ML complements MLOps well by adding a set of principles and
    practices that help ML practitioners shorten feedback loops and improve reliability
    of ML systems
  id: totrans-32
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-1\. CD4ML通过添加一组原则和实践，帮助ML从业者缩短反馈循环并提高ML系统的可靠性
- en: MLOps 101
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps 101
- en: MLOps is an ML engineering culture and practice aimed at streamlining the development,
    deployment, and management of ML models. Practicing MLOps means that you automate
    and monitor key components used in the training and deployment of an ML system,
    including the model, data, and software. It is an interdisciplinary field that
    combines elements of ML, infrastructure engineering, software engineering, and
    data engineering to create a more efficient and robust workflow for ML projects.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps是一种旨在简化ML模型开发、部署和管理的ML工程文化和实践。实践MLOps意味着您自动化和监控用于训练和部署ML系统的关键组件，包括模型、数据和软件。它是一个跨学科领域，结合了ML、基础设施工程、软件工程和数据工程的元素，为ML项目创建更高效、更健壮的工作流程。
- en: 'There are many articles enumerating the technical building blocks of MLOps
    (e.g., [Google’s “MLOps: Continuous Delivery and Automation Pipelines in Machine
    Learning”](https://oreil.ly/Z31qn), [Thoughtworks’ “CD4ML Framework”](https://oreil.ly/3t0Vh),
    [INNOQ’s “MLOps Principles”](https://oreil.ly/HuxKJ)), and they generally converge
    on a canonical architecture for supervised learning models, as depicted in [Figure 9-2](#a_typical_mlops_architecturecomma_inclu).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '有许多文章详细列举了MLOps的技术构建模块（例如，[Google的“MLOps: Continuous Delivery and Automation
    Pipelines in Machine Learning”](https://oreil.ly/Z31qn)，[Thoughtworks的“CD4ML Framework”](https://oreil.ly/3t0Vh)，[INNOQ的“MLOps
    Principles”](https://oreil.ly/HuxKJ)），它们通常都聚焦于监督学习模型的典型架构，如[图 9-2](#a_typical_mlops_architecturecomma_inclu)所示。'
- en: '![](assets/emlt_0903.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/emlt_0903.png)'
- en: 'Figure 9-2\. A typical MLOps architecture, including technical components and
    flow of tasks and actions (source: adapted from an image in [“MLOps: Continuous
    Delivery and Automation Pipelines in Machine Learning”](https://oreil.ly/Z31qn)
    by Google Cloud, used under [CC BY 4.0](https://oreil.ly/x-mKJ))'
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 9-2\. 典型的MLOps架构，包括技术组件和任务流的流程（来源：改编自Google Cloud在[“MLOps: Continuous Delivery
    and Automation Pipelines in Machine Learning”](https://oreil.ly/Z31qn)中的图像，使用[CC
    BY 4.0](https://oreil.ly/x-mKJ)许可）'
- en: 'Let’s go through the key components of an MLOps architecture:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看MLOps架构的关键组件：
- en: 1\. Scalable training infrastructure
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 可伸缩的训练基础设施
- en: A scalable training infrastructure refers to large-scale and ephemeral compute
    resources that are right-sized for an ML model’s training workload. While this
    could involve complex implementation details and many hundreds of lines of YAML
    or IaC (infrastructure-as-code) configuration, a good ML platform or tool will
    abstract away this complexity and provide a simple way for ML practitioners to
    provision large-scale compute resources on-demand without needing to tinker with
    training infrastructure.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 可伸缩的训练基础设施指的是针对ML模型训练工作负载合适大小的大规模和短暂计算资源。虽然这可能涉及复杂的实施细节和许多行YAML或IaC（基础设施即代码）配置，但良好的ML平台或工具会将这种复杂性抽象化，并为ML从业者提供一种简单的方式，以便按需提供大规模计算资源，而无需调整训练基础设施。
- en: An important characteristic to call out here is experimental-operational symmetry
    of training infrastructure. This means ensuring that the development environment
    is consistent and production-like. This symmetry ensures that what works during
    experimentation will work during large-scale training in production, and simplifies
    troubleshooting and development in general.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要强调的一个重要特征是训练基础设施的实验操作对称性。这意味着确保开发环境与生产环境一致。这种对称性确保在实验过程中有效的内容也将在生产中的大规模训练中有效，并简化了故障排除和开发过程。
- en: 'Tools include: Metaflow, Ray, Databricks, and various cloud services (e.g.,
    AWS SageMaker, Azure ML, Google Vertex AI).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包括：Metaflow、Ray、Databricks 和各种云服务（例如 AWS SageMaker、Azure ML、Google Vertex
    AI）。
- en: 2\. CI/CD pipelines (with tests, of course!)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. CI/CD 流水线（当然还有测试！）
- en: Continuous integration and continuous delivery (CI/CD) pipelines are essential
    for automating the process of testing and deploying ML models. When done properly,
    they help to verify the quality of every code push and automate the deployment
    of code changes if all prior tests pass. They enable teams to iterate rapidly
    while maintaining confidence in the system’s stability and performance.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 持续集成和持续交付（CI/CD）流水线对于自动化测试和部署 ML 模型的过程至关重要。当正确实施时，它们有助于验证每次代码推送的质量，并在所有先前测试通过的情况下自动部署代码更改。它们使团队能够快速迭代，同时保持对系统稳定性和性能的信心。
- en: Most ML teams that we’ve seen don’t practice CI, even though they have a CI
    pipeline (the following Note defines exactly what qualifies as CI and CD). As
    we explained in [Chapter 5](ch05.html#automated_testing_move_fast_without_bre),
    CI/CD without tests is a contradiction in terms. For a CI/CD pipeline to provide
    useful and fast feedback to ML practitioners, it must perform automated tests—such
    as the metrics tests and behavioral tests that we detailed in [Chapter 6](ch06.html#automated_testing_ml_model_tests)—and
    automated deployment, minimally to a preproduction environment, on every code
    push.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到大多数 ML 团队并不实践 CI，尽管他们有一个 CI 流水线（以下注释确切定义了什么算作 CI 和 CD）。正如我们在 [第五章](ch05.html#automated_testing_move_fast_without_bre)
    中解释的那样，没有测试的 CI/CD 是个矛盾体。为了让 CI/CD 流水线能够向 ML 从业者提供有用且快速的反馈，它必须执行自动化测试——如我们在 [第六章](ch06.html#automated_testing_ml_model_tests)
    中详细介绍的指标测试和行为测试——以及最低限度的自动部署，部署到预生产环境上每一个代码推送。
- en: 'Tools include: GitHub Actions, BuildKite, CircleCI, TeamCity, Jenkins, and
    various cloud resources.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包括：GitHub Actions、BuildKite、CircleCI、TeamCity、Jenkins 和各种云资源。
- en: Note
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Let’s define exactly what qualifies as continuous integration (CI), continuous
    delivery (CD), and continuous deployment:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确切定义什么算作持续集成（CI）、持续交付（CD）和持续部署：
- en: Continuous integration (CI)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 持续集成（CI）
- en: This is a practice that encourages developers to frequently *merge their code
    changes onto the main branch* (aka [trunk-based development](https://oreil.ly/949Mn)),
    ideally multiple times a day. Every code commit is then automatically built and
    tested to catch and report any errors quickly. Nothing is deployed.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种鼓励开发人员频繁*将其代码更改合并到主分支*的实践（又称[基于主干的开发](https://oreil.ly/949Mn)），理想情况下一天多次。每次代码提交后会自动构建和测试，以快速捕获和报告任何错误。无需部署。
- en: Continuous delivery (CD)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付（CD）
- en: This extends CI by ensuring that the code changes are not only tested but also
    prepared for release to production. Deployables (e.g., an ML model service) are
    deployed to a preproduction environment, with post-deployment tests. If all tests
    pass up till this last stage, we’re confident that this release candidate can
    be deployed to production at any time.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过确保代码更改不仅经过测试还准备好发布到生产环境来扩展 CI。可部署物件（例如 ML 模型服务）将被部署到预生产环境，并进行部署后测试。如果直到此最后阶段所有测试都通过，我们就有信心可以随时将这个发布候选部署到生产环境。
- en: Continuous deployment
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 持续部署
- en: This practice goes one step further than continuous delivery—if post-deployment
    tests after deployment to a preproduction environment pass, the deployable is
    automatically deployed to production, without human intervention. This requires
    a mature testing and monitoring setup to ensure that any issue or failure in the
    production environment is caught and fixed quickly.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这种实践比持续交付进一步——如果在部署到预生产环境后的部署后测试通过，则可自动将可部署物件部署到生产环境，无需人工干预。这需要成熟的测试和监控设置，以确保能快速捕捉并修复生产环境中的任何问题或故障。
- en: 3\. Deployment automation
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 部署自动化
- en: In MLOps, automated deployments help reduce manual intervention, human errors,
    and inconsistencies, while also accelerating the development and deployment process.
    It enables teams to streamline their workflows, making them more efficient and
    reliable.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MLOps 中，自动化部署有助于减少手动干预、人为错误和不一致性，同时加速开发和部署过程。它使团队能够优化其工作流程，使其更高效和可靠。
- en: 'Tools include: Seldon, TensorFlow Serving, TorchServe, and various cloud providers.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包括：Seldon、TensorFlow Serving、TorchServe 和各种云提供商。
- en: 4\. “As code” everything
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. "作为代码" 一切
- en: Adopting an “as code” approach in MLOps involves treating all aspects of the
    infrastructure, configuration, deployments, and monitoring as code. This practice
    allows for better version control, reproducibility, automation, and collaboration
    among team members.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在MLOps中采用“作为代码”的方法涉及将基础设施、配置、部署和监控的所有方面视为代码处理。这种实践有助于更好的版本控制、可重现性、自动化和团队成员之间的协作。
- en: 5\. Artifact stores
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 工件存储
- en: Artifact stores such as model registries, container registries, and metadata
    stores persist various artifacts generated during the ML lifecycle. These stores
    enable easy tracking, versioning, and retrieval of artifacts such as models, data,
    and metadata. This helps to facilitate collaboration, traceability, reproducibility,
    and auditability across projects.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 类似模型注册表、容器注册表和元数据存储的工件存储持久化了ML生命周期中生成的各种工件。这些存储库可以轻松跟踪、版本控制和检索模型、数据和元数据等工件。这有助于促进项目之间的协作、可追溯性、可重现性和审计能力。
- en: 'Tools include: Metaflow, Zen ML, and various cloud providers.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包括：[Metaflow](https://example.org/metaflow)，[Zen ML](https://example.org/zen_ml)，和各种云服务提供商。
- en: 6\. Experiment tracking
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. 实验跟踪
- en: Experiment tracking tools help ML practitioners manage and compare the numerous
    experiments that teams invariably run when iterating on ML models. They enable
    ML practitioners to track model performance metrics, hyperparameters, and other
    relevant information, which gives them valuable feedback on the effect of their
    changes. This feedback helps them identify the most promising models and, when
    organized well, can accelerate the development process.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 实验跟踪工具帮助ML从业者管理和比较团队在迭代ML模型时无可避免地运行的大量实验。它们使ML从业者能够跟踪模型性能指标、超参数和其他相关信息，这为他们提供了关于其变更效果的宝贵反馈。这种反馈有助于他们识别最有前景的模型，并且组织良好时，可以加速开发过程。
- en: 'Tools include: Weights and biases, MLFlow, and AWS SageMaker Experiments.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包括：[Weights and biases](https://example.org/weights_and_biases)，[MLFlow](https://example.org/mlflow)，以及[AWS
    SageMaker Experiments](https://example.org/aws_sagemaker_experiments)。
- en: 7\. Feature stores or feature platforms (with data versioning)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 7\. 特征存储或特征平台（具备数据版本控制）
- en: Feature stores serve as a centralized repository for feature engineering, storing
    preprocessed features used in training and inference stages. Data versioning in
    feature stores enables the tracking and management of different data versions,
    ensuring reproducibility and consistency in ML models. By using feature stores,
    teams can share and reuse features across projects without needing to duplicate
    feature processing logic in multiple places wherever features are consumed.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 特征存储作为特征工程的集中存储库，存储用于训练和推断阶段的预处理特征。特征存储中的数据版本控制使得能够追踪和管理不同的数据版本，确保ML模型的可重现性和一致性。通过使用特征存储，团队可以在项目之间共享和重用特征，而无需在多个位置重复特征处理逻辑。
- en: 'Tools include: AWS SageMaker Feature Store, Feast, Tecton, and Feathr.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包括：[AWS SageMaker Feature Store](https://example.org/aws_sagemaker_feature_store)，[Feast](https://example.org/feast)，[Tecton](https://example.org/tecton)，以及[Feathr](https://example.org/feathr)。
- en: 8\. Monitoring in production
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 8\. 生产监控
- en: As we discussed in [Chapter 6](ch06.html#automated_testing_ml_model_tests),
    monitoring in production can and should happen at multiple levels. The first level
    (service health) applies to ML models that are deployed as a web API and involves
    monitoring service-level health metrics that matter to the team (e.g., HTTP status
    codes, errors, latency). The model service should also produce well-structured
    logs to provide teams with valuable insights into system behavior.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第6章](ch06.html#automated_testing_ml_model_tests)中讨论的，生产中的监控可以并且应该在多个级别进行。第一级别（服务健康）适用于部署为Web
    API的ML模型，并涉及监控团队关心的服务级健康指标（例如HTTP状态码、错误、延迟）。模型服务还应生成结构良好的日志，为团队提供有价值的系统行为洞察。
- en: The next level of monitoring (model health) involves tracking and evaluating
    key performance metrics, data drift, and model degradation over time. (Refer to
    the section [“Learn from Production by Closing the Data Collection Loop”](ch06.html#learn_from_production_by_closing_the_da)
    for a definition of types of model drift.) This enables teams to assess their
    real-world performance and identify potential issues with the deployed model.
    To monitor the model’s real-world performance, we need to add new labels to the
    new predictions that the model is making in production (more on this in the next
    point).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下一级别的监控（模型健康）涉及跟踪和评估关键性能指标、数据漂移以及随时间变化的模型退化。（参阅“从生产中学习通过关闭数据收集环路”一节[ch06.html#learn_from_production_by_closing_the_da](https://example.org/learn_from_production_by_closing_the_da)了解模型漂移的定义。）这使团队能够评估其在实际应用中的性能，并识别部署模型可能出现的问题。为了监控模型在实际应用中的性能，我们需要为模型在生产环境中进行的新预测添加新标签（关于这一点，后续会有更多说明）。
- en: The final level of monitoring (business health) involves tracking business metrics
    relevant to our ML model. This varies according to the specific outcome that the
    ML model is intended to influence, but could involve metrics such as user engagement,
    sales, conversions, and number of subscribers.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的监控级别（业务健康）涉及跟踪与我们的 ML 模型相关的业务指标。这根据 ML 模型旨在影响的具体结果而变化，但可能涉及用户参与度、销售、转化率和订阅者数量等指标。
- en: 'Tools include: Alibi Detect, Evidently, Giskard, NannyML, New Relic, Splunk
    and various cloud providers.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包括：Alibi Detect、Evidently、Giskard、NannyML、New Relic、Splunk 和各种云服务提供商。
- en: 9\. Scalable data-labeling mechanisms
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 9\. 可扩展的数据标注机制
- en: The final and arguably most important component of any MLOps stack is a scalable
    data-labeling mechanism. By *scalable*, we mean techniques where user interaction
    signals, expert judgments, natural labels, etc., can be applied to many data points,
    or to just the most important data points for model performance, rather than labeling
    every point individually and indiscriminately. This enables data-centric model
    improvements and enables teams to retrain their model regularly with better data,
    to keep up with a nonstationary world.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 任何 MLOps 栈的最终且可以说是最重要的组成部分是可扩展的数据标注机制。在这里，“可扩展”意味着可以将用户交互信号、专家判断、自然标签等应用于许多数据点，或者仅应用于模型性能最重要的数据点，而不是单独和不加区别地标记每个数据点。这样做有助于数据中心的模型改进，并使团队能够定期使用更好的数据重新训练其模型，以跟上非静态世界的变化。
- en: The key challenge is that teams often face a bottleneck in labeling large volumes
    of data, which is a tedious, time-consuming and labor-intensive task. In addition
    to active learning and representation learning, one technique that we’ve found
    to be effective in addressing this challenge is [weak supervision](https://oreil.ly/yNoND),
    which can reduce annotation time by 10x to 100x compared to unassisted hand labeling,
    allowing teams to create large labeled datasets quickly.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 关键挑战在于团队经常面临数据标注的瓶颈，这是一项乏味、耗时且劳动密集的任务。除了主动学习和表征学习外，我们发现另一种技术在应对这一挑战中非常有效，即 [弱监督](https://oreil.ly/yNoND)，与未辅助手工标注相比，可以将注释时间缩短
    10 到 100 倍，使团队能够快速创建大型标记数据集。
- en: 'Tools include: Snorkel, Cleanlab, and various cloud providers.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包括：Snorkel、Cleanlab 和各种云服务提供商。
- en: Now that we’ve covered the basic building blocks of MLOps, let’s look at some
    common mistakes that teams make when implementing MLOps tools and practices.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了 MLOps 的基本构建模块，让我们看看在实施 MLOps 工具和实践时团队常犯的一些常见错误。
- en: 'Smells: Hints That We Missed Something'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 气味：提示我们错过了某些事情
- en: While the lay of the MLOps land from 10,000 feet looks logical and straightforward,
    teams building ML systems on the ground often find themselves getting ensnared
    in a complex terrain with many moving parts.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管从 10,000 英尺高空俯视 MLOps 的布局看起来逻辑和简单，但在地面上构建 ML 系统的团队常常发现自己陷入复杂的地形中，涉及许多移动部分。
- en: If each MLOps component is a waypoint in a journey, teams either completely
    miss out on a critical waypoint (e.g., they don’t have a scalable data-labeling
    mechanism), or they stop at the right waypoint but miss what they were meant to
    do there (e.g., implementing CI/CD pipelines without automated tests). This oversight
    can lead to detrimental consequences, including model quality issues in production
    and unwarranted friction that slows down experimentation and model improvements.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果每个 MLOps 组件都是旅程中的一个航点，团队可能完全错过了一个关键航点（例如，他们没有一个可扩展的数据标注机制），或者他们在正确的航点停下来，却错过了他们在那里应该做的事情（例如，在没有自动化测试的情况下实施
    CI/CD 流水线）。这种疏忽可能导致严重后果，包括生产中的模型质量问题以及减缓实验和模型改进速度的不必要摩擦。
- en: In this section, we’ll use the concept of “smells” (i.e., signals that suggest
    deeper problems) that we introduced in [Chapter 7](ch07.html#supercharging_your_code_editor_with_sim)
    to illustrate some common mistakes that we’ve seen in how teams apply MLOps practices.
    This sets the stage for the next section, where we explore how CD4ML complements
    MLOps and helps teams overcome these challenges.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用我们在 [第 7 章](ch07.html#supercharging_your_code_editor_with_sim) 中引入的“气味”概念（即指示更深层问题的信号），来说明团队在应用
    MLOps 实践时常见的一些错误。这为下一节打下了基础，我们将探讨 CD4ML 如何补充 MLOps 并帮助团队克服这些挑战。
- en: 'MLOps smell 1: CI/CD pipelines with no tests'
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'MLOps 气味 1: 没有测试的 CI/CD 流水线'
- en: As we mentioned in [Chapter 6](ch06.html#automated_testing_ml_model_tests),
    CI/CD pipelines without tests is a contradiction in terms—how can we continuously
    integrate (CI) code to the main branch if we don’t have automated tests to check
    for errors? Yet it’s common to see teams with this smell—possibly because ML engineers
    know how to set up CI pipelines and data scientists know how to train and evaluate
    models, but not all teams have worked out how to bridge both practices to automate
    model-evaluation procedures.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[第 6 章](ch06.html#automated_testing_ml_model_tests)中提到的，没有测试的 CI/CD 管道是个悖论——如果没有自动化测试来检查错误，我们如何持续集成（CI）代码到主分支呢？然而，我们经常看到团队存在这种问题——可能是因为机器学习工程师知道如何设置
    CI 管道，数据科学家知道如何训练和评估模型，但并非所有团队都能找到将这两者实践结合起来自动化模型评估过程的方法。
- en: The consequences are manifold. First, bugs and errors easily slip into the codebase
    and even into production. Second, we end up wasting significant amounts of time
    testing for or fixing errors. Third, even if we’ve optimized other parts of our
    CI/CD pipeline (e.g., model deployment in 30 seconds), the testing and quality
    assurance step will remain a bottleneck (e.g., manual testing takes a few hours,
    or whenever we have time to do it, which then stretches the bottleneck out to
    days or weeks).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 其后果是多方面的。首先，错误和漏洞很容易进入代码库甚至进入生产环境。其次，我们浪费了大量时间来测试或修复错误。第三，即使我们已经优化了 CI/CD 管道的其他部分（例如，30
    秒内模型部署），测试和质量保证步骤仍然是一个瓶颈（例如，手动测试需要几小时，或者在我们有时间进行时，这会将瓶颈拉长到几天甚至几周）。
- en: 'Fourth and finally, the lack of automated quality checks nudges us out of the
    main branch and into feature branches, because no one wants to: (i) accidentally
    commit defects or issues into the main branch, or (ii) manually and comprehensively
    test every commit. In our experience, this deferred integration (as opposed to
    continuous integration to the main branch we defined earlier) often causes merge
    conflicts when team members finally merge their branch after days or weeks of
    work. We have never met a single person who likes merge conflicts and unnecessarily
    wasting time and cognitive effort resolving merge conflicts.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 第四，也是最后，缺乏自动化质量检查推动我们离开主分支，进入功能分支，因为没有人愿意：（i）意外地将缺陷或问题提交到主分支，或者（ii）在每次提交后手动和全面地测试。根据我们的经验，这种推迟的集成（与我们之前定义的持续集成到主分支相反）经常会在团队成员在数天或数周的工作后最终合并分支时引发合并冲突。我们从未遇到过一个喜欢合并冲突并且不必要地浪费时间和认知努力来解决合并冲突的人。
- en: 'MLOps smell 2: Infrequent model deployments to production or preproduction
    environments'
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MLOps 异味 2：模型很少部署到生产环境或预生产环境
- en: Infrequent deployments to production and preproduction environments suggest
    that a team is not confident in the reliability and quality of changes (in code,
    data, and model).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据部署到生产环境和预生产环境的频率低下表明团队对代码、数据和模型的可靠性和质量缺乏信心。
- en: Infrequent deployments increase the likelihood of deployment failures. For example,
    deploying 100 commits (e.g., to a preproduction environment) every four weeks
    is very different from deploying five commits every day, even though the net number
    of commits is the same. In the first scenario, if a deployment fails, you have
    100 potential suspects and 4,950 pairwise interactions between suspects, which
    is far more difficult to debug than five (and 10 pairwise interactions). This
    is true for both production and preproduction environments.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 部署不频繁会增加部署失败的可能性。例如，每四周部署 100 个提交（例如，到预生产环境），与每天部署五个提交截然不同，尽管提交的总数相同。在第一个场景中，如果一个部署失败，你有
    100 个潜在的嫌疑人和 4,950 对之间的交互，这比五个（和 10 对之间的交互）要难得多。这对生产环境和预生产环境都是如此。
- en: 'That’s the value of having small batch sizes. David Farley and Jez Humble put
    it well in [*Continuous Delivery*](https://oreil.ly/HR-Bw) (Addison-Wesley Professional):
    “The earlier you catch defects, the cheaper they are to fix.” Smaller batch sizes
    allow you to catch defects earlier. In addition, infrequent deployments can hinder
    the team’s ability to respond to user feedback, fix issues, or introduce new features,
    ultimately impacting the overall responsiveness of the team and ML product.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是拥有小批量大小的价值。David Farley 和 Jez Humble 在《持续交付》（Addison-Wesley Professional）中表达得很好：提前发现缺陷，修复成本更低。较小的批量大小使您能够更早地发现缺陷。此外，部署不频繁可能会妨碍团队响应用户反馈、修复问题或引入新功能的能力，最终影响团队和
    ML 产品的整体响应能力。
- en: 'MLOps smell 3: Data in production goes to waste'
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MLOps 异味 3：生产中的数据被浪费
- en: Teams often throw away the data that a model generates in production (e.g.,
    requests and predictions)—data that could be used to improve their ML models.
    This can occur due to lack of proper data collection, processing, and labeling
    mechanisms. As a result, teams throw away a valuable feedback mechanism that can
    enhance the performance of the ML system.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 团队通常会在生产中丢弃模型生成的数据（例如请求和预测）——这些数据本可以用来改进他们的机器学习模型。这可能是由于缺乏适当的数据收集、处理和标记机制所致。因此，团队丢失了一个宝贵的反馈机制，可以提升机器学习系统的性能。
- en: Failing to process and leverage this new data from production for subsequent
    training can lead to models becoming outdated or less accurate over time, as they
    may not account for shifts in user behavior, changes in the environment, or emerging
    trends. Moreover, it can hinder the team’s ability to identify and address potential
    issues or biases in the models, which negatively impacts the ML product’s user
    experience in the real world.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未能处理和利用来自生产环境的新数据进行后续训练，可能导致模型随时间变得过时或不够准确，因为它们可能无法考虑用户行为的变化、环境的变化或新兴趋势。此外，这可能会阻碍团队识别和解决模型中潜在问题或偏见的能力，从而对机器学习产品在现实世界中的用户体验产生负面影响。
- en: In contrast, when teams design their ML system to close the data collection
    loop, they create a [flywheel effect](https://oreil.ly/h-h6l), where more usage
    of the model results in more data, which in turn leads to further refinements
    and improvements in the model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，当团队设计他们的机器学习系统以闭环数据收集时，他们创造了一个[飞轮效应](https://oreil.ly/h-h6l)，其中模型的更多使用导致更多数据，进而进一步改进和完善模型。
- en: 'MLOps smell 4: X is another team’s responsibility'
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MLOps 的臭味 4：X 是另一个团队的责任
- en: 'When you hear the phrase, “X (e.g., deployment, integration, customer experience,
    security) is another team’s responsibility” in one form or another, it’s usually
    a smell that suggests a number of deeper underlying problems. The first issue
    relates to team structure: The team wasn’t set up correctly and is lacking some
    key competency (e.g., deployment, integration, customer experience, security).
    To move fast, a team should have these core competencies, or be supported by enabling
    teams for cross-cutting competencies such as security, as we will explore in [Chapter 11](ch11.html#effective_ml_organizations).
    This will allow the team to operate autonomously without depending on (and risk
    being blocked by) other teams.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当你听到类似“X（例如部署、集成、客户体验、安全性）是另一个团队的责任”的说法时，通常这暗示着一些更深层次的问题。第一个问题涉及团队结构：团队没有正确设置，并且缺少某些关键的能力（例如部署、集成、客户体验、安全性）。为了快速前进，一个团队应该拥有这些核心能力，或者由支持跨领域能力（例如安全性）的使能团队支持，正如我们将在[第11章](ch11.html#effective_ml_organizations)中探讨的那样。这将使团队能够在不依赖于其他团队（并且不会因此而受阻）的情况下运行。
- en: 'The second issue relates to culture: X is someone else’s problem. We often
    detect the “someone else’s problem” mindset at the boundaries between teams, which
    indicates that both issues—structure and culture—are often mutually reinforcing.
    This mindset hinders collaboration and creates an environment where issues are
    left unaddressed, resulting in a suboptimal MLOps process and potentially compromising
    the quality and reliability of the ML models. This runs contrary to the DevOps
    mindset, which is focused on breaking down the wall between Dev and Ops (see [Figure 9-3](#a_devops_culture_breaks_down_the_divide))
    and now ML and Ops, so that ML folk (e.g., data scientists) and operations folk
    (e.g., ML engineers) pair to solve difficult challenges (e.g., automated quality
    assurance for ML models) and productionize reliable ML systems.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个问题涉及文化：X 是别人的问题。我们经常在团队之间的边界上检测到“别人的问题”思维方式，这表明结构和文化两个问题通常是相互加强的。这种思维方式阻碍了协作，并创造了一个未解决问题的环境，从而导致了次优的MLOps流程，并潜在地损害了机器学习模型的质量和可靠性。这与DevOps思维相悖，后者专注于打破开发和运维之间的壁垒（参见[图9-3](#a_devops_culture_breaks_down_the_divide)），现在还包括了ML和Ops，使得ML人员（例如数据科学家）和运维人员（例如ML工程师）联合解决难题（例如ML模型的自动化质量保证）并推广可靠的ML系统。
- en: '![](assets/emlt_0904.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/emlt_0904.png)'
- en: 'Figure 9-3\. The DevOps culture seeks to break down the divide between development
    teams and operations teams (source: [“DevOps Is Not a Role” by Daniel Stori](https://oreil.ly/CH_Q8),
    used under [CC BY-NC-SA 4.0](https://oreil.ly/-MSwI))'
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-3. DevOps文化旨在打破开发团队和运维团队之间的分隔（来源：[“DevOps Is Not a Role” by Daniel Stori](https://oreil.ly/CH_Q8)，在[CC
    BY-NC-SA 4.0](https://oreil.ly/-MSwI)下使用）
- en: By this point, you understand the fundamentals of MLOps and have seen, and perhaps
    identified with, these four gaps of MLOps—lack of automated tests, infrequent
    deployments, wasted production data, and “someone else’s problems.” Let’s now
    look at how the principles and practices of continuous delivery (CD) complement
    MLOps and mitigate these issues to help teams deliver reliably.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经了解了 MLOps 的基本原理，并看到，并且可能已经识别出了 MLOps 的这四个缺口——缺乏自动化测试、部署不频繁、生产数据浪费和“别人的问题”。现在让我们看看连续交付（CD）的原则和实践如何补充
    MLOps 并减少这些问题，以帮助团队可靠地交付。
- en: Continuous Delivery for Machine Learning
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于机器学习的持续交付
- en: What if we told you that there was a way to get changes of all types—including
    new models, new features, and bug fixes—to production and into the hands of users,
    safely, quickly, and reliably? Well, that is exactly what continuous delivery
    (CD) helps us achieve.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们告诉您，有一种方法可以安全、快速和可靠地将各种类型的更改（包括新模型、新功能和错误修复）推送到生产环境并交付给用户，那么这就是连续交付（CD）帮助我们实现的正是这一点。
- en: 'In this section, we will go through:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论：
- en: Benefits of CD4ML (the “why”)
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CD4ML 的好处（“为什么”）
- en: Principles of CD (the “what”)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CD 的原则（“什么”）
- en: Practices and building blocks of CD4ML (the “how”)
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CD4ML 的实践和构建模块（“如何”）
- en: Let’s begin by digging into the “why.”
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从深入探讨“为什么”开始。
- en: Benefits of CD4ML
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CD4ML 的好处
- en: 'Fully practicing CD4ML yields outcomes that virtually all ML teams desire.
    Let’s look at three key benefits:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 完全实践 CD4ML 可以产生几乎所有 ML 团队都渴望的结果。让我们看看三个关键好处：
- en: Shorter cycle times (between an idea and shipping it to customers in production)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 周期时间缩短（从想法到在生产中交付给客户的时间）
- en: CD4ML enables faster development and deployment cycles. By automating the processes
    involved in building, testing, and deploying ML models, teams can reduce the time
    and effort required in tedious, undifferentiated labor, such as repetitive manual
    testing. In our experience, this has helped us accelerate the time-to-market for
    changes of any kind, allowing teams to quickly respond to evolving business needs
    or market conditions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: CD4ML 可以加快开发和部署周期。通过自动化构建、测试和部署 ML 模型的流程，团队可以减少重复的手动测试等枯燥的、非差异化劳动所需的时间和精力。根据我们的经验，这有助于加速任何类型变更的上市时间，使团队能够快速响应不断变化的业务需求或市场条件。
- en: Lower defect rates
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 缺陷率降低
- en: Another advantage of CD4ML is improved model quality and performance. With comprehensive
    automated tests (as described in Chapters [5](ch05.html#automated_testing_move_fast_without_bre)
    and [6](ch06.html#automated_testing_ml_model_tests)) at each stage in the path
    to production, ML teams can quickly detect and fix any issues or bugs in their
    models before deployment. This enables them to ensure quality and reliability
    in their ML applications. The practice of monitoring model performance in production
    also allows teams to detect any degradation in model quality as it happens and
    make necessary updates or retrain models as needed.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个 CD4ML 的优势是提高了模型的质量和性能。在通向生产过程中的每个阶段都进行了全面的自动化测试（如第 [5](ch05.html#automated_testing_move_fast_without_bre)
    章和第 [6](ch06.html#automated_testing_ml_model_tests) 章所述），ML 团队可以快速检测和修复模型中的任何问题或错误，然后再进行部署。这使他们能够确保其
    ML 应用的质量和可靠性。在生产环境中监控模型性能的做法还允许团队在发生质量下降时立即检测并进行必要的更新或重新训练模型。
- en: CD4ML enables teams to “fail fast and fail loudly.” This ability to detect issues—through
    tests or monitoring—is especially important in ML systems because, unlike typical
    software applications, ML models are prone to silent errors. Such errors might
    not immediately crash the system or cause noticeable failures, but they can cause
    mispredictions that adversely affect the user experience. The result is that *users*
    will be the ones detecting and experiencing quality issues in production for an
    extended period of time until the issues are detected and resolved by the team.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: CD4ML 使团队能够“快速失败并大声失败”。通过测试或监控来检测问题的这种能力在 ML 系统中尤为重要，因为与典型的软件应用程序不同，ML 模型容易发生静默错误。这些错误可能不会立即使系统崩溃或引起明显的故障，但它们可能导致误预测，从而对用户体验产生不利影响。结果是，*用户*可能会在生产中长时间内检测到并经历质量问题，直到团队检测并解决这些问题为止。
- en: Faster recovery times (should something go wrong in production)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 恢复时间更快（如果在生产中出现问题）
- en: By embracing the practice of small, frequent deployments, teams can more easily
    triage and resolve problems. With an automated and streamlined deployment process,
    it becomes easier to roll back to a previous stable version or deploy fixes, minimizing
    downtime and potential damage to the user experience or the organization’s reputation.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通过采纳小而频繁的部署实践，团队可以更轻松地分类和解决问题。借助自动化和流程化的部署过程，更容易回滚到之前的稳定版本或部署修复程序，从而最小化停机时间和对用户体验或组织声誉的潜在损害。
- en: Note
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'In [*Accelerate*](https://oreil.ly/PDlPD), the authors present the findings
    of four years of research on software development practices to answer the question:
    What factors and practices set high-performing technology organizations apart
    from organizations with poorer business and financial performance?'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在《Accelerate》中，作者们通过四年的软件开发实践研究发现了什么因素和实践使高绩效技术组织与业绩较差的组织有所区别。
- en: 'They present insights based on data collected from thousands of organizations
    and highlight the key practices that drive excellence in software delivery. One
    of the key findings is a set of [24 key capabilities](https://oreil.ly/BJhd7)
    that drive improvements in software delivery performance in a statistically significant
    way. These 24 capabilities can be grouped into five categories:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 他们基于收集的成千上万个组织的数据提供了洞见，并强调了推动软件交付卓越的关键实践。其中一个关键发现是一组[24个关键能力](https://oreil.ly/BJhd7)，以统计显著的方式推动软件交付绩效的改进。这24个能力可以分为五类：
- en: Continuous delivery (the focus of this chapter)
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续交付（本章的重点）
- en: Architecture
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 架构
- en: Product and process (see [Chapter 2](ch02.html#product_and_delivery_practices_for_ml_t))
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品和流程（见[第2章](ch02.html#product_and_delivery_practices_for_ml_t)）
- en: Lean management and monitoring (see [Chapter 11](ch11.html#effective_ml_organizations))
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精益管理和监控（见第[11章](ch11.html#effective_ml_organizations)）
- en: Culture (see Chapters [10](ch10.html#building_blocks_of_effective_ml_tea) and
    [11](ch11.html#effective_ml_organizations))
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文化（见第[10](ch10.html#building_blocks_of_effective_ml_tea)章和第[11](ch11.html#effective_ml_organizations)章）
- en: While this empirical study hasn’t been replicated for ML teams yet at the time
    of writing, our experience working with teams to deliver ML solutions corroborate
    the authors’ conclusions.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在写作时，这项实证研究尚未为机器学习团队复制，但我们与团队合作交付机器学习解决方案的经验证实了作者的结论。
- en: A Crash Course on Continuous Delivery Principles
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于持续交付原则的速成课
- en: 'Now that we’ve seen the benefits of CD4ML, let’s delve into the core principles
    that guide CD practices. There are five principles at the heart of [CD](https://oreil.ly/W-AXL):'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了CD4ML的好处，让我们深入探讨指导CD实践的核心原则。在CD的核心有五个原则：[持续交付](https://oreil.ly/W-AXL)。
- en: 'Principle 1: Build quality into the product'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 原则1：在产品中建立质量
- en: It’s much more cost-effective to address issues and defects if they are detected
    as soon as they are introduced. Identifying defects later in the process through
    inspection methods (e.g., manual testing) is time-intensive and demands significant
    triage efforts. As stated in [“14 Points for Management”](https://oreil.ly/JsKu9)
    by Lean pioneer Edward Deming, we should “cease dependence on inspection to achieve
    quality. Eliminate the need for inspection on a mass basis *by building quality
    into the product in the first place*.”
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果能够在引入时立即检测到问题和缺陷，成本效益将更高。通过检查方法（例如手动测试）在后期识别缺陷是非常耗时的，并需要大量的分类工作。正如精益先锋爱德华·戴明在《管理的14点》中所述，我们应该“停止依赖检查来实现质量。首先在产品中建立质量，从而消除大规模检查的需要*。”（[“14
    Points for Management”](https://oreil.ly/JsKu9)）
- en: Preferably, we want to detect defects before they are even committed, by running
    automated tests. For ML, this can be achieved by writing automated tests for software,
    ML models, and data. Having an ML platform that enables ML practitioners to train
    models on-demand on scalable ephemeral infrastructure and run tests thereafter
    can help to obviate the need to commit and push code to know if something works.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最好能在提交之前检测到缺陷，通过运行自动化测试来实现。对于机器学习，可以通过为软件、机器学习模型和数据编写自动化测试来实现。拥有一个机器学习平台，使机器学习实践者能够根据需要在可扩展的临时基础设施上训练模型并进行测试，有助于避免提交和推送代码以了解某些功能是否正常工作的需要。
- en: By creating mechanisms to detect and resolve issues as soon as they appear,
    teams save effort and reduce context-switching between creating solutions and
    fixing broken stuff. Recall that in [Chapter 2](ch02.html#product_and_delivery_practices_for_ml_t),
    we go even further upstream, introducing methods to catching defects in *requirements*
    before we even write a line of code.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 通过创建机制来检测和解决问题，团队能够在问题出现时立即采取行动，从而节省精力，并减少在解决问题和修复故障之间的切换。回想一下，在[第2章](ch02.html#product_and_delivery_practices_for_ml_t)中，我们在甚至开始编写代码之前就引入了捕捉*需求*缺陷的方法。
- en: 'Principle 2: Work in small batches'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 原则2：采用小批量工作。
- en: In the 1990s and even into the 2010s, it was common for software to be handed
    off between multiple teams (from a team of business analysts to architects to
    developers to testers to operations) so that it could be deployed to production.
    In these cases, batch sizes were incredibly large—this is typically weeks and
    months of work before anything is deployed to production. (We still see this happening
    in some ML teams today!)
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪90年代甚至进入2010年代，将软件交接给多个团队（从业务分析师团队到架构师、开发人员、测试人员再到运营团队）以便部署到生产环境是很常见的。在这些情况下，批次大小非常大——通常是数周甚至数月的工作才能部署到生产环境。（我们今天仍然看到某些机器学习团队依然存在这种情况！）
- en: When continuous delivery was introduced circa 2010, it enabled teams to ship
    work in smaller batch sizes. Working in smaller batches offers numerous advantages,
    such as reduced time-to-feedback, reduced cognitive load, easier problem triage
    and remediation, and improved efficiency and sense of progress.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 自从2010年左右引入持续交付以来，团队可以以更小的批次大小进行工作。以更小的批次工作有很多优点，比如减少反馈时间、减少认知负荷、更容易进行问题分类和修复，以及提高效率和进度感。
- en: Along the path to production, we instrument multiple quality gates to give us
    rapid and comprehensive feedback on the quality of our changes. In the ML context,
    quality gates include automated tests (for software, data, and model), deployments
    to preproduction environments, post-deployment tests, and other fitness functions
    that we described in [Chapter 6](ch06.html#automated_testing_ml_model_tests).
    When the quality gates are comprehensive, we can confidently deploy any green
    build (triggered by code changes or scheduled training runs) to production.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在产品上线的过程中，我们设置了多个质量门，以便迅速和全面地反馈我们变更的质量。在机器学习的背景下，质量门包括自动化测试（软件、数据和模型）、部署到预生产环境、部署后测试以及我们在[第6章](ch06.html#automated_testing_ml_model_tests)中描述的其他适应性函数。当质量门覆盖全面时，我们可以放心地将任何绿色构建（由代码更改或计划的训练运行触发）部署到生产环境。
- en: 'Principle 3: Automation—computers perform repetitive tasks, people solve problems'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 原则3：自动化——计算机执行重复任务，人们解决问题。
- en: Automation is a critical component for streamlining and optimizing the process
    of delivering ML solutions. By automating repetitive tasks such as linting, testing,
    and deploying code, teams reduce the amount of manual intervention needed and
    consequently the amount of human error. This significantly improves efficiency
    and reliability.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化是简化和优化机器学习解决方案交付过程的关键组成部分。通过自动化诸如代码检查、测试和部署等重复任务，团队减少了需要手动干预的工作量，从而显著提高了效率和可靠性。
- en: Automated processes can also shorten feedback loops, enabling developers to
    identify and fix issues more quickly. This allows teams to focus on higher-level
    problem solving and innovation, rather than being bogged down by tedious tasks.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化过程还可以缩短反馈循环，使开发人员能够更快地识别和解决问题。这使团队能够专注于高级别的问题解决和创新，而不被繁琐的任务所拖累。
- en: 'Principle 4: Relentlessly pursue continuous improvement'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 原则4：不懈追求持续改进。
- en: As you may recall from [Chapter 1](ch01.html#challenges_and_better_paths_in_deliveri),
    continuous improvement (or *Kaizen* in Japanese) is one of the five principles
    of Lean. The goal of Kaizen is to help organizations and teams identify and eliminate
    waste, thereby improving the flow of value.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可能记得的那样，在[第1章](ch01.html#challenges_and_better_paths_in_deliveri)中，持续改进（或者用日语的*Kaizen*）是精益五大原则之一。Kaizen的目标是帮助组织和团队识别和消除浪费，从而改善价值流动。
- en: In our experience, the team’s mindset and actions—to pragmatically pursue collective
    continuous improvement—are more important than the forum (e.g., retrospectives,
    tech debt huddles, standups). Without the Kaizen mindset, suggestions for improvement
    are almost always procrastinated to accommodate other priorities, and team members
    can often give up trying.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的经验，团队的心态和行动——实现集体持续改进——比论坛（如回顾、技术债务聚焦会议、站立会议）更重要。如果没有改善的快速追求心态，改进建议几乎总是被拖延以适应其他优先事项，团队成员往往会放弃尝试。
- en: 'Principle 5: Everyone is responsible'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 'Principle 5: Everyone is responsible'
- en: In high-performing ML teams, nothing is “somebody else’s problem.” In contrast,
    low-performing teams often exude behavior that implies beliefs such as “deployability
    is not my concern,” or “we don’t have to worry about these vulnerable dependencies
    warnings because security is not an area of focus for our team.”
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在高效 ML 团队中，没有“别人的问题”。相反，低效团队经常表现出“部署性不是我的问题”等信念，或者“我们不必担心这些有漏洞的依赖警告，因为安全不是我们团队关注的领域”。
- en: While the will and desire to do the right thing is important, individuals and
    teams can quickly run out of steam and lose hope when they’re not supported with
    the right capabilities. Remember our earlier point on how structure and culture
    are mutually reinforcing? We can use the appropriate team structure (e.g., a cross-functional
    team) to build a practice and culture of developing and deploying reliable ML
    solutions. Everyone—data scientists, ML engineers, data engineers, platform engineers,
    product owners, security specialists, domain experts, etc.—works together to deliver
    reliable ML solutions, rather than optimizing for what’s best for their team or
    department.^([2](ch09.html#ch01fn38))
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有意愿和愿望做正确的事情很重要，但当个人和团队在没有得到正确能力支持时，他们可能会迅速失去动力和希望。还记得我们之前提到的结构和文化如何相互加强吗？我们可以使用适当的团队结构（例如跨功能团队）来建立开发和部署可靠
    ML 解决方案的实践和文化。每个人——数据科学家、ML 工程师、数据工程师、平台工程师、产品所有者、安全专家、领域专家等——共同努力交付可靠的 ML 解决方案，而不是优化他们团队或部门的最佳实践。^([2](ch09.html#ch01fn38))
- en: Now that we’ve established the five principles of CD, let’s now delve into the
    supporting practices for each principle. Together, these practices help ML teams
    ship reliable ML solutions to production early and often and enjoy their benefits.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经明确了持续交付的五个原则，让我们深入探讨每个原则的支持实践。这些实践共同帮助 ML 团队早期和频繁地将可靠的 ML 解决方案交付到生产中，并享受它们的好处。
- en: 'Building Blocks of CD4ML: Creating a Production-Ready ML System'
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CD4ML 的构建模块：创建可投入生产的 ML 系统
- en: In this section, we will describe the CD practices that help teams reduce waste
    and improve flow when delivering ML models. For the impatient, [Table 9-1](#mapping_practices_for_ml_teams_to_cd_pr)
    provides an overview of these practices.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述有助于团队在交付 ML 模型时减少浪费、改进流程的持续交付实践。对于急于了解的人，[表 9-1](#mapping_practices_for_ml_teams_to_cd_pr)
    提供了这些实践的概述。
- en: Table 9-1\. Mapping practices for ML teams to CD principles
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9-1\. 将 ML 团队的实践映射到持续交付原则
- en: '| CD principle | Supporting practices in ML teams |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| CD 原则 | ML 团队中的支持实践 |'
- en: '| --- | --- |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1\. Build quality into the product | 1.1 Test automation 1.2 Shift left on
    security |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 1\. 将质量融入产品中 | 1.1 测试自动化 1.2 安全左移 |'
- en: '| 2\. Work in small batches | 2.1 Use version control for all production artifacts
    2.2 Practice pair programming'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '| 2\. Work in small batches | 2.1 对所有生产工件使用版本控制 2.2 实践配对编程'
- en: 2.3 Implement continuous integration (CI)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 2.3 实施持续集成（CI）
- en: 2.4 Apply trunk-based development |
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 2.4 应用基于主干的开发 |
- en: '| 3\. Automation: Computers perform repetitive tasks, people solve problems
    | 3.1 Create reproducible development environments for developing models 3.2 Automate
    deployments (minimally to a preproduction environment)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '| 3\. 自动化：计算机执行重复任务，人们解决问题 | 3.1 为开发模型创建可重现的开发环境 3.2 自动化部署（至少到预生产环境）'
- en: 3.3 Monitor in production |
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 3.3 在生产中进行监控 |
- en: '| 4\. Relentlessly pursue continuous improvement | 4.1 Practice Kaizen (identify
    and act on opportunities for improvement) |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 4\. 不懈追求持续改进 | 4.1 实践改善（识别和行动改进的机会） |'
- en: '| 5\. Everyone is responsible | 5.1 Adopt the appropriate team topologies for
    your organization |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 5\. Everyone is responsible | 5.1 采用适合您组织的团队拓扑结构 |'
- en: Build quality into the product
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将质量融入产品中
- en: Let’s look at the practices that help teams build quality into their ML solutions.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看帮助团队将质量融入他们的 ML 解决方案的实践。
- en: Test automation
  id: totrans-161
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 测试自动化
- en: We’ve covered the why, what, and how of testing ML systems extensively in Chapters
    [5](ch05.html#automated_testing_move_fast_without_bre) and [6](ch06.html#automated_testing_ml_model_tests).
    A key point we made is that without comprehensive automated tests, teams *cannot*
    practice CI and CD. (We elaborate on why in the section [“Implement continuous
    integration (CI)”](#implement_continuous_integration_left_p).)
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第五章](ch05.html#automated_testing_move_fast_without_bre)和[第六章](ch06.html#automated_testing_ml_model_tests)中详细介绍了测试ML系统的原因、内容和方法。我们强调的一个关键点是，如果没有全面的自动化测试，团队将*无法*实践CI和CD。（我们在“实施持续集成（CI）”部分详细阐述了为什么。）
- en: Without tests that run automatically on every code push or every model training
    run, ML practitioners are forced to take on the burden of regression testing,
    which then diverts energy from other higher-value work, before any code change
    can be merged to the main branch (or model deployed to production). If they don’t,
    teams roll the dice and run the risk of introducing defects into the codebase
    and into production, which they then have to fix later whenever the defect is
    detected. As we’ve discussed before, it’s much more cost-effective to detect such
    issues early through comprehensive automated tests.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有在每次代码推送或每次模型训练运行时自动运行的测试，ML从业者将不得不承担回归测试的负担，这会分散他们在其他更高价值工作上的精力，在合并到主分支（或模型部署到生产环境）之前需要解决任何代码更改。如果不这样做，团队将冒险并面临将缺陷引入代码库和生产环境的风险，然后不得不在检测到缺陷时修复它们。正如我们之前讨论过的，通过全面的自动化测试及早检测此类问题要更具成本效益。
- en: Shift left on security
  id: totrans-164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全左移
- en: Shifting left on security means incorporating security measures early and throughout
    the ML development process, rather than considering them as an afterthought or
    a final checkpoint before deployment. This proactive approach helps teams preempt
    and defend against vulnerabilities and security issues before they become deeply
    embedded in the system, making them more costly and difficult to address later.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 安全左移意味着在ML开发过程的早期和整个过程中加入安全措施，而不是将其视为事后思考或最终部署前的最后检查点。这种积极的方法帮助团队在漏洞和安全问题深入系统之前防范和防御，使其后期修复变得更加昂贵和困难。
- en: 'This practice can include:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这种做法可以包括：
- en: Conducting security reviews and [threat modeling](https://oreil.ly/0p1V_) of
    ML solutions including involving the information security (InfoSec) team early
    on in the process of design and delivery
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对ML解决方案进行安全审查和[威胁建模](https://oreil.ly/0p1V_)，包括在设计和交付过程中及早引入信息安全（InfoSec）团队
- en: Reviewing, identifying, and mitigating [failure modes of an ML model](https://oreil.ly/gFDG1)
    (e.g., adversarial attacks, data poisoning)
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对ML模型的故障模式进行审查、识别和减轻（例如，对抗性攻击、数据污染）
- en: Establishing access controls to prevent unauthorized use
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立访问控制以防止未经授权的使用
- en: Automating the detection and updating of vulnerable dependencies (see [Chapter 4](ch04.html#effective_dependency_management_in_prac))
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化检测和更新易受攻击依赖项（见[第四章](ch04.html#effective_dependency_management_in_prac)）
- en: Including [automated security tests](https://oreil.ly/TK7xZ) as part of the
    automated testing suite on the CI pipeline
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包括将[自动化安全测试](https://oreil.ly/TK7xZ)作为CI流水线上自动化测试套件的一部分
- en: Supporting your organization’s security function, for example by having [security
    champions](https://oreil.ly/BX9Ry)
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持您组织的安全功能，例如通过拥有[安全冠军](https://oreil.ly/BX9Ry)
- en: 'Beyond ML, there are also critical security practices for data:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 除了ML外，还有关键的数据安全实践：
- en: In terms of data privacy, teams must anonymize personal identifiable information
    (PII) so that they are not at risk of accessing it.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据隐私方面，团队必须对个人可识别信息（PII）进行匿名化，以免存在访问风险。
- en: In terms of data security, teams must encrypt and establish access control on
    production data.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据安全方面，团队必须对生产数据进行加密和建立访问控制。
- en: Implementing security measures early can prevent costly and damaging security
    breaches down the line. Securing ML systems is also not a static destination.
    As malicious actors find [new ways to compromise ML](https://oreil.ly/Edc3M),
    teams need to stay updated with ongoing recommendations from the [cybersecurity](https://oreil.ly/eRHR1),
    [MLSecOps](https://oreil.ly/oofV4), and [DevSecOps](https://oreil.ly/w6Exh) communities.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 早期实施安全措施可以防止后续发生昂贵且具有破坏性的安全漏洞。保护ML系统也不是静态目标。随着恶意行为者找到[新的攻击方式](https://oreil.ly/Edc3M)，团队需要及时获取来自[网络安全](https://oreil.ly/eRHR1)、[MLSecOps](https://oreil.ly/oofV4)和[DevSecOps](https://oreil.ly/w6Exh)社区的持续建议。
- en: Work in small batches
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分批处理工作
- en: 'As we established in the previous section, working in smaller batches brings
    numerous benefits: reduced time-to-feedback, reduced cognitive load, easier problem
    triage and remediation, and improved efficiency and sense of progress.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中建立的，分批次工作带来了许多好处：缩短反馈时间、减少认知负荷、更轻松地解决问题和改善效率及进步感。
- en: Beyond just appropriate task sizing and scoping—which is important—the following
    practices help ML practitioners ship value in small batches.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅仅是适当的任务大小和范围——这很重要——以下实践帮助ML从业者分批次提供价值。
- en: Practice pair programming
  id: totrans-180
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习配对编程
- en: Pair programming involves two people writing code together to complete a user
    story or task. When we pair program, instead of working solo and having code reviews
    via pull requests, we shorten the feedback cycle from days (waiting and back-and-forth
    on pull request reviews) to minutes (feedback from your teammate as you are pairing).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 配对编程涉及两个人一起编写代码以完成用户故事或任务。当我们进行配对编程时，不再是单打独斗并通过拉取请求进行代码审查，我们将反馈周期从几天（等待和来回拉取请求审查）缩短到几分钟（与队友配对时的即时反馈）。
- en: Pair programming is also more than just writing code—it involves collaboration,
    planning, problem-solving, discussions, and knowledge sharing. The result is the
    cocreation of better solutions and socialization of preferred practices within
    the team.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 配对编程不仅仅是编写代码，它涉及协作、规划、解决问题、讨论和知识分享。其结果是在团队内共同创造更好的解决方案和首选实践的社会化。
- en: Pair programming is a common practice in the software engineering world and
    is also practiced—albeit to a lesser extent—in ML teams. It’s not uncommon to
    see data scientists go off on their own to work on something for a period of time.
    During that time, there are probably many assumptions that they make alone, questions
    that they didn’t ask, things that they weren’t aware of. In one anecdote, we worked
    with a data scientist who was working on a user story for three weeks, and finally
    the PR was rejected because the code was too messy, had no tests, and slowed down
    the training pipeline too much. What a frustrating waste of time that was for
    the data scientist!
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 配对编程在软件工程界是一种常见实践，在机器学习团队中也有所实践，尽管程度较低。看到数据科学家单独工作一段时间并不罕见。在此期间，他们可能会独自做出许多假设，没有提出的问题，他们不知道的事情。在一个轶事中，我们曾与一位数据科学家合作，他为一个用户故事工作了三周，最终PR被拒绝，因为代码太乱，没有测试，并且严重拖慢了训练管道。对数据科学家来说，这是多么令人沮丧的时间浪费！
- en: 'Pair programming has many well-documented benefits:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**配对编程**有许多充分记录的好处：'
- en: Knowledge sharing
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 知识分享
- en: As two individuals work together on a problem, they share and learn from each
    other’s approaches and techniques, which spreads local pockets of knowledge and
    best practices across the team. This is especially beneficial in ML teams where
    data scientists, ML engineers, and data engineers can learn from each other’s
    expertise, leading to more learning and higher-quality solutions.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个人共同解决问题时，他们分享并学习彼此的方法和技术，从而在团队中传播局部知识和最佳实践。这在机器学习团队尤其有益，数据科学家、ML工程师和数据工程师可以互相学习对方的专业知识，从而促进更多的学习和更高质量的解决方案。
- en: This also helps to increase the team’s [bus factor](https://oreil.ly/pB9mS)—the
    number of team members that, if they get “hit by a bus” (or win the lottery),
    will cause a project to slow to a stall due to lack of contextual knowledge. Pair
    programming increases the bus factor above one—thereby allowing team members to
    go on holidays without needing to stress about working on vacation or blocking
    the team’s work.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这也有助于增加团队的 [公交车因子](https://oreil.ly/pB9mS)——如果团队成员“被公交车撞倒”（或中彩票），会导致项目因缺乏上下文知识而减速至停滞。配对编程将公交车因子提高到超过一——从而使团队成员可以放心地度假，无需担心在度假期间工作或阻碍团队的工作。
- en: Fast feedback
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 快速反馈
- en: When we pair—and have intentional pairing—we get feedback on our code in minutes.
    This immediate feedback can help catch potential issues or bugs early, leading
    to higher-quality code and reduced debugging time. This is in contrast to getting
    feedback via pull requests—which, as an aside, is arguably a reliance on inspection
    rather than automated quality assurance. Pull requests tend to take days or even
    weeks before they’re ready for review, and another few hours or days of low-context
    back-and-forth between teammates before it can be merged.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行配对并有意识地配对时，我们可以在几分钟内获得对我们代码的反馈。这种即时反馈有助于早期捕捉潜在问题或 bug，从而提高代码质量并减少调试时间。这与通过拉取请求获得反馈形成对比——顺便说一句，这可以说是依赖检查而不是自动化质量保证。拉取请求通常需要几天甚至几周才能准备好进行审查，并且需要几个小时或几天的低上下文交流之后才能合并。
- en: 'Best of both worlds: high-level and detailed thinking'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 两全其美：高层和详细的思考
- en: When pairing, the navigator focuses more on high-level problem solving and design,
    while the driver focuses on low-level implementation details and execution. By
    combining two minds, teams can leverage the strengths of both individuals and
    reduce blind spots.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在配对时，导航者更专注于高层问题解决和设计，而驾驶者则专注于低级实现细节和执行。通过结合两个头脑，团队可以利用两个人的优势并减少盲点。
- en: Fast onboarding of new team members
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 新团队成员快速入职
- en: New team members can quickly learn the codebase, the team’s working practices,
    and tools by pairing with more experienced team members. This accelerates the
    onboarding process and helps new members to contribute effectively more quickly.
    This is much better than reading reams of documentation or watching recordings
    as a mode of onboarding.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 新团队成员可以通过与经验丰富的团队成员配对，快速学习代码库、团队的工作实践和工具。这加快了入职过程，帮助新成员更快有效地贡献。这比阅读大量文档或观看录像更好作为入职的方式。
- en: Staying focused
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 保持专注
- en: With pair programming, it’s harder for individuals to get distracted or go off
    track. The social nature of the activity keeps both programmers engaged, ensuring
    more focused and efficient work.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 使用配对编程，个人更难分心或走偏。这种活动的社交性质保持了程序员的参与，确保工作更加专注和高效。
- en: There are several techniques that help teams pair program effectively, such
    as driver-navigator, ping-pong, and “Dreyfus squared.” We encourage you to read
    about the benefits and mechanics of pair programming for you and your team in
    the brief article [“On Pair Programming”](https://oreil.ly/VIoSD).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种技术可以帮助团队有效进行配对编程，例如驾驶者导航、乒乓对打和“Dreyfus squared”。我们鼓励您阅读关于配对编程的好处和机制的简短文章，《“关于配对编程”》。
- en: Use version control for all production artifacts
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对所有生产工件使用版本控制
- en: Version control of code, data, and artifacts (e.g., configuration, intermediate
    data, trained models) helps teams with reproducibility, traceability, auditability,
    and debugging. In our experience, when we can access these intermediate and final
    artifacts, we can reproduce past results and perform various tasks, such as understanding
    the impact of changes in data on model performance. We can “summon” (or technically
    speaking, deserialize) models and data to re-create scenarios (bugs or otherwise)
    without needing to wait for long and potentially nondeterministic training runs.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 代码、数据和工件（例如配置、中间数据、训练模型）的版本控制帮助团队实现可重现性、可追溯性、可审计性和调试能力。根据我们的经验，当我们可以访问这些中间和最终工件时，我们可以重现过去的结果，并执行各种任务，例如了解数据变化对模型性能的影响。我们可以“召唤”（或者从技术上讲，反序列化）模型和数据来重新创建场景（出现的
    bug 或其他情况），而无需等待长时间和潜在的不确定的训练运行。
- en: Version control is indispensable for ensuring the reproducibility in ML systems.
    This is not just a matter of tracking changes in code but also involves versioning
    the datasets, model parameters, configuration settings, and even the random number
    generator seeds used during training. By seeding all random number generators
    (RNGs) used in the process, we can ensure that the stochastic elements of ML workflows—e.g.,
    data shuffling and initialization of model weights—are consistent across runs.
    This helps us better correlate changes in model quality to specific changes in
    the model’s inputs (e.g., code, data) and save time from debugging quality changes
    due to randomness.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 版本控制对于确保机器学习系统的可重现性至关重要。这不仅涉及跟踪代码变更，还包括对数据集、模型参数、配置设置甚至训练过程中使用的随机数生成器种子进行版本控制。通过对过程中使用的所有随机数生成器（RNGs）进行种子化，我们可以确保ML工作流中的随机元素（例如数据洗牌和模型权重初始化）在多次运行中保持一致。这有助于我们更好地将模型质量的变化与模型输入（例如代码、数据）的特定变化相关联，并节省由于随机性而导致的调试时间。
- en: In the context of version control of source code, it’s also important to [make
    small and frequent code commits](https://oreil.ly/T1ip7). We often see ML practitioners
    lumping multiple unrelated changes (even across 10–20 files) into a single commit.
    If that commit breaks the build on CI (i.e., tests fail), which logical set of
    changes caused the error? It’s hard to tell when change sets are large. So, in
    addition to using version control, we should also use it *well* by making changes
    in logically segregated and ideally small changes.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在源代码版本控制的背景下，还重要的是[进行小而频繁的代码提交](https://oreil.ly/T1ip7)。我们经常看到ML实践者将多个不相关的变更（甚至跨越10至20个文件）合并到一个提交中。如果该提交在CI上导致构建失败（即测试失败），那么哪一组逻辑上的变更导致了错误？当变更集较大时，很难说清楚。因此，除了使用版本控制外，我们还应该*善用*它，通过在逻辑上分离且理想情况下是小变更的方式进行更改。
- en: Implement continuous integration (CI)
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实施持续集成（CI）
- en: Continuous integration (CI) actually has a strict definition that is often watered
    down to the point of losing its actual meaning (see the note earlier in this chapter
    on the definitions of CI/CD). This is especially true among ML practitioners.
    CI refers to the practice of committing all code changes onto the main branch
    (aka [trunk-based development](https://oreil.ly/949Mn)—more on this in the next
    point), ideally several times a day.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 持续集成（CI）实际上有一个严格的定义，通常被淡化到失去其实际意义的程度（见本章前面关于CI/CD定义的注释）。这在机器学习实践者中尤为常见。CI指的是将所有代码更改提交到主分支（又称[基于主干的开发](https://oreil.ly/949Mn)——关于这一点，后文会详细介绍），理想情况下，每天多次提交。
- en: Each code push is then automatically tested and verified on the CI pipeline.
    This approach helps to spot and address quality and integration issues as early
    as possible, enhancing the overall software quality and reducing the time it takes
    to validate and deploy new features.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 每次代码推送都会自动在CI流水线上进行测试和验证。这种方法有助于尽早发现和解决质量和集成问题，从而提升整体软件质量并缩短验证和部署新功能所需的时间。
- en: Often, ML practitioners hesitate to practice CI because they don’t want long
    training runs (sometimes taking several hours or even days to complete) to block
    their ability to make a code commit. Hence, they carve out their own “workspace”
    in the form of a feature branch, and whenever they’re satisfied with the quality
    of their changes, they create a pull request to merge the changes to the main
    branch.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，机器学习实践者不愿意实践CI，因为他们不希望长时间的训练过程（有时需要几个小时甚至几天才能完成）阻碍他们进行代码提交的能力。因此，他们会通过创建特性分支的方式划分出自己的“工作空间”，并在满意其变更质量后，创建一个拉取请求将变更合并到主分支。
- en: This concern is valid, but teams should consider two factors that can help them
    avoid the costs and pitfalls of feature branching. First, don’t let ML be a “get
    out of jail free” card. If a component’s path to production doesn’t require time-consuming
    training runs (e.g., solutions with small models, LLM applications that don’t
    require fine-tuning, or supporting packages and libraries), then teams should
    practice CI, test automation, and trunk-based development to reap the benefits
    of flow, velocity, and quality.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这种担忧是合理的，但团队应考虑两个因素，这些因素可以帮助他们避免特性分支带来的成本和问题。首先，不要让ML成为“免罪金牌”。如果一个组件的生产路径不需要耗时的训练过程（例如小模型解决方案、不需要微调的LLM应用程序或支持包和库），则团队应该实践CI、测试自动化和基于主干的开发，以获取流畅性、速度和质量的好处。
- en: Second, in cases where the path to production of a code change *does* require
    time-consuming training runs, feature branching and pull requests (i.e., not doing
    trunk-based development and CI) may be an acceptable trade-off. But ML practitioners
    must still execute fast-running tests (e.g., training smoke tests as described
    in [Chapter 6](ch06.html#automated_testing_ml_model_tests)) locally and on the
    CI pipeline, before long and costly training runs. This affords ML practitioners
    fast feedback on the quality of their changes as they make [small and frequent
    commits](https://oreil.ly/T1ip7) on feature branches.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，在代码变更的路径*确实*需要耗时的训练运行的情况下，特性分支和拉取请求（即非主干开发和持续集成）可能是可以接受的权衡。但是机器学习从业者仍须在本地和
    CI 流水线上执行快速运行测试（例如在[第6章](ch06.html#automated_testing_ml_model_tests)中描述的训练冒烟测试），在进行漫长和昂贵的训练运行之前。这为机器学习从业者提供了有关其变更质量的快速反馈，这些变更是在特性分支上进行[小而频繁的提交](https://oreil.ly/T1ip7)。
- en: 'This was true for us [in one particular project](https://oreil.ly/oHIJT). We
    had CI pipelines with high test coverage, but we worked on feature branches (i.e.,
    we didn’t do trunk-based development and CI). However, we ensured that branches
    were short-lived (two to three weeks max). We pair-programmed, wrote tests, advocated
    for [nonblocking code reviews](https://oreil.ly/pcz3m), and ensured all branches
    underwent the same comprehensive tests on our CI pipelines. Now, when a code change
    is committed and pushed, the CI pipeline:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这在我们[特定项目中](https://oreil.ly/oHIJT)是真实的。我们的 CI 流水线具有很高的测试覆盖率，但我们使用特性分支工作（即我们没有使用主干开发和持续集成）。但是，我们确保分支生命周期短暂（最多两到三周）。我们进行配对编程，撰写测试，倡导[非阻塞代码审查](https://oreil.ly/pcz3m)，并确保所有分支在我们的
    CI 流水线上经历相同的全面测试。现在，当提交并推送代码变更时，CI 流水线：
- en: Runs a series of automated tests
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行一系列自动化测试
- en: Triggers large-scale training
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 触发大规模训练
- en: Runs model quality tests
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行模型质量测试
- en: Builds and publishes our model image to a container registry
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建并将我们的模型镜像发布到容器注册表
- en: Automatically deploys the image to the preproduction environment
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动将镜像部署到预生产环境
- en: Runs post-deployment tests in the preproduction environment
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在预生产环境中运行部署后测试
- en: When the entire CI pipeline is green, it means the trained model has passed
    all the [fitness functions](https://oreil.ly/hv_5B) we defined, and we can confidently
    merge the branch and deploy changes to production.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 当整个 CI 流水线全部通过时，表示训练模型已经通过了我们定义的所有[适应性函数](https://oreil.ly/hv_5B)，我们可以放心地合并分支并部署变更到生产环境。
- en: Apply trunk-based development
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 应用主干开发
- en: As detailed in [Table 9-2](#benefits_of_trunk_based_development_ver), trunk-based
    development is the practice of committing code changes to the main branch. This
    contrasts with feature branching, where developers create a separate branch and
    pull requests for each feature or bug fix. Trunk-based development benefits ML
    practitioners in myriad ways and helps address common challenges that ML teams
    grapple with long feedback cycles, broken builds, code quality issues, tech debt,
    blocked work, and inter-team and intra-team silos, among others.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[表 9-2](#benefits_of_trunk_based_development_ver)中详细描述的，主干开发是将代码变更提交到主分支的做法。这与特性分支开发相对，开发人员在每个特性或错误修复上创建单独的分支和拉取请求。主干开发以多种方式使机器学习从业者受益，并有助于解决长反馈周期、构建中断、代码质量问题、技术债务、阻塞工作以及团队内外沟通隔阂等常见挑战。
- en: 'Table 9-2\. Benefits of trunk-based development versus feature branching (source:
    adapted from [Mattia Battiston’s work on trunk-based development](https://oreil.ly/OeGHI))'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9-2\. 主干开发与特性分支开发的优劣势（来源：改编自[Mattia Battiston关于主干开发的工作](https://oreil.ly/OeGHI)）
- en: '| **Feature branching** *Work in isolated branches; raise pull request (PR);
    merge to main branch when PR is approved* | **Trunk-based development** *Push
    straight to main branch; pair program; run comprehensive tests on CI; enjoy reliable
    builds; branch by abstraction/feature flags* |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| **特性分支开发** *在孤立分支中工作；提出拉取请求（PR）；在PR获批后合并到主分支* | **主干开发** *直接推送到主分支；配对编程；在CI上运行全面测试；享受可靠的构建；通过抽象/特性标志进行分支*
    |'
- en: '| --- | --- |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| *Feedback comes late:* Too late to change anything substantial | *Fast feedback:*
    As you’re writing code or even before |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| *反馈较晚到来：* 太晚以至于无法更改任何重要事项 | *快速反馈：* 当您编写代码甚至在之前 |'
- en: '| *Low-quality feedback:* Through comments, lacking context and nuance; feedback
    sometimes withheld or not actioned due to friction of PR review process | *Better-quality
    feedback:* Through in-context discussion and demonstrating suggestions in action
    |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| *低质量反馈:* 通过缺乏上下文和细微差别的评论；有时由于 PR 审核流程的摩擦而被忽略或未被采纳 | *更好的质量反馈:* 通过上下文讨论和演示建议的实际效果
    |'
- en: '| *Large refactorings are dreaded and deferred:* Because they are likely to
    cause merge conflicts and slow down PR review process | *Large refactorings are
    easier to tackle:* The rest of the team is always up-to-date and immediately benefits
    from any refactoring |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| *害怕和推迟大规模重构:* 因为它们可能会引起合并冲突并减慢 PR 审核流程 | *更容易处理大规模重构:* 其余团队始终保持更新，并立即从任何重构中受益
    |'
- en: '| *Easy to ignore a failing build:* Because it runs on an isolated branch |
    *We get used to not breaking things:* Team makes a habit of keeping main branch
    green |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| *容易忽视构建失败:* 因为它运行在隔离分支上 | *我们习惯于不破坏事物:* 团队养成了保持主分支稳定的习惯 |'
- en: '| *Individual coding styles:* Tendency for fragmentation of styles, designs,
    and approaches even within a single codebase | *Team coding style:* Preferred
    styles, designs, and approaches are socialized and spread through pairing |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| *个体编码风格:* 即使在单个代码库内部也有风格、设计和方法的碎片化倾向 | *团队编码风格:* 通过配对社会化和传播的首选风格、设计和方法 |'
- en: '| *People work in isolation:* Harder to spot if someone needs help | *Visibility
    of what everyone is doing:* Easier to spot if someone needs support |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| *人们独自工作:* 更难发现是否有人需要帮助 | *能看到每个人在做什么:* 更容易发现是否有人需要支持 |'
- en: 'Trunk-based development is the icing on the cake of the CD practices we’ve
    detailed so far. It’s a practice that can and should only be done when you have
    implemented the safety prerequisites of test automation, pair programming, and
    CI/CD pipelines. The reverse is also true: without these safety prerequisites,
    trunk-based development is risky and often leads to broken builds and defects.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: Trunk-based development 是我们前面详细描述的持续交付实践的锦上添花。它是一种只有在实施了测试自动化、配对编程和 CI/CD 管道的安全前提条件下才能且应该采用的实践。反之亦然：如果缺乏这些安全前提条件，Trunk-based
    development 就存在风险，通常会导致构建失败和缺陷。
- en: 'Automation: Computers perform repetitive tasks, people solve problems'
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动化：计算机执行重复任务，人们解决问题
- en: Algorithmia’s [“2021 Enterprise Trends in Machine Learning” report](https://oreil.ly/9FAXH)
    found that 38% of organizations surveyed are spending *more than 50%* of their
    data scientists’ time on model deployment. And deployment is not the only undifferentiated
    tedium that ML practitioners are often tasked with—there’s also the grunt work
    of configuring development environments, troubleshooting and debugging in production,
    among others.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Algorithmia 的 [“2021年企业机器学习趋势”报告](https://oreil.ly/9FAXH) 发现，38% 的受访组织将其数据科学家超过50%
    的时间用于模型部署。而部署并不是机器学习实践者经常需要处理的唯一无差别乏味工作，还包括配置开发环境、生产中的故障排除和调试等任务。
- en: The following practices help ML practitioners reduce such manual toil so that
    they can focus on solving important problems and delivering value.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的实践帮助机器学习实践者减少这种手动劳动，使他们可以专注于解决重要问题并提供价值。
- en: Automate development environment setup
  id: totrans-230
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自动化开发环境设置
- en: We discussed in Chapters [3](ch03.html#effective_dependency_management_princip)
    and [4](ch04.html#effective_dependency_management_in_prac) the challenges that
    ML practitioners often face in creating reproducible and consistent development
    environments, and practical techniques to overcome these challenges. We mention
    this here again for completeness—automation is useful not just for testing and
    deploying models, but also for creating development environments.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第 [3](ch03.html#effective_dependency_management_princip) 和第 [4](ch04.html#effective_dependency_management_in_prac)
    章讨论了机器学习实践者在创建可重现和一致的开发环境时经常面临的挑战，以及克服这些挑战的实际技术。为了完整起见，我们在这里再次提到自动化不仅对于测试和部署模型有用，而且对于创建开发环境也很有帮助。
- en: To achieve this, teams can leverage container technologies and infrastructure-as-code
    (IaC) tools, enabling the creation of consistent, production-like compute environments
    locally or in the cloud for both development and production environments (i.e.,
    [experimental-operational symmetry](https://oreil.ly/Z31qn)).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一目标，团队可以利用容器技术和基础设施即代码（IaC）工具，在本地或云中创建一致的类生产计算环境，用于开发和生产环境（即 [实验-运营对称性](https://oreil.ly/Z31qn)）。
- en: This frees up ML practitioners to focus on higher-order problem solving and
    innovation, leaving the repetitive tasks of environment setup and configuration
    to the computers.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得ML从业者可以专注于高阶问题解决和创新，将环境设置和配置的重复任务交给计算机。
- en: Automate deployments (minimally to a preproduction environment)
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自动化部署（至少到预生产环境）
- en: As mentioned earlier, deployment automation is typically well-covered in MLOps
    literature and tooling. Specific techniques, such as canary deployments and A/B
    testing, are also explained comprehensively in Chip Huyen’s [*Designing Machine
    Learning Systems*](https://oreil.ly/qRv4E) (O’Reilly), so we won’t reiterate those
    points here but we will highlight the delta that CD4ML adds to the practice.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前文提到的，部署自动化通常在MLOps文献和工具中有很好的覆盖。特定技术，例如金丝雀部署和A/B测试，在Chip Huyen的《*设计机器学习系统*》（O’Reilly）中也有全面的解释，因此我们在此不会重复提及这些点，但我们会强调CD4ML为实践增加的差异。
- en: 'CD4ML takes the *ability* to automate model deployments further by recommending
    teams: (i) *trigger* automated deployments—minimally to preproduction environment(s)—on
    every code push, and (ii) run post-deployment tests to verify that the deployment
    succeeded and is ready for production at any time.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: CD4ML通过推荐团队将自动化模型部署的能力推向更高级别：（i）在每次代码推送时*触发*自动化部署——至少到预生产环境——和（ii）运行部署后的测试以验证部署成功并随时准备投入生产。
- en: Warning
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: In traditional software development, separate environments such as development,
    testing, user acceptance testing, and production are commonly used to ensure that
    changes are thoroughly vetted before they are deployed to end users. However,
    in ML systems, this approach usually doesn’t make sense because model training
    requires access to the most relevant, comprehensive, and up-to-date data, which
    often resides only in the production environment.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统软件开发中，通常使用不同的环境，如开发、测试、用户验收测试和生产，以确保在部署到最终用户之前充分审核更改。然而，在ML系统中，这种方法通常不合理，因为模型训练需要访问最相关、全面和最新的数据，这些数据通常只存在于生产环境中。
- en: As such, run full model training in only one environment where you have access
    to the best data—in most cases, it’s production. You can still run training smoke
    tests on a small sample of data (as described in [Chapter 6](ch06.html#automated_testing_ml_model_tests))
    in the other lower environments before running full training in production.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在只有一个环境可以访问最佳数据的情况下，只在该环境中运行完整的模型训练——在大多数情况下，即生产环境。在其他低级别环境中，你仍然可以对少量数据运行训练冒烟测试（如[第6章](ch06.html#automated_testing_ml_model_tests)中所述）之后再在生产环境中进行完整训练。
- en: Monitoring in production
  id: totrans-240
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 生产监控
- en: Production monitoring is an established practice in software engineering. If
    done well, monitoring (metrics, logs, and alerts) gives us useful feedback on
    how our product is behaving in the wild, and alerts us when there are any unexpected
    errors, model drift, performance degradation, or unusual activity.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 生产监控是软件工程中已经建立的实践。如果做得好，监控（指标、日志和警报）将为我们提供关于产品在野外行为的有用反馈，并在出现任何意外错误、模型漂移、性能下降或异常活动时通知我们。
- en: 'Monitoring gives us insight into scenarios that we haven’t considered before
    in our tests. As Edsger W. Dijkstra once said: “Testing may convincingly demonstrate
    the presence of bugs but can never demonstrate their absence.” That’s why monitoring
    in production is an essential complementary practice to testing.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 监控使我们能够洞察在测试中未考虑过的场景。正如Edsger W. Dijkstra曾经说过的：“测试可以有力地证明存在错误，但永远不能证明不存在错误。”这就是为什么在生产中进行监控是测试的一个必要的补充实践。
- en: 'We’ve written about the three levels of monitoring in the first section of
    this chapter, so we won’t reiterate the details, except to call out the components
    of monitoring that are useful in ML systems:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在本章的第一节中讨论了监控的三个层次，因此我们不会重复详细说明，除了指出在ML系统中有用的监控组件：
- en: Service monitoring (e.g., HTTP status codes, errors, latency)
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务监控（例如HTTP状态码、错误、延迟）
- en: Model monitoring (e.g., key performance metrics, model drift over time) (Refer
    to the section [“Learn from Production by Closing the Data Collection Loop”](ch06.html#learn_from_production_by_closing_the_da)
    for a definition of types of model drift.)
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型监控（例如关键性能指标、随时间的模型漂移）（参考章节[“通过关闭数据收集循环从生产中学习”](ch06.html#learn_from_production_by_closing_the_da)了解模型漂移类型的定义。）
- en: Data monitoring (e.g., data quality monitoring, anomaly detection, adherence
    to expected schemas)
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据监控（例如数据质量监控、异常检测、符合预期模式的监控）
- en: Business-level outcomes (e.g., user engagement, sales, conversions, number of
    subscribers)
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 业务级成果（例如用户参与度、销售、转化率、订阅人数）
- en: Structured logs that are informative and readable and don’t contain confidential
    or sensitive data (e.g., PII); they should have correlation IDs if production
    requests go through multiple services to facilitate debugging in distributed systems
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化日志应该是信息丰富且易于阅读的，不包含机密或敏感数据（例如PII）；如果生产请求经过多个服务，则应具有相关ID以便在分布式系统中进行调试。
- en: Alerts for undesirable scenarios in production (e.g., API errors, requests that
    go beyond latency budget; alerts should be informative and actionable, and be
    careful to avoid [alert fatigue](https://oreil.ly/CAh0D) and [broken windows](https://oreil.ly/hpXp2)!)
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产中不良场景的警报（例如API错误、超出延迟预算的请求）应该是信息丰富且可操作的，要小心避免[警报疲劳](https://oreil.ly/CAh0D)和[破窗效应](https://oreil.ly/hpXp2)！
- en: 'Kaizen: Relentlessly pursue continuous improvement'
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 改善：不懈追求持续改进。
- en: No system will ever be perfect, and there will always be issues and opportunities
    for improvement. Effective teams are those that can acknowledge their imperfect
    knowledge and set aside sufficient time and energy to identify and act on improvements.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何系统会是完美的，总会存在问题和改进的机会。有效的团队是那些能够承认自己不完美的知识，并抽出足够的时间和精力来识别并采取改进措施的团队。
- en: Continuous improvement (or Kaizen) is especially relevant to ML teams because
    of the sheer heterogeneity and novelty of teams, tools, platforms, processes,
    and problems in ML. As a community of practitioners, we’re constantly finding
    out new ways to solve problems, and the goal is not to get it right the first
    time (an impossible task!), but to make it easy and safe to iteratively change
    and improve how things are done.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 持续改进（或改善）对ML团队特别重要，因为ML团队在团队、工具、平台、流程和问题的异质性和新颖性方面都是如此。作为从业者社区，我们不断发现解决问题的新方法，目标不是第一次就做对（这是不可能的！），而是使迭代改变和改进工作方式变得简单和安全。
- en: It’s important to call out that we can practice point Kaizen and system Kaizen.
    Point Kaizen can happen quickly during the course of work. For example, team members
    can simply call out issues that repeatedly add friction (e.g., too many meetings,
    or manual deployment procedures), and identify follow-up actions to resolve these
    issues.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 强调重要的是，我们可以实行点改善和系统改善。点改善可以在工作过程中迅速进行。例如，团队成员可以简单地指出反复引起摩擦的问题（例如，过多的会议或手动部署程序），并确定后续行动来解决这些问题。
- en: For addressing system-level problems (e.g., team shapes that lead to too many
    handoffs and blockages, lack of platform capabilities), system Kaizen techniques
    such as [value stream mapping](https://oreil.ly/k_kn7) and [5 whys](https://oreil.ly/lh5ES)
    can help teams identify the problems and find ways to improve.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 针对系统级问题（例如导致过多交接和阻塞的团队形态，缺乏平台能力），诸如[价值流映射](https://oreil.ly/k_kn7)和[5个为什么](https://oreil.ly/lh5ES)等系统改善技术可以帮助团队识别问题并找到改进方法。
- en: 'Everyone is responsible: Rationalizing and cultivating ownership by adopting
    the appropriate team topologies'
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每个人都有责任：通过采用适当的团队拓扑来理性化和培养所有权。
- en: While the CD principle, “everyone is responsible,” is a useful belief that guides
    the decisions of individuals, we often find that things that are everyone’s responsibility
    often end up being no one’s responsibility.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管“每个人都有责任”的CD原则是一个有用的信念，指导个人的决策，但我们经常发现，每个人都有责任的事情最终往往成为没有人责任的事情。
- en: To realize this cultural aspiration, teams need to be supported by the right
    structure and systems of work that incentivize individuals and teams to fulfill
    their respective responsibilities, be it in ML, operations, customer experience,
    or security. Let’s look at how the principles and practices of [Team Topologies](https://oreil.ly/DWhOY)
    can help us in this regard.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这一文化愿望，团队需要在ML、运营、客户体验或安全等领域的适当结构和工作系统的支持下，激励个人和团队履行各自的责任。让我们看看如何通过[团队拓扑](https://oreil.ly/DWhOY)的原则和实践来帮助我们做到这一点。
- en: As many of you know, before the DevOps movement, developers would write code
    and throw it over the wall for operations engineers to package and deploy. We
    still see this happening in some ML teams, albeit not always to such drastic extents,
    where teams are sliced by function (i.e., a data science team, an ML engineering
    team, an API team). Such a structure nudges individuals to think of responsibilities
    (e.g., production monitoring or testing ML models) as belonging to other teams,
    even though this mindset can make or break the ML product they’re contributing
    to.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 正如许多人所知，在DevOps运动之前，开发人员会编写代码并将其投入操作工程师打包和部署。即使在一些机器学习团队中，我们仍然看到这种情况发生，尽管不总是如此极端，团队按功能划分（例如数据科学团队、机器学习工程团队、API团队）。这种结构促使个人思考责任（例如生产监控或测试机器学习模型）属于其他团队，即使这种心态可能决定了他们对所贡献的机器学习产品的重要性。
- en: In addition, this structure increases handoffs and backlog coupling between
    teams, which then increases wait time and friction. For example, in [an informal
    study](https://oreil.ly/MhC3P) of hundreds of tasks passing through a delivery
    center, tasks that had to wait for another team took *10–12 times longer* than
    tasks that could be completed by a single empowered team without dependency.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 此结构增加了团队之间的交接和积压耦合，进而增加了等待时间和摩擦。例如，在[一项非正式研究](https://oreil.ly/MhC3P)中，通过交付中心传递的数百项任务中，需要等待其他团队的任务比能由单个赋权团队完成的任务花费*10–12倍的时间*。
- en: We also see Conway’s Law—organizations produce designs that are copies of their
    communication structures—take effect, and each team undertakes some level of rework
    as opposed to coordinating to create a shared capability. In one instance, we
    worked with an organization that had two data science teams. Both teams independently
    solved the same problems repeatedly, such as tooling for large-scale model training,
    experiment tracking, and model explainability.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到康威法则——组织产生与其沟通结构副本相同的设计——生效，每个团队都在某种程度上进行重新工作，而不是协调创建共享能力。例如，我们曾与一个有两个数据科学团队的组织合作。这两个团队独立解决了相同的问题，如大规模模型训练的工具化、实验跟踪和模型可解释性。
- en: 'To address these challenges and to promote collaboration and collective ownership,
    consider the appropriate team structures and team topologies for your organization’s
    level of maturity and scale. We’ll discuss this in greater detail in [Chapter 11](ch11.html#effective_ml_organizations),
    but here’s a brief overview of the four types of teams in the Team Topologies
    model and how organizations can leverage them to scale the practice and delivery
    of ML in an organization:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些挑战并促进协作和集体所有权，考虑适当的团队结构和团队拓扑，以适应组织的成熟度和规模。我们将在[第11章](ch11.html#effective_ml_organizations)中详细讨论这一点，但这里简要概述了Team
    Topologies模型中的四种团队类型及组织如何利用它们来扩展ML实践和交付：
- en: Stream-aligned teams
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 流对齐的团队
- en: Cross-functional teams are organized around a product or set of products. The
    team should be empowered with the required capabilities and context to develop,
    test, and deploy ML model enhancements to production, without the need to wait
    on (and be blocked by) another team. Typically, this is a “two-pizza team” with
    competencies such as data science, ML engineering, software engineering, quality
    assurance, and product.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉功能团队围绕一个产品或一组产品组织起来。团队应具备所需的能力和背景来开发、测试和部署ML模型的增强版到生产环境，而无需等待（和被其他团队阻碍）。通常，这是一个“两披萨团队”，拥有数据科学、ML工程、软件工程、质量保证和产品等能力。
- en: Platform teams
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 平台团队
- en: These teams (e.g., data platform team, ML platform team) build and maintain
    platform capabilities that stream-aligned teams can use on a self-service basis.
    They also support stream-aligned teams where necessary to guide or troubleshoot
    existing platform capabilities or develop new platform capabilities.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这些团队（例如数据平台团队、机器学习平台团队）构建和维护平台能力，流对齐的团队可以自助使用这些能力。他们还在必要时支持流对齐的团队，以指导或解决现有平台能力或开发新平台能力。
- en: Enabling teams
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 使能团队
- en: These teams offer expertise (e.g., security consulting, ML governance, architecture)
    that equips and supports stream-aligned teams on an as-needed basis. Their role
    is to accelerate the stream-aligned teams by providing the necessary support,
    rather than owning a product or service themselves.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这些团队提供专业知识（例如安全咨询、机器学习治理、架构），根据需要为流对齐的团队提供支持。他们的角色是通过提供必要的支持来加速流对齐的团队，而不是拥有自己的产品或服务。
- en: Complicated subsystem teams
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂子系统团队
- en: These teams handle parts of the system that require specialized technical expertise
    (e.g., legacy platforms, search, personalization).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这些团队处理需要专业技术专长的系统部分（例如传统平台、搜索、个性化）。
- en: In the ML context, where there are multiple ML product use cases, we often see
    ML practitioners embedded in *stream-aligned teams* or *complicated subsystem
    teams* (e.g., a data science team building and supporting personalization in an
    organization). These teams are also enabled by a self-service ML platform and
    data platform capabilities, and supported by ML/data *platform teams* where necessary.
    They are also supported by *enabling teams* such as governance and architecture
    teams that can consult and support the stream-aligned teams where necessary.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（ML）领域中，存在多个ML产品使用案例的情况下，我们经常看到ML从业者嵌入在*与流对齐的团队*或*复杂的子系统团队*中（例如，一个数据科学团队在组织中构建和支持个性化）。这些团队还依赖于自助式ML平台和数据平台的能力，并在必要时得到ML/数据*平台团队*的支持。同时，这些团队还得到*支持团队*（如治理和架构团队）的支持，他们可以在必要时提供建议和支持流对齐团队。
- en: 'Establishing the right team structures help organizations improve the flow
    of information and, more importantly, keep cognitive load at a manageable level.
    Matthew Skelton, coauthor of *Team Topologies* (IT Revolution Press) puts it well:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 建立正确的团队结构有助于组织改善信息流动，更重要的是，保持认知负荷在可管理的水平上。《Team Topologies》（IT革命出版社）的共同作者Matthew
    Skelton表达得很好：
- en: If we stress the team by giving it responsibility for part of the system that
    is beyond its cognitive load capacity, it ceases to act like a high-performing
    unit and starts to behave like a loosely associated group of individuals, each
    trying to accomplish their individual tasks without the space to consider if those
    are in the team’s best interest. [...] When cognitive load isn’t considered, teams
    are spread thin trying to cover an excessive amount of responsibilities and domains.
    Such a team lacks bandwidth to pursue mastery of their trade and struggles with
    the costs of switching contexts.
  id: totrans-272
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果我们通过赋予团队超出其认知负荷能力的系统部分的责任来压力团队，它将不再像一个高效的单位，而开始像一群松散关联的个体，每个人都试图完成他们的个人任务，而没有空间去考虑这些任务是否符合团队的最佳利益。......当不考虑认知负荷时，团队会因试图涵盖过多的责任和领域而过度分散。这样的团队缺乏追求专业技能的带宽，并且在切换上下文的成本方面遇到困难。
- en: With the principles and practices of CD4ML under our belt, let’s turn to the
    final section of this chapter and look at how CD4ML supports teams in practicing
    ML governance and responsible AI.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 带着CD4ML的原则和实践，让我们转向本章的最后一部分，看看CD4ML如何支持团队实践ML治理和负责任AI。
- en: How CD4ML Supports ML Governance and Responsible AI
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CD4ML如何支持ML治理和负责任AI
- en: With increasing ML capabilities, and reliance on those capabilities, comes increasing
    potential for harm, such as the amplification of biases and unforeseen use cases
    with detrimental societal impacts. For some examples of such harm, refer to the
    [AIAAIC (AI, Algorithmic, and Automation Incidents and Controversies) repository](https://oreil.ly/h1-FN),
    which contains over 1,000 incidents and controversies including examples such
    as deepfakes, false claims, embedded racism, and privacy breaches.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ML能力的增强和对这些能力的依赖，带来的潜在危害也在增加，例如偏见的放大和具有有害社会影响的未预见用例。有关此类危害的一些例子，请参考[AIAAIC（AI、算法和自动化事件与争议）存储库](https://oreil.ly/h1-FN)，该存储库包含超过1,000个事件和争议，包括深度伪造，虚假声明，嵌入式种族主义和隐私侵犯。
- en: If ML teams don’t proactively identify potential failure modes and sources of
    harm, and implement risk controls accordingly, they are essentially building a
    house of cards that is not only vulnerable to functional failures, but that also
    risks causing harm to users and public reputational damage to the business. That’s
    why ML governance, which intersects with Responsible AI, is critical for any team
    building ML systems.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 如果ML团队不主动识别潜在的故障模式和危害来源，并相应地实施风险控制措施，他们实际上正在建造一座危机四伏的纸牌屋，这不仅容易发生功能故障，还可能对用户造成伤害，对企业的公共声誉造成风险。这就是为什么ML治理对于任何建立ML系统的团队都至关重要，因为它与负责任AI交汇。
- en: In [Chapter 1](ch01.html#challenges_and_better_paths_in_deliveri), we referred
    to MIT Sloan’s definition of Responsible AI:^([3](ch09.html#ch01fn39))
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](ch01.html#challenges_and_better_paths_in_deliveri)中，我们提到了MIT Sloan对负责任AI的定义:^([3](ch09.html#ch01fn39))
- en: A framework with principles, policies, tools, and processes to ensure that AI
    systems are developed and operated in the service of good for individuals and
    society while still achieving transformative business impact.
  id: totrans-278
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个原则、政策、工具和流程的框架，确保AI系统在为个人和社会造福的同时实现转变性业务影响。
- en: A Responsible AI framework should provide teams with practical tools to guide
    their decisions in the design, development, and deployment of ML systems. Responsible
    AI is an important component of ML governance. Effective ML governance ensures
    that we deliver value from ML systems, while adhering to ethical and regulatory
    standards, quality controls, risk management protocols, and engineering best practices.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 一个负责任的AI框架应为团队提供实用工具，指导他们在设计、开发和部署ML系统时的决策。负责任的AI是ML治理的重要组成部分。有效的ML治理确保我们在遵守道德和法规标准、质量控制、风险管理协议和工程最佳实践的同时从ML系统中提供价值。
- en: 'There is little existing literature on these topics but what there is includes
    some good references. For ML governance, see the reports [“AI Governance: A Lean
    Approach”](https://oreil.ly/l67w_) and [“The Framework for ML Governance”](https://oreil.ly/5RYHG).
    For Responsible AI, see Google’s [“Responsible AI Practices”](https://oreil.ly/d6lT0)
    and [*Responsible AI: Best Practices for Creating Trustworthy Systems*](https://oreil.ly/UDQJf)
    (Addison-Wesley Professional). We won’t go into these two topics in detail, but
    we’d like to describe four ways in which CD4ML can help teams operationalize ML
    governance principles into their daily workflows and decisions:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些主题的现有文献很少，但其中包括一些很好的参考资料。对于ML治理，请参阅报告[“AI治理：精简方法”](https://oreil.ly/l67w_)和[“ML治理框架”](https://oreil.ly/5RYHG)。对于负责任的AI，请查看谷歌的[“负责任AI实践”](https://oreil.ly/d6lT0)和[*负责任AI：创建值得信赖系统的最佳实践*](https://oreil.ly/UDQJf)（Addison-Wesley
    Professional）。我们不会详细讨论这两个主题，但我们想描述CD4ML如何帮助团队将ML治理原则操作化到他们的日常工作流程和决策中的四种方式：
- en: Enabling iterative improvements
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 促进迭代改进
- en: CD4ML—the ability to make small changes to ML systems with a specific intent,
    evaluate and monitor if those changes had the desired result, and roll them back
    if not—is a powerful enabler for Responsible AI in multiple ways.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: CD4ML——能够对ML系统进行小改动，并评估和监测这些改动是否产生了预期的结果，并在不符合预期时进行回滚——是多方面推动负责任AI的强大工具。
- en: First, it enables an iterative, human-centered approach to solution development,
    where we can research and test solutions with people in a series of small steps,
    allowing the early discovery and resolution of issues to reduce the likelihood
    of releasing anything harmful to users in production.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，它实现了一种迭代的、以人为中心的解决方案开发方法，我们可以在一系列小步骤中与人们研究和测试解决方案，从而早期发现和解决问题，减少在生产中释放任何对用户有害的可能性。
- en: Second, if a harm—or indeed any other issue—is later detected, we can respond
    nimbly and deploy resolutions with confidence and within a short period of time,
    minimizing the impact of the harm.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，如果稍后检测到伤害或任何其他问题，我们可以迅速做出响应并自信地在短时间内部署解决方案，最大限度地减少伤害的影响。
- en: Maximizing model lifetime value
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 最大化模型的生命周期价值
- en: Ad hoc development and deployment of models is typically the first stage of
    ML adoption in organizations, and indeed it may be difficult to justify investment
    in sophisticated MLOps or CD4ML at this stage, before the value is empirically
    established. Once the value of ML—or its potential to cause harm—is clear, then
    the lack of MLOps and CD4ML actually slows teams down in their efforts to improve
    model quality from their initial baseline performance.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 组织中ML采用的典型第一阶段是模型的临时开发和部署，确实在确定ML的价值或其潜在造成伤害的能力之前，很难在此阶段前投资复杂的MLOps或CD4ML。一旦清楚ML的价值或其潜在造成伤害的能力，那么缺乏MLOps和CD4ML实际上会减慢团队改善模型质量的努力，从其初始基准性能出发。
- en: MLOps and CD4ML—and the ethos and practices of automation and building quality
    in—help teams evaluate, monitor, and improve model quality in a timely manner,
    minimizing any [cost of delay](https://oreil.ly/z3ypM). This allows teams to quickly
    reclaim value left on the table, understand and responsively manage their risk
    exposure, and hence maximize a model’s value over its lifetime.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps和CD4ML以及自动化和建立质量的精神和实践，帮助团队及时评估、监控和改善模型质量，从而最小化任何[延迟成本](https://oreil.ly/z3ypM)。这使得团队可以快速挽回被忽视的价值，理解并响应性地管理他们的风险敞口，从而最大化模型在其生命周期内的价值。
- en: Defining and enforcing policy-as-code
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 定义和执行政策即代码
- en: MLOps and CD4ML enable the automated application of Responsible AI policies
    at various points in the software development lifecycle. For instance, we may
    validate that training data has been obtained with consent for a particular purpose,
    and produce documentation and a journal of experiments. Bias tests or data privacy
    tests may be defined as a fitness function that is part of a model validation
    and assurance suite, and model drift may be monitored in production. The same
    approaches can help maximize lifetime value of models.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps和CD4ML在软件开发生命周期的各个阶段实现了负责任AI政策的自动应用。例如，我们可以验证特定目的的训练数据是否已获得同意，并生成实验文档和日志。偏见测试或数据隐私测试可以定义为模型验证和保证套件的一部分健康度函数，并且可以在生产中监测模型漂移。相同的方法可以帮助最大化模型的生命周期价值。
- en: Automating policy enforcement and value accounting in this way reduces manual
    effort, improves compliance, and provides an audit trail. Like automation of testing,
    policy-as-code allows people to focus on defining Responsible AI policies, while
    machines do the repetitive, tedious work of evaluating compliance.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式自动化政策执行和价值核算，减少了手动工作量，提高了合规性，并提供了审计轨迹。与测试的自动化类似，政策即代码允许人们专注于定义负责任的AI政策，而机器则完成评估合规性的重复和乏味工作。
- en: Asking tough questions (a key aspect of Kaizen)
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 提问艰难（Kaizen的关键方面）
- en: As mentioned earlier, CI (or Kaizen) is a core practice in CD4ML. Kaizen requires
    us to prioritize quality outcomes over discomfort, and collective success over
    groupthink. Organizationally, it’s important to nurture a culture—through values,
    policies, and behavior—where it’s acceptable and even encouraged to highlight
    and explore potential issues, failure modes, and sources of harm. It can be as
    simple as any team member asking a question or making an observation when they
    notice practices that aren’t aligned with their values and principles, and exploring
    the implications and any necessary mitigations as a team.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，CI（或Kaizen）是CD4ML中的核心实践。Kaizen要求我们优先考虑质量结果而不是不适感，优先考虑集体成功而不是群体思维。在组织上，通过价值观、政策和行为来培养一种文化是很重要的，这种文化鼓励和甚至鼓励在团队成员发现与其价值观和原则不一致的做法时，突出和探索潜在问题、故障模式和伤害来源。当他们以团队的方式探索其影响和任何必要的减少时，任何团队成员提出问题或观察时，这可能是如此简单。
- en: To implement any Responsible AI framework, team members need to know it’s OK
    to ask tough questions about what should be done with AI and how it should be
    done. (For more on this topic, see the story of Andon Cord and NUMMI in [Chapter 10](ch10.html#building_blocks_of_effective_ml_tea),
    which talks about the importance of essence over form.)
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 要实施任何负责任的AI框架，团队成员需要知道可以对AI提出艰难的问题，以及如何执行。关于这个话题的更多信息，请参阅[第10章](ch10.html#building_blocks_of_effective_ml_tea)，讲述了精髓胜于形式的重要性。
- en: Our experience has taught us that ML governance is not a hindrance to innovation
    but a guiding framework that ensures faster and safer delivery of ML applications.
    CD4ML actually *enables* innovation by facilitating ML governance and encouraging
    teams to embed quality assurance, monitoring, and compliance as part of the ongoing
    delivery cycle, rather than being one-off checkpoints.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的经验表明，ML治理不是创新的障碍，而是确保更快、更安全交付ML应用的指导框架。CD4ML实际上通过促进ML治理并鼓励团队将质量保证、监控和合规性作为持续交付周期的一部分，而不是一次性检查点，*实现了*创新。
- en: Too frequently we encounter ML teams that are constrained by an inability to
    assess or see the risk of a particular application, because the elements described
    in this chapter are not in place. When good ML governance is in place, it sets
    safe boundaries for teams to experiment and build great solutions.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常遇到由于没有按照本章描述的要素设置而受到限制的ML团队无法评估或看到特定应用的风险。当有良好的ML治理时，它为团队设置了安全边界，以实验和构建出色的解决方案。
- en: To close, if your team or organization doesn’t have an ML governance framework
    in place, this would be a great opportunity to define one. The ML governance references
    mentioned earlier in this chapter offer a good starting point for you to adapt
    to your context.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您的团队或组织没有建立ML治理框架，这将是定义一个的好机会。本章早期提到的ML治理参考资料为您适应您的背景提供了一个良好的起点。
- en: It also helps to embed Responsible AI as an integral part of the development
    process, rather than an afterthought. You could consider starting with a statement
    of values regarding how the good of AI will be realized and how harms will be
    mitigated. The values statement establishes the purpose and guidance for the next
    element, which is a framework for designing and implementing AI solutions. That
    framework should accommodate external obligations, such as government regulations
    and third-party contracts, and also be aligned with internal policies and procedures.
    This can then cascade into a set of principles for the use of AI, of which there
    are many great examples from governments and NGOs, as well as books like Cathy
    O’Neil’s *Weapons of Math Destruction* (Crown Books) or Ellen Broad’s *Made by
    Humans* (Melbourne University Press). For anyone wanting to educate themselves
    further about potential harms from ML and proposed mitigations, explore and follow
    the work of leading researchers such as Dr. Joy Buolamwini, Dr. Timnit Gebru,
    Prof. Emily M. Bender, and Dr. Abeba Birhane.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 它还有助于将负责任的人工智能嵌入到开发过程的核心，而不是作为事后想法。你可以考虑从关于如何实现AI的好处以及如何减轻伤害的价值声明开始。价值声明为下一个元素提供了目的和指导，即设计和实施AI解决方案的框架。该框架应适应外部义务，如政府法规和第三方合同，并与内部政策和程序保持一致。这可以进一步衍生出一套关于AI使用的原则，这些原则包括来自政府和非政府组织的许多优秀示例，以及卡西·奥尼尔的《数学毁灭的武器》（Crown
    Books）或埃伦·布劳德的《人造》（墨尔本大学出版社）。对于任何希望进一步了解ML潜在危害及建议减轻措施的人来说，可以探索并关注领先研究人员的工作，如乔伊·布拉明维尼博士、蒂姆尼特·盖布鲁博士、埃米莉·M·本德教授和阿贝巴·比尔哈内博士。
- en: Now, let’s wrap up this massive chapter with a brief recap.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们用一个简短的总结来结束这个庞大的章节。
- en: Conclusion
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Coming back to our opening story, if Dana and Ted had these MLOps and CD4ML
    practices in place, the production deployment would have been a no-drama, no-nerves,
    click-of-a-button affair. This is not an aspiration, but a reality, based on our
    experience practicing CD4ML in real-world projects.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们开篇的故事，如果达纳和泰德采用了这些MLOps和CD4ML实践，生产部署将会是一个毫无戏剧性、无忧无虑、点击按钮即可完成的事务。这不是一个愿景，而是基于我们在真实项目中实践CD4ML的经验所得出的现实。
- en: Wherever you are on your organization’s ML maturity journey, we hope that these
    practices will help you scale and improve your organization’s ML practice. As
    MLOps tooling and techniques continue to grow, we find that these CD4ML principles
    and practices are enduring and provide a useful framework for identifying a set
    of quality gates and processes to help teams deliver ML models rapidly and reliably.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你的组织在其ML成熟度旅程的哪个阶段，我们希望这些实践能帮助你扩展和改进你的组织的ML实践。随着MLOps工具和技术的不断发展，我们发现这些CD4ML原则和实践具有持久性，并为帮助团队快速可靠地交付ML模型提供了一个有用的框架来识别一组质量门和过程。
- en: 'To recap, in this chapter, we’ve:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，在本章中，我们：
- en: Established the basic building blocks of MLOps, and outlined common pitfalls
    that teams experience when practicing MLOps
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立了MLOps的基本构建模块，并概述了团队在实践MLOps时常遇到的常见问题。
- en: Described how ML teams can benefit from CD principles of building quality into
    the product, working in small batches, automation, continuous improvement (Kaizen),
    and shared ownership
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述了机器学习团队如何从持续交付的原则中受益，包括将质量融入产品、小批量工作、自动化、持续改进（Kaizen）和共享所有权。
- en: Delved into why and how CD4ML is a great complement to MLOps, and the CD4ML
    practices that can help ML teams ship reliable ML solutions to production early
    and often
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探讨了为什么以及如何CD4ML作为MLOps的极好补充，以及CD4ML实践如何帮助ML团队早期和频繁地将可靠的ML解决方案推向生产环境。
- en: Explored how CD4ML supports ML governance and Responsible AI
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探讨了CD4ML如何支持ML治理和负责任的人工智能。
- en: Well done on completing this chapter! See you in the next chapter, where we’ll
    kick off [Part III, “Teams”](part03.html#partiii).
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了本章内容！我们下一章见，我们将开始[第三部分，“团队”](part03.html#partiii)。
- en: '^([1](ch09.html#ch01fn37-marker)) CD4ML has helped us accelerate the delivery
    of ML products. The following case studies provide more detail: [“Staying Nimble,
    Delivering Transformative Fintech at Speed”](https://oreil.ly/PC7os), [“The Journey
    to Build Australia’s Most Accurate Property Valuation Tool”](https://oreil.ly/MsnVj),
    and [“Getting Smart: Applying Continuous Delivery to Data Science to Drive Car
    Sales”](https://oreil.ly/2ZF4-).'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch09.html#ch01fn37-marker)) CD4ML帮助我们加速了ML产品的交付。以下案例研究提供了更多细节：[“保持敏捷，以速度交付变革性金融科技”](https://oreil.ly/PC7os)、[“构建澳大利亚最准确的房产估值工具之旅”](https://oreil.ly/MsnVj)和[“变得更聪明：应用持续交付到数据科学以推动汽车销售”](https://oreil.ly/2ZF4-)。
- en: ^([2](ch09.html#ch01fn38-marker)) While some roles (e.g., data scientists, ML
    engineers, product owners) can often be in a vertical cross-functional team, some
    other roles (e.g., security specialists) tend to be situated in a horizontal enabling
    team. We will discuss these nuances and team shape options in [Chapter 11](ch11.html#effective_ml_organizations)
    when we cover ML team topologies.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch09.html#ch01fn38-marker)) 虽然一些角色（例如数据科学家、ML 工程师、产品负责人）通常可以在垂直跨功能团队中，但另一些角色（例如安全专家）倾向于位于水平启用团队中。我们将在[第
    11 章](ch11.html#effective_ml_organizations)讨论这些细微差别和团队形态选项。
- en: ^([3](ch09.html#ch01fn39-marker)) Elizabeth M. Renieris, David Kiron, and Steven
    Mills, [“To Be a Responsible AI Leader, Focus on Being Responsible”](https://oreil.ly/XbPUv),
    *MIT Sloan Management Review*, accessed November 8, 2023.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch09.html#ch01fn39-marker)) Elizabeth M. Renieris, David Kiron, and Steven
    Mills, [“成为负责任的人工智能领导者，专注于负责任”](https://oreil.ly/XbPUv), *MIT Sloan Management
    Review*, 访问于 2023 年 11 月 8 日.
