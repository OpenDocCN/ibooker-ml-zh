- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序言
- en: A Brief History of Machine Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的简要历史
- en: Machine learning is a subfield of artificial intelligence (AI) in which computers
    learn from data—usually to improve their performance on some narrowly defined
    task—without being explicitly programmed. The term *machine learning* was coined
    as early as 1959 (by Arthur Samuel, a legend in the field of AI), but there were
    few major commercial successes in machine learning during the twenty-first century.
    Instead, the field remained a niche research area for academics at universities.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是人工智能的一个子领域，计算机通过数据学习，通常是为了在某些狭义定义的任务上提高性能，而无需显式编程。*机器学习* 这个术语早在1959年就被创造出来了（由AI领域的传奇人物亚瑟·塞缪尔），但在21世纪，机器学习并没有取得多少主要的商业成功。相反，该领域仍然是一种学术界的小众研究领域。
- en: Early on (in the 1960s) many in the AI community were too optimistic about its
    future. Researchers at the time, such as Herbert Simon and Marvin Minsky, claimed
    that AI would reach human-level intelligence within a matter of decades:^([1](preface01.html#idm140637565202624))
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期（上世纪六十年代），AI社区中许多人对其未来持过于乐观的态度。当时的研究人员，如赫伯特·西蒙和马文·明斯基，声称AI将在几十年内达到人类水平的智能：^([1](preface01.html#idm140637565202624))
- en: Machines will be capable, within twenty years, of doing any work a man can do.
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 机器将在二十年内有能力完成人类能够完成的任何工作。
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Herbert Simon, 1965
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 赫伯特·西蒙，1965
- en: From three to eight years, we will have a machine with the general intelligence
    of an average human being.
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从三到八年内，我们将拥有一台具有平均人类智能的机器。
- en: ''
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Marvin Minsky, 1970
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 马文·明斯基，1970
- en: Blinded by their optimism, researchers focused on so-called *strong AI* or *general
    artificial intelligence (AGI)* projects, attempting to build AI agents capable
    of problem solving, knowledge representation, learning and planning, natural language
    processing, perception, and motor control. This optimism helped attract significant
    funding into the nascent field from major players such as the Department of Defense,
    but the problems these researchers tackled were too ambitious and ultimately doomed
    to fail.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员过于乐观，专注于所谓的*强人工智能* 或 *通用人工智能（AGI）* 项目，试图构建能够解决问题、知识表示、学习和规划、自然语言处理、感知和运动控制的AI代理。这种乐观主义帮助吸引了来自国防部等主要参与者的重要资金，但这些研究人员所解决的问题过于雄心勃勃，最终注定失败。
- en: AI research rarely made the leap from academia to industry, and a series of
    so-called AI winters followed. In these AI winters (an analogy based on the nuclear
    winter during this Cold War era), interest in and funding for AI dwindled. Occasionally,
    hype cycles around AI occurred but had very little staying power. By the early
    1990s, interest in and funding for AI had hit a trough.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: AI研究很少从学术界跨入工业界，随之而来的是一系列所谓的AI寒冬。在这些AI寒冬中（这是基于冷战时代核冬天的类比），对AI的兴趣和资金逐渐减少。偶尔会出现围绕AI的炒作周期，但很少有持久性。到了1990年代初，对AI的兴趣和资金已经达到了低谷。
- en: AI Is Back, but Why Now?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI回归了，但为什么现在？
- en: AI has re-emerged with a vengeance over the past two decades—first as a purely
    academic area of interest and now as a full-blown field attracting the brightest
    minds at both universities and corporations.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 过去二十年中，AI重新以全新的姿态出现——起初作为一种纯学术兴趣领域，现在已成为吸引大学和公司最聪明头脑的完整领域。
- en: 'Three critical developments are behind this resurgence: breakthroughs in machine
    learning algorithms, the availability of lots of data, and superfast computers.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 三个关键发展推动了这一复兴：机器学习算法的突破、大量数据的可用性以及超快速的计算机。
- en: First, instead of focusing on overly ambitious strong AI projects, researchers
    turned their attention to narrowly defined subproblems of strong AI, also known
    as *weak AI* or *narrow AI*. This focus on improving solutions for narrowly defined
    tasks led to algorithmic breakthroughs, which paved the way for successful commercial
    applications. Many of these algorithms—often developed initially at universities
    or private research labs—were quickly open-sourced, speeding up the adoption of
    these technologies by industry.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，研究人员不再专注于过于雄心勃勃的强人工智能项目，转而关注强人工智能的狭义子问题，也被称为*弱人工智能* 或 *狭义人工智能*。这种专注于改进狭义任务解决方案的做法导致了算法上的突破，为成功的商业应用铺平了道路。许多这些算法——通常最初在大学或私人研究实验室开发——很快被开源，加速了这些技术在工业界的采纳。
- en: Second, data capture became a focus for most organizations, and the costs of
    storing data fell dramatically driven by advances in digital data storage. Thanks
    to the internet, lots of data also became widely and publicly available at a scale
    never before seen.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，数据捕获成为大多数组织的焦点，数字数据存储成本大幅下降。得益于互联网，大量数据也以前所未有的规模广泛公开和共享。
- en: Third, computers became increasingly powerful and available over the cloud,
    allowing AI researchers to easily and cheaply scale their IT infrastructure as
    required without making huge upfront investments in hardware.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，云端计算的普及使得AI研究人员能够根据需求轻松、廉价地扩展其IT基础设施，而无需进行大规模的前期硬件投资。
- en: The Emergence of Applied AI
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用人工智能的出现
- en: These three forces have pushed AI from academia to industry, helping attract
    increasingly higher levels of interest and funding every year. AI is no longer
    just a theoretical area of interest but rather a full-blown applied field. [Figure P-1](#ml-over-time)
    shows a chart from Google Trends, indicating the growth in interest in machine
    learning over the past five years.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这三股力量将AI从学术界推向工业界，每年吸引越来越高的兴趣和资金。AI不再仅仅是一个理论上的兴趣领域，而是一个成熟的应用领域。[Figure P-1](#ml-over-time)
    展示了Google Trends中机器学习兴趣的增长趋势图，涵盖了过去五年的时间。
- en: '![Interest in machine learning over time](assets/hulp_0001.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习兴趣随时间变化图](assets/hulp_0001.png)'
- en: Figure P-1\. Interest in machine learning over time
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图P-1. 机器学习兴趣随时间变化图
- en: AI is now viewed as a breakthrough horizontal technology, akin to the advent
    of computers and smartphones, that will have a significant impact on every single
    industry over the next decade.^([2](preface01.html#idm140637564315808))
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，人工智能被视为一种突破性的横向技术，类似于计算机和智能手机的出现，将在未来十年对每一个行业产生重大影响。^([2](preface01.html#idm140637564315808))
- en: Successful commercial applications involving machine learning include—but are
    certainly not limited to—optical character recognition, email spam filtering,
    image classification, computer vision, speech recognition, machine translation,
    group segmentation and clustering, generation of synthetic data, anomaly detection,
    cybercrime prevention, credit card fraud detection, internet fraud detection,
    time series prediction, natural language processing, board game and video game
    playing, document classification, recommender systems, search, robotics, online
    advertising, sentiment analysis, DNA sequencing, financial market analysis, information
    retrieval, question answering, and healthcare decision making.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及机器学习的成功商业应用包括但不限于光学字符识别、电子邮件垃圾过滤、图像分类、计算机视觉、语音识别、机器翻译、群体分割与聚类、生成合成数据、异常检测、网络犯罪预防、信用卡欺诈检测、网络欺诈检测、时间序列预测、自然语言处理、棋盘游戏和视频游戏、文档分类、推荐系统、搜索、机器人技术、在线广告、情感分析、DNA序列分析、金融市场分析、信息检索、问答系统和医疗决策。
- en: Major Milestones in Applied AI over the Past 20 Years
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过去20年来应用人工智能的主要里程碑
- en: The milestones presented here helped bring AI from a mostly academic topic of
    conversation then to a mainstream staple in technology today.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些里程碑将AI从当时主要是学术讨论的话题带到了今天科技的主流位置。
- en: '1997: Deep Blue, an AI bot that had been in development since the mid-1980s,
    beats world chess champion Garry Kasparov in a highly publicized chess event.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1997年：Deep Blue，一个自上世纪80年代中期开始研发的AI机器人，在一场备受关注的国际象棋比赛中击败了世界冠军加里·卡斯帕罗夫。
- en: '2004: DARPA introduces the DARPA Grand Challenge, an annually held autonomous
    driving challenge held in the desert. In 2005, Stanford takes the top prize. In
    2007, Carnegie Mellon University performs this feat in an urban setting. In 2009,
    Google builds a self-driving car. By 2015, many major technology giants, including
    Tesla, Alphabet’s Waymo, and Uber, have launched well-funded programs to build
    mainstream self-driving technology.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2004年：DARPA推出了DARPA Grand Challenge，这是一项年度举办的自动驾驶挑战赛，在沙漠地区举行。2005年，斯坦福获得了最高奖。2007年，卡内基梅隆大学在城市环境中实现了这一壮举。2009年，谷歌推出了自动驾驶汽车。到2015年，包括特斯拉、Alphabet的Waymo和Uber在内的许多主要技术巨头都推出了资金充裕的主流自动驾驶技术项目。
- en: '2006: Geoffrey Hinton of the University of Toronto introduces a fast learning
    algorithm to train neural networks with many layers, kicking off the deep learning
    revolution.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2006年：多伦多大学的Geoffrey Hinton提出了一种快速学习算法，用于训练多层神经网络，开启了深度学习革命。
- en: '2006: Netflix launches the Netflix Prize competition, with a one million dollar
    purse, challenging teams to use machine learning to improve its recommendation
    system’s accuracy by at least 10%. A team won the prize in 2009.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2006: Netflix启动了Netflix奖（Netflix Prize）竞赛，奖金高达一百万美元，挑战团队利用机器学习技术，将其推荐系统的准确性提高至少10%。一个团队在2009年赢得了这一奖项。'
- en: '2007: AI achieves superhuman performance at checkers, solved by a team from
    the University of Alberta.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2007: AI在跳棋比赛中达到超人类水平，由阿尔伯塔大学的团队解决。'
- en: '2010: ImageNet launches an annual contest—the ImageNet Large Scale Visual Recognition
    Challenge (ILSVRC)—in which teams use machine learning algorithms to correctly
    detect and classify objects in a large, well-curated image dataset. This draws
    significant attention from both academia and technology giants. The classification
    error rate falls from 25% in 2011 to just a few percent by 2015, backed by advances
    in deep convolutional neural networks. This leads to commercial applications of
    computer vision and object recognition.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2010: ImageNet启动了年度比赛——ImageNet大规模视觉识别挑战（ILSVRC），团队使用机器学习算法在一个大型、经过良好筛选的图像数据集中正确检测和分类对象。这引起了学术界和技术巨头的重视。由于深度卷积神经网络的进展，2011年的分类错误率从25%降至2015年的几个百分点。这导致了计算机视觉和物体识别的商业应用。'
- en: '2010: Microsoft launches Kinect for Xbox 360\. Developed by the computer vision
    team at Microsoft Research, Kinect is capable of tracking human body movement
    and translating this into gameplay.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2010: Microsoft推出了Xbox 360的Kinect。由Microsoft Research的计算机视觉团队开发，Kinect能够跟踪人体动作并将其转化为游戏操作。'
- en: '2010: Siri, one of the first mainstream digital voice assistants, is acquired
    by Apple and released as part of iPhone 4S in October 2011\. Eventually, Siri
    is rolled out across all of Apple’s products. Powered by convolutional neural
    networks and long short-term memory recurrent neural networks, Siri performs both
    speech recognition and natural language processing. Eventually, Amazon, Microsoft,
    and Google enter the race, releasing Alexa (2014), Cortana (2014), and Google
    Assistant (2016), respectively.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2010: Siri，最早的主流数字语音助手之一，被Apple收购，并作为iPhone 4S的一部分于2011年10月发布。最终，Siri在Apple的所有产品中都推出。由卷积神经网络和长短期记忆递归神经网络驱动，Siri执行语音识别和自然语言处理。随后，亚马逊、微软和谷歌进入竞争，分别发布了Alexa（2014年）、Cortana（2014年）和Google
    Assistant（2016年）。'
- en: '2011: IBM Watson, a question-answering AI agent developed by a team led by
    David Ferrucci, beats former *Jeopardy!* winners Brad Rutter and Ken Jennings.
    IBM Watson is now used across several industries, including healthcare and retail.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2011: IBM Watson，一个由David Ferrucci领导的团队开发的问答型AI代理程序，击败了前《危险边缘》获胜者Brad Rutter和Ken
    Jennings。IBM Watson现在被多个行业使用，包括医疗保健和零售。'
- en: '2012: Google Brain team, led by Andrew Ng and Jeff Dean, trains a neural network
    to recognize cats by watching unlabeled images taken from YouTube videos.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2012: 由Andrew Ng和Jeff Dean领导的Google Brain团队，通过观看来自YouTube视频的未标记图像，训练神经网络识别猫。'
- en: '2013: Google wins DARPA’s Robotics Challenge, involving trials in which semi-autonomous
    bots perform complex tasks in treacherous environments, such as driving a vehicle,
    walking across rubble, removing debris from a blocked entryway, opening a door,
    and climbing a ladder.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2013: Google赢得了DARPA机器人挑战赛，涉及半自主机器人在危险环境中执行复杂任务，如驾驶车辆、越过瓦砾、清除被堵入的入口、打开门和爬梯子。'
- en: '2014: Facebook publishes work on DeepFace, a neural network-based system that
    can identify faces with 97% accuracy. This is near human-level performance and
    is a more than 27% improvement over previous systems.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2014: Facebook发布了基于神经网络的DeepFace系统，可以以97%的准确率识别面部。这接近人类水平的性能，比先前系统提高了27%以上。'
- en: '2015: AI goes mainstream, and is commonly featured in media outlets around
    the world.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2015: AI成为主流，并广泛出现在全球的媒体报道中。'
- en: '2015: Google DeepMind’s AlphaGo beats world-class professional Fan Hui at the
    game Go. In 2016, AlphaGo defeats Lee Sedol, and in 2017, AlphaGo defeats Ke Jie.
    In 2017, a new version called AlphaGo Zero defeats the previous AlphaGo version
    100 to zero. AlphaGo Zero incorporates unsupervised learning techniques and masters
    Go just by playing itself.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2015: Google DeepMind的AlphaGo击败了世界级职业选手樊麾的围棋比赛。2016年，AlphaGo又击败了李世石，2017年又击败了柯洁。2017年，名为AlphaGo
    Zero的新版本以100比0击败了以前的AlphaGo版本。AlphaGo Zero采用无监督学习技术，仅通过与自己对弈就掌握了围棋。'
- en: '2016: Google launches a major revamp to its language translation, Google Translate,
    replacing its existing phrase-based translation system with a deep learning-based
    neural machine translation system, reducing translation errors by up to 87% and
    approaching near human-level accuracy.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2016年：谷歌对其语言翻译系统Google Translate进行了重大改进，将其现有的基于短语的翻译系统替换为基于深度学习的神经机器翻译系统，将翻译错误率降低了多达87%，接近人类水平的准确度。
- en: '2017: Libratus, developed by Carnegie Mellon, wins at head-to-head no-limit
    Texas Hold’em.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2017年：由卡内基梅隆大学开发的Libratus在无限制德州扑克头对头比赛中获胜。
- en: '2017: OpenAI-trained bot beats professional gamer at Dota 2 tournament.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2017年：OpenAI训练的机器人在Dota 2比赛中击败了职业玩家。
- en: From Narrow AI to AGI
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从狭义人工智能到通用人工智能
- en: Of course, these successes in applying AI to narrowly defined problems are just
    a starting point. There is a growing belief in the AI community that—by combining
    several weak AI systems—we can develop strong AI. This strong AI or AGI agent
    will be capable of human-level performance at many broadly defined tasks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，将人工智能成功应用于狭义问题只是一个起点。在人工智能社区中，有一种越来越强烈的信念，即通过结合几个弱人工智能系统，我们可以开发出强人工智能。这种强人工智能或通用人工智能（AGI）代理将能够在许多广义任务上达到人类水平的表现。
- en: Soon after AI achieves human-level performance, some researchers predict this
    strong AI will surpass human intelligence and reach so-called *superintelligence*.
    Estimates for attaining such superintelligence range from as little as 15 years
    to as many as 100 years from now, but most researchers believe AI will advance
    enough to achieve this in a few generations. Is this inflated hype once again
    (like what we saw in previous AI cycles), or is it different this time around?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能达到人类水平表现之后不久，一些研究人员预测这种强人工智能将超越人类智能，达到所谓的*超级智能*。达到这种超级智能的时间估计从现在起可能只需15年，也可能需要100年，但大多数研究人员认为，在未来几代人之内，人工智能将足够发展到达到这一水平。这一次，这是否又是像之前人工智能周期中看到的炒作，还是有所不同？
- en: Only time will tell.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 只有时间能说明一切。
- en: Objective and Approach
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标与方法
- en: Most of the successful commercial applications to date—in areas such as computer
    vision, speech recognition, machine translation, and natural language processing—have
    involved supervised learning, taking advantage of labeled datasets. However, most
    of the world’s data is *unlabeled*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，大多数成功的商业应用程序（如计算机视觉、语音识别、机器翻译和自然语言处理）都涉及有标签数据的监督学习。然而，大多数世界数据是*未标记*的。
- en: In this book, we will cover the field of *unsupervised learning* (which is a
    branch of machine learning used to find hidden patterns) and learn the underlying
    structure in unlabeled data. According to many industry experts, such as Yann
    LeCun, the Director of AI Research at Facebook and a professor at NYU, unsupervised
    learning is the next frontier in AI and may hold the key to AGI. For this and
    many other reasons, unsupervised learning is one of the trendiest topics in AI
    today.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将涵盖*无监督学习*领域（这是机器学习的一个分支，用于发现隐藏的模式），并学习未标记数据中的潜在结构。根据许多行业专家的说法，比如Facebook的AI研究总监兼纽约大学教授**杨立昆**，无监督学习是人工智能的下一个前沿，可能是实现通用人工智能的关键。因此，无监督学习是当今人工智能领域最炙手可热的话题之一。
- en: The book’s goal is to outline the concepts and tools required for you to develop
    the intuition necessary for applying this technology to everyday problems that
    you work on. In other words, this is an applied book, one that will allow you
    to build real-world systems. We will also explore how to efficiently label unlabeled
    datasets to turn unsupervised learning problems into semisupervised ones.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是概述您在日常工作中应用这项技术所需的概念和工具，以便您能够发展出这种直觉。换句话说，这是一本应用性的书籍，将帮助您构建真实世界的系统。我们还将探讨如何高效地标记未标记的数据集，将无监督学习问题转化为半监督学习问题。
- en: The book will use a hands-on approach, introducing some theory but focusing
    mostly on applying unsupervised learning techniques to solving real-world problems.
    The datasets and code are available online as Jupyter notebooks on [GitHub](http://bit.ly/2Gd4v7e).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将采用实践方法，介绍一些理论，但主要侧重于将无监督学习技术应用于解决现实世界的问题。数据集和代码可在[Jupyter notebooks on GitHub](http://bit.ly/2Gd4v7e)上找到。
- en: Armed with the conceptual understanding and hands-on experience you’ll gain
    from this book, you will be able to apply unsupervised learning to large, unlabeled
    datasets to uncover hidden patterns, obtain deeper business insight, detect anomalies,
    cluster groups based on similarity, perform automatic feature engineering and
    selection, generate synthetic datasets, and more.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 凭借从本书中获得的概念理解和实践经验，您将能够将无监督学习应用于大型未标记数据集，以揭示隐藏模式，获取更深入的业务见解，检测异常，基于相似性对群组进行聚类，执行自动特征工程和选择，生成合成数据集等等。
- en: Prerequisites
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 先决条件
- en: This book assumes that you have some Python programming experience, including
    familiarity with NumPy and Pandas.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本书假定您具有一些Python编程经验，包括熟悉NumPy和Pandas。
- en: For more on Python, visit the [official Python website](https://www.python.org/).
    For more on Jupyter Notebook, visit the [official Jupyter website](http://jupyter.org/index.html).
    For a refresher on college-level calculus, linear algebra, probability, and statistics,
    read [Part I of the *Deep Learning* textbook](http://www.deeplearningbook.org/)
    by Ian Goodfellow and Yoshua Bengio. For a refresher on machine learning, read
    [*The Elements of Statistical Learning*](https://stanford.io/2Tju4al).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Python的更多信息，请访问[官方Python网站](https://www.python.org/)。有关Jupyter Notebook的更多信息，请访问[官方Jupyter网站](http://jupyter.org/index.html)。要复习大学水平的微积分、线性代数、概率和统计学，请阅读Ian
    Goodfellow和Yoshua Bengio的[《深度学习》教材的第I部分](http://www.deeplearningbook.org/)。要复习机器学习，请阅读[*统计学习的要素*](https://stanford.io/2Tju4al)。
- en: Roadmap
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 路线图
- en: 'The book is organized into four parts, covering the following topics:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 本书分为四个部分，涵盖以下主题：
- en: '[Part I, *Fundamentals of Unsupervised Learning*](part01.html#Part_One)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 I 部分，*无监督学习基础*](part01.html#Part_One)'
- en: Differences between supervised and unsupervised learning, an overview of popular
    supervised and unsupervised algorithms, and an end-to-end machine learning project
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习和无监督学习之间的差异，流行的监督学习和无监督学习算法的概述，以及端到端的机器学习项目
- en: '[Part II, *Unsupervised Learning Using Scikit-Learn*](part02.html#Part_Two)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 II 部分，*使用Scikit-Learn进行无监督学习*](part02.html#Part_Two)'
- en: Dimensionality reduction, anomaly detection, and clustering and group segmentation
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 降维、异常检测和聚类和分组分割
- en: Tip
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: For more information on the concepts discussed in Parts I and II, refer to the
    [Scikit-learn documentation](https://scikit-learn.org/stable/modules/classes.html).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 有关部分I和II中讨论的概念的更多信息，请参阅[Scikit-learn文档](https://scikit-learn.org/stable/modules/classes.html)。
- en: '[Part III, *Unsupervised Learning Using TensorFlow and Keras*](part03.html#Part_Three)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 III 部分，*使用TensorFlow和Keras进行无监督学习*](part03.html#Part_Three)'
- en: Representation learning and automatic feature extraction, autoencoders, and
    semisupervised learning
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 表示学习和自动特征提取、自动编码器和半监督学习
- en: '[Part IV, *Deep Unsupervised Learning Using TensorFlow and Keras*](part04.html#Part_Four)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 IV 部分，*使用TensorFlow和Keras进行深度无监督学习*](part04.html#Part_Four)'
- en: Restricted Boltzmann machines, deep belief networks, and generative adversarial
    networks
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 受限玻尔兹曼机、深度信念网络和生成对抗网络
- en: Conventions Used in This Book
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书中使用的约定
- en: 'The following typographical conventions are used in this book:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用以下印刷约定：
- en: '*Italic*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*斜体*'
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 表示新术语、URL、电子邮件地址、文件名和文件扩展名。
- en: '`Constant width`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`常量宽度`'
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 用于程序清单，以及在段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。
- en: '**`Constant width bold`**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**`常量宽度粗体`**'
- en: Shows commands or other text that should be typed literally by the user.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 显示用户应该按字面意思输入的命令或其他文本。
- en: '*`Constant width italic`*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*`常量宽度斜体`*'
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 显示应替换为用户提供的值或上下文确定的值的文本。
- en: Tip
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: This element signifies a tip or suggestion.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示提示或建议。
- en: Note
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This element signifies a general note.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示一般注释。
- en: Warning
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: This element indicates a warning or caution.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示警告或注意事项。
- en: Using Code Examples
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用代码示例
- en: Supplemental material (code examples, etc.) is available for download on [GitHub](http://bit.ly/2Gd4v7e).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[GitHub](http://bit.ly/2Gd4v7e)上下载补充材料（代码示例等）。
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing a CD-ROM
    of examples from O’Reilly books does require permission. Answering a question
    by citing this book and quoting example code does not require permission. Incorporating
    a significant amount of example code from this book into your product’s documentation
    does require permission.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在帮助您完成工作。一般情况下，如果本书提供示例代码，您可以在您的程序和文档中使用它。除非您复制了代码的大部分内容，否则无需征得我们的许可。例如，编写一个使用本书中几个代码片段的程序无需许可。销售或分发包含奥莱利书籍示例的
    CD-ROM 需要许可。引用本书回答问题并引用示例代码无需许可。将本书的大量示例代码整合到您产品的文档中需要许可。
- en: 'We appreciate, but do not require, attribution. An attribution usually includes
    the title, author, publisher, and ISBN. For example: “*Hands-On Unsupervised Learning
    Using Python* by Ankur A. Patel (O’Reilly). Copyright 2019 Ankur A. Patel, 978-1-492-03564-0.”'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢但不需要署名。署名通常包括标题、作者、出版商和 ISBN。例如：“*使用 Python 进行无监督学习实战* 作者 Ankur A. Patel（奥莱利）。版权所有
    2019 Ankur A. Patel，978-1-492-03564-0。”
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您觉得您使用的代码示例超出了合理使用范围或上述授权，请随时通过 [*permissions@oreilly.com*](mailto:permissions@oreilly.com)
    联系我们。
- en: O’Reilly Online Learning
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奥莱利在线学习
- en: Note
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For almost 40 years, [*O’Reilly Media*](http://oreilly.com) has provided technology
    and business training, knowledge, and insight to help companies succeed.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 近 40 年来，[*奥莱利传媒*](http://oreilly.com) 为企业的成功提供技术和商业培训、知识和洞察。
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, conferences, and our online learning platform. O’Reilly’s
    online learning platform gives you on-demand access to live training courses,
    in-depth learning paths, interactive coding environments, and a vast collection
    of text and video from O’Reilly and 200+ other publishers. For more information,
    please visit [*http://oreilly.com*](http://oreilly.com).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们独特的专家和创新者网络通过书籍、文章、会议和我们的在线学习平台分享他们的知识和专业知识。奥莱利的在线学习平台为您提供按需访问的现场培训课程、深度学习路径、交互式编码环境以及来自奥莱利和其他
    200 多家出版商的大量文本和视频。更多信息，请访问 [*http://oreilly.com*](http://oreilly.com)。
- en: How to Contact Us
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何联系我们
- en: 'Please address comments and questions concerning this book to the publisher:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 请将有关本书的评论和问题发送至出版商：
- en: O’Reilly Media, Inc.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奥莱利传媒公司
- en: 1005 Gravenstein Highway North
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1005 Gravenstein Highway North
- en: Sebastopol, CA 95472
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CA 95472 Sebastopol
- en: 800-998-9938 (in the United States or Canada)
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 800-998-9938（美国或加拿大）
- en: 707-829-0515 (international or local)
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0515（国际或本地）
- en: 707-829-0104 (fax)
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0104（传真）
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*http://bit.ly/unsupervised-learning*](http://bit.ly/unsupervised-learning).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为本书设立了一个网页，列出勘误、示例和任何额外信息。您可以访问 [*http://bit.ly/unsupervised-learning*](http://bit.ly/unsupervised-learning)。
- en: To comment or ask technical questions about this book, send email to [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要就本书发表评论或提出技术问题，请发送电子邮件至 [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)。
- en: For more information about our books, courses, conferences, and news, see our
    website at [*http://www.oreilly.com*](http://www.oreilly.com).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 有关我们的图书、课程、会议和新闻的更多信息，请访问我们的网站 [*http://www.oreilly.com*](http://www.oreilly.com)。
- en: 'Find us on Facebook: [*http://facebook.com/oreilly*](http://facebook.com/oreilly)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Facebook 上找到我们：[*http://facebook.com/oreilly*](http://facebook.com/oreilly)
- en: 'Follow us on Twitter: [*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Twitter 上关注我们：[*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)
- en: 'Watch us on YouTube: [*http://www.youtube.com/oreillymedia*](http://www.youtube.com/oreillymedia)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在 YouTube 上观看我们：[*http://www.youtube.com/oreillymedia*](http://www.youtube.com/oreillymedia)
- en: '^([1](preface01.html#idm140637565202624-marker)) Such views inspired Stanley
    Kubrick in 1968 to create the AI agent HAL 9000 in *2001: A Space Odyssey*.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](preface01.html#idm140637565202624-marker)) 这些观点在 1968 年启发了斯坦利·库布里克创作 *2001：太空漫游*
    中的 AI 代理人 HAL 9000。
- en: ^([2](preface01.html#idm140637564315808-marker)) According to McKinsey Global
    Institute, over half of all the professional activities people are paid to do
    could be automated by 2055.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 根据麦肯锡全球研究所的报告，到2055年，人们获得报酬的所有专业活动中超过一半可以实现自动化。
