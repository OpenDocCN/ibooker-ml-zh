- en: Chapter 1\. Introduction to Responsible Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 介绍负责任的机器学习
- en: “Success in creating effective AI, could be the biggest event in the history
    of our civilization. Or the worst.”
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “成功地创造出有效的人工智能可能是我们文明史上最重大的事件。或者是最糟糕的。”
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Stephen Hawking
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 斯蒂芬·霍金
- en: Machine learning (ML) systems can make and save money for organizations across
    industries, and they’re a critical aspect of many organization’s digital transformation
    plans. For these reasons (and others), [ML investments were increasing rapidly](https://oreil.ly/aARnT)
    before the COVID-19 crisis, and they’re [expected to stay healthy](https://oreil.ly/15_1l)
    as the situation unfolds. However, ML systems present risks for operators, consumers,
    and the general public. In many ways, this is similar to an older generation of
    transformational commercial technologies, like jetliners and nuclear reactors.
    Like these technologies, ML can fail on its own, or adversaries can attack it.
    Unlike some older transformational technologies, and despite [growing evidence](https://oreil.ly/zy35H)
    of ML’s capability to do serious harm, ML practitioners don’t seem to consider
    risk mitigation to be a primary directive of their work.^([1](ch01.xhtml#idm46137004684600))
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）系统可以为各行各业的组织节省和赚取资金，它们是许多组织数字转型计划的关键方面。因此，[ML的投资在COVID-19危机前增长迅速](https://oreil.ly/aARnT)，而且在情况发展过程中它们的增长预期[依然健康](https://oreil.ly/15_1l)。然而，ML系统对操作者、消费者和公众都存在风险。在很多方面，这与旧一代变革性商业技术（如喷气客机和核反应堆）相似。像这些技术一样，ML可以自行失败，或者被对手攻击。与一些旧的变革性技术不同的是，尽管[越来越多的证据表明ML可能造成严重危害](https://oreil.ly/zy35H)，ML从业者似乎并不认为风险缓解是他们工作的主要指令^[1](ch01.xhtml#idm46137004684600)。
- en: Common ML failure modes include unaccountable black-box mechanisms, social discrimination,
    security vulnerabilities, privacy harms, and the decay of system quality over
    time. Most ML attacks involve insider manipulation of training data and model
    mechanisms; manipulation of predictions or intellectual property extraction by
    external adversaries; or trojans hidden in third-party data, models, or other
    artifacts. When failures or attacks spiral out of control, they become full-blown
    AI incidents, creating significant adverse outcomes for the operator or the public.
    There have been over 1,000 reports of AI incidents to date.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的ML故障模式包括不可解释的黑盒机制、社会歧视、安全漏洞、隐私危害以及系统质量随时间的衰退。大多数ML攻击涉及内部人员操纵训练数据和模型机制；外部对手操纵预测或知识产权抽取；或隐藏在第三方数据、模型或其他工件中的特洛伊木马。当故障或攻击失控时，它们会演变成全面的AI事件，对操作者或公众造成重大不利后果。到目前为止，已有超过1,000起AI事故报告。
- en: While AI incidents are receiving more attention in the news and technology media
    of late, the hype around ML still seems to focus mostly on ML successes and not
    on ML risks. Subsequently, some decision makers and practitioners implement ML
    without a sober evaluation of its dangers. This report will cut through the hype
    to provide a high-level overview of ML’s emerging risk mitigation practices—often
    called “responsible machine learning.” This first chapter will give definitions
    of responsible AI and ML, and Chapters [2](ch02.xhtml#people_humans_in_the_loop),
    [3](ch03.xhtml#processes_taming_the_wild_west_of_machine_learning_workflows),
    and [4](ch04.xhtml#technology_engineering_machine_learning_for_human_trust_and_understanding)
    discuss viable ML risk mitigation steps for people, processes, and technologies,
    respectively. [Chapter 5](ch05.xhtml#driving_value_with_responsible_machine_learning_innovation)
    closes this report with business-driven perspectives on risk and trust.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然AI事故最近在新闻和技术媒体上受到了更多关注，但围绕ML的炒作似乎主要集中在ML的成功上，而不是ML的风险上。因此，一些决策者和从业者在没有理性评估其危险性的情况下实施ML。本报告将消除炒作，提供ML新兴风险缓解实践的高层概述，通常被称为“负责任的机器学习”。本章将提供负责任人工智能和ML的定义，第[2](ch02.xhtml#people_humans_in_the_loop)、[3](ch03.xhtml#processes_taming_the_wild_west_of_machine_learning_workflows)和[4](ch04.xhtml#technology_engineering_machine_learning_for_human_trust_and_understanding)章将分别讨论人员、流程和技术的可行ML风险缓解步骤。[第5章](ch05.xhtml#driving_value_with_responsible_machine_learning_innovation)以业务驱动的视角结束本报告，关于风险和信任的问题。
- en: What Is Responsible Machine Learning?
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是负责任的机器学习？
- en: What is responsible ML? It’s not strictly defined yet, and the authors of this
    report don’t seek to define it precisely. The concept of responsible ML needs
    time to evolve and grow with input from diverse practitioners, researchers, and
    decision makers. We hope that, like commercial aviation and energy production
    today, risk mitigation will eventually rise to the forefront of ML’s practice,
    and there will be no need to differentiate between the general practice of ML
    and the responsible practice of ML. So, instead of putting forward a single definition,
    we present several potential definitions and discuss a few key similarities and
    differences between them to increase community awareness of this vital concept.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是负责任的机器学习？它还没有严格的定义，本报告的作者也不打算精确定义它。负责任机器学习的概念需要时间与来自不同从业者、研究人员和决策者的输入共同演化和发展。我们希望，就像今天的商业航空和能源生产一样，风险缓解最终将成为机器学习实践的核心，不再需要区分机器学习的一般实践和负责任机器学习的实践。因此，我们没有提出一个单一的定义，而是提出了几个潜在的定义，并讨论了它们之间的一些主要相似性和差异，以增强社区对这一重要概念的意识。
- en: Responsible Artificial Intelligence
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负责人工智能
- en: Several researchers and organizations have put forward helpful related definitions,
    particularly for “Responsible Artificial Intelligence.” Given that ML is a subdiscipline
    of AI, and that the two terms are often used interchangeably, these definitions
    seem like an excellent place to start.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 几位研究人员和组织提出了有关“负责任人工智能”的有帮助的相关定义，特别是因为机器学习是人工智能的一个分支学科，而且这两个术语常常可以互换使用，这些定义似乎是一个很好的起点。
- en: 'In her book, *Responsible Artificial Intelligence* (Springer), Virginia Dignum
    defines the eponymous concept: “Responsible Artificial Intelligence is about human
    responsibility for the development of intelligent systems along fundamental human
    principles and values, to ensure human-flourishing and well-being in a sustainable
    world.”'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在她的书《*负责任的人工智能*》（Springer）中，Virginia Dignum 定义了这一概念：“负责任的人工智能是关于人类按照基本的人类原则和价值观来发展智能系统的责任，以确保在可持续的世界中人类的繁荣和福祉。”
- en: 'The [Institute for Ethical AI & Machine Learning](https://oreil.ly/XwK_T) presents
    eight principles that “provide a practical framework to support technologists
    when designing, developing or maintaining systems that learn from data.” The principles
    include:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[伦理人工智能与机器学习研究所](https://oreil.ly/XwK_T) 提出了八项原则，“为技术人员在设计、开发或维护从数据中学习的系统时提供一个实用的框架”。这些原则包括：'
- en: Human augmentation
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 人类增强
- en: Human review and assessment of risks
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 人类审查和风险评估
- en: Bias evaluation
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 偏见评估
- en: Understanding, documenting, and monitoring sociological discrimination
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 理解、记录和监测社会歧视
- en: Explainability by justification
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 解释性通过理由
- en: Transparency and explainability
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 透明度和解释性
- en: Reproducible operations
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 可复制的操作
- en: Processes and outcomes should be reproducible
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 过程和结果应该是可复制的
- en: Displacement strategy
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 替代策略
- en: Consideration of the replacement of human jobs
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑人类工作替代
- en: Practical accuracy
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 实际准确性
- en: Real-world accuracy in addition to test data accuracy
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 实际世界的准确性以及测试数据的准确性
- en: Trust by privacy
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 信任与隐私
- en: Addressing training data and consumer data privacy
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 处理培训数据和消费者数据隐私
- en: Data risk awareness
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据风险意识
- en: Reasonable security precautions for data and models
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据和模型采取合理的安全预防措施
- en: Google has also put forward [Responsible AI Practices](https://oreil.ly/TYcIx).
    These include using human-centered design principles, using multiple assessment
    metrics for any AI system, examining raw data, understanding the limitations of
    selected approaches, and thorough testing and monitoring of AI systems. Google
    is just one many organizations to publicize such guidance, and a brief summary
    of the many posted responsible AI guidelines boils down to the use of transparent
    technical mechanisms that create appealable decisions or outcomes, perform reliably
    over time, exhibit minimal social discrimination, and are designed by humans with
    diverse experiences, both in terms of demographics and professional backgrounds.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌也提出了[负责任的AI实践](https://oreil.ly/TYcIx)。这些包括使用以人为中心的设计原则，对任何AI系统使用多种评估指标，审查原始数据，了解所选方法的限制，并对AI系统进行彻底的测试和监控。谷歌只是众多组织中公布此类指导的一个例子，而这些负责任的AI准则的简要总结可归结为使用透明的技术机制来创建可上诉的决策或结果，长期可靠的执行，展现最小的社会歧视，并由具有不同人口统计和专业背景经验的人类设计。
- en: The authors of this text recently put forward two additional relevant definitions.
    Both are visual definitions. One is a higher-level conceptual summary, and the
    other is geared toward frontline practitioners. The higher-level description uses
    a Venn diagram, presented in [Figure 1-1](#fig_1_a_responsible_ai_venn_diagram_figure_courtesy_of),
    to portray responsible AI as a combination of several preexisting and evolving
    disciplines.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的作者最近提出了另外两个相关定义。其中一个是高层次概念摘要，另一个是面向一线从业者的。高层次描述使用了一个Venn图，显示在[图 1-1](#fig_1_a_responsible_ai_venn_diagram_figure_courtesy_of)
    中，将负责任的AI描述为几个现有和不断发展的学科的结合。
- en: '![A responsible AI Venn diagram. Figure courtesy of Benjamin Cox and H2O.ai.](Images/reml_0101.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![一个负责任的AI Venn图。图片由本杰明·考克斯和H2O.ai提供。](Images/reml_0101.png)'
- en: Figure 1-1\. A responsible AI Venn diagram (courtesy of Benjamin Cox and H2O.ai).
  id: totrans-32
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-1\. 一个负责任的AI Venn图（由本杰明·考克斯和H2O.ai提供）。
- en: '[Figure 1-1](#fig_1_a_responsible_ai_venn_diagram_figure_courtesy_of) claims
    that responsible AI is the combination of:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1-1](#fig_1_a_responsible_ai_venn_diagram_figure_courtesy_of) 声称，负责任的AI是以下几个方面的结合：'
- en: Ethical AI
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 道德人工智能
- en: Sociological fairness in ML predictions (i.e., whether one category of person
    is being weighed unequally or unfavorably)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ML预测中的社会公平性（即某一类别的人是否被不平等或不利地权衡）
- en: Explainable AI
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释人工智能
- en: The ability to explain a model after it has been developed
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 开发后能解释模型的能力
- en: Human-centered machine learning
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以人为中心的机器学习
- en: Meaningful user interactions with AI and ML systems
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 与AI和ML系统的有意义用户交互
- en: Interpretable machine learning
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释的机器学习
- en: Transparent model architectures and increasing how intuitive and comprehensible
    ML models can be
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 透明的模型架构以及提高ML模型直观性和可理解性的方式
- en: Secure AI
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 安全的人工智能
- en: Debugging and deploying ML models with similar counter measures against insider
    and cyber threats, as seen in traditional software
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统软件类似的内部和网络威胁的ML模型调试和部署对策
- en: Compliance
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 合规性
- en: Aligning your ML systems with leading compliance guidance such as the EU GDPR,
    the Equal Credit Opportunity Act (ECOA), or the US Federal Reserve’s SR 11-7 guidance
    on model governance
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 将您的ML系统与领先的合规指南（如欧盟GDPR、平等信贷机会法案（ECOA）或美国联邦储备委员会的SR 11-7模型治理指导）对齐
- en: In the next section, a more technical definition is presented as a workflow
    in [Figure 1-2](#fig_2_a_responsible_machine_learning_workflow_diagram_a) and
    adapted from the recent paper, [*A Responsible Machine Learning Workflow with
    Focus on Interpretable Models, Post-hoc Explanation, and Discrimination Testing.*](https://oreil.ly/-6fXG)
    It specifically addresses details of Responsible ML.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，以一种更为技术的定义作为[图 1-2](#fig_2_a_responsible_machine_learning_workflow_diagram_a)
    中的工作流程呈现，并从最近的论文[*A Responsible Machine Learning Workflow with Focus on Interpretable
    Models, Post-hoc Explanation, and Discrimination Testing.*](https://oreil.ly/-6fXG)进行了调整。它专门详述了负责任的ML的细节。
- en: A Responsible Machine Learning Definition
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负责任的机器学习定义
- en: Most AI in the world today is likely based on ML. In trying to be as careful
    and realistic as possible, the [Figure 1-2](#fig_2_a_responsible_machine_learning_workflow_diagram_a)
    workflow is designed specifically for today’s ML systems. It walks practitioners
    through the processes required to mitigate many known risks associated with ML.
    In addition to traditional ML workflow steps, this diagram emphasizes transparency,
    human review, model end-of-life issues, and the evaluation of multiple key performance
    indicators (KPIs), including fairness, privacy, and security.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当今世界上大多数AI可能基于ML。为了尽可能谨慎和现实，[图 1-2](#fig_2_a_responsible_machine_learning_workflow_diagram_a)
    的工作流程专门设计用于当今的ML系统。它指导从业者执行减少与ML相关的许多已知风险所需的流程。除了传统的ML工作流步骤外，该图强调透明度、人工审查、模型寿命问题以及评估多个关键绩效指标（KPI），包括公平性、隐私和安全性。
- en: The many other available definitions for responsible AI and ML touch on a wide
    variety of topics, including everything from environmental impact to future unemployment.
    Common themes running through most definitions include human consideration and
    review of risks, enabling effective human interaction with ML systems, enhanced
    transparency and the treatment of discrimination, privacy harms, and security
    vulnerabilities. Notably, both the *Responsible Machine Learning Workflow* paper
    and the Venn diagram in [Figure 1-1](#fig_1_a_responsible_ai_venn_diagram_figure_courtesy_of),
    bring compliance and legality into the fold of responsible ML. Based on our experience
    as industry practitioners, we find that regulation and law can provide some of
    the clearest guidance for difficult ethical problems that arise in the implementation
    of ML systems. Moreover, legality is often the bottom-line concern for many high-stakes
    applications of ML. Compliance, legality, and regulation for ML, and several other
    concepts presented in the responsible AI and ML definitions will be discussed
    in the following chapters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于负责任的人工智能（AI）和机器学习（ML），有许多其他可用的定义涉及广泛的主题，包括从环境影响到未来失业等各种议题。大多数定义中共同的主题包括对风险的人类考虑和审查，使人类能有效地与ML系统进行交互，增强透明度以及对歧视、隐私损害和安全漏洞的处理。特别值得注意的是，《负责任的机器学习工作流程》论文和[图 1-1](ch01.xhtml#idm46137004684600-marker)中的Venn图，将合规性和法律性纳入负责任的ML范畴。根据我们作为行业从业者的经验，我们发现法规和法律可以为在ML系统实施过程中出现的困难伦理问题提供一些最清晰的指导。此外，法律性通常是许多高风险ML应用的底线关注点。ML的合规性、法律性和法规，以及负责任的AI和ML定义中提出的其他几个概念，将在以下章节中讨论。
- en: '![A responsible machine learning workflow diagram. Adapted with permission
    of the authors.](Images/reml_0102.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![一个负责任的机器学习工作流程图。根据作者许可改编。](Images/reml_0102.png)'
- en: Figure 1-2\. A responsible machine learning workflow diagram (adapted with permission
    of the authors).
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-2\. 一个负责任的机器学习工作流程图（根据作者许可改编）。
- en: ^([1](ch01.xhtml#idm46137004684600-marker)) See also [*https://oreil.ly/9hzwC*](https://oreil.ly/9hzwC),
    [*https://oreil.ly/hFjRY*](https://oreil.ly/hFjRY), and [*https://oreil.ly/2T8Kt*](https://oreil.ly/JPGpV).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.xhtml#idm46137004684600-marker)) 另请参见[*https://oreil.ly/9hzwC*](https://oreil.ly/9hzwC)，[*https://oreil.ly/hFjRY*](https://oreil.ly/hFjRY)和[*https://oreil.ly/2T8Kt*](https://oreil.ly/JPGpV)。
