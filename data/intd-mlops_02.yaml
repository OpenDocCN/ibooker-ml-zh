- en: Chapter 1\. Why Now and Challenges
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章\. 为何现在及挑战
- en: Machine learning operations (MLOps) is quickly becoming a critical component
    of successful data science project deployment in the enterprise ([Figure 1-1](#the_exponential_growth_of_mlopsdot_this)).
    It’s a process that helps organizations and business leaders generate long-term
    value and reduce risk associated with data science, machine learning, and AI initiatives.
    Yet it’s a relatively new concept; so why has it seemingly skyrocketed into the
    data science lexicon overnight? This introductory chapter delves into what MLOps
    is at a high level, its challenges, why it has become essential to a successful
    data science strategy in the enterprise, and, critically, why it is coming to
    the forefront now.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习运维（MLOps）迅速成为企业中成功部署数据科学项目的关键组成部分 ([图 1-1](#the_exponential_growth_of_mlopsdot_this))。这是一个帮助组织和业务领导者产生长期价值并降低与数据科学、机器学习和人工智能倡议相关风险的过程。然而，这是一个相对较新的概念；那么为什么它似乎一夜之间飙升到数据科学词汇中呢？本章介绍MLOps在高层次上的概述，它的挑战，为何它对企业成功的数据科学战略至关重要，以及为何现在成为前沿。
- en: '![](assets/imlo_0101.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/imlo_0101.png)'
- en: Figure 1-1\. Representation of the exponential growth of MLOps (not the parallel
    growth of the term “ModelOps”)
  id: totrans-3
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-1\. MLOps指数增长的表现（而非“模型运维”术语的平行增长）
- en: Defining MLOps and Its Challenges
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义MLOps及其挑战
- en: At its core, MLOps is the standardization and streamlining of machine learning
    life cycle management ([Figure 1-2](#a_simple_representation_of_the_machine)).
    But taking a step back, why does the machine learning life cycle need to be streamlined?
    On the surface, just looking at the steps to go from business problem to a machine
    learning model at a very high level, it seems straightforward.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps 的核心是标准化和优化机器学习生命周期管理（[图 1-2](#a_simple_representation_of_the_machine)）。但退一步想，为什么需要优化机器学习生命周期呢？从表面上看，仅仅从业务问题到机器学习模型的步骤在非常高的层面上似乎是直观的。
- en: For most traditional organizations, the development of multiple machine learning
    models and their deployment in a production environment are relatively new. Until
    recently, the number of models may have been manageable at a small scale, or there
    was simply less interest in understanding these models and their dependencies
    at a company-wide level. With decision automation (that is, an increasing prevalence
    of decision making that happens without human intervention), models become more
    critical, and, in parallel, managing model risks becomes more important at the
    top level.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数传统组织而言，多个机器学习模型的开发和在生产环境中的部署相对较新。直到最近，模型数量可能在小规模范围内是可管理的，或者公司范围内对了解这些模型及其依赖关系的兴趣很少。随着决策自动化的增加（即决策在没有人类干预的情况下进行的增加），模型变得更加关键，与此同时，在公司层面管理模型风险变得更加重要。
- en: The reality of the machine learning life cycle in an enterprise setting is much
    more complex, in terms of needs and tooling ([Figure 1-3](#the_realistic_picture_of_a_machine_lear)).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业设置中，机器学习生命周期的现实要复杂得多，涉及需求和工具的复杂性 ([图 1-3](#the_realistic_picture_of_a_machine_lear))。
- en: '![](assets/imlo_0102.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/imlo_0102.png)'
- en: Figure 1-2\. A simple representation of the machine learning model life cycle,
    which often underplays the need for MLOps, compared to [Figure 1-3](#the_realistic_picture_of_a_machine_lear)
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-2\. 机器学习模型生命周期的简单表示，通常低估了与[图 1-3](#the_realistic_picture_of_a_machine_lear)相比MLOps的需求。
- en: 'There are three key reasons that managing machine learning life cycles at scale
    is challenging:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 管理大规模机器学习生命周期面临三个主要挑战的原因有三点：
- en: There are many dependencies. Not only is data constantly changing, but business
    needs shift as well. Results need to be continually relayed back to the business
    to ensure that the reality of the model in production and on production data aligns
    with expectations and, critically, addresses the original problem or meets the
    original goal.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在许多依赖关系。数据不仅在不断变化，业务需求也在变化。必须持续向业务反馈结果，以确保生产环境中的模型现实与生产数据的预期一致，并且至关重要地解决原始问题或实现原始目标。
- en: Not everyone speaks the same language. Even though the machine learning life
    cycle involves people from the business, data science, and IT teams, none of these
    groups are using the same tools or even, in many cases, share the same fundamental
    skills to serve as a baseline of communication.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非每个人都说同样的语言。尽管机器学习生命周期涉及来自业务、数据科学和IT团队的人员，但这些群体没有人使用相同的工具，甚至在许多情况下，也没有分享相同的基本技能以作为沟通的基础。
- en: Data scientists are not software engineers. Most are specialized in model building
    and assessment, and they are not necessarily experts in writing applications.
    Though this may start to shift over time as some data scientists become specialists
    more on the deployment or operational side, for now many data scientists find
    themselves having to juggle many roles, making it challenging to do any of them
    thoroughly. Data scientists being stretched too thin becomes especially problematic
    at scale with increasingly more models to manage. The complexity becomes exponential
    when considering the turnover of staff on data teams and, suddenly, data scientists
    have to manage models they did not create.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家不是软件工程师。大多数人专注于模型构建和评估，并不一定擅长编写应用程序。虽然随着一些数据科学家逐渐成为部署或运营方面的专家，这种情况可能会发生变化，但目前许多数据科学家发现自己不得不承担许多角色，这让他们难以彻底完成任何一项工作。当需要管理越来越多的模型时，数据科学家的压力会随着规模的扩大而变得尤为棘手。考虑到数据团队人员的流动性，数据科学家突然间不得不管理他们没有创建的模型，这种复杂性变得非常庞杂。
- en: '![](assets/imlo_0103.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/imlo_0103.png)'
- en: Figure 1-3\. The realistic picture of a machine learning model life cycle inside
    an average organization today, which involves many different people with completely
    different skill sets and who are often using entirely different tools.
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3。今天平均组织内的机器学习模型生命周期的现实图景，其中涉及许多拥有完全不同技能集的人，他们通常使用完全不同的工具。
- en: 'If the definition (or even the name MLOps) sounds familiar, that’s because
    it pulls heavily from the concept of DevOps, which streamlines the practice of
    software changes and updates. Indeed, the two have quite a bit in common. For
    example, they both center around:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果定义（或者甚至是名称MLOps）听起来很熟悉，那是因为它很大程度上借鉴了DevOps的概念，它简化了软件变更和更新的实践。事实上，这两者有很多共同点。例如，它们都围绕着：
- en: Robust automation and trust between teams
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 坚固的自动化和团队之间的信任
- en: The idea of collaboration and increased communication between teams
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协作和团队间增加的沟通概念
- en: The end-to-end service life cycle (build, test, release)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端到端的服务生命周期（构建、测试、发布）
- en: Prioritizing continuous delivery and high quality
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优先考虑持续交付和高质量
- en: 'Yet there is one critical difference between MLOps and DevOps that makes the
    latter not immediately transferable to data science teams: deploying software
    code into production is fundamentally different than deploying machine learning
    models into production. While software code is relatively static (“relatively”
    because many modern software-as-a-service [SaaS] companies *do* have DevOps teams
    that can iterate quite quickly and deploy in production multiple times per day),
    data is always changing, which means machine learning models are constantly learning
    and adapting—or not, as the case may be—to new inputs. The complexity of this
    environment, including the fact that machine learning models are made up of both
    code and data, is what makes MLOps a new and unique discipline.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，MLOps与DevOps之间有一个关键差异，使得后者不能立即转移到数据科学团队：将软件代码部署到生产环境与将机器学习模型部署到生产环境根本是两回事。尽管软件代码相对静态（“相对”是因为许多现代软件即服务
    [SaaS] 公司确实有DevOps团队，可以很快迭代并多次每天在生产环境中部署），但数据始终在变化，这意味着机器学习模型在不断学习和适应——或者不适应，这取决于情况——新的输入。这种环境的复杂性，包括机器学习模型由代码和数据组成的事实，使MLOps成为一门新颖和独特的学科。
- en: 'As was the case with DevOps and later DataOps, until recently teams have been
    able to get by without defined and centralized processes mostly because—at an
    enterprise level—they weren’t deploying machine learning models into production
    at a large enough scale. Now, the tables are turning and teams are increasingly
    looking for ways to formalize a multi-stage, multi-discipline, multi-phase process
    with a heterogeneous environment and a framework for MLOps best practices, which
    is no small task. [Part II](part02.html#mlops_how) of this book, “MLOps: How,”
    will provide this guidance.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 就像DevOps和后来的DataOps一样，直到最近，团队们大多数时候可以在没有定义和集中化流程的情况下进行。因为在企业级别，他们没有将机器学习模型部署到足够大规模的生产环境中。现在，情况已经发生了变化，团队们越来越寻求方法来规范多阶段、多学科、多阶段过程，以及具有异构环境和MLOps最佳实践框架，这绝非易事。本书的[第二部分](part02.html#mlops_how)，“MLOps：如何”，将提供这一指导。
- en: MLOps to Mitigate Risk
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps 以缓解风险
- en: MLOps is important to any team that has even one model in production because,
    depending on the model, continuous performance monitoring and adjusting is essential.
    By allowing safe and reliable operations, MLOps is key in mitigating the risks
    induced by the use of ML models. However, MLOps practices do come at a cost, so
    a proper cost-benefit evaluation should be performed for each use case.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何一个在生产中有模型的团队来说，MLOps 都非常重要，因为根据模型的不同，持续的性能监控和调整至关重要。通过确保安全和可靠的运行，MLOps 是减少使用ML模型引发的风险的关键。然而，MLOps
    实践确实会有成本，因此应该为每个用例进行适当的成本效益评估。
- en: Risk Assessment
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 风险评估
- en: 'When it comes to machine learning models, risks vary widely. For example, the
    stakes are much lower for a recommendation engine used once a month to decide
    which marketing offer to send a customer than for a travel site whose pricing
    and revenue depend on a machine learning model. Therefore, when looking at MLOps
    as a way to mitigate risk, an analysis should cover:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到机器学习模型时，风险变化很大。例如，对于一个每月仅用于决定向客户发送哪些营销优惠的推荐引擎，风险要低得多，而对于一个旅行网站，其定价和收入依赖于机器学习模型，则风险要高得多。因此，在将MLOps视为减少风险的一种方式时，分析应该包括以下内容：
- en: The risk that the model is unavailable for a given period of time
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型在某一段时间内不可用的风险
- en: The risk that the model returns a bad prediction for a given sample
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型在给定样本上返回错误预测的风险
- en: The risk that the model accuracy or fairness decreases over time
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型准确性或公平性随时间下降的风险
- en: The risk that the skills necessary to maintain the model (i.e., data science
    talent) are lost
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护模型所需技能（即数据科学人才）流失的风险
- en: 'Risks are usually larger for models that are deployed widely and used outside
    of the organization. As shown in [Figure 1-4](#a_table_that_helps_decision_makers_with),
    risk assessment is generally based on two metrics: the probability and the impact
    of the adverse event. Mitigation measures are generally based on the combination
    of the two, i.e., the model’s severity. Risk assessment should be performed at
    the beginning of each project and reassessed periodically, as models may be used
    in ways that were not foreseen initially.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 针对广泛部署并且在组织外使用的模型，通常风险较大。如[图1-4](#a_table_that_helps_decision_makers_with)，风险评估通常基于两个指标：不良事件的概率和影响。缓解措施通常基于两者的组合，即模型的严重性。风险评估应在每个项目开始时进行，并定期重新评估，因为模型可能以未预见的方式使用。
- en: '![](assets/imlo_0104.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/imlo_0104.png)'
- en: Figure 1-4\. A table that helps decision makers with quantitative risk analysis
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. 一张表格，帮助决策者进行定量风险分析
- en: Risk Mitigation
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 风险缓解
- en: MLOps really tips the scales as critical for risk mitigation when a centralized
    team (with unique reporting of its activities, meaning that there can be multiple
    such teams at any given enterprise) has more than a handful of operational models.
    At this point, it becomes difficult to have a global view of the states of these
    models without the standardization that allows the appropriate mitigation measures
    to be taken for each of them (see [“Matching Governance with Risk Level”](ch08.html#matching_governance_with_risk_level)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps 在风险缓解方面真正发挥了关键作用，特别是当一个集中化团队（其活动有独特的报告方式，这意味着在任何给定企业中可能存在多个这样的团队）拥有超过少数运行模型时。此时，如果没有标准化，很难全面了解这些模型的状态，而这种标准化可以采取适当的缓解措施来处理每一个模型（参见[“匹配治理与风险水平”](ch08.html#matching_governance_with_risk_level)）。
- en: Pushing machine learning models into production without MLOps infrastructure
    is risky for many reasons, but first and foremost because fully assessing the
    performance of a machine learning model can often only be done in the production
    environment. Why? Because prediction models are only as good as the data they
    are trained on, which means the training data must be a good reflection of the
    data encountered in the production environment. If the production environment
    changes, then the model performance is likely to decrease rapidly (see [Chapter 5](ch05.html#preparing_for_production)
    for details).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有 MLOps 基础设施的情况下将机器学习模型推入生产环境存在许多风险，首要的原因是因为完全评估机器学习模型的性能通常只能在生产环境中完成。为什么？因为预测模型的表现只能和它们训练所用的数据一样好，这意味着训练数据必须很好地反映在生产环境中遇到的数据。如果生产环境发生变化，那么模型的性能可能会迅速下降（详情请参见[第5章](ch05.html#preparing_for_production)）。
- en: Another major risk factor is that machine learning model performance is often
    very sensitive to the production environment it is running in, including the versions
    of software and operating systems in use. They tend not to be buggy in the classic
    software sense, because most weren’t written by hand, but rather were machine-generated.
    Instead, the problem is that they are often built on a pile of open source software
    (e.g., libraries, like scikit-learn, Python, or Linux), and having versions of
    this software in production that match those that the model was verified on is
    critically important.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个主要的风险因素是机器学习模型的性能通常对其运行的生产环境非常敏感，包括正在使用的软件和操作系统的版本。它们不太可能以经典软件意义上的错误为特征，因为大多数不是手工编写的，而是机器生成的。问题在于它们通常是构建在一堆开源软件之上（例如，像scikit-learn、Python或Linux这样的库），因此在生产环境中使用与验证模型时相匹配的这些软件版本非常重要。
- en: Ultimately, pushing models into production is not the final step of the machine
    learning life cycle—far from it. It’s often just the beginning of monitoring its
    performance and ensuring that it behaves as expected. As more data scientists
    start pushing more machine learning models into production, MLOps becomes critical
    in mitigating the potential risks, which (depending on the model) can be devastating
    for the business if things go wrong. Monitoring is also essential so that the
    organization has a precise knowledge of how broadly each model is used.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 推动模型投入生产并不是机器学习生命周期的最终步骤——远非如此。通常这只是开始监控其性能并确保其按预期行事的开端。随着越来越多的数据科学家开始将更多的机器学习模型推入生产环境，MLOps
    在减轻潜在风险方面变得至关重要，如果出现问题，这些风险（取决于模型）可能对业务造成灾难性影响。监控同样至关重要，以便组织准确了解每个模型的广泛使用情况。
- en: MLOps for Responsible AI
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负责任的AI运营
- en: 'A responsible use of machine learning (more commonly referred to as Responsible
    AI) covers two main dimensions:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的负责任使用（更常被称为负责任AI）涵盖两个主要方面：
- en: Intentionality
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 故意性
- en: Ensuring that models are designed and behave in ways aligned with their purpose.
    This includes assurance that data used for AI projects comes from compliant and
    unbiased sources plus a collaborative approach to AI projects that ensures multiple
    checks and balances on potential model bias. Intentionality also includes explainability,
    meaning the results of AI systems should be explainable by humans (ideally, not
    just the humans who created the system).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 确保模型设计和行为与其目的一致。这包括确保用于人工智能项目的数据来自符合法规且无偏见的来源，以及在AI项目中采用协作方法，确保对潜在模型偏差进行多重检查和平衡。故意性还包括可解释性，即AI系统的结果应该可以由人类解释（理想情况下，不仅仅是创建系统的人类）。
- en: Accountability
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 责任制
- en: 'Centrally controlling, managing, and auditing the enterprise AI effort—[no
    shadow IT](https://oreil.ly/2k0G2)! Accountability is about having an overall
    view of which teams are using what data, how, and in which models. It also includes
    the need for trust that data is reliable and being collected in accordance with
    regulations as well as a centralized understanding of which models are used for
    what business processes. This is closely tied to traceability: if something goes
    wrong, is it easy to find where in the pipeline it happened?'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 集中控制、管理和审计企业AI工作——[无阴影IT](https://oreil.ly/2k0G2)！责任制是关于全面了解哪些团队正在使用什么数据、如何使用以及在哪些模型中使用的整体视角。它还包括对数据可靠性的信任以及根据法规收集数据的需要，以及对用于哪些业务流程的模型的集中了解。这与可追溯性密切相关：如果出现问题，很容易找到出问题的管道的位置。
- en: These principles may seem obvious, but it’s important to consider that machine
    learning models lack the transparency of traditional imperative code. In other
    words, it is much harder to understand what features are used to determine a prediction,
    which in turn can make it much harder to demonstrate that models comply with the
    necessary regulatory or internal governance requirements.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些原则可能显而易见，但重要的是要考虑到机器学习模型缺乏传统命令式代码的透明度。换句话说，很难理解用于确定预测的特征是什么，这反过来又会使得很难证明模型符合必要的监管或内部治理要求。
- en: The reality is that introducing automation vis-à-vis machine learning models
    shifts the fundamental onus of accountability from the bottom of the hierarchy
    to the top. That is, decisions that were perhaps previously made by individual
    contributors who operated within a margin of guidelines (for example, what the
    price of a given product should be or whether or not a person should be accepted
    for a loan) are now being made by a model. The person responsible for the automated
    decisions of said model is likely a data team manager or even executive, and that
    brings the concept of Responsible AI even more to the forefront.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，通过引入自动化与机器学习模型相比，将责任的基本重点从层次结构的底部转移到顶部。也就是说，以前由个体贡献者在一定指导原则下（例如，一个给定产品的价格应该是多少，或者是否应该接受一个人的贷款申请）可能做出的决策，现在是由模型做出的。对于该模型的自动化决策负责的人可能是数据团队经理甚至是高管，这更加突显了负责任的AI的概念。
- en: Given the previously discussed risks as well as these particular challenges
    and principles, it’s easy to see the interplay between MLOps and Responsible AI.
    Teams must have good MLOps principles to practice Responsible AI, and Responsible
    AI necessitates MLOps strategies. Given the gravity of this topic, we’ll come
    back to it multiple times throughout this book, examining how it should be addressed
    at each stage of the ML model life cycle.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于前面讨论的风险以及这些特定的挑战和原则，可以很容易地看出MLOps与负责任的AI之间的相互作用。团队必须有良好的MLOps原则来实践负责任的AI，而负责任的AI则需要MLOps策略。考虑到这个话题的重要性，我们将在本书的多个阶段回顾它，探讨如何在ML模型的生命周期的每个阶段都要解决这个问题。
- en: MLOps for Scale
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps的规模化
- en: MLOps isn’t just important because it helps mitigate the risk of machine learning
    models in production; it is also an essential component to massively deploying
    machine learning efforts (and in turn benefiting from the corresponding economies
    of scale). Going from one or a handful of models in production to tens, hundreds,
    or thousands that have a positive business impact requires MLOps discipline.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps之所以重要不仅因为它有助于减少生产中机器学习模型的风险，而且它也是大规模部署机器学习工作的重要组成部分（从而从相应的规模经济中受益）。从生产中的一个或少数几个模型到对业务有积极影响的数十、数百甚至数千个模型的过渡，都需要MLOps的纪律。
- en: 'Good MLOps practices will help teams at a minimum:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的MLOps实践至少会帮助团队：
- en: Keep track of versioning, especially with experiments in the design phase
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特别是在设计阶段进行实验时，要跟踪版本控制
- en: Understand whether retrained models are better than the previous versions (and
    promoting models to production that are performing better)
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解重新训练的模型是否优于之前的版本（并推广性能更好的模型到生产环境）
- en: Ensure (at defined periods—daily, monthly, etc.) that model performance is not
    degrading in production
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保（在每天、每月等定义的周期内）模型在生产中的性能没有下降
- en: Closing Thoughts
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结语
- en: Key features will be discussed at length in [Chapter 3](ch03.html#key_mlops_features),
    but the point here is that these are not optional practices. They are essential
    tasks for not only efficiently scaling data science and machine learning at the
    enterprise level, but also doing it in a way that doesn’t put the business at
    risk. Teams that attempt to deploy data science without proper MLOps practices
    in place will face issues with model quality and continuity—or, worse, they will
    introduce models that have a real, negative impact on the business (e.g., a model
    that makes biased predictions that reflect poorly on the company).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第三章](ch03.html#key_mlops_features)中将详细讨论关键特性，但这里要指出的是，这些不是可选的实践。它们是不仅有效地在企业级别扩展数据科学和机器学习的基础上，而且以不会给企业带来风险的方式进行的基本任务。试图在没有适当的MLOps实践的情况下部署数据科学的团队将面临模型质量和连续性的问题，甚至更糟的是，他们将引入对公司影响不利的真实负面影响的模型（例如，偏见预测）。
- en: MLOps is also, at a higher level, a critical part of transparent strategies
    for machine learning. Upper management and the C-suite should be able to understand
    as well as data scientists what machine learning models are deployed in production
    and what effect they’re having on the business. Beyond that, they should arguably
    be able to drill down to understand the whole data pipeline (i.e., the steps taken
    to go from raw data to final output) behind those machine learning models. MLOps,
    as described in this book, can provide this level of transparency and accountability.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps 在更高层次上，也是机器学习透明策略的关键部分。高层管理和C级管理人员应该能够像数据科学家一样理解哪些机器学习模型被部署到生产环境中，以及它们对业务的影响。除此之外，他们可能还应该能够深入了解支持这些机器学习模型的整个数据流水线（即从原始数据到最终输出的步骤）。本书描述的MLOps能够提供这种透明度和责任感。
