- en: Chapter 1\. Introduction to TensorFlow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 介绍 TensorFlow
- en: When it comes to creating artificial intelligence (AI), machine learning (ML)
    and deep learning are a great place to begin. When getting started, however, it’s
    easy to get overwhelmed by the options and all the new terminology. This book
    aims to demystify things for programmers, taking you through writing code to implement
    concepts of machine learning and deep learning; and building models that behave
    more as a human does, with scenarios like computer vision, natural language processing
    (NLP), and more. Thus, they become a form of synthesized, or artificial, intelligence.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建人工智能(AI)，机器学习(ML)和深度学习是一个很好的起点。然而，当开始时，很容易被各种选项和新术语所淹没。本书旨在为程序员揭开神秘面纱，带您编写代码来实现机器学习和深度学习的概念，并构建更像人类行为的模型，例如计算机视觉、自然语言处理（NLP）等场景。因此，它们成为一种合成的或人工的智能形式。
- en: But when we refer to *machine learning*, what in fact is this phenomenon? Let’s
    take a quick look at that, and consider it from a programmer’s perspective before
    we go any further. After that, this chapter will show you how to install the tools
    of the trade, from TensorFlow itself to environments where you can code and debug
    your TensorFlow models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 但是当我们提到*机器学习*时，实际上指的是什么现象呢？让我们快速看看这个，从程序员的角度来考虑，在我们进一步深入之前。在此之后，本章将向您展示如何安装行业工具，从TensorFlow本身到您可以编写和调试TensorFlow模型的环境。
- en: What Is Machine Learning?
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: Before we get into the ins and outs of ML, let’s consider how it evolved from
    traditional programming. We’ll start by examining what traditional programming
    is, then consider cases where it is limited. Then we’ll see how ML evolved to
    handle those cases, and as a result has opened up new opportunities to implement
    new scenarios, unlocking many of the concepts of artificial intelligence.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨机器学习的方方面面之前，让我们考虑它是如何从传统编程中演变而来的。我们将从研究传统编程的定义开始，然后考虑它存在局限的情况。接着我们将看到机器学习是如何演进来应对这些情况的，从而开启了实现新场景的新机会，并解锁了人工智能的许多概念。
- en: Traditional programming involves us writing rules, expressed in a programming
    language, that act on data and give us answers. This applies just about everywhere
    that something can be programmed with code.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 传统编程涉及我们编写规则，用编程语言表达，作用于数据并给出答案。这几乎适用于任何可以用代码编程的地方。
- en: For example, consider a game like the popular Breakout. Code determines the
    movement of the ball, the score, and the various conditions for winning or losing
    the game. Think about the scenario where the ball bounces off a brick, like in
    [Figure 1-1](#code_in_a_breakout_game).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑像流行的打砖块游戏一样的游戏。代码确定球的运动、得分以及各种赢得或输掉游戏的条件。想象一下球撞击砖块的情景，就像[图1-1](#code_in_a_breakout_game)中的代码一样。
- en: '![Code in a Breakout game](Images/aiml_0101.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![打砖块游戏中的代码](Images/aiml_0101.png)'
- en: Figure 1-1\. Code in a Breakout game
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1 打砖块游戏中的代码
- en: Here, the motion of the ball can be determined by its `dx` and `dy` properties.
    When it hits a brick, the brick is removed, and the velocity of the ball increases
    and changes direction. The code acts on data about the game situation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，球的运动可以由其`dx`和`dy`属性决定。当它撞击到砖块时，砖块被移除，球的速度增加并改变方向。代码作用于游戏情况的数据。
- en: Alternatively, consider a financial services scenario. You have data about a
    company’s stock, such as its current price and current earnings. You can calculate
    a valuable ratio called the P/E (for price divided by earnings) with code like
    that in [Figure 1-2](#code_in_a_financial_services_scenario).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 或者考虑一个金融服务场景。你有关于公司股票的数据，比如当前价格和当前收益。你可以用类似于[图1-2](#code_in_a_financial_services_scenario)中的代码来计算一个有价值的比率，称为P/E（即价格除以收益）。
- en: '![Code in a financial services scenario](Images/aiml_0102.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![金融服务场景中的代码](Images/aiml_0102.png)'
- en: Figure 1-2\. Code in a financial services scenario
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2 金融服务场景中的代码
- en: Your code reads the price, reads the earnings, and returns a value that is the
    former divided by the latter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你的代码读取价格，读取收益，并返回前者除以后者的值。
- en: If I were to try to sum up traditional programming like this into a single diagram,
    it might look like [Figure 1-3](#high_level_view_of_traditional_programm).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我试图用一个单一的图表来概括传统编程，它可能看起来像[图1-3](#high_level_view_of_traditional_programm)。
- en: '![High-level view of traditional programming](Images/aiml_0103.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![传统编程的高层视图](Images/aiml_0103.png)'
- en: Figure 1-3\. High-level view of traditional programming
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3 传统编程的高层视图
- en: As you can see, you have rules expressed in a programming language. These rules
    act on data, and the result is answers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，你可以看到用编程语言表达的规则。这些规则作用于数据，结果是答案。
- en: Limitations of Traditional Programming
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统编程的局限性
- en: 'The model from [Figure 1-3](#high_level_view_of_traditional_programm) has been
    the backbone of development since its inception. But it has an inherent limitation:
    namely, that only scenarios that can be implemented are ones for which you can
    derive rules. What about other scenarios? Usually, they are infeasible to develop
    because the code is too complex. It’s just not possible to write code to handle
    them.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 自从其诞生以来，[图 1-3](#high_level_view_of_traditional_programm)的模型一直是发展的支柱。但它有一个固有的限制：只有能够推导出规则的情景才能被实施。其他情景怎么办？通常因为代码太复杂而无法开发。编写处理它们的代码是不可能的。
- en: Consider, for example, activity detection. Fitness monitors that can detect
    our activity are a recent innovation, not just because of the availability of
    cheap and small hardware, but also because the algorithms to handle detection
    weren’t previously feasible. Let’s explore why.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑活动检测。能够检测我们活动的健身监测器是一种新近的创新，不仅因为廉价和小型硬件的可用性，而且还因为处理检测的算法以前是不可行的。让我们探讨一下原因。
- en: '[Figure 1-4](#algorithm_for_activity_detection) shows a naive activity detection
    algorithm for walking. It can consider the person’s speed. If it’s less than a
    particular value, we can determine that they are probably walking.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1-4](#algorithm_for_activity_detection)展示了一个简单的步行活动检测算法。它可以考虑个人的速度。如果速度低于特定值，我们可以确定他们可能在步行。'
- en: '![Algorithm for activity detection](Images/aiml_0104.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![活动检测算法](Images/aiml_0104.png)'
- en: Figure 1-4\. Algorithm for activity detection
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-4\. 活动检测算法
- en: Given that our data is speed, we could extend this to detect if they are running
    ([Figure 1-5](#extending_the_algorithm_for_running)).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到我们的数据是速度，我们可以扩展到检测他们是否在跑步（[图 1-5](#extending_the_algorithm_for_running)）。
- en: '![Extending the algorithm for running](Images/aiml_0105.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![扩展跑步算法](Images/aiml_0105.png)'
- en: Figure 1-5\. Extending the algorithm for running
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-5\. 扩展跑步算法
- en: As you can see, going by the speed, we might say if it is less than a particular
    value (say, 4 mph) the person is walking, and otherwise they are running. It still
    sort of works.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，根据速度，如果速度低于特定值（比如说，4 英里每小时），我们可能会说这个人正在步行，否则他们在跑步。这还算有点用。
- en: Now suppose we want to extend this to another popular fitness activity, biking.
    The algorithm could look like [Figure 1-6](#extending_the_algorithm_for_biking).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们想要将其扩展到另一种流行的健身活动，骑行。算法可能类似于 [图 1-6](#extending_the_algorithm_for_biking)。
- en: '![Extending the algorithm for biking](Images/aiml_0106.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![扩展骑行算法](Images/aiml_0106.png)'
- en: Figure 1-6\. Extending the algorithm for biking
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-6\. 扩展骑行算法
- en: I know it’s naive in that it just detects speed—some people run faster than
    others, and you might run downhill faster than you cycle uphill, for example.
    But on the whole, it still works. However, what happens if we want to implement
    another scenario, such as golfing ([Figure 1-7](#how_do_we_write_a_golfing_algorithmques))?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道这个算法很幼稚，因为它只检测速度——有些人跑得比其他人快，而且你可能在下坡跑得比在上坡骑自行车快，例如。但总体来说，它仍然有效。但是，如果我们想要实现另一种情景，比如高尔夫（[图
    1-7](#how_do_we_write_a_golfing_algorithmques)）会发生什么？
- en: '![How do we write a golfing algorithm?](Images/aiml_0107.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![如何编写高尔夫算法？](Images/aiml_0107.png)'
- en: Figure 1-7\. How do we write a golfing algorithm?
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-7\. 如何编写高尔夫算法？
- en: We’re now stuck. How do we determine that someone is golfing using this methodology?
    The person might walk for a bit, stop, do some activity, walk for a bit more,
    stop, etc. But how can we tell this is golf?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在陷入困境。我们如何确定某人正在高尔夫运动？这个人可能会走一段路，停下来做一些活动，再走一段路，再停下来等等。但我们如何确定这是高尔夫？
- en: Our ability to detect this activity using traditional rules has hit a wall.
    But maybe there’s a better way.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用传统规则检测这一活动的能力已经遇到了瓶颈。但也许有更好的方法。
- en: Enter machine learning.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 进入机器学习。
- en: From Programming to Learning
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从编程到学习
- en: Let’s look back at the diagram that we used to demonstrate what traditional
    programming is ([Figure 1-8](#the_traditional_programming_flow)). Here we have
    rules that act on data and give us answers. In our activity detection scenario,
    the data was the speed at which the person was moving; from that we could write
    rules to detect their activity, be it walking, biking, or running. We hit a wall
    when it came to golfing, because we couldn’t come up with rules to determine what
    that activity looks like.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下我们用来演示传统编程的图示([图1-8](#the_traditional_programming_flow))。在这里，我们有作用于数据并给我们答案的规则。在我们的活动检测场景中，数据是该人移动的速度；从中我们可以编写规则来检测他们的活动，无论是走路、骑车还是跑步。当涉及高尔夫运动时，我们遇到了困难，因为我们无法想出规则来确定该活动的样子。
- en: '![The traditional programming flow](Images/aiml_0108.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![传统编程流程](Images/aiml_0108.png)'
- en: Figure 1-8\. The traditional programming flow
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8\. 传统编程流程
- en: But what would happen if we were to flip the axes around on this diagram? Instead
    of us coming up with the *rules*, what if we were to come up with the *answers*,
    and along with the data have a way of figuring out what the rules might be?
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果我们在这个图表上翻转轴会发生什么？如果我们不是制定*规则*，而是提供*答案*，并且在数据的基础上找到可能的规则呢？
- en: '[Figure 1-9](#changing_the_axes_to_get_machine_learni) shows what this would
    look like. We can consider this high-level diagram to define *machine learning*.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-9](#changing_the_axes_to_get_machine_learni)展示了这个样子。我们可以通过这个高级别的图表来定义*机器学习*。'
- en: '![Changing the axes to get machine learning](Images/aiml_0109.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![改变轴以获得机器学习](Images/aiml_0109.png)'
- en: Figure 1-9\. Changing the axes to get machine learning
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-9\. 改变轴以获得机器学习
- en: So what are the implications of this? Well, now instead of *us* trying to figure
    out what the rules are, we get lots of data about our scenario, we label that
    data, and the computer can figure out what the rules are that make one piece of
    data match a particular label and another piece of data match a different label.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这意味着什么呢？现在我们不再需要我们来找出规则，我们得到了有关我们场景的大量数据，我们对这些数据进行了标记，计算机可以找出使一个数据匹配特定标签、另一个数据匹配不同标签的规则。
- en: How would this work for our activity detection scenario? Well, we can look at
    all the sensors that give us data about this person. If they have a wearable that
    detects information such as heart rate, location, speed, etc.—and if we collect
    a lot of instances of this data while they’re doing different activities—we end
    up with a scenario of having data that says “This is what walking looks like,”
    “This is what running looks like,” and so on ([Figure 1-10](#from_coding_to_ml_gathering_and_labelin)).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这对于我们的活动检测场景会如何工作呢？嗯，我们可以查看所有关于此人提供数据的传感器。如果他们有一个可穿戴设备可以检测诸如心率、位置、速度等信息—并且如果我们在他们进行不同活动时收集了大量这些数据的实例—我们最终会得到一种数据描述“这是走路的样子”，“这是跑步的样子”，诸如此类
    ([图1-10](#from_coding_to_ml_gathering_and_labelin))。
- en: '![From coding to ML: gathering and labeling data](Images/aiml_0110.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![从编码到机器学习：收集和标记数据](Images/aiml_0110.png)'
- en: 'Figure 1-10\. From coding to ML: gathering and labeling data'
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10\. 从编码到机器学习：收集和标记数据
- en: Now our job as programmers changes from figuring out the rules, to determining
    the activities, to writing the code that matches the data to the labels. If we
    can do this, then we can expand the scenarios that we can implement with code.
    Machine learning is a technique that enables us to do this, but in order to get
    started, we’ll need a framework—and that’s where TensorFlow enters the picture.
    In the next section we’ll take a look at what it is and how to install it, and
    then later in this chapter you’ll write your first code that learns the pattern
    between two values, like in the preceding scenario. It’s a simple “Hello World”
    scenario, but it has the same foundational code pattern that’s used in extremely
    complex ones.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们作为程序员的工作从找出规则转变为确定活动，编写能够将数据与标签匹配的代码。如果我们能做到这一点，那么我们可以用代码实现更多的场景。机器学习是一种使我们能够做到这一点的技术，但是为了开始，我们需要一个框架—这就是TensorFlow登场的地方。在接下来的部分，我们将看看它是什么以及如何安装它，然后在本章后面的部分，您将编写第一个学习两个值之间模式的代码，就像在上一场景中一样。这是一个简单的“Hello
    World”场景，但它具有用于极为复杂的场景的相同基础代码模式。
- en: The field of artificial intelligence is large and abstract, encompassing everything
    to do with making computers think and act the way human beings do. One of the
    ways a human takes on new behaviors is through learning by example. The discipline
    of machine learning can thus be thought of as an on-ramp to the development of
    artificial intelligence. Through it, a machine can learn to see like a human (a
    field called *computer vision*), read text like a human (natural language processing),
    and much more. We’ll be covering the basics of machine learning in this book,
    using the TensorFlow framework.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能领域广泛而抽象，涵盖了使计算机思考和行动方式与人类相似的所有内容。人类采用新行为的一种方式是通过示例学习。因此，机器学习学科可以被视为发展人工智能的入口。通过它，机器可以学会像人类一样看待事物（称为*计算机视觉*领域），阅读文本（自然语言处理），以及更多。在本书中，我们将介绍使用
    TensorFlow 框架的机器学习基础知识。
- en: What Is TensorFlow?
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 TensorFlow？
- en: TensorFlow is an open source platform for creating and using machine learning
    models. It implements many of the common algorithms and patterns needed for machine
    learning, saving you from needing to learn all the underlying math and logic and
    enabling you to just to focus on your scenario. It’s aimed at everyone from hobbyists,
    to professional developers, to researchers pushing the boundaries of artificial
    intelligence. Importantly, it also supports deployment of models to the web, cloud,
    mobile, and embedded systems. We’ll be covering each of these scenarios in this
    book.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是一个用于创建和使用机器学习模型的开源平台。它实现了许多常见的机器学习算法和模式，使你不需要学习所有底层的数学和逻辑，从而能够专注于你的场景。它面向从业余爱好者、专业开发人员，以及推动人工智能边界的研究人员。重要的是，它还支持将模型部署到Web、云、移动和嵌入式系统中。本书将涵盖这些场景中的每一个。
- en: The high-level architecture of TensorFlow can be seen in [Figure 1-11](#tensorflow_high_level_architecture).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow的高级架构可以在[图1-11](#tensorflow_high_level_architecture)中看到。
- en: '![TensorFlow high-level architecture](Images/aiml_0111.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![TensorFlow高级架构](Images/aiml_0111.png)'
- en: Figure 1-11\. TensorFlow high-level architecture
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-11\. TensorFlow高级架构
- en: The process of creating machine learning models is called *training*. This is
    where a computer uses a set of algorithms to learn about inputs and what distinguishes
    them from each other. So, for example, if you want a computer to recognize cats
    and dogs, you can use lots of pictures of both to create a model, and the computer
    will use that model to try to figure out what makes a cat a cat, and what makes
    a dog a dog. Once the model is trained, the process of having it recognize or
    categorize future inputs is called *inference*.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 创建机器学习模型的过程称为*训练*。这是计算机使用一组算法来学习输入及其之间的区别的过程。例如，如果你想让计算机识别猫和狗，你可以使用大量猫和狗的图片来创建一个模型，计算机将使用该模型来尝试弄清楚是什么使得一只猫是猫，一只狗是狗。一旦模型训练好了，将其用于识别或分类未来输入的过程称为*推断*。
- en: 'So, for training models, there are several things that you need to support.
    First is a set of APIs for designing the models themselves. With TensorFlow there
    are three main ways to do this: you can code everything by hand, where you figure
    out the logic for how a computer can learn and then implement that in code (not
    recommended); you can use built-in *estimators*, which are already-implemented
    neural networks that you can customize; or you can use Keras, a high-level API
    that allows you to encapsulate common machine learning paradigms in code. This
    book will primarily focus on using the Keras APIs when creating models.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了训练模型，你需要支持几件事情。首先是一组用于设计模型本身的API。使用 TensorFlow 有三种主要方式来做到这一点：你可以手动编写所有代码，即你自己找出计算机学习的逻辑然后实现在代码中（不推荐）；你可以使用内置的*估计器*，这些是已经实现的神经网络，你可以自定义；或者你可以使用
    Keras，这是一个高级API，允许你在代码中封装常见的机器学习范例。本书主要将关注在创建模型时使用 Keras API。
- en: There are many ways to train a model. For the most part, you’ll probably just
    use a single chip, be it a central processing unit (CPU) , a graphics processing
    unit (GPU), or something new called a *tensor processing unit* (TPU). In more
    advanced working and research environments, parallel training across multiple
    chips can be used, employing a *distribution strategy* where training spans multiple
    chips. TensorFlow supports this too.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以训练模型。大多数情况下，您可能只会使用单个芯片，无论是中央处理单元（CPU）、图形处理单元（GPU）还是一种称为*张量处理单元*（TPU）的新型设备。在更高级的工作和研究环境中，可以使用跨多个芯片的并行训练，使用*分布策略*跨多个芯片进行训练。TensorFlow也支持这种方式。
- en: The lifeblood of any model is its data. As discussed earlier, if you want to
    create a model that can recognize cats and dogs, it needs to be trained with lots
    of examples of cats and dogs. But how can you manage these examples? You’ll see,
    over time, that this can often involve a lot more coding than the creation of
    the models themselves. TensorFlow ships with APIs to try to ease this process,
    called TensorFlow Data Services. For learning, they include lots of preprocessed
    datasets that you can use with a single line of code. They also give you the tools
    for processing raw data to make it easier to use.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 任何模型的生命线是其数据。正如之前讨论的那样，如果您想创建一个能够识别猫和狗的模型，它需要使用大量猫和狗的示例进行训练。但是您如何管理这些示例呢？随着时间的推移，您会发现，这往往比模型本身的创建需要更多的编码工作。TensorFlow提供了API来尝试简化这个过程，称为TensorFlow数据服务。为了学习，它们包括许多预处理的数据集，您可以用一行代码就可以使用。它们还为您提供处理原始数据以便更容易使用的工具。
- en: Beyond creating models, you’ll also need to be able to get them into people’s
    hands where they can be used. To this end, TensorFlow includes APIs for *serving*,
    where you can provide model inference over an HTTP connection for cloud or web
    users. For models to run on mobile or embedded systems, there’s TensorFlow Lite,
    which provides tools for model inference on Android and iOS as well as Linux-based
    embedded systems such as a Raspberry Pi. A fork of TensorFlow Lite, called TensorFlow
    Lite Micro (TFLM), also provides inference on microcontrollers through an emerging
    concept known as TinyML. Finally, if you want to provide models to your browser
    or Node.js users, TensorFlow.js offers the ability to train and execute models
    in this way.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 除了创建模型外，您还需要能够将它们交给用户使用。为此，TensorFlow包含了用于*服务*的API，您可以通过HTTP连接为云或Web用户提供模型推断。为了在移动设备或嵌入式系统上运行模型，TensorFlow提供了TensorFlow
    Lite，该工具支持在Android和iOS上以及基于Linux的嵌入式系统（如树莓派）上进行模型推断。TensorFlow Lite的一个分支称为TensorFlow
    Lite Micro（TFLM），也提供了对微控制器的推断，通过一个名为TinyML的新兴概念。最后，如果您想为浏览器或Node.js用户提供模型，TensorFlow.js可以训练和执行模型。
- en: Next, I’ll show you how to install TensorFlow so that you can get started creating
    and using ML models with it.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将向你展示如何安装TensorFlow，以便您可以开始创建和使用ML模型。
- en: Using TensorFlow
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow
- en: In this section, we’ll look at the three main ways that you can install and
    use TensorFlow. We’ll start with how to install it on your developer box using
    the command line. We’ll then explore using the popular PyCharm IDE (integrated
    development environment) to install TensorFlow. Finally, we’ll look at Google
    Colab and how it can be used to access TensorFlow code with a cloud-based backend
    in your browser.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍三种主要的安装和使用TensorFlow的方法。首先，我们将讲解如何在开发者框中使用命令行安装它。然后，我们将探讨如何使用流行的PyCharm集成开发环境（IDE）安装TensorFlow。最后，我们将看看Google
    Colab以及如何在浏览器中使用基于云的后端访问TensorFlow代码。
- en: Installing TensorFlow in Python
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Python中安装TensorFlow
- en: TensorFlow supports the creation of models using multiple languages, including
    Python, Swift, Java, and more. In this book we’ll focus on using Python, which
    is the de facto language for machine learning due to its extensive support for
    mathematical models. If you don’t have it already, I strongly recommend you visit
    [Python](https://www.python.org) to get up and running with it, and [learnpython.org](https://www.learnpython.org)
    to learn the Python language syntax.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow支持使用多种语言创建模型，包括Python、Swift、Java等。在本书中，我们将专注于使用Python，因为它由于对数学模型的广泛支持而成为机器学习的事实标准语言。如果您还没有Python，我强烈建议您访问[Python](https://www.python.org)来快速上手，以及[learnpython.org](https://www.learnpython.org)来学习Python语法。
- en: With Python there are many ways to install frameworks, but the default one supported
    by the TensorFlow team is `pip`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Python，有许多安装框架的方法，但TensorFlow团队支持的默认方法是使用`pip`。
- en: 'So, in your Python environment, installing TensorFlow is as easy as using:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在您的 Python 环境中，安装 TensorFlow 就像使用以下命令一样简单：
- en: '[PRE0]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that starting with version 2.1, this will install the GPU version of TensorFlow
    by default. Prior to that, it used the CPU version. So, before installing, make
    sure you have a supported GPU and all the requisite drivers for it. Details on
    this are available at [TensorFlow](https://oreil.ly/5upaL).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，从 2.1 版本开始，默认安装 TensorFlow 的是 GPU 版本。在此之前，使用的是 CPU 版本。因此，在安装之前，请确保您有一个支持的
    GPU 和所有必需的驱动程序。有关详细信息，请参阅[TensorFlow](https://oreil.ly/5upaL)。
- en: 'If you don’t have the required GPU or drivers, you can still install the CPU
    version of TensorFlow on any Linux, PC, or Mac with:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有所需的 GPU 或驱动程序，仍然可以在任何 Linux、PC 或 Mac 上安装 TensorFlow 的 CPU 版本：
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once you’re up and running, you can test your TensorFlow version with the following
    code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您开始运行，可以使用以下代码测试您的 TensorFlow 版本：
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You should see output like that in [Figure 1-12](#running_tensorflow_in_python).
    This will print the currently running version of TensorFlow—here you can see that
    version 2.0.0 is installed.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到与[图 1-12](#running_tensorflow_in_python)类似的输出。这将打印当前运行的 TensorFlow 版本——在这里，您可以看到安装的版本为
    2.0.0。
- en: '![Running TensorFlow in Python](Images/aiml_0112.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![在 Python 中运行 TensorFlow](Images/aiml_0112.png)'
- en: Figure 1-12\. Running TensorFlow in Python
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-12\. 在 Python 中运行 TensorFlow
- en: Using TensorFlow in PyCharm
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 PyCharm 中使用 TensorFlow
- en: I’m particularly fond of using the [free community version of PyCharm](https://www.jetbrains.com/pycharm)
    for building models using TensorFlow. PyCharm is useful for many reasons, but
    one of my favorites is that it makes the management of virtual environments easy.
    This means you can have Python environments with versions of tools such as TensorFlow
    that are specific to your particular project. So, for example, if you want to
    use TensorFlow 2.0 in one project and TensorFlow 2.1 in another, you can separate
    these with virtual environments and not have to deal with installing/uninstalling
    dependencies when you switch. Additionally, with PyCharm you can do step-by-step
    debugging of your Python code—a must, especially if you’re just getting started.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我特别喜欢使用[PyCharm 的免费社区版本](https://www.jetbrains.com/pycharm)来构建使用 TensorFlow
    的模型。PyCharm 有许多有用之处，但我最喜欢的之一是它简化了虚拟环境的管理。这意味着您可以拥有与特定项目相关的工具版本（例如 TensorFlow 的不同版本）的
    Python 环境。因此，例如，如果您想在一个项目中使用 TensorFlow 2.0，而在另一个项目中使用 TensorFlow 2.1，您可以通过虚拟环境将它们分开，并且在切换时无需处理安装/卸载依赖项。此外，使用
    PyCharm，您可以对您的 Python 代码进行逐步调试——这对于刚开始使用的人尤为重要。
- en: For example, in [Figure 1-13](#creating_a_new_virtual_environment_usin) I have
    a new project that is called *example1*, and I’m specifying that I am going to
    create a new environment using Conda. When I create the project I’ll have a clean
    new virtual Python environment into which I can install any version of TensorFlow
    I want.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在[图 1-13](#creating_a_new_virtual_environment_usin)中，我有一个名为 *example1* 的新项目，并且我指定要使用
    Conda 创建一个新环境。当我创建项目时，我将拥有一个干净的新虚拟 Python 环境，可以在其中安装任何我想要的 TensorFlow 版本。
- en: '![Creating a new virtual environment using PyCharm](Images/aiml_0113.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![使用 PyCharm 创建新的虚拟环境](Images/aiml_0113.png)'
- en: Figure 1-13\. Creating a new virtual environment using PyCharm
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-13\. 使用 PyCharm 创建新的虚拟环境
- en: 'Once you’ve created a project, you can open the File → Settings dialog and
    choose the entry for “Project: *<your project name>*” from the menu on the left.
    You’ll then see choices to change the settings for the Project Interpreter and
    the Project Structure. Choose the Project Interpreter link, and you’ll see the
    interpreter that you’re using, as well as a list of packages that are installed
    in this virtual environment ([Figure 1-14](#adding_packages_to_a_virtual_environmen)).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 创建项目后，您可以打开“文件”→“设置”对话框，并从左侧菜单中选择“项目：*<your project name>*”条目。然后，您将看到更改项目解释器和项目结构设置的选项。选择“项目解释器”链接，您将看到您正在使用的解释器，以及安装在该虚拟环境中的包的列表（[图
    1-14](#adding_packages_to_a_virtual_environmen)）。
- en: '![Adding packages to a virtual environment](Images/aiml_0114.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![向虚拟环境添加包](Images/aiml_0114.png)'
- en: Figure 1-14\. Adding packages to a virtual environment
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-14\. 向虚拟环境添加包
- en: Click the + button on the right, and a dialog will open showing the packages
    that are currently available. Type “tensorflow” into the search box and you’ll
    see all available packages with “tensorflow” in the name ([Figure 1-15](#installing_tensorflow_with_pycharm)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 点击右侧的 + 按钮，会弹出对话框显示当前可用的包。在搜索框中输入“tensorflow”，您将看到所有包含“tensorflow”名称的可用包（[Figure 1-15](#installing_tensorflow_with_pycharm)）。
- en: '![Installing TensorFlow with PyCharm](Images/aiml_0115.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![使用 PyCharm 安装 TensorFlow](Images/aiml_0115.png)'
- en: Figure 1-15\. Installing TensorFlow with PyCharm
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 1-15\. 使用 PyCharm 安装 TensorFlow
- en: Once you’ve selected TensorFlow, or any other package you want to install, and
    then click the Install Package button, PyCharm will do the rest.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦选择了 TensorFlow 或任何其他要安装的包，并点击安装包按钮，PyCharm 将完成剩下的工作。
- en: Once TensorFlow is installed, you can now write and debug your TensorFlow code
    in Python.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了 TensorFlow，您现在可以在 Python 中编写和调试 TensorFlow 代码了。
- en: Using TensorFlow in Google Colab
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Google Colab 中使用 TensorFlow
- en: Another option, which is perhaps easiest for getting started, is to use [Google
    Colab](https://colab.research.google.com), a hosted Python environment that you
    can access via a browser. What’s really neat about Colab is that it provides GPU
    and TPU backends so you can train models using state-of-the-art hardware at no
    cost.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选项，也许是最简单的入门方法，是使用[Google Colab](https://colab.research.google.com)，这是一个托管的
    Python 环境，您可以通过浏览器访问。Colab 的真正好处在于它提供 GPU 和 TPU 后端，因此您可以免费使用先进硬件来训练模型。
- en: When you visit the Colab website, you’ll be given the option to open previous
    Colabs or start a new notebook, as shown in [Figure 1-16](#getting_started_with_google_colab).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当访问 Colab 网站时，您将有选项打开之前的 Colab 或开始一个新的笔记本，如 [Figure 1-16](#getting_started_with_google_colab)
    所示。
- en: '![Getting started with Google Colab](Images/aiml_0116.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![开始使用 Google Colab](Images/aiml_0116.png)'
- en: Figure 1-16\. Getting started with Google Colab
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 1-16\. 开始使用 Google Colab
- en: Clicking the New Python 3 Notebook link will open the editor, where you can
    add panes of code or text ([Figure 1-17](#running_tensorflow_code_in_colab)).
    You can execute the code by clicking the Play button (the arrow) to the left of
    the pane.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“New Python 3 Notebook”链接将打开编辑器，在这里你可以添加代码或文本窗格（[Figure 1-17](#running_tensorflow_code_in_colab)）。你可以通过点击左边窗格的播放按钮（箭头）来执行代码。
- en: '![Running TensorFlow code in Colab](Images/aiml_0117.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![在 Colab 中运行 TensorFlow 代码](Images/aiml_0117.png)'
- en: Figure 1-17\. Running TensorFlow code in Colab
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 1-17\. 在 Colab 中运行 TensorFlow 代码
- en: 'It’s always a good idea to check the TensorFlow version, as shown here, to
    be sure you’re running the correct version. Often Colab’s built-in TensorFlow
    will be a version or two behind the latest release. If that’s the case you can
    update it with `pip install` as shown earlier, by simply using a block of code
    like this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 始终建议检查 TensorFlow 的版本，如此处所示，以确保您运行的是正确的版本。通常情况下，Colab 内置的 TensorFlow 版本可能比最新版本要旧一两个版本。如果是这种情况，您可以像之前展示的那样，通过使用如下代码块来更新它：
- en: '[PRE3]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Once you run this command, your current environment within Colab will use the
    desired version of TensorFlow.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦运行此命令，您当前在 Colab 中的环境将使用所需版本的 TensorFlow。
- en: Getting Started with Machine Learning
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习入门
- en: 'As we saw earlier in the chapter, the machine learning paradigm is one where
    you have data, that data is labeled, and you want to figure out the rules that
    match the data to the labels. The simplest possible scenario to show this in code
    is as follows. Consider these two sets of numbers:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章早些时候看到的那样，机器学习范式是一种在其中有数据，数据被标记，然后你想找出将数据与标签匹配的规则的场景。展示这种情况的最简单的代码可能是这样的。考虑这两组数字：
- en: '[PRE4]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: There’s a relationship between the X and Y values (for example, if X is –1 then
    Y is –3, if X is 3 then Y is 5, and so on). Can you see it?
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: X 和 Y 值之间存在关系（例如，如果 X 是 –1，则 Y 是 –3，如果 X 是 3，则 Y 是 5，等等）。你能看出来吗？
- en: After a few seconds you probably saw that the pattern here is Y = 2X – 1\. How
    did you get that? Different people work it out in different ways, but I typically
    hear the observation that X increases by 1 in its sequence, and Y increases by
    2; thus, Y = 2X +/– something. They then look at when X = 0 and see that Y = –1,
    so they figure that the answer could be Y = 2X – 1\. Next they look at the other
    values and see that this hypothesis “fits,” and the answer is Y = 2X – 1.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 几秒钟后，你可能会发现这里的模式是 Y = 2X – 1\. 如何得出这个结果？不同的人有不同的方法，但我通常听到的观察是 X 在其序列中增加 1，而
    Y 增加 2；因此，Y = 2X +/– 一些东西。然后他们看 X = 0 时 Y = –1，所以他们推测答案可能是 Y = 2X – 1\. 接下来他们看其他数值，发现这个假设“符合”，答案就是
    Y = 2X – 1。
- en: That’s very similar to the machine learning process. Let’s take a look at some
    TensorFlow code that you could write to have a neural network do this figuring
    out for you.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这与机器学习过程非常相似。让我们看一下一些 TensorFlow 代码，你可以编写一个神经网络来帮你完成这个过程。
- en: 'Here’s the full code, using the TensorFlow Keras APIs. Don’t worry if it doesn’t
    make sense yet; we’ll go through it line by line:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用 TensorFlow Keras API 的完整代码。如果现在还不明白，不要担心；我们会逐行解释：
- en: '[PRE5]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Let’s start with the first line. You’ve probably heard of neural networks, and
    you’ve probably seen diagrams that explain them using layers of interconnected
    neurons, a little like [Figure 1-18](#a_typical_neural_network).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一行开始。你可能听说过神经网络，并且可能看到过用互连神经元层解释它们的图示，有点像[图 1-18](#a_typical_neural_network)。
- en: '![A typical neural network](Images/aiml_0118.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![一个典型的神经网络](Images/aiml_0118.png)'
- en: Figure 1-18\. A typical neural network
  id: totrans-111
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-18\. 一个典型的神经网络
- en: 'When you see a neural network like this, consider each of the “circles” to
    be a *neuron*, and each of the columns of circles to be a *layer*. So, in [Figure 1-18](#a_typical_neural_network),
    there are three layers: the first has five neurons, the second has four, and the
    third has two.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当你看到这样的神经网络时，请将每个“圆圈”视为*神经元*，并将每个圆圈列视为*层*。因此，在[图 1-18](#a_typical_neural_network)中，有三层：第一层有五个神经元，第二层有四个，第三层有两个。
- en: 'If we look back at our code and look at just the first line, we’ll see that
    we’re defining the simplest possible neural network. There’s only one layer, and
    it contains only one neuron:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回顾我们的代码，只看第一行，我们将看到我们在定义最简单可能的神经网络。只有一个层，它只包含一个神经元：
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When using TensorFlow, you define your layers using `Sequential`. Inside the
    `Sequential`, you then specify what each layer looks like. We only have one line
    inside our `Sequential`, so we have only one layer.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 TensorFlow 时，你使用 `Sequential` 定义你的层。在 `Sequential` 内部，你然后指定每一层的样子。我们只有一行在我们的
    `Sequential` 内部，所以我们只有一层。
- en: You then define what the layer looks like using the `keras.layers` API. There
    are lots of different layer types, but here we’re using a `Dense` layer. “Dense”
    means a set of fully (or densely) connected neurons, which is what you can see
    in [Figure 1-18](#a_typical_neural_network) where every neuron is connected to
    every neuron in the next layer. It’s the most common form of layer type. Our `Dense`
    layer has `units=1` specified, so we have just one dense layer with one neuron
    in our entire neural network. Finally, when you specify the *first* layer in a
    neural network (in this case, it’s our only layer), you have to tell it what the
    shape of the input data is. In this case our input data is our X, which is just
    a single value, so we specify that that’s its shape.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你使用 `keras.layers` API 定义层的样子。有很多不同类型的层，但在这里我们使用了 `Dense` 层。“Dense”意味着一组完全（或密集）连接的神经元，这就是你在[图 1-18](#a_typical_neural_network)中看到的，其中每个神经元与下一层中的每个神经元连接。这是最常见的层类型。我们的
    `Dense` 层指定了 `units=1`，所以我们在整个神经网络中只有一个密集层和一个神经元。最后，当你指定神经网络的*第一*层（在这种情况下，它是我们唯一的层）时，你必须告诉它输入数据的形状是什么。在这种情况下，我们的输入数据是我们的
    X，它只是一个单一的值，所以我们指定它的形状。
- en: 'The next line is where the fun really begins. Let’s look at it again:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的一行是真正有趣的开始。让我们再看一遍：
- en: '[PRE7]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If you’ve done anything with machine learning before, you’ve probably seen that
    it involves a lot of mathematics. If you haven’t done calculus in years it might
    have seemed like a barrier to entry. Here’s the part where the math comes in—it’s
    the core to machine learning.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你之前有机器学习的经验，你可能看到它涉及大量的数学。如果你多年没做过微积分，它可能看起来像是个门槛。这是数学涉及的部分——它是机器学习的核心。
- en: In a scenario such as this one, the computer has *no idea* what the relationship
    between X and Y is. So it will make a guess. Say for example it guesses that Y
    = 10X + 10\. It then needs to measure how good or how bad that guess is. That’s
    the job of the *loss function*.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，计算机*完全不知道*X和Y之间的关系。因此它会猜测。例如，它猜测Y = 10X + 10。然后它需要衡量这个猜测是好是坏。这就是*损失函数*的工作。
- en: It already knows the answers when X is –1, 0, 1, 2, 3, and 4, so the loss function
    can compare these to the answers for the guessed relationship. If it guessed Y
    = 10X + 10, then when X is –1, Y will be 0\. The correct answer there was –3,
    so it’s a bit off. But when X is 4, the guessed answer is 50, whereas the correct
    one is 7\. That’s really far off.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当X为–1, 0, 1, 2, 3和4时，它已经知道答案，因此损失函数可以将这些与猜测关系的答案进行比较。如果它猜测Y = 10X + 10，则当X为–1时，Y将为0。那里的正确答案是–3，所以有点偏离。但当X为4时，猜测答案是50，而正确答案是7。那相差甚远。
- en: Armed with this knowledge, the computer can then make another guess. That’s
    the job of the *optimizer*. This is where the heavy calculus is used, but with
    TensorFlow, that can be hidden from you. You just pick the appropriate optimizer
    to use for different scenarios. In this case we picked one called `sgd`, which
    stands for *stochastic gradient descent*—a complex mathematical function that,
    when given the values, the previous guess, and the results of calculating the
    errors (or loss) on that guess, can then generate another one. Over time, its
    job is to minimize the loss, and by so doing bring the guessed formula closer
    and closer to the correct answer.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握了这些知识后，计算机就可以进行另一次猜测。这就是*优化器*的工作。这是使用大量微积分的地方，但是使用TensorFlow，这些可以对你隐藏起来。你只需选择适合不同情景的优化器来使用。在这种情况下，我们选择了一个称为`sgd`的优化器，即*随机梯度下降*——一种复杂的数学函数，当给定值、先前的猜测以及计算出的误差（或损失）时，可以生成另一个值。随着时间的推移，它的工作是最小化损失，并通过这种方式使猜测的公式越来越接近正确答案。
- en: 'Next, we simply format our numbers into the data format that the layers expect.
    In Python, there’s a library called Numpy that TensorFlow can use, and here we
    put our numbers into a Numpy array to make it easy to process them:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们只需将我们的数字格式化为层所期望的数据格式。在Python中，有一个名为Numpy的库可以被TensorFlow使用，在这里我们将我们的数字放入一个Numpy数组中，以便于对它们进行处理：
- en: '[PRE8]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The *learning* process will then begin with the `model.fit` command, like this:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然后*学习*过程将以`model.fit`命令开始，就像这样：
- en: '[PRE9]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can read this as “fit the Xs to the Ys, and try it 500 times.” So, on the
    first try, the computer will guess the relationship (i.e., something like Y =
    10X + 10), and measure how good or bad that guess was. It will then feed those
    results to the optimizer, which will generate another guess. This process will
    then be repeated, with the logic being that the loss (or error) will go down over
    time, and as a result the “guess” will get better and better.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将其理解为“将X适配到Y，并尝试500次”。因此，在第一次尝试时，计算机将猜测关系（例如Y = 10X + 10），并测量该猜测的好坏程度。然后将这些结果馈送给优化器，优化器将生成另一个猜测。这个过程将重复进行，逻辑是随着时间的推移，损失（或错误）将逐渐减少，结果“猜测”将变得越来越好。
- en: '[Figure 1-19](#training_the_neural_networ) shows a screenshot of this running
    in a Colab notebook. Take a look at the loss values over time.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-19](#training_the_neural_networ)展示了在Colab笔记本中运行时的截图。看看随时间变化的损失值。'
- en: '![Training the neural network](Images/aiml_0119.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![训练神经网络](Images/aiml_0119.png)'
- en: Figure 1-19\. Training the neural network
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-19。训练神经网络
- en: We can see that over the first 10 epochs, the loss went from 3.2868 to 0.9682\.
    That is, after only 10 tries, the network was performing three times better than
    with its initial guess. Then take a look at what happens by the five hundredth
    epoch ([Figure 1-20](#training_the_neural_networkem_dashthe_l)).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在前10个时期内，损失从3.2868降到了0.9682。也就是说，仅经过10次尝试，网络的性能比初始猜测好了三倍。接下来看看在第500个时期时会发生什么（[图1-20](#training_the_neural_networkem_dashthe_l)）。
- en: '![Training the neural network—the last five epochs](Images/aiml_0120.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![训练神经网络——最后五个时期](Images/aiml_0120.png)'
- en: Figure 1-20\. Training the neural network—the last five epochs
  id: totrans-133
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-20。训练神经网络——最后五个时期
- en: We can now see the loss is 2.61 × 10^(-5). The loss has gotten so small that
    the model has pretty much figured out that the relationship between the numbers
    is Y = 2X – 1\. The *machine* has *learned* the pattern between them.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以看到损失为2.61 × 10^(-5)。损失已经变得非常小，以至于模型几乎已经弄清楚了数字之间的关系是Y = 2X - 1。*机器*已经*学会*了它们之间的模式。
- en: 'Our last line of code then used the trained model to get a prediction like
    this:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最后一行代码然后使用训练好的模型来进行类似这样的预测：
- en: '[PRE10]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The term *prediction* is typically used when dealing with ML models. Don’t think
    of it as looking into the future, though! This term is used because we’re dealing
    with a certain amount of uncertainty. Think back to the activity detection scenario
    we spoke about earlier. When the person was moving at a certain speed, she was
    *probably* walking. Similarly, when a model learns about the patterns between
    two things it will tell us what the answer *probably* is. In other words, it is
    *predicting* the answer. (Later you’ll also learn about *inference*, where the
    model is picking one answer among many, and *inferring* that it has picked the
    correct one.)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*预测* 一词通常在处理 ML 模型时使用。不过不要把它看作是对未来的预测！之所以使用这个术语，是因为我们处理了一定程度的不确定性。回想一下我们之前讨论的活动检测场景。当人以某个速度移动时，她很
    *可能* 是在走路。同样地，当模型学习到两者之间的模式时，它会告诉我们答案 *可能* 是什么。换句话说，它正在 *预测* 答案。 （稍后你还将了解 *推理*，在那里模型从多个答案中选择一个，并
    *推断* 它已经选择了正确的答案。）'
- en: What do you think the answer will be when we ask the model to predict Y when
    X is 10? You might instantly think 19, but that’s not correct. It will pick a
    value *very close* to 19\. There are several reasons for this. First of all, our
    loss wasn’t 0\. It was still a very small amount, so we should expect any predicted
    answer to be off by a very small amount. Secondly, the neural network is trained
    on only a small amount of data—in this case only six pairs of (X,Y) values.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们要求模型预测 X 为 10 时，你认为答案会是什么？你可能会立即想到 19，但那是不正确的。它将选择一个与 19 *非常接近* 的值。这有几个原因。首先，我们的损失不是
    0，它仍然是一个非常小的数量，因此我们应该期望任何预测答案都会有一个非常小的偏差。其次，神经网络仅基于少量数据进行了训练——在这种情况下只有六对 (X,Y)
    值。
- en: The model only has a single neuron in it, and that neuron learns a *weight*
    and a *bias*, so that Y = WX + B. This looks exactly like the relationship Y =
    2X – 1 that we want, where we would want it to learn that W = 2 and B = –1\. Given
    that the model was trained on only six items of data, the answer could never be
    expected to be exactly these values, but something very close to them.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型中只有一个神经元，该神经元学习了一个 *权重* 和一个 *偏差*，使得 Y = WX + B。这看起来完全像我们想要的关系 Y = 2X – 1，其中我们希望它学到
    W = 2 和 B = –1\. 考虑到该模型仅使用六项数据进行了训练，不可能期望答案恰好是这些值，但会非常接近它们。
- en: 'Run the code for yourself to see what you get. I got 18.977888 when I ran it,
    but your answer may differ slightly because when the neural network is first initialized
    there’s a random element: your initial guess will be slightly different from mine,
    and from a third person’s.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码以查看你会得到什么结果。我在运行时得到的是 18.977888，但你的答案可能略有不同，因为当神经网络首次初始化时存在随机元素：你的初始猜测将与我的略有不同，也会与第三个人的不同。
- en: Seeing What the Network Learned
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看网络学到了什么
- en: 'This is obviously a very simple scenario, where we are matching Xs to Ys in
    a linear relationship. As mentioned in the previous section, neurons have weight
    and bias parameters that they learn, which makes a single neuron fine for learning
    a relationship like this: namely, when Y = 2X – 1, the weight is 2 and the bias
    is –1\. With TensorFlow we can actually take a look at the weights and biases
    that are learned, with a simple change to our code like this:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这是一个非常简单的情景，我们在其中匹配 X 到 Y 在线性关系中。如前所述，神经元有权重和偏差参数，它们学习使单个神经元能够很好地学习到这样的关系：即当
    Y = 2X – 1 时，权重为 2，偏差为 –1\. 使用 TensorFlow，我们实际上可以查看学到的权重和偏差，只需简单修改我们的代码如下：
- en: '[PRE11]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The difference is that I created a variable called `l0` to hold the `Dense`
    layer. Then, after the network finishes learning, I can print out the values (or
    weights) that the layer learned.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 不同之处在于我创建了一个名为 `l0` 的变量来保存 `Dense` 层。然后，在网络完成学习后，我可以打印出该层学到的值（或权重）。
- en: 'In my case, the output was as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的案例中，输出如下所示：
- en: '[PRE12]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Thus, the learned relationship between X and Y was Y = 1.9967953X – 0.9900647.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，X 和 Y 之间学到的关系是 Y = 1.9967953X – 0.9900647。
- en: This is pretty close to what we’d expect (Y = 2X – 1), and we could argue that
    it’s even closer to reality, because we are *assuming* that the relationship will
    hold for other values.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这相当接近我们预期的结果（Y = 2X – 1），我们可以认为它甚至更接近现实，因为我们 *假设* 这种关系将适用于其他值。
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: That’s it for your first “Hello World” of machine learning. You might be thinking
    that this seems like massive overkill for something as simple as determining a
    linear relationship between two values. And you’d be right. But the cool thing
    about this is that the pattern of code we’ve created here is the same pattern
    that’s used for far more complex scenarios. You’ll see these starting in [Chapter 2](ch02.xhtml#introduction_to_computer_vision),
    where we’ll explore some basic computer vision techniques—the machine will learn
    to “see” patterns in pictures, and identify what’s in them.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你的第一个机器学习“Hello World”了。你可能会觉得，对于确定两个值之间的线性关系来说，这似乎有些杀鸡用牛刀。你的想法没错。但酷的是，我们在这里创建的代码模式，也是用于更复杂场景的相同模式。你将在[第二章](ch02.xhtml#introduction_to_computer_vision)中看到这些，我们将探索一些基本的计算机视觉技术——机器将学会“看”图片中的模式，并识别其中的内容。
