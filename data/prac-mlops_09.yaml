- en: Chapter 9\. MLOps for GCP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 9 章 MLOps 适用于 GCP
- en: By Noah Gift
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：诺亚·吉夫
- en: The best bonsai teachers have both a mastery of the reality and an ability not
    only to explain but to inspire. John once said, “Jin this part and wire it so
    it will dry with a nice shape.” “What shape?” I asked. “You decide,” he replied,
    “it’s not for me to sing your song for you!”
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最优秀的盆景教师既精通现实，又能够不仅解释而且激发。约翰曾经说过，“把这部分用线缠绕，这样它就会干得漂亮。” “什么形状？”我问。 “你决定吧，”他回答，“我不是为你唱歌！”
- en: ''
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Dr. Joseph Bogen
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 约瑟夫·博根博士
- en: The Google Cloud Platform (GCP) is unique compared to its competitors. On the
    one hand, it has been marginally enterprise-focused; on the other, it has world-class
    research and development that has created category-leading technology, including
    products like Kubernetes and TensorFlow. Yet one more unique aspect of the Google
    Cloud is the rich collection of educational resources available to students and
    working professionals through [*https://edu.google.com*](https://edu.google.com).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌云平台（GCP）与其竞争对手相比具有独特性。一方面，它在某种程度上专注于企业；另一方面，它拥有世界一流的研发，已经创建了领先类别的技术，包括 Kubernetes
    和 TensorFlow 等产品。然而，谷歌云的另一个独特之处是通过 [*https://edu.google.com*](https://edu.google.com)
    提供给学生和职业人士丰富的教育资源。
- en: Let’s dive into the Google Cloud with an emphasis on using it to perform MLOps.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入研究谷歌云，重点是如何利用它来进行 MLOps。
- en: Google Cloud Platform Overview
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌云平台概述
- en: Every cloud platform has pros and cons, so let’s start by covering the three
    main cons of the Google Cloud Platform. First, with Google trailing AWS and Microsoft
    Azure, one disadvantage of using Google is that it has fewer certified practitioners.
    In [Figure 9-1](#Figure-9-3), you can see that in 2020, AWS and Azure controlled
    over 50% of the market, and Google Cloud was less than 9%. Hiring talent for the
    Google Cloud Platform is more challenging as a result.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 每个云平台都有其利弊，因此让我们从覆盖谷歌云平台的三个主要缺点开始。首先，由于谷歌落后于 AWS 和微软 Azure，使用谷歌的一个缺点是其拥有较少的认证从业者。在
    [图 9-1](#Figure-9-3) 中，您可以看到在 2020 年，AWS 和 Azure 控制了超过 50% 的市场份额，而谷歌云不到 9%。因此，招聘谷歌云平台的人才更具挑战性。
- en: A second disadvantage is that Google is part of what Harvard Professor [Shoshana
    Zuboff](https://oreil.ly/le2OC) calls surveillance capitalism, in which “Silicon
    Valley and other corporations are mining users’ information to predict and shape
    their behavior.” Thus, it is theoretically possible that technology regulation
    could impact market share in the future.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个缺点是谷歌是哈佛大学教授 [Shoshana Zuboff](https://oreil.ly/le2OC) 所称的监控资本主义的一部分，其中“硅谷和其他公司正在挖掘用户信息以预测和塑造他们的行为”。因此，技术监管理论上可能会影响未来的市场份额。
- en: '![GCP Cloud Market Share](Images/pmlo_0901.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![GCP 云市场份额](Images/pmlo_0901.png)'
- en: Figure 9-1\. GCP Cloud market share
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-1\. GCP 云市场份额
- en: Finally, Google has a reputation for a poor user and customer experience and
    frequently abandons products like Google Hangouts and the Google Plus social network.
    Could it then discontinue Google Cloud if it remains the third-best option in
    the next five years?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，谷歌因用户和客户体验差而声名狼藉，并频繁放弃产品，如 Google Hangouts 和 Google Plus 社交网络。如果在未来五年内仍然是第三选择，它会继续停止
    Google Cloud 吗？
- en: 'While these are substantial challenges, and Google would be wise to address
    the cultural issues that led to these cons quickly, there are many unique advantages
    to the Google platform due to its culture. For example, while AWS and Microsoft
    are customer service-oriented cultures with a rich history of enterprise customer
    support, Google famously didn’t have phone support for most products. Instead,
    its culture focuses on intense “leet code” style interviews to only “hire the
    best.” Additionally, research and development of mind-numbingly complex solutions
    that work at “planet-scale” is something it does well. In particular, three of
    Google’s most successful open source projects show this cultural strength: Kubernetes,
    the Go language, and the deep learning framework TensorFlow.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些是重大挑战，而且谷歌应该迅速解决导致这些问题的文化问题，但由于其文化，谷歌平台有许多独特的优势。例如，虽然 AWS 和微软是以客户服务为导向的文化，具有丰富的企业客户支持历史，但谷歌因其大多数产品没有电话支持而闻名。相反，它的文化侧重于紧张的“leet
    code”风格面试，只聘用“最优秀的”人才。此外，研发能够在“全球范围”内运行的令人惊叹复杂解决方案是其擅长的。特别是，谷歌的三个最成功的开源项目展示了这种文化优势：Kubernetes、Go
    语言和深度学习框架 TensorFlow。
- en: Ultimately the number one advantage of using the Google Cloud may be that its
    technology is ideal for a multicloud strategy. Technologies like Kubernetes and
    Tensor Flow work well on any cloud and are widely adopted. As a result, using
    Google Cloud could be a hedge for large companies wanting to check the power of
    their vendor relationship with either AWS or Azure. Additionally, these technologies
    have wide adoption, so it is relatively straightforward to hire for positions
    that require expertise in TensorFlow.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，使用Google Cloud的头号优势可能在于其技术非常适合多云战略。像Kubernetes和TensorFlow这样的技术在任何云上表现良好，并得到广泛采用。因此，使用Google
    Cloud对于希望检查其与AWS或Azure供应商关系实力的大公司来说可能是一个避险措施。此外，这些技术具有广泛的采用，因此相对容易为需要TensorFlow专业知识的职位招聘人才。
- en: 'Let’s take a look at Google Cloud’s core offerings. These services divide into
    four clean categories: Compute, Storage, Big Data, and Machine Learning, as shown
    in [Figure 9-2](#Figure-9-3_2).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看Google Cloud的核心服务。这些服务分为四个主要类别：计算、存储、大数据和机器学习，如[图9-2](#Figure-9-3_2)所示。
- en: '![pmlo 0902](Images/pmlo_0902.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0902](Images/pmlo_0902.png)'
- en: Figure 9-2\. GCP Cloud services
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-2\. GCP云服务
- en: 'Let’s define the major components of Google Cloud next, starting with Compute:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们定义Google Cloud的主要组件，从计算开始：
- en: Compute Engine
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 计算引擎
- en: Like other cloud vendors (notably AWS and Azure), GCP offers virtual machines
    as a service. Compute Engine is a service that enables you to create and run virtual
    machines on Google’s infrastructure. Perhaps the most critical takeaway is that
    there are many different virtual machines, including Compute Intensive, Memory
    Intensive, Accelerator Optimized, and General Purpose. Additionally, there are
    preemptible VMs, available for up to 24 hours, suited for batch jobs, and they
    can save up to 80% on storage costs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他云供应商（特别是AWS和Azure）类似，GCP提供虚拟机作为服务。Compute Engine是一个服务，允许您在Google基础设施上创建和运行虚拟机。也许最重要的一点是，有许多不同类型的虚拟机，包括计算密集型、内存密集型、加速器优化和通用型。此外，还有可中断的VM，可供使用长达24小时，适用于批处理作业，可以节省高达80%的存储成本。
- en: As an MLOps practitioner, it is critical to use suitable types of machines for
    the task at hand. Costs do matter in the actual world, and the ability to accurately
    forecast costs could make or break a company doing machine learning. For example,
    with deep learning, it could be optimal to use Accelerator Optimized instances
    since they could leverage the additional massively parallel capabilities of NVIDIA
    GPUs. On the other hand, it would be incredibly wasteful to use these instances
    for machine learning training that cannot take advantage of GPUs. Similarly, by
    architecting around preemptible VMs for batch machine learning, an organization
    could save up to 80% of the cost.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作为MLOps从业者，使用适合当前任务的适当类型的机器非常关键。在实际世界中，成本确实很重要，准确预测成本的能力可能会成就或毁掉一家进行机器学习的公司。例如，在深度学习中，使用加速器优化实例可能是最佳选择，因为它们可以利用NVIDIA
    GPU的额外大规模并行能力。另一方面，对于不能利用GPU的机器学习训练来说，使用这些实例将非常浪费。类似地，通过围绕用于批处理机器学习的可中断VM进行架构设计，组织可以节省高达80%的成本。
- en: Kubernetes Engine and Cloud Run
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes引擎和Cloud Run
- en: Since Google created Kubernetes and maintains it, the support for doing work
    on Kubernetes is excellent through its GKE (Google Kubernetes Engine). Alternatively,
    Cloud Run is a high-level service that abstracts away many of the complexities
    of running containers. Cloud Run is a good starting point for the Google Cloud
    Platform for organizations wanting a simple way to deploy containerized machine
    learning applications.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Google创建并维护Kubernetes，通过其GKE（Google Kubernetes Engine）执行Kubernetes上的工作的支持非常出色。另外，Cloud
    Run是一个高级服务，抽象了运行容器的许多复杂性。对于希望以简单方式部署容器化机器学习应用程序的组织来说，Cloud Run是Google Cloud Platform的一个很好的起点。
- en: App Engine
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: App Engine
- en: Google App Engine is a fully managed PaaS. You can write code in many languages,
    including Node.js, Java, Ruby, C#, Go, Python, or PHP. MLOps workflows could use
    App Engine as the API endpoint of a fully automated continuous delivery pipeline
    using GCP Cloud Build to deploy changes.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Google App Engine是一个完全托管的PaaS。您可以使用多种语言编写代码，包括Node.js、Java、Ruby、C#、Go、Python或PHP。MLOps工作流可以使用App
    Engine作为完全自动化持续交付管道的API端点，使用GCP Cloud Build部署更改。
- en: Cloud Functions
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 云函数
- en: Google Cloud Functions act as a FaaS (functions as a service). FaaS works well
    with an event-driven architecture. For example, Cloud Functions could trigger
    a batch machine learning training job or deliver an ML prediction in response
    to an event.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud Functions 充当 FaaS（函数即服务）。FaaS 与事件驱动架构很搭配。例如，Cloud Functions 可以触发批量机器学习训练作业或者在事件响应中提供
    ML 预测。
- en: Next, let’s talk about storage on Google Cloud. Concerning MLOps, the main option
    to discuss is its Cloud Storage product. It offers unlimited storage, worldwide
    accessibility, low latency, geo-redundancy, and high durability. These facts mean
    that for MLOps workflows, the data lake is the location where unstructured and
    structured data resides for batch processing of machine learning training jobs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们谈谈 Google Cloud 上的存储。在 MLOps 方面，讨论的主要选项是其 Cloud Storage 产品。它提供无限存储、全球访问性、低延迟、地理冗余和高耐久性。这些事实意味着对于
    MLOps 工作流程来说，数据湖是非结构化和结构化数据的存储位置，用于批处理机器学习训练作业。
- en: Closely associated with this offering are the big data tools available from
    GCP. Many offerings assist in moving, querying, and computing big data. One of
    the most popular offerings is Google BigQuery because it offers a SQL interface,
    serverless paradigm, and the ability to do machine learning within the platform.
    Google BigQuery is a great place to start doing machine learning on GCP because
    you can solve the entire MLOps value chain from this one tool.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与此服务密切相关的是 GCP 提供的大数据工具。许多服务可以帮助移动、查询和计算大数据。其中最受欢迎的是 Google BigQuery，因为它提供 SQL
    接口、无服务器范式，并且可以在平台内进行机器学习。Google BigQuery 是在 GCP 上进行机器学习的绝佳起点，因为你可以从这个工具解决整个 MLOps
    的价值链。
- en: 'Finally, the machine learning and AI capabilities coordinate in a product called
    Vertex AI. One advantage of Google’s approach is that it aims to be an MLOps solution
    from the beginning. The workflow of Vertex AI allows a structured approach to
    ML, including the following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，机器学习和 AI 能力在一个名为 Vertex AI 的产品中协同工作。谷歌的一个优势是它从一开始就旨在成为 MLOps 解决方案。Vertex
    AI 的工作流程允许以结构化的方式进行 ML，包括以下内容：
- en: Dataset creation and storage
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的创建和存储
- en: Training an ML model
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练一个 ML 模型
- en: Storing the model in Vertex AI
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型存储在 Vertex AI 中
- en: Deploying the model to an endpoint for prediction
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型部署到端点以进行预测
- en: Testing and creating prediction requests
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试和创建预测请求
- en: Using traffic splitting for endpoints
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用流量分割进行端点处理
- en: Managing the lifecycle of ML models and endpoints
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理 ML 模型和端点的生命周期
- en: According to Google, these capabilities factor into how Vertex AI enables MLOps,
    as shown in [Figure 9-3](#Figure-9-3-1). At the center of these seven components
    is data and model management, the central element of MLOps.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 根据谷歌的说法，这些能力对 Vertex AI 如何实现 MLOps 起到了作用，如[图 9-3](#Figure-9-3-1)所示。这七个组件的中心是数据和模型管理，这是
    MLOps 的核心元素。
- en: '![Google''s Seven Components of MLOps](Images/pmlo_0903.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![Google 的 MLOps 七大组件](Images/pmlo_0903.png)'
- en: Figure 9-3\. Google’s seven components of MLOps
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-3\. Google 的 MLOps 七大组件
- en: This thought process culminates in Google’s idea of end-to-end MLOps, as described
    in [Figure 9-4](#Figure-9-3-2). A comprehensive platform like Vertex AI enables
    a comprehensive way to manage MLOps.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这种思维过程最终体现在谷歌对端到端 MLOps 的理念中，如[图 9-4](#Figure-9-3-2)所述。像 Vertex AI 这样的全面平台能够全面管理
    MLOps。
- en: In a nutshell, MLOps on the Google Cloud Platform is straightforward due to
    Vertex AI and subcomponents of this system like Google BigQuery. Next, let’s get
    into more detail on CI/CD on GCP, a nonoptional foundational component of MLOps.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，Google 云平台上的 MLOps 因 Vertex AI 和其系统的子组件（如 Google BigQuery）而变得简单明了。接下来，让我们更详细地探讨在
    GCP 上的 CI/CD，这是 MLOps 的一个不可或缺的基础组件。
- en: '![End to End MLOps on GCP](Images/pmlo_0904.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![GCP 上的端到端 MLOps](Images/pmlo_0904.png)'
- en: Figure 9-4\. End-to-end MLOps on GCP
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-4\. GCP 上的端到端 MLOps
- en: Continuous Integration and Continuous Delivery
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持续集成和持续交付
- en: 'One of the most important and yet neglected areas of a project involves continuous
    integration. Testing is a fundamental component to doing both DevOps and MLOps.
    For GCP, there are two main continuous integration options: use a SaaS offering
    like GitHub Actions or use the cloud native solution [Cloud Build](https://oreil.ly/oTafJ).
    Let’s take a look at both options. You can view an entire starter project scaffold
    in this [gcp-from-zero GitHub repository](https://oreil.ly/34TQt).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 项目中最重要但被忽视的一个领域是持续集成。测试是DevOps和MLOps的基本组成部分。对于GCP，有两种主要的持续集成选项：使用GitHub Actions这样的SaaS解决方案，或者使用云原生解决方案[Cloud
    Build](https://oreil.ly/oTafJ)。让我们看看这两个选项。您可以在这个[gcp-from-zero GitHub存储库](https://oreil.ly/34TQt)中查看整个初始项目脚手架。
- en: 'First, let’s take a look at Google Cloud Build. Here is an example of the configuration
    file for Google Cloud Build, [*cloudbuild.yaml*](https://oreil.ly/wWbRS):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看Google Cloud Build。这是Google Cloud Build的配置文件示例，[*cloudbuild.yaml*](https://oreil.ly/wWbRS)：
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A recommended way to work with Google Cloud is to use the built-in editor alongside
    the terminal, as shown in [Figure 9-5](#Figure-9-2). Note that a Python virtual
    environment is activated.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 与Google Cloud一起工作的推荐方式是使用内置编辑器和终端一起工作，如[第9-5图](#Figure-9-2)所示。请注意，Python虚拟环境已激活。
- en: '![pmlo 0905](Images/pmlo_0905.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0905](Images/pmlo_0905.png)'
- en: Figure 9-5\. GCP editor
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 第9-5图。GCP编辑器
- en: One takeaway is that Google Cloud Build is a bit clunky with testing and linting
    code compared to GitHub Actions, but it does make deploying services like Google
    App Engine easy.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一个要点是，与GitHub Actions相比，Google Cloud Build在测试和代码linting方面有些笨拙，但确实使像Google App
    Engine这样的服务部署变得容易。
- en: 'Now let’s look at how GitHub Actions works. You can reference the *python-publish.yml*
    [configuration file](https://oreil.ly/mJd0T):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看GitHub Actions的工作原理。您可以参考*python-publish.yml* [配置文件](https://oreil.ly/mJd0T)：
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: A critical difference between the two approaches is that GitHub focuses on delivering
    an incredible developer experience, while GCP focuses on the cloud experience.
    One strategy is to use GitHub Actions for developer feedback, i.e., linting and
    testing code, and to use Google Cloud Build for deployment.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 两种方法之间的一个关键区别在于，GitHub侧重于提供出色的开发者体验，而GCP侧重于云体验。一种策略是使用GitHub Actions进行开发者反馈，即代码的linting和测试，并使用Google
    Cloud Build进行部署。
- en: With a handle on CI/CD systems on GCP, let’s explore a core Google compute technology,
    Kubernetes.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在GCP上处理CI/CD系统后，让我们探讨一个核心Google计算技术，Kubernetes。
- en: Kubernetes Hello World
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes Hello World
- en: 'One way of thinking about Kubernetes is as a “mini-cloud” or a “cloud-in-a-box.”
    Kubernetes allows for the creation of near-infinite application complexity. A
    few of the capabilities of Kubernetes that make it ideal for MLOps include:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Kubernetes的一种思考方式是将其视为一个“迷你云”或“盒中云”。Kubernetes允许创建几乎无限的应用程序复杂性。使其成为MLOps理想选择的一些功能包括：
- en: High-availability architecture
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高可用架构
- en: Autoscaling
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动缩放
- en: Rich ecosystem
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 丰富的生态系统
- en: Service discovery
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务发现
- en: Container health management
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器健康管理
- en: Secrets and configuration management
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Secrets和配置管理
- en: Kubeflow (end-to-end ML platform for Kubernetes)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubeflow（用于Kubernetes的端到端ML平台）
- en: '[Figure 9-6](#Figure-9-3-3) notes that ML frameworks from TensorFlow to scikit-learn
    coordinate on top of the core Kubernetes architecture. Finally, Kubernetes, as
    discussed earlier, can run in many clouds or in your own data center.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9-6图](#Figure-9-3-3)表明，从TensorFlow到scikit-learn的ML框架在核心Kubernetes架构之上进行协调。最后，正如前文所述，Kubernetes可以在许多云端或您自己的数据中心中运行。'
- en: '![Kubeflow Architecture](Images/pmlo_0906.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![Kubeflow架构](Images/pmlo_0906.png)'
- en: Figure 9-6\. Kubeflow architecture
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 第9-6图。Kubeflow架构
- en: 'The foundation of the Kubernetes architecture in [Figure 9-7](#Figure-9-3-4)
    shows the core operations involved in Kubernetes include the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9-7图](#Figure-9-3-4)中Kubernetes架构的基础显示了Kubernetes中涉及的核心操作包括以下内容：'
- en: Creating a Kubernetes cluster.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个Kubernetes集群。
- en: Deploying an application into the cluster.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署应用程序到集群中。
- en: Exposing application ports.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 暴露应用程序端口。
- en: Scaling an application.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展应用程序。
- en: Updating an application.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新应用程序。
- en: '![Kubernetes Basics](Images/pmlo_0907.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![Kubernetes基础知识](Images/pmlo_0907.png)'
- en: Figure 9-7\. Kubernetes basics
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 第9-7图。Kubernetes基础知识
- en: The Kubernetes hierarchy in [Figure 9-8](#Figure-9-3-5) shows a Kubernetes control
    node that manages the other nodes containing one or more containers inside a pod.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9-8图](#Figure-9-3-5)显示了一个Kubernetes控制节点，管理包含一个或多个容器的其他节点内的pod。'
- en: '![Kubernetes Hierarchy](Images/pmlo_0908.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![Kubernetes层级结构](Images/pmlo_0908.png)'
- en: Figure 9-8\. Kubernetes hierarchy
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 第9-8图。Kubernetes层级结构
- en: Note
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'There are two main methods: set up a local cluster (preferably with Docker
    Desktop) or provision a cloud cluster: Amazon through Amazon EKS, Google through
    Google Kubernetes Engine GKE, and Microsoft through Azure Kubernetes Service (AKS).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种主要方法：设置本地集群（最好使用 Docker Desktop）或提供云集群：通过 Amazon EKS 的 Amazon、通过 Google Kubernetes
    Engine GKE 的 Google 和通过 Azure Kubernetes Service (AKS) 的 Microsoft。
- en: One of the “killer” features of Kubernetes is the ability to set up autoscaling
    via the Horizontal Pod Autoscaler (HPA). The Kubernetes HPA will automatically
    scale the number of pods (remember they can contain multiple containers) in a
    replication controller, deployment, or replica set. The scaling uses CPU utilization,
    memory, or custom metrics defined in the Kubernetes Metrics Server.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的“杀手级”特性之一是通过水平 Pod 自动缩放器（HPA）设置自动缩放功能。Kubernetes HPA 将自动调整副本控制器、部署或副本集中的
    Pod 数量（记住它们可以包含多个容器）。缩放使用 CPU 利用率、内存或在 Kubernetes Metrics Server 中定义的自定义指标。
- en: In [Figure 9-9](#Figure-9-3-6), Kubernetes is using a control loop to monitor
    metrics for the cluster and perform actions based on the metrics received.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 9-9](#Figure-9-3-6) 中，Kubernetes 使用控制循环监视集群的度量，并根据收到的度量执行操作。
- en: '![Kubernetes Auto-Scale](Images/pmlo_0909.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![Kubernetes 自动缩放](Images/pmlo_0909.png)'
- en: Figure 9-9\. Kubernetes autoscaler
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-9\. Kubernetes 自动缩放器
- en: Since Kubernetes is a core strength of the Google Platform and how much of MLOps
    works on the platform, let’s dive right into a “hello world” Kubernetes example.
    This project uses [a simple Flask app that returns correct change](https://oreil.ly/sOcdS)
    as the base project and converts it to Kubernetes. You can find the [complete
    source in the repository on GitHub](https://oreil.ly/ISgrh).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Kubernetes 是 Google 平台的核心优势，以及 MLOps 多大部分运行在该平台上，让我们直接进入一个“你好世界” Kubernetes
    示例。该项目使用一个简单的 Flask 应用程序作为基础项目（它返回正确的更改），并将其转换为 Kubernetes。您可以在 GitHub 上的[完整源代码库中找到](https://oreil.ly/ISgrh)。
- en: In [Figure 9-10](#Figure-9-4) the Kubernetes nodes attach to the Load Balancer.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 9-10](#Figure-9-4) 中，Kubernetes 节点连接到负载均衡器。
- en: '![pmlo 0910](Images/pmlo_0910.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0910](Images/pmlo_0910.png)'
- en: Figure 9-10\. Kubernetes hello world
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-10\. Kubernetes 你好世界
- en: Let’s look at the assets in the repository.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看存储库中的资产。
- en: '[*Makefile*](https://oreil.ly/HSX9G): Builds project'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*Makefile*](https://oreil.ly/HSX9G)：构建项目'
- en: '[*Dockerfile*](https://oreil.ly/2Znkk): Container configuration'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*Dockerfile*](https://oreil.ly/2Znkk)：容器配置'
- en: '[*app.py*](https://oreil.ly/G2Tjt): Flask app'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*app.py*](https://oreil.ly/G2Tjt)：Flask 应用程序'
- en: '[*kube-hello-change.yaml*](https://oreil.ly/BCARa): Kubernetes YAML Config'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*kube-hello-change.yaml*](https://oreil.ly/BCARa)：Kubernetes YAML 配置'
- en: 'To get started, do the following steps:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请执行以下步骤：
- en: 'Create Python virtual environment:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Python 虚拟环境：
- en: '[PRE2]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Run `make all` to execute multiple build steps, including installing the libraries,
    linting the project, and running the tests.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 `make all` 执行多个构建步骤，包括安装库、linting 项目和运行测试。
- en: 'Next, build and run a Docker Container:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，构建并运行一个 Docker 容器：
- en: Install [Docker Desktop](https://oreil.ly/oUB0E)
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 [Docker Desktop](https://oreil.ly/oUB0E)
- en: 'To build the image locally, do the following:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在本地构建镜像，请执行以下操作：
- en: '[PRE3]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: or run `make build`, which has the same command.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者运行 `make build`，该命令具有相同的效果。
- en: To verify container run `docker image ls`
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要验证容器运行，请运行 `docker image ls`
- en: 'To run the container do the following:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要运行容器，请执行以下操作：
- en: '[PRE4]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: or run `make run`, which has the same command.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者运行 `make run`，该命令具有相同的效果。
- en: 'In a separate terminal, invoke the web service via `curl`, or run `make invoke`
    which has the same command:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在单独的终端中，通过 `curl` 调用 Web 服务，或者运行 `make invoke` 具有相同的命令：
- en: '[PRE5]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here’s the output:'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '[PRE6]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Stop the running Docker container by using Ctrl+C command
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Ctrl+C 命令停止正在运行的 Docker 容器
- en: 'Next, run Kubernetes locally:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在本地运行 Kubernetes：
- en: 'Verify Kubernetes is working via docker-desktop context:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 docker-desktop 上下文验证 Kubernetes 是否工作：
- en: '[PRE7]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Run the application in Kubernetes using the following command, which tells
    Kubernetes to set up the load-balanced service and run it:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在 Kubernetes 中运行应用程序，该命令告诉 Kubernetes 设置负载平衡服务并运行它：
- en: '[PRE8]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: or run `make run-kube`, which has the same command.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者运行 `make run-kube`，该命令具有相同的效果。
- en: 'You can see from the config file that a load balancer along with three nodes
    are the configured application:'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以从配置文件中看到，负载均衡器和三个节点是配置的应用程序：
- en: '[PRE9]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Verify the container is running:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证容器是否正在运行：
- en: '[PRE10]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here is the output:'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '[PRE11]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Describe the load balanced service:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述负载平衡服务：
- en: '[PRE12]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You should see output similar to this:'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该看到类似于此的输出：
- en: '[PRE13]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Invoke the endpoint to `curl` it:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用 `curl` 来访问端点：
- en: '[PRE14]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In the next section, run the command `make invoke` to query the microservice.
    The output of that action is shown here:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在接下来的部分，运行命令 `make invoke` 查询微服务。该操作的输出如下所示：
- en: '[PRE15]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: To clean up the deployment, run `kubectl delete deployment hello-python`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要清理部署，请运行 `kubectl delete deployment hello-python` 命令。
- en: The next step beyond this basic tutorial is to use either GKE (Google Kubernetes
    Engine), Google Cloud Run (container as a service), or Vertex AI to deploy a machine
    learning endpoint. You can use the [Python MLOps Cookbook repo](https://oreil.ly/EYAvj)
    as a base to do this. The Kubernetes technology is an excellent foundation for
    building ML-powered APIs, and with GCP, there are many options available if you
    use Docker format containers from the start.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 超越基本教程的下一步是使用 GKE（Google Kubernetes Engine）、Google Cloud Run（容器即服务）或 Vertex
    AI 部署机器学习端点。您可以使用 [Python MLOps Cookbook 仓库](https://oreil.ly/EYAvj) 作为基础来完成这些操作。Kubernetes
    技术是构建支持 ML API 的优秀基础，结合 GCP，如果从一开始就使用 Docker 格式的容器，可以选择多种选项。
- en: With the basics of computing on GCP out of the way, let’s discuss how cloud
    native databases like Google BigQuery go a long way toward adopting MLOps.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 GCP 的基本计算方式，让我们讨论云原生数据库如 Google BigQuery 在采用 MLOps 过程中的长远发展。
- en: Cloud Native Database Choice and Design
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云原生数据库选择与设计
- en: One of the crown jewels of the Google Cloud Platform is Google BigQuery, for
    a few reasons. One of the reasons is how easy it is to get started, and another
    reason is the widespread publicly available databases. A good list of Google BigQuery
    open datasets is available [on this Reddit page](https://oreil.ly/2FdDK). Finally,
    from an MLOps perspective, one of the killer features of Google BigQuery is the
    ability to train and host ML models inside the Google BigQuery platform.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud 平台的一颗明珠是 Google BigQuery，原因有几个。其中之一是它的易用性，另一个是广泛可用的公共数据库。您可以在 [这个
    Reddit 页面](https://oreil.ly/2FdDK) 找到一份不错的 Google BigQuery 开放数据集列表。从 MLOps 的角度来看，Google
    BigQuery 的一个杀手级功能是能够在其平台内训练和托管 ML 模型。
- en: In looking at [Figure 9-12](#Figure-9-4-2), notice that Google BigQuery is the
    center of an MLOps pipeline that can export products to both business intelligence
    and machine learning engineering, including Vertex AI. This MLOps workflow is
    made possible because of the DataOps (Operationalization of Data) inputs such
    as public datasets, streaming API, and the Google Dataflow product. The fact that
    Google BigQuery performs machine learning inline streamlines the processing of
    big datasets.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看[图 9-12](#Figure-9-4-2)时，请注意 Google BigQuery 是一个 MLOps 管道的核心，可以将产品导出到商业智能和机器学习工程中，包括
    Vertex AI。这种 MLOps 工作流是由于 DataOps（数据运营）输入（如公共数据集、流式 API 和 Google Dataflow 产品）的支持。Google
    BigQuery 在线进行机器学习，从而简化了大数据集的处理过程。
- en: '![Google BigQuery MLOps Workflow](Images/pmlo_0912.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![Google BigQuery MLOps 工作流程](Images/pmlo_0912.png)'
- en: Figure 9-12\. Google BigQuery MLOps workflow
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-12\. Google BigQuery MLOps 工作流程
- en: An example of this workflow is shown in [Figure 9-13](#Figure-9-4-3), where
    after the ML modeling occurred in Google BigQuery, the results export to Google
    Data Studio. The artifact created from BigQuery is K-means clustering analysis
    [shown in this shareable report](https://oreil.ly/JcpbT).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 此工作流的一个示例显示在[图 9-13](#Figure-9-4-3)中，其中在 Google BigQuery 中进行了 ML 建模后，结果导出到 Google
    Data Studio。从 BigQuery 创建的工件是 K-means 聚类分析，[显示在此可共享报告中](https://oreil.ly/JcpbT)。
- en: '![Google Data Studio K-Means Clustering](Images/pmlo_0913.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![Google Data Studio K-Means 聚类](Images/pmlo_0913.png)'
- en: Figure 9-13\. Google Data Studio K-means clustering
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-13\. Google Data Studio K-means 聚类
- en: As a starting point for doing MLOps on the GCP platform, BigQuery is an optimal
    choice due to the platform’s flexibility. Next, let’s talk about DataOps and Applied
    Data Engineering on the GCP platform.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 作为在 GCP 平台上进行 MLOps 的起点，BigQuery 是一个优选的选择，因为该平台具有灵活性。接下来，让我们讨论在 GCP 平台上的 DataOps
    和应用数据工程。
- en: 'DataOps on GCP: Applied Data Engineering'
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GCP 上的 DataOps：应用数据工程
- en: Data is input necessary for building machine learning at scale, and as such,
    it is a critical aspect of MLOps. In one sense, the GCP has an almost unlimited
    amount of ways to automate data flow. This fact is due to the variety of computing
    and storage options available, including high-level tools like Dataflow.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是在规模上构建机器学习所需的输入，因此它是 MLOps 的关键组成部分。从某种意义上说，GCP 几乎可以通过各种方式自动化数据流。这一事实归功于可用的各种计算和存储选项，包括高级工具如
    Dataflow。
- en: For the sake of simplicity, let’s use a serverless approach to data engineering
    using Cloud Functions. To do this, let’s look at how Google Cloud Functions work
    and how they can serve double duty as both the ML solution via an AI API call
    or an MLOps pipeline using Cloud Functions talking to [Google Pub/Sub](https://oreil.ly/DKj58).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，让我们使用无服务器方法来进行数据工程，使用Cloud Functions。为此，让我们看看Google Cloud Functions如何工作，以及它们如何通过AI
    API调用作为ML解决方案或通过与[Google Pub/Sub](https://oreil.ly/DKj58)交流的MLOps管道服务。
- en: Let’s start with an intentionally simple Google Cloud Function that returns
    the correct change. You can find [the complete example here](https://oreil.ly/MFmyg).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个故意简单的Google Cloud Function开始，返回正确的更改。您可以在[这里找到完整示例](https://oreil.ly/MFmyg)。
- en: To get started, open the Google Cloud Console, create a new Cloud Function,
    and paste the following code inside, as shown in [Figure 9-14](#Figure-9-5). You
    can also “untoggle” the “Require authentication” to “Allow unauthenticated invocations.”
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请打开Google Cloud控制台，创建一个新的Cloud Function，并将以下代码粘贴到内部，如[图9-14](#Figure-9-5)所示。您还可以“取消”“要求身份验证”以“允许未经身份验证的调用”。
- en: '[PRE16]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![pmlo 0914](Images/pmlo_0914.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0914](Images/pmlo_0914.png)'
- en: Figure 9-14\. Google Cloud Function
  id: totrans-152
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-14\. Google Cloud Function
- en: 'To invoke via the `gcloud` command line do the following:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过`gcloud`命令行调用，请执行以下操作：
- en: '[PRE17]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To invoke via the `curl` command, you can use the following.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过`curl`命令调用，请使用以下命令。
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Another approach is to build a command line tool to invoke your endpoint:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是构建一个命令行工具来调用您的端点：
- en: '[PRE19]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Finally, one more approach is to either upload your ML model to Vertex AI or
    call an existing API endpoint that performs computer vision, NLP, or another ML-related
    task. You can [find the complete example on GitHub](https://oreil.ly/P7JsE). In
    the following example, let’s use a preexisting NLP API. You will also need to
    add two third-party libraries by editing the *requirements.txt* file included
    in the Google Cloud scaffolding (see [Figure 9-15](#Figure-9-6)).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，另一种方法是将您的ML模型上传到Vertex AI或调用执行计算机视觉、NLP或其他与ML相关任务的现有API端点。您可以在GitHub上找到[完整示例](https://oreil.ly/P7JsE)。在下面的示例中，让我们使用一个预先存在的NLP
    API。您还需要通过编辑包含在Google Cloud脚手架中的*requirements.txt*文件来添加两个第三方库（见[图9-15](#Figure-9-6)）。
- en: '![pmlo 0915](Images/pmlo_0915.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0915](Images/pmlo_0915.png)'
- en: Figure 9-15\. Add requirements
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-15\. 添加需求
- en: 'Paste this code into the *main.py* function in the Google Cloud Shell Console:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 将此代码粘贴到Google Cloud Shell控制台中的*main.py*函数中：
- en: '[PRE20]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To invoke the function, you can call it from the Google Cloud Shell:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要调用该函数，您可以从Google Cloud Shell调用它：
- en: '[PRE21]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You can see the output of the Russian translation in the Google Cloud Shell
    terminal in [Figure 9-16](#Figure-9-7).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在Google Cloud Shell终端中看到俄语翻译的输出，如[图9-16](#Figure-9-7)所示。
- en: '![pmlo 0916](Images/pmlo_0916.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0916](Images/pmlo_0916.png)'
- en: Figure 9-16\. Translate
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-16\. 翻译
- en: For prototyping data engineering workflows, there is no quicker method than
    serverless technology like Google Cloud Functions. My recommendation is to solve
    an initial data engineering workflow using serverless technology and move to more
    complex tools if necessary.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 对于原型化数据工程工作流程，没有比Google Cloud Functions等无服务器技术更快的方法了。我的建议是，使用无服务器技术解决初始数据工程工作流，如果需要，再转向更复杂的工具。
- en: An important note is that the Vertex AI platform adds many additional data engineering
    and ML engineering components that enhance larger projects. In particular, the
    ability to use Explainable AI, track the quality of a model, and use a Feature
    Store are valuable components of a comprehensive MLOps solution. Let’s dive into
    these options next.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明是Vertex AI平台添加了许多额外的数据工程和ML工程组件，以增强更大型项目。特别是使用可解释AI、跟踪模型质量和使用特征存储是全面MLOps解决方案中的有价值组件。接下来让我们深入探讨这些选项。
- en: Operationalizing ML Models
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运营ML模型
- en: Every major cloud platform nows has an MLOps platform. On GCP, the platform
    is Vertex AI and integrates many individual services it has developed over the
    years, including AutoML technology. In particular, some of the essential components
    of MLOps platforms include Feature Stores, Explainable AI, and tracking model
    quality. If starting an MLOps project at a larger company, the first place to
    start on GCP would be its Vertex AI platform, just like SageMaker on AWS or Azure
    ML Studio on Azure.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 每个主要的云平台现在都有一个MLOps平台。在GCP上，该平台是Vertex AI，并整合了多年来开发的许多个别服务，包括AutoML技术。特别是，MLOps平台的一些基本组件包括特征存储、可解释AI和跟踪模型质量。如果在较大公司启动MLOps项目，首选在GCP上的地方将是其Vertex
    AI平台，就像在AWS上的SageMaker或Azure上的Azure ML Studio一样。
- en: Another option is to use components as standalone solutions to operationalize
    ML models on the GCP platform. One service to use is the [prediction service](https://oreil.ly/7cWEV)
    to deploy models and then accept requests.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选项是将组件作为独立的解决方案在GCP平台上操作ML模型。其中一个可用的服务是[prediction service](https://oreil.ly/7cWEV)，用于部署模型并接收请求。
- en: 'For example, you could test a local sklearn model using a command similar to
    the following:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以使用类似以下命令来测试本地的sklearn模型：
- en: '[PRE22]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Later, you could create an endpoint and then call this endpoint from an example
    shown earlier in the chapter, say Google Cloud Functions, Google Cloud Run, or
    Google App Engine.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，您可以创建一个端点，然后从本章前面显示的示例中调用此端点，例如Google Cloud Functions、Google Cloud Run或Google
    App Engine。
- en: Let’s walk through an example of how a Google App Engine project looks on the
    GCP cloud using [this repo as a starting point](https://oreil.ly/2vC8t). To start
    with, notice the core architecture of continuous delivery on GCP. To get started,
    create a new Google App Engine project as shown in the “light” MLOps workflow
    in [Figure 9-17](#Figure-9-8).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个示例来了解Google App Engine项目在GCP云上的外观，使用[此存储库作为起点](https://oreil.ly/2vC8t)。首先，请注意在GCP上的持续交付的核心架构。要开始，请按照“轻量级”MLOps工作流程在[图9-17](#Figure-9-8)中所示的方式创建一个新的Google
    App Engine项目。
- en: Note
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Notice that this lightweight workflow allows for a transparent and straightforward
    way to deploy an ML model, but a “heavy” flow could add tremendous value if the
    features shown, like Explainable AI, are required for a project.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这种轻量级工作流程允许透明且简单地部署ML模型，但如果需要像可解释AI这样的功能，则“重量级”流程可能会增加巨大的价值。
- en: '![MLOps Light versus Heavy Workflows](Images/pmlo_0917.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![MLOps轻量与重量工作流程](Images/pmlo_0917.png)'
- en: Figure 9-17\. MLOps light versus heavy workflows
  id: totrans-181
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-17\. MLOps轻量与重量工作流程
- en: Next, enable the Cloud Build API as shown in [Figure 9-18](#Figure-9-9).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，请按照[图9-18](#Figure-9-9)中所示启用Cloud Build API。
- en: '![Cloud Build](Images/pmlo_0918.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![Cloud Build](Images/pmlo_0918.png)'
- en: Figure 9-18\. Cloud build
  id: totrans-184
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-18\. 云构建
- en: 'The *cloudbuild.yml* file needs only a deploy command:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '*cloudbuild.yml* 文件只需一个部署命令：'
- en: '[PRE23]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The only other requirements are *app.yaml*, *requirements.txt*, and *main.py*,
    all found in this [example repository](https://oreil.ly/YAy6c). A final step to
    make this application do any form of machine learning is to call an ML/AI API
    or use the AI Platform endpoint hosting.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的其他要求是*app.yaml*、*requirements.txt*和*main.py*，这些文件都可以在[此示例仓库](https://oreil.ly/YAy6c)中找到。使此应用程序执行任何形式的机器学习的最后一步是调用ML/AI
    API或使用AI平台端点托管。
- en: The advantage of the simple approach is that it is easy to set up an entire
    MLOps pipeline in an hour or two at most. You could also pick and choose from
    AI APIs, prediction services, and an AutoML endpoint.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 简单方法的优势在于，最多只需一两个小时就能设置整个MLOps流水线。您还可以从AI API、预测服务和AutoML端点中挑选和选择。
- en: There are both “light” and “heavy” approaches to doing MLOps on GCP. This example
    explored the “light” approach, but there is merit to using the platform technology
    Vertex AI since it includes advanced features many enterprises desire.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在GCP上进行MLOps有“轻量级”和“重量级”两种方法。本示例探讨了“轻量级”方法，但使用Vertex AI平台技术也有其优点，因为它包含许多企业所需的高级功能。
- en: Let’s wrap up the chapter and discuss the next steps for using the GCP for MLOps.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们结束本章，并讨论在MLOps中使用GCP的下一步。
- en: Conclusion
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: One final takeaway on MLOps technologies like Vertex AI is they solve a complicated
    problem better than most organizations can do themselves. I remember talking to
    someone at a research lab, and they bragged about how the cloud was overrated
    since they had a ton of GPUs. A ton of GPUs doesn’t give you platform services
    like these platforms. This statement is a fundamental misunderstanding of how
    enterprise software and startups work. Comparative advantage is critical for both
    early-stage startups and Fortune 500 companies. Don’t build something worse than
    what you can buy for a trivial cost.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 关于像Vertex AI这样的MLOps技术的最后一点体会是，它们比大多数组织自己解决复杂问题更有效。我记得曾与研究实验室的某人交谈，他们吹嘘云计算被高估了，因为他们拥有大量GPU。然而，大量GPU并不会给您这些平台服务。这种说法基本上是对企业软件和初创公司工作方式的根本误解。在早期阶段的初创公司和财富500强公司中，比较优势至关重要。不要为了一些微不足道的成本而构建比您可以购买的更差的东西。
- en: I recommend taking everything from this chapter and applying it to a final machine
    learning project that consists of building a cloud native ML application on the
    GCP. This project should give you the ability to create realistic, working solutions
    designed with modern techniques.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议将本章的所有内容应用到一个最终的机器学习项目中，该项目包括在 GCP 上构建一个云原生 ML 应用程序。这个项目应该使您能够使用现代技术创建实际可行的解决方案。
- en: Before you begin, make sure you read the Sculley et al. (2015) paper to consider
    [technical debt in machine-learning (ML) systems](https://oreil.ly/d8jrl). Your
    project may benefit from using public data from Google BigQuery datasets. Alternately,
    if using AutoML, data can be tutorial data or custom data.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保阅读Sculley等人（2015）的论文，考虑[机器学习系统中的技术债务](https://oreil.ly/d8jrl)。您的项目可能会受益于使用
    Google BigQuery 数据集的公共数据。或者，如果使用 AutoML，数据可以是教程数据或自定义数据。
- en: 'The main idea is to create a portfolio project demonstrating your ability to
    do ML engineering on the Google Cloud. Here are the suggested project requirements
    to think through:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 主要思想是创建一个展示您在 Google Cloud 上进行 ML 工程能力的组合项目。以下是建议的项目要求需要深入考虑：
- en: Source code stored in GitHub
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源代码存储在 GitHub 中
- en: Continuous deployment from CircleCI
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 CircleCI 进行持续部署
- en: Data stored in GCP (BigQuery, Google Cloud Storage, etc.)
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据存储在 GCP（BigQuery、Google Cloud Storage 等）
- en: ML predictions created and served out (AutoML, BigQuery, AI Platform, etc.)
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和提供 ML 预测（AutoML、BigQuery、AI Platform 等。）
- en: Cloud native monitoring
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云原生监控
- en: Google App Engine serves out HTTP requests via REST API with a JSON payload
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google App Engine 通过 REST API 提供 HTTP 请求，并附带一个 JSON 负载
- en: Deployed into GCP environment using Google Cloud Build
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Google Cloud Build 在 GCP 环境中部署
- en: 'Here are some items to add to a final project requirements checklist:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是添加到最终项目要求清单的一些项目：
- en: Does the application make ML inference?
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序是否进行了 ML 推断？
- en: Are there separate environments?
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否存在独立的环境？
- en: Is there comprehensive monitoring and alerts?
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有全面的监控和警报？
- en: Is the correct datastore used?
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否使用了正确的数据存储？
- en: Does the principle of least security apply?
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否适用最少安全原则？
- en: Is data encrypted in transit?
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据在传输过程中是否加密？
- en: You can see some recent student and top data science projects in the [official
    code repository](https://oreil.ly/hJkDx). These projects provide a frame of reference
    for what you can build, and you are welcome to submit a pull request in the future
    to get your project added.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[官方代码库](https://oreil.ly/hJkDx)中查看一些最近的学生和顶级数据科学项目。这些项目为您可以构建的内容提供了一个参考框架，欢迎您将来提交拉取请求以将您的项目添加进来。
- en: '[Jason Adams: FastAPI Sentiment Analysis with Kubernetes](https://oreil.ly/5Omf3)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Jason Adams: 使用 Kubernetes 进行快速API情感分析](https://oreil.ly/5Omf3)'
- en: '[James Salafatinos: Tensorflow.js real-time image classification](https://oreil.ly/rs4QQ)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[James Salafatinos: Tensorflow.js 实时图像分类](https://oreil.ly/rs4QQ)'
- en: '[Nikhil Bhargava: Sneaker Price Predict](https://oreil.ly/MjU7H)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Nikhil Bhargava: 鞋类价格预测](https://oreil.ly/MjU7H)'
- en: '[Covid Predictor](https://oreil.ly/Wm8UF)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Covid 预测器](https://oreil.ly/Wm8UF)'
- en: '[Absenteeism at Work](https://oreil.ly/Rrh6S)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[工作缺席](https://oreil.ly/Rrh6S)'
- en: The next chapter discusses machine learning interoperability and how it uniquely
    solves MLOps problems that crop up from different platforms, technologies, and
    model formats.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章讨论了机器学习的互操作性以及它如何通过不同平台、技术和模型格式解决MLOps问题的独特性。
- en: Exercises
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Using Google Cloud Shell Editor, create a new GitHub repository with necessary
    Python scaffolding using a Makefile, linting, and testing. Add steps such as code
    formatting in your Makefile.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Google Cloud Shell Editor，在 GitHub 上创建一个新的存储库，使用 Makefile、linting 和测试来构建必要的
    Python 脚手架。在您的 Makefile 中添加代码格式化步骤。
- en: Create a “hello world” pipeline to Google Cloud that calls into a Python-based
    Google App Engine (GAE) project and returns “hello world” as a JavaScript Object
    Notation (JSON) response.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个“Hello World”管道到 Google Cloud，调用基于 Python 的 Google App Engine (GAE) 项目，并返回一个
    JavaScript Object Notation (JSON) 响应中的“hello world”。
- en: Create an ingest to ETL pipeline using CSV files and Google BigQuery. Schedule
    a reoccurring cron job to batch update the data.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 CSV 文件和 Google BigQuery 创建一个摄取到 ETL 管道。安排一个定期的 cron 作业批量更新数据。
- en: Train a multiclass classification model on Google AutoML vision and deploy to
    an edge device.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Google AutoML Vision 上训练一个多类别分类模型，并部署到边缘设备。
- en: Create a production and development environment and deploy a project to both
    environments using Google Cloud Build.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个生产和开发环境，并使用 Google Cloud Build 在这两个环境中部署项目。
- en: Critical Thinking Discussion Questions
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批判性思维讨论问题
- en: What problems does a CI system solve, and why is a CI system an essential part
    of SaaS software?
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CI 系统解决了哪些问题，以及为什么 CI 系统是 SaaS 软件的重要组成部分？
- en: Why are cloud platforms the ideal target for analytics applications, and how
    does deep learning benefit from the cloud?
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么云平台是分析应用的理想目标，以及深度学习如何从云计算中受益？
- en: What are the advantages of managed services like Google BigQuery, and how does
    Google BigQuery differ from a traditional SQL?
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像 Google BigQuery 这样的托管服务有哪些优势，以及 Google BigQuery 如何与传统 SQL 不同？
- en: How does ML prediction directly from BigQuery add value to the Google platform,
    and what advantages could this have for analytics application engineering?
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 BigQuery 直接进行 ML 预测如何为 Google 平台增加价值，以及这对分析应用工程可能带来的优势是什么？
- en: How does AutoML have a lower total cost of ownership (TCO), and how could it
    have a higher TCO?
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoML 为何具有较低的总体拥有成本（TCO），以及如何可能有较高的 TCO？
