- en: Chapter 8\. Best Practices for Machine Learning Projects
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 机器学习项目的最佳实践
- en: Delivering the responsible AI outcomes we discussed in the previous chapter
    means setting and implementing machine learning best practices. Because machine
    learning and AI techniques draw on data science, with a strong focus on practical
    outcomes, good data handling is critical. Before you develop best practices for
    machine learning specifically, you also need to think about how to have a data
    culture in your organization—a set of norms and behavior that encourages basing
    decisions on data—for those best practices to build on.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 实现我们在上一章讨论的负责任AI结果意味着制定并实施机器学习的最佳实践。因为机器学习和AI技术依赖于数据科学，且强调实际结果，良好的数据处理至关重要。在特定于机器学习的最佳实践之前，您还需要考虑如何在您的组织中建立数据文化——一套鼓励基于数据做出决策的规范和行为，以便这些最佳实践得以发展。
- en: Working Well with Data
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与数据合作良好
- en: A data culture requires widespread data literacy. People need to understand
    how to work responsibly with data and have the tools to access, manipulate, prepare,
    and visualize data. Some of this is about technical systems you put in place,
    but as the term suggests, some of it is social and cultural issues. With on-demand,
    cloud AI tools, it’s especially easy to think that gathering and curating data
    responsibly is “someone else’s problem,” but working responsibly with data is
    both an individual and collective responsibility across the organization.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 数据文化需要普及的数据素养。人们需要理解如何负责地处理数据，并拥有获取、操纵、准备和可视化数据的工具。其中一些涉及您设置的技术系统，但正如术语所暗示的那样，其中一些是社会和文化问题。有了按需、云端AI工具，很容易认为负责任地收集和筛选数据是“别人的问题”，但负责任地处理数据既是组织内的个人责任，也是集体责任。
- en: 'Everyone should be asking key questions about data:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 每个人都应该询问关于数据的关键问题：
- en: What is the value of this data? Did we need to collect it, and should we keep
    it?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些数据的价值是什么？我们需要收集它吗，我们应该保留它吗？
- en: What did we collect this data for, and what can we use it for?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们收集这些数据的目的是什么？我们可以用它做什么？
- en: What are we doing with this data, how are we telling users about that, and what
    control do we give them?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们用这些数据做什么，我们如何告知用户，以及我们给予他们什么控制权？
- en: How is this data protected?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何保护这些数据？
- en: Sharing Data
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据共享
- en: Data silos and fragmentation of data between departments and different tools
    (maybe with proprietary formats) leave you with pockets of data that can’t be
    integrated. Putting a data platform in place makes it easier to access and use
    all the data you have, and using cloud data storage can simplify that. For example,
    data from Azure Blob storage that’s part of a Power BI dataflow is stored in Dataverse
    and accessible to Azure Data Factory, Azure Databricks, Azure Notebooks, and other
    services so it can be shared and reused (with the appropriate access and permissions).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据孤立和数据在部门和不同工具之间的碎片化（可能使用专有格式）会导致数据的片段无法集成。建立数据平台可以更轻松地访问和使用您拥有的所有数据，并使用云数据存储可以简化这一过程。例如，存储在Azure
    Blob存储中作为Power BI数据流的一部分的数据存储在Dataverse中，并且可以被Azure Data Factory、Azure Databricks、Azure
    Notebooks和其他服务访问和重复使用（在适当的访问和权限下）。
- en: Encourage people to share data and build data quality and curation processes
    so there aren’t multiple, slightly different versions of the same dataset in different
    teams and data stores.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励人们分享数据，并建立数据质量和筛选流程，以避免不同团队和数据存储中存在多个略有不同版本的同一数据集。
- en: Data sharing between colleagues and across teams means rather than different
    teams doing the same data preparation on the same data, people can build on each
    other’s work, improving on and standardizing data artifacts and contributing their
    own expertise to the process. They do that in the tools they’re comfortable with.
    So, a business analyst would explore a dataset in Power BI to understand historical
    patterns, and a data engineer might use the same dataset as machine learning training
    data in Azure Machine Learning to use those patterns for predictions and scoring
    new deals. Power BI dataflows can be used in multiple reports by colleagues but
    also enriched by developers using other tools like Azure Databricks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 同事和团队之间的数据共享意味着不同团队不再在相同数据上进行相同的数据准备工作，人们可以在彼此的工作基础上进行改进和标准化数据工件，并将自己的专业知识贡献给这个过程。他们会使用他们熟悉的工具。因此，业务分析师可能会在Power
    BI中探索数据集以理解历史模式，而数据工程师可能会将同一数据集用作Azure Machine Learning中的机器学习训练数据，以利用这些模式进行预测并评分新交易。Power
    BI数据流可以在多个报告中使用，同事们也可以通过其他工具（如Azure Databricks）来丰富开发者使用。
- en: Sharing and reusing data artifacts also enables more rigorous data classification,
    data governance, and lifecycle management.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 分享和重复使用数据工件还可以实现更严格的数据分类、数据治理和生命周期管理。
- en: Data Provenance and Governance
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据来源和治理
- en: Governance of your machine learning practices matters for both business and
    performance reasons. If you don’t have the right framework and processes in place
    for handling data responsibly—assessing bias, fairness, explainability, and the
    other fundamentals we covered in the previous chapter—as well as privacy and security,
    the robustness and long-term performance of your models are likely to be poor.
    Without those processes, you can’t track and measure the impact of changes to
    your data and your model as you experiment and iterate.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您的机器学习实践的治理对于业务和性能原因都很重要。如果您没有适当的框架和流程来负责处理数据——评估偏差、公平性、可解释性和我们在前一章中介绍的其他基本原则，以及隐私和安全性，那么您的模型的鲁棒性和长期性能可能会较差。没有这些流程，您将无法跟踪和衡量您对数据和模型进行实验和迭代时的影响。
- en: Understanding the provenance of datasets is important for using them responsibly.
    That can be a legal requirement under regulations like the GDPR and the California
    Consumer Privacy Act, but even without regulation, data collected under one set
    of circumstances may simply not be useful for or relevant in different circumstances.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 了解数据集的来源对于负责任地使用它们至关重要。这可能是法规要求，例如GDPR和加州消费者隐私法案，但即使没有法规，根据一组情况收集的数据可能在不同情况下根本不适用或相关。
- en: 'Physical or external systems may change over time, sensors may be moved to
    different locations, and different collection methods can skew physical readings.
    For data about people, the demographics of the audience or the economic conditions
    might have changed or not be representative of your own users and audience. Survey
    data from a different field might use different terminology or definitions for
    the same term. Even common terms can have different meanings in different regions
    and geographies: a biscuit is a very different thing in the United Kingdom and
    the United States!'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 物理或外部系统可能会随时间变化，传感器可能会被移动到不同的位置，不同的收集方法可能会使物理读数产生偏差。对于关于人的数据，观众的人口统计信息或经济状况可能已经改变或不代表您自己的用户和观众。来自不同领域的调查数据可能会对相同术语使用不同的术语或定义。即使是常见术语在不同的地区和地理位置也可能有不同的含义：在英国和美国，饼干是完全不同的东西！
- en: Curating labels
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精心策划标签
- en: You need to assess the quality of crowd-sourced labels, captions, and tags in
    training data, thinking about both accuracy and possible cultural bias. Have a
    clear policy for handling labeling you do yourself, and provide a consistent set
    of labels for people to choose from, with examples and definitions to work from.
    Create clear guidelines on how confident you want someone to be about the labels
    they choose, what they should do if multiple labels seem appropriate or no labels
    fit, and how to make changes if they realize they made a mistake on a label.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要评估众包标签、标题和标签在训练数据中的质量，考虑到准确性和可能存在的文化偏差。有一个清晰的政策来处理您自己进行的标记，并为人们提供一致的标签集，附有示例和定义供参考。制定清晰的指导方针，说明您希望某人对其选择的标签有多大信心，如果多个标签看似合适或没有符合的标签，应该如何处理，以及如果他们意识到在标签上犯了错误应该如何进行更改。
- en: For images, you may want to use the Azure Machine Learning ML-assisted labeling
    feature, which takes the manual label done on an image dataset and uses it to
    cluster images to speed up tagging, and then predicts labels and bounding boxes
    around objects that you can accept or change. This helps with both the time it
    takes to label data and the consistency of the labels.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像，您可能希望使用Azure机器学习的ML辅助标注功能，该功能可以使用在图像数据集上进行的手动标注来对图像进行聚类以加快标记速度，然后预测标签并绘制围绕对象的边界框，您可以接受或更改这些标签。这有助于减少标记数据的时间和标签的一致性。
- en: Using a portable format like [COCO](https://cocodataset.org) for labeled datasets
    helps with dataset sharing (and tools like [Roboflow](https://roboflow.com/formats/coco-json)
    can convert to and from other formats).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像[COCO](https://cocodataset.org)这样的可移植格式来标记数据集有助于数据的分享（并且像[Roboflow](https://roboflow.com/formats/coco-json)这样的工具可以转换成其他格式）。
- en: 'Datasets need to be labeled with the details of how, when, and where the data
    was collected, as well as why it was collected—both the legal basis and the original
    purpose it was collected for, because that can have implications for how comprehensive
    the data is. More data doesn’t automatically improve performance: having the right
    data matters more than having “big data” and just hoping the data you need is
    in there. Especially for training custom versions of existing models, having the
    relevant data well labeled will improve performance far more than large amounts
    of data that hasn’t been carefully curated.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集需要标记详细信息，包括数据的收集方式、时间和地点，以及收集数据的原因——包括法律依据和最初收集的目的，因为这可能影响数据的全面性。更多的数据并不会自动提高性能：拥有正确的数据比拥有“大数据”更为重要，只是希望所需数据在其中。特别是对于训练现有模型的自定义版本，拥有相关数据的良好标记将比大量未经精心策划的数据更能提高性能。
- en: Consider what’s in your data
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 考虑您的数据内容
- en: Data minimization—collecting only what you really need—is also an important
    principle for compliance. It may mean that a dataset you expect to contain the
    data you need may not actually include it because it was collected for a different
    purpose. The answer to that isn’t to cast a wider net and collect more data without
    knowing if it’s relevant. As the ICO, the UK’s data protection regulator, has
    stated, “finding the correlation does not retrospectively justify obtaining the
    data.”
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 数据最小化——仅收集您实际需要的内容——也是符合规定的重要原则。这可能意味着您期望包含所需数据的数据集实际上可能不包含，因为它是为不同目的收集的。对此的答案不是扩大范围，收集更多数据而不知道其是否相关。正如英国数据保护监管机构ICO所述：“找到相关性并不会事后证明获取数据是合理的。”
- en: The datasheets template from [Chapter 7](ch07.xhtml#responsible_ai_development_and_use)
    will help here. If you use a data governance tool like Azure Purview for classifying
    and understanding what data you have, this can also work against structured datasets.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[第七章](ch07.xhtml#responsible_ai_development_and_use)的数据表模板将在这里有所帮助。如果您使用像Azure
    Purview这样的数据治理工具来对数据进行分类和理解，这也可以用于结构化数据集。'
- en: 'You also need to document your data preparation pipeline and any data transformation
    or enrichment that’s performed as part of it. That data lineage is important for
    experimentation: the data preparation needs to be consistent and repeatable so
    you can compare the performance and accuracy of different versions of a model.
    Services like Azure Machine Learning offer automated auditing of lineage through
    a model registry, in the same way they track the results of machine learning experiments
    and where datasets and models are used.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要记录您的数据准备流水线以及作为其一部分执行的任何数据转换或丰富。这种数据血统对于实验至关重要：数据准备需要一致和可重复，以便您可以比较不同版本模型的性能和准确性。像Azure
    Machine Learning这样的服务通过模型注册表提供自动化的血统审计，类似于它们跟踪机器学习实验的结果以及数据集和模型的使用方式。
- en: If you’re working with data that contains personal or sensitive information
    (where encryption at rest isn’t sufficient and you need to protect it during processing),
    you may need to de-identify and anonymize some of the information using techniques
    like data masking, pseudonymization, and aggregation, as well as creating legal
    and organizational safeguards like access controls, usage policies, and segregation
    of personal data from more general data. You’ll also need to assess the risk of
    re-identification if the data is combined with other publicly available information.
    Or you might need to look into emerging techniques like differential privacy that
    inject noise to prevent that kind of correlation using tools like [SmartNoise](https://go.microsoft.com/fwlink/?linkid=2190181),
    or homomorphic encryption for [machine learning on encrypted data](https://go.microsoft.com/fwlink/?linkid=2190182).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您处理包含个人或敏感信息的数据（仅在静止状态加密不足以保护处理期间），您可能需要使用数据遮罩、伪匿名化和聚合等技术对某些信息进行去标识化和匿名化，同时创建法律和组织保障措施，如访问控制、使用政策以及将个人数据与更一般数据分隔开来。您还需要评估如果数据与其他公开可用信息结合可能导致重新识别的风险。或者您可能需要探索新兴技术，如通过工具如[SmartNoise](https://go.microsoft.com/fwlink/?linkid=2190181)注入噪音以防止这种相关性的差分隐私技术，或者针对[加密数据上的机器学习](https://go.microsoft.com/fwlink/?linkid=2190182)使用同态加密。
- en: Compliance and audit
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 合规性和审计
- en: The data you use for machine learning will likely fall under your organization’s
    compliance policies. At the very least, you may need to document the reproducibility
    and auditability of machine learning systems. Using a cloud AI service can simplify
    this, because you can extract details like model versioning and usage, for your
    own models, and refer to compliance documentation for the service for prebuilt
    models and APIs that you consume.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你用于机器学习的数据很可能会受到你组织的合规政策约束。至少，你可能需要记录机器学习系统的可重现性和可审计性。使用云AI服务可以简化这一过程，因为你可以提取诸如模型版本和使用情况等细节，针对你自己的模型，并参考服务的合规文档，适用于你使用的预构建模型和API。
- en: For regulated industries and in jurisdictions with privacy regulations, you
    may want to seek professional advice on whether your organization counts as a
    data controller or data processor when doing machine learning and what that will
    mean for compliance policies. As well as data collection, you need to consider
    data protection principles including accountability and privacy-by-design requirements.
    If you’re using machine learning for automated decision making or profiling, you
    may need to assess privacy, data protection, and compliance risks formally.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于受监管行业和隐私法规管辖的地区，你可能需要就你的组织在进行机器学习时是否属于数据控制者或数据处理者寻求专业意见，并了解这对合规政策意味着什么。除了数据收集，你还需要考虑包括问责制和隐私设计原则在内的数据保护原则。如果你正在使用机器学习进行自动决策或个人画像生成，你可能需要正式评估隐私、数据保护和合规风险。
- en: Security for machine learning
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习的安全性
- en: You also need to think about the security of training and operational data and
    securing access to the machine learning system in operation. You need to balance
    giving enough people access to datasets and machine learning resources to get
    value from them with adhering to security and compliance policies. The premise
    of machine learning is that you don’t know before you explore the data what insights
    you will be able to find in it, because training a machine learning model is how
    you discover what features in the data deliver the best predictions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要考虑训练和运行数据的安全性，以及保护对正在运行的机器学习系统的访问权限。你需要在允许足够多的人员访问数据集和机器学习资源以从中获得价值的同时，遵守安全和合规政策。机器学习的前提是在探索数据之前你并不知道能从中发现什么见解，因为训练机器学习模型是你发现数据中哪些特征提供最佳预测的方式。
- en: Using cloud AI services can make compliance much easier because the cloud service
    handles more of that, although you need to secure the accounts and credentials
    you use. Use RBAC and principles of least privilege; not everyone should have
    access to every dataset. Someone with access for labeling data shouldn’t necessarily
    be able to delete data or use it to train a model.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 使用云AI服务可以使合规性工作更加容易，因为云服务处理了更多的内容，尽管你需要确保所使用的账户和凭证的安全性。使用RBAC和最小权限原则；并非每个人都应该对所有数据集有访问权限。能够访问数据标记的人不一定能够删除数据或使用数据来训练模型。
- en: Tip
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Use virtual networks and Azure Private Link to ensure you can connect to your
    Azure Machine Learning workspace only from a set of private IP addresses on a
    virtual network rather than any public IP address (and remember to move your storage
    and inferencing environment onto the same VNet).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用虚拟网络和Azure私有链接，以确保你只能从虚拟网络上一组私有IP地址连接到你的Azure机器学习工作空间，而不是任何公共IP地址（并记得将你的存储和推断环境迁移到同一个虚拟网络）。
- en: 'Like any other computing system, a machine learning system can have security
    vulnerabilities: in machine learning libraries, in training, in inference, or
    in the deployment of the model.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 像任何其他计算系统一样，机器学习系统可能存在安全漏洞：在机器学习库中、在训练过程中、在推断中，或者在模型部署中。
- en: You have the same kind of shared responsibility model with cloud AI services
    as with other cloud services. The cloud AI service takes care of vulnerabilities
    in machine learning libraries by patching and updating regularly. Abusing deployment
    vulnerabilities requires write access to change a machine learning model (although
    read access could allow an attacker to steal a model, assess it offline, and use
    what they learn to attack your model in use). Either way, you need to limit and
    secure access to the cloud AI service by using RBAC and protecting credentials
    for the service and the model. The versioning and usage information in the cloud
    service will again be useful for auditing this.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他云服务一样，您在云AI服务中也有相同类型的共享责任模型。云AI服务通过定期打补丁和更新来处理机器学习库中的漏洞。滥用部署漏洞需要写访问权限以更改机器学习模型（尽管读访问权限可能允许攻击者窃取模型、离线评估它，并利用所学来攻击正在使用的模型）。无论哪种方式，您都需要通过使用RBAC并保护服务和模型的凭证来限制和保护对云AI服务的访问。云服务中的版本控制和使用信息将再次对审核很有用。
- en: 'Vulnerabilities in training can be handled by validating input and doing integrity
    checks on your datasets. Vulnerabilities in inferencing are usually attackers
    trying to fool the machine learning model by crafting input that isn’t what it
    appears to be (putting strips of tape on a stop sign so it’s recognized as a speed
    limit sign instead), but it could also be input that’s in an unexpected context:
    like a shop sign in the form of a stop sign or temporary traffic lights on the
    back of a truck driving in front of your car.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练中的漏洞可以通过验证输入并对数据集进行完整性检查来处理。在推理中的漏洞通常是攻击者试图欺骗机器学习模型，通过制造看起来不是实际内容的输入（例如在停止标志上放条带，使其被识别为限速标志），但也可能是在意料之外的上下文中的输入，例如在一辆车前面行驶的卡车上的商店标识或临时交通灯。
- en: These “adversarial” attacks are harder to protect against; think about how your
    machine learning model could be attacked and use adversarial examples in training,
    or limit the number of inferencing calls that can be made to the model by any
    one source to prevent someone from sending hundreds of messages to figure out
    what will or won’t get through.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这些“对抗性”攻击更难以防范；考虑一下您的机器学习模型可能受到的攻击方式，并在训练中使用对抗性示例，或限制任何一个来源对模型进行推理调用的次数，以防止有人发送数百条消息来测试哪些消息可以通过。
- en: Tip
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Security professionals can use Microsoft’s open source [Counterfit tool](https://github.com/Azure/counterfit)
    to automate security risk assessments of AI models hosted locally or in the cloud
    using adversarial AI frameworks, using approaches they will be familiar with,
    without needing to become machine learning experts themselves. The datasheets
    and transparency notes we looked at in the previous chapter will also be useful
    for the inventory of machine learning systems they will need to conduct.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 安全专业人士可以使用Microsoft的开源[Counterfit工具](https://github.com/Azure/counterfit)自动化地进行AI模型的安全风险评估，这些模型可以是本地托管的，也可以是云端的，使用对抗性AI框架，使用他们熟悉的方法，而不需要成为机器学习专家。我们在前一章中查看的数据表和透明度注释也将对他们需要进行的机器学习系统清单很有帮助。
- en: Use the [AI Security Risk Assessment Framework](https://go.microsoft.com/fwlink/?linkid=2190302)
    to guide you in securing your machine learning systems in ways that build on the
    security risk assessment you already do in other areas of development and operations.
    There’s a comprehensive guide to [threat modeling AI and machine learning systems](https://go.microsoft.com/fwlink/?linkid=2190183)
    that will help you walk through assessing, testing, and improving your systems.
    If you’re just starting to think about machine learning security, the [defensive
    guidelines for Counterfit](https://go.microsoft.com/fwlink/?linkid=2190301) are
    a good place to start even if you’re not using the tool.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[AI安全风险评估框架](https://go.microsoft.com/fwlink/?linkid=2190302)指导您在保护机器学习系统方面的工作，这些工作建立在您在开发和运营的其他领域已经进行的安全风险评估基础上。有一个详尽的指南，用于[威胁建模AI和机器学习系统](https://go.microsoft.com/fwlink/?linkid=2190183)，将帮助您评估、测试和改进您的系统。如果您刚开始考虑机器学习安全性，[Counterfit的防御指南](https://go.microsoft.com/fwlink/?linkid=2190301)是一个很好的起点，即使您不使用这个工具也是如此。
- en: Don’t forget to think about when dataset and machine learning models will be
    retired and replaced. Consider policies for how long data will stay relevant,
    how to assess if it’s out of date, and how to assess the long-term quality of
    predictions as a model ages.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记考虑数据集和机器学习模型何时将被淘汰和替换。考虑数据保持相关性的时间政策，如何评估数据是否过时以及如何评估模型老化对预测长期质量的影响。
- en: With data governance and sharing in place, you can start to build a process
    that will make you more likely to get useful outcomes from machine learning.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据治理和共享机制得到落实后，您可以开始建立一个流程，这将使您更有可能从机器学习中获得有用的结果。
- en: Making Machine Learning Projects Successful
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使机器学习项目成功
- en: The point of doing machine learning and other forms of AI is to help solve problems;
    that means you need to know what problem you’re trying to help solve with a particular
    machine learning project.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 进行机器学习和其他形式的人工智能的目的是帮助解决问题；这意味着您需要知道您尝试用特定的机器学习项目来解决什么问题。
- en: 'In addition to having the right process for handling data, you need clear guidelines
    for how you use machine learning to drive decisions. These should start by exploring
    and documenting the problem: what’s the question the machine learning model needs
    to answer, and what is the decision or action that needs to be taken that can
    be informed by data. If you’re not solving your own problem, you need to spend
    time with the business team who will be using the answers from the machine learning
    system to understand the issues. You may want to have a domain expert involved
    in the specification, testing, and validation.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 除了处理数据的正确流程外，您还需要明确如何使用机器学习来推动决策的指导方针。这些指南应始于探索和记录问题：机器学习模型需要回答的问题是什么，需要采取的决策或行动可以通过数据进行决策。如果您没有解决自己的问题，您需要与将使用机器学习系统答案的业务团队共同投入时间来理解问题。您可能希望有领域专家参与规范、测试和验证过程。
- en: Start by solving the problem manually, or by using heuristics; that will make
    sure you have a clear understanding of the problem and of the data that’s available.
    This will also give you a baseline for measuring the success of your machine learning
    improvements against (and if using machine learning doesn’t give better results
    than solving the problem manually, think carefully about whether machine learning
    is really applicable).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 首先通过手动解决问题或使用启发式方法来确保您对问题及其可用数据有清晰的理解。这也将为您提供一个用于衡量机器学习改进成功的基准（如果使用机器学习不比手动解决问题效果更好，那么请仔细考虑机器学习是否真的适用）。
- en: Then you can map the business scenario to a data science question that you can
    apply machine learning to; use the examples in [Table 8-1](#real_world_scenarios_mapping)
    to help you frame your own list of scenarios, decisions, and questions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以将业务场景映射到一个可以应用机器学习的数据科学问题；使用[表 8-1](#real_world_scenarios_mapping)中的示例来帮助您构建自己的场景、决策和问题列表。
- en: Table 8-1\. Real-world scenarios mapping business problems to data science questions
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-1\. 将业务问题映射到数据科学问题的实际场景
- en: '| Business scenario | Key decision | Data science question |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 业务场景 | 关键决策 | 数据科学问题 |'
- en: '| --- | --- | --- |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Predictive maintenance | Should I service this piece of equipment? | What
    is the probability this equipment will fail within the next *x* days? |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 预测性维护 | 我应该为这台设备提供服务吗？ | 这台设备在接下来的*x*天内发生故障的概率是多少？ |'
- en: '| Energy forecasting | Should I buy or sell energy contracts? | What will be
    the long-/short-term demand for energy in a region? |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 能源预测 | 我应该购买还是出售能源合同？ | 一个地区的能源需求的长期/短期预测是什么？ |'
- en: '| Customer churn | Which customers should I prioritize to reduce churn? | What
    is the probability of churn within *x* days for each customer? |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 用户流失 | 我应该优先考虑哪些客户来减少流失？ | 每位客户在*x*天内流失的概率是多少？ |'
- en: '| Personalized marketing | What product should I offer first? | What is the
    probability that customers will purchase each product? |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 个性化营销 | 我应该首先提供哪种产品？ | 每种产品客户购买的概率是多少？ |'
- en: '| Product feedback | Which service/product needs attention? | What is the social
    media sentiment for each service/product? |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 产品反馈 | 哪些服务/产品需要关注？ | 每种服务/产品的社交媒体情感是什么？ |'
- en: '| Root cause analysis | Why is this product out of stock? | What are the key
    influencers for stock levels for each product and distribution center? |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 根本原因分析 | 为什么这个产品缺货？ | 每种产品和分销中心库存水平的关键影响因素是什么？ |'
- en: Preparing Your Dataset
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备您的数据集
- en: You need a “balanced” dataset with enough examples of the different categories
    of data and a balanced distribution. If you’re teaching a custom image recognizer
    to detect different products from your catalog or different kinds of damage to
    those products, you need examples of all of them with photos taken in different
    situations, at different times of day, in different lighting conditions, from
    different distances, and roughly similar numbers of images for each type, like
    the second set of photos in [Figure 8-1](Images/#use_the_top_set_of_training_images_and).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一个“平衡”的数据集，包含足够数量不同类别数据的示例，并且分布均衡。如果你正在训练一个自定义图像识别器，用来检测目录中不同产品或这些产品的不同损伤类型，你需要所有这些示例，这些照片要在不同情况下、不同时间、不同光照条件、不同距离下拍摄，并且大致相等数量的图片属于每一种类型，就像[图 8-1](Images/#use_the_top_set_of_training_images_and)的第二组照片那样。
- en: Imagine you’re teaching an image recognizer the difference between roses and
    daisies. If all the pictures of the daisies are closeups of the flower and all
    the pictures of roses are pictures of the whole rose bush, a close-up picture
    of a white rose is more likely to be misrecognized as a daisy. It’s very common
    for healthcare AI systems, trained with images designed to teach human doctors,
    to learn to recognize not the condition shown in those photos but the ruler included
    for scale!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你在教一个图像识别器区分玫瑰和雏菊。如果所有的雏菊图片都是花朵的特写，而所有的玫瑰图片都是整株玫瑰花的图片，一朵白色玫瑰的特写照更有可能被错误识别为雏菊。对于那些以教导医生为目的设计的图像训练AI系统来说，学会的可能是诊断图片中的尺度参照，而不是显示的病况！
- en: Tip
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: If you’re using Azure Machine Learning AutoML, it performs several optimizations
    to avoid overfitting and shows charts and metrics to help you identify if your
    data is unbalanced.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用 Azure 机器学习自动化机器学习（AutoML），它会执行多项优化以避免过拟合，并显示图表和指标，帮助您确定数据是否不平衡。
- en: '![Use the top set of training images and you’ll accidentally train a model
    that knows the difference between fruit on a plate and fruit someone is holding
    rather than apples and oranges: the lower set of training images is more diverse
    and balanced](Images/aasc_0801.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![使用顶部集合的训练图片，您将意外地训练一个模型，知道水果盘上的水果和别人手里拿着的水果，而不是苹果和橙子：底部集合的训练图片更加多样化和平衡](Images/aasc_0801.png)'
- en: 'Figure 8-1\. Use the top set of training images and you’ll accidentally train
    a model that knows the difference between fruit on a plate and fruit someone is
    holding rather than apples and oranges: the lower set of training images is more
    diverse and balanced'
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-1\. 使用顶部集合的训练图片，您将意外地训练一个模型，知道水果盘上的水果和别人手里拿着的水果，而不是苹果和橙子：底部集合的训练图片更加多样化和平衡
- en: In the real world, the distribution of types and categories is often not even
    or balanced. If you’re training an image recognition system to detect when a traffic
    light is red, green, or yellow, you’re going to have a lot more images of red
    and green traffic lights because traffic lights are either red or green for much
    longer than they’re yellow. With a representative real-world dataset, the model
    will learn only the dominant classes—and it can show strong accuracy without ever
    learning to recognize yellow traffic lights because they’re comparatively rare.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，各种类型和类别的分布通常是不均匀或不平衡的。如果您正在训练一个图像识别系统来检测交通灯是红色、绿色还是黄色，那么您将拥有更多红色和绿色交通灯的图片，因为交通灯是红色或绿色的时间比黄色长得多。使用一个真实代表性的数据集，模型将仅学习主导类别，并且可以显示出很强的准确性，而不必学习识别黄色交通灯，因为它们相对较少。
- en: That means you need to balance the training dataset so it has more equal numbers
    of all three traffic light states, probably with some close-up images that show
    the traffic lights without the background of the road and traffic, so the system
    isn’t learning the state of traffic flow rather than the state of the traffic
    lights. (It can be hard to get examples of underrepresented data, and you may
    have to look into using synthetic data.)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你需要平衡训练数据集，确保所有三种交通灯状态的数量大致相等，可能还需要一些特写图片，显示交通灯而不显示道路和交通背景，这样系统就不会学习交通流量状态而是交通灯状态。（获取少数类别数据的示例可能很困难，你可能需要考虑使用合成数据。）
- en: 'It’s important to split your training data and reserve part of the dataset
    for validation, and a separate portion for testing. It’s also important not to
    adjust the training and test sets so that the model performs better on the test
    dataset, because that makes the model vulnerable to overfitting: where the model
    fits the training data so well it fails on real-world data because it hasn’t learned
    the general patterns that allow it to work with new data. Take the time to build
    a test set with data that represents what the model will need to deal with in
    use.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 将训练数据拆分，并保留数据集的一部分用于验证，另一部分用于测试非常重要。还要注意不要调整训练和测试集以使模型在测试数据集上表现更好，因为这会使模型容易过拟合：模型在训练数据上拟合得很好，但在真实世界数据上失败，因为它没有学习到允许其处理新数据的一般模式。花时间构建一个包含模型需要处理内容的测试集是很重要的。
- en: To avoid overfitting, you can use cross-validation—splitting your data into
    different subsets and training a model on each. This also avoids the temptation
    to tweak the training set to get a better score, but the process will take longer
    because you’re training the model multiple times rather than just once, so you’ll
    usually have to choose that explicitly. Again, it’s important to document all
    these decisions.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免过拟合，您可以使用交叉验证——将数据分成不同的子集，并在每个子集上训练模型。这样做还能避免调整训练集以获得更高分数的诱惑，但由于需要多次训练模型而不是一次，因此过程会更加耗时，所以通常需要明确选择。再次强调，记录所有这些决策是非常重要的。
- en: Establish Performance Metrics
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确立性能指标
- en: Like any other kind of development, once you know what problem you need to solve
    with machine learning, you need to document what success will look like, so the
    project makes progress toward the right goal. Again, make sure the business users
    are involved here.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何其他类型的开发一样，一旦您知道需要用机器学习解决什么问题，就需要记录成功的标准，以便项目朝着正确的目标取得进展。再次确保业务用户参与其中。
- en: There are quite a few metrics to choose from for scoring the success of predictions;
    cloud AI services will automatically show you many of these for a model.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多可供选择的指标来评估预测成功的分数；云AI服务将自动展示许多这些指标给一个模型。
- en: 'When scoring the accuracy of a model, consider not just how many times the
    model gets the right answer (correctly identifying the color of the traffic light),
    which is the precision score, but also what’s known as recall: how many images
    of yellow traffic lights are correctly recognized rather than being marked as
    red or green? [Figure 8-2](#precision_and_recall_measure_how_often) shows how
    those scores are calculated.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估模型准确性时，不仅要考虑模型答对的次数（正确识别交通灯颜色），即精确度分数，还要考虑到召回率：有多少张黄灯的图像被正确识别，而不是标记为红色或绿色？[Figure 8-2](#precision_and_recall_measure_how_often)
    展示了如何计算这些分数。
- en: '![Precision and recall measure how often the model is right and which predictions
    the model is right about](Images/aasc_0802.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![精确度和召回率衡量模型的正确性及其正确预测](Images/aasc_0802.png)'
- en: Figure 8-2\. Precision and recall measure how often the model is right and which
    predictions the model is right about
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-2\. 精确度和召回率衡量模型的正确性及其正确预测
- en: 'There are other accuracy metrics that are useful for specific machine learning
    algorithms. One of the most commonly used metrics for regression tasks is *root-mean-square
    error* (RMSE). This is defined as the square root of the average squared distance
    between the actual score and the predicted score, as shown here:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他适用于特定机器学习算法的准确性指标。对于回归任务中最常用的指标之一是*均方根误差*（RMSE）。其定义为实际得分与预测得分之间的平均平方距离的平方根，如下所示：
- en: <math display="block"><mrow><mtext>RMSE</mtext> <mo>=</mo> <msqrt><mrow><mfrac><mn>1</mn>
    <mi>n</mi></mfrac> <msubsup><mo>∑</mo> <mrow><mi>j</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mi>n</mi></msubsup> <msup><mrow><mo>(</mo> <msub><mi>y</mi> <mi>j</mi></msub>
    <mo>-</mo> <msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover> <mi>j</mi></msub>
    <mo>)</mo></mrow> <mn>2</mn></msup></mrow></msqrt></mrow></math>
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mtext>RMSE</mtext> <mo>=</mo> <msqrt><mrow><mfrac><mn>1</mn>
    <mi>n</mi></mfrac> <msubsup><mo>∑</mo> <mrow><mi>j</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mi>n</mi></msubsup> <msup><mrow><mo>(</mo> <msub><mi>y</mi> <mi>j</mi></msub>
    <mo>-</mo> <msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover> <mi>j</mi></msub>
    <mo>)</mo></mrow> <mn>2</mn></msup></mrow></msqrt></mrow></math>
- en: Here, *y[j]* denotes the true value for the i^(th) data point, and *ŷ[j]* denotes
    the predicted value. One intuitive way to understand this formula is that it is
    the Euclidean distance between the vector of the true values and the vector of
    the predicted values, averaged by *n*, where *n* is the number of data points.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*y[j]* 表示第 i 个数据点的真实值，*ŷ[j]* 表示预测值。理解这个公式的一种直观方法是，它是真实值向量与预测值向量之间的欧氏距离，除以
    *n*，其中 *n* 是数据点的数量，取平均值。
- en: Also, think about the implications of a prediction or classification being wrong.
    Are false positives or false negatives more of a problem? Is it worse to miss
    an opportunity because a deal had an inaccurately low prediction of success, or
    to spend time on deals that don’t result in a sale because they were scored too
    highly? These decisions are even more significant if you might be excluding or
    penalizing people, so you need to work through the responsible AI principles we
    looked at in the previous chapter as you decide what models provide good enough
    results to use.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请考虑预测或分类错误的影响。假阳性或假阴性更成问题？因为一笔交易的成功预测过低而错过机会更糟糕，还是因为分数过高而花费时间但交易最终未能成功更糟糕？如果可能会排除或处罚人员，则需要在决定哪些模型提供足够好的结果时，遵循我们在前一章中讨论的负责任的
    AI 原则。
- en: Warning
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Measuring the accuracy of results from the OpenAI Service is a more open-ended
    question because it depends on both the business outcome you’re trying to achieve
    and the nuance and complexity of the task you’re giving it. You’ll usually start
    by using the “few-shot” approach of giving just a few examples as a proof of concept
    to see if the service is a good fit and then fine-tuning the model with further
    prompts and completion examples. By design, you’ll get different results from
    the OpenAI API every time you send the same prompt, and you can use the temperature
    parameters to control how much variation you get in the responses. Choosing between
    two suggested paragraphs of text is often a very subjective decision, so you need
    to think about how to quantify “accuracy” and “suitability” for your specific
    problem, and you need to consider safety as well as accuracy (for example, are
    the responses generated appropriate for the context you’re using them in, and
    are you presenting them with the right level of transparency). Some responses
    may be blank, so you’ll need a way to screen those out.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 测量 OpenAI 服务结果的准确性是一个更开放的问题，因为它取决于您试图实现的业务结果以及您提供的任务的微妙和复杂性。通常，您会从使用“few-shot”方法开始，只需提供几个示例作为概念验证，看看该服务是否合适，然后通过进一步的提示和完成示例来微调模型。按设计，每次发送相同提示到
    OpenAI API，您都会获得不同的结果，并且您可以使用温度参数来控制响应中的变化程度。在选择两个建议的文本段落之间时，往往是一个非常主观的决定，因此您需要考虑如何量化“准确性”和“适用性”，以解决您的具体问题，并且您需要考虑安全性以及准确性（例如，生成的响应是否适合您使用的上下文，并且是否以适当的透明度呈现）。有些响应可能为空白，因此您需要一种方法来筛选它们。
- en: Whichever accuracy metrics are relevant to your particular machine learning
    model, you need to connect them to the business outcomes you want to achieve.
    A model can be accurate without being useful if what you generate isn’t helping
    someone make their decision or complete their task, so consider model scores in
    context. Sentiment analysis might detect with perfect accuracy that a customer
    is upset when speaking to a call center agent; if that’s because they’re calling
    to cancel the subscription of a family member who recently died, there’s nothing
    that the agent can do to “fix” the situation, and offering discounts or other
    retention incentives would be inappropriate.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您的特定机器学习模型的准确度指标如何，都需要将它们与您希望实现的业务结果联系起来。如果您生成的内容无助于某人做出决策或完成任务，那么即使模型准确，也可能没有用处，因此请考虑模型分数的上下文。情感分析可能会完美地检测到客户在与呼叫中心代理人交谈时的不满；如果这是因为他们打电话取消家庭成员最近去世的订阅，那么代理人无法做任何“修复”情况的事情，提供折扣或其他留存激励措施也是不合适的。
- en: Transparency and Trust
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 透明度和信任
- en: In the previous chapter we looked at how important it is to be able to understand
    and explain models and the decisions made using them. Your machine learning process
    needs to include sharing the accuracy and confidence levels of a model and explaining
    how it works and what it’s good or bad at predicting to the people who will use
    it and the people who will be affected by it. That might mean presenting to a
    business team and other stakeholders what the metrics are for the model, including
    accuracy, what the confidence levels actually mean in practice, and what features
    the model depends on, documenting those details for customers or simply tracking
    them in case of an audit.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们看到理解和解释模型以及使用它们做出的决策的重要性。你的机器学习过程需要包括分享模型的准确性和置信水平，并解释它的工作原理以及它在预测时的优势和劣势，以及会使用它和受它影响的人们。这可能意味着向业务团队和其他利益相关者展示模型的指标，包括准确性，实际置信水平的含义，以及模型依赖的特征，为客户记录这些详细信息或仅在审计时跟踪它们。
- en: Experiment, Update, and Move On
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验、更新和继续前行
- en: The metrics for a model should help you understand how well it does at solving
    the problem and answering the question you set for it. Although you might be able
    to get good results from a prebuilt cloud AI service immediately, in many cases
    you will want to experiment with different models, different algorithm and hyperparameter
    choices, or—when you’re customizing a model—different training datasets to see
    if you get better results.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的指标应帮助你了解它在解决问题和回答你为其设定的问题时的表现如何。虽然你可能能够立即从预构建的云AI服务中获得良好的结果，但在许多情况下，你将希望尝试不同的模型、不同的算法和超参数选择，或者在定制模型时尝试不同的训练数据集，以查看是否可以获得更好的结果。
- en: 'Part of the good data culture we looked at earlier in the chapter is embracing
    experimentation and respecting the results of those experiments:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章早些时候讨论过的良好数据文化的一部分是接受实验并尊重这些实验的结果：
- en: Define hypotheses clearly but don’t cling to them.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明确定义假设，但不要固守。
- en: Be willing to learn from experiments (successes and failures).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 愿意从实验中学习（成功和失败）。
- en: Look at what has worked for other people.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看看别人做过什么有效的事情。
- en: Share the learning with peers.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与同行分享学习。
- en: Promote successful experiments to production.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将成功的实验推广到生产环境。
- en: Understand that failure is a valid outcome of an experiment.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解失败是实验的一种有效结果。
- en: Quickly move on to the next hypothesis.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速转移到下一个假设。
- en: Refine the next experiment.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化下一个实验。
- en: 'Track model performance over time as well as when you first create it, and
    look at how well it correlates with metrics like sales, revenue, customer satisfaction,
    and the other outcomes you care about. As circumstances change, you may need to
    update, retire, or replace a model: document the end of the machine learning process
    as well as the beginning.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移跟踪模型的性能，以及在首次创建它时，并查看它与销售、收入、客户满意度以及其他你关心的结果之间的相关性。随着情况的变化，你可能需要更新、淘汰或替换模型：记录机器学习过程的结束以及开始。
- en: Collaboration, Not Silos
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合作而非孤立
- en: Knowing when a model needs updating—or even if it’s useful in the first place—means
    not working in isolation. The appeal of prebuilt cloud AI services and AI integration
    in low-code systems is that they allow business users to use machine learning
    to solve their own problems, but when there are developers, data engineers, or
    data scientists involved, they will need to collaborate with each other and with
    the business team that will be using the machine learning model.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 知道何时需要更新模型——甚至是否首先有用——意味着不是孤立工作。预构建的云AI服务和低代码系统中的AI集成吸引了企业用户使用机器学习解决自己的问题，但当涉及到开发人员、数据工程师或数据科学家时，他们将需要彼此合作，也需要与将使用机器学习模型的业务团队合作。
- en: 'Set up your machine learning process so that they all have the right tools
    and access to work on the areas that matter to them—ingesting and preparing data,
    building, deploying, and updating models for data scientists; building, maintaining,
    deploying, and updating the application for developers—but that they can easily
    work together. Cloud AI platforms like Azure Machine Learning simplify this with
    RBAC and integration to other systems like Power Platform: data scientists can
    have access to the full machine learning workspace, data engineers get access
    to data preparation and labeling tools, and the machine learning models can be
    shared with application developers and low-code business users.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 设置你的机器学习流程，使他们都有正确的工具和访问权限来处理对他们重要的领域——数据的摄入和准备，为数据科学家构建、部署和更新模型；为开发人员构建、维护、部署和更新应用程序——但他们可以轻松地共同工作。像Azure机器学习这样的云AI平台通过RBAC和与Power
    Platform等其他系统的集成简化了这一过程：数据科学家可以访问完整的机器学习工作区，数据工程师可以访问数据准备和标记工具，机器学习模型可以与应用程序开发人员和低代码业务用户共享。
- en: Wrapping It Up
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter we’ve looked at how putting responsible AI into your machine
    learning process helps you to build best practices that protect your customers
    and your organization and to get the best performance out of your machine learning
    models and datasets.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到将负责任的人工智能融入到您的机器学习流程中，可以帮助您建立保护客户和组织的最佳实践，并获得最佳的机器学习模型和数据集性能。
- en: Remember that this is as much about building a responsible data culture based
    on widespread data literacy as about any specific techniques or tools. It’s also
    about defining clearly what problems you’re trying to solve, which means understanding
    the business scenario.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这不仅仅是基于广泛数据素养建立负责任数据文化的问题，也与任何具体技术或工具一样重要。这也涉及清楚定义您试图解决的问题，这意味着理解业务场景。
- en: One advantage of cloud AI services is that it removes the need to manage the
    infrastructure your machine learning systems run on—or even, with Cognitive Services,
    the need to build those systems yourself. Want to take a peek behind the scenes
    of Cognitive Services to see how Microsoft puts these responsible AI principles
    and machine learning best practices into action, at scale? Check out the next
    section.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 云AI服务的一个优势是它消除了您需要管理机器学习系统运行的基础设施的需求——甚至是使用认知服务构建这些系统的需求。想要窥探认知服务背后的幕后运作，看看微软如何大规模地实施这些负责任的AI原则和机器学习最佳实践？请查看下一节。
