- en: 'Chapter 3\. Kubeflow Design: Beyond the Basics'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章\. Kubeflow 设计：进阶内容
- en: You made it through two chapters. Well done. So far you have decided to learn
    Kubeflow and worked through a simple example. Now we want to take a step back
    and look at each component in detail. [Figure 3-1](#ch3_kf_arch) shows the main
    Kubeflow components and the role they play in the overall architecture.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经通过了两章。做得好。到目前为止，您已经决定学习 Kubeflow 并完成了一个简单的示例。现在，我们希望退后一步，详细查看每个组件。[图 3-1](#ch3_kf_arch)
    显示了主要的 Kubeflow 组件及其在整体架构中的角色。
- en: '![Kubeflow Architecture](Images/kfml_0301.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Kubeflow 架构](Images/kfml_0301.png)'
- en: Figure 3-1\. Kubeflow architecture
  id: totrans-3
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. Kubeflow 架构
- en: Essentially, we’ll look at the core elements that make up our example deployment
    as well as the supporting pieces. In the chapters that follow, we will dig into
    each of these sections in greater depth.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Essentially, we’ll look at the core elements that make up our example deployment
    as well as the supporting pieces. In the chapters that follow, we will dig into
    each of these sections in greater depth.
- en: That said, let’s get started.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，让我们开始吧。
- en: Getting Around the Central Dashboard
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 环顾中央仪表板
- en: Your main interface to Kubeflow is the central dashboard (see [Figure 3-2](#central_dashboard)),
    which allows you to access the majority of Kubeflow components. Depending on your
    Kubernetes provider, it might take up to half an hour to have your ingress become
    available.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您与 Kubeflow 的主要交互界面是中央仪表板（参见 [图 3-2](#central_dashboard)），它允许您访问大多数 Kubeflow
    组件。根据您的 Kubernetes 提供程序，您的入口可能需要多达半小时才能变得可用。
- en: '![The Central Dashboard](Images/kfml_0302.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![中央仪表板](Images/kfml_0302.png)'
- en: Figure 3-2\. The central dashboard
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. 中央仪表板
- en: Note
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Note
- en: While it is meant to be automatic, if you don’t have a namespace created for
    your work, follow [Kubeflow’s “Manual profile creation” instructions](https://oreil.ly/_6iC5).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它应该是自动的，但如果您没有为您的工作创建命名空间，请按照[Kubeflow 的“手动配置文件创建”说明](https://oreil.ly/_6iC5)操作。
- en: From the home page of the central dashboard you can access Kubeflow’s Pipelines,
    Notebooks, Katib (hyperparameter tuning), and the artifact store. We will cover
    the design of these components and how to use them next.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从中央仪表板的主页，您可以访问 Kubeflow 的流水线、笔记本、Katib（超参数调优）和 artifact 存储。接下来我们将介绍这些组件的设计及其使用方法。
- en: Notebooks (JupyterHub)
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Notebooks (JupyterHub)
- en: 'The first step of most projects is some form of prototyping and experimentation.
    Kubeflow’s tool for this purpose is [JupyterHub](https://jupyter.org/hub)—a multiuser
    hub that spawns, manages, and proxies multiple instances of a single-user [Jupyter
    notebook](https://oreil.ly/C4dtQ). Jupyter notebooks support the whole computation
    process: developing, documenting, and executing code, as well as communicating
    the results.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数项目的第一步是某种形式的原型设计和实验。Kubeflow 用于此目的的工具是[JupyterHub](https://jupyter.org/hub)——一个多用户中心，可以生成、管理和代理多个单用户[Jupyter
    笔记本](https://oreil.ly/C4dtQ)实例。Jupyter 笔记本支持整个计算过程：开发、文档编写、代码执行以及结果通信。
- en: To access JupyterHub, go to the main Kubeflow page and click the notebook button.
    On the notebook page, you can connect to existing servers or create a new one.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问 JupyterHub，请转到主 Kubeflow 页面并单击笔记本按钮。在笔记本页面上，您可以连接到现有服务器或创建一个新服务器。
- en: To create a new server, you need to specify the server name and namespace, pick
    an image (from CPU optimized, GPU optimized, or a custom image that you can create),
    and specify resource requirements—CPU/memory, workspace, data volumes, custom
    configuration, and so on. Once the server is created, you can connect to it and
    start creating and editing notebooks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个新服务器，您需要指定服务器名称和命名空间，选择一个镜像（从CPU优化、GPU优化或您可以创建的自定义镜像中选择），并指定资源需求——CPU/内存、工作空间、数据卷、自定义配置等等。一旦服务器创建完成，您可以连接到它并开始创建和编辑笔记本。
- en: 'In order to allow data scientists to do cluster operations without leaving
    the notebook’s environment, Kubeflow adds [kubectl](https://oreil.ly/i-PFC) to
    the provided notebook images, which allows developers to use notebooks to create
    and manage Kubernetes resources. The Jupyter notebook pods run under a special
    service account `default-editor`, which has namespace-scoped permissions to the
    following Kubernetes resources:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了允许数据科学家在不离开笔记本环境的情况下进行集群操作，Kubeflow 在提供的笔记本镜像中添加了[kubectl](https://oreil.ly/i-PFC)，这使开发人员可以使用笔记本创建和管理
    Kubernetes 资源。Jupyter 笔记本 pod 运行在特殊的服务账户 `default-editor` 下，该账户在命名空间范围内对以下 Kubernetes
    资源有权限：
- en: Pods
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pods
- en: Deployments
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deployments
- en: Services
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Services
- en: Jobs
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jobs
- en: TFJobs
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TFJobs
- en: PyTorchJobs
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorchJobs
- en: 'You can bind this account to a custom role, in order to limit/extend permissions
    of the notebook server. This allows notebook developers to execute all of the
    (allowed by role) Kubernetes commands without leaving the notebook environment.
    For example, the creation of a new Kubernetes resource can be done by running
    the following command directly in a Jupyter notebook:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将此帐户绑定到自定义角色，以限制/扩展笔记本服务器的权限。这允许笔记本开发人员在不离开笔记本环境的情况下执行所有（由角色允许的）Kubernetes
    命令。例如，可以通过在 Jupyter 笔记本中直接运行以下命令来创建一个新的 Kubernetes 资源：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The contents of your `yaml` file will determine what resource is created. If
    you’re not used to making Kubernetes resources, don’t worry—Kubeflow’s pipelines
    include tools to make them for you.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 `yaml` 文件的内容将决定创建的资源。如果你不习惯创建 Kubernetes 资源，不用担心——Kubeflow 的管道包含工具，可以为你创建它们。
- en: To further increase Jupyter capabilities, Kubeflow also provides support in
    the notebooks for such important Kubeflow components as Pipelines and metadata
    management (described later in [“Metadata”](#metadata_manage)). Jupyter notebooks
    can also directly launch distributed training jobs.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步增强 Jupyter 的功能，Kubeflow 还在笔记本中提供了对管道和元数据管理的支持（稍后在 [“元数据”](#metadata_manage)
    中描述）。Jupyter 笔记本还可以直接启动分布式训练作业。
- en: Training Operators
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练操作符
- en: 'JupyterHub is a great tool for initial experimentation with the data and prototyping
    ML jobs. However, when moving to train in production, Kubeflow provides several
    training components to automate the execution of machine learning algorithms,
    including:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: JupyterHub 是进行数据初步实验和原型化 ML 作业的好工具。但是，当转向在生产环境中进行训练时，Kubeflow 提供了多个训练组件来自动执行机器学习算法，包括：
- en: '[Chainer training](https://oreil.ly/AjfwS)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Chainer 训练](https://oreil.ly/AjfwS)'
- en: '[MPI training](https://oreil.ly/SK19W)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPI 训练](https://oreil.ly/SK19W)'
- en: '[Apache MXNet training](https://oreil.ly/FvDdQ)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Apache MXNet 训练](https://oreil.ly/FvDdQ)'
- en: '[PyTorch training](https://oreil.ly/0z4j6)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch 训练](https://oreil.ly/0z4j6)'
- en: '[TensorFlow training](https://oreil.ly/YMGKx)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow 训练](https://oreil.ly/YMGKx)'
- en: In Kubeflow, distributed training jobs are managed by application-specific controllers,
    known as operators. These operators extend the Kubernetes APIs to create, manage,
    and manipulate the state of resources. For example, to run a distributed TensorFlow
    training job, the user just needs to provide a specification that describes the
    desired state (number of workers and parameter servers, etc.), and the TensorFlow
    operator component will take care of the rest and manage the life cycle of the
    training job.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubeflow 中，分布式训练作业由应用程序特定的控制器管理，称为操作符。这些操作符扩展了 Kubernetes API 来创建、管理和操作资源的状态。例如，要运行一个分布式
    TensorFlow 训练作业，用户只需提供描述期望状态的规范（工作节点数和参数服务器等），TensorFlow 操作符组件将处理其余并管理训练作业的生命周期。
- en: These operators allow the automation of important deployment concepts such as
    scalability, observability, and failover. They can also be used by pipelines to
    chain their execution with the execution of other components of the system.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些操作符允许重要部署概念如可伸缩性、可观察性和故障转移的自动化。它们还可以被管道用来链式执行系统其他组件的执行。
- en: Kubeflow Pipelines
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubeflow 管道
- en: In addition to providing specialized parameters implementing specific functionality,
    Kubeflow has [Pipelines](https://oreil.ly/QZjNV), which allows you to orchestrate
    the execution of machine learning applications. This implementation is based on
    [Argo Workflows](https://oreil.ly/6PsLK), an open source, container-native workflow
    engine for Kubernetes. Kubeflow installs all of the Argo components.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提供实施特定功能的专用参数外，Kubeflow 还拥有 [Pipelines](https://oreil.ly/QZjNV)，允许你编排机器学习应用的执行。这一实现基于
    [Argo Workflows](https://oreil.ly/6PsLK)，一个面向 Kubernetes 的开源容器本地工作流引擎。Kubeflow
    安装所有 Argo 组件。
- en: 'At a high level, the execution of a pipeline contains the following [components](https://oreil.ly/QZjNV):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，管道的执行包含以下 [组件](https://oreil.ly/QZjNV)：
- en: Python SDK
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Python SDK
- en: You create components or specify a pipeline using the Kubeflow Pipelines [domain-specific
    language](https://oreil.ly/c2DRj) (DSL).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 Kubeflow 管道的 [领域特定语言](https://oreil.ly/c2DRj)（DSL）创建组件或指定管道。
- en: DSL compiler
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: DSL 编译器
- en: The [DSL compiler](https://oreil.ly/5o2Yw) transforms your pipeline’s Python
    code into a static configuration (YAML).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[DSL 编译器](https://oreil.ly/5o2Yw) 将你的管道的 Python 代码转换为静态配置（YAML）。'
- en: Pipeline Service
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Pipeline 服务
- en: The Pipeline Service creates a pipeline run from the static configuration.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Pipeline 服务从静态配置创建管道运行。
- en: Kubernetes resources
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 资源
- en: The Pipeline Service calls the Kubernetes API server to create the necessary
    Kubernetes [custom resource definitions](https://oreil.ly/5wPjy) (CRDs) to run
    the pipeline.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线服务调用 Kubernetes API 服务器来创建必要的 Kubernetes [自定义资源定义](https://oreil.ly/5wPjy)（CRD）来运行流水线。
- en: Orchestration controllers
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 编排控制器
- en: A set of orchestration controllers execute the containers needed to complete
    the pipeline execution specified by the Kubernetes resources (CRDs). The containers
    execute within Kubernetes Pods on virtual machines. An example controller is the
    [Argo Workflow](https://oreil.ly/leX50) controller, which orchestrates task-driven
    workflows.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一组编排控制器执行完成由 Kubernetes 资源（CRD）指定的流水线执行所需的容器。这些容器在虚拟机上的 Kubernetes Pod 中执行。一个示例控制器是
    [Argo Workflow](https://oreil.ly/leX50) 控制器，它编排任务驱动的工作流程。
- en: Artifact storage
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 工件存储
- en: 'The Kubernetes Pods store two kinds of data:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes Pod 存储两种类型的数据：
- en: Metadata
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据
- en: Experiments, jobs, runs, single scalar metrics (generally aggregated for the
    purposes of sorting and filtering), etc. Kubeflow Pipelines stores the metadata
    in a MySQL database.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 实验、作业、运行、单一标量指标（通常用于排序和过滤目的的汇总指标），等等。Kubeflow Pipelines 将元数据存储在 MySQL 数据库中。
- en: Artifacts
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 工件
- en: Pipeline packages, views, large-scale metrics like time series (usually used
    for investigating an individual run’s performance and for debugging), etc. Kubeflow
    Pipelines stores the artifacts in an artifact store like [MinIO server](https://docs.minio.io),
    [Google Cloud Storage (GCS)](https://oreil.ly/k1bQz), or [Amazon S3](https://aws.amazon.com/s3).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线包、视图、如时间序列等大规模指标（通常用于调查单个运行的性能和调试），等等。Kubeflow Pipelines 将工件存储在类似于 [MinIO
    服务器](https://docs.minio.io)、[Google Cloud Storage (GCS)](https://oreil.ly/k1bQz)
    或 [Amazon S3](https://aws.amazon.com/s3) 的工件存储中。
- en: Kubeflow Pipelines gives you the ability to make your machine learning jobs
    repeatable and handle new data. It provides an intuitive DSL in Python to write
    your pipelines with. Your pipelines are then compiled down to an existing Kubernetes
    workflow engine (currently Argo Workflows). Kubeflow’s pipeline components make
    it easy to use and coordinate the different tools required to build an end-to-end
    machine learning project. On top of that, Kubeflow can track both data and metadata,
    improving how we can understand our jobs. For example, in [Chapter 5](ch05.xhtml#data_and_feature_prep)
    we use these artifacts to understand the schema. Pipelines can expose the parameters
    of the underlying machine learning algorithms, allowing Kubeflow to perform tuning.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow Pipelines 允许您使您的机器学习作业可重复，并处理新数据。它提供了一个直观的 Python DSL 来编写流水线。然后将您的流水线编译为现有的
    Kubernetes 工作流引擎（目前是 Argo Workflows）。Kubeflow 的流水线组件使得使用和协调构建端到端机器学习项目所需的不同工具变得简单。此外，Kubeflow
    可以跟踪数据和元数据，改进我们理解作业的方式。例如，在 [第 5 章](ch05.xhtml#data_and_feature_prep) 中，我们使用这些工件来理解模式。流水线可以暴露出底层机器学习算法的参数，使得
    Kubeflow 能够执行调整。
- en: Hyperparameter Tuning
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超参数调整
- en: Finding the right set of hyperparameters for your training model can be a challenging
    task. Traditional methodologies such as grid search can be time-consuming and
    quite tedious. Most existing hyperparameter systems are tied to one machine learning
    framework and have only a few options for searching the parameter space.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为您的训练模型找到合适的超参数集合可能是一项具有挑战性的任务。传统的方法如网格搜索可能耗时且相当乏味。大多数现有的超参数系统与一个机器学习框架绑定，并且在搜索参数空间时只有几个选项。
- en: Kubeflow provides a component (called Katib) that allows users to perform hyperparameter
    optimizations easily on Kubernetes clusters. Katib is inspired by [Google Vizier](https://oreil.ly/UInbP),
    a black-box optimization framework. It leverages advanced searching algorithms
    such as Bayesian optimization to find optimal hyperparameter configurations.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 提供了一个组件（称为 Katib），允许用户在 Kubernetes 集群上轻松执行超参数优化。Katib 受到 [Google Vizier](https://oreil.ly/UInbP)
    的启发，这是一个黑盒优化框架。它利用高级搜索算法如贝叶斯优化来找到最优的超参数配置。
- en: Katib supports [hyperparameter tuning](https://oreil.ly/O5mC9) and can run with
    any deep learning framework, including TensorFlow, MXNet, and PyTorch.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Katib 支持 [超参数调整](https://oreil.ly/O5mC9)，可以与包括 TensorFlow、MXNet 和 PyTorch 在内的任何深度学习框架一起运行。
- en: 'As in Google Vizier, Katib is based on four main concepts:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如同 Google Vizier，Katib 基于四个主要概念：
- en: Experiment
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 实验
- en: A single optimization run over a feasible space. Each experiment contains a
    configuration describing the feasible space, as well as a set of trials. It is
    assumed that objective function *f(x)* does not change in the course of the experiment.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在可行空间上进行的单次优化运行。每个实验包含描述可行空间的配置，以及一组试验。假设客观函数*f(x)*在实验过程中不会改变。
- en: Trial
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 试验
- en: A list of parameter values, *x*, that will lead to a single evaluation of *f(x)*.
    A trial can be “completed,” which means that it has been evaluated and the objective
    value *f(x)* has been assigned to it, otherwise it is “pending.” One trial corresponds
    to one job.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一组参数值，*x*，将导致*f(x)*的单次评估。一个试验可以“完成”，这意味着它已经被评估并且客观值*f(x)*已经被分配，否则它是“挂起”的。一个试验对应一个作业。
- en: Job
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 作业
- en: A process responsible for evaluating a pending trial and calculating its objective
    value.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 负责评估挂起试验并计算其客观值的过程。
- en: Suggestion
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 建议
- en: 'An algorithm to construct a parameter set. Currently, Katib supports the following
    exploration algorithms:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 构建参数集的算法。目前，Katib 支持以下探索算法：
- en: Random
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机
- en: Grid
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网格
- en: '[Hyperband](https://oreil.ly/LlCKw)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hyperband](https://oreil.ly/LlCKw)'
- en: '[Bayesian optimization](https://oreil.ly/Pa83u)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[贝叶斯优化](https://oreil.ly/Pa83u)'
- en: Using these core concepts, you can increase your model’s performance. Since
    Katib is not tied to one machine learning library, you can explore new algorithms
    and tools with minimal modifications.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这些核心概念，您可以提高模型的性能。由于 Katib 不限于一种机器学习库，因此您可以在几乎不进行修改的情况下探索新的算法和工具。
- en: Model Inference
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型推断
- en: Kubeflow makes it easy to deploy machine learning models in production environments
    at scale. It provides several model serving options, including [TFServing](https://oreil.ly/Hp2sb),
    [Seldon serving](https://oreil.ly/sWc71), [PyTorch serving](https://oreil.ly/bLJxg),
    and [TensorRT](https://oreil.ly/fuv-7). It also provides an umbrella implementation,
    [KFServing](https://oreil.ly/qEvqq), which generalizes the model inference concerns
    of autoscaling, networking, health checking, and server configuration.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 使得在生产环境中大规模部署机器学习模型变得容易。它提供了多种模型服务选项，包括[TFServing](https://oreil.ly/Hp2sb)、[Seldon
    serving](https://oreil.ly/sWc71)、[PyTorch serving](https://oreil.ly/bLJxg)和[TensorRT](https://oreil.ly/fuv-7)。它还提供了一个总体实现，[KFServing](https://oreil.ly/qEvqq)，它通用化了模型推断的自动扩展、网络、健康检查和服务器配置等问题。
- en: 'The overall implementation is based on leveraging [Istio](https://istio.io)
    (covered later) and [Knative serving](https://knative.dev)—serverless containers
    on Kubernetes. As defined in the [Knative documentation](https://oreil.ly/h6O1E),
    the Knative serving project provides middleware primitives that enable:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 整体实现基于利用[Istio](https://istio.io)（稍后详述）和[Knative serving](https://knative.dev)——基于
    Kubernetes 的无服务器容器。正如在[Knative 文档](https://oreil.ly/h6O1E)中定义的那样，Knative serving
    项目提供中间件原语，使以下功能成为可能：
- en: Rapid deployment of serverless containers
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器容器的快速部署
- en: Automatic scaling up and down to zero
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动扩展至零和缩减
- en: Routing and network programming for Istio components
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Istio 组件的路由和网络编程
- en: Since model serving is inherently spiky, rapid scaling up and down is important.
    Knative serving simplifies the support for continuous model updates, by automatically
    routing requests to newer model deployments. This requires scaling down to zero
    (minimizing resource utilization) for unused models while keeping them available
    for rollbacks. Since Knative is cloud native it benefits from its underlying infrastructure
    stack and therefore provides all the monitoring capabilities that exist within
    Kubernetes, such as logging, tracing, and monitoring. KFServing also makes use
    of [Knative eventing](https://oreil.ly/fpLrH) to give optional support for pluggable
    event sources.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型服务本质上是尖锐的，快速的扩展和缩减至零至关重要。Knative serving 简化了对连续模型更新的支持，通过自动将请求路由到较新的模型部署中。这需要将未使用的模型缩减至零（最小化资源利用），同时保持可供回滚使用。由于
    Knative 是云原生的，它从其基础设施堆栈中受益，并因此提供了所有存在于 Kubernetes 中的监控功能，例如日志记录、跟踪和监控。KFServing
    还利用[Knative 事件](https://oreil.ly/fpLrH)提供可选支持可插拔事件源。
- en: 'Similar to Seldon, every KFServing deployment is an orchestrator, wiring together
    the following components:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 Seldon，每个 KFServing 部署都是一个编排者，将以下组件连接在一起：
- en: Preprocessor
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理器
- en: An optional component responsible for the transformation of the input data into
    content/format required for model serving
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 负责将输入数据转换为模型服务所需的内容/格式的可选组件
- en: Predictor
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 预测器
- en: A mandatory component responsible for an actual model serving
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 负责实际模型服务的必需组件
- en: Postprocessor
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理器
- en: An optional component responsible for the transformation/enriching of the model
    serving result into content/format required for output
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 负责将模型服务结果转换/丰富为输出所需内容/格式的可选组件
- en: Additional components can enhance one’s overall model serving implementation,
    but are outside of the main execution pipeline. Tools like outlier detection and
    model explainability can run in this environment without slowing down the overall
    system.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 其他组件可以增强整体模型服务的实现，但不属于主要执行流水线。例如异常检测和模型可解释性工具可以在此环境中运行，而不会减慢整体系统速度。
- en: While all of these individual components and techniques have existed for a long
    time, having them integrated into the serving system of Kubeflow reduces the complexity
    involved in bringing new models into production.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些独立组件和技术已存在很长时间，但将它们集成到Kubeflow的服务系统中可以减少将新模型投入生产中的复杂性。
- en: In addition to the components directly supporting ML operations, Kubeflow also
    provides several supporting components.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 除了直接支持 ML 操作的组件外，Kubeflow 还提供几个支持组件。
- en: Metadata
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 元数据
- en: 'An important component of Kubeflow is metadata management, providing capabilities
    to capture and track information about a model’s creation. Many organizations
    build hundreds of models a day, but it’s very hard to manage all of a model’s
    related information. ML Metadata is both the infrastructure and a library for
    recording and retrieving metadata associated with an ML developer’s and data scientist’s
    workflow. The information, which can be registered in the metadata component includes:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 的一个重要组件是元数据管理，提供捕获和跟踪模型创建信息的能力。许多组织每天构建数百个模型，但很难管理所有与模型相关的信息。ML Metadata
    是记录和检索与 ML 开发人员和数据科学家工作流相关的元数据的基础设施和库。可以在元数据组件中注册的信息包括：
- en: Data sources used for the model’s creation
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于模型创建的数据来源
- en: The artifacts generated through the components/steps of the pipeline
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组件/流水线步骤生成的工件
- en: The executions of these components/steps
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些组件/步骤的执行
- en: The pipeline and associated lineage information
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流水线和相关的谱系信息
- en: ML Metadata tracks the inputs and outputs of all components and steps in an
    ML workflow and their lineage. This data powers several important features listed
    in [Table 3-1](#mlmd_features) and shown in [Figure 3-3](#metadata_dia).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ML Metadata 跟踪 ML 工作流中所有组件和步骤的输入和输出及其谱系。这些数据支持[表 3-1](#mlmd_features)中列出的几个重要功能，并显示在[图 3-3](#metadata_dia)中。
- en: Table 3-1\. Examples of ML Metadata operations
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-1\. ML Metadata 操作示例
- en: '| Operation | Example |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 示例 |'
- en: '| --- | --- |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| List all artifacts of a specific type. | All models that have been trained.
    |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 列出特定类型的所有工件。 | 所有已经训练的模型。 |'
- en: '| Compare two artifacts of the same type. | Compare results from two experiments.
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 比较相同类型的两个工件。 | 比较两个实验的结果。 |'
- en: '| Show a DAG of all related executions and their input and output artifacts.
    | Visualize the workflow of an experiment for debugging and discovery. |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 显示所有相关执行及其输入和输出工件的DAG。 | 可视化实验的工作流以进行调试和发现。 |'
- en: '| Display how an artifact was created. | See what data went into a model; enforce
    data retention plans. |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 显示工件的创建方式。 | 查看用于模型的数据；执行数据保留计划。 |'
- en: '| Identify all artifacts that were created using a given artifact. | Mark all
    models trained from a specific dataset with bad data. |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 标识所有使用特定工件创建的工件。 | 用有问题数据标记从特定数据集训练的所有模型。 |'
- en: '| Determine if an execution has been run on the same inputs before. | Determine
    whether a component/step has already completed the same work and the previous
    output can just be reused. |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 确定执行是否已在相同输入上运行过。 | 确定组件/步骤是否已完成相同工作，以便可以重用先前的输出。 |'
- en: '| Record and query context of workflow runs. | Track the owner and changes
    used for a workflow run; group the lineage by experiments; manage artifacts by
    projects. |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 记录和查询工作流运行的上下文。 | 跟踪工作流运行的所有者和变更；按实验分组谱系；按项目管理工件。 |'
- en: '![Metadata Diagram](Images/kfml_0303.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![Metadata Diagram](Images/kfml_0303.png)'
- en: Figure 3-3\. Metadata diagram
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. 元数据图
- en: Component Summary
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组件摘要
- en: The magic of Kubeflow is making all of these traditionally distinct components
    work together. While Kubeflow is certainly not the only system to bring together
    different parts of the machine learning landscape, it is unique in its flexibility
    in supporting a wide range of components. In addition to that, since it runs on
    standard Kubernetes, you can add your own components as desired. Much of this
    magic of tool integration happens inside of Kubeflow’s pipelines, but some of
    the support components are essential to allowing these tools to interact.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow的魔力在于使所有这些传统上不同的组件协同工作。虽然Kubeflow当然不是唯一一个将机器学习领域不同部分集成在一起的系统，但它在支持各种组件方面的灵活性是独一无二的。除此之外，由于它在标准Kubernetes上运行，您可以根据需要添加自己的组件。大部分工具集成的魔力发生在Kubeflow的管道内部，但一些支持组件对于让这些工具相互交互非常重要。
- en: Support Components
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持组件
- en: While these components aren’t explicitly exposed by Kubeflow, they play an important
    role in the overall Kubeflow ecosystem. Let’s briefly discuss each of them. We
    also encourage you to research them more on your own.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些组件并未明确暴露在Kubeflow之外，但它们在整个Kubeflow生态系统中扮演着重要角色。让我们简要讨论每一个。我们也鼓励您自行研究它们。
- en: MinIO
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MinIO
- en: The foundation of the pipeline architecture is shared storage. A common practice
    today is to keep data in external storage. Different cloud providers have different
    solutions, like Amazon S3, Azure Data Storage, Google Cloud Storage, etc. The
    variety of solutions makes it complex to port solutions from one cloud provider
    to another. To minimize this dependency, Kubeflow ships with MinIO, a high-performance
    distributed object storage server, designed for large-scale private cloud infrastructure.
    Not just for private clouds, MinIO can also act as a consistent gateway to public
    APIs.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线架构的基础是共享存储。今天的常见做法是将数据存储在外部存储中。不同的云提供商有不同的解决方案，如Amazon S3、Azure数据存储、Google
    Cloud Storage等。这种多样化的解决方案使得从一个云提供商迁移到另一个云提供商变得复杂。为了最小化这种依赖性，Kubeflow附带了MinIO，一个专为大规模私有云基础设施设计的高性能分布式对象存储服务器。MinIO不仅适用于私有云，还可以作为公共API的一致性网关。
- en: MinIO can be deployed in several different configurations. The default with
    Kubeflow is as a single container mode when MinIO runs using the Kubernetes built-in
    persistent storage on one container. Distributed MinIO lets you pool multiple
    volumes into a single object storage service.^([1](ch03.xhtml#idm45831180010264))
    It can also withstand multiple node failures and yet ensure full data protection
    (the number of failures depends on your replication configuration). MinIO Gateway
    provides S3 APIs on top of Azure Blob storage, Google Cloud storage, Gluster,
    or NAS storage. The gateway option is the most flexible, and allows you to create
    cloud independent implementation without scale limits.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: MinIO可以以多种不同的配置部署。在Kubeflow中的默认配置是单容器模式，当MinIO在一个容器中使用Kubernetes内置的持久存储时。分布式MinIO允许将多个卷汇集到一个单一的对象存储服务中。^([1](ch03.xhtml#idm45831180010264))它还可以承受多个节点故障，并确保完全的数据保护（故障数取决于您的复制配置）。MinIO网关在Azure
    Blob存储、Google Cloud存储、Gluster或NAS存储上提供了S3 API。网关选项最灵活，允许您创建无缩放限制的云独立实现。
- en: While Kubeflow’s default MinIO setup works, you will likely want to configure
    it further. Kubeflow installs both the MinIO server and UI. You can get access
    to the MinIO UI and explore what is stored, as seen in [Figure 3-4](#ex_minio_ui),
    by using port-forwarding, as in [Example 3-1](#ex_minio_fwd), or exposing an ingress.
    You can log in using Kubeflow’s default minio/minio123 user.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Kubeflow的默认MinIO设置可以使用，但您可能希望进一步配置它。Kubeflow安装了MinIO服务器和UI。您可以访问MinIO UI并探索存储的内容，如[图 3-4](#ex_minio_ui)中所示，通过端口转发（如[示例 3-1](#ex_minio_fwd)）或暴露入口。您可以使用Kubeflow的默认minio/minio123用户登录。
- en: Example 3-1\. Setting up port-forwarding
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-1\. 设置端口转发
- en: '[PRE1]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Minio dashboard](Images/kfml_03in01.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![Minio 仪表板](Images/kfml_03in01.png)'
- en: Figure 3-4\. MinIO dashboard
  id: totrans-122
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. MinIO 仪表板
- en: In addition, you can also install the [MinIO CLI (mc)](https://oreil.ly/_AAEv)
    to access your MinIO installation using commands from your workstation. For macOS,
    use Homebrew, as in [Example 3-2](#minio_homebrew). For Linux Ubuntu, use snap,
    as in [Example 3-3](#minio_linux).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还可以安装[MinIO CLI (mc)](https://oreil.ly/_AAEv)来使用工作站上的命令访问MinIO安装。对于macOS，使用Homebrew，如[示例 3-2](#minio_homebrew)中所示。对于Linux
    Ubuntu，使用snap，如[示例 3-3](#minio_linux)中所示。
- en: Example 3-2\. Install MinIO on Mac
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-2\. 在Mac上安装MinIO
- en: '[PRE2]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Example 3-3\. Install MinIO on Linux
  id: totrans-126
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-3\. 在Linux上安装MinIO
- en: '[PRE3]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You need to configure MinIO to talk to the correct endpoint, as in [Example 3-4](#minio_endpoint).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要配置 MinIO 以与正确的端点进行通信，如[示例 3-4](#minio_endpoint)所示。
- en: Example 3-4\. Configure MinIO client to talk to Kubeflow’s MinIO
  id: totrans-129
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-4\. 配置 MinIO 客户端与 Kubeflow 的 MinIO 对话
- en: '[PRE4]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Once you’ve configured the command line you can make new buckets, as in [Example 3-5](#minio_bucket),
    or change your setup.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你配置了命令行，你可以像[示例 3-5](#minio_bucket)那样创建新的存储桶，或者改变你的设置。
- en: Example 3-5\. Create a bucket with MinIO
  id: totrans-132
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-5\. 使用 MinIO 创建一个存储桶
- en: '[PRE5]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: MinIO exposes both native and S3-compatible APIs. The S3-compatible APIs are
    most important since most of our software can talk to S3, like TensorFlow and
    Spark.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: MinIO 提供本地和与 S3 兼容的 API。由于我们的大多数软件可以与 S3 对话，所以与 S3 兼容的 API 是最重要的。
- en: Warning
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Using MinIO with systems built on top of Hadoop (mostly Java-based) requires
    Hadoop 2.8 or higher.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用构建在 Hadoop 之上的系统（主要是基于 Java 的）需要 Hadoop 2.8 或更高版本。
- en: Kubeflow installation hardcodes MinIO credentials—minio/minio123, which you
    can use directly in your applications—but it’s generally a better practice to
    use a secret, especially if you might switch to regular S3. Kubernetes secrets
    provide you with a way to store credentials on the cluster separate from your
    application.^([2](ch03.xhtml#idm45831179889512)) To set one up for MinIO or S3,
    create a secret file like in [Example 3-6](#minio_secret). In Kubernetes secret
    values for the ID and key have to be base64 encoded. To encode a value, run the
    command `echo -n *xxx* | base64`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 安装将 MinIO 凭据硬编码为 minio/minio123，你可以直接在你的应用程序中使用，但通常最好使用密钥，特别是如果你可能会切换到常规的
    S3。Kubernetes 密钥为你提供了一种在集群上存储凭据的方式，与你的应用程序分开。^([2](ch03.xhtml#idm45831179889512))
    要为 MinIO 或 S3 设置一个密钥，可以创建一个类似于 [示例 3-6](#minio_secret) 的密钥文件。在 Kubernetes 中，ID
    和密钥的密钥值必须进行 base64 编码。要编码一个值，请运行命令 `echo -n *xxx* | base64`。
- en: Example 3-6\. Sample MinIO secret
  id: totrans-138
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-6\. MinIO 的示例密钥
- en: '[PRE6]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Save this YAML to the file *minioaccess.yaml*, and deploy the secret using the
    command `kubectl apply -f minioaccess.yaml`. Now that we understand data communication
    between pipeline stages, let’s work to understand network communication between
    components.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个 YAML 文件保存为 *minioaccess.yaml*，并使用命令 `kubectl apply -f minioaccess.yaml`
    部署这个密钥。现在我们理解了管道阶段之间的数据通信，让我们努力理解组件之间的网络通信。
- en: Istio
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Istio
- en: Another supporting component of Kubeflow is [Istio](https://istio.io)—a service
    mesh providing such vital features as service discovery, load balancing, failure
    recovery, metrics, monitoring, rate limiting, access control, and end-to-end authentication.
    Istio, as a service mesh, layers transparently onto a Kubernetes cluster. It integrates
    into any logging platform, or telemetry or policy system and promotes a uniform
    way to secure, connect, and monitor microservices. Istio implementation co-locates
    each service instance with a sidecar network proxy. All network traffic (HTTP,
    REST, gRPC, etc.) from an individual service instance flows via its local sidecar
    proxy to the appropriate destination. Thus, the service instance is not aware
    of the network at large and only knows about its local proxy. In effect, the distributed
    system network has been abstracted away from the service programmer.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 的另一个支持组件是[Istio](https://istio.io)，一个服务网格，提供诸如服务发现、负载均衡、故障恢复、指标、监控、速率限制、访问控制和端到端认证等重要功能。Istio
    作为一个服务网格，透明地层叠在 Kubernetes 集群之上。它可以集成到任何日志平台、遥测或策略系统，并推广一种统一的方式来保护、连接和监控微服务。Istio
    的实现将每个服务实例与一个旁路网络代理（sidecar）共存。所有来自单个服务实例的网络流量（HTTP、REST、gRPC 等）都通过其本地旁路代理流向适当的目标。因此，服务实例并不知晓整个网络，它只知道其本地代理。实际上，分布式系统网络已经被从服务程序员的视角中抽象出来。
- en: Istio implementation is logically split into a data plane and control plane.
    The data plane is composed of a set of intelligent proxies. These proxies mediate
    and control all network communication between pods. The control plane manages
    and configures the proxies to route traffic.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Istio 的实现在逻辑上分为数据平面和控制平面。数据平面由一组智能代理组成。这些代理中介和控制所有 pod 之间的网络通信。控制平面管理和配置代理以路由流量。
- en: 'The main components of Istio are:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Istio 的主要组件包括：
- en: '[Envoy](https://oreil.ly/7i49v)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[Envoy](https://oreil.ly/7i49v)'
- en: 'Istio data plane is based on Envoy proxy, which provides features like failure
    handling (for example, health checks and bounded retries), dynamic service discovery,
    and load balancing. Envoy has many built-in features, including:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Istio 数据平面基于 Envoy 代理，提供故障处理（例如健康检查和有界重试）、动态服务发现和负载均衡等功能。Envoy 具有许多内置功能，包括：
- en: Dynamic service discovery
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态服务发现
- en: Load balancing
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负载均衡
- en: TLS termination
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TLS 终止
- en: HTTP/2 and gRPC proxies
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP/2 和 gRPC 代理
- en: Circuit breakers
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 断路器
- en: Health checks
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 健康检查
- en: Staged rollouts with percent-based traffic splitting
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阶段性的推出，通过基于百分比的流量分割
- en: Fault injection
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故障注入
- en: Rich metrics
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 丰富的度量指标
- en: '[Mixer](https://oreil.ly/NV5xk)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mixer](https://oreil.ly/NV5xk)'
- en: Mixer enforces access control and usage policies across the service mesh, and
    collects telemetry data from the Envoy proxy and other services. The proxy extracts
    request-level attributes, and sends them to Mixer for evaluation.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Mixer 强制执行跨服务网格的访问控制和使用策略，并从 Envoy 代理和其他服务收集遥测数据。代理提取请求级属性，并将其发送到 Mixer 进行评估。
- en: '[Pilot](https://oreil.ly/lIAq_)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[Pilot](https://oreil.ly/lIAq_)'
- en: Pilot provides service discovery for the Envoy sidecars and traffic management
    capabilities for intelligent routing (e.g., A/B tests, canary rollouts) and resiliency
    (timeouts, retries, circuit breakers, etc.). This is done by converting high-level
    routing rules that control traffic behavior into Envoy-specific configurations,
    and propagating them to the sidecars at runtime. Pilot abstracts platform-specific
    service discovery mechanisms and synthesizes them into a standard format that
    any sidecar conforming with the Envoy data plane APIs can consume.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Pilot 为 Envoy Sidecar 提供服务发现和流量管理功能，如智能路由（例如 A/B 测试、金丝雀发布）和可靠性（超时、重试、断路器等）。通过将控制流量行为的高级路由规则转换为
    Envoy 特定的配置，并在运行时传播给 Sidecar，Pilot 抽象了特定于平台的服务发现机制，并将它们合成为符合 Envoy 数据平面 API 的标准格式。
- en: '[Galley](https://oreil.ly/gZdIY)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[Galley](https://oreil.ly/gZdIY)'
- en: Galley is Istio’s configuration validation, ingestion, processing, and distribution
    component. It is responsible for insulating the rest of the Istio components from
    the details of obtaining user configuration from the underlying platform.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Galley 是 Istio 的配置验证、接收、处理和分发组件。它负责保护 Istio 其他组件免受从底层平台获取用户配置的详细信息。
- en: '[Citadel](https://oreil.ly/sLh70)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[Citadel](https://oreil.ly/sLh70)'
- en: Citadel enables strong service-to-service and end-user authentication by providing
    identity and credential management. It allows for upgrading unencrypted traffic
    in the service mesh. Using Citadel, operators can enforce policies based on service
    identity rather than on relatively unstable layer 3 or layer 4 network identifiers.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Citadel 通过提供身份和凭据管理来实现强大的服务到服务和端用户认证。它允许在服务网格中升级未加密的流量。使用 Citadel，运营商可以基于服务标识而不是相对不稳定的第
    3 层或第 4 层网络标识符来执行策略。
- en: Istio’s overall architecture is illustrated in [Figure 3-5](#fig_istio_arch).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Istio 的整体架构如图 3-5 所示。
- en: '![Istio Architecture](Images/kfml_0304.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![Istio 架构](Images/kfml_0304.png)'
- en: Figure 3-5\. Istio architecture
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5. Istio 架构
- en: Kubeflow uses Istio to provide a proxy to the Kubeflow UI and to route requests
    appropriately and securely. Kubeflow’s KFServing leverages Knative, which requires
    a service mesh, like Istio.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 使用 Istio 提供代理给 Kubeflow UI，并适当且安全地路由请求。Kubeflow 的 KFServing 利用 Knative，需要像
    Istio 这样的服务网格。
- en: Knative
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Knative
- en: 'Another unseen support component used by Kubeflow is Knative. We will begin
    by describing the most important part: Knative Serving. Built on Kubernetes and
    Istio, [Knative Serving](https://oreil.ly/fcndQ) supports the deploying and serving
    of serverless applications. The Knative Serving project provides middleware primitives
    that enable:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 另一个不为人知的支持组件是 Knative。我们将从描述最重要的部分开始：Knative Serving。建立在 Kubernetes
    和 Istio 上，[Knative Serving](https://oreil.ly/fcndQ) 支持部署和提供无服务器应用程序服务。Knative
    Serving 项目提供的中间件原语使以下功能成为可能：
- en: Rapid deployment of serverless containers
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速部署无服务器容器
- en: Automatic scaling up and down to zero
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动缩放到零和向上缩放
- en: Routing and network programming for Istio components
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Istio 组件的路由和网络编程
- en: Point-in-time snapshots of deployed code and configurations
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署代码和配置的时序快照
- en: 'Knative Serving is implemented as a set of Kubernetes CRDs. These objects are
    used to define and control behavior of a serverless workload:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Knative Serving 实现为一组 Kubernetes CRD。这些对象用于定义和控制无服务器工作负载的行为：
- en: '[Service](https://oreil.ly/EbQRg)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[Service](https://oreil.ly/EbQRg)'
- en: The `service.serving.knative.dev` resource manages the workload as a whole.
    It orchestrates the creation and execution of other objects to ensure that an
    app has a configuration, a route, and a new revision for each update of the service.
    Service can be defined to always route traffic to the latest revision or to a
    specified revision.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`service.serving.knative.dev` 资源整体管理工作负载。它编排其他对象的创建和执行，以确保应用程序在每次服务更新时都有配置、路由和新的修订版本。服务可以定义为始终将流量路由到最新的修订版或指定的修订版。'
- en: '[Route](https://oreil.ly/FH50y)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[路由](https://oreil.ly/FH50y)'
- en: The `route.serving.knative.dev` resource maps a network endpoint to one or more
    revisions. This allows for multiple traffic management approaches, including fractional
    traffic and named routes.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`route.serving.knative.dev` 资源将网络端点映射到一个或多个修订版本。这允许多种流量管理方法，包括分数流量和命名路由。'
- en: '[Configuration](https://oreil.ly/cNsj3)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[配置](https://oreil.ly/cNsj3)'
- en: The `configuration.serving.knative.dev` resource maintains the desired state
    for deployment. It provides a clean separation between code and configuration
    and follows the Twelve-Factor App methodology. Modifying a configuration creates
    a new revision.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`configuration.serving.knative.dev` 资源维护部署的期望状态。它在代码和配置之间提供清晰的分离，并遵循 Twelve-Factor
    App 方法论。修改配置会创建一个新的修订版本。'
- en: '[Revision](https://oreil.ly/jxpW1)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '[修订版](https://oreil.ly/jxpW1)'
- en: The `revision.serving.knative.dev` resource is a point-in-time snapshot of the
    code and configuration for each modification made to the workload. Revisions are
    immutable objects and can be retained for as long as is useful. Knative Serving
    Revisions can be automatically scaled up and down according to incoming traffic.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '`revision.serving.knative.dev` 资源是每次对工作负载进行的代码和配置修改的时间点快照。修订版是不可变对象，可以保留尽可能长的时间。Knative
    Serving 修订版可以根据传入的流量自动扩展和缩减。'
- en: Knative’s overall architecture is illustrated in [Figure 3-6](#fig_knative_arch).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Knative 的整体架构在[图 3-6](#fig_knative_arch)中有所体现。
- en: '![Knative Architecture](Images/kfml_0305.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![Knative 架构](Images/kfml_0305.png)'
- en: Figure 3-6\. Knative architecture
  id: totrans-185
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-6\. Knative 架构
- en: Apache Spark
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apache Spark
- en: A more visible supporting component in Kubeflow is Apache Spark. Starting in
    Kubeflow 1.0, Kubeflow has a built-in Spark operator for running Spark jobs. In
    addition to the Spark operator, Kubeflow provides integration for using Google’s
    Dataproc and Amazon’s Elastic Map Reduce (EMR), two managed cloud services for
    running Spark. The components and the operator are focused on production use and
    are not well suited to exploration. For exploration, you can use Spark inside
    of your Jupyter notebook.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubeflow 中更显著的支持组件是 Apache Spark。从 Kubeflow 1.0 开始，Kubeflow 提供了用于运行 Spark
    作业的内置 Spark 运算符。除了 Spark 运算符外，Kubeflow 还提供了用于使用 Google 的 Dataproc 和 Amazon 的 Elastic
    Map Reduce（EMR）两种托管云服务运行 Spark 的集成。这些组件和运算符专注于生产使用，不适合用于探索。对于探索，您可以在 Jupyter 笔记本中使用
    Spark。
- en: Apache Spark allows you to handle larger datasets and scale problems that cannot
    fit on a single machine. While Spark does have its own machine learning libraries,
    it is more commonly used as part of a machine learning pipeline for data or feature
    preparation. We cover Spark in more detail in [Chapter 5](ch05.xhtml#data_and_feature_prep).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 允许您处理更大的数据集并解决无法放在单个计算机上的问题。虽然 Spark 有自己的机器学习库，但更常见的是作为数据或特征准备的机器学习流水线的一部分使用。我们在[第五章](ch05.xhtml#data_and_feature_prep)中更详细地讨论了
    Spark。
- en: Kubeflow Multiuser Isolation
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubeflow 多用户隔离
- en: 'The latest version of Kubeflow introduced multiuser isolation, which allows
    sharing the same pool of resources across different teams and users. Multiuser
    isolation provides users with a reliable way to isolate and protect their own
    resources, without accidentally viewing or changing each other’s resources. The
    key concepts of such isolation are:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 的最新版本引入了多用户隔离，允许在不同团队和用户之间共享同一资源池。多用户隔离为用户提供了一种可靠的方法来隔离和保护自己的资源，避免意外查看或更改彼此的资源。这种隔离的关键概念包括：
- en: Administrator
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员
- en: An administrator is someone who creates and maintains the Kubeflow cluster.
    This person has permission to grant access permissions to others.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员是创建和维护 Kubeflow 集群的人员。此人有权授予他人访问权限。
- en: User
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 用户
- en: A user is someone who has access to some set of resources in the cluster. A
    user needs to be granted access permissions by the administrator.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 用户是具有对集群中某些资源集的访问权限的人。用户需要管理员授予访问权限。
- en: Profile
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 档案
- en: A profile is a grouping of all Kubernetes namespaces and resources owned by
    a user.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 档案是用户拥有的所有 Kubernetes 命名空间和资源的分组。
- en: As of version 1.0, Kubeflow’s Jupyter notebook service is the first application
    to be fully integrated with multiuser isolation. Notebooks and their creation
    are controlled by the profile access policies set by the administrator or the
    owners of the profiles. Resources created by the notebooks (e.g., training jobs
    and deployments) will also inherit the same access. By default, Kubeflow provides
    automatic profile creation for authenticated users on first login,^([3](ch03.xhtml#idm45831179752680))
    which creates a new namespace. Alternatively, profiles for users can be created
    [manually](https://oreil.ly/6aklV). This means that every user can work independently
    in their own namespace and use their own Jupyter server and notebooks. To share
    access to your server/notebooks with others, go to the manage contributors page
    and add your collaborators’ emails.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 从版本 1.0 开始，Kubeflow 的 Jupyter 笔记本服务是第一个完全与多用户隔离集成的应用程序。笔记本及其创建由管理员或配置文件所有者设置的配置文件访问策略控制。笔记本创建的资源（例如训练作业和部署）也将继承相同的访问权限。默认情况下，Kubeflow
    在首次登录时为经过身份验证的用户提供自动配置文件创建，这会创建一个新的命名空间。或者，用户的配置文件可以通过[手动方式](https://oreil.ly/6aklV)创建。这意味着每个用户都可以在其自己的命名空间中独立工作，并使用其自己的
    Jupyter 服务器和笔记本。要与他人共享对您的服务器/笔记本的访问权限，请转到管理贡献者页面并添加您的合作者的电子邮件。
- en: Conclusion
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: You now know the different components of Kubeflow and how they fit together.
    Kubeflow’s central dashboard gives you access to its web components. You’ve seen
    that JupyterHub facilitates the explorative phase of model development. We’ve
    covered the different built-in training operators for Kubeflow. We revisited Kubeflow
    pipelines to discuss how they tie together all of Kubeflow’s other components.
    We introduced Katib, Kubeflow’s tool for hyperparameter tuning that works on pipelines.
    We talked about the different options for serving your models with Kubeflow (including
    KF Serving and Seldon). We discussed Kubeflow’s system for tracking your machine
    learning metadata and artifacts. Then we wrapped it up with some of Kubeflow’s
    supporting components that enable the rest, Knative and Istio. By understanding
    the different parts of Kubeflow, as well as the overall design, you should now
    be able to start seeing how your machine learning tasks and workflow translate
    to Kubeflow.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已了解 Kubeflow 的不同组件及其如何相互配合。Kubeflow 的中央仪表板为您提供访问其 Web 组件的权限。您已经看到 JupyterHub
    如何促进模型开发的探索阶段。我们涵盖了 Kubeflow 的不同内置训练操作符。我们重新审视了 Kubeflow 流水线，讨论了它如何将所有 Kubeflow
    的其他组件联系在一起。我们介绍了 Katib，Kubeflow 的用于管道的超参数调整工具。我们讨论了使用 Kubeflow 提供的不同模型服务选项（包括
    KF Serving 和 Seldon）。我们讨论了 Kubeflow 的跟踪机器学习元数据和工件的系统。然后我们总结了一些支持 Kubeflow 其余部分的组件，例如
    Knative 和 Istio。通过了解 Kubeflow 的不同部分以及总体设计，您现在应该能够开始看到如何将您的机器学习任务和工作流转化为 Kubeflow。
- en: The next few chapters will help you gain insights into these components and
    how to apply them to your use cases.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的几章将帮助您深入了解这些组件以及如何将它们应用到您的使用案例中。
- en: ^([1](ch03.xhtml#idm45831180010264-marker)) This can run on multiple servers
    while exposing a consistent endpoint.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.xhtml#idm45831180010264-marker)) 这可以在多台服务器上运行，同时暴露一个一致的端点。
- en: ^([2](ch03.xhtml#idm45831179889512-marker)) Storing credentials inside your
    application can lead to security breaches.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch03.xhtml#idm45831179889512-marker)) 将凭证存储在应用程序内部可能导致安全漏洞。
- en: '^([3](ch03.xhtml#idm45831179752680-marker)) To enable users to log in, they
    should be given minimal permission scope that allows them to connect to the Kubernetes
    cluster. For example, for GCP users, they can be granted IAM roles: Kubernetes
    Engine Cluster Viewer and IAP-secured Web App User.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch03.xhtml#idm45831179752680-marker)) 为了使用户能够登录，他们应被授予最小的权限范围，允许他们连接到
    Kubernetes 集群。例如，对于 GCP 用户，他们可以被授予 IAM 角色：Kubernetes Engine Cluster Viewer 和 IAP-secured
    Web App User。
