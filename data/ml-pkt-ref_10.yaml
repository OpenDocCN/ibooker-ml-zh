- en: Chapter 10\. Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 10 章。分类
- en: Classification is a *supervised learning* mechanism for labeling a sample based
    on the features. Supervised learning means that we have labels for classification
    or numbers for regression that the algorithm should learn.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是一种基于特征对样本进行标记的*监督学习*机制。监督学习意味着我们对于分类有标签，或者对于回归有数字，算法应该学习这些。
- en: We will look at various classification models in this chapter. Sklearn implements
    many common and useful models. We will also see some that are not in sklearn,
    but implement the sklearn interface. Because they follow the same interface, it
    is easy to try different families of models and see how well they perform.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章中查看各种分类模型。Sklearn 实现了许多常见且有用的模型。我们还将看到一些不在 sklearn 中的模型，但实现了 sklearn 接口。因为它们遵循相同的接口，所以很容易尝试不同系列的模型，并查看它们的性能如何。
- en: In sklearn, we create a model instance and call the `.fit` method on it with
    the training data and training labels. We can now call the `.predict` method (or
    the `.predict_proba` or the `.predict_``log_proba` methods) with the fitted model.
    To evaluate the model, we use the `.score` with testing data and testing labels.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在 sklearn 中，我们创建一个模型实例，并在训练数据和训练标签上调用 `.fit` 方法。现在，我们可以使用拟合模型调用`.predict`方法（或`.predict_proba`或`.predict_log_proba`方法）。要评估模型，我们使用
    `.score` 方法与测试数据和测试标签。
- en: The bigger challenge is usually arranging data in a form that will work with
    sklearn. The data (`X`) should be an (m by n) numpy array (or pandas DataFrame)
    with m rows of sample data each with n features (columns). The label (`y`) is
    a vector (or pandas series) of size m with a value (class) for each sample.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 更大的挑战通常是将数据安排成与 sklearn 兼容的形式。数据(`X`)应该是一个(m 行 n 列)的 numpy 数组（或 pandas DataFrame），其中每个样本数据都有
    n 个特征（列）。标签(`y`)是一个大小为 m 的向量（或 pandas series），其中每个样本都有一个值（类）。
- en: The `.score` method returns the mean accuracy, which by itself might not be
    sufficient to evaluate a classifier. We will see other evaluation metrics.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '`.score`方法返回平均准确度，单独可能不足以评估分类器。我们将看到其他评估指标。'
- en: We will look at many models and discuss their efficiency, the preprocessing
    techniques they require, how to prevent overfitting, and if the model supports
    intuitive interpretation of results.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究许多模型，并讨论它们的效率，它们所需的预处理技术，如何防止过拟合以及模型是否支持结果的直观解释。
- en: 'The general methods that sklearn type models implement are:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: sklearn 类型模型实现的一般方法包括：
- en: '`fit(X, y[, sample_weight])`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '`fit(X, y[, sample_weight])`'
- en: Fit a model
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合模型
- en: '`predict(X)`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict(X)`'
- en: Predict classes
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 预测类别
- en: '`predict_log_proba(X)`'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict_log_proba(X)`'
- en: Predict log probability
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 预测对数概率
- en: '`predict_proba(X)`'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict_proba(X)`'
- en: Predict probability
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 预测概率
- en: '`score(X, y[, sample_weight])`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`score(X, y[, sample_weight])`'
- en: Get accuracy
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 获得准确度
- en: Logistic Regression
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Logistic regression estimates probabilities by using a logistic function. (Careful;
    even though it has regression in the name, it is used for classification.) This
    has been the standard classification model for most sciences.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归通过使用逻辑函数来估计概率。（注意；尽管它的名字中有回归，但它用于分类。）这一直是大多数科学的标准分类模型。
- en: 'The following are some model characteristics that we will include for each
    model:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们将为每个模型包含的一些模型特征：
- en: Runtime efficiency
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时效率
- en: Can use `n_jobs` if not using `'liblinear'` solver.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不使用`'liblinear'`求解器，则可以使用`n_jobs`。
- en: Preprocess data
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理数据
- en: If `solver` is set to `'sag'` or `'saga'`, standardize so that convergence works.
    Can handle sparse input.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`solver`设置为`'sag'`或`'saga'`，则标准化以确保收敛正常。可以处理稀疏输入。
- en: Prevent overfitting
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 防止过拟合
- en: The `C` parameter controls regularization. (Lower `C` is more regularization,
    higher means less.) Can specify `penalty` to `'l1'` or `'l2'` (the default).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`C`参数控制正则化。（较低的`C`表示更多的正则化，较高表示较少。）可以指定`penalty`为`''l1''`或`''l2''`（默认值）。'
- en: Interpret results
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 解释结果
- en: The `.coef_` attribute of the fitted model shows the decision function coefficients.
    A change in x one unit changes the log odds ratio by the coefficient. The `.intercept_`
    attribute is the inverse log odds of the baseline condition.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合模型的`.coef_`属性显示决策函数的系数。x 的一个单位变化会使对数几率比按系数变化。`.intercept_`属性是基线条件的逆对数几率。
- en: 'Here is an example using this model:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用此模型的一个示例：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Instance parameters:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 实例参数：
- en: '`penalty=''l2''`'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`penalty=''l2''`'
- en: Penalization norm, `'l1'` or `'l2'`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 惩罚范数，`'l1'`或`'l2'`。
- en: '`dual=False`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`dual=False`'
- en: Use dual formulation (only with `'l2'` and `'liblinear'`).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用双重制定（仅适用于`'l2'`和`'liblinear'`）。
- en: '`C=1.0`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`C=1.0`'
- en: Positive float. Inverse regularization strength. Smaller is stronger regularization.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正浮点数。逆正则化强度。数值越小，正则化越强。
- en: '`fit_intercept=True`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`fit_intercept=True`'
- en: Add bias to the decision function.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为决策函数添加偏置。
- en: '`intercept_scaling=1`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`intercept_scaling=1`'
- en: If `fit_intercept` and `'liblinear'`, scale the intercept.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`fit_intercept`和`'liblinear'`，则缩放截距。
- en: '`max_iter=100`'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_iter=100`'
- en: Maximum number of iterations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最大迭代次数。
- en: '`multi_class=''ovr''`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`multi_class=''ovr''`'
- en: Use one versus rest for each class, or for `'multinomial'`, train one class.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个类使用一对其余，或对于`'multinomial'`，训练一个类。
- en: '`class_weight=None`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`class_weight=None`'
- en: Dictionary or `'balanced'`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 字典或`'balanced'`。
- en: '`solver=''liblinear''`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`solver=''liblinear''`'
- en: '`''liblinear''` is good for small data. `''newton-cg''`, `''sag''`, `''saga''`,
    and `''lbfgs''` are for multiclass data. `''liblinear''` and `''saga''` only work
    with `''l1''` penalty. The others work with `''l2''`.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`''liblinear''`适用于小数据。`''newton-cg''`、`''sag''`、`''saga''`和`''lbfgs''`适用于多类数据。`''liblinear''`和`''saga''`只适用于`''l1''`惩罚。其他适用于`''l2''`。'
- en: '`tol=0.0001`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`tol=0.0001`'
- en: Stopping tolerance.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 停止容差。
- en: '`verbose=0`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`verbose=0`'
- en: Be verbose (if nonzero int).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果非零整数，则显示详细信息。
- en: '`warm_start=False`'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`warm_start=False`'
- en: If `True`, remember previous fit.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果为`True`，记住以前的拟合。
- en: '`njobs=1`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`njobs=1`'
- en: Number of CPUs to use. `-1` is all. Only works with `multi_class='over'` and
    `solver` is not `'liblinear'`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用的CPU数。`-1`是全部。仅适用于`multi_class='over'`且`solver`不是`'liblinear'`。
- en: 'Attributes after fitting:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合后的属性：
- en: '`coef_`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`coef_`'
- en: Decision function coefficients
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 决策函数系数
- en: '`intercept_`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`intercept_`'
- en: Intercept of the decision function
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 决策函数的截距
- en: '`n_iter_`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_iter_`'
- en: Number of iterations
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代次数
- en: 'The intercept is the log odds of the baseline condition. We can convert it
    back to a percent accuracy (proportion):'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 截距是基准条件的对数几率。我们可以将其转换回百分比准确率（比例）：
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Using the inverse logit function, we see that the baseline for survival is
    34%:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用逆logit函数，我们可以看到生存的基线是34%：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can inspect the coefficients. The inverse logit of the coefficients gives
    the proportion of the positive cases. In this case, if fare goes up, we are more
    likely to survive. If sex is male, we are less likely to survive:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以检查系数。系数的逆logit给出正例的比例。在这种情况下，如果票价上涨，我们更有可能生存。如果性别是男性，我们更不可能生存：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Yellowbrick can also visualize the coefficients. This visualizer has a `relative=True`
    parameter that makes the largest value be 100 (or -100), and the others are the
    percentages of that (see [Figure 10-1](#idlr1_2)):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Yellowbrick还可以可视化系数。此可视化器具有`relative=True`参数，使最大值为100（或-100），其他值为该百分比（见[图10-1](#idlr1_2)）：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Feature importance (relative to largest absolute regression coefficient).](assets/mlpr_1001.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![特征重要性（相对于最大绝对回归系数）。](assets/mlpr_1001.png)'
- en: Figure 10-1\. Feature importance (relative to largest absolute regression coefficient).
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-1. 特征重要性（相对于最大绝对回归系数）。
- en: Naive Bayes
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯
- en: Naive Bayes is a probabilistic classifier that assumes independence between
    the features of the data. It is popular for text classification applications,
    such as catching spam. One advantage of this model is that because it assumes
    feature independence, it can train a model with a small number of samples. (A
    downside is that it can’t capture the interactions between features.) This simple
    model can also work with data that has many features. As such, it serves as a
    good baseline model.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯是一种概率分类器，假设数据特征之间独立。它在文本分类应用中很受欢迎，如捕捉垃圾邮件。该模型的一个优点是，因为它假设特征独立，所以可以用少量样本训练模型（缺点是不能捕捉特征之间的交互作用）。这个简单模型也可以处理具有许多特征的数据。因此，它作为一个良好的基准模型。
- en: 'There are three classes in sklearn: `GaussianNB`, `MultinomialNB`, and `BernoulliNB`.
    The first assumes a Gaussian distribution (continuous features with a normal distribution),
    the second is for discrete occurrence counts, and the third is for discrete Boolean
    features.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: sklearn中有三类：`GaussianNB`、`MultinomialNB`和`BernoulliNB`。第一种假设高斯分布（具有正态分布的连续特征），第二种用于离散发生计数，第三种用于离散布尔特征。
- en: 'This model has the following properties:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型具有以下属性：
- en: Runtime efficiency
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时效率
- en: Training O(Nd), where N is the number of training examples and d is dimensionality.
    Testing O(cd), where c is the number of classes.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 训练O(Nd)，其中N是训练样本数，d是维度。测试O(cd)，其中c是类数。
- en: Preprocess data
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理数据
- en: Assumes that data is independent. Should perform better after removing colinear
    columns. For continuous numerical data, might be good to bin data. Gaussian assumes
    normal distribution, and you might need to transform data to convert to normal
    distribution.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 假设数据是独立的。在删除共线列后，应该表现更好。对于连续数值数据，可能需要对数据进行分箱。高斯假设正态分布，可能需要转换数据以转换为正态分布。
- en: Prevent overfitting
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 防止过拟合
- en: Exhibits high bias and low variance (ensembles won’t reduce variance).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 表现出高偏差和低方差（集成不会减少方差）。
- en: Interpret results
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 解释结果
- en: Percentage is the likelihood that a sample belongs to a class based on priors.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 百分比是样本属于某一类的概率，基于先验概率。
- en: 'Here is an example using this model:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用该模型的示例：
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Instance parameters:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 实例参数：
- en: '`priors=None`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`priors=None`'
- en: Prior probabilities of classes.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 类别的先验概率。
- en: '`var_smoothing=1e-9`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`var_smoothing=1e-9`'
- en: Added to variance for stable calculations.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 添加到方差以进行稳定计算。
- en: 'Attributes after fitting:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合后的属性：
- en: '`class_prior_`'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`class_prior_`'
- en: Probabilities of classes
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 类别的概率
- en: '`class_count_`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`class_count_`'
- en: Counts of classes
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 类别的计数
- en: '`theta_`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`theta_`'
- en: Mean of each column per class
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 每类别每列的均值
- en: '`sigma_`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`sigma_`'
- en: Variance of each column per class
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 每类别每列的方差
- en: '`epsilon_`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`epsilon_`'
- en: Additive value to each variance
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个方差添加的附加值
- en: Tip
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: These models are susceptible to the *zero probability problem*. If you try to
    classify a new sample that has no training data, it will have a zero probability.
    One solution is to use *Laplace smoothing*. Sklearn controls this with the `alpha`
    parameter, which defaults to `1` and enables smoothing on the `MultinomialNB`
    and `BernoulliNB` models.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型容易受到*零概率问题*的影响。如果尝试对没有训练数据的新样本进行分类，其概率将为零。一种解决方案是使用*Laplace平滑*。Sklearn 使用
    `alpha` 参数控制此功能，默认为 `1`，并在 `MultinomialNB` 和 `BernoulliNB` 模型上启用平滑。
- en: Support Vector Machine
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机
- en: A Support Vector Machine (SVM) is an algorithm that tries to fit a line (or
    plane or hyperplane) between the different classes that maximizes the distance
    from the line to the points of the classes. In this way it tries to find a robust
    separation between the classes. The *support vectors* are the points of the edge
    of the dividing hyperplane.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）是一种算法，试图在不同类别之间拟合一条（或平面或超平面）线，以最大化从线到类别点的距离。通过这种方式，它试图找到类别之间的稳健分割。*支持向量*是分隔超平面边缘的点。
- en: Note
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There are a few different SVM implementations in sklearn. `SVC` wraps the `libsvm`
    library, while `LinearSVC` wraps the `liblinear` library.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: sklearn 中有几种不同的 SVM 实现。`SVC` 使用 `libsvm` 库，而 `LinearSVC` 使用 `liblinear` 库。
- en: There is also the `linear_model.SGDClassifier`, which implements SVM when using
    the default `loss` parameter. This chapter will describe the first implementation.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 还有 `linear_model.SGDClassifier`，当使用默认的 `loss` 参数时，它实现了 SVM。本章将描述第一次实现。
- en: SVM generally performs well and can support linear spaces or nonlinear spaces
    by using a *kernel trick*. The kernel trick is the idea that we can create a decision
    boundary in a new dimension by minimizing a formula that is easier to calculate
    than actually mapping the points to the new dimension. The default kernel is the
    Radial Basis Function (`'rbf'`), which is controlled by the `gamma` parameter
    and can map an input space into a high dimensional space.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: SVM通常表现良好，并且可以通过*核技巧*支持线性空间或非线性空间。核技巧是指我们可以通过最小化一个比实际映射点到新维度更容易计算的公式来在新维度中创建决策边界的想法。默认核函数是径向基函数（`'rbf'`），由
    `gamma` 参数控制，并可以将输入空间映射到高维空间。
- en: 'SVMs have the following properties:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 具有以下特性：
- en: Runtime efficiency
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时效率
- en: The scikit-learn implementation is O(n⁴), so it can be hard to scale to large
    sizes. Using a linear kernel or the `LinearSVC` model can improve the runtime
    performance at perhaps the cost of accuracy. Upping the `cache_size` parameter
    can bring that down to O(n³).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 的实现是 O(n⁴)，因此很难扩展到大尺寸。使用线性核或 `LinearSVC` 模型可以提高运行时性能，但可能会降低准确性。增加
    `cache_size` 参数可以将其降至 O(n³)。
- en: Preprocess data
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理数据
- en: The algorithm is not scale invariant. Standardizing the data is highly recommended.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法不具备尺度不变性。强烈建议对数据进行标准化。
- en: Prevent overfitting
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 防止过拟合
- en: The `C` (penalty parameter) controls regularization. A smaller value allows
    for a smaller margin in the hyperplane. A higher value for `gamma` will tend to
    overfit the training data. The `LinearSVC` model supports a `loss` and `penalty`
    parameter to support regularization.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`C`（惩罚参数）控制正则化。较小的值允许在超平面上有更小的间隔。较高的`gamma`值倾向于过拟合训练数据。`LinearSVC`模型支持`loss`和`penalty`参数以支持正则化。'
- en: Interpret results
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 解释结果
- en: Inspect `.support_vectors_`, though these are hard to explain. With linear kernels,
    you can inspect `.coef_`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 `.support_vectors_`，尽管这些很难解释。对于线性核，可以检查 `.coef_`。
- en: 'Here is an example using scikit-learn’s SVM implementation:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用scikit-learn的SVM实现的示例：
- en: '[PRE6]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: To get probability, use `probability=True`, which will slow down fitting of
    the model.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取概率，请使用 `probability=True`，这会减慢模型的拟合速度。
- en: This is similar to a perceptron, but will find the maximum margin. If the data
    is not linearly separable, it will minimize the error. Alternatively, a different
    kernel may be used.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这类似于感知器，但会找到最大间隔。如果数据不是线性可分的，它将最小化误差。或者，可以使用不同的核函数。
- en: 'Instance parameters:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 实例参数：
- en: '`C=1.0`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`C=1.0`'
- en: The penalty parameter. The smaller the value, the tighter the decision boundary
    (more overfitting).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 惩罚参数。值越小，决策边界越紧（更容易过拟合）。
- en: '`cache_size=200`'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`cache_size=200`'
- en: Cache size (MB). Bumping this up can improve training time on large datasets.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存大小（MB）。增加这个值可以提高在大数据集上的训练时间。
- en: '`class_weight=None`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`class_weight=None`'
- en: Dictionary or `'balanced'`. Use dictionary to set `C` for each class.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 字典或`'balanced'`。使用字典为每个类设置`C`。
- en: '`coef0=0.0`'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`coef0=0.0`'
- en: Independent term for poly and sigmoid kernels.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式和sigmoid核的独立项。
- en: '`decision_function_shape=''ovr''`'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`decision_function_shape=''ovr''`'
- en: Use one versus rest (`'ovr'`) or one versus one.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一对其余（`'ovr'`）或一对一。
- en: '`degree=3`'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`degree=3`'
- en: Degree for polynomial kernel.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式核的次数。
- en: '`gamma=''auto''`'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`gamma=''auto''`'
- en: Kernel coefficient. Can be a number, `'scale'` (default in 0.22, 1 / (`num features`
    * `X.std()` ) ), or `'auto'` (default prior, 1 / `num features`). A lower value
    leads to overfitting the training data.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 核系数。可以是一个数字，`'scale'`（0.22版中的默认值，1 /（`num features` * `X.std()`）），或`'auto'`（默认优先，1
    / `num features`）。较低的值会导致过拟合训练数据。
- en: '`kernel=''rbf''`'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`kernel=''rbf''`'
- en: 'Kernel type: `''linear''`, `''poly''`, `''rbf''` (default), `''sigmoid''`,
    `''precomputed''`, or a function.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 核类型：`'linear'`，`'poly'`，`'rbf'`（默认），`'sigmoid'`，`'precomputed'`或一个函数。
- en: '`max_iter=-1`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_iter=-1`'
- en: Maximum number of iterations for solver. -1 for no limit.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 求解器的最大迭代次数。设为 -1 表示无限制。
- en: '`probability=False`'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`probability=False`'
- en: Enable probability estimation. Slows down training.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 启用概率估计。训练速度减慢。
- en: '`random_state=None`'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`random_state=None`'
- en: Random seed.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 随机种子。
- en: '`shrinking=True`'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '`shrinking=True`'
- en: Use shrinking heuristic.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用缩减启发式。
- en: '`tol=0.001`'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`tol=0.001`'
- en: Stopping tolerance.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 停止容差。
- en: '`verbose=False`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`verbose=False`'
- en: Verbosity.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 冗余性。
- en: 'Attributes after fitting:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合后的属性：
- en: '`support_`'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`support_`'
- en: Support vector indices
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量索引
- en: '`support_vectors_`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`support_vectors_`'
- en: Support vectors
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量
- en: '`n_support_vectors_`'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_support_vectors_`'
- en: Count of per-class support vectors
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 每类支持向量的计数
- en: '`coef_`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`coef_`'
- en: Coefficients (for linear) kernel
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 系数（线性核）。
- en: K-Nearest Neighbor
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-最近邻
- en: The K-Nearest Neighbor (KNN) algorithm classifies based on distance to some
    number (k) of training samples. The algorithm family is called *instance-based*
    learning as there are no parameters to learn. This model assumes that distance
    is sufficient for inference; otherwise it makes no assumptions about the underlying
    data or its distributions.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: K-最近邻（KNN）算法基于到一些训练样本的距离进行分类。这种算法族称为*基于实例*的学习，因为没有要学习的参数。该模型假设距离足以进行推断；否则，它对底层数据或其分布不做任何假设。
- en: The tricky part is selecting the appropriate k value. Also, the curse of dimensionality
    can hamper distance metrics as there is little difference in high dimensions between
    nearest and farthest neighbor.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 棘手的部分是选择合适的 k 值。此外，维度诅咒可能会妨碍距离度量，因为在高维空间中，最近邻和最远邻之间的差异很小。
- en: 'Nearest neighbor models have the following properties:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻模型具有以下属性：
- en: Runtime efficiency
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时效率
- en: Training O(1), but need to store data. Testing O(Nd) where N is the number of
    training examples and d is dimensionality.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 O(1)，但需要存储数据。测试 O(Nd)，其中 N 是训练样本的数量，d 是维度。
- en: Preprocess data
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理数据
- en: Yes, distance-based calculations perform better when standardized.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，当标准化时，基于距离的计算性能更好。
- en: Prevent overfitting
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 防止过拟合。
- en: Raise `n_neighbors`. Change `p` for L1 or L2 metric.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 增加 `n_neighbors`。对于 L1 或 L2 度量，修改 `p`。
- en: Interpret results
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 解释结果
- en: Interpret the k-nearest neighbors to the sample (using the `.kneighbors` method).
    Those neighbors (if you can explain them) explain your result.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 解释 k 最近邻样本（使用 `.kneighbors` 方法）。如果可以解释这些邻居，它们可以解释你的结果。
- en: 'Here is an example of using the model:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用模型的一个例子：
- en: '[PRE7]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Attributes:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 属性：
- en: '`algorithm=''auto''`'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`algorithm=''auto''`'
- en: Can be `'brute'`, `'ball_tree'`, or `'kd_tree'`.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 可以是 `'brute'`、`'ball_tree'` 或 `'kd_tree'`。
- en: '`leaf_size=30`'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`leaf_size=30`'
- en: Used for tree algorithms.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 用于树算法。
- en: '`metric=''minkowski''`'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '`metric=''minkowski''`'
- en: Distance metric.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 距离度量。
- en: '`metric_params=None`'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`metric_params=None`'
- en: Additional dictionary of parameters for custom metric function.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义度量函数的额外参数字典。
- en: '`n_jobs=1`'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_jobs=1`'
- en: Number of CPUs.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 的数量。
- en: '`n_neighbors=5`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_neighbors=5`'
- en: Number of neighbors.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 邻居的数量。
- en: '`p=2`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`p=2`'
- en: 'Minkowski power parameter: 1 = manhattan (L1). 2 = Euclidean (L2).'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Minkowski 功率参数：1 = 曼哈顿（L1）。2 = 欧几里得（L2）。
- en: '`weights=''uniform''`'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`weights=''uniform''`'
- en: Can be `'distance'`, in which case, closer points have more influence.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 可以是 `'distance'`，在这种情况下，更接近的点具有更大的影响力。
- en: 'Distance metrics include: `''euclidean''`, `''manhattan''`, `''chebyshev''`,
    `''minkowski''`, `''wminkowski''`, `''seuclidean''`, `''mahalanobis''`, `''haversine''`,
    `''hamming''`, `''canberra''`, `''braycurtis''`, `''jaccard''`, `''matching''`,
    `''dice''`, `''rogerstanimoto''`, `''russellrao''`, `''sokalmichener''`, `''sokalsneath''`,
    or a callable (user defined).'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 距离度量包括：`'euclidean'`、`'manhattan'`、`'chebyshev'`、`'minkowski'`、`'wminkowski'`、`'seuclidean'`、`'mahalanobis'`、`'haversine'`、`'hamming'`、`'canberra'`、`'braycurtis'`、`'jaccard'`、`'matching'`、`'dice'`、`'rogerstanimoto'`、`'russellrao'`、`'sokalmichener'`、`'sokalsneath'`或一个可调用的（用户定义的）函数。
- en: Note
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If k is an even number and the neighbors are split, the result depends on the
    order of the training data.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 k 是偶数且邻居分开，结果取决于训练数据的顺序。
- en: Decision Tree
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树
- en: A decision tree is like going to a doctor who asks a series of questions to
    determine the cause of your symptoms. We can use a process to create a decision
    tree and have a series of questions to predict a target class. The advantages
    of this model include support for nonnumeric data (in some implementations), little
    data preparation (no need for scaling), support for dealing with nonlinear relationships,
    feature importances are revealed, and it is easy to explain.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树就像去看医生，医生会问一系列问题来确定症状的原因。我们可以使用一个过程创建决策树，并提出一系列问题来预测目标类。此模型的优点包括对非数值数据的支持（在某些实现中），几乎不需要数据准备（无需缩放），支持处理非线性关系，揭示特征重要性并且易于解释。
- en: The default algorithm used for creation is called the classification and regression
    tree (CART). It uses the Gini impurity or index measure to construct decisions.
    This is done by looping over the features and finding the value that gives the
    lowest probability of misclassifying.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 用于创建的默认算法称为分类与回归树（CART）。它使用基尼不纯度或指数度量来构建决策。这通过循环特征并找到给出最低误分类概率的值来完成。
- en: Tip
  id: totrans-201
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The default values will lead to a fully grown (read overfit) tree. Use a mechanism
    such as `max_depth` and cross-validation to control for this.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 默认值会导致一个完全生长（过拟合）的树。使用诸如 `max_depth` 和交叉验证来控制这一情况。
- en: 'Decision trees have the following properties:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树具有以下特性：
- en: Runtime efficiency
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时效率
- en: For creation, loop over each of the m features, and sort all n samples, O(mn
    log n). For predicting, you walk the tree, O( height).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 对于创建，循环遍历每个 m 特征，并对所有 n 个样本进行排序，O(mn log n)。对于预测，您沿着树行走，O( height)。
- en: Preprocess data
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理数据
- en: Scaling is not necessary. Need to get rid of missing values and convert to numeric.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放不是必需的。需要处理丢失的值并转换为数值。
- en: Prevent overfitting
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 防止过拟合
- en: Set `max_depth` to a lower number, raise `min_``impurity_decrease`.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `max_depth` 设置为较低的数值，提高 `min_impurity_decrease`。
- en: Interpret results
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 解释结果
- en: Can step through the tree of choices. Because there are steps, a tree is bad
    at dealing with linear relationships (a small change in a number can go down a
    different path). The tree is also highly dependent on the training data. A small
    change can change the whole tree.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 可以逐步浏览选择树。因为有步骤，树在处理线性关系时效果不佳（数字的微小变化可能导致不同路径）。该树还高度依赖于训练数据。微小变化可能改变整棵树。
- en: 'Here is an example using the scikit-learn library:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是使用 scikit-learn 库的示例：
- en: '[PRE8]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Instance parameters:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 实例参数：
- en: '`class_weight=None`'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`class_weight=None`'
- en: Weights for class in dictionary. `'balanced'` will set values to the inverse
    proportion of class frequencies. Default is a value of 1 for each class. For multiclass,
    need a list of dictionaries, one-versus-rest (OVR) for each class.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 字典中类的权重。`'balanced'` 将值设置为类频率的倒数比例。对于多类问题，需要一个字典列表，每个类别使用一对多（OVR）。
- en: '`criterion=''gini''`'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`criterion=''gini''`'
- en: Splitting function, `'gini'` or `'entropy'`.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 分裂函数，`'gini'` 或 `'entropy'`。
- en: '`max_depth=None`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_depth=None`'
- en: Depth of tree. Default will build until the leaves contain less than `min_samples_split`.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 树的深度。默认将构建直到叶子节点包含少于 `min_samples_split`。
- en: '`max_features=None`'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_features=None`'
- en: Number of features to examine for split. Default is all.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 用于切分的特征数。默认为全部。
- en: '`max_leaf_nodes=None`'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_leaf_nodes=None`'
- en: Limit the number of leaves. Default is unlimited.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 限制叶子节点的数量。默认为无限制。
- en: '`min_impurity_decrease=0.0`'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_impurity_decrease=0.0`'
- en: Split node if a split will decrease impurity >= value.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果切分能使不纯度减少 >= 给定值，则切分节点。
- en: '`min_impurity_split=None`'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_impurity_split=None`'
- en: Deprecated.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 已弃用。
- en: '`min_samples_leaf=1`'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_samples_leaf=1`'
- en: Minimum number of samples at each leaf.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 每个叶子节点的最小样本数。
- en: '`min_samples_split=2`'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_samples_split=2`'
- en: Minimum number of samples required to split a node.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 切分节点所需的最小样本数。
- en: '`min_weight_fraction_leaf=0.0`'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_weight_fraction_leaf=0.0`'
- en: Minimum sum total of weights required for leaf nodes.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 叶节点所需的权重总和的最小值。
- en: '`presort=False`'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '`presort=False`'
- en: May speed up training with a small dataset or restricted depth if set to `True`.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如果设置为 `True`，可能会加速训练小数据集或限制深度。
- en: '`random_state=None`'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '`random_state=None`'
- en: Random seed.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 随机种子。
- en: '`splitter=''best''`'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '`splitter=''best''`'
- en: Use `'random'` or `'best'`.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `'random'` 或 `'best'`。
- en: 'Attributes after fitting:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合后的属性：
- en: '`classes_`'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`classes_`'
- en: Class labels
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 类标签
- en: '`feature_importances_`'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`feature_importances_`'
- en: Array of Gini importance
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 基尼重要性数组
- en: '`n_classes_`'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_classes_`'
- en: Number of classes
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 类的数量
- en: '`n_features_`'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_features_`'
- en: Number of features
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 特征数
- en: '`tree_`'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '`tree_`'
- en: Underlying tree object
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 底层树对象
- en: 'View the tree with this code (see [Figure 10-2](#id21)):'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此代码查看树（见 [图 10-2](#id21)）：
- en: '[PRE9]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'For Jupyter, use:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Jupyter，使用：
- en: '[PRE10]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Decision Tree.](assets/mlpr_1002.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![决策树。](assets/mlpr_1002.png)'
- en: Figure 10-2\. Decision tree.
  id: totrans-257
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-2\. 决策树。
- en: 'The [dtreeviz package](https://github.com/parrt/dtreeviz) can aid in understanding
    how the decision tree works. It creates a tree with labeled histograms, which
    gives valuable insight (see [Figure 10-3](#iddtviz)). Here is an example. In Jupyter
    we can just display the `viz` object directly. If we are working from a script,
    we can call the `.save` method to create a PDF, SVG, or PNG:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '[dtreeviz 包](https://github.com/parrt/dtreeviz) 可帮助理解决策树的工作原理。它创建带有标记直方图的树，提供宝贵的见解（见
    [图 10-3](#iddtviz)）。这里是一个示例。在 Jupyter 中，我们可以直接显示 `viz` 对象。如果我们从脚本中工作，我们可以调用 `.save`
    方法创建 PDF、SVG 或 PNG：'
- en: '[PRE11]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![dtreeviz output.](assets/mlpr_1003.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![dtreeviz 输出。](assets/mlpr_1003.png)'
- en: Figure 10-3\. dtreeviz output.
  id: totrans-261
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-3\. dtreeviz 输出。
- en: 'Feature importance showing Gini importance (reduction of error by using that
    feature):'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 特征重要性显示基尼重要性（使用该特征减少错误）：
- en: '[PRE12]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can also use Yellowbrick to visualize feature importance (see [Figure 10-4](#id22)):'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用 Yellowbrick 来可视化特征重要性（见 [图 10-4](#id22)）：
- en: '[PRE13]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Feature importance (Gini coefficient) for decision tree (normalized to male
    importance).](assets/mlpr_1004.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![决策树的特征重要性（基尼系数）（归一化到男性重要性）。](assets/mlpr_1004.png)'
- en: Figure 10-4\. Feature importance (Gini coefficient) for decision tree (normalized
    to male importance).
  id: totrans-267
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-4\. 决策树的特征重要性（基尼系数）（归一化到男性重要性）。
- en: Random Forest
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林
- en: A random forest is an ensemble of decision trees. It uses *bagging* to correct
    the tendency of decision trees to overfit. By creating many trees trained on random
    subsamples of the samples and random features of the data, the variance is lowered.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是决策树的集成。它使用 *装袋*（bagging）来纠正决策树过拟合的倾向。通过在样本的随机子样本和数据的随机特征上训练多个树，可以降低方差。
- en: Because they train on subsamples of the data, random forests can evaluate OOB
    error and evaluate performance. They can also track feature importance by averaging
    the feature importance over all of the trees.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它们训练在数据的子样本上，随机森林可以评估OOB错误并评估性能。它们还可以通过对所有树平均特征重要性来跟踪特征重要性。
- en: The intuition for understanding bagging comes from a 1785 essay by Marquis de
    Condorcet. The essence is that if you are creating a jury, you should add anyone
    who has a greater than 50% chance of delivering the correct verdict and then average
    their decisions. Every time you add another member (and their selection process
    is independent of the others), you will get a better result.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 理解bagging的直觉源自康多塞的1785年的一篇文章。其核心是，如果你要创建一个陪审团，你应该加入任何有超过50%的机会提供正确裁决的人，并平均他们的决策。每次添加另一位成员（并且他们的选择过程是独立于其他人的），你都会得到更好的结果。
- en: The idea with random forests is to create a “forest” of decision trees trained
    on different columns of the training data. If each tree has a better than 50%
    chance of correct classification, you should incorporate its prediction. The random
    forest has been an excellent tool for both classification and regression, though
    it has recently fallen out of favor for gradient-boosted trees.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林的理念是在训练数据的不同列上创建许多决策树的“森林”。如果每棵树有超过50%的正确分类几率，应该合并它们的预测。随机森林既可用于分类也可用于回归，尽管最近已经不再流行梯度提升树。
- en: 'It has the following properties:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 它具有以下属性：
- en: Runtime efficiency
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时效率
- en: Need to create j random trees. This can be done in parallel using `n_jobs`.
    Complexity for each tree is O(mn log n), where n is the number of samples and
    m is the number of features. For creation, loop over each of the m features, and
    sort all n samples, O(mn log n). For predicting, walk the tree O( height).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 需要创建j棵随机树。这可以使用`n_jobs`并行进行。每棵树的复杂度为O(mn log n)，其中n是样本数，m是特征数。对于创建，遍历每个m个特征，并对所有n个样本排序，O(mn
    log n)。对于预测，遍历树O(高度)。
- en: Preprocess data
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理数据
- en: Not necessary.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 不必要。
- en: Prevent overfitting
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 防止过拟合
- en: Add more trees (`n_estimators`). Use lower `max_depth`.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 增加更多的树（`n_estimators`）。使用较低的`max_depth`。
- en: Interpret results
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 解释结果
- en: Supports feature importance, but we don’t have a single decision tree that we
    can walk through. Can inspect single trees from the ensemble.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 支持特征重要性，但我们没有一个可以浏览的单个决策树。可以检查集成中的单个树。
- en: 'Here is an example:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个例子：
- en: '[PRE14]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Instance parameters (these options mirror the decision tree):'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 实例参数（这些选项反映了决策树）：
- en: '`bootstrap=True`'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '`bootstrap=True`'
- en: Bootstrap when building trees.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 构建树时的自举法。
- en: '`class_weight=None`'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`class_weight=None`'
- en: Weights for class in dictionary. `'balanced'` will set values to the inverse
    proportion of class frequencies. Default is a value of 1 for each class. For multiclass,
    need a list of dictionaries (OVR) for each class.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 字典中类的权重。`'balanced'`会设置为类频率的倒数比例。默认为每个类的值为1。对于多类别，需要每个类的字典列表（OVR）。
- en: '`criterion=''gini''`'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '`criterion=''gini''`'
- en: Splitting function, `'gini'` or `'entropy'`.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 分裂函数，`'gini'`或`'entropy'`。
- en: '`max_depth=None`'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_depth=None`'
- en: Depth of tree. Default will build until leaves contain less than `min_samples_split`.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 树的深度。默认将构建直到叶子节点包含少于`min_samples_split`。
- en: '`max_features=''auto''`'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_features=''auto''`'
- en: Number of features to examine for split. Default is all.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查拆分的特征数。默认为全部。
- en: '`max_leaf_nodes=None`'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_leaf_nodes=None`'
- en: Limit the number of leaves. Default is unlimited.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 限制叶子节点的数量。默认为无限制。
- en: '`min_impurity_decrease=0.0`'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_impurity_decrease=0.0`'
- en: Split node if a split will decrease impurity >= value.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 如果分裂将使不纯度减少大于或等于值，则分裂节点。
- en: '`min_impurity_split=None`'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_impurity_split=None`'
- en: Deprecated.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 废弃的。
- en: '`min_samples_leaf=1`'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_samples_leaf=1`'
- en: Minimum number of samples at each leaf.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 每个叶子节点的最小样本数。
- en: '`min_samples_split=2`'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_samples_split=2`'
- en: Minimum number of samples required to split a node. `min_weight_fraction_leaf=0.0`-
    Minimum sum total of weights required for leaf nodes.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 分裂节点所需的最小样本数。`min_weight_fraction_leaf=0.0`- 叶子节点所需的最小总权重。
- en: '* `n_estimators=10`'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '* `n_estimators=10`'
- en: Number of trees in the forest.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 森林中的树的数量。
- en: '`n_jobs=1`'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_jobs=1`'
- en: Number of jobs for fitting and predicting.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 用于拟合和预测的作业数。
- en: '`oob_score=False`'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '`oob_score=False`'
- en: Whether to estimate `oob_score`.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 是否估算`oob_score`。
- en: '`random_state=None`'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '`random_state=None`'
- en: Random seed.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 随机种子。
- en: '`verbose=0`'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '`verbose=0`'
- en: Verbosity.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 冗余性。
- en: '`warm_start=False`'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '`warm_start=False`'
- en: Fit a new forest or use the existing one.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合新的森林或使用现有的森林。
- en: 'Attributes after fitting:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合后的属性：
- en: '`classes_`'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '`classes_`'
- en: Class labels.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 类标签。
- en: '`feature_importances_`'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '`feature_importances_`'
- en: Array of Gini importance.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 基尼重要性数组。
- en: '`n_classes_`'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_classes_`'
- en: Number of classes.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 类的数量。
- en: '`n_features_`'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_features_`'
- en: Number of features.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 特征数量。
- en: '`oob_score_`'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '`oob_score_`'
- en: OOB score. Average accuracy for each observation not used in trees.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: OOB分数。未在树中使用的每个观察的平均准确度。
- en: 'Feature importance showing Gini importance (reduction of error by using that
    feature):'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 特征重要性显示基尼重要性（使用该特征减少误差）：
- en: '[PRE15]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Tip
  id: totrans-330
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The random forest classifier computes the feature importance by determining
    the *mean decrease in impurity* for each feature (also known as Gini importance).
    Features that reduce uncertainty in classification receive higher scores.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林分类器通过确定每个特征的*不纯度平均减少*（也称为基尼重要性）来计算特征重要性。减少分类不确定性的特征得分较高。
- en: 'These numbers might be off if features vary in scale or cardinality of categorical
    columns. A more reliable score is *permutation importance* (where each column
    has its values permuted and the drop in accuracy is measured). An even more reliable
    mechanism is *drop column importance* (where each column is dropped and the model
    is re-evaluated), but sadly this requires creating a new model for each column
    that is dropped. See the `importances` function in the `rfpimp` package:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 如果特征在规模或分类列的基数上变化，则这些数字可能会有所偏差。*排列重要性*是一个更可靠的分数（其中每列的值被排列并测量准确度下降）。*删除列重要性*是一个更可靠的机制（其中删除每列并重新评估模型），但遗憾的是这需要为删除的每列创建一个新模型。请参阅
    `rfpimp` 包中的 `importances` 函数：
- en: '[PRE16]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: XGBoost
  id: totrans-334
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: XGBoost
- en: Although sklearn has a `GradientBoostedClassifier`, it is better to use a third-party
    implementation that uses extreme boosting. These tend to provide better results.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 sklearn 有一个 `GradientBoostedClassifier`，但最好使用使用极限提升的第三方实现。这些通常提供更好的结果。
- en: '[XGBoost](https://oreil.ly/WBo0g) is a popular library outside of scikit-learn.
    It creates a weak tree and then “boosts” the subsequent trees to reduce the residual
    errors. It tries to capture and address any patterns in the errors until they
    appear to be random.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '[XGBoost](https://oreil.ly/WBo0g) 是 scikit-learn 之外的一个流行库。它创建一个弱树，然后“提升”后续的树以减少残差误差。它试图捕捉并解决任何错误中的模式，直到它们看起来是随机的。'
- en: 'XGBoost has the following properties:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 具有以下特性：
- en: Runtime efficiency
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 运行效率
- en: XGBoost is parallelizeable. Use the `n_jobs` option to indicate the number of
    CPUs. Use GPU for even better performance.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 可并行化。使用 `n_jobs` 选项指示 CPU 数量。使用 GPU 可获得更好的性能。
- en: Preprocess data
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理数据
- en: No scaling necessary with tree models. Need to encode categorical data.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 树模型无需缩放。需要对分类数据进行编码。
- en: Prevent overfitting
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 防止过拟合
- en: The `early_stopping_rounds=N` parameter can be set to stop training if there
    is no improvement after N rounds. L1 and L2 regularization are controlled by `reg_alpha`
    and `reg_lambda`, respectively. Higher numbers are more conservative.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 如果经过 N 轮后没有改善，则可以设置 `early_stopping_rounds=N` 参数停止训练。L1 和 L2 正则化分别由 `reg_alpha`
    和 `reg_lambda` 控制。较高的数值更为保守。
- en: Interpret results
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 解释结果
- en: Has feature importance.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 具有特征重要性。
- en: 'XGBoost has an extra parameter for the `.fit` method. The `early_stopping_rounds`
    parameter can be combined with the `eval_set` parameter to tell XGBoost to stop
    creating trees if the evaluation metric has not improved after that many boosting
    rounds. The `eval_metric` can also be set to one of the following: `''rmse''`,
    `''mae''`, `''logloss''`, `''error''` (default), `''auc''`, `''aucpr''`, as well
    as a custom function.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 在 `.fit` 方法中有一个额外的参数。`early_stopping_rounds` 参数可以与 `eval_set` 参数结合使用，告诉
    XGBoost 如果在这么多提升轮之后评估指标没有改善，则停止创建树。`eval_metric` 也可以设置为以下之一：`'rmse'`、`'mae'`、`'logloss'`、`'error'`（默认）、`'auc'`、`'aucpr'`，以及自定义函数。
- en: 'Here is an example using the library:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用该库的示例：
- en: '[PRE17]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Instance parameters:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 实例参数：
- en: '`max_depth=3`'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_depth=3`'
- en: Maximum depth.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 最大深度。
- en: '`learning_rate=0.1`'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '`learning_rate=0.1`'
- en: Learning rate (also called eta) for boosting (between 0 and 1). After each boost
    step, the newly added weights are scaled by this factor. The lower the value,
    the more conservative, but will also need more trees to converge. In the call
    to `.train`, you can pass a `learning_rates` parameter, which is a list of rates
    at each round (i.e., `[.1]*100 + [.05]*100`).
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 提升（在 0 和 1 之间）的学习率（也称为 eta）。在每次提升步骤之后，新添加的权重会按此因子进行缩放。值越低，越保守，但也需要更多的树来收敛。在调用
    `.train` 时，可以传递一个 `learning_rates` 参数，这是每一轮的速率列表（例如，`[.1]*100 + [.05]*100`）。
- en: '`n_estimators=100`'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_estimators=100`'
- en: Number of rounds or boosted trees.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 轮次或提升树的数量。
- en: '`silent=True`'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '`silent=True`'
- en: Opposite of verbose. Whether to print messages while running boosting.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 相反于冗长。在运行提升过程时是否打印消息。
- en: '`objective=''binary:logistic''`'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '`objective=''binary:logistic''`'
- en: Learning task or callable for classification.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 分类的学习任务或可调用对象。
- en: '`booster=''gbtree''`'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '`booster=''gbtree''`'
- en: Can be `'gbtree'`, `'gblinear'`, or `'dart'`.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 可以是 `'gbtree'`、`'gblinear'` 或 `'dart'`。
- en: '`nthread=None`'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '`nthread=None`'
- en: Deprecated.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 弃用。
- en: '`n_jobs=1`'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_jobs=1`'
- en: Number of threads to use.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用的线程数。
- en: '`gamma=0`'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '`gamma=0`'
- en: Controls pruning. Range is 0 to infinite. Minimum loss reduction needed to further
    split a leaf. Higher gamma is more conservative. If training and test scores are
    diverging, insert a higher number (around 10). If training and test scores are
    close, use a lower number.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 控制剪枝。范围是 0 到无穷大。进一步分割叶子所需的最小损失减少。较高的 gamma 更加保守。如果训练和测试分数发散，请插入一个较高的数字（大约为 10）。如果训练和测试分数接近，请使用较低的数字。
- en: '`min_child_weight=1`'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_child_weight=1`'
- en: Minimum value for sum of hessian for a child.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 子节点的 hessian 和的最小值。
- en: '`max_delta_step=0`'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_delta_step=0`'
- en: Make update more conservative. Set 1 to 10 for imbalanced classes.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 使更新更加保守。对于不平衡的类，将 1 设置为 10。
- en: '`subsample=1`'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '`subsample=1`'
- en: Fraction of samples to use for next round.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 下一轮使用的样本比例。
- en: '`colsample_bytree=1`'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '`colsample_bytree=1`'
- en: Fraction of columns to use for round.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 用于回合的列比例。
- en: '`colsample_bylevel=1`'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '`colsample_bylevel=1`'
- en: Fraction of columns to use for level.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 用于级别的列比例。
- en: '`colsample_bynode=1`'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '`colsample_bynode=1`'
- en: Fraction of columns to use for node.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 用于节点的列比例。
- en: '`reg_alpha=0`'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '`reg_alpha=0`'
- en: L1 regularization (mean of weights) encourages sparsity. Increase to be more
    conservative.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: L1 正则化（权重的平均值）鼓励稀疏性。增加以更加保守。
- en: '`reg_lambda=1`'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '`reg_lambda=1`'
- en: L2 regularization (root of squared weights) encourages small weights. Increase
    to be more conservative.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: L2 正则化（权重平方的根）鼓励小权重。增加以更加保守。
- en: '`scale_pos_weight=1`'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '`scale_pos_weight=1`'
- en: Ratio of negative/positive weight.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 负/正权重比例。
- en: '`base_score=.5`'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '`base_score=.5`'
- en: Initial prediction.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 初始预测。
- en: '`seed=None`'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '`seed=None`'
- en: Deprecated.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 已弃用。
- en: '`random_state=0`'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '`random_state=0`'
- en: Random seed.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 随机种子。
- en: '`missing=None`'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '`missing=None`'
- en: Value to interpret for `missing`. `None` means `np.nan`.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '`missing` 的解释值。`None` 表示 `np.nan`。'
- en: '`importance_type=''gain''`'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '`importance_type=''gain''`'
- en: 'The feature importance type: `''gain''`, `''weight''`, `''cover''`, `''total_gain''`,
    or `''total_cover''`.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 特征重要性类型：`'gain'`、`'weight'`、`'cover'`、`'total_gain'` 或 `'total_cover'`。
- en: 'Attributes:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 属性：
- en: '`coef_`'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '`coef_`'
- en: Coefficients for gblinear learners
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: gblinear 学习器的系数
- en: '`feature_importances_`'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '`feature_importances_`'
- en: Feature importances for gbtree learners
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: gbtree 学习器的特征重要性
- en: 'Feature importance is the average gain across all the nodes where the feature
    is used:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 特征重要性是使用该特征的所有节点的平均增益：
- en: '[PRE18]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'XGBoost can plot the feature importance (see [Figure 10-5](#id25)). It has
    an `importance_type` parameter. The default value is `"weight"`, which is the
    number of times a feature appears in a tree. It can also be `"gain"`, which shows
    the average gain when the feature is used, or `"cover"`, which is the number of
    samples affected by a split:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 可以绘制特征重要性（参见[图 10-5](#id25)）。它有一个 `importance_type` 参数。默认值是 `"weight"`，即特征出现在树中的次数。也可以是
    `"gain"`，显示特征使用时的平均增益，或者是 `"cover"`，即受到拆分影响的样本数：
- en: '[PRE19]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![Feature importance showing weight (how many times a feature appears in the
    trees).](assets/mlpr_1005.png)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![特征重要性显示权重（特征在树中出现的次数）。](assets/mlpr_1005.png)'
- en: Figure 10-5\. Feature importance showing weight (how many times a feature appears
    in the trees).
  id: totrans-406
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-5\. 特征重要性显示权重（特征在树中出现的次数）。
- en: 'We can plot this in Yellowbrick, which normalizes the values (see [Figure 10-6](#id26)):'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 Yellowbrick 中绘制这个，它会归一化这些值（参见[图 10-6](#id26)）：
- en: '[PRE20]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![Yellowbrick feature importance for XGBoost (normalized to 100).](assets/mlpr_1006.png)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![XGBoost的 Yellowbrick 特征重要性（归一化为 100）。](assets/mlpr_1006.png)'
- en: Figure 10-6\. Yellowbrick feature importance for XGBoost (normalized to 100).
  id: totrans-410
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-6\. XGBoost 的 Yellowbrick 特征重要性（归一化为 100）。
- en: 'XGBoost provides both a textual representation of the trees and a graphical
    one. Here is the text representation:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 提供了树的文本表示和图形表示。这是文本表示：
- en: '[PRE21]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The value in the leaf is the score for class 1\. It can be converted into a
    probability using the logistic function. If the decisions fell through to leaf
    7, the probability of class 1 is 53%. This is the score from a single tree. If
    our model had 100 trees, you would sum up each leaf value and get the probability
    with the logistic function:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 叶子中的值是类 1 的分数。可以使用 logistic 函数将其转换为概率。如果决策落到叶子 7，则类 1 的概率为 53%。这是单棵树的分数。如果我们的模型有
    100 棵树，您将对每个叶子值求和，并使用 logistic 函数获得概率：
- en: '[PRE22]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here is the graphical version of the first tree in the model (see [Figure 10-7](#id27)):'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 这是模型中第一棵树的图形版本（参见[图 10-7](#id27)）：
- en: '[PRE23]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![Tree of XGBoost.](assets/mlpr_1007.png)'
  id: totrans-417
  prefs: []
  type: TYPE_IMG
  zh: '![XGBoost的树形结构。](assets/mlpr_1007.png)'
- en: Figure 10-7\. Tree of XGBoost.
  id: totrans-418
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-7\. XGBoost 的树形结构。
- en: The [xgbfir package](https://oreil.ly/kPnRv) is a library built on top of XGBoost.
    This library gives various measures about feature importance. What is unique is
    that it provides these measures about the columns, and also pairs of columns,
    so you can see the interactions. In addition, you can get information about triplets
    (three-column) interactions.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '[xgbfir 包](https://oreil.ly/kPnRv) 是建立在 XGBoost 之上的一个库。该库提供关于特征重要性的各种度量。独特之处在于，它提供关于列和列对的这些度量，因此您可以查看交互。此外，您还可以获取关于三元组（三列）交互的信息。'
- en: 'The measures it provides are:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供的度量有：
- en: '`Gain`'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '`Gain`'
- en: Total gain of each feature or feature interaction
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 每个特征或特征交互的总增益
- en: '`FScore`'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '`FScore`'
- en: Amount of possible splits taken on a feature or feature interaction
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 每个特征或特征交互可能的分割数量
- en: '`wFScore`'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '`wFScore`'
- en: Amount of possible splits taken on a feature or feature interaction, weighted
    by the probability of the splits to take place
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 每个特征或特征交互可能的分割数量，按照分割发生的概率加权
- en: '`Average wFScore`'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '`Average wFScore`'
- en: '`wFScore` divided by `FScore`'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: '`wFScore` 除以 `FScore`'
- en: '`Average Gain`'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '`Average Gain`'
- en: '`Gain` divided by `FScore`'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '`Gain` 除以 `FScore`'
- en: '`Expected Gain`'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '`Expected Gain`'
- en: Total gain of each feature or feature interaction weighted by the probability
    to gather the gain
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 每个特征或特征交互的总增益，按照收集增益的概率加权
- en: 'The interface is simply an export to a spreadsheet, so we will use pandas to
    read them back in. Here is the column importance:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 接口只是将其导出到电子表格，因此我们将使用 pandas 将其读取回来。这里是列重要性：
- en: '[PRE24]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: From this table, we see sex_male ranks high in gain, average wFScore, average
    gain, and expected gain, whereas fare tops out in FScore and wFScore.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个表格中，我们看到 sex_male 在增益、平均 wFScore、平均增益和预期增益中排名较高，而 fare 在 FScore 和 wFScore
    中占据前列。
- en: 'Let’s look at pairs of column interactions:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看列之间的交互对：
- en: '[PRE25]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Here we see that the top two interactions involve the sex_male column in combination
    with pclass and age. If you were only able to make a model with two features,
    you would probably want to choose pclass and sex_male.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到排名前两位的交互包括 sex_male 列与 pclass 和 age 的组合。如果您只能使用两个特征来建模，您可能会选择 pclass
    和 sex_male。
- en: 'Finally, let’s look at triplets:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们来看一下三元组：
- en: '[PRE26]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This is only showing the first triplet due to space limitations, but the spreadsheet
    has many more:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 由于空间限制，这里只展示了第一个三元组，但是电子表格中还有更多：
- en: '[PRE27]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Gradient Boosted with LightGBM
  id: totrans-443
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LightGBM 进行梯度增强
- en: LightGBM is an implementation by Microsoft. LightGBM uses a sampling mechanism
    to deal with continuous values. This allows quicker creation of trees (than say
    XGBoost), and reduces memory usage.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: LightGBM 是 Microsoft 的一种实现。LightGBM 使用采样机制来处理连续值。这使得树的创建更快（比如 XGBoost），并减少了内存使用。
- en: LightGBM also grows trees depth first (*leaf-wise* rather than *level-wise*).
    Because of this, rather than using `max_depth` to control overfitting, use `num_leaves`
    (where this value is < 2^(`max_depth`)).
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: LightGBM 也是深度优先增长树（以叶子为基础而不是层次为基础）。因此，与使用 `max_depth` 控制过拟合不同，应使用 `num_leaves`（其中此值
    < 2^(`max_depth`)）。
- en: Note
  id: totrans-446
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Installation of this library currently requires having a compiler and is a little
    more involved than just a `pip install`.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 当前安装这个库需要编译器，并且比简单的 `pip install` 更复杂一些。
- en: 'It has the following properties:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 它具有以下特性：
- en: Runtime efficiency
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 运行效率
- en: Can take advantage of multiple CPUs. By using binning, can be 15 times faster
    than XGBoost.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 可以利用多个 CPU。通过使用分箱，比 XGBoost 快 15 倍。
- en: Preprocess data
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理数据
- en: Has some support for encoding categorical columns as integers (or pandas `Categorical`
    type), but AUC appears to suffer compared to one-hot encoding.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 对将分类列编码为整数（或 pandas 的 `Categorical` 类型）提供了一些支持，但是与独热编码相比，AUC 表现似乎有所下降。
- en: Prevent overfitting
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 防止过拟合
- en: Lower `num_leaves`. Increase `min_data_in_leaf`. Use `min_gain_to_split` with
    `lambda_l1` or `lambda_l2`.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 减小 `num_leaves`。增加 `min_data_in_leaf`。使用 `min_gain_to_split` 和 `lambda_l1` 或
    `lambda_l2`。
- en: Interpret results
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 解释结果
- en: Feature importance is available. Individual trees are weak and tend to be hard
    to interpret.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的特征重要性。单棵树弱，往往难以解释。
- en: 'Here is an example using the library:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用该库的一个示例：
- en: '[PRE28]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Instance parameters:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 实例参数：
- en: '`boosting_type=''gbdt''`'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '`boosting_type=''gbdt''`'
- en: 'Can be: `''gbdt''` (gradient boosting), `''rf''` (random forest), `''dart''`
    (dropouts meet multiple additive regression trees), or `''goss''` (gradient-based,
    one-sided sampling).'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 可以是：`'gbdt'`（梯度提升树），`'rf'`（随机森林），`'dart'`（Dropouts Meet Multiple Additive Regression
    Trees），或者`'goss'`（基于梯度的单侧采样）。
- en: '`class_weight=None`'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: '`class_weight=None`'
- en: Dictionary or `'balanced'`. Use dictionary to set weight for each class label
    when doing multiclass problems. For binary problems, use `is_unbalance` or `scale_pos_weight`.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 字典或者`'balanced'`。在多类问题中，使用字典设置每个类标签的权重。对于二元问题，使用`is_unbalance`或`scale_pos_weight`。
- en: '`colsample_bytree=1.0`'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '`colsample_bytree=1.0`'
- en: Range (0, 1.0]. Select percent of features for each boosting round.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 范围（0, 1.0]。选择每个增强轮次的特征百分比。
- en: '`importance_type=''split''`'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: '`importance_type=''split''`'
- en: How to calculate feature importance. `'split'` means number of times a feature
    is used. `'gain'` is total gains of splits for a feature.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 如何计算特征重要性。`'split'` 表示特征使用次数。`'gain'` 表示特征分裂的总增益。
- en: '`learning_rate=0.1`'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '`learning_rate=0.1`'
- en: Range (0, 1.0]. Learning rate for boosting. A smaller value slows down overfitting
    as boosting rounds have less impact. A smaller number should give better performance
    but will require more `num_iterations`.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 范围（0, 1.0]。增强学习的学习率。较小的值减缓过拟合，因为增强轮次的影响减少。较小的数字应该提供更好的性能，但会需要更多的`num_iterations`。
- en: '`max_depth=-1`'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_depth=-1`'
- en: Maximum tree depth. -1 is unlimited. Larger depths tend to overfit more.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 最大树深度。-1 表示无限制。更大的深度往往会导致过拟合。
- en: '`min_child_samples=20`'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_child_samples=20`'
- en: Number of samples required for a leaf. Lower numbers mean more overfitting.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 叶子所需的样本数。较低的数字意味着更多的过拟合。
- en: '`min_child_weight=0.001`'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_child_weight=0.001`'
- en: Sum of hessian weight required for a leaf.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 叶子所需的海森权重总和。
- en: '`min_split_gain=0.0`'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_split_gain=0.0`'
- en: Loss reduction required to partition leaf.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 分区叶子所需的损失减少。
- en: '`n_estimators=100`'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_estimators=100`'
- en: Number of trees or boosting rounds.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 树的数量或增强轮数。
- en: '`n_jobs=-1`'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_jobs=-1`'
- en: Number of threads.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 线程数。
- en: '`num_leaves=31`'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '`num_leaves=31`'
- en: Maximum tree leaves.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 最大树叶子。
- en: '`objective=None`'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '`objective=None`'
- en: '`None` is `''binary''` or `''multiclass''` for classifier. Can be a function
    or string.'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: '`None` 是分类器的`''binary''`或`''multiclass''`。可以是函数或字符串。'
- en: '`random_state=42`'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '`random_state=42`'
- en: Random seed.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 随机种子。
- en: '`reg_alpha=0.0`'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '`reg_alpha=0.0`'
- en: L1 regularization (mean of weights). Increase to be more conservative.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: L1 正则化（权重的均值）。增加以更加保守。
- en: '`reg_lambda=0.0`'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '`reg_lambda=0.0`'
- en: L2 regularization (root of squared weights). Increase to be more conservative.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: L2 正则化（权重的平方根）。增加以更加保守。
- en: '`silent=True`'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '`silent=True`'
- en: Verbose mode.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 详细模式。
- en: '`subsample=1.0`'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: '`subsample=1.0`'
- en: Fraction of samples to use for next round.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 下一轮使用的样本比例。
- en: '`subsample_for_bin=200000`'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '`subsample_for_bin=200000`'
- en: Samples required to create bins.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 创建箱子所需的样本。
- en: '`subsample_freq=0`'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '`subsample_freq=0`'
- en: Subsample frequency. Change to 1 to enable.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 子采样频率。设置为1以启用。
- en: 'Feature importance based on `''splits''` (number of times a product is used):'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 基于`'splits'`（产品使用次数）的特征重要性：
- en: '[PRE29]'
  id: totrans-501
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The LightGBM library supports creating a feature importance plot (see [Figure 10-8](#id23)).
    The default is based on `''splits''`, the number of times a feature is used. You
    can specify `''importance_type''` if you want to change it to `''gain''`:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: LightGBM 库支持创建特征重要性图（见[图 10-8](#id23)）。默认基于`'splits'`，即特征使用次数。如果要更改为`'gain'`，可以指定`'importance_type'`：
- en: '[PRE30]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![Feature Importance splits for LightGBM.](assets/mlpr_1008.png)'
  id: totrans-504
  prefs: []
  type: TYPE_IMG
  zh: '![LightGBM 的特征重要性拆分。](assets/mlpr_1008.png)'
- en: Figure 10-8\. Feature importance splits for LightGBM.
  id: totrans-505
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-8\. LightGBM 的特征重要性拆分。
- en: Warning
  id: totrans-506
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: As of version 0.9, Yellowbrick doesn’t work with LightGBM for creating feature
    importance plots.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 截至版本0.9，Yellowbrick 不支持与 LightGBM 一起创建特征重要性图。
- en: 'We can create a tree of the decisions as well (see [Figure 10-9](#id24)):'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以创建决策树（见[图 10-9](#id24)）：
- en: '[PRE31]'
  id: totrans-509
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![LightGBM tree.](assets/mlpr_1009.png)'
  id: totrans-510
  prefs: []
  type: TYPE_IMG
  zh: '![LightGBM 树。](assets/mlpr_1009.png)'
- en: Figure 10-9\. LightGBM tree.
  id: totrans-511
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-9\. LightGBM 树。
- en: Tip
  id: totrans-512
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'In Jupyter, use the following command to view a tree:'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Jupyter 中，使用以下命令查看树：
- en: '[PRE32]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: TPOT
  id: totrans-515
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TPOT
- en: '[TPOT](https://oreil.ly/NFJvl) uses a genetic algorithm to try different models
    and ensembles. This can take hours to days to run as it considers multiple models
    and preprocessing steps, as well as the hyperparameters for said models, and ensembling
    options. On a typical machine, a generation may take five or more minutes to run.'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: '[TPOT](https://oreil.ly/NFJvl) 使用遗传算法尝试不同的模型和集成方法。由于考虑了多个模型、预处理步骤以及这些模型的超参数和集成选项，因此可能需要几小时甚至几天才能运行。在典型的机器上，一代可能需要五分钟或更长时间才能运行。'
- en: 'It has the following properties:'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 其具有以下属性：
- en: Runtime efficiency
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 运行效率
- en: Can take hours or days. Use `n_jobs=-1` to use all CPUs.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 可以花费几小时或几天。使用`n_jobs=-1`可以使用所有CPU。
- en: Preprocess data
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理数据
- en: You need to remove NaN and categorical data.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要删除 NaN 和分类数据。
- en: Prevent overfitting
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 防止过拟合
- en: Ideally, results should use cross-validation to minimize overfitting.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，结果应使用交叉验证以最小化过拟合。
- en: Interpret results
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 解释结果
- en: Depends on the results.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 取决于结果。
- en: 'Here is an example of using the library:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用该库的示例：
- en: '[PRE33]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Instance parameters:'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 实例参数：
- en: '`generations=100`'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: '`generations=100`'
- en: Iterations to run.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 运行的迭代次数。
- en: '`population_size=100`'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '`population_size=100`'
- en: Population size for genetic programming. Larger size usually performs better
    but takes more memory and time.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 遗传编程的种群大小。通常较大的大小性能更好，但需要更多内存和时间。
- en: '`offspring_size=None`'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: '`offspring_size=None`'
- en: Offspring for each generation. Default is `population_size`.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 每代的后代数。默认为`population_size`。
- en: '`mutation_rate=.9`'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: '`mutation_rate=.9`'
- en: Mutation rate for algorithm [0, 1]. Default is .9.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的变异率[0, 1]。默认为0.9。
- en: '`crossover_rate=.1`'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: '`crossover_rate=.1`'
- en: Cross-over rate (how many pipelines to breed in a generation). Range [0, 1].
    Default is .1.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉率（在一代中繁殖多少个管道）。范围[0, 1]。默认为0.1。
- en: '`scoring=''accuracy''`'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: '`scoring=''accuracy''`'
- en: Scoring mechanism. Uses sklearn strings.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 评分机制。使用sklearn字符串。
- en: '`cv=5`'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv=5`'
- en: Cross-validation folds.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证折数。
- en: '`subsample=1`'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: '`subsample=1`'
- en: Subsample training instances. Range [0, 1]. Default is 1.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 对训练实例进行子采样。范围[0, 1]。默认为1。
- en: '`n_jobs=1`'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_jobs=1`'
- en: Number of CPUs to use, -1 for all cores.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的CPU数量，-1表示所有核心。
- en: '`max_time_mins=None`'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_time_mins=None`'
- en: Maximum amount of minutes to run.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 运行的最大分钟数。
- en: '`max_eval_time_mins=5`'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_eval_time_mins=5`'
- en: Maximum amount of minutes to evaluate a single pipeline.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 评估单个管道的最大分钟数。
- en: '`random_state=None`'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '`random_state=None`'
- en: Random seed.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 随机种子。
- en: '`config_dict`'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: '`config_dict`'
- en: Configuration options for optimization.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 优化的配置选项。
- en: '`warm_start=False`'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '`warm_start=False`'
- en: Reuse previous calls to `.fit`.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 重用以前的`.fit`调用。
- en: '`memory=None`'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: '`memory=None`'
- en: Can cache pipelines. `'auto'` or a path will persist in a directory.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 可以缓存管道。`'auto'`或路径会持久化到一个目录。
- en: '`use_dask=False`'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: '`use_dask=False`'
- en: Use dask.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 使用dask。
- en: '`periodic_checkpoint_folder=None`'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: '`periodic_checkpoint_folder=None`'
- en: Path to a folder where the best pipeline will be persisted periodically.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳管道定期保存的文件夹路径。
- en: '`early_stop=None`'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '`early_stop=None`'
- en: Stop after running this many generations with no improvement.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行这么多代没有改进后停止。
- en: '`verbosity=0`'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: '`verbosity=0`'
- en: 0 = none, 1 = minimal, 2 = high, or 3 = all. 2 and higher shows a progress bar.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 0 = 无，1 = 最小，2 = 高，或3 = 全部。2及以上显示进度条。
- en: '`disable_update_check=False`'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: '`disable_update_check=False`'
- en: Disable version check.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用版本检查。
- en: 'Attributes:'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 属性：
- en: '`evaluated_individuals_`'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: '`evaluated_individuals_`'
- en: Dictionary with all pipelines that were evaluated.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 包含所有评估过的管道的字典。
- en: '`fitted_pipeline_`'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '`fitted_pipeline_`'
- en: Best pipeline.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳管道。
- en: 'After you are done, you can export the pipeline:'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，可以导出管道：
- en: '[PRE34]'
  id: totrans-575
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The result might look like this:'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可能如下所示：
- en: '[PRE35]'
  id: totrans-577
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
