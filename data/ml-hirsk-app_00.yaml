- en: Foreword
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: Renowned statistician George Box once famously stated, “All models are wrong,
    but some are useful.” Acknowledgment of this fact forms the foundation of effective
    risk management. In a world where machine learning increasingly automates important
    decisions about our lives, the consequences of model failures can be catastrophic.
    It’s critical to take deliberate steps to mitigate risk and avoid unintended harm.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 著名统计学家乔治·博克斯曾经著名地说过：“所有模型都是错误的，但有些是有用的。”承认这一事实构成有效风险管理的基础。在机器学习日益自动化我们生活中重要决策的世界中，模型失败的后果可能是灾难性的。采取刻意措施来减轻风险并避免意外伤害至关重要。
- en: Following the 2008 financial crisis, regulators and financial institutions recognized
    the importance of managing model risk in ensuring the safety of banks, refining
    the practice of model risk management (MRM). As AI and machine learning gain widespread
    adoption, MRM principles are being applied to manage their risk. The National
    Institute of Standards and Technology’s AI Risk Management Framework serves as
    an example of this evolution. Proper governance and control of the entire process,
    from senior management oversight to policy and procedures, including organizational
    structure and incentives, are crucial to promoting a culture of model risk management.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在2008年金融危机之后，监管机构和金融机构意识到管理模型风险以确保银行安全的重要性，完善了模型风险管理（MRM）的实践。随着人工智能和机器学习的广泛应用，MRM原则正在被应用于管理其风险。美国国家标准与技术研究院的AI风险管理框架作为这一演变的例证。从高级管理监督到政策和程序，包括组织结构和激励措施，正确治理和控制整个过程对于促进模型风险管理文化至关重要。
- en: In *Machine Learning for High-Risk Applications*, Hall, Curtis, and Pandey have
    presented a framework for applying machine learning to high-stakes decision making.
    They provide compelling evidence through documented cases of model failures and
    emerging regulations that highlight the importance of strong governance and culture.
    Unfortunately, these principles are still rarely implemented outside of regulated
    industries, such as banks. The book covers important topics ranging across model
    transparency, governance, security, bias management, and more.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在《面向高风险应用的机器学习》中，霍尔、柯蒂斯和潘迪提出了一个框架，用于将机器学习应用于重大决策。通过记录的模型失败案例和新兴法规提供了令人信服的证据，强调了强有力的治理和文化的重要性。不幸的是，这些原则在非受监管行业，如银行之外，仍然很少被实施。该书涵盖了重要的主题，包括模型透明性、治理、安全性、偏见管理等。
- en: Performance testing alone is not enough in machine learning, where very different
    models can have the same performance due to model multiplicity. Models must also
    be explainable, secure, and fair. This is the first book that emphasizes inherently
    interpretable models and their recent development and application, particularly
    in cases where models impact individuals, such as in consumer finance. In these
    scenarios, where explainability standards and regulations are particularly stringent,
    the explainable AI (XAI) post hoc explainability approach often faces significant
    challenges.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，仅进行性能测试是不够的，因为非常不同的模型可能由于模型多样性而具有相同的性能。模型还必须具有可解释性、安全性和公平性。这是第一本强调固有可解释模型及其最近的发展和应用的书籍，特别是在模型影响个人的情况下，如消费金融领域。在这些场景中，解释性人工智能（XAI）事后解释方法通常面临重大挑战。
- en: Developing reliable and safe machine learning systems also requires a rigorous
    evaluation of model weaknesses. This book presents two thorough examples alongside
    a methodology for model debugging, including identifying model flaws through error
    or residual slicing, evaluating model robustness under input corruption, assessing
    the reliability or uncertainty of model outputs, and testing model resilience
    under distribution shift through stress testing. These are crucial topics for
    developing and deploying machine learning in high-risk settings.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 开发可靠和安全的机器学习系统还需要严格评估模型的弱点。本书提供了两个详尽的示例以及模型调试方法论，包括通过错误或残差切片识别模型缺陷，评估输入数据损坏下模型的鲁棒性，评估模型输出的可靠性或不确定性，以及通过压力测试测试模型在分布变化下的弹性。这些对于在高风险环境中开发和部署机器学习至关重要。
- en: Machine learning models have the potential to disproportionately harm historically
    marginalized groups, and to deliver this harm rapidly and at scale through automation.
    Biased model decisions have detrimental impacts on protected groups, perpetuating
    social and economic disparities. In this book, the reader will learn how to approach
    the issue of model fairness through a sociotechnical lens. The authors also detail
    a thorough study of the effects of model debiasing techniques, and give practical
    advice on the application of these techniques within different regulated verticals.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型有潜力通过自动化迅速且规模化地对历史上被边缘化的群体造成不成比例的伤害。偏见的模型决策对受保护群体产生有害影响，持续加剧社会和经济差距。本书将教读者如何通过社会技术视角解决模型公平性问题。作者还详细研究了模型去偏差技术的影响，并就如何在不同受监管行业应用这些技术提供了实用建议。
- en: '*Machine Learning for High-Risk Applications* is a practical, opinionated,
    and timely book. Readers of all stripes will find rich insights into this fraught
    subject, whether you’re a data scientist interested in better understanding your
    models, or a manager responsible for ensuring compliance with existing standards,
    or an executive trying to improve your organization’s risk controls.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*《高风险应用的机器学习》* 是一本实用、主观和及时的书籍。各类读者都能在这个充满挑战的主题中找到丰富的见解，无论你是一名数据科学家，希望更好地理解你的模型，还是一名负责确保符合现有标准的经理，或者是一名试图改进组织风险控制的高管。'
- en: Agus Sudjianto, PhD
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Agus Sudjianto，博士
- en: EVP, Head of Corporate Model Risk, Wells Fargo
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 威尔斯法格（Wells Fargo）公司模型风险负责人，执行副总裁（EVP）
