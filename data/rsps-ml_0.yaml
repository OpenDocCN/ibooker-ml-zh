- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: Machine learning (ML) sits at the cross section of business applications, statistics,
    and computer science. It’s seen several waves of hype and disappointment in its
    roughly 60-year history. It’s a big, technical subject, and it’s also emerging
    as a powerful commercial technology. Yet, like other powerful technologies, it
    presents both opportunities and challenges. It can be a tool or a weapon. It can
    generate revenue, and, in some instances, be transformational for organizations.
    But it can also fail, be attacked, and cause significant incidents. From where
    we sit, most of the ML community appears too focused on ML’s hype and upside.
    When we focus only on the upside of technology, we turn our backs on obvious realities
    that must be addressed to enable wider adoption. Perhaps this is why we’ve found
    it a little strange to write a report called *Responsible Machine Learning*. After
    all, we don’t often hear about “responsible” aviation or “responsible” nuclear
    power. Responsibility and risk mitigation are usually baked into our notions of
    these technologies, and this apparently hasn’t happened yet for ML. This could
    be because we know what happens when commercial jetliners or nuclear reactors
    fail or are attacked, but as a community, we’re not yet so sure about the consequences
    of lousy ML.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）坐落在商业应用、统计学和计算机科学的交汇处。在其大约60年的历史中，它经历了几波炒作和失望。这是一个庞大而技术性强的主题，也是一种强大的商业技术。然而，与其他强大的技术一样，它既带来机遇也带来挑战。它可以是工具，也可以是武器。它可以带来收入，并且在某些情况下，可以改变组织。但它也可能失败、遭到攻击，并引发重大事件。从我们的角度来看，大多数机器学习社区似乎过于关注ML的炒作和优势。当我们只关注技术的优势时，我们就背弃了必须解决的明显现实。也许这就是为什么我们觉得写一篇名为*负责任的机器学习*的报告有些奇怪。毕竟，我们不经常听到“负责任”的航空或“负责任”的核能。责任和风险缓解通常已经融入我们对这些技术的概念中，但显然对于机器学习尚未发生。这可能是因为我们知道商业喷气客机或核反应堆出现故障或受到攻击时会发生什么，但作为一个社区，我们对糟糕的ML的后果尚不确定。
- en: If this is the case, it betrays a lack of effort by the practitioner community.
    While the consequences of ML failures and attacks are just beginning to filter
    into the news, if you know where to look, you can already find over 1,000 [public
    reports of AI incidents](https://oreil.ly/zy35H). Furthermore, [government](https://oreil.ly/vdpja)
    and [public](https://oreil.ly/5TEBp) awareness of creepy and discriminatory ML
    is also increasing. Digging deeper than surface level ML hype reveals an entire
    world of AI incidents, pending regulation of AI, and ML risk mitigation tools.
    This report provides an introduction to this world. Since there are so many issues
    to cover, we don’t dwell on any subject for very long. We hope that interested
    readers will engage in and explore our references to understand the real-world
    implications and the real, human consequences. We also hope that the sheer volume
    and diversity of presented material leave an indelible impression on how readers
    think about ML.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是这样，这就暴露出从业者社区的不作为。尽管ML失败和攻击的后果刚刚开始进入新闻报道，但如果你知道在哪里找，你已经可以找到超过1,000个[AI事件的公开报告](https://oreil.ly/zy35H)。此外，[政府](https://oreil.ly/vdpja)和[公众](https://oreil.ly/5TEBp)对诡异和歧视性ML的认识也在增加。深挖ML炒作的表面之下，你将发现整个AI事件世界、AI监管的待定和ML风险缓解工具。本报告介绍了这个世界。由于有很多问题需要涵盖，我们不会对任何主题深入探讨。我们希望感兴趣的读者能参与并探索我们的参考资料，了解现实世界的影响和真正的人类后果。我们也希望所呈现的材料的数量和多样性能够对读者思考ML的方式留下不可磨灭的印象。
- en: 'We break our discussions of risk mitigation and ML adoption strategies into
    three major chapters: people, processes, and technologies. The people and processes
    chapters (Chapters [2](ch02.xhtml#people_humans_in_the_loop) and [3](ch03.xhtml#processes_taming_the_wild_west_of_machine_learning_workflows))
    describe actions people can take, and processes that organizations can employ
    to mitigate ML risks and increase ML adoption. These two chapters are meant to
    be approachable for non-technical audiences. While it includes no mathematical
    formulas, the technology chapter ([Chapter 4](ch04.xhtml#technology_engineering_machine_learning_for_human_trust_and_understanding))
    requires some technical background in ML, and it may be best suited for ML practitioners
    and their frontline managers. It’s also important to say that the ML risks we’re
    addressing are sophisticated, unsolved, and intersectional. Given the complexity
    of ML systems and how they interact with the world, there’s no silver bullet to
    derisk an ML system completely.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将风险缓解和机器学习采纳策略的讨论分成三大章节：人员、流程和技术。人员和流程章节（第[2](ch02.xhtml#people_humans_in_the_loop)章和第[3](ch03.xhtml#processes_taming_the_wild_west_of_machine_learning_workflows)章）描述了人们可以采取的行动，以及组织可以采用的流程来缓解机器学习风险并增加机器学习的采纳率。这两章旨在面向非技术人员。虽然它不包括数学公式，但技术章节（[第4章](ch04.xhtml#technology_engineering_machine_learning_for_human_trust_and_understanding)）需要一些机器学习的技术背景，可能更适合机器学习从业者及其一线管理者。同样重要的是，我们要说的是，我们正在解决的机器学习风险是复杂的、未解决的，并且具有交叉性。考虑到机器学习系统的复杂性及其与世界的互动方式，没有完全解决ML系统风险的万能方案。
- en: 'Moreover, the serial nature of a printed report means that we address risks
    and mitigation strategies one by one. In truth, both the risks and strategies
    are inherently connected: compliance, discrimination, instability, privacy, and
    security risks are related, and so are the actions you could take to address them.
    Since deployment by an organization is often where risks become real for ML, proper
    risk mitigation is a key last-mile problem for ML’s success. Although imperfect,
    we hope you’ll find the proposed strategies helpful and actionable to decrease
    risk and maximize the long-term value of ML in your organization.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，印刷报告的连续性意味着我们逐一解决风险和缓解策略。事实上，风险和策略本质上是相互关联的：遵从性、歧视、不稳定性、隐私和安全风险是相关的，采取的行动也是如此。由于组织的部署通常是机器学习风险变得真实的地方，适当的风险缓解是机器学习成功的关键问题。尽管不完美，我们希望您会发现提议的策略对减少风险并最大化机器学习在您的组织中的长期价值是有帮助且可行的。
