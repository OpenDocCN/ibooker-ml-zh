- en: 'Chapter 10\. Bringing It All Together: Building an AI-Powered Customer Analytics
    Dashboard'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章：将所有内容结合起来：构建AI驱动的客户分析仪表板
- en: You have come a long way in this book and (hopefully!) learned a lot of new
    things about how AI services can be deployed at various levels of the analytics
    stack. In this chapter, I will show you how these layers of analytics and AI services
    can be combined to provide a better experience for BI users and harness the potential
    of AI and BI by blending the two approaches. In fact, you should see that different
    AI services are not an either/or decision but that they can complement each other.
    For example, we can turn unstructured data (raw text) into structured data (sentiment
    scores table) so we can use it to do supervised learning (use sentiment scores
    to predict customer churn).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你在这本书中走了很长的路（希望如此！）并学到了很多关于如何在分析堆栈的各个层次部署AI服务的新知识。在本章中，我将向你展示如何将这些分析和AI服务层次结合起来，为BI用户提供更好的体验，并通过融合这两种方法来利用AI和BI的潜力。事实上，你应该看到不同的AI服务并不是二选一的决定，它们可以互补。例如，我们可以将非结构化数据（原始文本）转换为结构化数据（情感评分表），以便我们可以用它来进行监督学习（使用情感评分来预测客户流失）。
- en: By the end of this chapter, you will be able to mix and match multiple AI services
    to develop even more powerful use cases. To keep programming effort to a minimum,
    we will use Azure Machine Learning Designer as a no-code tool to create advanced
    ML workflows that allow for more customization than the AutoML service you learned
    about in the previous chapters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，你将能够混合和匹配多个AI服务，开发更强大的用例。为了将编程工作保持在最低限度，我们将使用Azure机器学习设计器作为一个无代码工具来创建高级ML工作流，这允许比你在前几章学到的AutoML服务更多的定制化。
- en: Problem Statement
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题陈述
- en: In this scenario, we are part of the data analytics team of a telecommunications
    provider. The head of sales and marketing of the consumer division has initiated
    a project to look further into the topic of customer churn. As per the business’
    definition, churn happens at the moment a customer cancels their contract, no
    matter the remaining duration of the contract (the business is offering monthly
    and 24-month contracts).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情景下，我们是一个电信服务提供商的数据分析团队的一部分。消费者部门的销售和营销负责人发起了一个项目，进一步研究客户流失的主题。根据企业的定义，客户在取消合同的那一刻即算是流失，无论合同的剩余期限如何（企业提供月租和24个月合同）。
- en: 'The business is currently facing the following challenges:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 企业目前面临以下挑战：
- en: Churn rates are measured, but marketing and sales can’t yet make sense of them.
    The churn metrics seem to go up and down sporadically, and the staff is struggling
    to get any meaningful insights from these metrics.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流失率被测量，但营销和销售部门尚不能理解它们。流失指标似乎断断续续地上升和下降，员工们在尝试从这些指标中获得任何有意义的见解时遇到了困难。
- en: As an effective measure to counter churn, the business has identified counteroffers
    to be a viable strategy. Offers are presented to customers who are quitting their
    contract as a means to win them back or prevent them from quitting at all. The
    offers turned out to be effective, but costly. Therefore, the business wants to
    know which customers are most lucrative to be targeted by such counterchurn offers
    and would ideally like to predict churn before it happens to ensure a good fit
    between the offer type and the customer segments.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为抵制流失的有效措施，企业已确定提供反流失策略是一种可行的策略。这些优惠被提供给正在取消合同的客户，以赢回他们或者防止他们完全取消。这些优惠被证明是有效的，但成本高昂。因此，企业希望知道哪些客户最有利于被针对此类反流失优惠，并且最好在发生流失之前预测流失，以确保优惠类型与客户细分的匹配度良好。
- en: The business is running regular surveys among customers that include a lot of
    open-text feedback. Looking at samples of the survey data, the survey team suggests
    that the text answers could provide important signals for churn modeling.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 企业定期对客户进行调查，其中包括大量的开放式文本反馈。通过查看调查数据的样本，调查团队建议文本答案可能为流失建模提供重要信号。
- en: The business expects a certain level of interactivity to comb through the data
    in order to get a feeling for what’s happening with regards to customer churn
    in various customer segments.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 企业希望通过浏览数据来达到一定的交互性，以了解在各种客户细分中关于客户流失的情况。
- en: The data analytics team is expected to identify viable ways to present the requested
    information to the business stakeholders—of course, as soon as possible and with
    heavy budget constraints.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析团队预计能够确定向业务利益相关者呈现请求信息的可行方式——当然，尽快并且在重度预算约束下。
- en: Solution Overview
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案概述
- en: Take a look at the use case architecture in [Figure 10-1](#ai_powered_customer_analytics_use_case).
    As you can immediately see, this will be the most complex use case we are building
    in this book. But don’t worry, we are essentially reusing concepts and techniques
    that you learned in the previous chapters.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[图 10-1](#ai_powered_customer_analytics_use_case)中的用例架构。正如您立即看到的那样，这将是我们在本书中构建的最复杂的用例。但别担心，我们基本上是在重用您在前几章学到的概念和技术。
- en: 'To understand what’s happening in this architecture, let’s start at the top
    with the user layer and find out what our output should actually look like. We
    want to have an interactive dashboard in Power BI that lets us analyze customer
    churn in multiple ways; we want to do the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解这个架构中发生了什么，让我们从用户层的顶部开始，并找出我们的输出应该实际是什么样子的。我们希望在Power BI中有一个交互式仪表板，让我们能够多方面分析客户流失；我们想做以下几件事：
- en: Understand where churn happened and provide a seamless experience for users
    to interact with historical data (descriptive analytics). We will use the Power
    BI Q&A visual for that purpose.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解流失发生的位置，并为用户提供与历史数据交互的无缝体验（描述性分析）。我们将使用Power BI Q&A视觉来实现这一目的。
- en: Understand which fluctuations in recent customer churn should be flagged as
    “too high.” We will use anomaly detection for that (diagnostic analytics).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解最近客户流失中哪些波动应标记为“过高”。我们将使用异常检测进行诊断分析。
- en: Predict customer churn for the future to understand what revenue is at risk
    in which segments (predictive analytics).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测未来客户流失，以了解哪些部分的收入面临风险（预测分析）。
- en: Analyze feedback from customer reviews to inform our churn report to understand
    what it is that customers are complaining about (unstructured data).
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析客户评价反馈，以了解我们的流失报告中客户抱怨的内容（非结构化数据）。
- en: '![AI-powered customer analytics use case architecture](Images/apbi_1001.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![AI驱动的客户分析用例架构](Images/apbi_1001.png)'
- en: Figure 10-1\. AI-powered customer analytics use case architecture
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-1\. AI驱动的客户分析用例架构
- en: 'Before we look at what’s happening in the analysis layer, let’s jump to the
    bottom and examine the data layer we have for this use case. Our BI system will
    mainly be fed by three data sources:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看分析层发生了什么之前，让我们跳到底部，检查我们为这个用例准备的数据层。我们的BI系统主要由三个数据源提供数据：
- en: The source *Churn_Metrics_2021.csv* contains aggregated historical information
    about customer churn.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源文件*Churn_Metrics_2021.csv*包含有关客户流失的汇总历史信息。
- en: The source *Churn_Predictions_June_2022.csv* contains the most recent customer
    data with respective churn predictions.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源文件*Churn_Predictions_June_2022.csv*包含最新的客户数据及其相应的流失预测。
- en: The source *Customer_Dimensions_June_2022.csv* contains demographic information
    about our customers that we can use for further explorations or drill-downs.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源文件*Customer_Dimensions_June_2022.csv*包含关于我们客户的人口统计信息，我们可以用于进一步的探索或钻取。
- en: This data would be typically stored in a data warehouse, but in our case we’re
    fetching them as CSV files from Azure Blob Storage to keep things simple. While
    the files *Churn_Metrics_2021.csv* and *Customer_Dimensions_June_2022.csv* are
    given, we need to create *Churn_Predictions_June_2022.csv* by using analytics.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据通常存储在数据仓库中，但在我们的情况下，我们从Azure Blob Storage中获取它们作为CSV文件，以保持简单。虽然*Churn_Metrics_2021.csv*和*Customer_Dimensions_June_2022.csv*这些文件已经给出，但我们需要通过分析来创建*Churn_Predictions_June_2022.csv*。
- en: Now, let’s head over to the analysis layer. For our purposes, we will use an
    ML model that will be trained on historical data (structured and unstructured)
    in Azure ML Designer. The historical customer fact tables we have been provided
    stretch over the past five months and already include a churn label calculated
    by our in-house analysts. Besides the churn label, the fact tables contain a flag
    indicating whether customers accepted a counterchurn in the past. The training
    data will also include sentiment information from user surveys provided as raw
    text in *Survey_Responses_Jan-May_2022.csv*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们转向分析层。为了我们的目的，我们将在Azure ML Designer中使用一个ML模型，该模型将在历史数据（结构化和非结构化数据）上进行训练。我们已提供的历史客户事实表涵盖了过去五个月，并已包括由我们内部分析师计算的流失标签。除了流失标签，事实表还包含一个标志，指示客户是否在过去接受了反流失。训练数据还将包括来自*Survey_Responses_Jan-May_2022.csv*中提供的用户调查原始文本的情感信息。
- en: To make sense of the open-ended text answers, we will run sentiment analysis
    on the customer feedback and see whether these sentiment labels will help us increase
    the performance of the predictive model. Instead of handling the workflow for
    this manually, we will use Azure ML Designer, which comes as part of our Azure
    subscription. The ML Designer is a no-code AI platform that allows us to build
    and deploy managed ML workflows in the Azure cloud with as little technical friction
    as possible.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解开放式文本答案的意义，我们将对客户反馈进行情感分析，并查看这些情感标签是否能帮助我们提高预测模型的性能。我们将不再手动处理此工作流程，而是使用作为Azure订阅一部分的Azure
    ML Designer。ML Designer是一个无代码AI平台，允许我们尽可能少地在Azure云中构建和部署托管的ML工作流。
- en: Preparing the Datasets
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据集
- en: 'Download the following files from the [book’s website](https://oreil.ly/XKoQk):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从[书籍网站](https://oreil.ly/XKoQk)下载以下文件：
- en: '*customers_factTable_Jan-May_2022.csv*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*customers_factTable_Jan-May_2022.csv*'
- en: Information about customer metrics and churn labels for January through May
    2022
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 关于2022年1月至5月间客户指标和流失标签的信息
- en: '*survey_responses_Jan-May_2022.csv*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*survey_responses_Jan-May_2022.csv*'
- en: Customer feedback from a survey of a sample of customers conducted between January
    and May 2022
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 来自2022年1月至5月期间的样本客户调查的客户反馈
- en: '*customers_factTable_June_2022.csv*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*customers_factTable_June_2022.csv*'
- en: Customer facts for the current month of June 2022
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年6月的当前客户事实数据
- en: '*survey_responses_June_2022.csv*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*survey_responses_June_2022.csv*'
- en: New survey data from June 2022
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 新的2022年6月调查数据
- en: Open [Microsoft Azure Machine Learning Studio](https://ml.azure.com), choose
    your preferred workspace, and you should see your dashboard ([Figure 10-2](#azure_machine_learning_studio_dashboard)).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 打开[Microsoft Azure Machine Learning Studio](https://ml.azure.com)，选择您喜欢的工作区，您应该看到您的仪表板（[图 10-2](#azure_machine_learning_studio_dashboard)）。
- en: '![Azure Machine Learning Studio dashboard](Images/apbi_1002.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![Azure Machine Learning Studio 仪表板](Images/apbi_1002.png)'
- en: Figure 10-2\. Azure Machine Learning Studio dashboard
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-2\. Azure Machine Learning Studio 仪表板
- en: First, we will upload all four CSV files as datasets (data assets) into Azure
    ML Studio, one by one, in order to be able to access them through the ML Designer
    later. Click the plus icon and choose “Data asset” or select “Data” from the menu
    on the left.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将逐个将所有四个CSV文件作为数据集（数据资产）上传到Azure ML Studio，以便稍后通过ML Designer访问它们。单击加号图标，选择“数据资产”或从左侧菜单中选择“数据”。
- en: For each of the CSV files, select Create → From local files. Provide the names
    for the dataset as in the filename—for example, `**customers_factTable_Jan-May_2022**`
    for the file *customers_factTable_Jan-May_2022.csv*. Follow along through the
    form, upload the CSV files, and check the data preview if everything looks fine.
    The delimiter in all files should be Comma, and the encoding is UTF-8\. When it
    comes to the schema, you have to make some adjustments.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个CSV文件，选择创建 → 从本地文件创建。按文件名提供数据集的名称，例如，对于文件*customers_factTable_Jan-May_2022.csv*，名称应为`**customers_factTable_Jan-May_2022**`。跟随表单，上传CSV文件，并检查数据预览是否一切正常。所有文件的分隔符应为逗号，编码为UTF-8。在模式方面，您必须进行一些调整。
- en: 'Please make sure that the schema is as follows for the customer fact tables
    (Note: the columns Churn and OfferAccepted don’t appear in the file from June,
    as this represents the most current month and the churn info isn’t available yet—that’s
    what we are going to predict in a bit.):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保客户事实表的模式如下（注意：6月份的文件中不包含Churn和OfferAccepted列，因为这代表最新月份，而流失信息尚不可用，这是我们稍后要预测的）：
- en: 'customerID: String'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'customerID: String'
- en: 'tenure: Integer'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'tenure: Integer'
- en: 'Contract: String'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合同：String
- en: 'Monthly Charges: Decimal (dot)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 月度费用：Decimal（小数点）
- en: 'Churn: String'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Churn: 字符串'
- en: 'Don’t include: OfferAccepted'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不包括：OfferAccepted
- en: 'Don’t include: Month'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不包括：Month
- en: 'For both survey files, make sure the columns match the following schema:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于两个调查文件，请确保列与以下架构匹配：
- en: 'id: String'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'id: 字符串'
- en: 'text: String'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'text: 字符串'
- en: 'By the end of this, you should see the following four datasets within ML Studio:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 到最后，您应该在 ML Studio 中看到以下四个数据集：
- en: customers_factTable_Jan-May_2022
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: customers_factTable_Jan-May_2022
- en: survey_responses_Jan-May_2022
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: survey_responses_Jan-May_2022
- en: customers_factTable_June_2022
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: customers_factTable_June_2022
- en: survey_responses_June_2022
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: survey_responses_June_2022
- en: Allocating a Compute Resource
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分配计算资源
- en: Now that we have the data in place, we need to make sure that resources are
    available where the actual computations can happen. To add a compute resource,
    select Compute from the menu on the left of ML Studio, as shown in [Figure 10-3](#adding_a_compute_resource_in_azure_ml_s).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好数据，需要确保资源可用以进行实际计算。要添加计算资源，请在 ML Studio 左侧的菜单中选择 Compute，如 [Figure 10-3](#adding_a_compute_resource_in_azure_ml_s)
    所示。
- en: '![Adding a compute resource in Azure ML Studio](Images/apbi_1003.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![在 Azure ML Studio 中添加计算资源](Images/apbi_1003.png)'
- en: Figure 10-3\. Adding a compute resource in Azure ML Studio
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-3\. 在 Azure ML Studio 中添加计算资源
- en: Here, you should still see the compute resource that you used throughout the
    previous chapters. If you see the resource, but it hasn’t been started yet, select
    the resource and click Start. If you don’t have any resource yet or you deleted
    it previously, click New and create a new compute resource with the default settings
    and the cheapest machine type (`STANDARD_DS1_V2`) that will be sufficient for
    this case study. Once you have at least one compute instance up and running, you
    can proceed to the ML Designer.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您应该仍然看到您在前几章中使用的计算资源。如果您看到资源，但尚未启动，请选择资源并点击“启动”。如果您还没有任何资源或之前删除了它，请点击“新建”，并创建一个带有默认设置和足够本案例研究的最便宜机器类型（`STANDARD_DS1_V2`）的新计算资源。一旦您至少有一个计算实例正在运行，您可以继续使用
    ML Designer。
- en: Building the ML Workflow
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建 ML 工作流程
- en: Choose Designer from the menu on the left ([Figure 10-4](#ml_designer_in_azure_ml_studio)).
    The ML Designer will be our drag-and-drop interface to build ML pipelines. We
    can train our own models, but we can also do some basic data preprocessing and
    run custom scripts.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从左侧菜单中选择 Designer（[Figure 10-4](#ml_designer_in_azure_ml_studio)）。ML Designer
    将是我们拖放界面，用于构建 ML 管道。我们可以训练自己的模型，也可以进行基本的数据预处理和运行自定义脚本。
- en: '![ML Designer in Azure ML Studio](Images/apbi_1004.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![Azure ML Studio 中的 ML Designer](Images/apbi_1004.png)'
- en: Figure 10-4\. ML Designer in Azure ML Studio
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-4\. Azure ML Studio 中的 ML Designer
- en: 'Create your first pipeline by clicking “New pipeline.” You should now see the
    empty canvas for the ML Designer ([Figure 10-5](#azure_ml_designer_interface)).
    The ML Designer has three main components: the *library* on the left, where you
    can toggle between data assets and components; a *canvas* on the right to build
    your pipeline; and a *toolbar* on the top to Save, Edit, and Submit the entire
    pipeline.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“新管道”创建您的第一个管道。现在您应该可以看到 ML Designer 的空白画布（图 10-5）([Figure 10-5](#azure_ml_designer_interface))。ML
    Designer 有三个主要组件：左侧的*库*，您可以在其中切换数据资产和组件；右侧的*画布*用于构建管道；顶部的*工具栏*用于保存、编辑和提交整个管道。
- en: '![Azure ML Designer interface](Images/apbi_1005.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![Azure ML Designer 界面](Images/apbi_1005.png)'
- en: Figure 10-5\. Azure ML Designer interface
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-5\. Azure ML Designer 界面
- en: Before we can start, assign the running compute instance to our session. If
    the settings window did not pop up automatically, you can access it by clicking
    the cog icon next to the pipeline name in the toolbar. Speaking of pipeline names,
    change the pipeline title to `**Customer-Churn-Predictor**` in the settings.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，将正在运行的计算实例分配给我们的会话。如果设置窗口没有自动弹出，请单击工具栏中管道名称旁边的齿轮图标访问它。说到管道名称，将管道标题更改为`**Customer-Churn-Predictor**`。
- en: We can now start to populate the empty canvas. The idea is that you build a
    custom workflow by using the prebuilt modules on the left and combining them on
    the canvas. Each module can have input and output ports and provides different
    settings.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始填充空白画布了。构建自定义工作流的想法是使用左侧预构建的模块，并将它们组合在画布上。每个模块都可以有输入和输出端口，并提供不同的设置。
- en: From the assets library select the dataset *customers_factTable_Jan-May_2022*
    and drag and drop it onto the canvas, as shown in [Figure 10-6](#adding_a_dataset_to_the_canvas).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 从资产库中选择数据集 *customers_factTable_Jan-May_2022*，并将其拖放到画布上，如 [Figure 10-6](#adding_a_dataset_to_the_canvas)
    所示。
- en: '![Adding a dataset to the canvas](Images/apbi_1006.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![在画布上添加一个数据集](Images/apbi_1006.png)'
- en: Figure 10-6\. Adding a dataset to the canvas
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-6\. 在画布上添加数据集
- en: The pipelines will be executed from top to bottom. So everything will start
    by loading this dataset. If you like, you can preview the data by right-clicking
    the module and selecting “Preview data.” Previewing outputs of individual modules
    on the canvas is an intuitive way for debugging, especially at the beginning,
    when you are just familiarizing yourself with the interface.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 管道将从顶部到底部执行。因此，一切将从加载此数据集开始。如果愿意，可以通过右键点击模块并选择“预览数据”来预览数据。在开始时，特别是在熟悉界面时，通过在画布上预览单个模块的输出是一种直观的调试方式。
- en: Next, let’s do something with the data. Our goal is to build a simple ML pipeline
    that will predict the Churn column given our input features, similar to the AutoML
    use case from [Chapter 7](ch07.xhtml#ai_powered_predictive_analytics).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们对数据进行一些操作。我们的目标是构建一个简单的机器学习管道，根据输入特征预测流失列，类似于[第 7 章](ch07.xhtml#ai_powered_predictive_analytics)中的AutoML用例。
- en: Switch from Data assets to components in the library by clicking the respective
    icon. Search for `**select columns in dataset**`. The purpose of this module is
    to get rid of the columns we don’t need for the predictions, such as the Customer
    ID. Drag the module onto the canvas below the Dataset module. Close the settings
    for now, if they pop up automatically. Connect the output port from the Dataset
    module to the Select Columns in Dataset module, as shown in [Figure 10-7](#adding_the_select_columns_in_dataset_mo).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通过点击相应的图标，从数据资产切换到库中的组件。搜索`**select columns in dataset**`。此模块的目的是去除我们预测不需要的列，例如Customer
    ID。将模块拖动到数据集模块下方的画布上。如果它们自动弹出，请暂时关闭设置。将数据集模块的输出端口连接到选择数据集模块，如[图 10-7](#adding_the_select_columns_in_dataset_mo)所示。
- en: '![Adding the Select Columns in Dataset module](Images/apbi_1007.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![在数据集模块中添加选择列](Images/apbi_1007.png)'
- en: Figure 10-7\. Adding the Select Columns in Dataset module
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-7\. 添加选择数据集模块
- en: Drawing a connection between two modules allows for metadata to flow downstream
    in our pipeline. That means our Select Columns in Dataset module will now know
    the available column names. Double-click the module on the canvas to open the
    settings once again. Click “Edit columns” and choose to select columns “By name,”
    as shown in [Figure 10-8](#filtering_columns).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个模块之间绘制连接允许元数据在我们的流水线中向下流动。这意味着我们的选择数据集模块现在将知道可用的列名。双击画布上的模块再次打开设置。点击“编辑列”并选择按名称选择列，如[图 10-8](#filtering_columns)所示。
- en: '![Filtering columns](Images/apbi_1008.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![过滤列](Images/apbi_1008.png)'
- en: Figure 10-8\. Filtering columns
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-8\. 过滤列
- en: Select all but the CustomerID column. Confirm by clicking Save. Close the module’s
    settings pane to make more space for the canvas.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 选择除了CustomerID列之外的所有列。点击保存进行确认。关闭模块设置窗格以为画布腾出更多空间。
- en: 'Next, we want to split our data into a training and a test set. Search for
    `**Split Data**` in the modules search bar and drag the module onto the canvas.
    In the module settings, define the following split parameters:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们要将数据分成训练集和测试集。在模块搜索栏中搜索`**Split Data**`，并将模块拖动到画布上。在模块设置中，定义以下拆分参数：
- en: 'Splitting mode: Split Rows'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拆分模式：拆分行
- en: 'Fractions of rows in the first output: 0.75'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个输出的行分数：0.75
- en: 'Randomized split: True'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机拆分：True
- en: 'Random seed: 1234 (for reproducibility)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机种子：1234（用于可重现性）
- en: 'Stratified split: True'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分层拆分：True
- en: 'Stratification key columns: Churn'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分层键列：流失
- en: With these settings, we are doing a stratified train-test split, with 75% of
    the data for training and 25% for testing. *Stratified* means that the class distribution
    for the Churn label will be the same for both the training and test sets.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些设置，我们进行了分层的训练-测试拆分，其中数据的75%用于训练，25%用于测试。*分层*意味着流失标签的类别分布在训练集和测试集中相同。
- en: Close the settings and connect the output port of the Select Columns in Dataset
    module to the input port of the Split Data module. As you can see in [Figure 10-9](#adding_a_split_data_component),
    the Split Data module has two outputs now, one for the training (left) and one
    for the test dataset (right).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭设置，并连接选择数据集模块的输出端口到分割数据模块的输入端口。正如你在[图 10-9](#adding_a_split_data_component)中所看到的，现在分割数据模块有两个输出，一个用于训练（左）和一个用于测试数据集（右）。
- en: '![Adding a Split Data component](Images/apbi_1009.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![添加一个分割数据组件](Images/apbi_1009.png)'
- en: Figure 10-9\. Adding a Split Data component
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-9\. 添加一个分割数据组件
- en: 'We can now add the Train Model component. Search for it in the module pane
    and drag it onto the canvas. You will realize that this module has two inputs:
    the left one expects the training algorithm, and the right one expects the training
    dataset. Connect the left output node of the Split Data module to the right input
    port of the Train Model module. We still need to tell the Train Model component
    which column we actually want to predict. So double-click the component to open
    the settings and provide Churn as the Label column.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以添加**Train Model**组件。在模块窗格中搜索该组件并将其拖放到画布上。您会发现该模块有两个输入：左侧期望训练算法，右侧期望训练数据集。将**Split
    Data**模块的左输出节点连接到**Train Model**模块的右输入端口。我们还需要告诉**Train Model**组件我们实际想要预测的列。因此，双击该组件以打开设置，并将Churn提供为标签列。
- en: Now it’s up to us to provide the actual training algorithm. In contrast to AutoML,
    we have to choose the training algorithm ourselves. Now, this isn’t a Machine
    Learning Fundamentals book, but in most supervised learning scenarios, you will
    achieve pretty good results by choosing an ensemble method such as decision forest
    or boosted trees as a first baseline. These models try to combine several weak
    learners such as decision trees to a strong learning algorithm that tries to minimize
    the prediction error on your training dataset. These models work for both classification
    and regression problems, so they are good all-round algorithms, although they
    are rather complex. The good thing about the ML Designer is that you can easily
    try out different, even simpler algorithms such as linear or logistic regression,
    and see how they perform on your dataset.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在该由我们提供实际的训练算法了。与AutoML相比，我们必须自己选择训练算法。现在，这不是一本机器学习基础知识的书，但在大多数监督学习场景中，选择像决策森林或提升树等集成方法作为第一个基线，您将会获得相当不错的结果。这些模型尝试将几个弱学习器（例如决策树）结合成一个强学习算法，试图在训练数据集上最小化预测误差。这些模型适用于分类和回归问题，因此它们是非常全面的算法，尽管它们相对复杂。ML
    Designer 的好处在于您可以轻松尝试不同的、甚至更简单的算法，如线性或逻辑回归，并查看它们在数据集上的表现。
- en: For our exercise, search for `**Two-Class Boosted Decision Tree**` from the
    module pane and drag it over to the canvas. We can leave all its settings to the
    defaults for now. Connect the Decision Tree module to the Train Model component,
    and your pipeline should look like [Figure 10-10](#adding_the_decision_tree_and_train_mode).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的练习，从模块窗格中搜索`**Two-Class Boosted Decision Tree**`并将其拖放到画布上。现在，我们可以将所有设置保留为默认值。将决策树模块连接到**Train
    Model**组件，您的流水线应该看起来像 [Figure 10-10](#adding_the_decision_tree_and_train_mode)。
- en: '![Adding the Decision Tree and Train Model components](Images/apbi_1010.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![添加决策树和Train Model组件](Images/apbi_1010.png)'
- en: Figure 10-10\. Adding the Decision Tree and Train Model components
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-10\. 添加决策树和Train Model组件
- en: We’re almost there! Only one thing is missing, and that is adding a component
    that scores actual predictions based on the trained model and calculates evaluation
    metrics for it.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们快要完成了！只剩下一件事，那就是添加一个组件，根据训练好的模型对实际预测进行评分并计算评估指标。
- en: Search for the `**Score Model**` component and drag it over to the canvas. Connect
    the output port from the Train Model component to the left input port of the Score
    Model component.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索**Score Model**组件并将其拖放到画布上。将**Train Model**组件的输出端口连接到**Score Model**组件的左输入端口。
- en: Then connect the right output port from the Split Data component to the right
    input port of the Score Model component. This will allow us to calculate predictions
    for the test dataset by using our model trained on the training dataset. Finally,
    find the Evaluate Model module, pull it over to the canvas, and connect the Score
    Model output port to the left input port of the Evaluate Model component. Your
    final pipeline should now look similar to [Figure 10-11](#first_end_to_end_workflow_in_ml_designe).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将**Split Data**组件的右输出端口连接到**Score Model**组件的右输入端口。这将允许我们使用在训练数据集上训练的模型来计算测试数据集的预测值。最后，找到**Evaluate
    Model**模块，将其拖放到画布上，并将**Score Model**的输出端口连接到**Evaluate Model**组件的左输入端口。您的最终流水线现在应该看起来类似于
    [Figure 10-11](#first_end_to_end_workflow_in_ml_designe)。
- en: '![First end-to-end workflow in ML Designer](Images/apbi_1011.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![ML Designer 中的第一个端到端工作流](Images/apbi_1011.png)'
- en: Figure 10-11\. First end-to-end workflow in ML Designer
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-11\. ML Designer 中的第一个端到端工作流
- en: Congratulations! You have just built your first ML pipeline from scratch. Click
    the Submit button to run the pipeline. All runs will be gathered in *experiments*,
    as we are used to from the AutoML scenario. I suggest creating a new experiment
    for this pipeline so you keep your work organized. Create a new experiment and
    provide a telling name such as `**customer-churn-prediction-training**`. Click
    Submit and lean back while Azure ML Studio does its magic behind the scenes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您刚刚从头开始构建了您的第一个ML流水线。单击提交按钮运行流水线。所有运行将被收集到*实验*中，这是我们从AutoML场景中习惯的。我建议为这个流水线创建一个新实验，以保持您的工作组织良好。创建一个新实验并提供一个有意义的名称，如`**customer-churn-prediction-training**`。点击提交并在Azure
    ML Studio在幕后做它的魔法时稍事休息。
- en: To follow along with the training click “Job detail” under “Submitted jobs”
    on the left part of the screen. Here, the ML Designer will indicate which step
    is currently running and which step is completed. Note that you have just left
    the Designer and switched to the Jobs section, as you can see from the menu. While
    the Designer lets you create the pipelines, Jobs will allow you to monitor the
    actual pipeline execution and trigger the final deployment. The whole job should
    take approximately 10 to 15 minutes.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟踪训练过程，请在屏幕左侧的“已提交作业”下单击“作业详情”。在这里，ML Designer将指示当前正在运行的步骤以及已完成的步骤。请注意，您刚刚离开了Designer并切换到了作业部分，正如您从菜单中看到的那样。虽然Designer允许您创建流水线，但作业将允许您监视实际的流水线执行并触发最终部署。整个作业应该需要大约10到15分钟。
- en: The reason this is taking so long is that Azure is spinning up separate processes
    for each module, which creates some overhead. The advantage is that this interface
    will also work well for really large datasets because each module runs independently
    from the other. That is why running the ML Designer for some rather small datasets
    as in our case will actually take longer compared to running them on your local
    notebook. But the larger the dataset gets, the more performance advantages you
    will see.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 之所以这么长时间是因为Azure为每个模块单独启动了进程，这会产生一些开销。好处是，这种界面也适用于非常大的数据集，因为每个模块都独立于其他模块运行。这就是为什么在我们的案例中，与在您的本地笔记本上运行相比，运行ML
    Designer对一些相当小的数据集实际上会花费更长的时间。但数据集越大，您将看到的性能优势就越多。
- en: When the process has finished, you should see the Completed badge on the last
    Evaluate Model module. In this case, double-click the module to view the Evaluation
    results. This should give you the outputs shown in [Figure 10-12](#evaluation_metrics_for_first_workflow).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 当过程完成时，您应该在最后一个评估模块上看到完成徽章。在这种情况下，双击模块以查看评估结果。这应该会给您显示在[图10-12](#evaluation_metrics_for_first_workflow)中展示的输出。
- en: '![Evaluation metrics for first workflow](Images/apbi_1012.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![第一个工作流的评估指标](Images/apbi_1012.png)'
- en: Figure 10-12\. Evaluation metrics for first workflow
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-12\. 第一个工作流的评估指标
- en: Click the Enlarge icon to make more space, and the whole interface should look
    familiar, like what you’ve seen in previous chapters. With our initial run, we
    have reached an Accuracy of 86.6% and an F1-score of 80.9%. That’s not bad for
    a first try, but let’s see if we can improve this metric even more by blending
    our training dataset with more data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 单击放大图标以腾出更多空间，整个界面应该看起来很熟悉，就像您在前几章中看到的那样。通过我们的初步运行，我们已经达到了86.6%的准确率和80.9%的F1分数。对于第一次尝试来说，这还不错，但让我们看看是否可以通过将训练数据集与更多数据混合来进一步提高这个度量指标。
- en: So far, what we have done is just another unsupervised ML workflow that we could
    have easily done with the AutoML service from [Chapter 7](ch07.xhtml#ai_powered_predictive_analytics).
    In fact, if this was it, I would recommend using the AutoML service instead of
    Azure ML Studio. However, we are not done yet, as we still want to insert insights
    from unstructured data (sentiment scores) and incorporate them into our final
    model. This workflow would not be possible with the AutoML service alone, so we
    choose ML Studio for this task.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所做的只是另一个无监督的ML工作流，我们本可以很容易地使用[第7章](ch07.xhtml#ai_powered_predictive_analytics)中的AutoML服务来完成。事实上，如果只是这样的话，我会建议使用AutoML服务而不是Azure
    ML Studio。然而，我们还没有完成，因为我们仍然希望插入来自非结构化数据（情感评分）的见解，并将它们合并到我们的最终模型中。这个工作流程仅依靠AutoML服务是不可能的，因此我们选择ML
    Studio来完成这项任务。
- en: Adding Sentiment Data to the Workflow
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将情感数据添加到工作流程中
- en: Close the evaluation metrics and go back to the Designer. This time, we want
    to add the analysis of the customer feedback and see if that helps to improve
    our customer churn predictions. The way we approach this is that we build a second
    pipeline next to the one we already have and feed the results into the right input
    port of the Evaluate Model module. This will give us a direct comparison of both
    modeling approaches.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭评估指标并返回到设计界面。这次，我们想要增加对客户反馈的分析，看看这是否有助于改进我们的客户流失预测。我们的方法是在已有的管道旁边建立第二个管道，并将结果馈送到评估模型模块的正确输入端口。这将直接比较两种建模方法。
- en: Let’s tackle this step by step. First, drag and drop the Dataset module for
    *customers_factTable_Jan-May_2022* from the module pane on the left to the canvas.
    In addition, locate the Dataset module for *survey_responses_Jan-May_2022* and
    drag it next to the other two Dataset modules. Your canvas should now look like
    [Figure 10-13](#adding_more_data_sources_to_ml_designer).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步步来解决这个问题。首先，从左侧模块窗格将*customers_factTable_Jan-May_2022*数据集模块拖放到画布上。此外，找到*survey_responses_Jan-May_2022*数据集模块，并将其拖放到另外两个数据集模块旁边。你的画布现在应该看起来像[图 10-13](#adding_more_data_sources_to_ml_designer)。
- en: '![Adding more data sources to ML Designer](Images/apbi_1013.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![将更多数据源添加到ML Designer](Images/apbi_1013.png)'
- en: Figure 10-13\. Adding more data sources to ML Designer
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-13\. 将更多数据源添加到ML Designer
- en: To get more familiar with the survey data, right-click the module and select
    “Preview data.” The dataset contains only two columns, the customer ID and the
    text response, both values that came from the original customer survey results.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更熟悉调查数据，请右键单击该模块并选择“预览数据”。数据集仅包含两列，即客户ID和文本响应，这两个值来自原始客户调查结果。
- en: So far, our ML model can’t handle the raw text inputs very well as predictive
    features. To make them more accessible, we will read the open-ended text answers
    from the survey dataset, send them to Azure Cognitive Services, and get the sentiment
    value for each text. The classification “negative” or “positive” will then become
    an additional feature for our classification model. For this purpose, we will
    use the Azure Cognitive Services for Sentiment Analysis, which we deployed in
    [Chapter 9](ch09.xhtml#leveraging_unstructured_data_with_ai).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的机器学习模型无法很好地处理原始文本输入作为预测特征。为了使它们更易访问，我们将从调查数据集中读取开放式文本答案，发送到Azure认知服务，并获取每个文本的情感值。分类“负面”或“正面”将成为我们分类模型的额外特征。为此，我们将使用在[第 9 章](ch09.xhtml#leveraging_unstructured_data_with_ai)中部署的Azure认知服务情感分析。
- en: 'Let’s bring this AI service component to the canvas! Believe it or not, Azure
    Cognitive Services has no prebuilt module that you can just drag onto the canvas
    in the ML Designer (at least not at the time of this writing). But what we can
    do is simply add a module that runs Python or R code for us. And that is just
    the approach we are going to take: we will take the responses from the survey,
    send them to a remote AI service API using Python or R, and feed the results back
    into the ML Designer pipeline.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个AI服务组件带到画布上吧！信不信由你，Azure认知服务在ML Designer中没有预构建的模块可以直接拖放到画布上（至少在撰写本文时是这样）。但我们可以采取的方法是简单地添加一个可以运行Python或R代码的模块。这正是我们要采取的方法：我们将从调查中获取的响应，通过Python或R发送到远程AI服务API，并将结果馈送回ML
    Designer管道中。
- en: To start, search for `**Execute Python Script**` or `**Execute R Script**`,
    depending on your preference. Drag it over to the canvas. Connect the output port
    of the *survey_responses* dataset to the first input port of the script module.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请搜索`**执行Python脚本**`或`**执行R脚本**`，取决于您的偏好。将其拖动到画布上。连接*survey_responses*数据集的输出端口到脚本模块的第一个输入端口。
- en: The way the script module works is that it expects up to two dataframes (tables)
    that can be then modified within a function called `azureml_main`. The result
    will again be returned as one or two dataframes.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本模块的工作方式是，它期望最多两个数据帧（表格），然后可以在名为`azureml_main`的函数中进行修改。结果将再次作为一个或两个数据帧返回。
- en: The underlying Python or R runtimes come with a limited number of packages.
    To find out more about them, check the Microsoft documents [“Run Python Code in
    Azure Machine Learning Designer”](https://oreil.ly/ksZi8) or [“Execute R Script
    Component”](https://oreil.ly/YdexI), respectively. All we need to do now is to
    replace the prebuilt demo code with our custom code for the task we want to do.
    I’ll walk you through the example using Python, but the same steps also apply
    to the R script.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 底层的 Python 或 R 运行时附带了有限数量的包。要了解更多信息，请查阅微软文档 [“在 Azure 机器学习设计师中运行 Python 代码”](https://oreil.ly/ksZi8)
    或 [“执行 R 脚本组件”](https://oreil.ly/YdexI)。现在我们只需将预构建的演示代码替换为我们想要执行的任务的自定义代码。我将使用
    Python 来示例说明，但是相同的步骤也适用于 R 脚本。
- en: Open *ml-designer.py* (*ml-designer.R*) from the [book’s website](https://oreil.ly/XKoQk)
    in a text editor. Replace the key and endpoint with your custom parameters, as
    shown in [Chapter 9](ch09.xhtml#leveraging_unstructured_data_with_ai). Now select
    all of the script and copy it. Replace all of the sample code of the Execute Python
    Script module in the ML Designer with the contents of your clipboard. The script
    module should now contain only the code from the *ml-designer.py* file and nothing
    else ([Figure 10-14](#python_scripting_module_in_azure_ml_des)).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本编辑器中打开来自[书籍网站](https://oreil.ly/XKoQk)的 *ml-designer.py*（*ml-designer.R*）。用您的自定义参数替换密钥和端点，如[第
    9 章](ch09.xhtml#leveraging_unstructured_data_with_ai)所示。现在选择所有脚本并复制它。将 Execute
    Python Script 模块中的所有示例代码替换为剪贴板内容。脚本模块现在应仅包含来自 *ml-designer.py* 文件的代码，而不包括其他内容（见[图
    10-14](#python_scripting_module_in_azure_ml_des)）。
- en: '![Python scripting module in Azure ML Designer](Images/apbi_1014.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![Azure ML 设计师中的 Python 脚本模块](Images/apbi_1014.png)'
- en: Figure 10-14\. Python scripting module in Azure ML Designer
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-14\. Azure ML 设计师中的 Python 脚本模块
- en: The code will basically read the dataframe as input and shape it to a format
    that the API service can handle. It will return the original dataframe with the
    sentiment predictions attached. Now, click Submit to run the new graph. Go to
    Jobs and verify that everything is running as expected.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码基本上会将 dataframe 作为输入读取并将其整理成 API 服务可以处理的格式。它将返回附有情感预测的原始 dataframe。现在，单击提交以运行新的图形。转到作业并验证一切是否如预期运行。
- en: Note that all steps we ran previously on the left side of the graph will not
    be re-executed since we didn’t change anything here. Instead, this run will only
    read in the new dataset and feed it into the script module. After some minutes,
    you should see that the script was executed successfully. If an error comes up,
    click the script module and take a look at the log files. The error message there
    will help you to debug, for example, if your resource key is not valid or your
    free quota has been exceeded.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们之前在图的左侧运行的所有步骤不会重新执行，因为我们在这里没有做任何更改。相反，此运行将仅读取新数据集并将其馈送到脚本模块中。几分钟后，您应该会看到脚本成功执行。如果出现错误，请单击脚本模块并查看日志文件。那里的错误消息将帮助您调试，例如，如果您的资源密钥无效或您的免费配额已超过。
- en: When the run has been completed, right-click the script module in the submitted
    training job and choose Preview data → Result dataset. As shown in [Figure 10-15](#sentiment_analysis_results_in_azure_ml),
    you should see that each customer feedback entry has now gotten a sentiment label.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行完成后，右键点击已提交的训练作业中的脚本模块，选择预览数据 → 结果数据集。如图所示[图 10-15](#sentiment_analysis_results_in_azure_ml)，您应该可以看到现在每个客户反馈条目已经获得了情感标签。
- en: '![Sentiment analysis results in Azure ML Designer](Images/apbi_1015.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![Azure ML 设计师中的情感分析结果](Images/apbi_1015.png)'
- en: Figure 10-15\. Sentiment analysis results in Azure ML Designer
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-15\. Azure ML 设计师中的情感分析结果
- en: Our goal is to add this information to our main dataset that is used for training
    the churn model. We need to join this table to the main table without losing any
    records in the main table; remember that this survey wasn’t done for all customers,
    but only for a sample. This joining of data is called a *left outer join*; the
    left table is our main dataset, and the right table is the dataset from where
    we want to join additional information. Go back to the Designer and find the corresponding
    component by searching for `**Join Data**` in the asset library.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是将此信息添加到用于训练客户流失模型的主数据集中。我们需要将此表连接到主表中，而不会丢失主表中的任何记录；请记住，这次调查并不是针对所有客户进行的，而是针对样本进行的。这种数据连接称为*左外连接*；左表是我们的主数据集，右表是我们希望连接其他信息的数据集。返回到设计师并在资产库中搜索
    `**Join Data**`，找到相应的组件。
- en: Drag the Join Data module to the canvas. Connect the first output port of the
    previous scripting module to the right input port of the Join Data module. Then
    connect the output port of *customers_factTable_Jan-May_2022* (the one we didn’t
    use yet) to the left input port of the Join Data module. Double-click the Join
    Data module on the canvas to bring up its settings. We have to define the key
    columns on which both datasets will be merged. You can edit the key columns by
    clicking “Edit column” for both the left and the right dataset. For the left dataset,
    choose the column customerID, and for the right dataset the column “id.” Set the
    join type to Left Outer Join and set “Keep right key columns in joined table”
    to False. Your settings should ultimately look like those in [Figure 10-16](#joining_data_from_different_sources).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 将连接数据模块拖动到画布上。将前一个脚本模块的第一个输出端口连接到连接数据模块的右输入端口。然后将 *customers_factTable_Jan-May_2022*
    的输出端口（我们尚未使用的那个）连接到连接数据模块的左输入端口。在画布上双击连接数据模块以打开其设置。我们必须定义将两个数据集合并的关键列。您可以通过点击左右数据集的“编辑列”来编辑关键列。对于左侧数据集，选择列
    customerID，对于右侧数据集，选择列 “id”。将连接类型设置为左外连接，并将 “在连接表中保留右侧键列” 设置为 False。您的设置最终应与[图 10-16](#joining_data_from_different_sources)中的设置相似。
- en: '![Joining data from different sources](Images/apbi_1016.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![从不同来源连接数据](Images/apbi_1016.png)'
- en: Figure 10-16\. Joining data from different sources
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-16\. 从不同来源连接数据
- en: Run the pipeline by clicking Submit to verify that the join works as expected.
    Your merged dataset should have seven columns and 3,814 rows, which you can verify
    by right-clicking the Join Data module and choosing Preview data → Results dataset
    after the run has been completed.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 点击提交以运行流水线，验证连接是否按预期工作。您合并后的数据集应该有七列和 3,814 行，您可以右键单击连接数据模块并选择“预览数据”→“运行完成后的结果数据集”来验证。
- en: 'We now pretty much have to re-create the rest of the pipeline as we did previously.
    I won’t go through these steps in detail, as these are repetitive. In brief, add
    the following modules and apply these settings:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在基本上必须像之前一样重新创建其余的流水线。我不会详细介绍这些步骤，因为这些都是重复的。简单来说，添加以下模块并应用以下设置：
- en: Select Columns in Dataset
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 选择数据集中的列
- en: 'Select columns by rules: include all listed columns except “customerID,” include
    column name “sentiment,” and exclude column name “text.”'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 按规则选择列：包括所有列，除了 “customerID”，包括列名 “sentiment”，并排除列名 “text”。
- en: Split Data
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 分割数据
- en: Same as before, 0.75 stratified sample on the column Churn.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在列 Churn 上进行与之前相同的 0.75 分层样本。
- en: Train Model
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型
- en: The Label column is Churn.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 标签列是 Churn。
- en: Two-Class Boosted Decision Tree
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 二类增强决策树
- en: Leave the default settings.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 保持默认设置。
- en: Score Model
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 评分模型
- en: Connect the last output port from the Score Model component to the right input
    port of the Evaluate Model component we created before.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Score Model 组件的最后一个输出端口连接到我们之前创建的 Evaluate Model 组件的右输入端口。
- en: The final pipeline is shown in [Figure 10-17](#second_end_to_end_workflow).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的流水线显示在[图 10-17](#second_end_to_end_workflow)中。
- en: '![Second end-to-end workflow](Images/apbi_1017.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![第二个端到端工作流](Images/apbi_1017.png)'
- en: Figure 10-17\. Second end-to-end workflow
  id: totrans-150
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-17\. 第二个端到端工作流
- en: Click Submit to run the whole graph. If you think that it’s time for another
    coffee, you’re right! The whole process might take a couple of minutes. Check
    back when the process has been completed.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 点击提交以运行整个图形。如果您认为现在是喝咖啡的时候，那您是对的！整个过程可能需要几分钟。当流程完成后，请回来查看结果。
- en: When the run has completed, let’s check our evaluation module to see if the
    model performance could be improved. Go to Jobs and select your completed training
    job. Right-click the Evaluate Model module and choose Preview Data → Evaluation
    Results. [Figure 10-18](#evaluation_metrics_of_second_workflow) shows the output.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行完成后，让我们检查评估模块，看看是否可以改进模型性能。转到作业并选择您完成的训练作业。右键单击评估模块，选择“预览数据”→“评估结果”。[图 10-18](#evaluation_metrics_of_second_workflow)显示了输出。
- en: '![Evaluation metrics of second workflow](Images/apbi_1018.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![第二工作流的评估指标](Images/apbi_1018.png)'
- en: Figure 10-18\. Evaluation metrics of second workflow
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-18\. 第二工作流的评估指标
- en: From the evaluation metrics, we can see that the accuracy has improved by another
    percentage point, to 87.7%, and the F1 score has increased to 82.6%. While not
    groundbreaking, this is still a solid performance improvement considering that
    the sentiment label was provided for only a fraction of the data. This means that
    the sentiment information itself has very high predictive power for our use case.
    So it’s good to keep this information in our dataset and use it whenever possible.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 从评估指标中，我们可以看到准确率提高了另一个百分点，达到了 87.7%，而 F1 分数增加到了 82.6%。虽然不是突破性的，但考虑到情感标签仅为数据的一小部分提供了这一点，这仍然是一个可靠的性能提升。这意味着情感信息本身对于我们的用例具有非常高的预测能力。因此，最好保留这些信息在我们的数据集中，并在可能的情况下使用它。
- en: If we wanted to increase the accuracy even more, we could try training on more
    data (rows), use a different algorithm, or try more features (columns) to get
    better results. There’s no general rule for what accuracy value is sufficient,
    as it depends on your use case. But in general, having an existing baseline (as
    in [Chapter 7](ch07.xhtml#ai_powered_predictive_analytics)) gives you a good benchmark,
    as your ML model should be able to significantly outperform that baseline. Otherwise,
    it wouldn’t be worth all the extra effort.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想进一步提高准确率，我们可以尝试在更多数据（行）上进行训练，使用不同的算法，或尝试更多特征（列）以获得更好的结果。对于什么准确率值是足够的，没有通用的规则，因为这取决于您的用例。但一般来说，拥有现有基线（如[第 7
    章](ch07.xhtml#ai_powered_predictive_analytics)）可以给您一个良好的基准，因为您的 ML 模型应该能够显著超越该基线。否则，所有额外的努力都不值得。
- en: Now, our model training is complete. Congratulations! You have just combined
    an out-of-the-box AI service with an advanced ML algorithm to craft a powerful
    custom AI model yourself! It’s now time to put the model to work and make it ready
    for inference.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的模型训练完成了。恭喜！您刚刚将一个即开即用的 AI 服务与先进的 ML 算法结合起来，自己打造了一个强大的定制 AI 模型！现在是时候让这个模型投入工作，并准备好进行推断了。
- en: Before we proceed, let’s tidy up our graph by selecting all parts on the left
    and deleting them. In the Designer, open your workflow and click Clone from the
    top menu bar to create a copy of the graph.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们通过选择左侧的所有部分并删除它们来整理我们的图形。在设计师中，打开你的工作流，并从顶部菜单栏点击克隆以创建图形的副本。
- en: To select multiple modules, choose the selection tool from the toolbar and select
    all components on the left side of the graph, as shown in [Figure 10-19](#selecting_multiple_components_on_the_ca).
    Right-click on the selection and choose Delete.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 要选择多个模块，请从工具栏中选择选择工具，并选择图左侧所有组件，如[图 10-19](#selecting_multiple_components_on_the_ca)所示。右键单击选择内容，然后选择删除。
- en: '![Selecting multiple components on the canvas](Images/apbi_1019.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![选择画布上的多个组件](Images/apbi_1019.png)'
- en: Figure 10-19\. Selecting multiple components on the canvas
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-19\. 选择画布上的多个组件
- en: Finally, reconnect the Score Model module to the first input port of the Evaluate
    Model module by selecting the existing connection between both, deleting it, and
    redrawing to the first input port. Submit the training pipeline for a last time;
    this will be quick since it will recalculate only the results for the last module.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过选择连接 Score Model 模块与 Evaluate Model 模块第一个输入端口之间的现有连接，删除它，并重新连接到第一个输入端口，重新提交训练流水线最后一次；这将很快，因为它仅重新计算最后一个模块的结果。
- en: Deploying the Workflow for Inference
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署推断工作流
- en: We can deploy this graph now as an inference pipeline. All we need to do is
    go to Jobs, open the latest experiment, and select “Create inference pipeline”
    from the top menu and then choose “Batch inference pipeline” ([Figure 10-20](#creating_a_batch_inference_pipeline)).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将这个图形部署为一个推断流水线。我们只需要进入作业，打开最新的实验，并从顶部菜单中选择“创建推断流水线”，然后选择“批处理推断流水线” ([图 10-20](#creating_a_batch_inference_pipeline))。
- en: '![Creating a batch inference pipeline](Images/apbi_1020.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![创建批处理推断流水线](Images/apbi_1020.png)'
- en: Figure 10-20\. Creating a batch inference pipeline
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-20\. 创建批处理推断流水线
- en: The main difference between online and batch inference pipelines in this case
    is that the batch pipeline takes a blob dataset as input, whereas the online pipeline
    takes data submitted through an online API.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，在线推断管道和批处理推断管道的主要区别在于批处理管道将 Blob 数据集作为输入，而在线管道则通过在线 API 提交数据。
- en: In any case, the training pipeline will be converted to an inference pipeline,
    which I renamed to “Customer-Churn-Predictor Batch Inference,” as shown in [Figure 10-21](#batch_inference_pipeline_left_parenthe).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，训练管道都将被转换为推断管道，我将其重命名为“客户流失预测器批量推断”，如[图 10-21](#batch_inference_pipeline_left_parenthe)所示。
- en: '![Batch inference pipeline (raw)](Images/apbi_1021.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![批量推断管道（原始）](Images/apbi_1021.png)'
- en: Figure 10-21\. Batch inference pipeline (raw)
  id: totrans-170
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-21\. 批量推断管道（原始）
- en: The main difference between the training and the inference pipeline is that
    the inference pipeline does not contain any training components. Note that the
    Boosted Decision Tree model and the Train Model modules have been replaced by
    a new module called MD-Customer-Churn-Predictor-Train_Model_Trained_model, as
    highlighted in [Figure 10-21](#batch_inference_pipeline_left_parenthe). This module
    will automatically reference our trained model so we can use it for inference.
    The rest of the data preparation pipeline, including our Python script, will remain
    the same.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和推断管道的主要区别在于推断管道不包含任何训练组件。请注意，“提升决策树”模型和“训练模型”模块已被一个名为“MD-客户流失预测器-Train_Model_Trained_model”的新模块替换，如[图
    10-21](#batch_inference_pipeline_left_parenthe)所示。此模块将自动引用我们训练过的模型，以便我们可以用于推断。数据准备管道的其余部分，包括我们的Python脚本，将保持不变。
- en: To run inference for new data, replace the input datasets with *customers_factTable_June_2022*
    and *survey_responses_June_2022*, respectively. These two datasets represent new
    data from customers; we don’t know yet if they are going to churn. To replace
    the datasets, simply delete the existing datasets from the canvas and pull the
    new datasets over from the asset library. Your canvas should look like [Figure 10-22](#batch_inference_pipeline_left_parenthes).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 要对新数据运行推断，请分别用*customers_factTable_June_2022*和*survey_responses_June_2022*替换输入数据集。这两个数据集代表了客户的新数据；我们还不知道他们是否会流失。要替换数据集，只需从画布中删除现有数据集，并从资产库中拉取新数据集。您的画布应该看起来像[图
    10-22](#batch_inference_pipeline_left_parenthes)。
- en: '![Batch inference pipeline (new data)](Images/apbi_1022.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![批量推断管道（新数据）](Images/apbi_1022.png)'
- en: Figure 10-22\. Batch inference pipeline (new data)
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-22\. 批量推断管道（新数据）
- en: Before we can run the inference, we still need to make some small adjustments.
    Locate the module Select Columns in Dataset on the canvas. It still contains the
    column Churn we used for training. We don’t have this column during inference
    (that’s the one we want to predict!). So edit the settings and delete the Churn
    column from the module. Also, keep the column customerID, because we will need
    this later to match the churn predictions to the customer records. Double-check
    that the column sentiment is still included.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以进行推断之前，我们仍然需要进行一些小调整。在画布上找到数据集中的“选择列”模块。它仍然包含我们用于训练的“流失”列。但是在推断阶段我们不会有这一列（这就是我们要预测的列！）。因此，请编辑设置并从模块中删除“流失”列。同时保留“customerID”列，因为稍后我们需要用它来将流失预测与客户记录匹配。双重检查，“sentiment”列是否仍然包含在内。
- en: If you jump to the end of our pipeline, you will still see the Evaluate Model
    module as the last component here. However, we don’t need this component at this
    stage, because we don’t have any ground truth to compare to. Instead, we want
    to export the scored data to a location. To do this, delete the Evaluate Model
    component from the canvas and drag the Export Data component from the asset library
    to the canvas.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您跳到管道的末尾，您仍然会看到“评估模型”模块作为最后一个组件。但是在这个阶段我们不需要这个组件，因为我们没有任何地面真相可供比较。相反，我们希望将得分数据导出到某个位置。为此，请从画布中删除“评估模型”组件，并从资产库中拖动“导出数据”组件到画布上。
- en: In the Export Data module settings, select Azure Blob Storage as the datastore
    type. For the Datastore, click New Datastore and give it a name such as `**churn_⁠m⁠o⁠d⁠e⁠l⁠_​s⁠c⁠o⁠r⁠i⁠n⁠g**`.
    For the storage account, choose the storage account that you used in previous
    chapters and select “tables” under “Blob container.” Your settings should look
    similar to [Figure 10-23](#creating_a_new_datastore).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在“导出数据”模块设置中，选择Azure Blob Storage作为数据存储类型。对于数据存储，点击“新数据存储”并给它取一个名称，比如`**churn_⁠m⁠o⁠d⁠e⁠l⁠_​s⁠c⁠o⁠r⁠i⁠n⁠g**`。对于存储账户，选择您在之前章节中使用的存储账户，并在“Blob
    container”下选择“tables”。您的设置应该看起来与[图 10-23](#creating_a_new_datastore)类似。
- en: '![Creating a new datastore](Images/apbi_1023.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![创建新的数据存储](Images/apbi_1023.png)'
- en: Figure 10-23\. Creating a new datastore
  id: totrans-179
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-23\. 创建新的数据存储
- en: Scroll down and paste your Account Key from the Azure Storage Account resource
    to the respective field in this settings window. Click Create and you should find
    yourself back in the Export Data settings. Double-check that your newly created
    datastore has been selected and assign your output file the name `**churn_predictions_June_2022.csv**`
    in the Path field. Finally, set the file format to CSV. [Figure 10-24](#add_export_data_module_and_settings)
    shows an example of the export settings.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 向下滚动并将您的 Azure 存储帐户资源中的帐户密钥粘贴到此设置窗口中的相应字段。单击“创建”，您应该会发现自己回到导出数据设置中。仔细检查您新创建的数据存储是否已选择，并在路径字段中将输出文件命名为`**churn_predictions_June_2022.csv**`。最后，将文件格式设置为
    CSV。 [Figure 10-24](#add_export_data_module_and_settings) 显示了导出设置的示例。
- en: '![Add Export Data module and settings](Images/apbi_1024.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![添加导出数据模块和设置](Images/apbi_1024.png)'
- en: Figure 10-24\. Add Export Data module and settings
  id: totrans-182
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-24\. 添加导出数据模块和设置
- en: Lastly, connect the Score Model module to the Export Data module. The final
    pipeline is shown in [Figure 10-25](#final_inference_pipeline).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将评分模型模块连接到导出数据模块。最终管道显示在 [Figure 10-25](#final_inference_pipeline) 中。
- en: Now, click Submit to run your inference pipeline. To keep things organized,
    create a new experiment such as `**customer-churn-inference**` that separates
    your inference runs from your training runs. The inference run will take a couple
    of minutes. Again, we’re doing this on relatively small data samples here, but
    the process itself does scale pretty well to very large datasets without scaling
    proportionally in time.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，单击“提交”以运行您的推理管道。为了保持组织良好，创建一个新的实验，比如`**customer-churn-inference**`，将您的推理运行与培训运行分开。推理运行将花费几分钟时间。再次强调，我们在这里使用的是相对较小的数据样本，但这个过程本身在处理非常大的数据集时表现良好，而且时间成本并不成比例增加。
- en: '![Final inference pipeline](Images/apbi_1025.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![最终推理管道](Images/apbi_1025.png)'
- en: Figure 10-25\. Final inference pipeline
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-25\. 最终推理管道
- en: Once the inference run has been completed, you should see the new file *churn_predictions_June_2022.csv*
    in your *tables* folder in your storage container ([Figure 10-26](#table_output_in_azure_blob_storage)).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦推理运行完成，您应该会在存储容器中的“tables”文件夹中看到名为 *churn_predictions_June_2022.csv* 的新文件（[Figure 10-26](#table_output_in_azure_blob_storage)）。
- en: '![Table output in Azure Blob Storage](Images/apbi_1026.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![Azure Blob Storage 中的表输出](Images/apbi_1026.png)'
- en: Figure 10-26\. Table output in Azure Blob Storage
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-26\. Azure Blob Storage 中的表输出
- en: Time to head over to our BI!
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候转向我们的 BI 了！
- en: Building the AI-Powered Dashboard in Power BI
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Power BI 中构建 AI 动力仪表板
- en: Now that we have built our predictive model and turned unstructured text into
    easy-to-analyze categorical data, let’s bring it all together by building an AI-powered
    customer dashboard.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了预测模型，并将非结构化文本转化为易于分析的分类数据，让我们通过构建一个 AI 动力客户仪表板将所有内容整合起来。
- en: Remember, our goal was to build a dashboard for marketing and sales that provides
    a high-level overview of how customer churn is developing, if things are “still
    normal,” and how effective counteractions were taken. The dashboard should also
    provide further functionality to dive deeper for custom insights. In contrast
    to the previous chapters, I won’t give you detailed step-by-step instructions
    on how the dashboard was built, but instead focus on the main concepts and the
    different components at work here.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们的目标是为营销和销售构建一个仪表板，提供客户流失发展的高级概述，如果事情“仍然正常”，以及采取有效对策的情况。该仪表板还应提供进一步的功能，以深入了解定制洞察。与之前的章节不同，我不会详细说明如何构建仪表板的逐步说明，而是专注于此处运作的主要概念和不同组件。
- en: You can download *Customer_Analytics_AI-Powered.pbix* from the [book’s website](https://oreil.ly/XKoQk)
    or re-create it yourself. I’ve used the steps that were outlined previously.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从 [book’s website](https://oreil.ly/XKoQk) 下载 *Customer_Analytics_AI-Powered.pbix*
    或自行重新创建。我使用了之前概述的步骤。
- en: Note
  id: totrans-195
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For a step-by-step video tutorial on how to build the dashboard, visit [*https://www.aipoweredbi.com/chapter-10*](https://www.aipoweredbi.com/chapter-10).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解如何构建仪表板的逐步视频教程，请访问 [*https://www.aipoweredbi.com/chapter-10*](https://www.aipoweredbi.com/chapter-10)。
- en: 'To build our customer dashboard, we will need the data model in [Figure 10-27](#data_model_in_power_bi-id000003),
    which is based on the following four tables:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建我们的客户仪表板，我们需要 [Figure 10-27](#data_model_in_power_bi-id000003) 中的数据模型，该模型基于以下四个表：
- en: churn_predictions_June_2022
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: churn_predictions_June_2022
- en: This table includes the scored churn dataset that we got from the ML Designer.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表格包括我们从ML Designer获得的得分流失数据集。
- en: customer_dimensions_June_2022
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: customer_dimensions_June_2022
- en: This table contains further BI data for customers such as tenure, services,
    and demographic information. It has a one-to-one relationship to the table churn_predictions_June_2022
    based on the field customer ID.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 此表还包含有关客户的进一步BI数据，例如服务时间、服务和人口统计信息。它与表churn_predictions_June_2022具有一对一的关系，基于客户ID字段。
- en: Churn_Metrics_2021
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Churn_Metrics_2021
- en: A table that includes aggregated churn rates and offers acceptance rates per
    month from previous months. This data could come from a SQL data warehouse; in
    our case, it’s provided as a CSV file on Azure Blob Storage.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 一个表格，包括以往几个月每月的聚合流失率和接受优惠率。这些数据可能来自SQL数据仓库；在我们这里，它作为一个CSV文件存储在Azure Blob存储中提供。
- en: Aggregated_metrics_2022
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Aggregated_metrics_2022
- en: This table is generated by Power BI by taking the dataset churn_metrics_2021
    and adding the predicted churn rate for June 2022\. It will take this time series
    and send it to Azure Anomaly Detection to infer the expected lower and upper bounds
    for the metrics and set a flag for anomalies found.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 此表由Power BI生成，通过获取数据集churn_metrics_2021并添加2022年6月的预测流失率生成。它将获取这个时间序列，并发送至Azure异常检测以推断出该指标的期望下限和上限，并设置检测到的异常标志。
- en: '![](Images/apbi_1027.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/apbi_1027.png)'
- en: Figure 10-27\. Data model in Power BI
  id: totrans-207
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-27\. Power BI中的数据模型
- en: With this data, we can generate a dashboard that looks like [Figure 10-28](#components_of_the_final_dashboard).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这些数据，我们可以生成一个看起来像[图 10-28](#components_of_the_final_dashboard)的仪表板。
- en: '![Components of the final dashboard](Images/apbi_1028.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![最终仪表板的组件](Images/apbi_1028.png)'
- en: Figure 10-28\. Components of the final dashboard
  id: totrans-210
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-28\. 最终仪表板的组件
- en: Let’s unpack the various components.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解各个组件。
- en: Anomaly Detection
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异常检测
- en: At the top left of the dashboard, two line charts show the churn rate and offer
    acceptance rate by month. You can see this part of the dashboard in [Figure 10-29](#churn_and_offer_acceptance_metrics_per).
    While the line charts themselves “just” represent basic descriptive analytics
    (“What happened?”), we are enriching the chart by blending two more pieces of
    information here.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在仪表板的左上角，有两个线图显示了每月的流失率和接受优惠率。您可以在[图 10-29](#churn_and_offer_acceptance_metrics_per)中看到仪表板的这一部分。虽然线图本身只代表基本的描述性分析（“发生了什么？”），但我们在这里通过混合另外两种信息来丰富图表。
- en: First, we are showing a light gray line to represent the expected value of the
    respective metrics based on the data we have seen so far. Second, we highlight
    data points that show an abnormal positive spike (either too high churn rate or
    too high offer acceptance rate). These anomalies are depicted by square data markers.
    With this additional information, we can see that the overall churn trend seems
    to be negative (which is good!), and at the same time we did not really observe
    any clear outlier, although the line seems to be rather wriggly. For the offers,
    we can clearly observe that the high spike in the last month was detected as an
    anomaly, but so were some data points before. The overall trend therefore seems
    to be rather steady, except for some outliers. All this information came from
    the anomaly detection AI service that we were calling with an R or Python script
    directly from Power BI.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们展示了一个浅灰色线来表示根据迄今为止所见数据的相应指标的预期值。其次，我们突出显示显示异常正向高峰点的数据点（无论是流失率过高还是接受优惠率过高）。这些异常由方形数据标记表示。通过这些额外信息，我们可以看到整体的流失趋势似乎是负向的（这是好的！），同时我们并没有真正观察到任何明显的异常值，尽管线看起来相当曲折。对于优惠，我们可以明显观察到上个月高峰被检测为异常，但之前也有一些数据点。因此，整体趋势似乎相当稳定，除了一些异常值。所有这些信息都来自我们直接从Power
    BI调用的异常检测AI服务的数据。
- en: '![Churn and offer acceptance metrics per month](Images/apbi_1029.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![每月流失率和接受优惠率指标](Images/apbi_1029.png)'
- en: Figure 10-29\. Churn and offer acceptance metrics per month
  id: totrans-216
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-29\. 每月流失率和接受优惠率指标
- en: Predictive Analytics
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测分析
- en: The predictive analytics section of the dashboard combines historical information
    with the AI predictions. [Figure 10-30](#churn_prediction_kpi_metric) shows this
    visual. This includes the predicted customer churn rate for the current month,
    as well as a translation to what this means to revenues at risk. The predicted
    customer churn rate for the current month is a KPI that we are calculating as
    a summary metric based on the individual AI predictions we have seen from the
    model we used in the ML Designer. We can compare this metric to a goal, which
    in this case is defined as a churn rate of 0.33—a criteria that is probably met
    in the current month.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板的预测分析部分结合了历史信息和AI预测。[图 10-30](#churn_prediction_kpi_metric) 展示了这一可视化效果。其中包括了当前月份预测的客户流失率，以及这对收入风险的影响。当前月份预测的客户流失率是我们基于ML
    Designer中使用的模型的个别AI预测计算出的摘要指标。我们可以将这一指标与目标进行比较，本例中定义为0.33的流失率——这个标准可能在当前月份得到满足。
- en: To make this information more accessible for business users, we are blending
    this metric with a donut chart called “Revenue at risk,” which sums up all the
    revenues of the current month from customers marked with a `churn flag = 1`. Note
    that this metric is rather simplistic, as it does not account for customer lifetime
    values. We could add this information if we wanted, but for the sake of this demo,
    I decided to stick to the basics. The core idea here is that we can blend AI predictions
    with historical or transactional BI data to make the predictions more relevant
    for the business. We will see another, more detailed example of this in the next
    component.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使业务用户更易于理解这些信息，我们将此指标与称为“风险收入”的圆环图表结合在一起，总结了本月从标有 `churn flag = 1` 的客户处获得的所有收入。请注意，这一指标相当简单化，因为它没有考虑客户的生命周期价值。如果我们希望，可以添加这些信息，但出于演示的目的，我决定坚持基础内容。核心思想在于，我们可以将AI预测与历史或交易型BI数据相结合，使预测对业务更加相关。我们将在下一个组件中看到另一个更详细的示例。
- en: '![Churn prediction KPI metric](Images/apbi_1030.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![流失预测 KPI 指标](Images/apbi_1030.png)'
- en: Figure 10-30\. Churn prediction KPI metric
  id: totrans-221
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-30\. 流失预测 KPI 指标
- en: AI-Powered Descriptive Analytics
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI驱动的描述性分析
- en: In the AI-powered descriptive analytics part of the dashboard, the AI at work
    is the most seamless, yet possibly the most intuitive for users. The AI-powered
    descriptive part of this analysis consists of two charts, shown in [Figure 10-31](#descriptive_analytics_component).
    The upper part is a Q&A tool, and the lower part is a table visual.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在仪表板的AI驱动的描述性分析部分，AI的工作是最无缝的，但可能也是对用户最直观的。这项分析的AI驱动部分包括两个图表，显示在[图 10-31](#descriptive_analytics_component)
    中。上部分是一个问答工具，下部分是一个表格可视化。
- en: Let’s explore the Q&A tool first. This tool combines churn scores with BI data
    to allow queries such as, “What’s the average predicted churn rate in segment
    *xyz*?” This visual can be used to run natural language queries against our data
    models. Thanks to the relationship between the predicted churn outcomes and the
    dimensional BI data from the warehouse, the user can seamlessly blend AI-powered
    predictions with additional properties about the customers. As shown in the example,
    the user can query the “Average churn per internet service” and see that the churn
    rate for fiber optics is much higher than in the other internet service categories.
    The only settings we needed to make for this is to define synonyms in the Q&A
    tool so that “average churn” can be matched to the data field “scored labels,”
    as it is called originally in the source data table.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们探索问答工具。此工具将流失评分与BI数据结合，允许查询诸如“在 *xyz* 细分中的平均预测流失率是多少？”这样的问题。此可视化可用于针对我们的数据模型运行自然语言查询。由于预测流失结果与数据仓库中的维度BI数据之间的关系，用户可以无缝地将AI驱动的预测与客户的附加属性相结合。如示例所示，用户可以查询“每种互联网服务的平均流失率”，并看到光纤的流失率比其他互联网服务类别要高得多。我们唯一需要做的设置是在问答工具中定义同义词，以便将“平均流失率”与源数据表中称为“评分标签”的数据字段匹配起来。
- en: '![Descriptive analytics component](Images/apbi_1031.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![描述性分析组件](Images/apbi_1031.png)'
- en: Figure 10-31\. Descriptive analytics component
  id: totrans-226
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-31\. 描述性分析组件
- en: The lower part of the descriptive analytics component is a table that leverages
    a combination of historic BI data and AI predictions. The user can calculate revenue
    at risk by combining churn prediction with current revenues. To do this, the table
    uses a new field called Revenue Risk, which was generated in Power BI as a quick
    measure that multiplies a customer’s monthly revenue with their individual churn
    probabilities. If we now sum that up over various customer categories, we can
    easily spot the customer segments where most money is going to be lost, making
    the aggregate churn number even more actionable for sales and marketing. If we
    look at [Figure 10-31](#descriptive_analytics_component), we can clearly see that
    the segment of customers who are on a monthly contract with fiber optics internet
    service and without multiple lines provide the biggest leverage to defend revenue,
    with a revenue risk of $8,754 per month. If marketing was to think about personalized
    counterchurn offer incentives, this should be an interesting category to look
    further into.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 描述性分析组件的下部是一个表格，利用历史BI数据和AI预测的组合。用户可以通过将流失预测与当前收入结合来计算风险收入。为此，该表格使用了一个名为“收入风险”的新字段，这个字段在Power
    BI中作为快速度量生成，通过将客户的月度收入乘以其个体流失概率来计算。如果我们现在在各种客户类别上累加这些值，我们可以轻松地发现将会损失大量资金的客户细分，使总体流失数字对销售和营销更具操作性。如果我们看一下[图 10-31](#descriptive_analytics_component)，我们可以清楚地看到，使用光纤互联网服务的月租合同客户且没有多条线路的客户群体，为捍卫收入提供了最大的杠杆效应，每月的收入风险为$8,754。如果营销部门考虑个性化的反流失优惠，这将是一个有趣的类别进一步探索。
- en: Unstructured Data
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非结构化数据
- en: And lastly, the unstructured data area of the dashboard provides more insights
    on the sentiment scores in combination with dimensional data. The sentiment analysis
    of the unstructured data eventually became part of our churn prediction model,
    but it can also stand on its own to provide further insights.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在仪表板的非结构化数据区域，结合维度数据，可以提供更多有关情感分数的见解。非结构化数据的情感分析最终成为我们流失预测模型的一部分，但它也可以独立提供更深入的见解。
- en: The treemap visual, shown in [Figure 10-32](#sentiment_analysis), contrasts
    the sentiment labels to any customer dimension we want—in this case, the contract
    type. From this visual, we can see that while most customers are actually happy
    with regards to the sentiment of their survey comments, the majority of all customers
    who provided negative feedback were on a monthly plan. Considering the high churn
    likelihood of customers in this category, it should be the first priority to look
    into this category about what’s fundamentally going wrong here.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Treemap视觉化，显示在[图 10-32](#sentiment_analysis)，将情感标签与我们想要的任何客户维度进行对比——在本例中为合同类型。从这个视觉化中，我们可以看到，尽管大多数客户对他们的调查评论的情感感到满意，但提供负面反馈的大多数客户都是月度计划用户。考虑到这一类客户的高流失可能性，应首先优先处理这一类别中出现的根本问题。
- en: '![Sentiment analysis](Images/apbi_1032.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![情感分析](Images/apbi_1032.png)'
- en: Figure 10-32\. Sentiment analysis
  id: totrans-232
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-32\. 情感分析
- en: 'If we pull everything together and look at the dashboard itself ([Figure 10-33](#final_dashboard)),
    we can provide the marketing and sales staff with a customer-centric dashboard
    that uses AI under the hood not to show off, but with one goal in mind: to make
    data more actionable and more meaningful to business stakeholders.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们把所有内容汇总，并查看仪表板本身（[图 10-33](#final_dashboard)），我们可以为市场营销和销售人员提供一个以客户为中心的仪表板，它在幕后使用AI，并非为了炫耀，而是有一个目标：使数据对业务利益相关者更具操作性和更有意义。
- en: Try it out yourself, by opening the accompanying Power BI file on your computer
    and playing around with the components therein. Which information would you add,
    change, or delete altogether?
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试自己操作，通过在计算机上打开配套的Power BI文件并与其中的组件互动。您会添加、更改或完全删除哪些信息？
- en: '![Final dashboard](Images/apbi_1033.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![最终仪表板](Images/apbi_1033.png)'
- en: Figure 10-33\. Final dashboard
  id: totrans-236
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-33\. 最终仪表板
- en: Cleaning Up Resources
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清理资源
- en: When you’re done with the use cases in this book, I recommend deleting all resources
    used to avoid ongoing costs on Microsoft Azure. To delete all resources at once,
    visit the [Azure portal](http://portal.azure.com) and select “Resource groups.”
    Select the resource group that you created for this book and choose “Delete resource
    group.” Confirm the resource group name and then click Delete.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 当您完成了本书中的使用案例后，我建议删除所有使用的资源，以避免在 Microsoft Azure 上产生持续的成本。要一次性删除所有资源，请访问 [Azure
    门户](http://portal.azure.com) 并选择“资源组”。选择您为本书创建的资源组，然后选择“删除资源组”。确认资源组名称，然后单击删除。
- en: Summary
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: 'I hope that this chapter has shown you that using AI services in your BI isn’t
    an either/or decision. In fact, the biggest benefits come from combining multiple
    AI services. However, don’t let the technology pull you down a rabbit hole, where
    the BI functionality is overloaded with AI components at work. Remember that each
    AI service that you add also adds another layer of technical debt: someone has
    to eventually take care of the models, the Q&A tools, the data integration, and
    so on.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 希望本章能够向您展示，在您的商业智能中使用 AI 服务并不是非此即彼的选择。事实上，最大的好处来自于结合多个 AI 服务。但是，不要让技术把您拖入兔子洞，使得商业智能功能因工作中的
    AI 组件而过载。请记住，每个添加的 AI 服务都会增加一层技术债务：最终必须有人来管理模型、问答工具、数据集成等。
- en: Pulling various AI services together, however, is a great way of validating
    that the business benefits from further insights or of carving out what it is
    exactly that the business is looking for. With your flexible analytics stack ranging
    all the way from accessing unstructured data, to descriptive analytics, up to
    prescriptive analytics, from within the same platform, you’re in a great position
    to find the sweet spots between adding technical complexity and delivering actual
    business value.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将各种 AI 服务整合在一起，是验证业务是否从进一步洞察中获益，或明确业务正在寻找的内容的一种很好的方式。通过您灵活的分析堆栈，从访问非结构化数据、到描述性分析，再到规范性分析，都能在同一平台内实现，您将能够找到增加技术复杂性与提供实际业务价值之间的最佳平衡点。
- en: Congratulations, you’ve successfully built your first prototype, which contains
    no fewer than four AI services! But what’s next? As mentioned, it is a prototype,
    and it still has a good way to go before we could ship this dashboard to a production
    environment. In the next chapter, you will learn more about what it takes to move
    from prototype to production and how to tackle the complexities that come with
    it.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您成功构建了第一个原型，其中包含不少于四个 AI 服务！接下来呢？如前所述，这只是一个原型，离能够将此仪表板部署到生产环境还有很长的路要走。在下一章中，您将了解更多关于从原型到生产的过程及如何处理随之而来的复杂性。
