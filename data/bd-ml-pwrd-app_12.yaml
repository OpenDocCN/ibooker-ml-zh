- en: Chapter 8\. Considerations When Deploying Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第八章。 部署模型时的考虑因素
- en: The previous chapters covered model training and generalization performance.
    These are necessary steps to deploy a model, but they are not sufficient to guarantee
    the success of an ML-powered product.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 前几章涵盖了模型训练和泛化性能。 这些是部署模型所必需的步骤，但不足以保证ML驱动产品的成功。
- en: 'Deploying a model requires a deeper dive into failure modes that could impact
    users. When building products that learn from data, here are a few questions you
    should answer:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 部署模型需要更深入地研究可能影响用户的故障模式。 在构建从数据中学习的产品时，以下是您应该回答的几个问题：
- en: How was the data you are using collected?
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您使用的数据是如何收集的？
- en: What assumptions is your model making by learning from this dataset?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的模型通过从这个数据集学习得出什么假设？
- en: Is this dataset representative enough to produce a useful model?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此数据集是否足够代表性以生成有用的模型？
- en: How could the results of your work be misused?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的工作结果如何可能被滥用？
- en: What is the intended use and scope of your model?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的模型的预期使用和范围是什么？
- en: The field of data ethics aims to answer some of these questions, and the methods
    used are constantly evolving. If you’d like to dive deeper, O’Reilly has a comprehensive
    report on the subject, [*Ethics and Data Science*](https://www.oreilly.com/library/view/ethics-and-data/9781492043898/),
    by Mike Loukides et al.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据伦理学旨在回答其中一些问题，使用的方法不断发展。 如果您想更深入地了解，O'Reilly有一份由Mike Loukides等人编写的关于这一主题的综合报告，[*Ethics
    and Data Science*](https://www.oreilly.com/library/view/ethics-and-data/9781492043898/)。
- en: In this chapter, we will discuss some concerns around data collection and usage
    and the challenges involved with making sure models keep working well for everyone.
    We will conclude the section with a practical interview covering tips to translate
    model predictions to user feedback.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论围绕数据收集和使用的一些关注点以及确保模型对每个人保持良好运作的挑战。 我们将通过一个实用的访谈结束本节，介绍将模型预测翻译为用户反馈的技巧。
- en: Let’s start by looking at data, first covering ownership concerns and then moving
    on to bias.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从数据开始，首先涵盖所有权问题，然后再讨论偏见。
- en: Data Concerns
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据关注
- en: In this section, we will start by outlining tips to keep in mind when you store,
    use, and generate data. We will start by covering data ownership and the responsibilities
    that come with storing data. Then, we will discuss common sources of bias in datasets
    and methods to take this bias into account when building models. Finally, we’ll
    cover examples of the negative consequences of such biases and why they are important
    to mitigate.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将首先概述存储、使用和生成数据时应牢记的几个提示。 我们将从数据所有权和存储数据所带来的责任开始。 然后，我们将讨论数据集中常见偏见的来源及在构建模型时考虑这些偏见的方法。
    最后，我们将讨论此类偏见的负面后果示例及其为何重要的原因。
- en: Data Ownership
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据所有权
- en: 'Data ownership refers to the requirements associated with the collection and
    use of data. Here are a few important aspects to consider with regard to data
    ownership:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据所有权指的是与数据收集和使用相关的要求。 以下是几个关于数据所有权需要考虑的重要方面：
- en: '*Data collection:* Are you legally authorized to collect and use the dataset
    you want to train your model on?'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据收集：*您是否有法律授权收集和使用您希望在模型上训练的数据集？'
- en: '*Data usage and permission:* Have you clearly explained to your users why you
    needed their data and how you wanted to use it, and did they agree?'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据使用和许可：*您是否向用户清楚解释了为什么需要他们的数据以及您希望如何使用它，并且他们是否同意？'
- en: '*Data storage:* How are you storing your data, who has access to it, and when
    will you delete it?'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据存储：*您如何存储数据，谁可以访问它，何时将其删除？'
- en: Collecting data from users can help personalize and tailor product experiences.
    It also implies both moral and legal responsibilities. While there has always
    been a moral obligation to safe-keep data provided by users, new regulations increasingly
    make it a legal one. In Europe, for example, the GDPR regulation now sets strict
    guidelines regarding data collection and processing.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户那里收集数据可以帮助个性化和定制产品体验。 这也意味着道德和法律责任。 尽管保护用户提供的数据始终存在道德义务，但新的法规越来越多地使其成为法律义务。
    例如，在欧洲，GDPR法规现在设置了严格的数据收集和处理指南。
- en: For organizations storing large amounts of data, data breaches represent a significant
    liability risk. Such breaches both erode the trust of users in the organization
    and often lead to legal action. Limiting the amount of data collected thus limits
    legal exposure.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于存储大量数据的组织来说，数据泄露代表了重大的责任风险。这些泄露不仅侵蚀了用户对组织的信任，还经常导致法律诉讼。因此，限制收集的数据量可以减少法律风险。
- en: For our ML editor, we will start by using publicly available datasets, which
    were collected with the agreement of users and are stored online. If we wanted
    to record additional data, such as records of how our service is used in order
    to improve it, we would have to clearly define a data collection policy and share
    it with users.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的机器学习编辑器，我们将首先使用公开可用的数据集，这些数据集是在用户同意的情况下收集并在线存储的。如果我们想要记录额外的数据，例如记录我们的服务如何使用以便改进，我们必须明确定义数据收集政策并与用户分享。
- en: In addition to data collection and storage, it is important to consider whether
    using collected data may lead to poor performance. A dataset is appropriate to
    use in some cases, but not in others. Let’s explore why.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据收集和存储外，考虑使用收集的数据可能导致性能不佳也很重要。在某些情况下，数据集适合使用，但在其他情况下则不适合。让我们来探讨一下为什么。
- en: Data Bias
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据偏见
- en: Datasets are the result of specific data collection decisions. These decisions
    lead to datasets presenting a biased view of the world. ML models learn from datasets
    and thus will reproduce these biases.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集是特定数据收集决策的结果。这些决策导致数据集呈现了对世界的偏见观点。机器学习模型从数据集中学习，因此会重现这些偏见。
- en: For example, let’s say a model is trained on historical data to predict leadership
    skills by forecasting the likelihood of a person becoming a CEO based on information
    including their gender. Historically, according to [the “The Data on Women Leaders”
    fact sheet](https://oreil.ly/vTLkH) compiled by the Pew Research Center, most
    Fortune 500 CEOs have been male. Using this data to train a model will lead to
    it learning that being male is a valuable predictor of leadership. Being male
    and being a CEO are correlated in the chosen dataset due to societal reasons,
    which led to fewer opportunities for women to even be considered for such roles.
    By blindly training a model on this data and using it to make predictions, we
    would simply be reinforcing biases of the past.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设一个模型是基于历史数据进行训练的，以预测领导能力，即预测一个人成为CEO的可能性，其中包括他们的性别信息。根据皮尤研究中心编制的《女性领导数据》信息表所述，历史上大多数财富500强公司的CEO都是男性。使用这些数据来训练模型将导致模型学习到男性是领导力宝贵的预测因素。在所选数据集中，男性和CEO之间存在相关性，这是由于社会原因，导致女性甚至不被考虑这样的角色。通过盲目地在这些数据上训练模型并用于预测，我们只会加强过去的偏见。
- en: It can be tempting to consider data as ground truth. In reality, most datasets
    are a collection of approximate measurements that ignore a larger context. We
    should start with the assumption that any dataset is biased and estimate how this
    bias will affect our model. We can then take steps to improve a dataset by making
    it more representative and adjust models to limit their ability to propagate existing
    bias.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 认为数据是真实的可能很诱人。实际上，大多数数据集是近似测量的集合，忽略了更大背景。我们应该假设任何数据集都存在偏见，并估计这种偏见将如何影响我们的模型。然后，我们可以采取措施改进数据集，使其更具代表性，并调整模型以限制其传播现有偏见的能力。
- en: 'Here are a few examples of common sources of errors and biases in datasets:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是数据集中常见错误和偏见的几个例子：
- en: '*Measurement errors or corrupted data:* Each data point comes with uncertainty
    due to the method used to produce it. Most models ignore such uncertainty and
    can thus propagate systematic measurement errors.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*测量误差或数据损坏：* 每个数据点由于生成方法的不确定性而带有不确定性。大多数模型忽略这种不确定性，因此可能传播系统测量误差。'
- en: '*Representation:* Most datasets present an unrepresentative view of a population.
    Many early face recognition datasets mostly contained images of white men. This
    led to models performing well for this demographic but failing on others.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*代表性：* 大多数数据集呈现了人口的不典型视图。许多早期的面部识别数据集主要包含白人男性的图像。这导致模型在这个人群中表现良好，但在其他人群中失败。'
- en: '*Access:* Some datasets can be harder to find than others. For example, English
    text is easier to gather online than other languages. This ease of access leads
    to most of the state-of-the-art language models being trained exclusively on English
    data. As a consequence, English speakers will have access to better ML-powered
    services than non-English speakers. This disparity often is self-reinforcing,
    as the additional volume of users for English products helps make those models
    even better compared to ones for other languages.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*获取:* 有些数据集比其他数据集更难获取。例如，英文文本比其他语言更容易在线获取。这种获取的便利性导致大多数最先进的语言模型仅基于英文数据进行训练。因此，英语使用者将比非英语使用者能够访问到更好的机器学习服务。这种差异通常是自我强化的，因为英语产品的用户量更大有助于使这些模型相比其他语言的模型更加优秀。'
- en: Test sets are used to evaluate the performance of models. For this reason, you
    should take special care to make sure that your test set is as accurate and representative
    as possible.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集用于评估模型的性能。因此，您应特别注意确保您的测试集尽可能准确和代表性。
- en: Test sets
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试集
- en: Representation appears in every ML problem. In [“Split Your Dataset”](ch05.html#splitting_data),
    we covered the value of separating data in different sets to evaluate a model’s
    performance. When doing this, you should attempt to build a test set that is inclusive,
    representative, and realistic. This is because a test set serves as a proxy for
    performance in production.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个机器学习问题中都会出现表示问题。在[《分割数据集》](ch05.html#splitting_data)中，我们讨论了将数据分成不同集合以评估模型性能的价值。在执行此操作时，您应努力构建一个包含、代表和现实的测试集。这是因为测试集充当了生产环境性能的代理。
- en: To do this, when designing your test set, think of every user that could interact
    with your model. To improve the chances that every user has an equally positive
    experience, try to include examples representative of every type of user in your
    test set.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，在设计测试集时，请考虑每个可能与您的模型互动的用户。为了提高每个用户都能有同样积极体验的机会，尽量在测试集中包含每种类型用户的代表性示例。
- en: Design your test set to encode product goals. When building a diagnosis model,
    you’ll want to make sure that it performs adequately for all genders. To evaluate
    whether that is the case, you’ll need to have them all represented in your test
    set. Gathering a diverse set of point of views can help with this endeavor. If
    you can, before deploying a model, give a diverse set of users an opportunity
    to examine it, interact with it, and share feedback.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 设计您的测试集以编码产品目标。在构建诊断模型时，您将希望确保它对所有性别的表现都足够好。为了评估是否达到了这一目标，您需要在测试集中包含所有性别的代表性数据。收集多样化的观点可以帮助实现这一努力。如果可能的话，在部署模型之前，让多样化的用户有机会检查、与之互动并分享反馈。
- en: I want to make a final point when it comes to bias. Models are often trained
    on historical data, which represents the state of the world in the past. Because
    of this, bias most often affects populations that are already disenfranchised.
    Working to eliminate bias is thus an endeavor that can help make systems fairer
    for the people who need it most.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到偏见时，我想最后指出一点。模型通常是基于历史数据进行训练的，这些数据反映了过去的世界状态。因此，偏见往往最容易影响到那些已经处于弱势的群体。致力于消除偏见是一个可以帮助使系统对最需要帮助的人群更公平的努力。
- en: Systemic Bias
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 制度性偏见
- en: Systemic bias refers to institutional and structural policies that have led
    to some populations being unfairly discriminated against. Because of this discrimination,
    such populations are often over- or underrepresented in historical datasets. For
    example, if societal factors have contributed to some populations being historically
    overrepresented in criminal arrest databases, an ML model trained from that data
    will encode this bias and carry it forward to modern-day predictions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 制度性偏见指的是导致某些人群受到不公平歧视的体制和结构性政策。由于这种歧视，这些人群在历史数据集中往往被过度或不足地代表。例如，如果社会因素导致某些人群在犯罪逮捕数据库中历史上被过度代表，那么从这些数据训练的机器学习模型将会编码这种偏见，并将其延续到现代预测中。
- en: This can have disastrous consequences and lead to the marginalization of subsets
    of the population. For a concrete example, see J. Angwin et al.’s [“Machine Bias”
    ProPublica report](https://oreil.ly/6UE3z), on ML bias for crime prediction.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能会带来灾难性的后果，并导致某些人群的边缘化。具体示例，请参见J. Angwin等人的[《机器偏见》ProPublica报告](https://oreil.ly/6UE3z)，关于犯罪预测中的机器学习偏见。
- en: Removing or limiting bias in a dataset is challenging. When trying to prevent
    a model from being biased against certain features such as ethnicity or gender,
    some have tried to remove the attribute in question from the list of features
    that a model uses to make predictions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 移除或限制数据集中的偏差是具有挑战性的。当试图防止模型对某些特征（如种族或性别）存在偏见时，有些人尝试从模型用于预测的特征列表中删除相关属性。
- en: In practice, simply removing a feature does not prevent a model from being biased
    against it, because most datasets contain many other features that are strongly
    correlated with it. For example, ZIP code and income are highly correlated with
    ethnicity in the United States. If you remove only one feature, a model may be
    just as biased, albeit in ways that are harder to detect.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，仅仅删除一个特征并不能防止模型对其存在偏见，因为大多数数据集中还有许多与之强相关的其他特征。例如，在美国，邮政编码和收入与种族高度相关。如果只移除一个特征，模型可能仍然存在偏见，尽管这种偏见可能更难以检测。
- en: 'Instead, you should be explicit about which fairness constraints you are trying
    to enforce. For example, you could follow the approach outlined in the paper by
    M. B. Zafar et al., [“Fairness Constraints: Mechanisms for Fair Classification”](https://oreil.ly/JWlIi),
    where the fairness of a model is measured using the p% rule. The p% rule is defined
    as “the ratio between the percentage of subjects having a certain sensitive attribute
    value receiving a positive outcome and the percentage of subjects not having that
    value receiving the same outcome should be no less than p:100.” Using such a rule
    allows us to quantify bias and thus address it better, but it requires keeping
    track of the feature we’d like a model not to be biased against.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，你应该明确你试图强制执行的公平约束。例如，你可以遵循M. B. Zafar等人在论文中提出的方法，["公平约束：公平分类的机制"](https://oreil.ly/JWlIi)，其中模型的公平性是使用p%规则来衡量的。p%规则被定义为“具有某一敏感属性值的受试者接收积极结果的百分比与不具备该值的受试者接收相同结果的百分比之比不得低于p:100”。使用这样的规则允许我们量化偏差，并更好地加以解决，但需要跟踪我们希望模型不偏见的特征。
- en: In addition to evaluating risk, biases, and errors in a dataset, ML requires
    evaluating models.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 除了评估数据集中的风险、偏见和错误之外，ML还需要评估模型本身。
- en: Modeling Concerns
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模关注点
- en: How can we minimize the risk of a model introducing undesirable bias?
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何最小化模型引入不良偏差的风险？
- en: There are multiple ways that models can impact users negatively. First, we’ll
    tackle runaway feedback loops, and then we’ll explore the risks of a model discreetly
    failing on a small segment of the population. We will then discuss the importance
    of contextualizing ML predictions appropriately for users and end this section
    by covering the risk of having nefarious actors abusing models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以对用户产生负面影响的方式有多种。首先，我们将解决失控的反馈循环问题，然后探讨模型在小部分人群中悄悄失败的风险。接着，我们将讨论适当地为用户提供ML预测的重要性，并通过讨论恶意行为者滥用模型的风险来结束本节。
- en: Feedback Loops
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反馈循环
- en: In most ML-powered systems, having a user follow a model’s recommendation will
    make it more likely for future models to make the same recommendation. When left
    unchecked, this phenomenon can lead to models entering a self-reinforcing feedback
    loop.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数由ML驱动的系统中，用户跟随模型的推荐会使未来的模型更有可能做出相同的推荐。如果不加以控制，这种现象会导致模型进入自我强化的反馈循环。
- en: For example, if we train a model to recommend videos to users and our first
    version of the model is slightly more likely to recommend videos of cats than
    dogs, then users will watch more cat videos than dog videos on average. If we
    train a second version of the model using a dataset of historical recommendations
    and clicks, we will incorporate the first model’s bias into our dataset, and our
    second model will favor cats much more heavily.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们训练一个模型来向用户推荐视频，并且我们的第一个版本的模型比推荐猫的视频要稍微多一点，那么用户平均来看会观看更多的猫视频而不是狗视频。如果我们使用历史推荐和点击数据集训练第二个版本的模型，我们将把第一个模型的偏见纳入我们的数据集，第二个模型将更偏向于大量推荐猫的视频。
- en: Since content recommendation models often get updated multiple times a day,
    it would not take long before our most recent version of the model recommends
    exclusively cat videos. You can see an example of this in [Figure 8-1](#feedback_loop).
    Due to an initial popularity of a cat video, the model progressively learns to
    recommend more cat videos, until it reaches the state on the right, only ever
    recommending cat videos.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于内容推荐模型通常每天更新多次，不久后我们的模型最新版本将只推荐猫视频。你可以在[图 8-1](#feedback_loop)中看到一个例子。由于猫视频的初始受欢迎程度，该模型逐渐学会更多推荐猫视频，直到最终仅推荐猫视频。
- en: '![Example of a feedback loop](assets/bmla_0801.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![反馈循环示例](assets/bmla_0801.png)'
- en: Figure 8-1\. Example of a feedback loop
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-1\. 反馈循环示例
- en: Filling the internet up with cat videos might not seem like a tragedy, but you
    can imagine how these mechanisms can rapidly reinforce negative biases and recommend
    inappropriate or dangerous content to unsuspecting users. In fact, models that
    attempt to maximize the probability of a user clicking will learn to recommend
    clickbait content, content that is very tempting to click but does not provide
    any value to the user.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管填充互联网充斥着猫视频可能看起来不像是一场悲剧，但你可以想象这些机制如何快速强化负面偏见，向毫无戒备的用户推荐不当或危险的内容。事实上，试图最大化用户点击概率的模型将学会推荐点击诱饵内容，即非常诱人点击但对用户没有任何价值的内容。
- en: Feedback loops also tend to introduce bias to favor a minority of very active
    users. If a video platform uses the number of clicks on each video to train its
    recommendation algorithm, it risks having its recommendation overfit to its most
    active users who represent the vast majority of clicks. Every other user of the
    platform would then be exposed to the same videos regardless of their individual
    preferences.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈循环还倾向于引入偏见，以偏爱少数非常活跃的用户。如果视频平台使用每个视频的点击次数来训练其推荐算法，它有风险将其推荐过度拟合到占点击数量绝大多数的最活跃用户。平台的其他用户将会看到相同的视频，而不考虑他们的个人偏好。
- en: To limit negative effects of feedback loops, choose a label that is less prone
    to creating such a loop. Clicks only measure whether a user opens a video, not
    whether they enjoy it. Using clicks as an optimization goal leads to recommending
    more eye-catching content, without any concerns for its relevance. Replacing the
    target metric with watch time, which is more correlated with the user satisfaction,
    would help alleviate such a feedback loop.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了限制反馈循环的负面影响，选择一个不易造成这种循环的指标。点击仅仅衡量用户是否打开了视频，而不是他们是否喜欢它。将点击作为优化目标会导致推荐更吸引眼球的内容，而不考虑其相关性。用观看时间替换目标指标，这与用户满意度更相关，有助于减轻这种反馈循环。
- en: Even then, recommendation algorithms that optimize for engagement of any sort
    always carry the risk of degenerating into a feedback loop since their only objective
    is to maximize a practically limitless metric. For example, even if an algorithm
    optimizes for watch time to encourage more engaging content, the state of the
    world that would maximize this metric is one where every user spent their entire
    day watching videos. Using such engagement metrics may help increase usage, but
    this raises the question of whether that is always a worthwhile goal to optimize
    for.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 即使如此，优化任何形式参与度的推荐算法始终存在退化为反馈循环的风险，因为它们的唯一目标是最大化一个实际上无限制的指标。例如，即使算法优化观看时间以鼓励更吸引人的内容，最大化这一指标的世界状态是每个用户整天观看视频。使用这样的参与度指标可能有助于增加使用率，但这引发了一个问题：这是否总是一个值得优化的目标。
- en: In addition to the risk of creating feedback loops, models can also exhibit
    poorer performance than expected in production despite receiving convincing scores
    on offline validation metrics.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 除了存在创造反馈循环的风险外，模型在生产环境中的表现也可能比离线验证指标预期的要差。
- en: Inclusive Model Performance
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 包容性模型表现
- en: 'In [“Evaluate Your Model: Look Beyond Accuracy”](ch05.html#beyond_accuracy),
    we covered a variety of evaluation metrics that attempt to judge performance on
    different subsets of a dataset. This type of analysis is helpful to ensure that
    a model performs equally well for different types of users.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“评估您的模型：超越准确性”](ch05.html#beyond_accuracy)中，我们涵盖了多种评估指标，试图评估数据集不同子集上的性能。这种类型的分析有助于确保模型对不同类型的用户表现同样出色。
- en: This is especially important when training new versions of existing models and
    deciding whether to deploy them. If you only compare aggregate performance, you
    could fail to notice a significant degradation of performance on a segment of
    the data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这在训练现有模型的新版本并决定是否部署它们时尤为重要。如果您仅比较总体性能，您可能会忽视数据的某个段落性能显著下降。
- en: Failure to notice such degradation of performance has led to catastrophic product
    failures. In 2015, an automated photo-tagging system categorized photos of African
    American users as gorillas (see this [2015 BBC article](https://oreil.ly/nVkZv)).
    This is an appalling failure and a consequence of not validating a model on a
    representative set of inputs.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 忽视性能下降的问题导致了灾难性的产品失败。2015年，一个自动化照片标记系统将非裔美国用户的照片分类为大猩猩（请参阅这篇[2015年BBC文章](https://oreil.ly/nVkZv)）。这是一个令人震惊的失败，是因为没有在代表性输入集上验证模型的结果。
- en: This sort of issue can arise when updating an existing model. Say you are updating
    a facial recognition model, for example. The previous model had an accuracy of
    90%, and the new one has an accuracy of 92%. Before deploying this new model,
    you should benchmark its performance on a few different subsets of users. You
    may find that while the performance has slightly improved in aggregate, the new
    model’s accuracy is performing very poorly for photos of women over the age of
    40, so you should abstain from deploying it. Instead, you should modify the training
    data to add more representative examples and retrain a model that can perform
    well for every category.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当更新现有模型时可能会出现这种问题。比如说，你正在更新一个面部识别模型。之前的模型精度为90%，而新模型的精度为92%。在部署这个新模型之前，你应该在几个不同的用户子集上评估其性能。你可能会发现，虽然总体性能略有提高，但新模型在40岁以上女性的照片上表现非常糟糕，因此你应该避免部署它。相反，你应该修改训练数据，增加更多代表性的例子，并重新训练一个可以在每个类别中表现良好的模型。
- en: Omitting such benchmarks can lead to models not working for a significant proportion
    of their intended audience. Most models will never work for every possible input,
    but it is important to validate that they work for all expected ones.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略这些基准可能导致模型无法为其预期受众的大部分工作。大多数模型永远不会对每个可能的输入都有效，但验证它们对所有预期输入的有效性非常重要。
- en: Considering Context
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 考虑到上下文
- en: Users will not always be aware that a given piece of information originated
    as a prediction from a ML model. Whenever possible, you should share the context
    of a prediction with a user, so they can make an informed decision as to how to
    leverage it. To do so, you can start by describing to them how the model was trained.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 用户并不总是意识到某些信息来自ML模型的预测。在可能的情况下，您应该与用户分享预测背后的背景信息，以便他们能够决定如何利用它。为此，您可以开始描述模型的训练方式。
- en: There is no industry-standard “model disclaimer” format yet, but active research
    in this area has shown promising formats, such as model cards (see this article
    by M. Mitchell et al., [“Model Cards for Model Reporting”](https://arxiv.org/abs/1810.03993)),
    a documentation system for transparent model reporting. In the proposed approach,
    a model is accompanied by metadata about how it was trained, which data it was
    tested on, what its intended use is, and more.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 目前尚无行业标准的“模型免责声明”格式，但该领域的活跃研究显示出了一些有前景的格式，例如模型卡片（参见M. Mitchell等人的文章[“模型报告的模型卡片”](https://arxiv.org/abs/1810.03993)）。在提议的方法中，模型附带有关其训练方式、测试数据以及预期用途等元数据。
- en: In our case study, the ML Editor provides feedback based on a specific dataset
    of questions. If we were to deploy it as a product, we would include a disclaimer
    about the types of inputs the model is expected to perform well on. Such a disclaimer
    could be as simple as “This product attempts to recommend better ways to phrase
    a question. It was trained on questions from the writing Stack Exchange and may
    thus reflect the particular preferences of that community.”
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例研究中，ML编辑器根据特定的问题数据集提供反馈。如果我们将其作为产品部署，我们将包含一个关于模型预期表现良好输入类型的免责声明。这样的免责声明可以简单地表述为“本产品试图推荐更好的问题表达方式。它是在写作Stack
    Exchange的问题上进行训练的，因此可能反映了该社区的特定偏好。”
- en: Keeping well-meaning users informed is important. Now, let’s look at potential
    challenges that can come from less-friendly users.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 保持善意用户的信息通知是重要的。现在，让我们来看看可能由不友好用户带来的潜在挑战。
- en: Adversaries
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对手
- en: Some ML projects need to consider the risk of having models be defeated by adversaries.
    Fraudsters may attempt to fool a model that is tasked with detecting suspicious
    credit card transactions. Alternatively, adversaries may want to probe a trained
    model to glean information they should not be allowed to access about the underlying
    training data, such as sensitive user information.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一些机器学习项目需要考虑模型被对手击败的风险。欺诈者可能试图愚弄一个旨在检测可疑信用卡交易的模型。或者，对手可能希望探测一个训练好的模型，以获取有关底层训练数据的信息，这些信息他们本不应该访问，例如敏感用户信息。
- en: Defeating a model
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 打败一个模型
- en: Many ML models are deployed to protect accounts and transactions from fraudsters.
    In turn, fraudsters attempt to defeat these models by fooling them into believing
    they are legitimate users.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习模型被部署来保护账户和交易免受欺诈者的侵害。反过来，欺诈者试图击败这些模型，以使它们相信他们是合法用户。
- en: If you are trying to prevent fraudulent logins to an online platform, for example,
    you may want to consider sets of features that would include the user’s country
    of origin (many large-scale attacks use multiple servers from the same region).
    If you train a model on such features, you risk introducing bias against nonfraudulent
    users in countries where fraudsters live. In addition, relying only on such a
    feature will make it easy for malicious actors to fool your systems by faking
    their location.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您试图防止对在线平台的欺诈登录，例如，您可能希望考虑包括用户原籍国家在内的一组特征（许多大规模攻击使用同一地区的多个服务器）。如果您在这些特征上训练一个模型，您将面临引入针对非欺诈用户的偏见的风险，这些用户居住在欺诈者所在的国家。此外，仅依赖这样一个特征将使恶意行为者轻而易举地通过伪造他们的位置来愚弄您的系统。
- en: To defend against adversaries, it is important to regularly update models. As
    attackers learn existing patterns of defense and adapt their behavior to defeat
    them, update your models so that they can quickly classify this new behavior as
    fraudulent. This requires monitoring systems so that we can detect changes of
    patterns in activity. We will cover this in more detail in [Chapter 11](ch11.html#monitoring).
    In many cases, defending against attackers requires generating new features to
    better detect their behavior. Feel free to refer to [“Let Data Inform Features
    and Models”](ch04.html#feature_models) for a refresher on feature generation.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防范对手，定期更新模型至关重要。随着攻击者了解现有的防御模式并调整他们的行为以击败它们，更新您的模型，使其能够快速将这种新行为分类为欺诈行为。这需要监控系统以便检测活动模式的变化。我们将在[第11章](ch11.html#monitoring)中详细讨论这一点。在许多情况下，防御攻击者需要生成新的特征以更好地检测他们的行为。请随时参考[“让数据指导特征和模型”](ch04.html#feature_models)以便对特征生成进行复习。
- en: The most common type of attack on models aims to fool them into a wrong prediction,
    but other types of attacks exist. Some attacks aim to use a trained model to learn
    about the data it was trained on.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击模型的最常见方式是欺骗它们产生错误的预测，但还存在其他类型的攻击。一些攻击旨在利用训练好的模型来了解它所训练的数据。
- en: Exploiting a model
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利用一个模型
- en: More than simply fooling a model, attackers could use it to learn private information.
    A model reflects the data it was trained on, so one could use its predictions
    to infer patterns in the original dataset. To illustrate this idea, consider the
    example of a classification model trained on a dataset containing two examples.
    Each example is of a different class, and both examples differ only by a single
    feature value. If you gave an attacker access to a model trained on this dataset
    and allowed them to observe its predictions to arbitrary inputs, they could eventually
    infer that this feature is the only predictive one in the dataset. Similarly,
    an attacker could infer the distribution of features within the training data.
    These distributions often receive sensitive or private information.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 超出简单欺骗模型的范畴，攻击者可以利用它来获取私人信息。模型反映了它所训练的数据，因此可以利用其预测来推断原始数据集中的模式。为了说明这个想法，考虑一个在包含两个示例的数据集上训练的分类模型的例子。每个示例属于不同的类，并且两个示例仅在单个特征值上有所不同。如果您让攻击者访问一个在此数据集上训练的模型，并允许他们观察其对任意输入的预测，他们最终可以推断出这个特征是数据集中唯一的预测性特征。类似地，攻击者可以推断训练数据中特征的分布。这些分布通常涉及敏感或私人信息。
- en: In the fraudulent login detection example, let’s imagine that ZIP code is one
    of the required fields at login. An attacker could attempt to log in with many
    different accounts, testing different ZIP codes to see which values lead to a
    successful login. Doing so would allow them to estimate the distribution of ZIP
    codes in the training set and thus the geographical distribution of this website’s
    customers.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在欺诈登录检测的例子中，假设邮政编码是登录时的必填字段之一。攻击者可以尝试使用许多不同的账户登录，测试不同的邮政编码，以确定哪些值能够成功登录。这样做可以帮助他们估计训练集中邮政编码的分布，从而推断出该网站客户的地理分布。
- en: The simplest way to limit the efficiency of such attacks is to limit the number
    of requests a given user can make, thereby limiting their ability to explore feature
    values. This is not a silver bullet, as sophisticated attackers may be able to
    create multiple accounts to circumvent such a limit.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 限制这类攻击效率的最简单方法是限制特定用户可以发出的请求次数，从而限制其探索特征值的能力。这并非万能药，因为复杂的攻击者可能能够创建多个账户来规避此类限制。
- en: The adversaries described in this section are not the only nefarious users you
    should be concerned with. If you choose to share your work with the wider community,
    you should also ask yourself whether it could be used for dangerous applications.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述的对手不是你唯一需要关注的恶意用户。如果你选择与更广泛的社区分享你的工作，你还应该问自己它是否可能被用于危险的应用程序。
- en: Abuse Concerns and Dual-Use
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 滥用和双重用途
- en: Dual-use describes technologies that are developed for one purpose but can be
    used for others. Because of ML’s ability to perform well on datasets of similar
    types (see [Figure 2-3](ch02.html#input_output_abstraction)), ML models often
    present a dual-use concern.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 双重用途指的是为一种目的开发的技术，但可以用于其他目的。由于机器学习在类似类型的数据集上表现出色（见[图2-3](ch02.html#input_output_abstraction)），ML模型经常引起双重用途的关注。
- en: If you build a model that allows people to change their voice to sound like
    their friends’, could it be misused to impersonate others without their consent?
    If you do choose to build it, how could you include the proper guidance and resources
    to make sure that users understand the proper use of your model?
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你开发了一个允许人们改变声音以模仿朋友的模型，是否可能被滥用来未经同意地冒充他人？如果你决定开发它，如何包含适当的指导和资源，确保用户理解模型的正确使用方式？
- en: Similarly, any model that can accurately classify faces has dual-use implications
    for surveillance. While such a model may originally be built to enable a smart
    doorbell, it could then be used to automatically track individuals across a city-wide
    network of cameras. Models are built using a given dataset but can present risks
    when retrained on other similar datasets.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，任何能准确分类人脸的模型都可能存在监控的双重用途。虽然这样的模型最初可能是为了智能门铃而建立的，但它们随后可能被用于自动跟踪城市范围内的个体，通过摄像头网络实现这一功能。模型是根据特定数据集构建的，但在重新训练时可能带来风险，尤其是在使用类似数据集时。
- en: There are currently no clear best practices on considering dual-use. If you
    believe your work could be exploited for unethical uses, I encourage you to consider
    making it harder to reproduce for that purpose or to engage in thoughtful discussion
    with the community. Recently, OpenAI made the decision to not release its most
    powerful language model because of concerns that it may make spreading disinformation
    online much easier (see OpenAI’s announcement post, [“Better Language Models and
    Their Implications”](https://oreil.ly/W1Y6f)). While this was a relatively novel
    decision, I wouldn’t be surprised if such concerns are raised more often going
    forward.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 目前尚无明确的最佳实践以考虑双重用途。如果你认为你的工作可能会被用于不道德的用途，我建议你考虑增加难以复制的条件，或者与社区进行深入讨论。最近，OpenAI决定不发布其最强大的语言模型，因为担心其可能会使在线传播虚假信息变得更容易（见OpenAI的公告文章，[“更好的语言模型及其影响”](https://oreil.ly/W1Y6f)）。虽然这是一个相对新颖的决定，但我认为类似的担忧未来可能会更频繁地被提出。
- en: To conclude this chapter, in the next section I am sharing a discussion with
    Chris Harland, currently director of engineering at Textio, who has an abundance
    of experience deploying models to users and presenting the results with enough
    context to make them useful.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 总结本章节，在接下来的部分，我将分享与克里斯·哈兰德的讨论，他目前是Textio的工程总监，拥有丰富的模型部署经验，并在呈现结果时提供足够的背景信息，使其有用。
- en: 'Chris Harland: Shipping Experiments'
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 克里斯·哈兰德：航运实验
- en: Chris has a Ph.D. in physics and worked on a variety of ML tasks including computer
    vision to extract structured information from receipts for expensing software.
    He worked on the search team at Microsoft, where he realized the value of ML engineering.
    Chris then joined Textio, a company that builds augmented writing products to
    help users write more compelling job descriptions. Chris and I sat down to discuss
    his experience shipping ML-powered products and how he approaches validating results
    beyond accuracy metrics.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 克里斯拥有物理学博士学位，并在多个ML任务中工作，包括计算机视觉，从收据中提取结构化信息以用于报销软件。他在微软的搜索团队工作时意识到ML工程的价值。后来，克里斯加入了Textio，一家专门构建增强写作产品的公司，帮助用户撰写更具吸引力的职位描述。我与克里斯坐下来讨论了他在推出基于ML的产品和如何验证结果的经验。
- en: 'Q: *Textio uses ML to directly guide users. How is that different from other
    ML tasks?*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: *Textio使用ML直接指导用户。这与其他ML任务有何不同？*'
- en: 'A: When you only focus on predictions, such as when to buy gold or who to follow
    on Twitter, you can tolerate some amount of variance. When you do guidance for
    writing, that is not the case, because your recommendations carry a lot of subtext.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 当你只专注于预测，比如何时买黄金或者在Twitter上关注谁，你可以容忍一定程度的变化。但当你进行写作指导时，情况就不同了，因为你的建议背后潜藏着大量的含义。'
- en: If you tell me to write 200 more words, your model should be consistent and
    allow the user to follow its advice. Once the user writes 150 words, the model
    can’t change its mind and recommend to lower the word count.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你告诉我写200个字，你的模型应该是一致的，并允许用户遵循其建议。一旦用户写了150个字，模型就不能改变主意并建议减少字数了。
- en: 'Guidance also requires clarity: “remove stop words by 50%” is a confusing instruction,
    but “reduce the length of these 3 sentences” may help users in a more actionable
    way. A challenge then becomes maintaining performance while using features that
    are more human understandable.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 指导还需要清晰度：像“减少50%的停用词”这样的指令是令人困惑的，但像“缩短这三个句子的长度”可能以更具体的方式帮助用户。一个挑战是在使用更易于理解的特征时保持性能。
- en: Essentially, ML writing assistants guide the user through our feature space
    from an initial point to a better one according to our model. Sometimes, this
    can involve passing through points that are worse, which can be a frustrating
    user experience. The product needs to be built with these constraints in mind.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，ML写作助手通过我们的模型，引导用户从一个初始点到更好的点在我们的特征空间中移动。有时，这可能涉及经过更糟糕的点，这可能是一种令用户沮丧的体验。产品在建设时需要考虑到这些限制。
- en: 'Q: *What are good ways to perform this guidance?*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: *如何进行这种引导？*'
- en: 'A: For guidance, precision is much more interesting than recall. If you think
    of giving advice to a person, recall would be the ability to give advice in all
    potential relevant domains and some irrelevant ones (of which there are many),
    while precision would be giving advice in a few promising domains ignoring potential
    other ones.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 对于指导来说，精确度比召回率更加有趣。如果你考虑给某人建议，召回率就是在所有潜在相关的领域以及一些无关的领域（其中有很多）中给出建议的能力，而精确度则是在几个有前景的领域中给出建议，忽略潜在的其他领域。'
- en: When giving advice, the cost of being wrong is very high, so precision is the
    most useful. Users will also learn from recommendations that your model has previously
    given and apply them unprompted to future inputs, which makes the precision of
    these recommendations even more important.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在给出建议时，错误的成本非常高，所以精确度是最有用的。用户还会从你的模型先前给出的建议中学习，并在未来的输入中自动应用这些建议，这使得这些建议的精确度变得更加重要。
- en: In addition, since we surface different factors, we measure whether users actually
    take advantage of them. If not, we should understand why not. A practical example
    is our “active to passive ratio” feature, which was underutilized. We realized
    that this was because of the recommendation not being actionable enough, so we
    improved it by highlighting the words themselves that we recommend changing.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，因为我们展示了不同的因素，我们要衡量用户是否真正利用了它们。如果没有，我们就要了解为什么。一个实际的例子是我们的“主动到被动比率”特征，它被低估了。我们意识到这是因为建议不够具体可行，所以我们通过突出显示推荐更改的具体单词来改进它。
- en: 'Q: *How do you find new ways to guide your users or new features?*'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: *你如何找到新的指导用户或新特性的方法？*'
- en: 'A: Both top-down and bottom-up approaches are valuable.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 自上而下和自下而上的方法都是有价值的。'
- en: Top-down hypothesis investigation is domain knowledge-driven and basically consists
    of feature matching from prior experience. This can come from product or sales
    teams, for example. A top-down hypothesis may look like “we believe that there
    is something about the mystery aspect of recruiting emails that helps drive engagement.”
    The challenge in top-down is usually to find a practical way to extract that feature.
    Only then can we validate whether the feature is predictive.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 自顶向下的假设调查是基于领域知识驱动的，基本上是通过先前经验的特征匹配来进行的。例如，这可能来自产品或销售团队。自顶向下的假设可能是“我们认为招聘邮件中神秘方面有助于提高参与度。”
    自顶向下的挑战通常在于找到一种实用的方法来提取该特征。只有这样，我们才能验证该特征是否具有预测性。
- en: Bottom-up aims to introspect a classification pipeline to understand what it
    finds predictive. If we have a general representation of text such as word vectors,
    tokens, and parts of speech annotations that we then feed to ensembles of models
    to classify as good or bad text, which features are most predictive of our classification?
    Domain experts will often be the best equipped to identify these patterns from
    a model’s predictions. The challenge is then to find a way to make these features
    human understandable.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 自下而上的目标是审视分类管道以理解其发现预测性的方法。如果我们有文本的一般表示形式，如词向量、标记和词性标注，然后将其提供给多模型集合以分类好或坏的文本，哪些特征最能预测我们的分类？领域专家通常是最适合从模型预测中识别这些模式的人。难点在于找到一种使这些特征人类可理解的方法。
- en: 'Q: *How do you decide when a model is good enough?*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: *如何确定一个模型是否足够好？*'
- en: 'A: You shouldn’t underestimate how far a small text dataset of relevant language
    gets you. It turns out that using only a thousand documents in your domain is
    enough for many use cases. Having an ability to label that small set of data is
    worthwhile. You can then start by testing your model on out-of-sample data.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 您不应低估相关语言的小文本数据集能为您带来多大进展。事实证明，在许多用例中，仅使用域内的一千份文档就足够了。有能力对这小部分数据集进行标记是值得的。然后，您可以开始在样本外数据上测试您的模型。'
- en: You should make it easy to run experiments. An overwhelming majority of the
    ideas you have about changing your product end up having a net effect that is
    null, which should allow you to be a little less worried about new features.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该简化运行实验的流程。您对于改变产品的大多数想法最终都会产生零效果，这应该使您对于新功能稍微少担心一些。
- en: Finally, building a bad model is fine and is what you should start with. Fixing
    the bad models will make your product much more robust to problems and help it
    evolve faster.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，建立一个糟糕的模型是可以接受的，并且这是您应该开始的。修复糟糕的模型将使您的产品更加稳健，并帮助其更快地发展。
- en: 'Q: *How do you see how a model is doing once it is in production?*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: *一旦模型投入使用，如何确定其表现如何？*'
- en: 'A: When in production, expose your model’s predictions to users clearly and
    let them override it. Log feature values, predictions, and overwrites so that
    you can monitor them and analyze them later. If your model produces a score, finding
    ways to compare this score to usage of your recommendations can be an additional
    signal. If you are predicting whether an email will be opened, for example, it
    can be extremely valuable to get access to the ground truth data from your users
    so you can improve your model.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 在生产环境中，明确向用户展示您的模型预测，并允许他们覆盖它。记录特征值、预测值和覆盖值，以便稍后监控和分析它们。如果您的模型生成分数，找到比较此分数与用户推荐使用情况的方法可能是一个额外的信号。例如，如果您在预测邮件是否会被打开，获取用户的真实数据将非常有价值，因此您可以改进您的模型。'
- en: The ultimate success metric is customer success, which is the most delayed and
    is influenced by many other factors.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的成功指标是客户的成功，这是最为延迟的，并且受到许多其他因素的影响。
- en: Conclusion
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We started by covering concerns with using and storing data. Then, we dove into
    causes of bias in datasets and tips to identify and reduce them. Next, we looked
    at the challenges that models face in the wild and how to reduce the risks associated
    with exposing them to users. Finally, we looked at how to architect systems so
    that they are designed to be resilient to errors.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先讨论了使用和存储数据时的关注点。然后，我们深入探讨了数据集中偏见的原因以及识别和减少它们的技巧。接下来，我们看了模型在实际应用中面临的挑战，以及如何减少将其暴露给用户所带来的风险。最后，我们研究了如何设计系统，使其能够对错误具有弹性。
- en: These are complex issues, and the field of ML still has much to do to tackle
    all potential forms of abuse. The first step is for all practitioners to be aware
    of these concerns and to be mindful of them in their own projects.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是复杂的问题，机器学习领域仍然有很多工作要做，以解决所有可能的滥用形式。第一步是让所有从业者意识到这些问题，并在他们自己的项目中注意这些问题。
- en: We are now ready to deploy models. To start, we will explore the trade-offs
    between different deployment options in [Chapter 9](ch09.html#deploying). Then,
    we will cover methods to mitigate some of the risks associated with deploying
    models in [Chapter 10](ch10.html#model_engineering).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备部署模型。首先，我们将在[第 9 章](ch09.html#deploying)中探讨不同部署选项之间的权衡。然后，我们将介绍一些减少部署模型风险的方法，在[第
    10 章](ch10.html#model_engineering)中。
