- en: 'Chapter 5\. Automated Testing: Move Fast Without Breaking Things'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章 自动化测试：快速迭代而不破坏
- en: '*Dana has just sat down at her desk, the aroma of fresh coffee filling the
    space around her. She and a junior data scientist on the team continued on the
    user story that they kicked off yesterday—engineering a new feature that could
    improve the model.*'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*Dana 刚刚坐在她的桌子前，新鲜咖啡的香气弥漫在她周围。她和团队中的一位初级数据科学家继续进行昨天启动的用户故事——设计一个能够改进模型的新功能。*'
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*They made the necessary changes and executed a command to run the tests. This
    suite of tests helped validate that the entire codebase was still behaving as
    expected. After 20 seconds, their terminal showed dashes of green—all the tests
    passed.*'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*他们做出了必要的更改，并执行了运行测试的命令。这套测试帮助验证整个代码库仍然如预期般运行。20 秒后，他们的终端显示了绿色的标志——所有测试都通过了。*'
- en: ''
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Sometimes the terminal went red. Some tests failed, but that’s OK—the failing
    tests caught them as they were about to fall into a deep rabbit hole, helping
    them recover easily by tracing a few steps backward. The tests are now back to
    green and they gave it another go.*'
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*有时终端显示红色。有些测试失败了，但没关系——失败的测试帮助他们在深陷困境之前发现问题，并通过追溯几步轻松恢复。现在测试又恢复到了绿色，他们又重新尝试了一次。*'
- en: ''
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Green or red, the tests gave them fast feedback on code changes. The tests
    gave them confidence and the occasional dopamine hit to tell them if they were
    going in the right direction or stop them when they went in the wrong direction.
    They didn’t have to follow a tedious sequence of manual steps to test the code.
    When the tests failed, there were only a small number of changes that could have
    caused the failure, not hours of potential suspects to sort through.*'
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*无论是绿色还是红色，这些测试都能快速反馈代码更改的情况。测试给了他们信心，有时还能让他们兴奋不已，告诉他们是否朝着正确的方向前进，或者在错误方向上停下来。他们不必跟随繁琐的手动步骤来测试代码。当测试失败时，可能导致失败的变更只有少数几个，而不是数小时的潜在嫌疑人供他们筛选。*'
- en: ''
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*When they needed to train the model, they ran a command that triggered training
    on the cloud and their experiment-tracking dashboard lit up with updated metrics
    and explainability visualizations, which signaled whether they were on the right
    track. They iterated with steady steps, making reasonably sized git commits and
    pushes—which triggered automated model tests on the CI pipeline—along the way
    until the story was done.*'
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*当他们需要训练模型时，他们运行了一个命令，在云端触发了训练，并且他们的实验追踪仪表板上更新了指标和可解释性可视化，这些都是信号，告诉他们是否走在了正确的道路上。他们稳步迭代，做出了合理大小的
    git 提交和推送——这些触发了 CI 流水线上的自动化模型测试——直到故事完成。*'
- en: ''
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Their cognitive load remained manageable. They retained clarity on what they
    needed to do and completed their work one steady step at a time.*'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*他们的认知负荷保持在可控范围内。他们清楚地知道自己需要做什么，并且一步步完成工作。*'
- en: We often find that ML products and systems tend to be under-tested. The lack
    of automated tests is one of the most common types of technical debt, which forces
    ML practitioners to pay interest every time they want to make a change. Without
    automated tests, ML practitioners waste copious amounts of time on manual testing
    or resolving production incidents due to errors that slipped through the cracks
    of manual testing. Not only does this reduce our capacity for valuable work, we
    also leave the door open for bugs, errors, and underperforming models to flow
    into the hands of users in the real world. Such product defects could sink months,
    and even years, of effort in building an ML product and can bring significant
    [reputational and financial costs for an organization](https://oreil.ly/1y076).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常发现，机器学习产品和系统往往测试不足。缺乏自动化测试是技术债务中最常见的一种类型，这迫使机器学习从业者每次想要进行更改时都要付出代价。没有自动化测试，机器学习从业者会在手动测试或解决由手动测试中未能发现的错误导致的生产事故上浪费大量时间。这不仅减少了我们进行有价值工作的能力，还让缺陷、错误和性能不佳的模型流入真实用户的手中。这些产品缺陷可能会摧毁数月甚至数年的机器学习产品建设工作，并给组织带来显著的
    [声誉和财务成本](https://oreil.ly/1y076)。
- en: That said, testing is not new to ML practitioners—in fact, we do it all the
    time. But we often do it manually rather than through automated means. If you
    find yourself spending more time than you’d like on manually testing the quality
    of your models or code changes, this chapter is for you. We’ll share practical
    techniques for creating comprehensive automated tests for your ML solutions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，对于机器学习实践者来说，测试并不是什么新鲜事物——事实上，我们经常进行测试。但我们通常是手动进行测试，而不是通过自动化手段。如果你发现自己花在手动测试模型或代码变更质量上的时间比预期多，那么这一章就是为你准备的。我们将分享创建全面自动化测试的实用技术，帮助你的机器学习解决方案。
- en: 'In this chapter, we’ll detail:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将详细说明：
- en: The challenges and unscalable costs of manual testing, especially in ML systems
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动测试的挑战和不可扩展成本，特别是在机器学习系统中。
- en: The benefits of automated testing and how it can help ML practitioners create
    reliable and maintainable systems
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化测试的好处及其如何帮助机器学习从业者创建可靠和易于维护的系统。
- en: 'The building blocks of a comprehensive automated testing strategy, grouped
    into two categories: software tests and model tests'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全面自动化测试策略的构建模块分为两类：软件测试和模型测试。
- en: 'This chapter will focus on the “why” and the “what” of automated tests (e.g.,
    What tests should we write? What does a good test look like?). This will give
    you a high-level mental framework to organize the details of each component of
    a test strategy. We’ll then dive into the “how” for the first category: software
    tests.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点讨论自动化测试的“为什么”和“什么”（例如，我们应该编写哪些测试？一个好的测试看起来如何？）。这将为你提供一个高层次的思维框架，以组织测试策略的每个组成部分的详细信息。然后，我们将深入讨论第一类别的“如何”：软件测试。
- en: 'In the next chapter, we will explore:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨：
- en: 'ML model tests: the challenges, necessity, and methods of automated testing
    for ML models'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型测试：自动化测试的挑战、必要性和方法。
- en: Techniques for testing large language model (LLM) applications
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试大型语言模型（LLM）应用程序的技术。
- en: 'Using model tests as: (i) a cost-effective way to ensure code, data, and model
    changes do not degrade the product experience; and (ii) a “ratcheting” mechanism
    that lets us set new performance benchmarks without compromising established standards'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用模型测试作为：(i) 一种成本效益的方式，确保代码、数据和模型变更不会降低产品体验；以及 (ii) 一种“梯步提升”的机制，使我们能够设定新的性能基准，而不会影响已建立的标准。
- en: To make these two chapters useful to as many readers as possible, we will assume
    that readers have the desire but not necessarily the experience to write these
    tests. You can skip sections for tests that you’re already familiar with, and
    pore through sections that are new to you.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这两章尽可能对尽可能多的读者有用，我们假设读者有意愿但不一定有经验来编写这些测试。你可以跳过你已经熟悉的测试部分，然后详细阅读对你新的部分。
- en: We’ll illustrate each type of test using hands-on examples in the [code-along
    repository](https://oreil.ly/Hkgzc), which you can clone to read, run, and write
    tests. This is the same repository that we used in the previous chapter and you
    can find the same setup steps in the README or in [Chapter 4](ch04.html#effective_dependency_management_in_prac).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用实际示例来说明每种类型的测试，这些示例可以在[代码克隆存储库](https://oreil.ly/Hkgzc)中进行操作，你可以克隆它来阅读、运行和编写测试。这与我们在前一章中使用的存储库相同，你可以在
    README 或[第四章](ch04.html#effective_dependency_management_in_prac)中找到相同的设置步骤。
- en: 'Automated Tests: The Foundation for Iterating Quickly and Reliably'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化测试：快速和可靠迭代的基础。
- en: Automated tests are the essential foundation for products that are easy to maintain
    and evolve. Tests give us fast feedback on changes and allow us to rapidly respond
    to changes imposed on our product, such as changes in training data, feature engineering
    strategies, modeling approaches, and business requirements.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化测试是易于维护和演进产品的基础。测试可以快速反馈变更，并使我们能够迅速应对对产品施加的变更，如训练数据的变化、特征工程策略、建模方法和业务需求的变化。
- en: Without automated tests, changes become error-prone, tedious, and stressful.
    When we change one part of the codebase, the lack of tests forces us to take on
    the burden of manually testing the *entire* system to ensure that a change (e.g.,
    in feature engineering logic) hasn’t caused a degradation (e.g., in model quality).
    As illustrated in [Figure 5-1](#automated_tests_help_us_manage_and_tame), as the
    size of the codebase grows, not only do we have to take on the quality assurance
    effort of the new features being developed, but also the burden of manual regression
    testing on the entire solution.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 没有自动化测试，变更会变得容易出错、繁琐和紧张。当我们改变代码库的某一部分时，缺乏测试会迫使我们承担手动测试*整个*系统的负担，以确保变更（例如特征工程逻辑的变更）没有导致降级（例如模型质量的降低）。正如[图5-1](#automated_tests_help_us_manage_and_tame)所示，随着代码库的规模增长，我们不仅需要承担正在开发的新功能的质量保证工作，还需要承担整个解决方案的手动回归测试负担。
- en: '![](assets/emlt_0501.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/emlt_0501.png)'
- en: Figure 5-1\. Without automated tests, the effort required for quality assurance
    grows quadratically, as compared to a more manageable linear growth in effort
    afforded by automated tests
  id: totrans-29
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1。没有自动化测试，质量保证所需的工作量会呈二次增长，而自动化测试可以使工作量增长更可控。
- en: In this section, we’ll detail the benefits of automated tests and explain why
    continuous integration and continuous delivery (CI/CD) without tests is a contradiction
    in terms. We’ll also discuss why, in our opinion, ML projects tend to be under-tested
    and what we can do about it.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将详细说明自动化测试的好处，并解释为什么没有测试的持续集成和持续交付（CI/CD）是一个悖论。我们还将讨论为什么在我们看来，ML项目往往被低估测试，以及我们可以采取的措施。
- en: Note
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Later in this chapter, we will dissect tests into two categories: software
    tests and ML model tests. While practitioners are typically familiar with how
    to automate software tests, the uncertain and complex nature—especially in early
    and exploratory phases—of building an ML solution means that it can sometimes
    be hard to define automated tests for our ML models from the get-go.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章后面，我们将把测试分为两类：软件测试和ML模型测试。虽然从业者通常熟悉如何自动化软件测试，但在早期和探索性阶段尤其是在构建ML解决方案时，由于其不确定性和复杂性，有时很难一开始就为我们的ML模型定义自动化测试。
- en: Trying to test such unknown unknowns up front can introduce unnecessary friction.
    In these scenarios, you can start by using exploratory testing and visualization
    as stepping stones toward formulating heuristics about model quality that you
    can use in automated model tests. We’ll discuss this in greater detail in [Chapter 6](ch06.html#automated_testing_ml_model_tests).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 试图从一开始测试这些未知的未知因素可能会引入不必要的摩擦。在这些情况下，您可以开始使用探索性测试和可视化作为制定关于模型质量的启发式方法的垫脚石，这些方法可以在自动化模型测试中使用。我们将在[第6章](ch06.html#automated_testing_ml_model_tests)中更详细地讨论这一点。
- en: 'Starting with Why: Benefits of Test Automation'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从为什么开始：测试自动化的好处
- en: In this section, we’ll detail the benefits of test automation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将详细说明测试自动化的好处。
- en: 'Not only do tests benefit consumers of the ML system through automated quality
    assurance, they also provide fast and essential feedback to creators of the ML
    system during development. By “fast,” we are talking about a night-and-day difference:
    A comprehensive set of tests can shorten feedback cycles by several orders of
    magnitude—from tens of minutes to seconds, from hours to minutes. For some who
    are accustomed to running models overnight, this night-and-day difference becomes
    quite literal on some occasions—you don’t have to wait a night and a day only
    to discover that there was a mistake in your code change.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 测试不仅通过自动化质量保证使ML系统的使用者受益，而且在开发过程中为ML系统的创建者提供快速和重要的反馈。所谓“快速”，我们指的是昼夜之间的差异：一套全面的测试可以将反馈周期缩短数个数量级，从几十分钟到几秒钟，从几小时到几分钟。对于习惯于过夜运行模型的人来说，在某些情况下，这种昼夜之间的差异在某些时候变得非常明显——你不必等待一个昼夜，才发现你的代码更改中存在错误。
- en: Let’s look at a scenario to illustrate the mechanical benefits of having comprehensive
    automated tests. Remember our properly caffeinated protagonist at the start of
    this chapter? Each code change or data change that they make goes through a series
    of automated quality checks (see [Figure 5-2](#a_series_of_automated_tests_serve_as_qu)).
    Each set of tests specifies a set of quality standards that the team has defined
    for a given aspect of the software. For example, you can assert that the model
    metric for each key segment of the data remains above a current threshold (we
    have more examples of model tests in [Chapter 6](ch06.html#automated_testing_ml_model_tests)).
    When all the tests pass, you can be confident that the model and associated components
    are *as good as before* or *better than before* and can be released to production.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个场景来说明具有全面自动化测试的机械化优势。还记得我们在本章开头提到的充分饮用咖啡的主角吗？他们进行的每一次代码更改或数据更改都要经过一系列自动化质量检查（参见[图 5-2](#a_series_of_automated_tests_serve_as_qu)）。每一组测试都规定了团队为软件的特定方面定义的一套质量标准。例如，您可以断言数据每个关键段的模型度量仍高于当前阈值（我们在[第六章](ch06.html#automated_testing_ml_model_tests)有更多模型测试的例子）。当所有测试通过时，您可以确信模型及其相关组件与*以前一样好*甚至*比以前更好*，可以发布到生产环境中。
- en: '![](assets/emlt_0502.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/emlt_0502.png)'
- en: Figure 5-2\. A series of automated tests serve as quality gates that validate
    if changes produce an artifact that is fit for production
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-2\. 一系列自动化测试作为质量门，验证变更是否生成适合生产的产物
- en: In contrast, if any change violates the quality standards that you have defined
    for your ML product, the tests that are run locally or on your CI pipeline will
    catch that regression. The tests give us fast feedback (on the order of minutes
    or even seconds) and tell us that there are issues with the change, rather than
    leaving us to discover these issues much later through manual testing or customer
    complaints. One more production incident avoided, thanks to our tests. This may
    sound like a dream, but in this chapter and the next we’ll demonstrate how you
    can make it a reality.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，如果任何变更违反了您为ML产品定义的质量标准，本地或CI流水线运行的测试将捕捉到这种回归。测试为我们提供了快速反馈（大约在几分钟或甚至几秒钟内），告诉我们变更存在问题，而不是留待我们通过手动测试或客户投诉在更晚的时候发现这些问题。感谢我们的测试，又避免了一次生产事故。这听起来可能像是一个梦想，但在本章和下一章中，我们将演示如何使其成为现实。
- en: 'If you’re still not convinced about why you should be automating your tests,
    here’s a list of key benefits of test automation:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您仍不确定为什么应该自动化您的测试，这里列出了测试自动化的关键好处：
- en: Fast feedback
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 快速反馈
- en: For every code change, even if it’s just one line or across multiple files,
    you can run one command and test if everything is working within seconds or a
    few minutes at most. This is in contrast to manual testing, which is tedious and
    can take up to hours and even days.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一次代码更改，即使只是一行代码或跨多个文件，您也可以运行一个命令，并在几秒钟或最多几分钟内测试一切是否正常运行。这与手动测试形成对比，手动测试是繁琐的，可能需要数小时甚至数天。
- en: Reduced risk of production defects
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 减少生产缺陷的风险
- en: When your test coverage is high, your tests can catch any accidental bugs and
    regressions introduced before they get to production—in test environments or even
    *while* you are coding. This saves you and your team from the effort and stress
    of fighting fires in production.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当测试覆盖率较高时，您的测试可以捕捉到任何在进入生产环境之前引入的意外错误和回归。这节省了您和您的团队在生产环境中应对问题时的努力和压力。
- en: Living documentation and self-testing code
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 活的文档和自我测试代码
- en: All functionality is accompanied by tests that describe what the component does
    and what scenarios or edge cases it can handle. If we ever need to change a component’s
    behavior, we will also update the tests. As a result, documentation is cohesive
    and colocated with the actual code, in contrast to documentation pages, which
    can become stale and inconsistent from the code that it describes.^([1](ch05.html#ch01fn25))
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 所有功能均伴有描述组件功能及其能处理的场景或边缘情况的测试。如果我们需要更改组件的行为，我们也会更新测试。因此，文档与实际代码是一体的，与描述代码的文档页面形成鲜明对比，后者可能会过时且不一致。^([1](ch05.html#ch01fn25))
- en: Reduced cognitive load
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 减少认知负荷
- en: Tests help you focus on the task at hand by systematically verifying that each
    part of the solution still works as expected, thereby allowing you to concentrate
    on a specific aspect of the problem without constantly worrying about unintended
    consequences in other areas. In addition, if the problem you’re solving consists
    of many subproblems, writing tests helps you focus on one subproblem at a time,
    which presents a much lower cognitive load than trying to solve them all at once.
    Tests also nudge us to create modular components and well-defined interfaces.
    We tend to end up with software architectures that are easier to reason about
    and easier to refactor.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 测试通过系统验证解决方案的每个部分仍然按预期工作，有助于您专注于问题的特定方面，而无需不断担心其他领域的意外后果。此外，如果您解决的问题由许多子问题组成，编写测试有助于您一次专注于一个子问题，这比尝试同时解决所有问题的认知负荷要小得多。测试还促使我们创建模块化组件和明确定义的接口。我们往往会得到更易于理解和重构的软件架构。
- en: Refactoring
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 重构
- en: Refactoring is an essential habit of effective teams because it helps them regularly
    reduce technical debt and complexity, but without tests, refactoring is highly
    risky. Often, this leads teams to follow the path of least resistance—i.e., not
    refactoring—and the codebase becomes increasingly convoluted. As a result, executing
    on our ideas becomes harder and slower over time.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 重构是有效团队的重要习惯，因为它有助于团队定期减少技术债务和复杂性，但没有测试的情况下，重构是非常高风险的。这往往导致团队选择最小阻力路径——即不进行重构——而代码库变得越来越混乱。结果是，随着时间的推移，执行我们的想法变得更加困难和缓慢。
- en: On the other hand, the safety harness of comprehensive tests makes it easy for
    us to make a change, validate the change, and regularly reduce technical debt
    as we deliver new features. In [Chapter 8](ch08.html#refactoring_and_technical_debt_manageme),
    we’ll share a story of how we completed a major refactoring in one of our projects
    in an hour because our entire ML system had high test coverage—unit tests, integration
    tests, and model quality tests. When the refactoring was done, all the tests passed,
    we committed our changes, all the tests on the CI pipeline passed, and the change
    was deployed to production with no drama.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，全面测试的安全保护带来的便利性使我们能够进行更改、验证更改，并在交付新功能时定期减少技术债务。在[第8章](ch08.html#refactoring_and_technical_debt_manageme)中，我们将分享一个故事，讲述我们如何在一个小时内完成了我们项目的一次重大重构，因为我们整个ML系统都有高测试覆盖率——单元测试、集成测试和模型质量测试。重构完成后，所有测试都通过了，我们提交了变更，CI管道上的所有测试都通过了，变更已部署到生产环境，没有任何戏剧性事件发生。
- en: Regulatory compliance
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 规范合规性
- en: The regulatory standards of most industries will typically have an aspect on
    quality assurance and model validation before models are released for consumption
    in production. For example, the [European Commission has said](https://oreil.ly/lWJTL),
    the “testing of and experimenting with AI products and services is crucial to
    make them market-ready, ensure compliance with safety standards and rules as well
    as security by design [...].”
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数行业的监管标准通常在模型投放生产前会有质量保证和模型验证的要求。例如，[欧洲委员会表示](https://oreil.ly/lWJTL)，“对AI产品和服务进行测试和实验对于使其市场就绪、确保符合安全标准和规则以及安全设计至关重要[...]。”
- en: While regulatory bodies don’t always mandate that these tests be automated,
    automating them can make it much easier for us to demonstrate our compliance.
    Rather than scrambling at the eleventh hour during regulatory audits, you can
    instead test your ML products with the tools and techniques that are available
    to you today to ensure that your ML products are of an acceptable quality for
    your users.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管监管机构并不总是要求这些测试自动化，但自动化测试可以使我们更容易展示合规性。与在监管审核的最后一刻慌乱相比，您可以利用今天可用的工具和技术测试您的ML产品，以确保您的ML产品对用户的质量是可以接受的。
- en: Improved flow, productivity, and satisfaction
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 改进流程、提升生产力和满意度
- en: All the preceding benefits help ML practitioners reduce friction, burdensome
    work, and unnecessary cognitive load. Taken together, automated tests help teams
    to enjoy fast feedback, reduced production defects, continuous improvements, and
    this all helps to contribute to flow, productivity, and satisfaction.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 所有前述的好处帮助ML从业者减少摩擦、繁重的工作和不必要的认知负荷。总体而言，自动化测试帮助团队享受快速反馈、减少生产缺陷、持续改进，这些都有助于促进流程、提升生产力和满意度。
- en: Note
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: While our tests during model development aim to cover all anticipated production
    scenarios, the dynamic nature of real-world data ensures there will always be
    surprises. That is why operational monitoring in production is an aspect of a
    holistic test strategy. It enables teams to detect and address any deviations
    or anomalies that arise from shifts in production data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进行模型开发期间的测试时，我们的目标是涵盖所有预期的生产场景，但现实世界数据的动态性确保总会有意外情况发生。这就是为什么在生产中进行操作监控是全面测试策略的一部分的原因。它使团队能够检测并解决由于生产数据变动而产生的任何偏差或异常。
- en: We’ll discuss monitoring ML systems in production in the next chapter.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章中我们将讨论在生产环境中监控机器学习系统。
- en: Now that you understand the benefits of automated tests, let’s look at some
    common reasons why ML systems often lack automated tests.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了自动化测试的好处，让我们看看机器学习系统经常缺乏自动化测试的一些常见原因。
- en: If Automated Testing Is So Important, Why Aren’t We Doing It?
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果自动化测试如此重要，为什么我们还没有进行呢？
- en: In this section, we’ll look at the three common reasons for why ML systems often
    lack automated tests.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论为什么机器学习系统经常缺乏自动化测试的三个常见原因。
- en: 'Reason 1: We think writing automated tests slows us down'
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原因 1：我们认为编写自动化测试会减慢开发速度
- en: The idea that writing automated tests slows us down claims, Why waste time writing
    tests when we could just write the code and implement the feature? This reasoning
    stems partly from the [well-traveled road bias](https://oreil.ly/ELRA8)—the tendency
    to underestimate the duration taken to traverse oft-traveled routes and overestimate
    the duration taken to traverse less familiar routes.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 认为编写自动化测试会减慢我们的速度的观点声称：为什么要浪费时间写测试，当我们可以直接编写代码并实现功能呢？这种推理在一定程度上源于[熟道误判](https://oreil.ly/ELRA8)——低估经常走的路线所需的时间，高估不熟悉的路线所需的时间。
- en: From our experience across multiple ML and software projects, we’ve observed
    that the lack of automated tests *always* leads teams to spend *more time* in
    manually testing the code (see [Figure 5-3](#counterintuition_writing_automated_test)).
    On the other hand, in projects with comprehensive automated tests, ML practitioners
    could work more effectively because the automated tests freed them up from manual
    regression testing and from resolving production defects that accidentally slipped
    through the cracks of manual testing.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们在多个机器学习和软件项目中的经验，我们观察到缺乏自动化测试总是导致团队在手动测试代码时花费更多时间（参见[图 5-3](#counterintuition_writing_automated_test)）。另一方面，在具有全面自动化测试的项目中，机器学习从业者可以更有效地工作，因为自动化测试使他们免于手动回归测试和解决由于手动测试中不小心遗漏的生产缺陷带来的问题。
- en: '![](assets/emlt_0503.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/emlt_0503.png)'
- en: 'Figure 5-3\. Counterintuition: writing automated tests appears to cost more
    time but in practice saves us time overall'
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-3\. 反直觉：编写自动化测试似乎会花费更多时间，但实际上节省了总体时间
- en: 'Let’s illustrate this with an example. Let’s say we’re developing some feature
    engineering logic that we think will improve our model metric—both global and
    stratified metrics—by X%. Automated tests help us save time in three horizons:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举个例子来说明这一点。假设我们正在开发一些特征工程逻辑，我们认为这些逻辑将改善我们的模型度量指标（包括全局和分层度量指标）达到 X%。自动化测试帮助我们在三个时间段内节省时间：
- en: During development
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发过程中
- en: As we are developing, we also write a test specifying the new metric threshold
    that we expect. We run the tests with a single command and iterate on our feature
    engineering logic until the test passes (and we could also write other tests for
    other smaller subproblems along the way). We save time and effort from repeatedly
    parsing global model metrics or stratified model metrics from notebooks or print
    statements buried in logs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发过程中，我们还编写了一个测试，指定了我们期望的新度量阈值。我们用一个命令运行测试，并迭代我们的特征工程逻辑，直到测试通过（在此过程中，我们还可以为其他较小的子问题编写其他测试）。这样一来，我们就可以节省时间和精力，不必反复解析全局模型度量或分层模型度量，而是从笔记本或日志中深藏的打印语句中找到结果。
- en: After development
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 开发完成后
- en: When we complete a user story,^([2](ch05.html#ch01fn26)) our team is confident
    that the new logic did what it’s supposed to do (improve the model by X%) by looking
    at the passing tests. This removes the need for another teammate to repeat manual
    testing procedures, which frees them up to test for edge cases, missing data,
    and other scenarios that we may have missed during development.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们完成一个用户故事^([2](ch05.html#ch01fn26))时，我们的团队确信新逻辑已经达到了预期效果（通过查看通过的测试来提高模型 X%）。这消除了需要另一位团队成员重复手动测试流程的必要性，这使他们能够测试边缘情况、缺失数据以及在开发过程中可能忽略的其他场景。
- en: During subsequent development
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在随后的开发过程中
- en: In the future weeks or months, should any change cause the model to regress
    below the new threshold, the automated tests will catch it. Without this test,
    we either have to spend time manually eyeballing the model’s quality metric *with
    every commit, pull request or release*, or we live with the risk that we may be
    unknowingly degrading the model over time.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来的几周或几个月里，如果任何变更导致模型回归到新的阈值以下，自动化测试将捕捉到这一点。没有这个测试，我们要么必须花时间手动检查每次提交、拉取请求或发布的模型质量指标，要么面临我们可能在时间上不知不觉地降低模型质量的风险。
- en: 'Reason 2: “We have CI/CD”'
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理由二：“我们有CI/CD”
- en: CI/CD has become an increasingly popular term in the ML community, but it tends
    to be misused and misunderstood. In software engineering, continuous integration
    (CI) refers to the ability to *frequently integrate code changes to the main branch*.
    Continuous delivery (CD) refers to the ability to deploy software on the main
    branch *at any moment* to production (see detailed definition and discussion on
    CI/CD in [Chapter 9](ch09.html#mlops_and_continuous_delivery_for_ml_le)). Both
    of these can be done *only when* we have comprehensive automated tests that give
    us feedback and confidence about the quality of the code changes. By this standard,
    we haven’t seen many ML teams actually practice CI/CD.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: CI/CD已经成为机器学习社区中越来越流行的术语，但它往往被误用和误解。在软件工程中，持续集成（CI）指的是频繁地集成代码变更到主分支的能力。持续交付（CD）指的是能够在任何时刻将软件部署到主分支上到生产环境（详见第9章关于CI/CD的详细定义和讨论）。只有当我们有全面的自动化测试来给我们关于代码变更质量的反馈和信心时，这两者才能实现。按照这个标准，我们并没有看到很多机器学习团队实际上在实践CI/CD。
- en: 'Just because teams have a CI pipeline and automated deployments doesn’t mean
    they’re doing CI/CD. The contents of the CI/CD pipelines matter: What tests do
    we actually run on the CI/CD pipeline? What tests do we run to give us confidence
    that we’re releasing high-quality models? What is the test coverage on our CI/CD
    pipelines?'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅因为团队拥有CI流水线和自动化部署，并不意味着他们正在进行CI/CD。CI/CD流水线的内容很重要：我们实际在CI/CD流水线上运行了哪些测试？我们运行了哪些测试来确保我们发布了高质量的模型？我们的CI/CD流水线的测试覆盖率是多少？
- en: '*Talking about CI/CD without comprehensive automated tests is a contradiction
    in terms—*a group of words associating incompatible objects or ideas—and gives
    us a false sense of security. The CI pipeline might be all green but without comprehensive
    tests we can still be releasing defects into production. In this scenario, the
    CI pipeline helps us faithfully release defects rather than discovering and remediating
    them in development. If we want to actually enjoy the benefits of CI/CD (detailed
    in [Chapter 9](ch09.html#mlops_and_continuous_delivery_for_ml_le)), we need comprehensive
    automated tests.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*在没有全面自动化测试的情况下谈论CI/CD，这是一种自相矛盾*—这是一组词语，将不兼容的对象或思想联系在一起—并且给我们一种虚假的安全感。虽然CI流水线可能全部绿灯，但如果没有全面的测试，我们仍然可能会发布缺陷到生产环境中。在这种情况下，CI流水线帮助我们忠实地发布缺陷，而不是在开发过程中发现并修复它们。如果我们真的想享受CI/CD的好处（详细内容见[第9章](ch09.html#mlops_and_continuous_delivery_for_ml_le)），我们需要全面的自动化测试。'
- en: There is perhaps a sociocultural origin to the predicament we find ourselves
    in. On one hand, ML engineers tend to focus on MLOps and DevOps, which are traditionally
    focused on deployment automation, infrastructure-as-code, and CI/CD. On the other
    hand, data scientists tend to focus on training and evaluating ML models. While
    the two worlds have collided, there remains a competency gap between ML engineers
    (automation) and data scientists (model evaluation) in many teams. We know how
    to set up CI pipelines and we know how to train and evaluate models, but not all
    teams have worked out how to bridge both practices to automate manual model evaluation
    procedures. This leads us to our next point.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所面临的困境或许有一个社会文化起源。一方面，机器学习工程师倾向于专注于MLOps和DevOps，这些传统上专注于部署自动化、基础设施即代码和CI/CD。另一方面，数据科学家倾向于专注于训练和评估机器学习模型。虽然这两个世界已经碰撞，但在许多团队中，机器学习工程师（自动化）和数据科学家（模型评估）之间仍然存在能力差距。我们知道如何设置CI流水线，也知道如何训练和评估模型，但并不是所有团队都弄清楚如何跨越这两种实践以自动化手动模型评估程序。这引出了我们的下一个观点。
- en: 'Reason 3: We just don’t know how to test ML systems'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理由三：我们不知道如何测试机器学习系统
- en: From our interaction with ML practitioners across various industries, we know
    many of them are open to writing automated tests. While automated testing was
    new to them, some of them eventually came to see its value and write tests as
    part of their work. The main reason for not writing tests was simply that they
    didn’t know how to or weren’t taught how to.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 通过与各行业的ML从业者互动，我们知道许多人愿意编写自动化测试。虽然自动化测试对他们来说是新鲜事物，但一些人最终认识到其价值，并将测试作为其工作的一部分。不编写测试的主要原因简单地是他们不知道如何或者没有人教他们如何。
- en: In the seminal [“ML Test Score” paper](https://oreil.ly/hGTTh), the authors
    rightly pointed out that ML system testing can be more challenging than manually
    coded system testing because ML system behavior can depend strongly on data, and
    models that cannot be strongly specified *a priori*. (In the paper, they then
    go on to lay out a rubric on how ML systems can be tested and monitored.)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在开创性的[“ML测试分数”论文](https://oreil.ly/hGTTh)中，作者正确地指出，与手动编码系统测试相比，ML系统测试可能更具挑战性，因为ML系统的行为可能强烈依赖数据，并且无法在先验上强制指定模型。（在论文中，他们接着提出了一个关于如何测试和监控ML系统的评分表。）
- en: Since the time of that paper, patterns for testing specific components in an
    ML solution have been emerging. We’ve begun to disambiguate parts of an ML system
    (e.g., feature engineering, data processing, model serving) and identified corresponding
    test strategies for various subjects under test.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 自那篇论文以来，针对ML解决方案中特定组件的测试模式逐渐显现。我们已经开始消除ML系统的各部分（例如特征工程、数据处理、模型服务）的歧义，并为不同的测试对象确定了相应的测试策略。
- en: That puts us in a good place because we want to write better tests, and we know
    that there are ways for us to formulate the appropriate types of tests. The only
    thing stopping us is knowing what types of tests we can write, and how we can
    write them. For that, let’s turn to the next section.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我们处于一个很好的位置，因为我们想要编写更好的测试，我们知道有方法可以制定适当的测试类型。唯一阻止我们的是知道我们可以编写哪些类型的测试，以及如何编写它们。因此，让我们转向下一节。
- en: Building Blocks for a Comprehensive Test Strategy for ML Systems
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML系统全面测试策略的构建基块
- en: Now that you see the importance of automated tests, let’s start to piece together
    what a comprehensive test strategy could look like. In this section, we start
    by identifying what we should test, before laying out a typology of tests you
    can include in your toolkit. Finally, we’ll describe characteristics of a good
    automated test.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到自动化测试的重要性，让我们开始拼凑一个全面的测试策略看起来像什么。在这一部分中，我们首先确定应该测试什么，然后描述您可以包含在工具包中的测试类型的分类。最后，我们将描述一个好的自动化测试的特征。
- en: 'The What: Identifying Components For Testing'
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定测试组件
- en: The first step in building a comprehensive test strategy is to identify what
    we need to test. [Table 5-1](#types_of_automated_tests_for_ml_systems) details
    the typical components that we’d find in an ML system—e.g., model training pipeline,
    API service, and feature engineering logic. If you find that your ML product contains
    any of the components in [Table 5-1](#types_of_automated_tests_for_ml_systems),
    each of them can and should be tested. These tests are also depicted in [Figure 5-2](#a_series_of_automated_tests_serve_as_qu)
    to help you contextualize where to use each type of test in an ML model’s path
    to production.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 构建全面测试策略的第一步是确定我们需要测试什么。[表 5-1](#types_of_automated_tests_for_ml_systems)详细描述了我们在ML系统中可能找到的典型组件，例如模型训练管道、API服务和特征工程逻辑。如果您发现您的ML产品包含[表 5-1](#types_of_automated_tests_for_ml_systems)中的任何组件，那么每个组件都可以和应该被测试。这些测试还在[图 5-2](#a_series_of_automated_tests_serve_as_qu)中描述，以帮助您理解在ML模型进入生产过程中的哪个环节使用每种类型的测试。
- en: Table 5-1\. Types of automated tests for ML systems
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 表5-1\. ML系统的自动化测试类型
- en: '| Component, or subject under test (SUT) | Type of test | What good looks like
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 组件或测试对象（SUT） | 测试类型 | 优秀的表现 |'
- en: '| --- | --- | --- |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| *Software logic* |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| *软件逻辑* |'
- en: '| Logic, data transformations, feature engineering | Unit tests | Tests enumerate
    scenarios of how we interact with a function or class and specify the correct
    and expected behavior.*Fast-running:* Tens of tests run in seconds; even hundreds
    of tests can run within one to two minutes.Internal “private” functions may not
    need tests if they are tested as part of another function.*Quantity:* Tens to
    hundreds of tests |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 逻辑、数据转换、特征工程 | 单元测试 | 测试列举我们与函数或类交互的场景，并指定正确和预期的行为。*快速运行:* 几十个测试在几秒内运行；甚至数百个测试也能在一到两分钟内完成。如果作为另一个函数的一部分进行了测试，则可能不需要测试“私有”函数。*数量:*
    几十到数百个测试 |'
- en: '| Model training pipeline | Training smoke tests | Tests exercise all code
    paths as a full model training run would.Avoid conditional statements that would
    introduce asymmetry between training smoke tests and actual training runs in production.*Fast-running:*
    Even for an ML pipeline that takes hours to run, training smoke tests should take
    one to two minutes to complete.*Locally runnable:* The ability to run and debug
    the training pipeline locally helps provide fast feedback for troubleshooting
    any pipeline failures.*Quantity:* Typically one or two tests |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 模型训练流水线 | 训练烟雾测试 | 测试涵盖所有代码路径，就像完整的模型训练运行一样。避免引入条件语句，这会导致训练烟雾测试与实际生产中的训练运行不对称。*快速运行:*
    即使是需要数小时运行的 ML 流水线，训练烟雾测试也应在一到两分钟内完成。*可本地运行:* 在本地运行和调试训练流水线有助于快速反馈并排查流水线故障。*数量:*
    通常为一到两个测试 |'
- en: '| Model API | API tests | Tests specify all the scenarios that our model service
    will handle.Tests represent the model service’s contract and guarantee to downstream
    consumers.Tests include happy paths and unhappy paths to demonstrate how the model
    handles error scenarios (e.g., null values, wrong data types).*Locally runnable:*
    As above*Quantity:* Can range from five to tens, depending on the API’s responsibilities
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 模型 API | API 测试 | 测试指定我们的模型服务将处理的所有场景。测试代表模型服务的契约，并保证向下游消费者。测试包括正常路径和异常路径，以演示模型处理错误场景的方式（例如空值、错误的数据类型）。*可本地运行:*
    如上所述*数量:* 可以从五到数十个不等，具体取决于 API 的责任 |'
- en: '| Deployed model API | Post-deployment tests | Tests invoke a model service
    that has just been deployed to a preproduction or production environment.Tests
    do not duplicate scenarios that are already covered by API tests.*Locally runnable:*
    When running the tests against a real service, we should be able to access the
    associated logs to understand the service’s behavior.*Quantity:* Typically one
    or two tests |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 部署的模型 API | 部署后测试 | 测试调用刚部署到预生产或生产环境的模型服务。测试不重复覆盖已由 API 测试覆盖的场景。*可本地运行:*
    在针对真实服务运行测试时，我们应能访问相关日志以了解服务的行为。*数量:* 通常为一到两个测试 |'
- en: '| *ML models* |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| *ML 模型* |'
- en: '| Trained ML model | Metric tests (global and stratified) | Tests evaluate
    the model using a validation dataset.Tests should be extensible and can be run
    with new validation data as they become available, without being coupled to the
    training pipeline (see [“Open-Closed Test Design”](ch06.html#open_closed_test_design)).*Locally
    runnable:* As above*Quantity:* Typically between a few to ten |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 训练后的 ML 模型 | 度量测试（全局和分层） | 测试使用验证数据集评估模型。测试应具有可扩展性，并能够在新的验证数据可用时运行，而不与训练流水线耦合（参见[“开闭式测试设计”](ch06.html#open_closed_test_design)）。*可本地运行:*
    如上所述*数量:* 通常在几个到十个之间 |'
- en: '| Trained ML model | Behavioral tests | Tests enumerate specific—and potentially
    out-of-sample—scenarios and specify the expected behavior for the model.We can
    start with just one or two examples and use data-generation techniques to scale
    to include many examples in a single scenario, if that provides value (more details
    in [Chapter 6](ch06.html#automated_testing_ml_model_tests)).*Quantity:* Typically
    between a few to tens |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 训练后的 ML 模型 | 行为测试 | 测试列举特定的——可能是样本外的——场景，并指定模型的预期行为。我们可以从一个或两个示例开始，并使用数据生成技术来扩展到单个场景中包含许多示例（更多细节参见[第
    6 章](ch06.html#automated_testing_ml_model_tests)）。*数量:* 通常在几个到几十个之间 |'
- en: '| *Data* |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| *数据* |'
- en: '| Data pipelines, for input and output data | Data pipeline testsData contract
    tests | Tests ensure the data pipeline operates correctly by verifying each step
    (e.g., extraction, transformation, loading) functions as expected. These tests
    check for the integrity and accuracy of data as it moves through the pipeline.Tests
    also validate that the data adheres to the agreed schema, types, and formats expected
    by consuming systems or components.*Quantity:* Varies depending on the complexity
    of the pipeline, but usually multiple tests for each step in the pipeline in order
    to fail fast and fail loudly. |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 数据管道，用于输入和输出数据 | 数据管道测试数据契约测试 | 测试确保数据管道通过验证每个步骤（例如，提取、转换、加载）按预期运行。这些测试检查数据在管道中移动时的完整性和准确性。测试还验证数据是否符合消费系统或组件期望的约定模式、类型和格式。*数量：*
    根据管道复杂性而变化，但通常对管道中的每个步骤进行多个测试，以便快速失败并高声失败。 |'
- en: '| Input: Training data | Data privacy tests | Tests check that training data
    doesn’t contain PII and is compliant with relevant data protection laws (e.g.,
    GDPR).*Quantity:* Should be thorough enough to prove compliance; the number may
    vary according to the types of data handled. |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 输入：训练数据 | 数据隐私测试 | 测试检查训练数据不包含个人身份信息（PII）并符合相关数据保护法（例如，GDPR）的要求。*数量：* 应充分证明合规性；具体数目可能根据处理的数据类型而有所不同。
    |'
- en: We cover both categories of tests (software tests and model tests) in this book
    because, while each category of test is *indispensable*, each one alone is *incomplete*.
    For example, software tests are suited to testing logical correctness, but can
    fall short in testing ML model quality. And while model tests can help us scale
    the number of scenarios under which we can observe a model’s behavior, it is too
    distant (i.e., too many layers of abstraction away) from a feature engineering
    logic and would be a blunt tool for testing the correctness of that logic. In
    short, all ML systems need *both* software tests and model tests.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 本书涵盖了软件测试和模型测试两类测试，因为虽然每类测试都是 *不可或缺的*，但单独一类测试 *不完整*。例如，软件测试适合测试逻辑正确性，但在测试 ML
    模型质量时可能不足。而模型测试虽然可以帮助我们扩展可以观察模型行为的场景数量，但与特征工程逻辑相距甚远，并不适合测试该逻辑的正确性。总之，所有的 ML 系统都需要
    *既有* 软件测试 *又有* 模型测试。
- en: It helps to consider the [Swiss cheese model of accident causation](https://oreil.ly/-ysTS),
    which comes from the field of risk management. The model demonstrates that each
    layer of tests prevents a specific type of issue but no single layer of tests
    (e.g., unit tests, training smoke tests, or metrics tests) can test for all kinds
    of undesired outcomes. The layers complement each other to reduce blind spots
    and reduce the risk of bugs, errors, and other adverse outcomes flowing into production
    (see [Figure 5-4](#the_swiss_cheese_model_of_accident_caus)).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑事故因果的 [瑞士奶酪模型](https://oreil.ly/-ysTS)，它来自风险管理领域。该模型表明，每一层测试可以防止特定类型的问题，但单独的任何一层测试（例如单元测试、训练烟雾测试或指标测试）都不能测试所有不良结果的可能性。这些层次相互补充，以减少盲点并降低错误和其他不良结果进入生产环境的风险（见
    [图 5-4](#the_swiss_cheese_model_of_accident_caus)）。
- en: '![](assets/emlt_0504.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/emlt_0504.png)'
- en: 'Figure 5-4\. The [Swiss cheese model of accident causation](https://oreil.ly/-ysTS)
    (source: [Ben Aveling, Wikimedia Commons](https://oreil.ly/kJbAs), used under
    [CC BY-SA 4.0](https://oreil.ly/Hq5C_))'
  id: totrans-107
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-4\. 事故因果的 [瑞士奶酪模型](https://oreil.ly/-ysTS)（来源：[Ben Aveling, Wikimedia Commons](https://oreil.ly/kJbAs)，使用
    [CC BY-SA 4.0](https://oreil.ly/Hq5C_) 许可）
- en: Let’s go through [Table 5-1](#types_of_automated_tests_for_ml_systems)—types
    of automated tests for ML systems—in a bit more detail.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细查看 [表 5-1](#types_of_automated_tests_for_ml_systems) — 机器学习系统的自动化测试类型。
- en: Software logic
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 软件逻辑
- en: Whether you are training an ML model from scratch, fine-tuning a pretrained
    model with your custom domain data, deploying a pretrained model, or doing federated
    learning on edge devices, you will be writing code and your code is [software](https://oreil.ly/1IoCJ)
    (i.e., a set of instructions that tells a computer what to do or how to perform
    a task).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是从头开始训练 ML 模型，使用自定义域数据微调预训练模型，部署预训练模型，还是在边缘设备上进行联邦学习，您都将编写代码，而您的代码是 [软件](https://oreil.ly/1IoCJ)（即，一组指令，告诉计算机如何执行任务或完成任务）。
- en: Software logic components are characterized by *deterministic measures of correctness*
    (e.g., `add(1, 2) = 3`). Each component and its constituent functions take some
    input data, apply some transformation logic to the data, and either return the
    output data or perform a side effect with the data (e.g., save the data to disk).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 软件逻辑组件的特点是*确定性正确性度量*（例如，`add(1, 2) = 3`）。每个组件及其组成函数接受一些输入数据，对数据应用一些转换逻辑，并返回输出数据或对数据执行副作用（例如，将数据保存到磁盘）。
- en: For a list of typical components in the software logic category and their corresponding
    tests, refer to [Table 5-1](#types_of_automated_tests_for_ml_systems).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 关于软件逻辑类别中典型组件及其对应测试的列表，请参阅[表5-1](#types_of_automated_tests_for_ml_systems)。
- en: ML models
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习模型
- en: While software tests are indispensable, they are but one part of the testing
    puzzle and are insufficient for fully testing ML systems. This is because the
    model’s behavior is learned from multidimensional data, and it can be hard to
    articulate our expectations of what constitutes “correct” behavior in one or even
    a few assertions.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然软件测试是不可或缺的，但它们只是测试难题的一部分，并不足以完全测试机器学习系统。这是因为模型的行为是从多维数据中学习的，我们很难表达我们对“正确”行为的期望，即使是一个或几个断言也很难。
- en: Software tests tend to be *example-based* or *point-based*, and even property-based
    testing tends to get hard to read and maintain beyond three or four dimensions.
    That’s where model tests come in. They test our model using production-like data,
    checking our model’s behavior against expected behavior and aggregating the results
    in a meaningful and actionable way.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 软件测试通常是*基于示例*或*基于点*的，即使是基于属性的测试在超过三四个维度后也很难阅读和维护。这就是模型测试的用武之地。它们使用类似生产数据的模型进行测试，检查模型的行为是否符合预期，并以有意义且可操作的方式汇总结果。
- en: ML practitioners are typically familiar with model evaluation techniques, and
    domain experts and customers typically have implicit mental heuristics to judge
    if a model’s behavior is correct or wrong, good or bad, better or worse. That’s
    a great starting point for instrumenting automated ML tests. We can start by looking
    at existing manual testing approaches—when we release a model to production, what
    metrics or manual tests give us the confidence that a new model is “good enough”
    for production? What classes of behavior are undesirable? We can automate—and
    over time, deepen—these model tests as we consider how to automate more quality
    checks in our path to production.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习从业者通常熟悉模型评估技术，领域专家和客户通常有隐含的心理启发法来判断模型的行为是否正确或错误，好还是坏，更好还是更差。这是自动化机器学习测试的一个很好的起点。我们可以从现有的手动测试方法入手——当我们将一个模型发布到生产环境时，哪些指标或手动测试可以让我们对新模型足够自信？哪些行为类别是不希望出现的？随着我们考虑如何在通往生产过程中自动化更多的质量检查，我们可以自动化——并随着时间的推移，加深——这些模型测试。
- en: We can codify these implicit heuristics as automated [*fitness functions*](https://oreil.ly/Fi6wL)—objective,
    executable functions that can be used to summarize, as a single figure of merit,
    how close a solution is to its target state. These fitness functions can then
    be incorporated into our release pipelines to lay the foundation for iteratively
    improving our ML models and reducing manual testing. We’ll elaborate on fitness
    functions in [Chapter 6](ch06.html#automated_testing_ml_model_tests).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些隐含的启发法编码为自动化的[*适应性函数*](https://oreil.ly/Fi6wL)——客观的、可执行的函数，用于总结解决方案接近目标状态的程度。这些适应性函数可以被纳入我们的发布流水线，为逐步改进我们的机器学习模型和减少手动测试奠定基础。我们将在[第6章](ch06.html#automated_testing_ml_model_tests)详细阐述适应性函数。
- en: It’s worth calling out that model tests are closely related to the practices
    of *exploratory evaluation*, *error analysis*, *production monitoring*, and *data
    curation*. We will describe how these practices complement each other in [Chapter 6](ch06.html#automated_testing_ml_model_tests).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，模型测试与*探索性评估*、*错误分析*、*生产监控*和*数据管理*实践密切相关。我们将在[第6章](ch06.html#automated_testing_ml_model_tests)描述这些实践如何互补。
- en: 'Putting it together: The ML Systems Test Pyramid'
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 综合起来：机器学习系统测试金字塔
- en: To illustrate how software tests, model tests, and other types of tests come
    together to create a comprehensive test strategy, let’s look at the ML Systems
    Test Pyramid (see [Figure 5-5](#the_ml_systems_test_pyramiddot_left_par)). The
    Pyramid illustrates the types and quantities of tests in an ML system. The four
    pyramids (from left to right, and up) represent tests for data, model training
    pipelines, software logic, and ML models respectively.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明软件测试、模型测试和其他类型的测试如何共同创建全面的测试策略，让我们看看 ML 系统测试金字塔（见 [图 5-5](#the_ml_systems_test_pyramiddot_left_par)）。
- en: The size of each layer of the pyramid loosely represents the quantity of tests.
    For example, a big bottom layer for unit tests indicates that we should have many
    unit tests because they are fast, targeted, and easy to reason about and debug
    in the case of a failure. On the other hand, exploratory tests occupy a smaller
    area on the top of the Pyramid because, while they have a place in a comprehensive
    test strategy, they tend to be manual and unscalable, so we want to ensure we
    don’t accumulate a large quantity of exploratory manual testing procedures.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 金字塔的每个层的大小大致代表测试的数量。例如，单元测试的大底层表示我们应该有许多单元测试，因为它们快速、有针对性，并且在失败时易于理解和调试。另一方面，探索性测试占据金字塔顶部较小的区域，因为虽然它们在全面测试策略中有一席之地，但它们倾向于是手动和不可扩展的，因此我们要确保不要积累大量的探索性手动测试程序。
- en: '![](assets/emlt_0505.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/emlt_0505.png)'
- en: 'Figure 5-5\. The ML Systems Test Pyramid (source: adapted from an image in
    [“Continuous Delivery for Machine Learning” by Danilo Sato et al.](https://oreil.ly/PMz0Z))'
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-5\. ML 系统测试金字塔（来源：改编自 [“Continuous Delivery for Machine Learning” by Danilo
    Sato et al.](https://oreil.ly/PMz0Z) 中的一幅图像）
- en: In our book, even though we categorize the tests slightly differently—e.g.,
    software logic tests can show up as unit tests in three pyramids (data, ML model,
    software)—we still find the ML Systems Test Pyramid to be a helpful visual to
    identify the types of tests you can include in your solution to reduce manual
    testing and improve automated quality assurance.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在书中将测试的分类略有不同——例如，软件逻辑测试可以显示为三个金字塔中的单元测试（数据、ML 模型、软件），我们仍然发现 ML 系统测试金字塔对于识别可包含在解决方案中以减少手动测试并提高自动化质量保证非常有帮助。
- en: Now that we’ve got a good grasp of the breadth of tests for an ML system, let’s
    look at characteristics of a good test and key pitfalls to avoid.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经很好地掌握了 ML 系统测试的测试层次，让我们看看一个好的测试的特征以及需要避免的关键陷阱。
- en: Characteristics of a Good Test and Pitfalls to Avoid
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个好的测试的特征和需要避免的陷阱
- en: Let’s look at characteristics and practices that help us write reasonable and
    maintainable tests. While many of these practices are adapted from unit testing
    and test-driven development in the software engineering world, we find that they
    generalize well to the model tests that we’ll cover in the next chapter.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看帮助我们编写合理和可维护测试的特征和实践。虽然这些实践大多数是从软件工程领域的单元测试和测试驱动开发中借鉴而来，但我们发现它们对我们即将在下一章讨论的模型测试也适用良好。
- en: Tests should be independent and idempotent
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试应该是独立的并且幂等的
- en: Each test should be independent—i.e., the outcome of one test should not depend
    on what happens in another test. Tests should also be idempotent—i.e., no matter
    how many times we execute them, we achieve the same result. To this end, it helps
    to avoid any kind of shared state (e.g., tests that interact with a shared database
    or file).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 每个测试应该是独立的，即一个测试的结果不应取决于另一个测试的结果。测试还应该是幂等的，即无论执行多少次，结果都应该相同。为了达到这个目的，最好避免任何形式的共享状态（例如与共享数据库或文件进行交互的测试）。
- en: The opposite of idempotent tests would be flaky tests—tests that pass or fail
    unpredictably even when nothing has changed. When we see a flaky test, we should
    either fix it or remove it. Otherwise, flaky tests will waste the team’s time
    in triaging and rerunning the tests until they pass by chance, and they also diminish
    our confidence in our tests and CI pipeline.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 幂等测试的相反就是脆弱测试——即使没有任何变化，测试结果也会无法预测地通过或失败。当我们遇到脆弱测试时，我们应该修复或删除它。否则，脆弱测试将浪费团队的时间在分析和重新运行测试直到它们偶然通过，并且它们还会降低我们对测试和
    CI 流水线的信心。
- en: Tests should fail fast and fail loudly
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tests should fail fast and fail loudly
- en: What’s worse than bugs and errors? Silent bugs and errors, of course! A common
    example of silent regressions are model training pipelines that complete successfully,
    but lurking beneath the green pipeline status is a potential model-quality degradation
    that remains undetected.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 有什么比Bug和错误更糟糕？当然是无声的Bug和错误！无声回归的常见例子是模型训练流水线顺利完成，但在绿色流水线状态下潜藏的是潜在的模型质量下降问题，这些问题未被发现。
- en: To avoid this, you can adopt the principle of [failing fast and loudly](https://oreil.ly/Fz9mG)—a
    Unix Philosophy principle that you can apply to your tests and CI pipelines to
    give you the fast feedback you need. For example, if a model training pipeline
    takes an hour, you can fail fast and loudly by writing a test to exercise the
    entire pipeline with a very small dataset (we’ll discuss training smoke tests
    later in this chapter) and get feedback within one to two minutes should your
    changes cause a regression.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要避免这种情况，你可以采用“[快速失败与高声失败](https://oreil.ly/Fz9mG)”的原则——Unix哲学中的一个原则，你可以应用到你的测试和CI流水线中，以获得所需的快速反馈。例如，如果一个模型训练流水线需要一个小时，你可以通过编写一个测试来使用非常小的数据集执行整个流水线（我们将在本章后面讨论训练的烟雾测试），如果你的更改引起回归，你可以在一到两分钟内得到反馈。
- en: Tests should check behavior, not implementation
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试应该检查行为，而不是实现细节。
- en: 'Let’s illustrate this point with Jason Swett’s [analogy of testing a car](https://oreil.ly/0mXqU).
    When you test implementation, you try to test that the car works by checking if
    it has all the right stuff: presence of an engine, an ignition, wheels, and everything
    else that’s needed to get from point A to point B. On the other hand, when you
    test behavior, you test that the car works by starting the car and driving it
    for a bit.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过Jason Swett的[测试汽车的类比](https://oreil.ly/0mXqU)来说明这一点。当你测试实现细节时，你尝试通过检查汽车是否有所有正确的东西来测试汽车是否正常工作：发动机的存在、点火装置、轮子和其他所有从A点到B点所需的东西。另一方面，当你测试行为时，你通过启动汽车并行驶一段距离来测试汽车是否正常工作。
- en: 'Tests that focus on implementation are hard to read and they are brittle to
    changes. Let’s illustrate this with a negative and a positive example:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 那些关注实现细节的测试很难阅读，而且对变化很脆弱。让我们用一个负面和一个正面的例子来说明这一点：
- en: '[PRE0]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Notice how the second test was easier to understand?
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 注意第二个测试如何更易于理解？
- en: The first test is especially common in cases where the subject under test is
    poorly written and lacks testable boundaries. A convenient workaround is to short-circuit
    certain parts of the code with mocks, but this comes at a cost. For example, the
    private function `_fit_model()` may actually contain an error, but because we
    short-circuited parts of the code for ease of testing, we never actually execute
    that part of the code, and the tests can’t help us discover any errors that may
    be hiding in `_fit_model()`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个测试在被测试对象编写不良且缺乏可测试边界的情况下尤为常见。一个方便的解决方法是使用模拟来截断代码的某些部分，但这是有代价的。例如，私有函数`_fit_model()`实际上可能包含错误，但由于我们为了便于测试而截断了代码的某些部分，我们从未实际执行该部分代码，因此测试无法帮助我们发现可能隐藏在`_fit_model()`中的任何错误。
- en: By focusing on testing behavior and not implementation, our tests become more
    readable, more useful, and less brittle to inevitable changes in implementation.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 通过关注测试行为而不是实现细节，我们的测试变得更易读、更有用，对实现细节的变化更不脆弱。
- en: Note
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We should treat tests as code because tests are code. The pitfalls we observe
    in the preceding bad example test arise from poor software design. For example,
    the first test violated *encapsulation* because the test knew too much about internal
    implementation details of the function that it’s testing. Violating encapsulation
    leads to tight coupling, which leads to brittle code that requires [shotgun surgery](https://oreil.ly/YMGWZ)—the
    need to make changes in multiple places throughout a codebase to achieve a single
    modification.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该把测试看作代码，因为测试就是代码。我们观察到的上一个糟糕示例中的陷阱源于糟糕的软件设计。例如，第一个测试违反了*封装*，因为测试了太多关于被测试函数的内部实现细节。违反封装会导致紧耦合，这会导致脆弱的代码，需要[散弹手术](https://oreil.ly/YMGWZ)——在整个代码库中进行多处修改以实现单一修改的需求。
- en: We’ll discuss these design principles in greater detail in [Chapter 8](ch08.html#refactoring_and_technical_debt_manageme),
    and the point to note here is that tests are, in essence, also software. We should
    write our tests with good coding practices that help us write readable and maintainable
    code.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第8章](ch08.html#refactoring_and_technical_debt_manageme)中更详细地讨论这些设计原则，这里需要注意的一点是，测试本质上也是软件。我们应该用有助于编写可读性和可维护性代码的良好编码实践来编写我们的测试。
- en: Tests should be runnable in your development environment
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试应该可以在你的开发环境中运行
- en: Every test that we run on the cloud (e.g., on CI pipeline) should be runnable
    in your development environment—be it locally or in your cloud development environment.
    The ability to run tests and reproduce any failures in your development environment
    helps you avoid the antipattern of “pushing to know if something works.” The former
    gives us feedback on the order of seconds, while the latter gives us feedback
    on the order of minutes or tens of minutes.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在云上（例如在CI管道上）运行的每个测试都应该可以在你的开发环境中运行——无论是在本地还是在你的云开发环境中。能够在你的开发环境中运行测试并重现任何失败有助于你避免“推送以确认某事是否有效”的反模式。前者给我们提供了几秒钟的反馈，而后者则需要几分钟甚至几十分钟的时间来提供反馈。
- en: When a test fails on CI, first reproduce the failure in your development environment
    and iterate on a bug fix. You can even add breakpoints and debug and inspect the
    code, which is more effective than adding a print statement, pushing, waiting
    a few minutes or even hours, seeing what the print statement says, and doing so
    repeatedly. The ability to do error analysis in your development environment can
    help you triage the failure more quickly.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个测试在CI上失败时，首先在你的开发环境中重现这个失败，并迭代一个错误修复。你甚至可以添加断点、调试和检查代码，这比添加打印语句、推送、等待几分钟甚至几个小时，再查看打印语句说了什么，然后重复这一过程更为有效。在你的开发环境中进行错误分析的能力可以帮助你更快地诊断失败。
- en: In some scenarios, it may not be possible to run some tests on a local machine—e.g.,
    when a model is too large to fit on our local machine, or when it takes too long
    to train a model locally. In such cases, you can design your tests to be runnable
    locally by having a very small test dataset to train a very small model, simply
    to act as a smoke test before spending time running a full training in the cloud.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，可能无法在本地机器上运行一些测试，例如当模型太大而无法在本地机器上容纳时，或者当在本地训练模型花费太长时间时。在这种情况下，你可以设计你的测试使其能够在本地运行，例如使用一个非常小的测试数据集训练一个非常小的模型，简单地作为在云端运行完整训练之前的烟雾测试。
- en: In addition, you can also set up your development environment so that you can
    trigger large-scale model training remotely on the cloud (e.g., using tools such
    as [Metaflow](https://oreil.ly/RzNXY) or [Ray](https://oreil.ly/yOrkm)) from your
    local machine, to avoid the antipattern of “pushing to know if something works.”
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还可以设置你的开发环境，从本地机器触发远程云端的大规模模型训练（例如使用[Metaflow](https://oreil.ly/RzNXY)或[Ray](https://oreil.ly/yOrkm)等工具），以避免“推送以确认某事是否有效”的反模式。
- en: Tests must be part of feature development
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试必须成为功能开发的一部分
- en: You should be writing tests as part of feature development, not as an afterthought
    in a separate story, for two reasons.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在开发功能的同时编写测试，而不是在单独的故事中作为事后想法进行，理由有两个。
- en: First, post-hoc tests tend to be too coarse-grained and miss out on the value
    of writing tests as part of your development process. If the problem you’re solving
    consists of many subproblems, and they often do, writing tests helps you focus
    on one subproblem at a time, which presents a much lower cognitive load than trying
    to solve them all at once.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，事后测试往往过于粗粒度，错失了在开发过程中编写测试的价值。如果你要解决的问题由许多子问题组成（通常是这样的），编写测试有助于你一次集中精力解决一个子问题，这比尝试同时解决所有问题要少得多的认知负荷。
- en: Second, “testing stories” don’t appear as valuable as developing new features
    and the sociopsychological pressures to “get work done” often cause such stories
    to be relegated to the graveyard of other backlog stories. As a result, you accumulate
    technical debt and are forced to pay interest (e.g., spend time on manual testing)
    in subsequent features that you develop (recall [Figure 5-3](#counterintuition_writing_automated_test),
    where you saw the quadratic, cumulative testing effort that results from the lack
    of automated tests).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，“测试故事”似乎不如开发新功能有价值，而社会心理压力使得这些故事常常被置于其他积压故事的坟墓中。因此，你会积累技术债务，并且被迫支付利息（例如，在开发后续功能时花费时间进行手动测试），请回忆[图 5-3](#counterintuition_writing_automated_test)，你会看到由于缺乏自动化测试而导致的二次方累积测试工作量。
- en: Refer to the following sidebar on test-driven development (TDD) for a brief
    discussion on the why, what, and how of writing tests as part of feature development.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考有关测试驱动开发（TDD）的侧边栏，简要讨论将测试作为功能开发的一部分的原因、内容和方式。
- en: Tests let us “catch bugs once”
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试让我们“一次捕捉到所有的错误”
- en: As we’ve established, you should be writing tests as part of feature development.
    Bug fixes or production incident responses are no different in that you should
    also be writing tests as part of the fix. By writing the test first to reproduce
    the error scenario, you have a firm starting point and you can run the tests very
    quickly as you iterate on a fix. The tests guarantee that this bug will never
    happen again (unless someone skips or removes them!).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所建立的，您应该在功能开发的一部分编写测试。修复错误或生产事故响应在这方面也没有不同，您也应该在修复的过程中编写测试。通过先编写测试来复现错误场景，您有一个坚实的起点，并且在迭代修复时可以快速运行测试。这些测试保证了这个错误将不会再次发生（除非有人跳过或删除它们！）。
- en: This is applicable to model tests as well. For example, through your own manual
    testing or through user feedback, you may realize that your model was producing
    incorrect predictions more often for one segment of your data than for other segments.
    In addition to ad hoc error analysis to triage the issue, you can also write a
    stratified metric test to assert that your model quality metric for each segment
    is within X% of each other. This test will ensure that if your model is again
    underperforming for a key segment of our data, your tests will catch it and prevent
    this model from being released to production. We’ll show an example of such a
    test in [Chapter 6](ch06.html#automated_testing_ml_model_tests).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这对模型测试同样适用。例如，通过自己的手动测试或用户反馈，您可能会意识到您的模型在某些数据段上产生的错误预测比其他数据段更频繁。除了临时性的错误分析来处理这个问题，您还可以编写分层度量测试，以确保每个数据段的模型质量度量在相互之间的误差范围内（X%）。这个测试将确保如果您的模型再次在关键数据段表现不佳，您的测试将捕捉到它，并防止该模型发布到生产环境中。我们将在[第六章](ch06.html#automated_testing_ml_model_tests)展示这样一个测试的示例。
- en: As Isao Yoshino, a Toyota veteran, said, “It’s only a failure if you don’t learn
    (from it).” Every production incident or customer complaint is a valuable point
    of feedback about a gap in our product, and tests help us codify that those gaps
    have been mitigated and ensure that the same bugs don’t happen again.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 正如丰田的老将吉野功所说，“只有当你不学习（从中）时才是失败”。每一个生产事故或客户投诉都是我们产品中一个有价值的反馈点，而测试帮助我们将这些差距编码化，并确保相同的错误不会再次发生。
- en: This set of characteristics and pitfalls to avoid are useful guidelines when
    we’re designing and writing our tests. Especially when we’re feeling unsure (e.g.,
    is there value in writing tests as a part of this story?), these principles have
    helped us make better decisions. We hope it will guide you just the same.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们设计和编写测试时，这一组特征及其避免的陷阱是有用的指南。特别是当我们感到不确定时（例如，在这个故事的一部分中编写测试是否有价值？），这些原则帮助我们做出更好的决策。我们希望它也能同样地指导您。
- en: Now that you know the desirable characteristics of tests, let’s look at components
    of an automated test and how we can write one.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了测试的理想特征，让我们来看一下自动化测试的组成部分以及我们如何编写它们。
- en: 'The How: Structure of a Test'
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试的结构：如何编写测试
- en: In this section, we will describe the structure of an automated test. While
    this structure is drawn from the practice of unit testing, we find it generalizes
    well to other types of software tests and model tests.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述自动化测试的结构。虽然这个结构来源于单元测试的实践，但我们发现它对其他类型的软件测试和模型测试同样适用。
- en: 'An automated test should have three ingredients:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一个自动化测试应包含三个要素：
- en: A meaningful test name
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个有意义的测试名称
- en: Structure of arrange, act, assert (AAA)
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安排（arrange）、执行（act）、断言（assert）（AAA）的结构
- en: Specific and holistic assertions
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具体和全面的断言
- en: 'To illustrate these ingredients, let’s take a look at a positive and a negative
    example of a test. We’ll show more sophisticated tests in the next section, but
    for now a simple example will help us focus on the characteristics of a good test:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这些要素，让我们看一个测试的正面和负面例子。我们将在下一节展示更复杂的测试，但现在一个简单的例子将帮助我们关注一个好测试的特征：
- en: '[PRE1]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![](assets/1.png)](#code_id_5_1)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/1.png)](#code_id_5_1)'
- en: The name of the test describes what we are testing—the function `convert_keys_to_snake_case()`
    and what it should do (update the keys in a dictionary) for a given condition
    (keys with spaces and punctuation). Our brain is primed and prepared to digest
    the implementation details that follow. In large projects with many tests, well-named
    tests that clearly describe the “what” help us to reduce cognitive load by abstracting
    away the “how” and dense implementation details in the test.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 测试名称描述了我们正在测试的内容——函数`convert_keys_to_snake_case()`应该做什么（更新字典中的键，以适应包含空格和标点符号的键）。我们的大脑已经准备好接受接下来的实现细节。在具有许多测试的大型项目中，良好命名的测试可以通过摘要“如何”和测试中的密集实现细节来减少认知负荷。
- en: '[![](assets/2.png)](#code_id_5_2)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/2.png)](#code_id_5_2)'
- en: The test has the structure of arrange, act, assert, and we use a blank new line
    to create a visual hierarchy denoting the three blocks of code. In a real test
    though, we wouldn’t need to explicitly spell out “arrange, act, assert,” as the
    use of a blank line is a typical convention in software testing to indicate the
    three blocks. You may also merge sections (e.g., arrange and act can be merged
    in small tests), if it makes the tests easier to read.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 测试具有排列（arrange）、执行（act）、断言（assert）的结构，我们使用一个空白新行来创建视觉层次，表示这三个代码块。然而，在真实的测试中，我们不需要明确地列出“arrange,
    act, assert”，因为空白行是软件测试中的典型约定，用于指示三个代码块。如果测试更易读，则可以合并部分（例如，可以在小测试中合并排列和执行）。
- en: '[![](assets/3.png)](#code_id_5_3)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/3.png)](#code_id_5_3)'
- en: A single, holistic assertion makes it clear what we expect of this function.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 单一的整体断言清楚地表明了我们对这个函数的期望。
- en: 'Next, let’s take a look at a bad example:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看一个糟糕的例子：
- en: '[PRE2]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![](assets/1.png)](#code_id_5_4)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/1.png)](#code_id_5_4)'
- en: The generic test name (just prefixing the function we’re testing with `test_`)
    gives us little information on what scenarios we are testing and forces us to
    read the implementation details in the test.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 通用测试名称（只是在我们正在测试的函数前面添加`test_`前缀）几乎没有提供我们正在测试哪些场景的信息，并迫使我们阅读测试中的实现细节。
- en: '[![](assets/2.png)](#code_id_5_5)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/2.png)](#code_id_5_5)'
- en: Assertions are piecemeal and incomplete. In this case, the test could actually
    miss a bug because we didn’t assert on `Current_title`.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 断言是零散和不完整的。在这种情况下，测试实际上可能会忽略一个bug，因为我们没有对`Current_title`进行断言。
- en: '[![](assets/3.png)](#code_id_5_6)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/3.png)](#code_id_5_6)'
- en: The second assertion is too vague. The function could return a wrong value for
    the `work_address` field and our test would still pass.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个断言太模糊了。该函数可能会对`work_address`字段返回错误的值，但我们的测试仍然会通过。
- en: 'Equipped with the why, what, and how of automated testing, you’re now ready
    to dive into the first category of tests: software tests!'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握了自动化测试的原因、内容和方式，现在您已准备好深入了解第一类测试：软件测试！
- en: Software Tests
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件测试
- en: 'In this section, let’s look at four types of software tests that are useful
    for testing software components commonly found in ML systems:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，让我们看一下对于ML系统中常见的软件组件进行测试非常有用的四种软件测试类型：
- en: Unit tests
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单元测试
- en: Training smoke tests
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练冒烟测试
- en: API tests
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API测试
- en: Post-deployment tests
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署后测试
- en: '[Figure 5-2](#a_series_of_automated_tests_serve_as_qu) will help you situate
    where each of these software tests sit in an ML model’s path to production.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[Figure 5-2](#a_series_of_automated_tests_serve_as_qu) 将帮助您了解这些软件测试在ML模型生产路径中的位置。'
- en: Unit Tests
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单元测试
- en: Unit tests help ensure the correctness of individual building blocks of our
    ML system—most commonly *functions*. Whatever the function does, it is doing something,
    and unit tests help us to explicitly specify the function’s expected behavior
    and ensure that these expectations still hold true with every code change. Decades
    of software engineering have taught us that this is much more reliable and scalable
    than manual testing—which is error-prone and ever-increasingly time-consuming—or
    worse, not testing at all.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 单元测试有助于确保我们的ML系统中各个基本构建块的正确性——最常见的是*函数*。无论函数做什么，它都在做某事，而单元测试帮助我们明确指定函数的预期行为，并确保这些期望在每次代码更改时仍然成立。几十年的软件工程经验告诉我们，这比手动测试（容易出错且时间消耗大）、或者更糟糕的是不进行测试，更加可靠和可扩展。
- en: While other types of tests listed in this chapter may not be needed for certain
    situations (e.g., you won’t need API tests if you’re not deploying an API), unit
    tests are the only type of test that is unequivocally necessary in ML solutions.
    Software logic generally accounts for most of the code footprint in ML projects.
    For example, an important part of ML systems is feature engineering, and these
    data transformations are essentially pure functions and logical transformations
    to data. If we don’t test this logic, we’re keeping a door open for bugs, errors,
    and countless hours debugging defects that slipped through the large cracks of
    manual testing.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本章中列出的其他类型的测试在某些情况下可能不需要（例如，如果不部署 API，则不需要 API 测试），但单元测试是机器学习解决方案中唯一绝对必要的测试类型。软件逻辑通常占据机器学习项目中大部分代码的占比。例如，机器学习系统的一个重要部分是特征工程，这些数据转换本质上是纯函数和数据的逻辑转换。如果我们不对这些逻辑进行测试，就会为通过手动测试大洞漏漏过的缺陷、错误以及无数小时的调试留下一扇大门。
- en: How to design unit-testable code
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何设计可单元测试的代码
- en: Alright. You are convinced of the value of unit testing and you want to start
    writing your own unit tests. However, you may be looking at a codebase that looks
    incredibly difficult to test. For example, imagine if all of the code is in a
    very long Python script or notebook, with no callable functions—this makes it
    hard to test because we don’t even have a function to invoke, much less a result
    to assert on.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 好了。你已经被说服了单元测试的价值，并且想要开始编写自己的单元测试。但是，你可能正在查看一个看起来非常难以测试的代码库。例如，想象一下，如果所有的代码都在一个非常长的
    Python 脚本或笔记本中，并且没有可调用的函数——这会使得测试变得困难，因为我们甚至没有函数可以调用，更不用说要断言的结果了。
- en: 'The good news is that, if you find yourself in a codebase like that, there
    are techniques that you can apply to refactor your way to a modular, reasonable,
    and testable codebase (we’ll demonstrate this in [Chapter 8](ch08.html#refactoring_and_technical_debt_manageme)
    on refactoring). But for now, the point is—code can be written in a way that’s
    hard to test. This usually happens when automated testing is done as an afterthought.
    You can, and should, make it easier for yourself to unit test your code by (i)
    writing tests as part of your solution, and (ii) writing your code using the [functional
    core, imperative shell design pattern](https://oreil.ly/3Gqkc) from functional
    programming (see [Figure 5-6](#functional_corecomma_imperative_shell_d)):'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，如果你发现自己处于这样的代码库中，有一些技术可以帮助你重构为模块化、合理且可测试的代码库（我们将在第 8 章中展示这一点）。但是现在，重点是——代码可以以一种难以测试的方式编写。这通常发生在自动化测试被视为事后附加项时。通过（i）将测试作为解决方案的一部分编写，以及（ii）使用功能编程中的
    [功能核心，命令式外壳设计模式](https://oreil.ly/3Gqkc) 来编写代码（见 [图 5-6](#functional_corecomma_imperative_shell_d)），你可以并且应该使得编写单元测试变得更容易。
- en: Thick functional core
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 厚的功能核心
- en: The thick functional core refers to a collection of pure functions (i.e., a
    function that returns identical outputs when given identical inputs, without any
    side effects). Examples could include any kind of data processing, feature engineering,
    and data transformations. Pure functions are deterministic and idempotent, and
    far easier to test.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 厚的功能核心是一组纯函数（即，给定相同输入时返回相同输出的函数，没有任何副作用）。示例可以包括任何类型的数据处理、特征工程和数据转换。纯函数是确定性的且幂等，更容易测试。
- en: Thin imperative shell
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 薄的命令式外壳
- en: The thin imperative shell refers to a small collection of functions that perform
    side effects (e.g., loading data, or saving a file to disk or a remote bucket).
    These interactions with the outside world are computationally expensive and also
    nondeterministic. By excluding them from our functional core, we make our functional
    core far easier and faster to test.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 薄的命令式外壳是指执行副作用的少量函数集合（例如，加载数据或将文件保存到磁盘或远程存储桶）。这些与外界的交互既计算密集又不确定。通过将它们排除在功能核心之外，我们使功能核心更容易且更快速地测试。
- en: '![](assets/emlt_0506.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/emlt_0506.png)'
- en: Figure 5-6\. [Functional core, imperative shell design pattern](https://oreil.ly/3Gqkc)
  id: totrans-201
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-6\. [功能核心，命令式外壳设计模式](https://oreil.ly/3Gqkc)
- en: Note
  id: totrans-202
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: As an aside, the word “imperative” in this context puzzled us initially, because
    we thought it was referring to the style of coding using an explicit sequence
    of instructions to tell the computer how to do things (as in [imperative code
    versus declarative code](https://oreil.ly/zk2JZ)). However, it’s actually referring
    to *imperative programming* (as in [imperative programming versus functional programming](https://oreil.ly/EOA0i)),
    which according to instructor Philip Fong at Simon Fraser University is a “style
    of programming, in which side effects are not only permissible but are also the
    primary means by which we program.”
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，在这种情况下，“命令式”这个词一开始让我们感到困惑，因为我们以为它是指使用明确的指令序列告诉计算机如何操作的编码风格（就像[命令式代码与声明式代码](https://oreil.ly/zk2JZ)中的方式）。然而，它实际上是指*命令式编程*（如[命令式编程与函数式编程](https://oreil.ly/EOA0i)），根据西蒙弗雷泽大学的Philip
    Fong教授的说法，“是一种编程风格，其中副作用不仅被允许，而且是我们编程的主要手段。”
- en: With this design tool in our hands, let’s zoom in and learn how to write a unit
    test for a particular function.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个设计工具，让我们放大来学习如何为特定函数编写单元测试。
- en: How do I write a unit test?
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我怎样编写单元测试？
- en: In each unit test, we specify the inputs that we pass to the function under
    test and our expectations of the function’s return value (or side effect, in the
    case of functions in the thin imperative shell).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个单元测试中，我们指定传递给被测试函数的输入以及我们对函数返回值的期望（或在薄的命令式壳中，函数的副作用）。
- en: 'A unit test shares the same ingredients as the automated test that we described
    earlier in the chapter: a readable test name, AAA structure (arrange, act, assert),
    and holistic assertions. As a mini-challenge, can you read the code sample below
    and spot each ingredient in the test?'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 单元测试与本章前面描述的自动化测试共享相同的要素：可读的测试名称，AAA结构（安排，执行，断言），以及整体断言。作为一个小挑战，你能读懂下面的代码示例并找到每个测试的要素吗？
- en: 'Here is an example of a unit test for a function that transforms a dictionary
    to have snake-cased keys:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个示例，展示了一个将字典转换为蛇形命名键的函数的单元测试：
- en: '[PRE3]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here’s another example of a unit test, but this time for a function that applies
    a data transformation to a pandas dataframe:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是另一个单元测试的例子，但这次是针对将数据变换应用到pandas dataframe的函数：
- en: '[PRE4]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![](assets/1.png)](#code_id_5_7)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/1.png)](#code_id_5_7)'
- en: For testing dataframe equality, we use [`assert_frame_equal()`](https://oreil.ly/mIdFt)
    or [`assert​_ser⁠ies_equal()`](https://oreil.ly/ZQqdx) from pandas.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 对于测试数据框架的相等性，我们使用[`assert_frame_equal()`](https://oreil.ly/mIdFt)或[`assert_series_equal()`](https://oreil.ly/ZQqdx)从pandas中使用。
- en: '[![](assets/2.png)](#code_id_5_8)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/2.png)](#code_id_5_8)'
- en: By articulating our expectations of a function, we improve our understanding
    of the code’s behavior. In this example, we may discover that min-max normalization
    is the wrong data transformation to apply, as it would baseline the smallest value
    to 0 (e.g., the “income” of 10 now becomes 0 after normalization). Perhaps we
    should be using [log transformations](https://oreil.ly/RKDC8) instead. Through
    writing this test, we uncovered a bug and found an opportunity to improve our
    feature engineering logic.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 通过明确我们对函数的期望，我们提高了对代码行为的理解。在这个例子中，我们可能会发现最小-最大归一化是错误的数据转换，因为它会将最小值基准化为0（例如，10的“收入”在归一化后变为0）。也许我们应该改用[对数变换](https://oreil.ly/RKDC8)。通过编写这个测试，我们发现了一个错误，并找到了改进我们特征工程逻辑的机会。
- en: If that looked too easy, it’s because it is, once you’ve learned how to do it!
    Unit testing is a simple and powerful tool that helps you ensure that every new
    piece of functionality you write is accompanied with tests, and helps you reap
    the benefits we described earlier. When a team develops the habit and discipline
    of ensuring the correctness and quality of their code through automated tests,
    they improve the reliability, agility, and velocity of their ML experimentation
    cycles.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这看起来太容易，那是因为一旦你学会了，它就是简单而强大的！单元测试是一个简单而强大的工具，帮助您确保您编写的每个新功能都伴随有测试，并帮助您获得我们早期描述的各种好处。当团队养成通过自动化测试确保其代码正确性和质量的习惯和纪律时，他们将提高其ML实验周期的可靠性、灵活性和速度。
- en: 'With that in order, we can now shift gears to look at another component of
    an ML system that some consider hard to test: the ML training pipeline.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些准备工作，我们现在可以转而关注ML系统中另一个被认为难以测试的组件：ML训练管道。
- en: Training Smoke Tests
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练 Smoke Tests
- en: ML training is usually long running and can range between minutes to hours.
    The wait time lengthens the feedback loop we use to assess the effect of a code
    change, and also disrupts our flow, and possibly even steers us toward more multitasking
    and context-switching.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ML训练通常是长时间运行的，可能需要几分钟到几小时。等待时间延长了我们用来评估代码变更效果的反馈循环，也打断了我们的流程，甚至可能使我们更多地进行多任务处理和上下文切换。
- en: Even if model training takes just 10 minutes, why wait 10 minutes to find an
    error in a final step when you can find out in a minute or less? Training smoke
    tests give us fast feedback (within a minute or so) on whether our code change
    worked as expected, or caused any issues, in the ML training task. When it passes,
    we’re more confident that the full-scale ML training is more likely to succeed.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 即使模型训练只需10分钟，为什么要等待10分钟才能在最后一步发现错误，当你可以在一分钟或更短的时间内发现呢？训练烟雾测试能在一分钟左右内快速反馈我们的代码变更是否按预期工作或导致任何问题，在ML训练任务中。当测试通过时，我们更有信心全面的ML训练更有可能成功。
- en: A training smoke test works by exercising the entire code path, just as a full-scale
    ML training would, except that we use the smallest possible dataset—even 10 samples
    could suffice. The subject under test here is the code that glues together the
    end-to-end ML training (you could call it an ML training pipeline, task, or script),
    all the way from loading data, feature engineering, model training, and creating
    a consumable artifact, even if it’s a small model.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 训练烟雾测试通过模拟整个代码路径来工作，就像全面的ML训练一样，只是我们使用尽可能小的数据集——甚至10个样本就足够了。这里被测试的对象是将数据加载、特征工程、模型训练和创建可消耗的工件（即使是小模型）粘合在一起的代码（你可以称之为ML训练流水线、任务或脚本）。
- en: The test passes if nothing blows up (i.e., there’s no smoke). The term “smoke
    test” [originates from electronic hardware testing](https://oreil.ly/S7Da1)—you
    plug in a new board and turn on the power. If you see smoke coming from the board,
    turn off the power because something is broken. We have also seen other practitioners
    in the ML community refer to this type of test as a [pretrain test](https://oreil.ly/idW2z),
    or [integration test](https://oreil.ly/ZS4h8).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有什么爆炸（即，没有烟），测试通过。术语“烟雾测试”[起源于电子硬件测试](https://oreil.ly/S7Da1)——你插入一个新板并打开电源。如果看到板子冒烟，关掉电源，因为有东西坏了。我们也看到ML社区中的其他从业者将这种类型的测试称为[预训练测试](https://oreil.ly/idW2z)，或[集成测试](https://oreil.ly/ZS4h8)。
- en: How do I write these tests?
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何编写这些测试？
- en: 'While the implementation of these tests may differ depending on your ML training
    framework, the general approach is the same. Invoke your ML training pipeline
    locally, as you would in full-scale training, except that you will use a very
    small dataset. Here is an example of a training smoke test:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些测试的实现可能因你的ML训练框架而异，但一般的方法是相同的。像在全面训练中那样在本地调用你的ML训练流水线，只是你会使用一个非常小的数据集。以下是一个训练烟雾测试的例子：
- en: '[PRE5]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In your terminal, you can run the training smoke test by executing the following
    command:^([3](ch05.html#ch01fn27))
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的终端中，你可以通过执行以下命令来运行训练烟雾测试：^([3](ch05.html#ch01fn27))
- en: '[PRE6]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In one of our previous projects, we had an ML training pipeline that took three
    hours. The full-scale training ran on the cloud (we were using [Metaflow](https://oreil.ly/RzNXY))
    and ML practitioners sometimes waited two hours only to see an error in the final
    step of the pipeline. So, we devised a training smoke test by running a Metaflow
    flow in local mode with a small dataset and ran the training pipeline locally
    in one to two *minutes*.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的一个项目中，我们有一个ML训练流水线需要三个小时。全面的训练在云端运行（我们使用[Metaflow](https://oreil.ly/RzNXY)），ML从业者有时等待两个小时，只是为了在流水线的最后一步看到一个错误。所以，我们设计了一个训练烟雾测试，通过在本地模式下使用小数据集运行Metaflow流，并在一到两分钟内本地运行训练流水线。
- en: The training smoke test also runs as a pre-commit hook, so if we were about
    to push an error, we would find the error in under two minutes, rather than three
    hours.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 训练烟雾测试还作为一个预提交钩子运行，因此如果我们即将推送一个错误，我们会在两分钟内找到错误，而不是三个小时。
- en: Whichever ML orchestration tool or platform you are using, explore how you can
    use it to create a training smoke test. If there isn’t a way to do it, and you
    frequently find yourself spending significant amounts of time waiting, then perhaps
    the platform or the tool is hindering rather than helping you.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用哪种ML编排工具或平台，探索如何使用它来创建一个训练烟雾测试。如果没有办法做到这一点，并且你经常发现自己花费大量时间等待，那么也许这个平台或工具不是帮助，而是阻碍你。
- en: Now that you can get fast feedback on what is typically a slow and long-running
    component of our ML systems, let’s switch gears again to look at how you can test
    the software we write to serve our model for consumption.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以快速获得关于我们机器学习系统中典型的缓慢和长时间运行组件的反馈，让我们再次转换视角，看看您如何测试我们编写的软件以为我们的模型提供服务。
- en: API Tests
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: API 测试
- en: If you are encapsulating and deploying the trained model as a web API, you can
    test and start the API as we would any other web API. The subject under test is
    a web API application.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您将训练好的模型封装并部署为 web API，您可以像测试任何其他 web API 一样测试和启动 API。受测试对象是一个 web API 应用程序。
- en: As a producer of an ML model, you are likely going to have downstream components
    that depend on you, such as a frontend application or other APIs. These downstream
    consumers will inevitably depend on the behavior of your API (e.g., request and
    response schema). Should your behavior change in a way that breaks your contract
    or promise to those consumers, you will be breaking downstream consumers and causing
    lots of headaches for everyone.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 作为机器学习模型的生产者，您可能会有依赖于您的下游组件，例如前端应用程序或其他 API 的组件。这些下游消费者将不可避免地依赖于您的 API 的行为（例如请求和响应模式）。如果您的行为发生变化并违反了您对这些消费者的约定或承诺，将会导致下游消费者的故障，并为所有人带来很多麻烦。
- en: This is where API tests are immensely helpful. They can serve as a lightweight
    *contract test—*a test that verifies you are still fulfilling your promise (i.e.,
    contract) to the external world. If your code change is going to break downstream
    systems, you’d much rather your tests tell you locally, before the changes are
    deployed anywhere and before the defect is even committed. The API test failure
    will also be a hook to prompt you to think about API versioning and [managing
    API schema changes](https://oreil.ly/A7r-y). A failing test is certainly better
    than an unexpected flurry of messages from other teams in the middle of your dinner.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 API 测试极为有用的地方。它们可以作为一种轻量级的*契约测试*——验证您仍在履行对外界的承诺（即契约）的测试。如果您的代码变更会破坏下游系统，您更希望在本地测试告诉您，在任何地方部署这些变更之前，甚至在提交缺陷之前。API
    测试失败也会提示您考虑 API 版本控制和[管理 API 模式更改](https://oreil.ly/A7r-y)。失败的测试肯定比在晚餐时间突然收到其他团队大量消息要好得多。
- en: How do I write these tests?
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我该如何编写这些测试？
- en: 'You can write these tests in three steps:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按照以下三个步骤编写这些测试：
- en: Consider what behavior you expect for a given request.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑对于给定请求您期望的行为。
- en: Find documentation on how to write API tests for the API library you are using
    (e.g., [FastAPI TestClient](https://oreil.ly/5uqzm) if you are using FastAPI).
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到有关如何为您正在使用的 API 库编写 API 测试的文档（例如，如果您使用的是 FastAPI，则找到关于 [FastAPI TestClient](https://oreil.ly/5uqzm)
    的文档）。
- en: Write and run the test!
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写并运行测试！
- en: 'Here is an example of a model API test:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个模型 API 测试的示例：
- en: '[PRE7]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![](assets/1.png)](#code_id_5_9)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/1.png)](#code_id_5_9)'
- en: Assuming you’ve defined a handler for requests for `"/"` that returns a hello
    world message, you can write a simple assertion like this to test that the endpoint
    handler returns the expected response.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您已经为返回一个 hello world 消息的请求 `"/"` 定义了一个处理程序，您可以编写如下简单的断言来测试端点处理程序是否返回了预期的响应。
- en: '[![](assets/2.png)](#code_id_5_10)'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/2.png)](#code_id_5_10)'
- en: 'A readable test name. We’ve opted for the format of: “{the endpoint path} (/predict)
    returns {expected output} when given {a type of input}.” You can further finesse
    the test name for other test scenarios (e.g., predict returns a missing features
    error message when the request does not contain all required features).'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可读性强的测试名称。我们选择了以下格式：“{端点路径} (/predict) 在给定 {输入类型} 时返回 {预期输出}。” 您可以进一步调整测试名称以适应其他测试场景（例如，当请求不包含所有必需特征时，predict
    返回一个缺少特征的错误消息）。
- en: '[![](assets/3.png)](#code_id_5_11)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/3.png)](#code_id_5_11)'
- en: Arrange.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 安排。
- en: '[![](assets/4.png)](#code_id_5_12)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/4.png)](#code_id_5_12)'
- en: Act.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 行动。
- en: '[![](assets/5.png)](#code_id_5_13)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/5.png)](#code_id_5_13)'
- en: Assert.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 断言。
- en: 'In your terminal, you can run the API tests by executing the following command:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的终端中，您可以通过执行以下命令来运行 API 测试：
- en: '[PRE8]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Recommended practice: Assert on “the whole elephant”'
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推荐做法：对“整体”进行断言
- en: 'One common pitfall we’ve seen in tests is piecemeal assertions. In the bad
    example below, the assertion on the response object is broken up into multiple
    assertions, while the good example asserts on the response object using a single
    dictionary:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在测试中经常看到的一个常见问题是零碎的断言。在下面的不良示例中，对响应对象的断言被分成了多个断言，而良好的示例则使用单个字典对响应对象进行断言：
- en: '[PRE9]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We characterize the bad example as asserting on “parts of the elephant,” and
    the good example as asserting “the whole elephant.” Asserting the whole elephant
    is better for two reasons. First, the test is more readable. At a glance, you
    can see the schema of the API response (it’s a dictionary with two fields).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将坏的例子描述为对“大象的部分”进行断言，而将好的例子描述为对“整体的大象”进行断言。断言整个大象有两个原因更好。首先，测试更易读。一眼就可以看到API响应的模式（它是一个包含两个字段的字典）。
- en: Second, the test is more comprehensive—we are testing the whole response payload
    returned by the API and can catch any unexpected changes to the response payload.
    In our experience, when asserting on “parts of the elephant,” when teams add a
    new part (e.g., a trunk), teams can sometimes forget to update the tests. One
    day, the trunk might go missing and the test would give you zero feedback about
    the defect.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，测试更为全面——我们测试API返回的整个响应有效负载，并且可以捕获到响应有效负载的任何意外更改。根据我们的经验，在断言“大象的部分”时，当团队添加新的部分（例如象鼻）时，团队有时会忘记更新测试。有一天，象鼻可能会丢失，而测试则不会对这个缺陷提供任何反馈。
- en: 'Teams sometimes opt to write piecemeal assertions because they lack the tool
    or language to specify holistic assertions. For example, the model’s prediction
    in a test could be nondeterministic, so teams break up the assertions to accommodate
    that. Thankfully, we now have Python libraries (e.g., [precisely](https://oreil.ly/__A8U))
    that let us write holistic assertions to assert on the schemas of the response,
    rather than specific values of the model’s predictions. Let’s see how you can
    write a holistic assertion in this style of testing:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 团队有时选择分步断言，因为他们缺乏工具或语言来指定整体断言。例如，测试中模型的预测可能是非确定性的，因此团队分解断言以适应这一点。幸运的是，现在我们有Python库（例如[precisely](https://oreil.ly/__A8U)）可以让我们编写整体断言来断言响应的模式，而不是模型预测的具体值。让我们看看你如何以这种测试风格编写整体断言：
- en: '[PRE10]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[![](assets/1.png)](#code_id_5_14)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/1.png)](#code_id_5_14)'
- en: A hard-coded response for illustration purposes. In a real test, this would
    be a result returned by a function.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明目的而硬编码的响应。在真实测试中，这将是函数返回的结果。
- en: '[![](assets/2.png)](#code_id_5_15)'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/2.png)](#code_id_5_15)'
- en: The model can return any value between 0 and 2 for prediction.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型可以预测0到2之间的任何值。
- en: '[![](assets/3.png)](#code_id_5_16)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/3.png)](#code_id_5_16)'
- en: This field is a deterministic value.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这个字段是一个确定性的值。
- en: '[![](assets/4.png)](#code_id_5_17)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/4.png)](#code_id_5_17)'
- en: Assume we don’t care about the specific value of this field; we just care that
    it’s a string.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们不关心这个字段的具体值；我们只关心它是一个字符串。
- en: '[![](assets/5.png)](#code_id_5_18)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/5.png)](#code_id_5_18)'
- en: '`is_mapping()` specifies that we are expecting a Python dictionary (known as
    a Map in other programming languages).'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '`is_mapping()`指定我们期望一个Python字典（在其他编程语言中称为映射）。'
- en: '[![](assets/6.png)](#code_id_5_19)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/6.png)](#code_id_5_19)'
- en: 'We are saying that prediction can be any of these values : 0, 1, 2\. For longer
    lists, you can write this as a list comprehension for brevity.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们说预测可以是这些值之一：0, 1, 2。对于更长的列表，你可以使用列表理解来简洁地写这个。
- en: '[![](assets/7.png)](#code_id_5_20)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/7.png)](#code_id_5_20)'
- en: We say we only care that user_name is a string, and it doesn’t matter what specific
    value it returns in our case.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们说我们只关心user_name是一个字符串，在我们的情况下，它返回什么具体的值并不重要。
- en: This tool and technique can help us write readable and holistic assertions,
    even for situations when the subject of our assertions contains nondeterministic
    values.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这种工具和技术可以帮助我们编写可读和整体的断言，即使在我们断言的主体包含非确定性值的情况下也是如此。
- en: Note
  id: totrans-277
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In organizations with mature software engineering practices, there may be established
    patterns on how to test APIs or even other aspects of a holistic testing strategy.
    If that’s the case for you, we recommend that you find the relevant documentation
    or experts to assess and adapt these patterns for the model APIs that you are
    deploying.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在拥有成熟软件工程实践的组织中，可能已经建立了关于如何测试API甚至其他整体测试策略方面的模式。如果你的情况是这样，我们建议你查找相关文档或专家，以评估并调整这些模式，以适应你正在部署的模型API。
- en: Now that we’ve tested our API in a local environment, let’s look at another
    powerful software test—testing our API after it’s been deployed to a real environment.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在本地环境中测试了我们的API，让我们来看看另一种强大的软件测试——在API部署到真实环境后测试我们的API。
- en: Post-deployment Tests
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署后测试
- en: In post-deployment tests, the subject under test is the API, which has been
    deployed to a real environment (e.g., preproduction, production). Every time we
    promote a deployable to an environment, we want to test that it can handle requests
    successfully according to our expectations.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署后测试中，被测试的对象是API，该API已部署到真实环境（例如预生产环境、生产环境）。每次我们将一个可部署项推向一个环境时，我们希望测试它能按照我们的预期成功处理请求。
- en: If the API has any dependencies (e.g., a database, a remote bucket, an external
    service), these tests also serve as a [*broad integration test*](https://oreil.ly/KXecM)
    to test that these dependencies are working as expected in a real environment.
    Post-deployment tests focus on verifying that the interfaces between components
    (e.g., API, ML model, database) are working fine in a real environment.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 如果API有任何依赖项（例如数据库、远程存储桶、外部服务），这些测试还充当一个[*广泛的集成测试*](https://oreil.ly/KXecM)，以测试这些依赖项在真实环境中是否按预期工作。部署后测试侧重于验证组件之间的接口（例如API、ML模型、数据库）在真实环境中是否正常工作。
- en: 'Post-deployment tests are *critical* because they can help to spot bugs *right
    after* we’ve deployed a change to a preproduction environment, and *before* we
    deploy our software to production. This brings a whole host of benefits: time
    saved from tedious manual testing, and reduced production defects (which means
    less time wasted triaging and resolving stressful production incidents). We typically
    also run the tests right after deploying a change to production to verify that
    the production deployment has succeeded.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 部署后测试非常关键，因为它们可以帮助在我们将更改部署到预生产环境后立即发现错误，并在将软件部署到生产环境之前。这带来了一系列好处：节省了从繁琐的手动测试中节省的时间，减少了生产缺陷（这意味着减少了浪费时间进行分析和解决压力型生产事故）。通常，我们还会在将更改部署到生产环境后立即运行这些测试，以验证生产部署是否成功。
- en: Post-deployment tests also are essential for *continuous deployment*, which
    is the practice of deploying every change to production if all stages of your
    CI pipeline are green. The ability to do continuous deployment is fundamental
    in helping your team become a *high performer*, as defined by [DORA (DevOps Research
    and Assessment) metrics](https://oreil.ly/60Dwo) (more on this in [Chapter 9](ch09.html#mlops_and_continuous_delivery_for_ml_le)).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 部署后测试对于*持续部署*也至关重要，如果您的CI流水线的所有阶段都通过，则每次更改都会部署到生产环境。如果您的团队希望成为[DORA（DevOps研究和评估）指标](https://oreil.ly/60Dwo)定义的*高绩效团队*，持续部署能力是非常基础的。
- en: How do I write these tests?
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何编写这些测试？
- en: You should be careful not to duplicate the logic from your API tests, or you’ll
    end up maintaining and updating two sets of tests. You have tested your API thoroughly
    in your API tests, covering all code paths and edge cases. If the API has other
    dependencies (e.g., a database), your API tests could include logic to mock and
    stub responses to simulate errors, and you can’t do that in these tests, which
    are running against a real environment.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 您应当注意不要从API测试中复制逻辑，否则您将不得不维护和更新两套测试。您已经在API测试中彻底测试了您的API，涵盖了所有的代码路径和边缘情况。如果API有其他依赖项（例如数据库），则您的API测试可以包括模拟和存根响应的逻辑，以模拟错误，而这些测试无法做到这一点，因为它们在真实环境中运行。
- en: 'In post-deployment tests, you simply make requests to the subject under test
    (i.e., the API, which has been deployed to an environment) and verify that you
    received the response you expected, as shown below:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署后测试中，您只需向被测试对象（即已部署到环境中的API）发出请求，并验证您收到了预期的响应，如下所示：
- en: '[PRE11]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![](assets/1.png)](#code_id_5_21)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/1.png)](#code_id_5_21)'
- en: The target of your request is an API endpoint in a real environment. This variable
    can also be read from an environment variable, so that you can reuse the same
    test in multiple environments (e.g., preproduction, production). If your API is
    a public API, you will likely need some authentication and authorization using
    a test account. For simplicity, we have omitted these details from the example,
    but it can be done in the [test setup steps](https://docs.pytest.org/en/6.2.x/xunit_setup.html).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 您请求的目标是真实环境中的API端点。这个变量也可以从环境变量中读取，这样您可以在多个环境中重用相同的测试（例如预生产环境、生产环境）。如果您的API是公共API，则可能需要使用测试帐户进行一些身份验证和授权。为简单起见，我们已从示例中省略了这些细节，但可以在[测试设置步骤](https://docs.pytest.org/en/6.2.x/xunit_setup.html)中完成。
- en: '[![](assets/2.png)](#code_id_5_22)'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/2.png)](#code_id_5_22)'
- en: Notice how the test names look similar to the preceding local API tests? The
    local API tests can give you some ideas of what you want to test in the real API,
    though you will need to apply some discretion to ensure that you’re not retesting
    things that have already been tested in the local API tests.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 注意测试名称看起来与前面的本地 API 测试相似？本地 API 测试可以给你一些关于你希望在真实 API 中测试的想法，尽管你需要谨慎地应用以确保不重复测试已在本地
    API 测试中测试过的内容。
- en: '[![](assets/3.png)](#code_id_5_23)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/3.png)](#code_id_5_23)'
- en: We use the `requests` package to make a request to a real API endpoint.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `requests` 包向真实的 API 端点发送请求。
- en: '[![](assets/4.png)](#code_id_5_24)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](assets/4.png)](#code_id_5_24)'
- en: Speaking of not retesting things, we didn’t replicate the assertion from our
    local API tests because it would be redundant. If we changed our API’s behavior,
    we would need to update it in two places. In this example, we simply asserted
    that we received a positive HTTP status code (in your context, you would specify
    whatever you constitute to be a correct and successful handling of this request
    in a real environment).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到不重复测试的事情，我们没有复制本地 API 测试中的断言，因为那样会显得多余。如果我们改变了 API 的行为，我们需要在两个地方更新它。在这个例子中，我们只断言我们收到了一个正常的
    HTTP 状态码（在你的上下文中，你会指定这个请求在真实环境中的正确和成功的处理方式）。
- en: Give yourself a big pat on your back! By this point in the chapter, you’ve learned
    how to test many components that are typically under-tested in ML systems. With
    this knowledge, you can save your team days and weeks of time and energy from
    manual testing and fixing defects that slip through the cracks of manual testing.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 为自己鼓掌！通过这一章，你已经学会了如何测试许多通常在机器学习系统中被低估的组件。凭借这些知识，你可以为团队节省数天甚至数周的手动测试和修复因手动测试中疏漏而产生的缺陷所耗费的时间和精力。
- en: Conclusion
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'Let’s recap what we’ve learned in this chapter. We’ve learned:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下本章学到的内容。我们学到了：
- en: '*Why* automated tests are essential for teams that want to iterate quickly,
    safely, and reliably'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*为什么* 对于希望快速、安全和可靠迭代的团队来说，自动化测试至关重要'
- en: That if we make mistakes while coding (as humans inevitably do), tests act as
    a safety net to catch us as we fall, instead of letting us crash painfully into
    errors in production
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们在编码时犯错（正如人类不可避免地做），测试就像一个安全网，能够在我们摔倒时抓住我们，而不是让我们痛苦地撞向生产中的错误。
- en: The benefits of automated testing (e.g., reduced cognitive load, ease of refactoring,
    improved team velocity), based on our experience in using them when delivering
    ML solutions across various industries
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于我们在各个行业交付机器学习解决方案时的经验，自动化测试的好处（例如减少认知负担、重构的便捷性、团队速度的提高）
- en: The rationale for *not* writing automated tests in ML systems (we challenged
    the validity of that reasoning, given the testing knowledge, techniques, and tools
    that we have today)
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不在机器学习系统中写自动化测试的理由（鉴于我们今天拥有的测试知识、技术和工具，我们挑战了这种理由的有效性）
- en: The *what:* the building blocks for a comprehensive test strategy across a breadth
    of components that can be tested (software and ML models)
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*什么:* 一个全面的测试策略的构建模块，覆盖可以测试的多种组件（软件和机器学习模型）'
- en: The *how:* how to write an automated test, characteristics of useful and dependable
    tests, and pitfalls to avoid
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如何:* 如何编写自动化测试，有用和可靠测试的特征，以及要避免的陷阱'
- en: 'Now it’s your turn to put your knowledge into practice. Reflecting on your
    own ML project, consider:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 现在轮到你将知识付诸实践了。反思你自己的机器学习项目，考虑：
- en: Where does your team spend the most time on manual testing?
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的团队在手动测试上花费最多时间的地方是哪里？
- en: Are there any low-hanging fruits (currently untested areas) in your codebase
    that could benefit from automated tests?
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的代码库中是否有任何低 hanging fruits（当前未经测试的区域）可以受益于自动化测试？
- en: 'Can you write and commit one or more automated tests to address these low-hanging
    fruits and significant time sinks? (Hint: refer to the [code-along repository](https://oreil.ly/Hkgzc)
    for examples of how to write and run tests.)'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能写并提交一个或多个自动化测试来解决这些低 hanging fruits 和显著的时间浪费吗？（提示：参考 [code-along 代码库](https://oreil.ly/Hkgzc)
    以获取编写和运行测试的示例。）
- en: In the next chapter, we’ll look at how you can automate ML model tests, and
    practices that complement ML model testing in ML systems.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看看如何自动化机器学习模型的测试，以及在机器学习系统中测试机器学习模型的实践。
- en: ^([1](ch05.html#ch01fn25-marker)) Documentation is essential in any software,
    but the component-level or function-level documentation that tests give us serve
    a different purpose from other types of documentation (e.g., [model cards](https://oreil.ly/b-qIC),
    service one-pagers).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch05.html#ch01fn25-marker)) 文档在任何软件中都是必不可少的，但是测试提供的组件级或功能级文档与其他类型的文档（例如[model
    cards](https://oreil.ly/b-qIC)，服务单页）有着不同的目的。
- en: ^([2](ch05.html#ch01fn26-marker)) A user story is a tool used in agile software
    development to capture a description of a software feature from an end-user perspective.
    For more details, see [Chapter 2](ch02.html#product_and_delivery_practices_for_ml_t).
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch05.html#ch01fn26-marker)) 用户故事是敏捷软件开发中用来捕获软件功能描述的工具。更多详情请参见 [第 2 章](ch02.html#product_and_delivery_practices_for_ml_t)。
- en: ^([3](ch05.html#ch01fn27-marker)) For a refresher on what batect is and how
    to set it up, have a look at [Chapter 4](ch04.html#effective_dependency_management_in_prac).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch05.html#ch01fn27-marker)) 如果你需要回顾一下 batect 是什么以及如何设置它，请查看 [第 4 章](ch04.html#effective_dependency_management_in_prac)。
