- en: Chapter 7\. Training a Machine Learning Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 7 章。训练一个机器学习模型
- en: In [Chapter 5](ch05.xhtml#data_and_feature_prep), we learned how to prepare
    and clean up our data, which is the first step in the machine learning pipeline.
    Now let’s take a deep dive into how to use our data to train a machine learning
    model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第五章](ch05.xhtml#data_and_feature_prep) 中，我们学习了如何准备和清理我们的数据，这是机器学习流程中的第一步。现在让我们深入探讨如何利用我们的数据来训练一个机器学习模型。
- en: Training is often considered the “bulk” of the work in machine learning. Our
    goal is to create a function (the “model”) that can accurately predict results
    that it hasn’t seen before. Intuitively, model training is very much like how
    humans learn a new skill—we observe, practice, correct our mistakes, and gradually
    improve. In machine learning, we start with an initial model that might not be
    very good at its job. We then put the model through a series of training steps,
    where training data is fed to the model. At each training step, we compare the
    prediction results produced by our model with the true results, and see how well
    our model performed. We then tinker with the parameters to this model (for example,
    by changing how much weight is given to each feature) to attempt to improve the
    model’s accuracy. A good model is one that makes accurate predictions without
    overfitting to a specific set of inputs.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 训练通常被认为是机器学习中的“大部分”工作。我们的目标是创建一个函数（即“模型”），能够准确预测它之前没有见过的结果。直观地说，模型训练非常像人类学习新技能的方式——我们观察、练习、纠正错误，并逐渐改进。在机器学习中，我们从一个可能不太擅长其工作的初始模型开始。然后，我们将模型通过一系列的训练步骤，将训练数据馈送给模型。在每个训练步骤中，我们将模型产生的预测结果与真实结果进行比较，并查看模型的表现如何。然后，我们调整这个模型的参数（例如，通过改变每个特征所赋予的权重），试图提高模型的准确性。一个好的模型是能够在不过度拟合特定输入集的情况下进行准确预测的模型。
- en: In this chapter, we are going to learn how to train machine learning models
    using two different libraries—TensorFlow and Scikit-learn. TensorFlow has native,
    first-class support in Kubeflow, while Scikit-learn does not. But as we will see
    in this chapter, both libraries can be easily integrated with Kubeflow. We’ll
    demonstrate how you can experiment with models in Kubeflow’s notebooks, and how
    you can deploy these models to production environments.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何使用两种不同的库——TensorFlow 和 Scikit-learn 来训练机器学习模型。TensorFlow 在 Kubeflow
    中有原生的一流支持，而 Scikit-learn 则没有。但正如我们在本章中所看到的，这两个库都可以很容易地集成到 Kubeflow 中。我们将演示如何在
    Kubeflow 的笔记本中对模型进行实验，以及如何将这些模型部署到生产环境中。
- en: Building a Recommender with TensorFlow
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 构建推荐系统
- en: Let us first take a look at TensorFlow—an open source framework for machine
    learning developed by Google. It is currently one of the most popular libraries
    for machine learning–powered applications, in particular for implementing deep
    learning. TensorFlow has great support for computational tasks on a variety of
    hardware, including CPUs, GPUs, and TPUs. We chose TensorFlow for this tutorial
    because its high-level APIs are user-friendly and abstract away many of the gory
    details.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先来了解 TensorFlow——这是一个由 Google 开发的机器学习开源框架。它目前是实现深度学习的最流行库之一，特别是在机器学习驱动的应用程序中。TensorFlow
    对于包括 CPU、GPU 和 TPU 在内的各种硬件的计算任务有很好的支持。我们选择 TensorFlow 进行这个教程是因为它的高级 API 用户友好，并且抽象了许多复杂的细节。
- en: 'Let’s get acquainted with TensorFlow with a simple tutorial. In [Chapter 1](ch01.xhtml#who_is_kubeflow_for_ch)
    we introduced our case studies, one of which is a product recommendation system
    for customers. In this chapter, we will be implementing this system with TensorFlow.
    Specifically, we will do two things:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个简单的教程来熟悉 TensorFlow。在 [第一章](ch01.xhtml#who_is_kubeflow_for_ch) 中，我们介绍了我们的案例研究之一，即面向客户的产品推荐系统。在本章中，我们将使用
    TensorFlow 来实现这个系统。具体来说，我们将做两件事情：
- en: Use TensorFlow to train a model for product recommendation.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 来训练一个产品推荐模型。
- en: Use Kubeflow to wrap the training code and deploy it to a production cluster.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Kubeflow 将训练代码封装并部署到生产集群中。
- en: TensorFlow’s high-level Keras API makes it relatively easy to implement our
    model. In fact, the bulk of the model can be implemented with less than 50 lines
    of Python code.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 的高级 Keras API 使得实现我们的模型相对容易。事实上，大部分模型可以用不到 50 行 Python 代码来实现。
- en: Tip
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Keras is the high-level TensorFlow API for deep learning models. It has a user-friendly
    interface and high extensibility. As an added bonus, Keras has many common neural
    network implementations straight out of the box, so you can get a model up and
    running right away.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 是用于深度学习模型的高级 TensorFlow API。它具有用户友好的界面和高可扩展性。此外，Keras 还预置了许多常见的神经网络实现，因此您可以立即启动一个模型。
- en: Let’s begin by selecting a model for our recommender. We begin with a simple
    assumption—that if two people (Alice and Bob) have similar opinions on a set of
    products, then they are also more likely to think similarly about other products.
    In other words, Alice is more likely to have the same preferences as Bob than
    would a randomly chosen third person. Thus, we can build a recommendation model
    using just the users’ purchase history. This is the idea of collaborative filtering—we
    collect preferential information from many users (hence “collaborative”) and use
    this data to make selective predictions (hence “filtering”).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先选择我们的推荐系统模型。我们从一个简单的假设开始——如果两个人（Alice 和 Bob）对一组产品有相似的意见，那么他们在其他产品上的看法也更可能相似。换句话说，Alice
    更有可能与 Bob 拥有相同的偏好，而不是随机选择的第三个人。因此，我们可以仅使用用户的购买历史来构建推荐模型。这就是协同过滤的理念——我们从许多用户（因此称为“协同”）那里收集偏好信息，并使用这些数据进行选择性预测（因此称为“过滤”）。
- en: 'To build this recommender model, we will need a few things:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建这个推荐模型，我们需要几件事：
- en: Users’ purchasing history
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 用户的购买历史
- en: We will use the example input data [from this GitHub repo](https://oreil.ly/F-8rS).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用来自[此 GitHub 仓库的示例输入数据](https://oreil.ly/F-8rS)。
- en: Data storage
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据存储
- en: To make sure that our model works across different platforms, we’ll use MinIO
    as the storage system.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们的模型能够跨不同的平台工作，我们将使用 MinIO 作为存储系统。
- en: Training model
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型
- en: The implementation that we are using is based on a [Keras model on GitHub](https://oreil.ly/hTGQf).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的实现基于[Github 上的 Keras 模型](https://oreil.ly/hTGQf)。
- en: We will first experiment with this model using Kubeflow’s notebook servers,
    and then deploy the training job to our cluster using Kubeflow’s TFJob APIs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用 Kubeflow 的笔记本服务器对该模型进行实验，然后使用 Kubeflow 的 TFJob API 将训练工作部署到我们的集群上。
- en: Getting Started
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 入门
- en: Let’s get started by downloading the prerequisites. You can download the notebook
    from [this book’s GitHub repo](https://oreil.ly/Kubeflow_for_ML_ch07). To run
    the notebook, you will need a running Kubeflow cluster that includes a MinIO service.
    Review [“Support Components”](ch03.xhtml#Supp_components) to configure MinIO.
    Make sure that MinIO Client (“mc”) is also installed.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从下载先决条件开始。您可以从[本书的 GitHub 仓库](https://oreil.ly/Kubeflow_for_ML_ch07)下载笔记本。要运行笔记本，您需要一个运行中包含
    MinIO 服务的 Kubeflow 集群。请查看[“支持组件”](ch03.xhtml#Supp_components)来配置 MinIO。确保还安装了
    MinIO 客户端（“mc”）。
- en: 'We also need to prepare the data to facilitate training: you can download the
    user purchase history data from [this GitHub site](https://oreil.ly/BK6XS). Then
    you can use MinIO Client to create the storage objects, as shown in [Example 7-1](#set_up_prerequisites).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要准备数据以便进行训练：您可以从[这个 GitHub 站点](https://oreil.ly/BK6XS)下载用户购买历史数据。然后，您可以使用
    MinIO 客户端创建存储对象，如[示例 7-1](#set_up_prerequisites) 中所示。
- en: Example 7-1\. Setting up prerequisites
  id: totrans-24
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-1. 设置先决条件
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Starting a New Notebook Session
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动新的笔记本会话
- en: Now let’s start by creating a new notebook. You can do this by navigating to
    the “Notebook Servers” panel in your Kubeflow dashboard, then clicking “New Server”
    and following the instructions. For this example, we use the `tensorFlow-1.15.2-notebook-cpu:1.0`
    image.^([1](ch07.xhtml#idm45831173117976))
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过创建一个新的笔记本开始。您可以通过在 Kubeflow 仪表板的“笔记本服务器”面板中导航，然后点击“New Server”并按照说明操作来完成此操作。对于本示例，我们使用`tensorFlow-1.15.2-notebook-cpu:1.0`镜像。^([1](ch07.xhtml#idm45831173117976))
- en: When the notebook server starts up, click the “Upload” button in the top right
    corner and upload the `Recommender_Kubeflow.ipynb` file. Click the file to start
    a new session.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当笔记本服务器启动时，请点击右上角的“上传”按钮并上传`Recommender_Kubeflow.ipynb`文件。单击文件以启动新会话。
- en: The first few sections of the code involve importing libraries and reading the
    training data from MinIO. Then we normalize the input data so that we are ready
    to start training. This process is called feature preparation, which we discussed
    in [Chapter 5](ch05.xhtml#data_and_feature_prep). In this chapter we’ll focus
    on the model training part of the exercise.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的前几部分涉及导入库并从 MinIO 中读取训练数据。然后，我们对输入数据进行归一化处理，以便准备开始训练。这个过程称为特征准备，我们在[第 5 章](ch05.xhtml#data_and_feature_prep)中讨论过。在本章中，我们将专注于练习的模型训练部分。
- en: TensorFlow Training
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow 训练
- en: Now that our notebook is set up and the data is prepared, we can create a TensorFlow
    session, as shown in [Example 7-2](#creating_tensorflow_session).^([2](ch07.xhtml#idm45831173106920))
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的笔记本已设置并准备好数据，我们可以创建一个 TensorFlow 会话，如[示例 7-2](#creating_tensorflow_session)所示。^([2](ch07.xhtml#idm45831173106920))
- en: Example 7-2\. Creating a TensorFlow session
  id: totrans-32
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-2\. 创建 TensorFlow 会话
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For the model class, we use the code in [Example 7-3](#DeepCollaborativeFiltering_learning)
    for collaborative filtering.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模型类，我们使用协作过滤的[示例 7-3](#DeepCollaborativeFiltering_learning)中的代码。
- en: Example 7-3\. DeepCollaborativeFiltering learning
  id: totrans-35
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-3\. 深度协同过滤学习
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This is the basis of our model class. It includes a constructor with some code
    to instantiate the collaborative filtering model using Keras APIs, and a “rate”
    function that we can use to make a prediction using our model—namely, what rating
    a customer would give to a particular product.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们模型类的基础。它包括一个构造函数，其中包含一些用于使用 Keras API 实例化协作过滤模型的代码，以及一个“rate”函数，我们可以使用我们的模型进行预测——即客户对特定产品的评分。
- en: We can create an instance of the model, as in [Example 7-4](#Model_creation_ex).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像[示例 7-4](#Model_creation_ex)那样创建一个模型实例。
- en: Example 7-4\. Model creation
  id: totrans-39
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-4\. 模型创建
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now we are ready to start training our model. We can do this by setting a few
    hyperparameters, as shown in [Example 7-5](#Settg_Training_config).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备开始训练我们的模型。我们可以通过设置一些超参数来实现这一点，如[示例 7-5](#Settg_Training_config)所示。
- en: Example 7-5\. Setting Training configuration
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-5\. 设置训练配置
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: These are hyperparameters that control the training process. They are typically
    set before training begins, unlike model parameters, which are learned from the
    training process. Setting the right values for hyperparameters can significantly
    impact the effectiveness of your model. For now, let’s just set some default values
    for them. In [Chapter 10](ch10.xhtml#hyperparameter_tuning) we’ll look at how
    to use Kubeflow to tune hyperparameters.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是控制训练过程的超参数。它们通常在训练开始之前设置，不像模型参数那样是从训练过程中学习的。设置正确的超参数值可以显著影响模型的有效性。目前，让我们为它们设置一些默认值。在[第
    10 章](ch10.xhtml#hyperparameter_tuning)中，我们将学习如何使用 Kubeflow 调整超参数。
- en: We are now ready to run the training code. See [Example 7-6](#Fitting_model_ex).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已准备好运行训练代码。查看[示例 7-6](#Fitting_model_ex)。
- en: Example 7-6\. Fitting model
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-6\. 拟合模型
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Once the training is complete, you should see results like in [Example 7-7](#Model_training_results_ex).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，你应该能看到类似于[示例 7-7](#Model_training_results_ex)中的结果。
- en: Example 7-7\. Model training results
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-7\. 模型训练结果
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Congratulations: you’ve successfully trained a TensorFlow model in a Jupyter
    notebook. But we’re not quite done yet—to make use of our model later, we should
    first export it. You can do this by setting up the export destination using MinIO
    Client, as shown in [Example 7-8](#Setting_export_dest).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你：你已成功在 Jupyter 笔记本中训练了一个 TensorFlow 模型。但我们还没有完成——为了以后能够使用我们的模型，我们应该先导出它。你可以通过设置使用
    MinIO Client 的导出目的地来完成此操作，如[示例 7-8](#Setting_export_dest)所示。
- en: Example 7-8\. Setting export destination
  id: totrans-52
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-8\. 设置导出目的地
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Once you have set up your export destination, you can then export the model,
    as in [Example 7-9](#Exporting_model_example).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设置了导出目的地，你可以像[示例 7-9](#Exporting_model_example)那样导出模型。
- en: Example 7-9\. Exporting the model
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-9\. 导出模型
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now we’re ready to use this model to serve predictions, as we’ll learn in [Chapter 8](ch08.xhtml#inference_ch).
    But before that, let’s look at how to deploy this training job using Kubeflow.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备使用这个模型来提供预测，正如我们将在[第 8 章](ch08.xhtml#inference_ch)中学到的那样。但在此之前，让我们看看如何使用
    Kubeflow 部署这个训练作业。
- en: Deploying a TensorFlow Training Job
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署 TensorFlow 训练任务
- en: So far we have done some TensorFlow training using Jupyter notebooks, which
    is a great way to prototype and experiment. But soon we may discover that our
    prototype is insufficient—perhaps we need to refine the model using more data,
    or perhaps we need to train the model using specialized hardware. Sometimes we
    may even need to continuously run the training job because our model is constantly
    evolving. Perhaps most importantly, our model has to be deployable to production,
    where it can serve actual customer requests.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经使用 Jupyter 笔记本进行了一些 TensorFlow 训练，这是原型设计和实验的好方法。但很快我们可能会发现我们的原型不足——也许我们需要使用更多数据来完善模型，或者我们需要使用专用硬件来训练模型。有时候，我们甚至可能需要持续运行训练作业，因为我们的模型在不断发展。或许更重要的是，我们的模型必须能够部署到生产环境中，以便为实际的客户请求提供服务。
- en: In order to handle these requirements, our training code must be easily packageable
    and deployable to various different environments. One of the ways to achieve this
    is to use TFJob—a Kubernetes custom resource (implemented using Kubernetes operator
    `tf-operator`) that you can use to run TensorFlow training jobs on Kubernetes.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理这些需求，我们的训练代码必须易于打包和部署到不同的环境中。实现这一点的一种方法是使用 TFJob——一个 Kubernetes 自定义资源（使用
    Kubernetes 操作者 `tf-operator` 实现），您可以使用它在 Kubernetes 上运行 TensorFlow 训练作业。
- en: We’ll start by deploying our recommender as a single-container TFJob. Since
    we already have a Python notebook, exporting it as a Python file is fairly simple—just
    select “File,” then “Download as” and select “Python.” This should save your notebook
    as a ready-to-execute Python file.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先将我们的推荐器部署为单容器 TFJob。由于我们已经有一个 Python 笔记本，将其导出为 Python 文件非常简单——只需选择“文件”，然后选择“另存为”，然后选择“Python”。这将保存您的笔记本作为一个可以立即执行的
    Python 文件。
- en: The next step is to package the training code in a container. This can be done
    with the Dockerfile, as seen in [Example 7-10](#TFJob_Dockerfi).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤是将训练代码打包到容器中。可以通过 Dockerfile 完成，就像在[示例 7-10](#TFJob_Dockerfi)中看到的那样。
- en: Example 7-10\. TFJob Dockerfile
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-10\. TFJob Dockerfile
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we need to build this container along with its required libraries, and
    push the container image to a repository:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要将此容器及其所需的库一起构建，并将容器映像推送到存储库：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Once that’s done, we are ready to create the specification for a TFJob, as in
    [Example 7-11](#TFJob_exam).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们准备创建 TFJob 的规范，就像在[示例 7-11](#TFJob_exam)中所示。
- en: Example 7-11\. Single-container TFJob example
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-11\. 单容器 TFJob 示例
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](Images/1.png)](#co_training_a_machine_learning_model_CO1-1)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_training_a_machine_learning_model_CO1-1)'
- en: The `apiVersion` field specifies which version of the TFJob custom resource
    you are using. The corresponding version (in this case v1) needs to be installed
    in your Kubeflow cluster.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`apiVersion`字段指定您正在使用的 TFJob 自定义资源的版本。需要在您的 Kubeflow 集群中安装相应的版本（在本例中为 v1）。'
- en: '[![2](Images/2.png)](#co_training_a_machine_learning_model_CO1-2)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_training_a_machine_learning_model_CO1-2)'
- en: The `kind` field identifies the type of the custom resource—in this case a TFJob.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`kind`字段标识自定义资源的类型——在本例中是 TFJob。'
- en: '[![3](Images/3.png)](#co_training_a_machine_learning_model_CO1-3)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_training_a_machine_learning_model_CO1-3)'
- en: The `metadata` field is common to all Kubernetes objects and is used to uniquely
    identify the object in the cluster—you can add fields like name, namespace, and
    labels here.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`metadata`字段适用于所有 Kubernetes 对象，并用于在集群中唯一标识对象——您可以在此处添加名称、命名空间和标签等字段。'
- en: '[![4](Images/4.png)](#co_training_a_machine_learning_model_CO1-4)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_training_a_machine_learning_model_CO1-4)'
- en: The most important part of the schema is `tfReplicaSpecs`. This is the actual
    description of your TensorFlow training cluster and its desired state. For this
    example, we just have a single worker replica. In the following section, we’ll
    examine this field further.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 架构中最重要的部分是`tfReplicaSpecs`。这是您的 TensorFlow 训练集群及其期望状态的实际描述。在此示例中，我们只有一个工作节点副本。在接下来的部分中，我们将进一步检查这个字段。
- en: 'There are a few other optional configurations for your TFJob, including:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您的 TFJob 还有一些其他可选配置，包括：
- en: '`activeDeadlineSeconds`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`activeDeadlineSeconds`'
- en: How long to keep this job active before the system can terminate it. If this
    is set, the system will kill the job after the deadline expires.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在系统可以终止作业之前保持作业活动的时间。如果设置了此项，则系统将在截止日期到期后终止作业。
- en: '`backoffLimit`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`backoffLimit`'
- en: How many times to keep retrying this job before marking it as failed. For example,
    setting this to 3 means that if a job fails 3 times, the system will stop retrying.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将作业标记为失败之前重试此作业的次数。例如，将其设置为 3 意味着如果作业失败 3 次，系统将停止重试。
- en: '`cleanPodPolicy`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`cleanPodPolicy`'
- en: Configures whether or not to clean up the Kubernetes pods after the job completes.
    Setting this policy can be useful to keep pods for debugging purposes. This can
    be set to All (all pods are cleaned up), Running (only running pods are cleaned
    up), or None (no pods are cleaned up).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 配置是否在作业完成后清理Kubernetes pods。设置此策略可以用于保留用于调试的pods。可以设置为All（清理所有pods）、Running（仅清理运行中的pods）或None（不清理pods）。
- en: Now deploy the TFJob to your cluster, as in [Example 7-12](#Depl_TFJob).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将TFJob部署到您的集群中，就像[示例 7-12](#Depl_TFJob)中所示。
- en: Example 7-12\. Deploying TFJob
  id: totrans-86
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-12\. 部署TFJob
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You can monitor the status of the TFJob with the command in [Example 7-13](#View_state_TFJob).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令监视TFJob的状态，如[示例 7-13](#View_state_TFJob)。
- en: Example 7-13\. Viewing the state of TFJob
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-13\. 查看TFJob的状态
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This should display something like [Example 7-14](#TF_Recommender_job_descr_ex).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该显示类似于[示例 7-14](#TF_Recommender_job_descr_ex)的内容。
- en: Example 7-14\. TF Recommender job description
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-14\. TF推荐作业描述
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note that the status field contains a list of job conditions, which represent
    when the job transitioned into each state. This is useful for debugging—if the
    job failed, the reason for the job’s failure would appear here.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，状态字段包含一系列作业条件，表示作业转换到每个状态的时间。这对调试非常有用——如果作业失败，作业失败的原因将在此处显示。
- en: So far we have trained a fairly simple and straightforward model with a modest
    number of training samples. In real life, learning more complex models may require
    significantly more training samples or model parameters. Such models can be too
    large and computationally complex to be handled by one machine. This is where
    distributed training comes in.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用了一些训练样本数量适中的相对简单和直接的模型进行了训练。在实际生活中，学习更复杂的模型可能需要大量训练样本或模型参数。这样的模型可能过大且计算复杂，无法由单台机器处理。这就是分布式训练发挥作用的地方。
- en: Distributed Training
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式训练
- en: By now we’ve deployed a single-worker TensorFlow job with Kubeflow. It is called
    “single-worker” because everything from hosting the data to executing the actual
    training steps is done on a single machine. However, as models become more complex,
    a single machine is often insufficient—we may need to distribute the model or
    the training samples over several networked machines. TensorFlow supports a distributed
    training mode, in which training is performed in parallel over several worker
    nodes.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经在Kubeflow上部署了一个单工作节点的TensorFlow作业。它被称为“单工作节点”，因为从托管数据到执行实际训练步骤的所有工作都在单台机器上完成。然而，随着模型变得更复杂，单台机器通常不够用——我们可能需要将模型或训练样本分布到多台联网机器上。TensorFlow支持分布式训练模式，其中训练在多个工作节点上并行执行。
- en: 'Distributed training typically comes in two flavors: data parallelism and model
    parallelism. In data parallelism, the training data is partitioned into chunks,
    and the same training code runs on each chunk. At the end of each training step,
    each worker communicates its updates to all other nodes. Model parallelism is
    the opposite—the same training data is used in all workers, but the model itself
    is partitioned. At the end of each step, each worker is responsible for synchronizing
    the shared parts of the model.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式训练通常有两种方式：数据并行和模型并行。在数据并行中，训练数据被分成多个块，每个块上运行相同的训练代码。在每个训练步骤结束时，每个工作节点向所有其他节点通信其更新。模型并行则相反——所有工作节点使用相同的训练数据，但模型本身被分割。在每个步骤结束时，每个工作节点负责同步模型的共享部分。
- en: The TFJob interface supports multiworker distributed training. Conceptually,
    a TFJob is a logical grouping of all resources related to a training job, including
    *pods* and *services*. In Kubeflow, each replicated worker or parameter server
    is scheduled on its own single-container pod. In order for the replicas to synchronize
    with each other, each replica needs to expose itself through an endpoint, which
    is a Kubernetes internal service. Grouping these resources logically under a parent
    resource (which is the TFJob) allows these resources to be co-scheduled and garbage
    collected together.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: TFJob接口支持多工作节点分布式训练。在概念上，TFJob是与训练作业相关的所有资源的逻辑分组，包括*pods*和*services*。在Kubeflow中，每个复制的工作节点或参数服务器都计划在自己的单容器pod上。为了使副本能够相互同步，每个副本都需要通过端点暴露自己，这是一个Kubernetes内部服务。将这些资源在父资源（即TFJob）下逻辑地分组允许这些资源一起协同调度和垃圾回收。
- en: In this section we’ll deploy a simple MNIST example with distributed training.
    The TensorFlow training code is provided for you at [this GitHub repo](https://oreil.ly/ySztV).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将部署一个简单的 MNIST 示例，并进行分布式训练。TensorFlow 训练代码已为您提供，可以在 [此 GitHub 仓库](https://oreil.ly/ySztV)
    中找到。
- en: Let’s take a look at the YAML file for the distributed TensorFlow job in [Example 7-15](#distrib_TFJob).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下分布式 TensorFlow 作业的 YAML 文件，位于 [示例 7-15](#distrib_TFJob) 中。
- en: Example 7-15\. Distributed TFJob example
  id: totrans-102
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-15\. 分布式 TFJob 示例
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Note that the `tfReplicaSpecs` field now contains a few different replica types.
    In a typical TensorFlow training cluster, there are a few possible possibilities:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`tfReplicaSpecs` 字段现在包含几种不同的副本类型。在典型的 TensorFlow 训练集群中，有几种可能的情况：
- en: Chief
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点
- en: Responsible for orchestrating computational tasks, emitting events, and checkpointing
    the model
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 负责编排计算任务、发出事件并对模型进行检查点处理
- en: Parameter servers
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 参数服务器
- en: Provide a distributed data store for the model parameters
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为模型参数提供分布式数据存储
- en: Worker
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点
- en: This is where the computations and training actually happen. When a chief node
    is not explicitly defined (as in the preceding example), one of the workers acts
    as the chief node.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这是实际进行计算和训练的地方。当主节点未明确定义（如前述示例中），其中一个工作节点充当主节点。
- en: Evaluator
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 评估者
- en: The evaluators can be used to compute evaluation metrics as the model is trained.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 评估者可以用于在训练模型时计算评估指标。
- en: 'Note also that a replica spec contains a number of properties that describe
    its desired state:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，副本规范包含多个属性，描述其期望的状态：
- en: '`replicas`'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`replicas`'
- en: How many replicas should be spawned for this replica type
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 应为此副本类型生成多少副本
- en: '`template`'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`template`'
- en: A `PodTemplateSpec` that describes the pod to create for each replica
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 描述每个副本要创建的 pod 的 `PodTemplateSpec`
- en: '`restartPolicy`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '`restartPolicy`'
- en: 'Determines whether pods will be restarted when they exit. The allowed values
    are as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 确定 pod 退出时是否重新启动。允许的值如下：
- en: '`Always`'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`Always`'
- en: Means the pod will always be restarted. This policy is good for parameter servers
    since they never exit and should always be restarted in the event of failure.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 意味着 pod 将始终重新启动。这个策略适用于参数服务器，因为它们永不退出，应在失败事件中始终重新启动。
- en: '`OnFailure`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`OnFailure`'
- en: Means the pod will be restarted if the pod exits due to failure. A nonzero exit
    code indicates a failure. An exit code of 0 indicates success and the pod will
    not be restarted. This policy is good for the chief and workers.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 意味着如果 pod 由于失败而退出，将重新启动 pod。非零退出代码表示失败。退出代码为 0 表示成功，pod 将不会重新启动。这个策略适用于主节点和工作节点。
- en: '`ExitCode`'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`ExitCode`'
- en: 'Means the restart behavior is dependent on the exit code of the TensorFlow
    container as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 意味着重新启动行为取决于 TensorFlow 容器的退出代码如下：
- en: 0 indicates the process completed successfully and will not be restarted.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示进程成功完成，将不会重新启动。
- en: 1–127 indicates a permanent error and that the container will not be restarted.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1–127 表示永久错误，容器将不会重新启动。
- en: 128–255 indicates a retryable error and the container will be restarted. This
    policy is good for the chief and workers.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 128–255 表示可重试错误，容器将被重新启动。这个策略适用于主节点和工作节点。
- en: '`Never`'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`Never`'
- en: This means pods that terminate will never be restarted. This policy should rarely
    be used, because Kubernetes will terminate pods for any number of reasons (e.g.,
    node becomes unhealthy) and this will prevent the job from recovering.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 意味着终止的 pod 将永远不会重新启动。这个策略应该很少使用，因为 Kubernetes 可能会因各种原因（如节点变得不健康）而终止 pod，并且这会阻止作业恢复。
- en: 'Once you have the TFJob spec written, deploy it to your Kubeflow cluster:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 编写完 TFJob 规范后，将其部署到您的 Kubeflow 集群：
- en: '[PRE16]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Monitoring the job status is similar to a single-container job:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 监控作业状态类似于单容器作业：
- en: '[PRE17]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This should output something like [Example 7-16](#TFJob_execution_result_ex).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该输出类似于 [示例 7-16](#TFJob_execution_result_ex) 的内容。
- en: Example 7-16\. TFJob execution result
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-16\. TFJob 执行结果
- en: '[PRE18]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Notice that the `Replica Statuses` field shows a breakdown of status by each
    replica type. The TFJob is successfully completed when all of its workers complete.
    If any worker has failed, then the TFJob’s status would be failed as well.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`Replica Statuses` 字段显示了每个副本类型的状态细分。当所有工作节点都完成时，TFJob 将成功完成。如果有任何工作节点失败，则
    TFJob 的状态也将失败。
- en: Using GPUs
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 GPU
- en: GPUs are processors that are composed of many smaller and specialized cores.
    Originally designed to render graphics, GPUs are increasingly used for massively
    parallel computational tasks, such as machine learning. Unlike CPUs, GPUs are
    ideal for distributing large workloads over its many cores and executing them
    concurrently.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: GPU是由许多较小且专业的核心组成的处理器。最初设计用于渲染图形，GPU越来越多地用于大规模并行计算任务，如机器学习。与CPU不同，GPU非常适合在其多个核心上分发大型工作负载并同时执行。
- en: To use GPUs for training, your Kubeflow cluster needs to be preconfigured to
    enable GPUs. Refer to your cloud provider’s documentation on enabling GPU usage.
    After enabling GPUs on the cluster, you can enable GPUs on the specific replica
    type in the training spec by modifying the command-line arguments, as in [Example 7-17](#TFJob_w_GPU_ex).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用GPU进行训练，您的Kubeflow集群需要预先配置以启用GPU。请参考您的云服务提供商的文档以启用GPU使用。在集群上启用GPU后，您可以通过修改命令行参数在训练规范中的特定副本类型上启用GPU，例如[示例 7-17](#TFJob_w_GPU_ex)。
- en: Example 7-17\. TFJob with GPU example
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-17\. TFJob with GPU example
- en: '[PRE19]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Using Other Frameworks for Distributed Training
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用其他框架进行分布式训练
- en: Kubeflow is designed to be a multiframework machine learning platform. That
    means the schema for distributed training can easily be extended to other frameworks.
    As of the time of this writing, there are a number of operators written to provide
    first-class support for other frameworks, including PyTorch and Caffe2.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow被设计为一个多框架的机器学习平台。这意味着分布式训练的模式可以轻松扩展到其他框架。截至本文撰写时，已编写了许多运算符，为其他框架（包括PyTorch和Caffe2）提供一流支持。
- en: '[Example 7-18](#pytorch_distrib) shows what a PyTorch training job spec looks
    like.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 7-18](#pytorch_distrib)展示了PyTorch训练作业规范的样子。'
- en: Example 7-18\. Pytorch Distributed Training Example
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-18\. Pytorch Distributed Training Example
- en: '[PRE20]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As you can see, the format is very similar to that of TFJobs. The only difference
    is in the replica types.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，其格式与TFJobs非常相似。唯一的区别在于副本类型。
- en: Training a Model Using Scikit-Learn
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Scikit-Learn训练模型
- en: Thus far we have seen how to use the built-in operators in Kubeflow to train
    machine learning models. However, there are many frameworks and libraries for
    which there are no Kubeflow operators. In these cases you can still use your favorite
    frameworks in Jupyter notebooks^([3](ch07.xhtml#idm45831171922664)) or in custom
    Docker images.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到如何使用Kubeflow中的内置运算符来训练机器学习模型。然而，还有许多框架和库没有Kubeflow运算符。在这些情况下，您仍然可以在Jupyter笔记本^([3](ch07.xhtml#idm45831171922664))或自定义Docker镜像中使用您喜欢的框架。
- en: Scikit-learn is an open source Python library for machine learning built on
    top of NumPy for high-performance linear algebra and array operations. The project
    started as scikits.learn, a Google Summer of Code project by David Cournapeau.
    Its name stems from the notion that it is a “SciKit” (SciPy Toolkit), a separately
    developed and distributed third-party extension to SciPy. Scikit-learn is one
    of the most popular machine learning libraries on GitHub, and one of the best-maintained.
    Training models with Scikit-learn is supported in Kubeflow as generic Python code,
    with no specific operators for distributed training.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn是一个基于NumPy构建的用于机器学习的开源Python库，用于高性能线性代数和数组操作。该项目起源于scikits.learn，由David
    Cournapeau在Google Summer of Code项目中开发。其名称源于它是一个“SciKit”（SciPy工具包），是一个单独开发和分发的第三方扩展到SciPy。Scikit-learn是GitHub上最受欢迎的机器学习库之一，也是维护最好的之一。在Kubeflow中，使用Scikit-learn训练模型作为通用的Python代码支持，无需专门的分布式训练运算符。
- en: The library supports state-of-the-art algorithms such as KNN, XGBoost, Random
    Forest, and SVM. Scikit-learn is widely used in Kaggle competitions and by prominent
    tech companies. Scikit-learn helps in preprocessing, dimensionality reduction
    (parameter selection), classification, regression, clustering, and model selection.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 该库支持最先进的算法，如KNN、XGBoost、随机森林和SVM。Scikit-learn在Kaggle竞赛和知名技术公司中被广泛使用。Scikit-learn在预处理、降维（参数选择）、分类、回归、聚类和模型选择方面提供帮助。
- en: In this section, we will explore how to train models in Kubeflow by using Scikit-learn
    on the [1994 US Census dataset](https://oreil.ly/9nQrt). This example is based
    on [this implementation](https://oreil.ly/9hnha) of Anchor explanations for income
    prediction, and leverages an extract from the 1994 census dataset. The dataset
    includes several categorical variables and continuous features, including age,
    education, marital status, occupation, salary, relationship, race, sex, native
    country, and capital gains and losses. We will use a Random Forest algorithm—an
    ensemble learning method for classification, regression, and other tasks that
    operates by constructing a multitude of decision trees at training time and outputting
    the class that is the mode of the classes (classification) or mean prediction
    (regression) of the individual trees.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过使用 Scikit-learn 在[1994年美国人口普查数据集](https://oreil.ly/9nQrt)上训练模型来探索
    Kubeflow。该示例基于用于收入预测的Anchor解释的[这个实现](https://oreil.ly/9hnha)，并利用了从1994年人口普查数据集中提取的数据。数据集包括多个分类变量和连续特征，包括年龄、教育、婚姻状况、职业、工资、关系、种族、性别、原籍国家以及资本收益和损失。我们将使用随机森林算法——一种集成学习方法，用于分类、回归以及其他任务，在训练时通过构建大量决策树并输出类的众数（分类）或个体树的平均预测（回归）来运行。
- en: You can download the notebook from [this book’s GitHub repo](https://oreil.ly/Kubeflow_for_ML_ch07_notebook).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[本书的GitHub存储库](https://oreil.ly/Kubeflow_for_ML_ch07_notebook)下载这个笔记本。
- en: Starting a New Notebook Session
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始一个新的笔记本会话
- en: Let’s start by creating a new notebook. Similar to TensorFlow training, you
    can do this by navigating to the “Notebook Servers” panel in your Kubeflow dashboard,
    then clicking “New Server” and following the instructions. For this example, we
    can use the `tensorFlow-1.15.2-notebook-cpu:1.0 image`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一个新的笔记本开始。类似于 TensorFlow 训练，你可以通过导航到你的 Kubeflow 仪表板中的“笔记本服务器”面板，然后点击“新建服务器”，按照指示操作。例如，我们可以使用`tensorFlow-1.15.2-notebook-cpu:1.0
    image`。
- en: Tip
  id: totrans-158
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: When working in Kubeflow, an easy way to take advantage of GPU resources to
    accelerate your Scikit model is to switch to GPU type.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubeflow中工作时，利用GPU资源加速你的Scikit模型的一种简单方法是切换到GPU类型。
- en: When the notebook server starts up, click the “Upload” button in the top right
    corner and upload the *IncomePrediction.ipynb* file. Click the file to start a
    new session.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当笔记本服务器启动时，在右上角点击“上传”按钮并上传*IncomePrediction.ipynb*文件。点击文件以启动一个新的会话。
- en: Data Preparation
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: The first few sections of the notebook involve importing libraries and reading
    the data. Then we proceed to feature preparation.^([4](ch07.xhtml#idm45831171897544))
    For feature transformation we are using Scikit-learn pipelines. The pipeline makes
    it easier to feed the model with consistent data.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本的前几个部分涉及导入库和读取数据。然后我们继续进行特征准备。^([4](ch07.xhtml#idm45831171897544)) 为了特征转换，我们使用Scikit-learn的管道。管道使得将一致数据输入模型变得更加容易。
- en: For our Random Forest training, we need to define ordinal (standardize data)
    and categorical (one-hot encoding) features, as in [Example 7-19](#Feature_pre_Ex).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的随机森林训练，我们需要定义有序（标准化数据）和分类（独热编码）特征，就像[示例 7-19](#Feature_pre_Ex)中那样。
- en: Example 7-19\. Feature preparation
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-19\. 特征准备
- en: '[PRE21]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Tip
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Many real-world datasets contain missing values, which are encoded by data-specific
    placeholders, such as blanks and NaNs. Such datasets are typically incompatible
    with Scikit-learn estimators, which assume that all values are numerical. There
    are multiple strategies to deal with such missing data. One basic strategy would
    be to discard entire rows and/or columns containing missing values, which comes
    at the price of losing data. A better strategy is to impute the missing values—to
    infer them from the known part of the data. `Simple imputer` is a Scikit-learn
    class that allows you to handle the missing data in the predictive model dataset
    by replacing the NaN values with specified predefined values.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 许多真实世界的数据集包含缺失值，这些值被数据特定的占位符（如空白和NaN）编码。这种数据集通常与假设所有值为数值的Scikit-learn估计器不兼容。有多种策略可以处理这种缺失数据。一个基本的策略是丢弃包含缺失值的整行和/或列，这样做的代价是丢失数据。一个更好的策略是填补缺失值——通过从已知数据部分推断出它们。`Simple
    imputer`是一个Scikit-learn类，允许你通过用指定的预定义值替换NaN值来处理预测模型数据集中的缺失数据。
- en: Once features are defined, we can use a column transformer to combine them,
    as shown in [Example 7-20](#Comb_cols_using_col_transf).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了特征，我们可以使用列转换器将它们组合，如[示例 7-20](#Comb_cols_using_col_transf)所示。
- en: Example 7-20\. Combining columns using column transformer
  id: totrans-169
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例7-20\. 使用列转换器组合列
- en: '[PRE22]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Tip
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Scikit-learn one-hot encoding is used to encode categorical features as a one-hot
    numeric array. The encoder transforms an array of integers or strings, replacing
    the values by categorical (discrete) features. The features are encoded using
    a one-hot (aka, one-of-K or dummy) encoding scheme. This creates a binary column
    for each category and returns a sparse matrix or dense array (depending on the
    sparse parameter).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn的独热编码用于将分类特征编码为独热数字数组。编码器将整数或字符串数组转换，用分类（离散）特征替换值。使用独热编码方案对特征进行编码，为每个类别创建一个二进制列，并返回一个稀疏矩阵或密集数组（取决于sparse参数）。
- en: The transformer itself looks like [Example 7-21](#Data_transform_ex).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 转换器本身看起来像[示例7-21](#Data_transform_ex)。
- en: Example 7-21\. Data transformer
  id: totrans-174
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例7-21\. 数据变换器
- en: '[PRE23]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As a result of this transformation, we have our data in the form of features
    ready for training.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种转换，我们的数据以特征的形式准备好进行训练。
- en: Scikit-Learn Training
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scikit-Learn训练
- en: Once we have our features prepared we can proceed with the training. Here we
    will use `RandomForestClassifier`, provided by the Scikit-learn library, as shown
    in [Example 7-22](#Using_RandomForestClass_ex).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们准备好特征，就可以开始训练。这里我们将使用由Scikit-learn库提供的`RandomForestClassifier`，如示例[7-22](#Using_RandomForestClass_ex)所示。
- en: Example 7-22\. Using RandomForestClassifier
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例7-22\. 使用RandomForestClassifier
- en: '[PRE24]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Tip
  id: totrans-181
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The set and specific features of machine learning algorithm(s) is one of the
    main drivers behind picking a specific framework for machine learning implementation.
    Even the same algorithm implementation in different frameworks provides slightly
    different features that might (or might not) be important for your specific dataset.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法的集合和特定特征是选择特定机器学习实现框架的主要驱动因素之一。即使在不同框架中相同算法的实现提供略有不同的特性，这些特性可能（或可能不）对您的特定数据集很重要。
- en: Once prediction is done, we can evaluate training results, as shown in [Example 7-23](#Eval_train_results).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦预测完成，我们可以评估训练结果，如[示例7-23](#Eval_train_results)所示。
- en: Example 7-23\. Evaluating training results
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例7-23\. 评估训练结果
- en: '[PRE25]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Which returns the results in [Example 7-24](#Train_results_ex).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 该部分将返回[示例7-24](#Train_results_ex)中的结果。
- en: Example 7-24\. Training results
  id: totrans-187
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例7-24\. 训练结果
- en: '[PRE26]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'At this point the model is created and can be directly used by exporting it
    (see the next section). One of the most important attributes of a model is its
    explainability. Although model explainability is mostly used in model serving,
    it is also important for model creation, for two main reasons:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，模型已创建并可以通过导出直接使用（参见下一节）。模型的一个最重要的属性是其可解释性。虽然模型的可解释性主要用于模型服务，但对于模型创建也很重要，有两个主要原因：
- en: If explainability is important for model serving during model creation, we often
    need to validate that the model that was created is explainable.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果在模型创建期间模型服务中的可解释性很重要，我们经常需要验证所创建的模型是否可解释。
- en: Many of the model explanation methods require additional calculations during
    model creation.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多模型解释方法要求在模型创建过程中进行额外的计算。
- en: Based on this, we will show how to implement model explainability^([5](ch07.xhtml#idm45831171376248))
    during model creation.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，我们将展示如何在模型创建过程中实现模型可解释性^([5](ch07.xhtml#idm45831171376248))。
- en: Explaining the Model
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解释模型
- en: For model explanation, we are using anchors, which are part of [Seldon’s Alibi
    project](https://oreil.ly/VSGxe).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模型解释，我们使用锚点，这是[Seldon's Alibi project](https://oreil.ly/VSGxe)的一部分。
- en: The algorithm provides model-agnostic (black box) and human-interpretable explanations
    suitable for classification models applied to images, text, and tabular data.
    The continuous features are discretized into quantiles (e.g., deciles), so they
    become more interpretable. The features in a candidate anchor are kept constant
    (same category or bin for discretized features) while we sample the other features
    from a training set, as in [Example 7-25](#Defining_Tab_Anchor).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法提供了适用于应用于图像、文本和表格数据的分类模型的模型无关（黑盒）和人类可解释的解释。连续特征被离散化为分位数（例如，分位数），因此它们变得更易解释。在候选锚点中，保持特征不变（相同类别或分箱为离散化特征），同时从训练集中对其他特征进行抽样，如[示例7-25](#Defining_Tab_Anchor)所示。
- en: Example 7-25\. Defining the tabular anchor
  id: totrans-196
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例7-25\. 定义表格锚点
- en: '[PRE27]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This creates the tabular anchor ([Example 7-26](#Tab_Anchor_ex)).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这创建了表格锚点（[示例7-26](#Tab_Anchor_ex)）。
- en: Example 7-26\. Tabular anchor
  id: totrans-199
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例7-26\. 表格锚点
- en: '[PRE28]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Now we can get an anchor for the prediction of the first observation in the
    test set. An *anchor* is a sufficient condition—that is, when the anchor holds,
    the prediction should be the same as the prediction for this instance in [Example 7-27](#Prediction_calc_ex).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以为测试集中第一条观测的预测获取一个锚点。*锚点*是一个充分条件——即，当锚点成立时，预测应与[示例 7-27](#Prediction_calc_ex)中此实例的预测相同。
- en: Example 7-27\. Prediction calculation
  id: totrans-202
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-27\. 预测计算
- en: '[PRE29]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Which returns a prediction calculation result as shown in [Example 7-28](#Prediction_calc_result_ex).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 返回如[示例 7-28](#Prediction_calc_result_ex)所示的预测计算结果。
- en: Example 7-28\. Prediction calculation result
  id: totrans-205
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-28\. 预测计算结果
- en: '[PRE30]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We set the precision threshold to `0.95`. This means that predictions on observations
    where the anchor holds will be the same as the prediction on the explained instance
    at least 95% of the time. Now we can get an explanation ([Example 7-29](#Model_expl_ex))
    for this prediction.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将精度阈值设置为`0.95`。这意味着在锚定条件成立的观察中，预测至少95%的时间将与解释实例的预测相同。现在我们可以为这个预测获取解释（[示例 7-29](#Model_expl_ex)）。
- en: Example 7-29\. Model explanation
  id: totrans-208
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-29\. 模型解释
- en: '[PRE31]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Which returns a model explanation result as shown in [Example 7-30](#Model_expl_results_ex).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 返回如[示例 7-30](#Model_expl_results_ex)所示的模型解释结果。
- en: Example 7-30\. Model explanation result
  id: totrans-211
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-30\. 模型解释结果
- en: '[PRE32]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This tells us that the main factors for decision are marital status (`Separated`)
    and sex (`Female`). Anchors might not be found for all points. Let’s try getting
    an anchor for a different observation in the test set—one for which the prediction
    is `>50K`, shown in [Example 7-31](#Model_expl_ex2).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，决策的主要因素是婚姻状况（`Separated`）和性别（`Female`）。并非所有点都可以找到锚点。让我们尝试为测试集中的另一条观测获取一个锚点——一个预测为`>50K`的示例，如[示例
    7-31](#Model_expl_ex2)所示。
- en: Example 7-31\. Model explanation
  id: totrans-214
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-31\. 模型解释
- en: '[PRE33]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Which returns a model explanation result as shown in [Example 7-32](#Model_expl_results_ex2).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 返回如[示例 7-32](#Model_expl_results_ex2)所示的模型解释结果。
- en: Example 7-32\. Model explanation result
  id: totrans-217
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-32\. 模型解释结果
- en: '[PRE34]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Due to the imbalanced dataset (roughly 25:75 high:low earner proportion), during
    the sampling stage feature ranges corresponding to low earners will be oversampled.
    As a result, the anchor in this case is not found. This is a feature because it
    can point out an imbalanced dataset, but it can also be fixed by producing balanced
    datasets to enable anchors to be found for either class.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集不平衡（大约25:75高:低收入者比例），在采样阶段与低收入者对应的特征范围将被过度采样。因此，在这种情况下找不到锚点。这是一个特征，因为它可以指出数据集不平衡，但也可以通过生成平衡数据集来修复，以便为任何类找到锚点。
- en: Exporting Model
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型导出
- en: In order to use the created model for serving, we need to export the model.
    This is done using Scikit-learn functionality, as in [Example 7-33](#Exporting_model_ex).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将创建的模型用于服务，我们需要导出模型。这可以通过Scikit-learn功能完成，如[示例 7-33](#Exporting_model_ex)所示。
- en: Example 7-33\. Exporting model
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-33\. 导出模型
- en: '[PRE35]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This exports a model in Scikit-learn format, that can be used by, for example,
    Scikit-learn server for inference.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这将以Scikit-learn格式导出一个模型，例如，可以由Scikit-learn服务器用于推断。
- en: Integration into Pipelines
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成到流水线中
- en: Regardless of which Python-based machine learning library you want to use, if
    Kubeflow doesn’t have an operator for it, you can simply write your code as normal
    and then containerize it. To take the notebook we built in this chapter and use
    it as a pipeline stage, see [“Using an Entire Notebook as a Data Preparation Pipeline
    Stage”](ch05.xhtml#notebook_as_pipeline_stage). Here we can use `file_output`
    to upload the resulting model to our artifact tracking system, but you can also
    use the persistent volume mechanism.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您想使用哪个基于Python的机器学习库，如果Kubeflow没有相应的操作符，您可以按照正常方式编写您的代码，然后将其容器化。要将本章中构建的笔记本作为流水线阶段使用，请参阅[“将整个笔记本用作数据准备流水线阶段”](ch05.xhtml#notebook_as_pipeline_stage)。在这里，我们可以使用`file_output`将生成的模型上传到我们的工件跟踪系统，但您也可以使用持久卷机制。
- en: Conclusion
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this chapter, we have taken a look at how to train machine learning models
    in Kubeflow using two very different frameworks: TensorFlow and Scikit-learn.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看了如何使用两种非常不同的框架（TensorFlow和Scikit-learn）在Kubeflow中训练机器学习模型。
- en: We learned how to build a collaborative filtering recommendation system using
    TensorFlow. We used Kubeflow to create a notebook session, where we’ve prototyped
    a TensorFlow model with Keras APIs, and then used the TFJob APIs to deploy our
    training job to a Kubernetes cluster. Finally, we’ve looked at how to use TFJob
    for distributed training.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了如何使用TensorFlow构建协同过滤推荐系统。我们使用Kubeflow创建了一个笔记本会话，在那里我们使用了Keras API原型化了一个TensorFlow模型，然后使用TFJob
    API将我们的训练作业部署到了Kubernetes集群。最后，我们看了如何使用TFJob进行分布式训练。
- en: We also learned how to train a generic Python model using Scikit-learn, a framework
    that is not natively supported by Kubeflow. [Chapter 9](ch09.xhtml#beyond_tf)
    looks at how to integrate nonsupported non-Python machine learning systems, which
    is a bit more complicated. While Kubeflow’s first-party training operators can
    simplify your work, it’s important to remember you aren’t limited by this.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还学习了如何使用Scikit-learn训练通用的Python模型，这是Kubeflow不原生支持的框架。[第9章](ch09.xhtml#beyond_tf)讨论了如何集成不受支持的非Python机器学习系统，这有点复杂。尽管Kubeflow的一方面训练操作员可以简化您的工作，但重要的是要记住您并不受此限制。
- en: In [Chapter 8](ch08.xhtml#inference_ch) we will look at how to serve the model
    that we’ve trained in this chapter.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第8章](ch08.xhtml#inference_ch)中，我们将探讨如何提供在本章中训练的模型。
- en: ^([1](ch07.xhtml#idm45831173117976-marker)) Currently Kubeflow provides CPU
    and GPU images with TensorFlow 1.15.2 and 2.1.0, or you can use a custom image.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch07.xhtml#idm45831173117976-marker)) 当前，Kubeflow提供了带有TensorFlow 1.15.2和2.1.0的CPU和GPU镜像，或者您可以使用自定义镜像。
- en: ^([2](ch07.xhtml#idm45831173106920-marker)) The examples in this chapter use
    TensorFlow 1.15.2\. Examples with TensorFlow 2.1.0 can be found on [this Kubeflow
    GitHub site](https://oreil.ly/I71lt).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch07.xhtml#idm45831173106920-marker)) 本章中的示例使用了TensorFlow 1.15.2。您可以在[这个Kubeflow
    GitHub网站](https://oreil.ly/I71lt)找到使用TensorFlow 2.1.0的示例。
- en: ^([3](ch07.xhtml#idm45831171922664-marker)) The languages currently supported
    by Jupyter notebooks include Python, R, Julia, and Scala.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch07.xhtml#idm45831171922664-marker)) 目前Jupyter笔记本支持的语言包括Python、R、Julia和Scala。
- en: ^([4](ch07.xhtml#idm45831171897544-marker)) See [Chapter 5](ch05.xhtml#data_and_feature_prep)
    for an in-depth discussion of feature preparation.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch07.xhtml#idm45831171897544-marker)) 请参阅[第5章](ch05.xhtml#data_and_feature_prep)详细讨论特征准备。
- en: ^([5](ch07.xhtml#idm45831171376248-marker)) Refer to this [blog post by Rui
    Aguiar](https://oreil.ly/juWml) for more information on model explainability.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch07.xhtml#idm45831171376248-marker)) 有关模型可解释性的更多信息，请参阅[Rui Aguiar的这篇博客文章](https://oreil.ly/juWml)。
