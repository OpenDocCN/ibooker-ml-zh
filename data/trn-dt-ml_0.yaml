- en: Chapter 1\. Training Data Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章\. 训练数据介绍
- en: Data is all around us. Videos, images, text, 3D, geospatial, documents, and
    more. Yet, in its raw form this data is of little use to supervised machine learning
    (ML). How do we make use of this data? How do we record our intelligence so it
    can be reproduced through ML? The answer is the Art of Training Data - the discipline
    of making raw data useful.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '数据无处不在。视频、图像、文本、3D、地理空间、文档等等。然而，以其原始形式，这些数据对于监督式机器学习（ML）几乎无用。我们如何利用这些数据？我们如何记录我们的智慧，以便通过ML再现它？答案就是训练数据的艺术——使原始数据变得有用的学科。 '
- en: 'In this book you will learn:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，您将学到：
- en: All-new Training Data specific concepts
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全新的训练数据特定概念
- en: The Day to Day Practice of Training Data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据的日常实践
- en: How to improve Training Data efficiency
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何提高训练数据的效率
- en: Real world case studies
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真实世界案例研究
- en: How to transform your team to be more AI/ML centric
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使您的团队更加AI/ML中心化
- en: Before we can cover some of these concepts, we first have to understand the
    foundations, which this chapter will unpack.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够涵盖这些概念之前，我们首先必须理解这一章将揭示的基础知识。
- en: Training Data is about molding, reforming, shaping, and digesting raw data into
    new forms. Creating new meaning out of raw data to solve problems. These acts
    of creation and destruction sit at the intersection of subject matter expertise,
    business needs, and technical requirements. It’s a diverse set of activities that
    crosscut multiple domains.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据是将原始数据塑造、重塑、形成和消化成新形式的过程。从原始数据中创造新的含义以解决问题。这些创造和破坏的行为处于学科专业知识、业务需求和技术要求的交集。这是一组跨越多个领域的多样化活动。
- en: At the heart of these activities is annotation. Annotation produces structured
    data that is ready to be consumed by a machine learning model. Without annotation,
    raw data is considered to be unstructured and not usable. That’s why training
    data is required for modern machine learning use cases including computer vision,
    natural language processing and speech recognition.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些活动的核心是注释。注释生成了结构化数据，可供机器学习模型使用。没有注释，原始数据被认为是非结构化且不可用的。这就是为什么现代机器学习用例，包括计算机视觉、自然语言处理和语音识别，都需要训练数据的原因。
- en: 'To cement this idea in an example let’s consider annotation in detail. When
    we annotate data we are capturing human knowledge. Typically, this process looks
    as follows: a piece of media such as an image, text, video, 3D, or audio, is presented
    along with a set of predefined options (labels). A human reviews the media and
    determines the most appropriate answers. For example, declaring a region of an
    image to be “good” or “bad”. This label provides the context needed to apply machine
    learning concepts (Figure 1-1).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要在一个例子中巩固这个概念，让我们详细考虑注释。当我们注释数据时，我们在捕获人类知识。通常，这个过程如下所示：提供一个媒体片段，比如图像、文本、视频、3D或音频，并附上一组预定义的选项（标签）。人类审查媒体并确定最合适的答案。例如，声明图像的某个区域是“好”还是“坏”。这个标签提供了应用机器学习概念所需的上下文（图1-1）。
- en: But how did we get there? How did we get to the point that the right media element,
    with the right predefined set of options, is shown to the right person at the
    right time? There are many concepts that lead up to and follow the moment where
    that annotation, or knowledge capture, actually happens. Collectively all of these
    concepts are the art of training data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们是如何做到的？我们是如何达到这一点的？正确的媒体元素与正确的预定义选项在正确的时间显示给正确的人？导致并随着注释或知识捕获实际发生的许多概念。总之，所有这些概念都是训练数据的艺术。
- en: '![Fig 1.1  The Training Data Process](Images/training_data_introduction_865720_01.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1 训练数据过程](Images/training_data_introduction_865720_01.png)'
- en: Figure 1-1\. The Training Data Process
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 训练数据过程
- en: In this chapter, we’ll introduce what training data is, why it matters, and
    dive into many key concepts that will form the base for the rest of the book.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将介绍训练数据是什么，为什么它很重要，并深入探讨将构成本书其余部分基础的许多关键概念。
- en: Training Data Intents
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据意图
- en: What can you do with Training Data. What is it most concerned with? What are
    people aiming to achieve with Training Data? The purpose of Training Data varies
    across different use cases, problems, and scenarios. Let’s explore some of the
    most common questions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过训练数据做什么？它最关心的是什么？人们希望通过训练数据实现什么？训练数据的目的因不同的用例、问题和场景而异。让我们探讨一些最常见的问题。
- en: What can you do with Training Data?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 您可以通过训练数据做什么？
- en: Training Data is the foundation of AI/ML systems - the underpinning that makes
    these systems work.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 培训数据是AI/ML系统的基础 - 支撑这些系统运行的基础。
- en: With Training Data you can build and maintain modern ML systems, such as ones
    that create next generation automations, improve existing products, and even create
    all new products.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 培训数据使您能够构建和维护现代ML系统，例如创建下一代自动化、改进现有产品，甚至创建全新产品。
- en: In order to be useful, the data needs to be presented in a structured way to
    ML programs. That’s where Training Data comes in - adding and maintaining structure
    to make the raw data useful. If you have great Training Data, you are on the path
    towards a great overall solution.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有用，数据需要以结构化的方式呈现给ML程序。这就是培训数据的作用 - 添加和维护结构，使原始数据有用。如果你有出色的培训数据，你就在通向一个优秀的整体解决方案的道路上。
- en: 'In practice, common use cases center around:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，常见的用例集中在
- en: Improving an existing product (e.g., performance), even if ML is not currently
    a part of it
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改进现有产品（例如性能），即使当前尚未包含ML部分
- en: Production of a new product, including systems that run in a limited or “one
    off” fashion
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制造新产品，包括以有限或“一次性”方式运行的系统
- en: Research and Development
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研发
- en: Training Data transcends all parts of ML programs. Training data comes up before
    you can run an ML Program, it comes up during running in terms of output and results,
    and even later in analysis and maintenance. Further, Training Data concerns tend
    to be long lived. For example, after getting a model up and running, maintaining
    the Training Data is an important part of maintaining a model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 培训数据贯穿ML程序的所有部分。培训数据在您运行ML程序之前就出现了，在运行期间涉及输出和结果，甚至在分析和维护之后也是如此。此外，培训数据的关注点往往是长期存在的。例如，在启动并运行模型之后，维护培训数据是维护模型的重要组成部分。
- en: The creation and maintenance of novel data is a primary concern of this book.
    A dataset at a moment in time is an output of the complex processes of Training
    Data. For example, a Train/Test/Val split is a derivative of an original, novel
    set. And that novel set itself is simply a snapshot, a single view into larger
    Training Data processes. Similar to how a programmer may decide to print or log
    a variable, the variable printed is just the output, it doesn’t explain the complex
    set of functions that were required to get the desired value. A goal of this book
    is to explain the complex processes behind getting usable datasets.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的主要关注点是创建和维护新数据。某一时刻的数据集是培训数据复杂过程的输出。例如，一个训练/测试/验证分割是原始新颖集合的衍生物。而这个新颖集合本身只是一个快照，一个对更大培训数据过程的单一视角。类似于程序员决定打印或记录变量的方式，打印的变量只是输出，它并没有解释获取所需值所需的复杂函数集合。本书的目标之一是解释背后获取可用数据集的复杂过程。
- en: Annotation, the act of humans directly annotating samples, is an important part
    of Training Data. However, it is just one part, and the process of Training Data
    involves many others, outlined later in this chapter.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 注释，即人类直接注释样本的行为，是培训数据的重要组成部分。然而，它只是其中的一部分，培训数据的过程涉及后面本章中概述的许多其他部分。
- en: What is Training Data most concerned with?
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 培训数据最关心什么？
- en: This book covers a variety of people, organizational, and technical concerns.
    We’ll walk through each of these concepts in detail in a moment, but before we
    do, let’s think about areas Training Data is focused on.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书涵盖了各种人员、组织和技术问题。我们将在稍后详细讨论每一个概念，但在此之前，让我们先思考培训数据关注的领域。
- en: For example, how does the Schema, which is a map between your annotations and
    their meaning for your use case, accurately represent the problem? How do you
    ensure raw data is collected and used in a way relevant to the problem? How is
    human validation, monitoring, controls, and correction applied?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，模式Schema如何准确地表示您的注释与它们在您的用例中的意义之间的映射问题？如何确保原始数据被收集并以与问题相关的方式使用？如何应用人类验证、监控、控制和修正？
- en: How do you repeatedly achieve and maintain acceptable degrees of quality when
    there is such a large human component? How does it integrate with other technologies,
    including data sources and your application?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在存在如此多的人为因素时，如何重复达到和维持可接受的质量水平？它如何与其他技术集成，包括数据源和您的应用程序？
- en: 'While not perfect, to help organize this you can broadly divide into the following
    topics: Schema, Raw Data, Quality, Integrations, and the Human Role. Next, I’ll
    take a deeper look at each of those topics.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然不完美，为了帮助组织这一点，您可以广泛划分为以下主题：Schema、原始数据、质量、集成和人类角色。接下来，我将深入研究每个主题。
- en: Schema
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Schema
- en: Schema is central in every aspect of Training Data. Schema is the map between
    human input and meaning for your use case. It defines what the ML program is capable
    of outputting. It’s the vital link, it’s what binds together everyone’s hard work.
    So to state the obvious, it’s important.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Schema在训练数据的每个方面都是核心。Schema是人类输入和您用例含义之间的映射。它定义了机器学习程序能够输出的内容。它是至关重要的链接，是将每个人的辛勤工作联系在一起的东西。所以显而易见的是，它很重要。
- en: A goodSchema is useful and relevant to your specific need**.** It’s usually
    best to create a new, custom Schema, and then keep iterating on it for your specific
    cases. It’s normal to draw on domain specific databases for inspirations, or to
    fill in certain levels of detail, but be sure that’s done in the context of guidance
    for a new, novel, Schema. Don’t expect an existing Schema from another context
    to work for ML programs without further updates.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的Schema对您的特定需求是有用和相关的。通常最好创建一个新的、定制的Schema，然后针对您的具体情况进行迭代。在获取灵感时，从特定领域的数据库借鉴或填写某些详细级别是正常的，但务必在为新的、新颖的Schema提供指导的情况下完成。不要期望来自另一个上下文的现有Schema能在没有进一步更新的情况下适用于机器学习程序。
- en: So, why is it important to design it according to your specific needs, and not
    some predefined set?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么根据您的具体需求设计它很重要，而不是某些预定义集？
- en: First, the Schema is for both human annotation and ML machine use. An existing
    domain specific schema may be designed for human use in a different context or
    for machine use in a classic, non-ML context. This is one of those cases where
    something that’s output seems really similar, but is actually formed in totally
    different ways.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，Schema既适用于人类注释又适用于机器学习。现有的领域特定Schema可能是为不同上下文的人类使用或经典非机器学习上下文的机器使用而设计的。这是其中一种情况，看起来输出很相似，但实际上形成方式完全不同。
- en: Like two different math functions that both output the same value, but run on
    completely different logic. The output of the Schema may appear similar, but the
    differences are important to make it friendly to annotation and ML use.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 就像两个输出相同值的不同数学函数，但运行在完全不同的逻辑上。Schema的输出可能看起来相似，但其中的差异对于使其友好地用于注释和机器学习至关重要。
- en: Second, if the Schema is not useful, then even great model predictions are not
    useful. Failure with Schema design likely will cascade to failure of the overall
    system. The context here is that ML programs can usually only predict what is
    included in the Schema.^([1](ch01.xhtml#idm45486441047360)) It’s rare that an
    ML Program will produce relevant results that are better than the original Schema.
    It’s also rare that it will predict something that a human, or group of humans,
    looking at the same raw data could not also predict.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，如果Schema无用，即使很棒的模型预测也是无用的。Schema设计的失败可能会导致整个系统的失败。这里的背景是，机器学习程序通常只能预测Schema中包含的内容。^([1](ch01.xhtml#idm45486441047360))
    很少有机器学习程序能够产生比原始Schema更好的相关结果。同样罕见的是，它会预测出人类或人类群体在查看相同原始数据时无法预测到的内容。
- en: It is common to see Schemas that have questionable value. So, it’s really worth
    stopping and thinking “If we automatically got the data labeled with this Schema,
    would it actually be useful to us?”. And “Can a human looking at the raw data,
    reasonably choose something from the Schema that fits it?”
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 经常看到有价值存疑的Schema。因此，停下来仔细思考一下“如果我们自动使用这个Schema标记数据，它对我们是否真正有用？”以及“人类查看原始数据时，是否可以合理地从Schema中选择符合它的内容？”是非常值得的。
- en: In the first few chapters, we will cover the technical aspects of Schema, and
    we will come back to Schema concerns through practical examples later in the book.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前几章中，我们将涵盖Schema的技术方面，并稍后通过实际示例回到Schema的关注点。
- en: Raw Data
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原始数据
- en: When we think about raw data, the most important thing is that it’s collected
    and used in a way relevant to the Schema.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑原始数据时，最重要的是以与Schema相关的方式收集和使用它。
- en: To illustrate the idea of relevance let’s consider the difference between hearing
    a sports game on the radio, seeing it on TV, or being at the game in person. It’s
    the same event regardless of the medium, but you receive a very different amount
    of data in each context. The context of the collection frames the potential of
    the data. So for example, if you were trying to determine possession of the ball
    automatically, the visual data will likely be a better fit then the radio data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明相关性的概念，让我们考虑在收听收音机中的体育比赛、在电视上看到它或亲自参加比赛之间的差异。无论使用哪种媒介，这是同一事件，但在每种情境下，你接收到的数据量是非常不同的。收集的上下文框定了数据的潜力。因此，例如，如果你试图自动确定球权，视觉数据可能比收音机数据更适合。
- en: Compared to software we humans are good at automatically making contextual correlations
    and working with noisy data. We make many assumptions, often drawing on data sources
    not present in the moment to our senses. This ability to understand the context
    above the directly sensed sights, sounds, etc. makes it difficult to remember
    that software is more limited here.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 与软件相比，我们人类擅长自动进行上下文相关的相关性推断和处理嘈杂数据。我们做出许多假设，通常依赖于此时并非直接感知到的数据来源。理解上述直接感知视觉、声音等之上的上下文的能力，使得我们很难记住软件在这方面更为有限。
- en: Software only has the context that is programmed into it, be it through data
    or lines of code. This means the real challenge with raw data is overcoming our
    human assumptions around context to make the right data available.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 软件只能通过编程到其中的数据或代码获取到上下文。这意味着处理原始数据的真正挑战是克服我们对上下文的人类假设，以便使正确的数据可用。
- en: So how do you do that? One of the more successful ways is to start with the
    Schema, and then map ideas of raw data collection to that. It can be visualized
    as a chain of Problem -> Schema -> Raw Data. The Schema need is always defined
    by the Problem or Product. That way there is always this easy check of “Given
    the Schema, and the raw data, can a human make a reasonable judgment?”
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 那么你该怎么做呢？其中一种更成功的方法是从模式开始，然后将原始数据收集的想法映射到其中。它可以被视为一个问题 -> 模式 -> 原始数据的链条。模式的需求总是由问题或产品定义的。通过这种方式，总能轻松检查“给定模式和原始数据，人类能做出合理的判断吗？”
- en: Centering around the Schema also encourages thinking about new ways of data
    collection, instead limiting to existing or easiest to reach data collection methods.
    Over time the Schema and Raw Data can be jointly iterated on, this is just to
    get started. Another way to relate it on the product side, is that the Schema
    represents the Product. So to use the cliche of “Product Market Fit”, this is
    “Product Data Fit”.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 着眼于模式，还鼓励考虑收集数据的新方法，而不仅限于现有或最易获得的数据收集方法。随着时间的推移，模式和原始数据可以共同迭代，这只是一个开始。在产品方面，另一种关联方式是，模式代表了产品。因此，使用“产品市场匹配”的陈词滥调，这是“产品数据匹配”。
- en: 'To put the above abstractions into more concrete terms, here’s some of what
    I see most common in industry:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 要将上述抽象概念具体化，以下是我在行业中最常见到的一些内容：
- en: Differences between data used during development and production is one of the
    most common source of errors. It is common because it is somewhat unavoidable.
    That’s why being able to get to some level of “real” data early in the iteration
    process is crucial. You have to expect that production data will be different,
    and plan for it as part of your data overall data collection strategy.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发和生产过程中使用的数据之间的差异是最常见的错误源之一。这是普遍的，因为它在某种程度上是不可避免的。这就是为什么在迭代过程的早期能够达到某种程度的“真实”数据是至关重要的。你必须期待生产数据将会不同，并将其作为你的数据整体收集策略的一部分进行规划。
- en: The data program can *only* see the raw data and the annotations. Only what
    is given to it. If a human annotator is relying on knowledge outside of what can
    be understood from the sample presented, it’s unlikely the data program will have
    that context, and it will fail. We must remember that all needed context must
    be present, either in the data or lines of code of the program.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 数据程序只能看到原始数据和注释。只能看到给予它的东西。如果人类标注员依赖于无法从呈现的样本中理解的知识外的知识，那么数据程序可能不会具备这种上下文，它将失败。我们必须记住，所有必需的上下文必须存在，无论是在数据中还是在程序的代码行中。
- en: 'To recap:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下：
- en: The raw data needs to be relevant to the Schema.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始数据需要与模式相关。
- en: The raw data should be as similar to production data as possible.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始数据应尽可能与生产数据相似。
- en: The raw data should have all the context needed in the sample itself.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始数据在样本本身应具有所需的所有上下文。
- en: Quality
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 质量
- en: Training Data quality is naturally a spectrum. What is acceptable in one context
    may not be in another.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据质量自然是一个连续的过程。在一个情境中可接受的东西，在另一个情境中可能就不行了。
- en: So what are the biggest factors that go into Training Data quality?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，影响训练数据质量的最大因素是什么？
- en: 'Well we already talked about two of them: Schema and raw data. For example:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了其中两个：架构和原始数据。例如：
- en: A bad Schema may cause more quality issues than bad annotators.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个糟糕的架构可能比糟糕的标注者引起更多的质量问题。
- en: If the concept is not clear in the raw data sample, it’s unlikely it will be
    clear to the ML program.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果在原始数据样本中概念不清楚，那么它很可能对机器学习程序来说也不清楚。
- en: Often, Annotation quality is the next biggest item. Annotation quality is important,
    but perhaps not in the ways you may expect. Specifically, that people tend to
    think of Annotation quality as “was it annotated right”? But “right” is often
    out of scope.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，标注质量是接下来最重要的一个项目。标注质量很重要，但也许不是你所期望的方式。具体来说，人们倾向于认为标注质量是“它是否被正确标注了”？但是“正确”通常是超出范围的。
- en: To understand how the “right” answer is often out of scope, let’s imagine we
    are annotating traffic lights, and the light in sample you are presented is off
    (e.g. power failure) and your only options from the Schema are variations on an
    active traffic light. Clearly either the Schema needs to be updated to include
    an ‘off’ traffic light, or our production system will never be usable in a context
    where a traffic light may have a power failure.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解“正确答案”通常超出范围的方式，让我们想象我们正在标注交通灯，而你所呈现的样本中的灯是关掉的（例如停电），而我们的架构的选项只有活动交通灯的各种变化。显然，要么架构需要更新以包括“关掉”的交通灯，要么我们的生产系统永远无法在可能会发生交通灯停电的情境中使用。
- en: To move into a slightly harder to control case, consider if the traffic light
    is really far away or at an odd angle, that will also limit the ability to annotate
    it properly. Often these cases sound like they should be easily manageable but
    in practice they often aren’t. So more generally, real issues with annotation
    quality tend to circle back to issues with the Schema and Raw Data. So quality
    with Annotation is more about communication of issues, of annotators surfacing
    problems in Schema and Data, then just about annotating “correctly”.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 要进入一个稍难以控制的案例，考虑交通灯是否非常远或者处于奇怪的角度，这也将限制正确标注的能力。通常这些情况听起来应该是容易管理的，但在实践中往往不是这样。因此，标注质量的真正问题往往是围绕着架构和原始数据的问题。因此，标注质量更多地是关于问题的沟通，标注者在架构和数据中表现出问题，而不仅仅是正确地标注。
- en: Hopefully this has hammered home the point that Schema and raw data deserve
    a lot of attention. However, Annotating correctly does still matter, and one of
    the approaches is to have multiple people look at the same sample. This is often
    costly. And someone must interpret the meaning of the multiple opinions on the
    same sample, adding further cost. For an industry usable case, where the Schema
    has a reasonable degree of complexity, the meta-analysis of the opinions is a
    further time sink.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这已经让大家深刻认识到架构和原始数据值得高度关注。然而，正确的标注仍然很重要，其中一种方法是让多人查看同一样本。这通常是昂贵的。必须有人解释对同一样本的多个意见的含义，这会进一步增加成本。对于一个有合理复杂度的架构的行业可用案例来说，对意见进行的元分析将是一个进一步的时间消耗。
- en: Think of a crowd of people watching a sports game instant replay. Imagine trying
    to statistically sample their opinions to get a “proof” of what is “more right”.
    Instead of this, we have a referee who individually reviews the situation and
    makes a determination. That determination may or may not be “right”, but it’s
    more cost effective then trying to survey the crowd, and realistically works better.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一群人观看体育比赛的即时重播。试想着统计抽样他们的意见来获取“证据”来确定什么是“更正确”的。与此不同的是，我们有一位裁判单独审查情况并作出判断。这个判断可能是对的，也可能不对，但比试图调查群众更具成本效益，并且实际上运作更好。
- en: Similarly, often a more cost effective approach is to randomly sample a percent
    of the data for a review loop, and have annotators raise issues with the Schema
    and raw data fit, as they occur. This review loop and quality assurance processes
    will be discussed in more depth later.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，通常更具成本效益的方法是随机抽样数据的百分比进行审查循环，并且标注者在出现问题时提出架构和原始数据匹配的问题。稍后将更深入地讨论这个审查循环和质量保证过程。
- en: If the review method fails, and you think you still need multiple people you
    probably have a bad Product Data Fit and need to change the Schema or raw data
    collection to fix it.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果审查方法失败，并且您认为仍然需要多人参与，那么您可能存在糟糕的产品数据适配性，并且需要更改架构或原始数据收集以修复它。
- en: Zooming out from Schema, Raw Data, and Annotation, the other big aspects of
    quality is maintenance of the data and the integration points with ML programs.
    Quality includes cost considerations, expected use, and expected failure rates.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 从架构、原始数据和注释中放大，质量的另一个重要方面是数据的维护和与ML程序的集成点。质量包括成本考虑、预期使用和预期故障率。
- en: To recap here, quality is first and foremost formed by the Schema and Raw data,
    then by the Annotators and associated processes, and rounded out by the maintenance
    and integration.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，质量首先主要由架构和原始数据形成，然后由注释者和相关流程形成，最后由维护和集成来补充。
- en: Integrations
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成
- en: Much time and energy are focused on “training a model”. However, this often
    misses the point because training a model is a primarily technical, and primarily
    data science focused concept.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 许多时间和精力集中在“训练模型”上。然而，这经常忽略了一个主要因素，因为训练模型是一个主要的技术概念，主要集中在数据科学上。
- en: What about maintenance of the training data? What about ML programs that output
    useful training data results, such as sampling, finding errors, reducing workload
    etc., that are not to do with training a model? How about the integration with
    the application the results of the model or ML sub program will be used in? What
    about tech that tests and monitors datasets? The hardware? Human notifications?
    How is the technology packaged into other tech?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 那么训练数据的维护呢？ML程序的输出结果如何，比如抽样、查找错误、减少工作量等，与训练模型无关？那么与结果的应用集成如何？技术如何测试和监控数据集？硬件？人类通知？技术如何打包到其他技术中？
- en: Training a model is just one component. To successfully build an ML program,
    a data driven program, we need to think about how all the technology components
    work together. And to avoid reinventing the wheel we need to be aware of the growing
    Training Data ecosystem.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型只是其中一个组成部分。要成功构建一个ML程序、一个数据驱动程序，我们需要考虑所有技术组件如何协同工作。为了避免重复发明轮子，我们需要了解不断增长的训练数据生态系统。
- en: 'A few key aspects to remember about working with integrations:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 关于处理集成的几个关键方面需要记住：
- en: The training data is only useful if it can be consumed by something, usually
    within a larger program.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有能够被某物消费的培训数据才有用，通常是在更大的程序中。
- en: Integration with data science is multi-faceted, it’s not just about some final
    “output” of annotations. It’s about the ongoing human control, maintenance, Schema,
    validation, lifecycle, security, etc. A batch of outputted annotations is like
    the result of a single SQL query, it’s a single, limited view into a complex database.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与数据科学的集成是多方面的，不仅仅是一些最终“输出”的注释。它关乎持续的人类控制、维护、架构、验证、生命周期、安全性等等。一批输出的注释就像是单个SQL查询的结果，它是对复杂数据库的单一、有限视角。
- en: Getting a model trained is only a small part of the overall ecosystem.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型只是整体生态系统的一小部分。
- en: The Human Role
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人类角色
- en: Training Data involves the human, the subject matter experts and annotators,
    directly in the process. Humans are programing, creating, and controlling through
    data.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据涉及人类、主题专家和注释者直接参与过程。人类通过数据进行编程、创建和控制。
- en: Humans exert control on data programs by controlling the Training Data. This
    includes controlling the aspects we have discussed so far, the Schema, raw Data,
    Quality, and integrations with other systems. And of course Annotation itself,
    the humans looking at each individual sample.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 人类通过控制训练数据来控制数据程序。这包括控制我们到目前为止讨论过的方面：架构、原始数据、质量以及与其他系统的集成。当然还包括注释本身，人类查看每个单独样本。
- en: 'This control is exercised at many stages, and by many people: from initial
    training data to human evaluations of data science outputs validating data science
    results. This large volume of people involved is very different from classic ML.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种控制在许多阶段和许多人员中进行：从最初的训练数据到对数据科学输出的人类评估，验证数据科学结果。这么多人参与，与传统的机器学习非常不同。
- en: We have new metrics, like how many samples were accepted, how long is spent
    on each task, lifecycle of datasets, fidelity of raw data, what the distribution
    of the Schema looks like. These concepts may overlap with data science concepts,
    like class distribution, but are worth thinking of as separate concepts. For example,
    model metrics are based on the ground truth of the Training Data so if the data
    is wrong the metrics are wrong. And as discussed in the QA section, metrics around
    something like annotator agreement, miss larger points of Schema and Raw Data
    issues.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有新的指标，比如接受了多少样本，每个任务花费多长时间，数据集的生命周期，原始数据的保真度，模式分布的分布情况等等。这些概念可能与数据科学概念重叠，比如类分布，但值得单独思考。例如，模型指标基于训练数据的地面真实性，因此如果数据错误，指标也会错误。正如在质量保证部分讨论的那样，围绕注释者一致性的指标，错过了模式和原始数据问题的更大点。
- en: Human oversight is about so much more than just quantitative metrics. It’s about
    qualitative understanding. Human observation, human understanding of the Schema,
    raw data, individual samples, etc. is of great importance. This qualitative view
    extends into business and use case concepts. Further these validations and controls
    quickly extend from being easily defined, to more of an art from, acts of creation.
    Not to mention political and social expectations around system performances and
    output.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 人工监督不仅仅关乎定量指标。它关乎定性理解。人类对模式、原始数据、单个样本等的观察和理解至关重要。这种定性视角延伸到业务和用例概念中。此外，这些验证和控制很快从易于定义的形式扩展到更多的艺术形式，成为创造行为。更不用说政治和社会对系统性能和输出的期望了。
- en: Working with training data is an opportunity to create. To capture human intelligence
    and insights in novel ways. To frame problems in a new Training Data context.
    To create new Schema, new raw data capture, and other Training Data specific methods.
    Subject matter experts can directly create new data by annotating.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 处理训练数据是一个创造性的机会。以新的方式捕捉人类智慧和见解。在新的训练数据环境中构建问题。创造新的模式、新的原始数据捕捉和其他特定训练数据的方法。专家可以通过注释直接创建新的数据。
- en: This creation, this control, it’s all new. While we have established patterns
    for various types of human computer interaction. There is much less established
    for human ML program interactions. For human supervision a data driven system,
    where the humans can directly correct and program the data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这种创造，这种控制，都是全新的。虽然我们已经为各种类型的人机交互建立了模式，但是对于人机学习程序交互的模式远没有那么成熟。对于人类监督数据驱动系统来说，人类可以直接修正和编程数据。
- en: For example, we expect an average office worker to know how to use word processing,
    but we don’t expect them to use video editing tools. Training data requires subject
    matter experts. So in the same way a doctor must know how to use a computer for
    common tasks today, they must now learn how to use standard annotation patterns.
    As human controlled, data driven, programs emerge and become more common these
    interactions will continue to increase in importance and variance.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们期望普通办公室工作人员知道如何使用文字处理，但我们不指望他们使用视频编辑工具。训练数据需要专家。因此，就像今天医生必须学会使用计算机进行常见任务一样，他们现在必须学会使用标准的注释模式。随着人类控制的数据驱动程序的出现和普及，这些交互将继续增加其重要性和变化性。
- en: Training Data Opportunities
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据机会
- en: Now that we understand many of the fundamentals, let’s frame some opportunities.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了许多基本原理，让我们来构思一些机会。
- en: 'If you’re considering adding Training Data to your ML/AI program, some questions
    you may want to ask are:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在考虑将训练数据添加到您的ML/AI程序中，您可能想问的一些问题是：
- en: What are the best practices?
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是最佳实践？
- en: Are we doing this the “right” way?
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否以“正确”的方式进行？
- en: How can my team work more efficiently with Training Data?
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我的团队如何能更高效地使用训练数据？
- en: What business opportunities can Training Data centric projects unlock?
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据中心项目可以解锁哪些商业机会？
- en: Can I turn an existing work process, like an existing quality assurance pipeline,
    into training data? What if all of my training data could be in one place instead
    of shuffling data from A to B to C? How can I be more proficient with Training
    Data tools?
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我能把现有的工作流程，比如现有的质量保证流水线，转化为训练数据吗？如果我的所有训练数据都可以集中在一个地方，而不是从A到B到C不停地搬运数据，会怎样？如何更有效地利用训练数据工具？
- en: 'Broadly, a business can:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 广义上来说，企业可以：
- en: Increase Revenue by shipping new AI/ML Data products.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过推出新的AI/ML数据产品增加收入。
- en: Maintain Existing Revenue by improving performance of an existing product through
    AI/ML Data.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过改进现有产品的性能来维持现有收入，通过AI/ML数据。
- en: Reduce Security Risks — Reduce risks and costs from AI/ML data exposure and
    loss.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少安全风险 — 降低因AI/ML数据暴露和丢失而造成的风险和成本。
- en: Improve Productivity by moving employee work further up the automation food
    chain. For example by continuously learning from data — creating your AI/ML Data
    engine.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将员工的工作进一步提升至自动化食物链的更高层次来提高生产力。例如，通过不断从数据中学习 — 创建您的AI/ML数据引擎。
- en: All of these elements can lead to transformations through an organization, which
    I’ll cover next.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些元素都可以通过组织来实现转型，我将在接下来详细介绍。
- en: Business Transformation
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 业务转型
- en: Your team and company’s mindset around training data is important. I’ll provide
    more detail in the Transformation Chapter, but for now, here are some important
    ways to start thinking about this.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 你团队和公司对训练数据的心态非常重要。在转型章节中我将提供更多细节，但现在，以下是一些开始思考的重要方式。
- en: Start viewing all existing routine work at the company as an opportunity for
    Training Data
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始将公司所有现有的日常工作视为训练数据的机会
- en: Realize that work not captured in a Training Data system is lost
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 认识到未在训练数据系统中捕获的工作将会丢失
- en: Begin shifting annotation to be part of every frontline worker’s day
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始将注释作为每个一线工作人员日常工作的一部分进行转移
- en: Define your organizational leadership structures to better support Training
    Data efforts
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义您的组织领导结构以更好地支持训练数据工作
- en: Manage your training data processes at scale. What works for an individual data
    scientist is very different from a team, and different still from a corporation
    with multiple teams.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在规模上管理您的训练数据流程。适用于单个数据科学家的方式与适用于团队的方式大不相同，而与拥有多个团队的公司更是不同。
- en: In order to accomplish all of this, it’s important to implement strong Training
    Data practices within your team and organization. To do this, you need to create
    a Training Data centric mindset at your company. This can be complex and may take
    time, but it’s worth the investment now.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现所有这些目标，重要的是在您的团队和组织中实施强大的训练数据实践。为此，您需要在公司内部树立一个以训练数据为中心的思维方式。这可能很复杂，可能需要时间，但现在进行投资是值得的。
- en: To do this, involve subject matter experts in your project planning discussions.
    They’ll bring valuable insights that will save your team time downstream. It’s
    also important to use tools to maintain abstractions and integrations for raw
    data collection, ingest, and egress. You’ll need new libraries for specific training
    data purposes so you can avoid reinventing the wheel. Having the proper tools
    and systems in place will help your team perform with a data centric mindset.
    And finally, make sure you and your teams are reporting and describing training
    data. Understanding what was done, why it was done, and what the outcomes were
    will inform future projects.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，要在项目计划讨论中涉及主题专家。他们将带来宝贵的见解，节省您团队未来的时间。使用工具来维护原始数据的收集、摄取和输出的抽象和集成也是非常重要的。您将需要新的库来实现特定的训练数据目的，以避免重复造轮子。确保您和您的团队报告和描述训练数据非常重要。了解做了什么、为什么这样做以及结果是什么，将为未来的项目提供信息。
- en: All of this may sound daunting now, so let’s break things down a step further.
    When you first get started with training data, you’ll be learning new training
    data specific concepts that will lead to mindset shifts. For example, adding new
    data and annotations will become part of your routine workflows. You’ll be more
    informed as you get initial datasets, schema, and other configurations setup.
    This book will help you become more familiar with new tools, new APIs, new SDKs,
    and more, enabling you to integrate training data tools into your workflow.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这些可能听起来很困难，所以让我们再深入一步。当您开始使用训练数据时，您将学习到特定的新概念，这将带来心态的转变。例如，添加新数据和注释将成为您日常工作流程的一部分。当您开始获取初始数据集、架构和其他配置时，您将变得更加了解。本书将帮助您更熟悉新工具、新API、新SDK等，使您能够将训练数据工具整合到您的工作流程中。
- en: Training Data Efficiency
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练数据效率
- en: 'Efficiency in training data is a function of many parts. We’ll explore this
    in greater detail in the chapters to come, but for now, consider these questions:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据的效率取决于多个因素。我们将在接下来的章节中详细探讨这一点，但现在，请考虑以下问题：
- en: How can we create and maintain better Schemas?
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何创建和维护更好的架构？
- en: How can we better capture and maintain Raw Data?
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何更好地捕获和维护原始数据？
- en: How can we annotate more efficiently?
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何更高效地进行注释？
- en: How can we reduce the relevant sample counts so there is less to annotate in
    the first place?
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何减少相关样本数量，以便一开始就减少注释的工作量？
- en: How can we get people up to speed on new tools?
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何让人们快速掌握新工具？
- en: How can we make this work with our application? What are the integration points?
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何将这项工作与我们的应用程序结合起来？有哪些集成点？
- en: As with most processes, there are a lot of areas to improve efficiency, and
    this book will show you how sound Training Data practices can help.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数流程一样，有很多可以提高效率的地方，这本书将向您展示如何通过健全的训练数据实践来帮助您。
- en: Tooling Proficiency
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工具熟练度
- en: New tools, like Diffgram, now offer many ways to help realize your Training
    Data goals. As these tools grow in complexity, being able to master them becomes
    more important. You may have picked up this book looking for a broad overview,
    or to optimize specific pain points. The tooling chapter will dive into those
    concerns.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 新工具，如Diffgram，现在提供了许多帮助实现你的训练数据目标的方法。随着这些工具复杂性的增加，掌握它们的能力变得更加重要。你可能拿起这本书是为了获取广泛的概述，或者优化特定的痛点。工具章节将深入探讨这些问题。
- en: Common Pain Points
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见的痛点
- en: 'To highlight a few common challenges, such as:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 突出一些常见的挑战，比如：
- en: Annotation quality is poor, too costly, too manual, too error prone.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注释质量不佳，成本太高，手工操作过多，容易出错。
- en: Duplicate work
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复工作
- en: Subject matter expert labor cost too high
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主题专家劳动成本过高
- en: Too much routine or tedious work
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 太多例行或乏味的工作
- en: It is near impossible to get enough of the original raw data
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很难获得足够的原始数据
- en: Raw data volume clearly exceeds any reasonable ability to manually look at it.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始数据量显然超出了任何手工查看的合理能力。
- en: What are you trying to achieve with Training Data?
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望通过训练数据实现什么目标？
- en: Why Training Data Matters
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么训练数据如此重要
- en: In this section, I’ll cover why Training Data is important for your organization.
    And why a strong training data practice is essential. These are central themes
    throughout the book, and you’ll see them come up again in the future.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我将讨论为什么训练数据对您的组织如此重要。以及为什么强大的训练数据实践至关重要。这些是本书始终关注的核心主题，在今后的内容中您会再次看到它们。
- en: First, Training Data determines what your AI program, your system, can do. Without
    Training Data there is no system. With Training Data the opportunities are only
    bounded by your imagination. Anything that you can form into a Schema and record
    raw data for, the system can repeat. It can learn anything. Meaning the intelligence
    and ability of the system depends on the quality of the Schema, and the volume
    and variety of data you can teach it.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，训练数据决定了你的AI程序、你的系统能做什么。没有训练数据就没有系统。有了训练数据，机会只受你的想象力限制。任何你能形成架构并记录原始数据的内容，系统都能重复。它可以学习任何东西。这意味着系统的智能和能力取决于架构的质量，以及你可以教给它的数据的数量和多样性。
- en: Second, Training Data work is upstream, before Data Science work. This means
    Data Science is dependent on Training Data. Errors in Training Data flow down
    to Data Science. Or to use the cliché - garbage in, garbage out. Figure 1-2 walks
    through what this data flow looks like in practice.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，训练数据工作是上游工作，即在数据科学工作之前进行。这意味着数据科学依赖于训练数据。训练数据中的错误会影响到数据科学的结果。或者用老生常谈的话说 -
    垃圾进，垃圾出。图1-2展示了这种数据流在实践中的工作原理。
- en: '![Fig 1 2 Conceptual position of training data and data science](Images/training_data_introduction_865720_02.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图 1-2 训练数据和数据科学的概念位置](Images/training_data_introduction_865720_02.png)'
- en: Figure 1-2\. Conceptual position of training data and data science
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. 训练数据和数据科学的概念位置
- en: Third, The Art of Training Data represents a shift in thinking about how to
    build AI systems. Instead of over focus on improving mathematical algorithms,
    in parallel we optimize the Training Data to better match our needs. This is the
    heart of the AI Transformation taking place and the core of modern automation.
    For the first time knowledge work is now being automated.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，训练数据的艺术代表了如何思考构建AI系统的转变。我们不再过度关注改进数学算法，而是与此同时优化训练数据以更好地满足我们的需求。这是AI转型的核心，也是现代自动化的核心。知识工作首次被自动化。
- en: ML Applications are Becoming Mainstream
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习应用正在成为主流
- en: In 2005 a university team used a Training Data based^([2](ch01.xhtml#idm45486432521344))
    approach to drive autonomously on an off-road 175-mile long desert course, winning
    the [DARPA grand challenge](https://www.computerhistory.org/timeline/ai-robotics/).^([3](ch01.xhtml#idm45486432365104))
    About 15 years later, in October 2020, an automotive company released a controversial
    [Full Self Driving (FSD)](https://www.theverge.com/2020/10/22/21528508/tesla-full-self-driving-beta-first-reaction-video)
    technology in public, ushering in a new era of consumer awareness. In 2021, data
    labeling concerns started getting mentioned on earnings calls. In other words,
    the mainstream is starting to get exposed to Training Data.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在2005年，一支大学团队采用了基于训练数据的方法，在一个长达175英里的沙漠赛道上实现了自动驾驶，赢得了[DARPA大挑战](https://www.computerhistory.org/timeline/ai-robotics/)。大约15年后的2020年10月，一家汽车公司在公众中发布了一项具有争议的[全自动驾驶技术（FSD）](https://www.theverge.com/2020/10/22/21528508/tesla-full-self-driving-beta-first-reaction-video)，开启了消费者意识新时代。2021年，数据标注问题开始在财报电话中被提及。换句话说，主流开始接触训练数据。
- en: This commercialization goes beyond headlines of AI research results. In the
    last few years we have seen the demands placed on technology increase dramatically.
    We expect to be able to speak to software and be understood, to automatically
    get good recommendations and personalized content. Big tech companies, startups,
    and business alike are increasingly turning to AI to solve this explosion in use
    case combinations.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这种商业化超越了AI研究成果的头条新闻。在过去几年中，我们看到对技术的需求急剧增加。我们期望能与软件进行交流并被理解，自动获得良好的推荐和个性化内容。大型科技公司、初创企业和企业都越来越倾向于利用AI来解决这些应用案例组合的爆炸性增长。
- en: AI knowledge, tooling and best practices rapidly expand. What used to be the
    exclusive domain of a few is now becoming common knowledge and pre-built API calls.
    We are at the transition phase, going from R&D demos, to the early stage of real
    world industry use cases.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: AI知识、工具和最佳实践迅速扩展。过去只有少数人的专属领域现在正在成为常识和预构建API调用。我们正处于过渡阶段，从研发演示到早期的真实世界行业使用案例阶段。
- en: Expectations around automation are being redefined. Cruise control to a new
    car buyer has gone from just “maintain constant speed” to include “lane keeping,
    distance pacing, and more”. These are not future considerations. These are current
    consumer and business expectations. They are clear and present needs to have an
    AI strategy and to have ML and training data competency in your company.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化期望正在被重新定义。对于新车购买者来说，定速巡航已经不再仅限于“保持恒定速度”，还包括“车道保持、距离保持等”。这些不是未来的考虑，而是当前消费者和企业的期望。这些是明确且迫切的需要，需要制定AI战略并在公司中具备ML和训练数据能力。
- en: The Foundation of Successful AI
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成功AI的基础
- en: Machine Learning is about learning from data. Historically, this meant creating
    datasets in the form of logs, or similar tabular data such as “Anthony viewed
    a video.”
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是关于从数据中学习的。从历史上看，这意味着创建类似日志或类似表格数据的数据集，比如“安东尼观看了一个视频”。
- en: These systems continue to have significant value. However, they have some limits.
    They won’t help us do things modern training data powered AI can do like build
    systems to understand a CT Scan or other medical imaging, understand football
    tactics, or in the future operate a vehicle.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这些系统继续具有显著的价值。然而，它们也有一些限制。它们不能帮助我们做现代训练数据驱动的AI可以做的事情，比如构建理解CT扫描或其他医学图像的系统，理解足球战术，或者未来驾驶车辆。
- en: The idea behind this new type of AI is a human expressly saying “here’s an example
    of what a player passing a ball” looks like, “Here’s what a tumor looks like”,
    or “This section of the apple is rotten”.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这种新型AI背后的理念是人类明确地说“这是一个球员传球的示例是什么样子的”，“这是一个肿瘤的样子”，或者“这个苹果的这部分是腐烂的”。
- en: 'This form of expression is similar to how in a classroom a teacher explains
    concepts to students: by words and examples. Teachers help fill the gap between
    the textbooks, and the multidimensional *understanding* that a student builds
    over time. In Training Data, the annotator acts as the teacher, filling the gap
    between the Schema and the raw data.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这种表达形式类似于在课堂上老师向学生解释概念的方式：通过文字和例子。老师帮助填补教科书和学生随时间建立的多维度*理解*之间的差距。在训练数据中，标注者充当教师，填补模式和原始数据之间的差距。
- en: Dataset (Definition)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集（定义）
- en: A dataset is like a folder. It usually has the special meaning that there are
    both “raw” data (such as images) and annotations in the same place. For example
    a folder of 100 images plus a text file that lists the annotations. In practice
    a dataset is dynamic and stored in part in a database form.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集就像一个文件夹。通常它有一个特殊的含义，即在同一个地方有“原始”数据（例如图像）和注释。例如，一个包含100张图片和一个列出注释的文本文件的文件夹。在实践中，数据集是动态的，并部分存储在数据库形式中。
- en: Training Data is Here to Stay
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练数据是不可或缺的
- en: Training Data is going to be here for a very long time. Conceptually I think
    Training Data concepts will still exist decades, or even a century or more from
    now. How can I say that with confidence? Let’s think about the trends.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据将会在很长一段时间内存在。从概念上讲，我认为训练数据的概念将在几十年甚至一个世纪后仍然存在。我如何能如此自信地说呢？让我们思考一下趋势。
- en: As mentioned earlier, use cases for modern AI/ML data are transitioning from
    R&D to industry. We are at the very start of a long curve on that business cycle.
    Naturally the specifics shift quickly. However, the conceptual ideas around thinking
    of day to day work as annotation, encouraging people to strive more and more for
    unique work, and oversight of increasingly capable ML programs, are all here to
    stay.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，现代人工智能/机器学习数据的用途正在从研发转向工业应用。我们处于业务周期的早期阶段。自然地，具体的细节迅速变化。然而，围绕将日常工作视为注释的概念、鼓励人们追求更独特工作的想法，以及监督日益强大的机器学习程序的概念，都将长期存在。
- en: On the research side, algorithms and ideas on how to use Training Data both
    keep improving. For example, the trend is for certain types of models to require
    less and less data to be effective. The less samples a model needs to learn, the
    more weight is put on creating Training Data with greater breadth and depth. And
    on the other side of the coin, many industry use cases often require even greater
    amounts of data to reach business goals. In that business context, the need for
    more and more people to be involved in training data puts further pressure on
    tooling.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究方面，关于如何使用训练数据的算法和想法不断改进。例如，某些类型的模型越来越不需要大量数据就能发挥作用的趋势。模型所需的样本越少，就越重视创造广度和深度更大的训练数据。另一方面，在许多行业应用案例中，通常需要更多的数据才能实现业务目标。在这种商业背景下，需要更多人参与训练数据，进一步增加了工具的压力。
- en: In other words, the expansion directions of research and industry put more and
    more importance on Training Data over time.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，研究和工业的扩展方向随着时间的推移越来越重视训练数据的重要性。
- en: Training Data Controls the ML Program
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练数据控制机器学习程序
- en: The question in any system is control. Where is the control? In normal computer
    code, this is human-written logic in the form of loops, if statements, etc. This
    logic defines the system.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 任何系统中的问题是控制。控制在哪里？在正常的计算机代码中，这是以人为书写的逻辑形式存在，如循环，条件语句等等。这种逻辑定义了系统。
- en: In classic Machine Learning, the first steps include defining features of interest
    and a dataset. Then an algorithm generates a model. While it may appear that the
    algorithm is in control, the real control is exercised by choosing the features
    and data. The algorithm’s degrees of freedom are then controlled by the features
    and the data.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在经典的机器学习中，第一步包括定义感兴趣的特征和数据集。然后算法生成模型。虽然看起来算法控制一切，但真正的控制在于选择特征和数据。然后算法的自由度由特征和数据控制。
- en: In a Deep Learning system, the algorithm does its own Feature Selection. The
    algorithm attempts to determine what features are relevant to a given goal. That
    goal is defined by Training Data itself. In fact, Training Data is the *entire
    definition* of the goal.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习系统中，算法自行进行特征选择。算法试图确定哪些特征与给定目标相关。这个目标由训练数据本身定义。事实上，训练数据是目标的*整个定义*。
- en: Here’s how it works. An internal part of the algorithm, called a loss function,
    describes a key part of how the algorithm can learn a good representation of this
    goal. The algorithm uses the loss function to determine how close it is to the
    goal defined in the training data.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 它是如何工作的呢？算法的内部部分称为损失函数，描述了算法如何学习实现这一目标的关键部分。算法使用损失函数来确定它距离训练数据中定义的目标有多接近。
- en: More technically, the loss is the error we want to minimize during training.
    The loss function doesn’t work without having some exterior defined goal (such
    as the training data). In a sense, this is a “goal within a goal”. It’s the Loss
    function’s goal to optimize the Loss, but it can only do that by having some reference
    point, which is defined by the training data.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 更技术化地说，损失是我们在训练期间希望最小化的错误。没有一些外部定义的目标（如训练数据），损失函数就无法工作。在某种意义上，这是一个“目标中的目标”。损失函数的目标是优化损失，但它只能通过有些参考点来实现，这些参考点由训练数据定义。
- en: Therefore, the training data is the “ground truth” for correctness of the model’s
    relationship to the human defined goal.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，训练数据是模型与人类定义的目标之间关系正确性的“真实情况”。
- en: To further understand why this is the case, consider that in many use cases
    the loss function is closely related to the task. For example, a given object
    detection approach usually includes references to a specific loss function. That
    said, in the case of “unsupervised” learning the Loss function may be more related
    to the goal. While this may seem like a contradiction at first blush, for practical
    purposes it’s generally not relevant to supervised cases.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步理解这种情况的原因，考虑到在许多用例中，损失函数与任务密切相关。例如，给定的物体检测方法通常包括对特定损失函数的引用。也就是说，在“无监督”学习的情况下，损失函数可能更与目标相关。虽然这乍一看似乎是矛盾的，但在实际目的上，对于监督案例来说通常不相关。
- en: New Types of Users
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新用户类型
- en: In traditional software development there is a degree of dependency between
    the end user and the engineering. The end user cannot truly say if the program
    is “correct”, and neither can the engineer.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统软件开发中，最终用户和工程之间存在一定程度的依赖关系。最终用户无法真正说出程序是否“正确”，工程师也无法。
- en: It’s hard for an end user to say what they want until a prototype of it has
    been built. Therefore both the end user and engineer are dependent on each other.
    This is called a circular dependency. The ability to improve the software comes
    from the interplay between both, to be able to iterate together.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 最终用户很难在建立原型之前表达他们想要什么。因此，最终用户和工程师彼此依赖。这被称为循环依赖。改进软件的能力来自于两者的互动，能够共同迭代。
- en: With Training Data, the humans control the meaning of the system when doing
    the literal supervision. The Data Scientists control it when working on the Schema,
    such as choosing abstractions such as label templates.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练数据方面，当进行文字监督时，人类控制系统的含义。数据科学家在处理模式时控制它，例如选择抽象化，如标签模板。
- en: For example, if I as an annotator were to label a tumor as cancerous when in
    fact it’s benign, I would be controlling the output of the system in a detrimental
    way. In this context, it’s worth understanding there is no validation possible
    to ever 100% eliminate this control. Engineering cannot, both because of volume
    of data and because of lack of subject matter expertise, control the data system.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我作为注释者在实际上一个良性的肿瘤被标记为癌症性，那么我将以有害的方式控制系统的输出。在这种情况下，值得理解的是，不可能完全消除这种控制的验证，工程技术无法做到这一点，既因为数据量，也因为缺乏主题专业知识。
- en: There used to be this assumption that Data Science knew what ‘correct’ was.
    The theory was that they could define some examples of “correct”, and then as
    long as the human supervisors generally stuck to that guide, they knew what correct
    was. The problem is, how can an English speaking data scientist know if a translation
    to French is correct? How can a data scientist know if a doctor’s medical opinion
    on an X-Ray image is correct? The short answer is - they can’t. As the role of
    AI systems grows subject matter experts increasingly exercise control on the system
    that supersedes Data Science.^([4](ch01.xhtml#idm45486432332832))
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 曾经有这样一种假设，认为数据科学家知道什么是“正确”的。理论上，他们可以定义一些“正确”的例子，只要人类监督员大致遵循这一指南，他们就知道什么是正确的。问题是，一个说英语的数据科学家如何知道法语的翻译是否正确？数据科学家如何知道医生对X光图像的医学意见是否正确？简短的答案是
    - 他们不能。随着AI系统角色的增长，学科专家越来越多地在超越数据科学的系统上行使控制。
- en: To understand why this goes beyond the “garbage in, garbage out” phrase. Consider
    that in a traditional program, while the end user may not be happy, the engineer
    can, through a concept called unit tests, at least guarantee that the code is
    “correct”. This doesn’t mean that it gives the output desired by the end user,
    but just that the code does what the engineer feels it’s supposed to do.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解为什么这超出了“垃圾进，垃圾出”这一短语。考虑到在传统程序中，虽然最终用户可能不会感到满意，但工程师可以通过一个称为单元测试的概念，至少保证代码是“正确的”。这并不意味着它提供了最终用户所期望的输出，而只是代码是否执行了工程师认为它应该执行的操作。
- en: Writing that style of unit test is impossible in the context of training data*–*
    because the controls available to engineering, such as a validation set, are still
    based on the control executed by the individual AI supervisors.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练数据的背景下编写这种单元测试是不可能的*——*因为工程师可以控制的控件，如验证集，仍然基于个体AI监督员执行的控件。
- en: Further, the AI supervisors are generally bound by the control exerted by engineering
    in defining the abstractions they are allowed to use. The end user is coding through
    data. In a sense the end user is woven into the fabric of the system itself.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，AI监督员通常受到工程定义的控制，工程定义了他们允许使用的抽象。最终用户通过数据进行编码。在某种程度上，最终用户被编织到系统本身的结构中。
- en: This blurring of the lines between “content” and “system” is important.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: “内容”和“系统”之间的界限变得模糊是很重要的。
- en: This is distinctly different from classic systems. For example, on a social
    media platform, your content may be the value, but it’s still clear what is the
    literal system (the box you type in, the results you see, etc) and the content
    you post (text, pictures, etc).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这与传统系统截然不同。例如，在社交媒体平台上，你的内容可能是价值所在，但系统的文字（你输入的框，你看到的结果等）和你发布的内容（文本，图片等）之间仍然清晰可见。
- en: 'Examples of control include:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 控制的例子包括：
- en: Abstractions, like the Schema, define one level of control.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 抽象概念，比如模式，定义了一级控制。
- en: Annotation, literally looking at samples, defines another level of control.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标注，字面上看样本，定义了另一级控制。
- en: While Data Science may control the algorithms, the controls of Training data
    often act in an “oversight” capacity, above the algorithm.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数据科学可能控制算法，但训练数据的控制通常以“监督”的角色存在，高于算法。
- en: Training Data in the Wild
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 野外训练数据
- en: So far, we’ve covered a lot of concepts and theory, but training data in practice
    can be a complex and challenging thing to do well.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了许多概念和理论，但实践中的训练数据可能是一件复杂和具有挑战性的事情。
- en: What Makes Training Data Difficult?
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么使训练数据变得困难？
- en: The apparent simplicity of data annotation hides the vast complexity, novel
    considerations, new concepts and new forms of art involved. It may appear that
    a human selects an appropriate label, the data goes through a machine process,
    and voila, we have a solution, right? Well, not quite. Here are a few common elements
    that can prove difficult.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 数据标注的显而易见的简单性掩盖了涉及的广泛复杂性，新颖的考虑因素，新概念和新形式的艺术。可能会出现这样的情况：看起来好像是一个人选择了适当的标签，数据经过了机器处理，然后，哇，我们有了一个解决方案，对吧？嗯，并不完全是这样。以下是一些可能令人困惑的常见元素。
- en: When experts from various fields have to work closely with each other.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当来自各个领域的专家必须紧密合作时。
- en: Subject matter experts (SMEs) are working with technical folks in new ways and
    vice versa. These new social interactions introduce new people challenges.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主题专家（SME）正在与技术人员以及反过来的方式进行新的社交互动，这些新的社交互动引入了新的人际挑战。
- en: Experts have individual experiences, beliefs, inherent bias, and prior experiences.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专家有个人经历，信念，固有偏见和先前的经验。
- en: Users are operating novel annotation interfaces with few common expectations
    on what standard design looks like
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户正在操作具有少量共同期望的新颖标注界面，这些共同期望定义了标准设计的样式。
- en: The problem itself may be difficult with unclear answers or poorly defined solutions
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题本身可能很难，答案不明确或解决方案定义不清晰。
- en: Even if the knowledge is well formed in a person’s head, and the person is familiar
    with the annotation interface, inputting that knowledge accurately can be tedious
    and time consuming
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使知识在一个人的头脑中形成，而且该人熟悉标注界面，准确输入这些知识也可能是乏味且耗时的。
- en: Often there is a voluminous amount of data labeling work with multiple datasets
    to manage and technical challenges around storing, accessing and querying the
    new forms of data
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经常需要大量的数据标记工作，并管理多个数据集以及围绕存储，访问和查询新形式数据的技术挑战。
- en: Given that this is a new discipline, there is a lack of organizational experience
    and operational excellence that can only come with time
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鉴于这是一个新的学科，缺乏组织经验和操作卓越，这些只能随着时间的推移逐步积累
- en: Organizations with a strong classical ML culture may have trouble adapting to
    this fundamentally different, yet operationally critical, area. This blindspot
    of thinking they have already understood and implemented ML when in fact it’s
    a totally different form.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有强大的传统机器学习文化的组织可能在适应这个基本上不同但在运营上至关重要的领域时遇到困难。这种盲点认为他们已经理解和实施了机器学习，而事实上这是完全不同的形式。
- en: There is a lack of awareness, access or familiarity to the right training data
    tools
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏对正确训练数据工具的意识、访问或熟悉
- en: As a new art form general ideas and concepts are not well known
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为一种新的艺术形式，一般的想法和概念并不广为人知
- en: Schemas may be complex with thousands of elements including nested conditional
    structures
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式可能非常复杂，包括数千个元素，包括嵌套的条件结构
- en: Media formats impose challenges like series, relationships, and 3D navigation
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 媒体格式带来了一些挑战，如系列、关系和3D导航
- en: Most automation tools introduce new challenges and difficulties
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数自动化工具引入了新的挑战和困难
- en: And that’s the *short* list.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 而这只是*简短*列表。
- en: While the challenges are myriad and at times difficult, we’ll tackle each of
    these in this book to provide a roadmap you and your organization can implement
    to improve training data.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然挑战是多样的，有时也很困难，但我们将在本书中解决每一个，为您和您的组织提供可以实施以改进训练数据的路线图。
- en: The Art of Supervising Machines
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**监督机器的艺术**'
- en: Up to this point, we’ve covered some of the basics and a few of the challenges
    around training data. Let’s shift gears away from the science for a moment and
    focus on the art. The apparent simplicity of annotation hides the vast volume
    of work involved. Annotation is to Training Data is what typing is to writing.
    Simply pressing keys on a keyboard doesn’t provide value if you don’t have the
    human element informing the action and accurately carrying out the task.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了一些关于训练数据的基础知识和一些挑战。让我们暂时远离科学，专注于艺术。注释的表面简单掩盖了所涉及的大量工作。注释对训练数据来说就像打字对写作一样重要。如果没有人的参与和准确执行任务的动作，简单地在键盘上按键并不会提供价值。
- en: Training Data is a new paradigm upon which a growing list of mindsets, theories,
    research and standards are emerging. This involves technical representations,
    people decisions, processes, tooling, system design, and a variety of new concepts
    specific to it.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据是一个新的范例，正在涌现出一长串思维方式、理论、研究和标准。这涉及技术表示、人员决策、流程、工具、系统设计以及特定于它的各种新概念。
- en: One thing that makes training data so special is that it is capturing the user’s
    knowledge, intent, ideas, concepts, *without* specifying “how” they arrived at
    them. For example if I label a “bird”, I am not telling the computer what a bird
    is, the history of birds, etc.-- only that it *is* a bird. This idea of conveying
    a high level of intent is different from most classic programming perspectives.
    Throughout this book I will come back to this idea of thinking of training data
    as a new form of coding.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据之所以如此特殊的一点是，它捕捉了用户的知识、意图、想法、概念，*而不是*指定“它们是如何”得到的。例如，如果我标记一个“鸟”，我并没有告诉计算机鸟是什么，鸟的历史等等——只是它*是*一只鸟。这种传达高层次意图的想法与大多数经典编程观点不同。在本书中，我将不断回到这种将训练数据视为一种新形式编码的思想。
- en: A New Thing
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种新事物
- en: Training Data is not Data Science. They have different goals. Training Data
    produces structured data. Data Science consumes it. Training Data is mapping human
    knowledge from the real world into the computer. Data Science is mapping that
    data back to the real world. They are the two different sides of the coin.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据不等同于数据科学。它们有不同的目标。训练数据产生结构化数据。数据科学则消费这些数据。训练数据是将人类知识从现实世界映射到计算机中。数据科学则将这些数据映射回现实世界。它们是同一枚硬币的两个不同面。
- en: In the same way that model is embedded in an application, even a minimal input/output,
    in order to be useful, training data must be consumed by data science to be useful.
    The fact that it’s used in this way should not detract from its differences. There
    are still mappings of concepts to a form usable by data science. The point is
    having clearly defined abstractions between them, instead of ad-hoc guessing on
    terms.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 就像模型嵌入到应用程序中一样，即使是最小的输入/输出，为了有用，训练数据也必须被数据科学消费。事实上，它被这种方式使用不应该减损其差异性。仍然有将概念映射到数据科学可用形式的过程。关键是在它们之间有清晰定义的抽象，而不是在术语上的临时猜测。
- en: It seems more reasonable to think of Training Data as an Art practiced by all
    the other professions, than to think of Data Science as the all encompassing starting
    point. Given how many subject matter experts and non-technical people are involved,
    that rather preposterous alternative would seem to assume that Data Science towers
    over all!
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 把训练数据看作是所有其他专业实践的一种艺术，而不是把数据科学视为一切开始的起点，似乎更合理。考虑到有多少学科专家和非技术人员参与其中，那种相当荒谬的替代假设似乎是认为数据科学高高在上！
- en: While attempting to call anything a new art form is automatically presumptuous,
    I take solace in that I am simply labeling something people are already doing.
    In fact, things make much more sense when we treat it as its own art and stop
    shoehorning into other existing given categories.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管称任何事物为新艺术形式可能是自作多情的，但我在于我只是在给已经做的事情贴标签。事实上，当我们将其视为独立的艺术形式并停止把它硬塞到其他已有的类别中时，一切就显得更合理了。
- en: I cover this in more detail in chapter 7 - AI Transformation.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我在第七章“AI转型”中详细介绍这个问题。
- en: 'Because Training Data is new, the language and definitions remain fluid. The
    following terms are all closely related:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 由于训练数据是新的，语言和定义仍然不确定。以下术语都密切相关：
- en: Training Data
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据
- en: Data Labeling
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据标记
- en: Human Computer Supervision
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人机监督
- en: Annotation
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注释
- en: Data Program
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据程序
- en: 'Depending on the context, those terms can map to various definitions:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上下文，这些术语可以映射到各种定义：
- en: The overall Art of Training Data.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练数据的整体艺术。
- en: The act of annotating, such as drawing geometries and answering Schema questions.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注释行为，例如绘制几何形状和回答模式问题。
- en: The definition of what we want to achieve in a machine learning (ML) system,
    the ideal state desired, the control of the ML system, including correction of
    existing systems.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在机器学习（ML）系统中我们想要达到的定义，期望的理想状态，对ML系统的控制，包括纠正现有系统。
- en: A system that relies on human controlled data.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 依赖于人类控制的数据系统。
- en: For example, I can say Annotation as a specific sub component of the overall
    concept of Training Data. I can also say “to work with Training Data”, to mean
    the act of annotating. As a novel developing area people may say Data Labeling
    and mean just the literal basics of annotation, while others mean the overall
    concept of Training Data.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我可以说注释是训练数据整体概念的一个具体子组件。我也可以说“使用训练数据工作”，意味着进行注释的行为。作为一个新兴领域，人们可能会说数据标记，指的只是注释的基本文字意义，而其他人可能指整体的训练数据概念。
- en: The short story here is it’s not worth getting too hung up on any of those terms,
    and the context it’s used in is usually needed to understand the meaning.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，不值得过多关注这些术语，通常需要了解其使用的上下文来理解含义。
- en: Media Types
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 媒体类型
- en: Data comes in many media types. Popular media types include Images, Videos,
    Text, PDF/Document, HTML, Audio, Timeseries, 3D/DICOM, Geospatial, Sensor Fusion,
    Multimodal. While popular media types are often the best supported in practice,
    in theory any media type can be used. Forms of Annotation include attributes (detailed
    options), geometries, relationships and more. We’ll cover all of this in great
    detail as the book progresses, but it’s important to note that if a media type
    exists, someone is likely attempting to extract data from it.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 数据有许多媒体类型。流行的媒体类型包括图像、视频、文本、PDF/文档、HTML、音频、时间序列、3D/DICOM、地理空间、传感器融合、多模态。虽然流行的媒体类型在实践中通常得到最好的支持，但理论上任何媒体类型都可以使用。注释的形式包括属性（详细选项）、几何形状、关系等。随着本书的进展，我们将详细介绍所有这些内容，但重要的是要注意，如果存在某种媒体类型，可能会有人试图从中提取数据。
- en: ML Program Ecosystem
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML程序生态系统
- en: Training Data interacts with a growing ecosystem of adjacent programs and concepts.
    It is common to send data from a Training Data program to an ML Modeling program.
    Or to install an ML program on a Training Data platform. Production data, such
    as predictions, are often sent to a Training Data program for validation, review,
    and further control. The linkage between these various programs continues to expand.
    Later in this book we cover some of the technical specifics of ingesting and streaming
    data.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据与日益扩展的相邻程序和概念生态系统相互作用。通常会将数据从训练数据程序发送到ML建模程序。或者在训练数据平台上安装ML程序。生产数据，如预测结果，通常会发送到训练数据程序进行验证、审查和进一步控制。这些各种程序之间的联系继续扩展。本书后面将详细介绍数据的摄入和流处理的技术细节。
- en: Data-Centric Machine Learning
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据中心化机器学习
- en: Subject matter experts (SMEs) and data entry folks may end up spending 4-8 hours
    a day, every day, on training data tasks like annotation. It’s a time-intensive
    task, and it may become their primary work. In some cases, 99% of the overall
    team’s time is spent on Training Data and 1% on the modeling process, for example
    by using an AutoML type solution or having a large team or SMEs.^([5](ch01.xhtml#idm45486432456544))
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 专业领域专家（SMEs）和数据录入人员可能每天每天花费4-8小时在诸如标注之类的训练数据任务上。这是一项耗时的任务，可能会成为他们的主要工作。在某些情况下，整个团队99%的时间都花在训练数据上，而只有1%花在建模过程上，例如使用AutoML类型的解决方案或拥有大型团队或SMEs。^([5](ch01.xhtml#idm45486432456544))
- en: Data-Centric AI is focusing on Training Data as being its own important thing.
    Creating new data, new Schema’s, new raw data capture, and new annotations by
    subject matter experts. Developing programs with Training Data at the heart, and
    deeply integrating Training Data into aspects of your program. There was mobile-first,
    and now there’s data-first.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心化AI专注于将训练数据作为其重要组成部分。通过专业领域专家创建新数据、新架构、新原始数据捕捉和新注释。开发以训练数据为核心，并将训练数据深度整合到程序各个方面的程序。先有移动端优先，现在有数据优先。
- en: 'In the data centric mindset you can:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据中心化的思维模式下，您可以：
- en: Use or add data collection points. Such as New sensors. New cameras, new ways
    to capture documents etc.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用或添加数据收集点。例如新传感器、新摄像头、捕捉文档的新方法等。
- en: Add new human knowledge.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加新的人类知识。
- en: 'The rationales behind a data-centric approach are:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心化方法背后的理念是：
- en: The majority of the work is in the training data, and the data science aspect
    is out of our control.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大部分工作都在训练数据上，数据科学方面超出我们的控制。
- en: There are more degrees of freedom with training data and modeling, than with
    algorithm improvements alone.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据和建模中，比仅仅改进算法具有更多的自由度。
- en: When I combine this idea of Data-Centric AI, with the idea of seeing the breadth
    and depth of Training Data as its own art, I start to see the vast fields of opportunities.
    What will you build with training data?
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 当我将数据中心化AI的这一思想与将训练数据的广度和深度视为一种艺术的想法相结合时，我开始看到广阔的机会领域。您将用训练数据构建什么？
- en: Failures
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 失败
- en: It’s common for any system to have a variety of bugs and still generally “work”.
    Data programs are similar. For example some classes of failures are expected,
    and others are not. Let’s dive in.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 任何系统通常都会有各种各样的错误，但总体上“工作”。数据程序也是如此。例如，某些类别的失败是预期的，而其他类别则不是。让我们深入了解一下。
- en: Data programs work when their associated sets of assumptions remain true. For
    example, assumptions around the Schema and raw data. These assumptions are often
    most obvious are creation, but can be changed or modified as part of a data maintenance
    cycle.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 数据程序在其相关的假设集保持真实时运行。例如，关于架构和原始数据的假设。这些假设在创建时通常最为明显，但可以作为数据维护周期的一部分进行更改或修改。
- en: To dive into a visual example, imagine a parking lot detection system. The system
    may have very different views as shown in [Figure 1-3](#fig_3_5_comparison_of_major_differences_in_raw_data_that).5\.
    If we create a training data set based on a top down view (left) and then attempt
    to use a car level view (right) we will likely get an “unexpected” class of failure.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解一个视觉示例，想象一下停车场检测系统。该系统可能有不同的视角，如[图1-3](#fig_3_5_comparison_of_major_differences_in_raw_data_that)所示。如果我们基于顶视图创建一个训练数据集（左侧），然后尝试使用汽车级视图（右侧），我们可能会遇到“意外”的失败类别。
- en: '![5 Comparison of major differences in raw data that would likely lead to an
    unexpected failure ](Images/training_data_introduction_865720_03.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![5 比较主要差异的原始数据，可能会导致意外失败 ](Images/training_data_introduction_865720_03.png)'
- en: Figure 1-3\. Comparison of major differences in raw data that would likely lead
    to an unexpected failure
  id: totrans-242
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3\. 比较主要差异的原始数据，可能会导致意外失败
- en: Why is it a failure? A machine learning system trained only on images from a
    top-down view as in the left image has a hard time running in an environment where
    the images are from a front view as shown in the right image. In other words,
    the system would not understand the concept of a car and parking lot from a front
    view if it has never seen such an image during training.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么会失败？一个仅训练于如左图所示的顶视图的机器学习系统，在如右图所示的前视图环境中运行时会遇到困难。换句话说，如果在训练期间从未见过这样的图像，系统将无法理解从前视图中看到的汽车和停车场的概念。
- en: While this may seem obvious, a very similar issue caused [a real world failure](https://www.defenseone.com/technology/2021/12/air-force-targeting-ai-thought-it-had-90-success-rate-it-was-more-25/187437/)
    in a US Air Force system, leading them to think their system was materially better
    than it actually was.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这可能显而易见，但一个非常相似的问题导致了美国空军系统的 [一次真实世界失败](https://www.defenseone.com/technology/2021/12/air-force-targeting-ai-thought-it-had-90-success-rate-it-was-more-25/187437/)，使他们认为他们的系统比实际情况好得多。
- en: How can we prevent failures like this? Well for this specific one it’s a clear
    example of why it’s important that the data we use to train a system closely matches
    production data. What about failures that aren’t listed specifically in a book?
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何预防这样的失败？对于这个具体的例子，重要的是我们使用来训练系统的数据与生产数据尽可能接近。那么，还有哪些未在书中明确列出的失败呢？
- en: The first step is being aware of training data best practices. Earlier talking
    about the Human Role, I mentioned how communication with annotators and subject
    matter experts is important. Annotators need to be able to flag issues. Issues
    between Schema and raw data alignment. And to surface issues outside the scope
    of specified instructions and Schema, e.g. that “common sense” that something
    isn’t right.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是意识到训练数据的最佳实践。之前提到人类角色时，我提到了与标注者和主题专家的沟通的重要性。标注者需要能够标记问题。Schema 和原始数据之间的问题。以及表明指定说明和
    Schema 范围之外的问题，例如“常识”，即某些事情不对劲。
- en: Admins need to be aware of the concept of creating a novel, well named, Schema.
    That the raw data should always be relevant to the Schema. That maintenance of
    the data will be required.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员需要意识到创建一个新颖且命名良好的 Schema 的概念。原始数据应始终与 Schema 相关。数据的维护将是必要的。
- en: Failure modes are surfaced during development through discussions around Schema,
    expected data usage, and discussions with Annotators.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发过程中，通过对 Schema、预期数据使用情况的讨论以及与标注者的讨论，会暴露出失败模式。
- en: Failure Example In a Deployed Systems
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署系统中的失败示例
- en: Given how new some of these systems are it’s likely that we have barely seen
    the smallest of the failure cases of training data.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于一些系统的新颖性，我们很可能只见到了训练数据中最小的失败案例。
- en: In April 2020, Google deployed a medical AI to help with COVID-19.^([6](ch01.xhtml#idm45486432212944))
    They trained it higher quality scans then what was available during production.
    So when people went to actually use it, they had to often retake the scans to
    try and meet that expected quality level. And even with this extra burden of retaking
    them, the system still rejected about 25%. That would be like an email service
    that made you resend every second email and completely refused to deliver every
    fourth email.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 2020 年 4 月，Google 部署了一款医疗 AI 来帮助 COVID-19。^([6](ch01.xhtml#idm45486432212944))
    他们训练了比生产时可用的更高质量的扫描。所以当人们实际使用它时，他们经常不得不重新扫描，以达到预期的质量水平。即使在重新扫描的额外负担下，系统仍然拒绝了大约
    25% 的情况。这就像一个电子邮件服务，使您不得不重新发送每第二封电子邮件，并且完全拒绝发送每第四封电子邮件。
- en: Of course there are nuances to that story but conceptually it shows how important
    it is to align the development and production data. What the system trains on
    needs to resemble what will actually be used in the field. In other words, don’t
    use “lab” level scans for the development set and then expect a smart phone camera
    to work well in production. If production will be using a smart phone camera then
    the training data needs to be from it too.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这个故事有其细微之处，但概念上显示了开发和生产数据对齐的重要性。系统训练的内容必须与实际使用的内容相似。换句话说，不要在开发集中使用“实验室”级别的扫描，然后期望智能手机摄像头在生产中表现良好。如果生产将使用智能手机摄像头，那么训练数据也需要来自于它。
- en: Failing to Achieve the Desired Bias
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未能实现期望的偏差
- en: When we think of classic software programs, any given program is “Biased” towards
    certain states of operation. For example, an application desired for a smartphone
    has a certain context, and may be better or worse than a desktop application at
    certain things. A spreadsheet app that may be better suited for Desktop use.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑经典软件程序时，任何给定的程序都“偏向”于某些操作状态。例如，设计用于智能手机的应用程序具有特定的上下文，并且在某些方面可能比桌面应用程序更好或更差。电子表格应用程序可能更适合桌面使用。
- en: This bias may be intentional. For example an official money sending system will
    need to disallow random edits, where as a personal note taking app may want to
    make it easy to edit. Once a program like that has been written, it becomes hard
    to “unbias it”. The edit focused program was built assuming the user would be
    allowed to (generally) - edit stuff. Whereas the money sending app has many assumptions
    built around an end user not being able to “undo” a transaction.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这种偏差可能是有意的。例如，官方的汇款系统需要禁止随机编辑，而个人记事应用程序可能希望方便进行编辑。一旦编写了这样的程序，取消偏见就变得困难。以编辑为重点的程序建立在用户可以（通常）编辑内容的假设上。而汇款应用程序则建立在用户不能“撤销”交易的多个假设上。
- en: There’s a similar concept in Training Data. Let’s imagine a crop inspection
    application. Imagine it’s mostly designed around diseases that affect potato crops.
    There are assumptions made regarding everything from the “raw” data (eg that the
    media is captured at certain heights), to the types of diseases, to the volume
    of samples. It’s unlikely it will work well for other types of crops. Therefore
    it’s important to ensure the Schema fits your desired application goals, the desired
    bias.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据中有一个类似的概念。让我们想象一个作物检查应用程序。假设它主要围绕影响马铃薯作物的疾病设计。对于从“原始”数据（例如，媒体是以某些高度捕获的）到疾病类型再到样本数量的一切做出了假设。它不太可能对其他类型的作物有效。因此，确保模式与你所需的应用目标和所需偏差匹配非常重要。
- en: I will cover Bias from many angles and provide practical tips on how to work
    with Training Data to achieve your desired Bias.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我将从多个角度讨论偏差，并提供如何利用训练数据来实现你所需偏差的实用技巧。
- en: What Training Data is Not
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是训练数据
- en: Training Data is not an ML algorithm. It is not tied to a specific machine learning
    approach.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据不是一个机器学习算法。它不与特定的机器学习方法捆绑在一起。
- en: Rather it’s the definition of what we want to achieve. The fundamental challenge
    is effectively identifying and mapping the desired human meaning into a machine
    readable form.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 它不是我们想要实现的目标的定义。基本挑战在于有效地识别和映射所需的人类含义到机器可读形式。
- en: The effectiveness of training data depends primarily on how well it relates
    to the human defined meaning and how reasonably it represents real model usage.
    Practically, choices around Training Data have a huge impact on the ability to
    train a model effectively.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据的有效性主要取决于其与人类定义的含义的相关性以及其合理地代表实际模型使用方式。实际上，围绕训练数据的选择对有效训练模型的能力有着巨大影响。
- en: Generative AI
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成AI
- en: Generative AI (GenAI) concepts, like Generative Pre-trained Transformers (GPT),
    and Large-Language Models (LLMs) became very popular in early 2023\. Here I will
    briefly touch on how these concepts relate to Training Data.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 生成AI（GenAI）概念，如生成预训练转换器（GPT）和大语言模型（LLMs），在2023年初变得非常流行。在这里，我将简要介绍这些概念与训练数据的关系。
- en: 'Note: At the time of writing this area is moving very rapidly. Major commercial
    players are being extremely restrictive in what they share publicly so there’s
    a lot of speculation and hype but little consensus. Therefore most likely some
    of this Generative AI section will be out of date by the time you are reading
    it.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在撰写本文时，这一领域正在迅速发展。主要的商业参与者在公开分享方面非常谨慎，因此存在大量猜测和炒作，但缺乏共识。因此，很可能到你阅读本文时，这个生成AI部分的一些内容已经过时。
- en: First, there is the concept of Unsupervised Learning. The broad stated goal
    of Unsupervised Learning in the GenAI context is to work without newly defined
    human made labels. However, LLMs “pre training” is based off of human source material.
    So you still need data, and usually human generated data to get something that’s
    meaningful to humans. The difference is when “pre training” generative AI the
    data doesn’t initially need labels to create an output, affectionately referred
    to as the unsupervised “monster”. This “monster” as shown in Fig 1.4 must still
    be tamed with human supervision.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，有无监督学习的概念。在GenAI的上下文中，无监督学习的广泛声明目标是在不需要新定义的人类制定标签的情况下工作。然而，LLMs的“预训练”是基于人类来源材料的。因此，你仍然需要数据，通常是人为生成的数据，以获得对人类有意义的内容。不同之处在于，在“预训练”生成AI时，数据起初不需要标签来创建输出，亲切地称为无监督的“怪物”。如图1.4所示，这个“怪物”仍然需要人类监督来驯服。
- en: '![Fig 1.4  TBD Illustration similar to image  Relationship of Unsupervised
    learning to Supervised Fine Tuning and Human Alignment](Images/training_data_introduction_865720_04.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图1.4 类似于图像的TBD插图 无监督学习与监督微调及人类对齐关系](Images/training_data_introduction_865720_04.png)'
- en: Figure 1-4\. Relationship of Unsupervised learning to Supervised Fine Tuning
    and Human Alignment
  id: totrans-267
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-4\. 无监督学习与监督微调及人类对齐的关系
- en: 'Broadly speaking these are the major ways that GenAI interacts with Human Supervision:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 广义上说，这些是GenAI与人类监督互动的主要方式：
- en: Human Alignment
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 人类对齐
- en: Using human supervision to build and improve GenAI models.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 使用人类监督来构建和改进GenAI模型。
- en: Efficiency improvements
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 效率改进
- en: Using GenAI models to improve tedious supervision tasks (like image segmentation).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GenAI模型改进繁琐的监督任务（如图像分割）。
- en: Working in Tandem with Supervised AI
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 与监督AI协同工作
- en: Using GenAI models to interpret, combine, interface with and use Supervised
    outputs.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GenAI模型来解释、结合、接口和使用监督输出。
- en: General awareness of AI.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: AI的一般意识。
- en: AI is being mentioned daily in major news outlets and on earning calls by companies.
    General excitement around AI has increased dramatically.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: AI正在被主要新闻媒体和公司的财报电话中每天提及。围绕AI的一般兴奋情绪显著增加。
- en: I’ll expand on the human alignment concept in the next subsection.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在下一小节详细阐述人类对齐的概念。
- en: You can also use GenAI to help improve Supervised Training Data efficiency.
    Some “low hanging” fruit in terms of generic object segmentation, generic classification
    of broadly accepted categories, etc. are all possible (with some caveats) through
    current GenAI systems. I’ll cover this more in Chapter Eight when I discuss automation.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以利用GenAI来帮助提高监督训练数据的效率。通过当前的GenAI系统，一些“低挂果实”的例子，如通用对象分割，广泛接受类别的通用分类等，都是可能的（带有一些警告）。我将在第八章更详细地讨论这一点，讨论自动化时。
- en: Working in Tandem with Supervised AI is mostly out of scope of this book, beyond
    briefly stating that there is surprisingly little overlap. GenAI and Supervised
    systems are both important building blocks.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 与监督AI协同工作大多超出了本书的范围，除了简要说明几乎没有重叠之外。GenAI和监督系统都是重要的构建模块。
- en: Advances in GenAI have made AI front page news again. As a result, organizations
    are rethinking their AI objectives, and putting more energy into AI initiatives
    in general, not just GenAI. To ship a GenAI system, human alignment (in other
    words, training data) is needed. To ship a complete AI system often GenAI + SupervisedAI
    is needed. Learning the skills in this book for working with training data will
    help you with both goals.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI 的进展再次成为头条新闻。因此，组织正在重新思考他们的AI目标，并在总体上更多地投入AI倡议，而不仅仅是GenAI。要推出一个GenAI系统，需要人类对齐（即训练数据）。要推出一个完整的AI系统，通常需要GenAI
    + SupervisedAI。学习本书中有关处理训练数据的技能将有助于实现这两个目标。
- en: Human Alignment is Human Supervision
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人类对齐即人类监督
- en: Human supervision, the focus of this book, is often referred to as Human Alignment
    in the GenAI context. The vast majority of concepts discussed in this book also
    apply to Human Alignment, with some case specific modifications.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 人类监督，在本书中的重点，通常在GenAI背景下被称为人类对齐。本书讨论的大多数概念也适用于人类对齐，有一些案例特定的修改。
- en: 'The goal is less to directly learn to repeat an exact representation, but rather
    to “direct” the unsupervised results. While exactly which human alignment “direction”
    methods are a subject of hot debate, specific examples of current popular approaches
    to Human Alignment include:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 目标不是直接学习重复精确的表示，而是“引导”无监督结果。虽然关于人类对齐“引导”方法的具体细节存在激烈的辩论，但当前流行的人类对齐方法具体例子包括：
- en: '**Direct supervision**, such as question and answer pairs, ranking outputs
    (e.g. personal preference Best to Worst), and flagging specifically iterated concerns
    such as Not Safe for Work. This approach was key to GPT-4’s fame.'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**直接监督**，例如问答对，排名输出（例如个人偏好从最佳到最差），以及标记明确迭代的关注点，例如不适宜工作。这种方法是GPT-4声名鹊起的关键。'
- en: '**Indirect supervision**, such as end users voting up/down, providing free
    form feedback etc. Usually this input must go through some additional process
    before being presented to the model.'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**间接监督**，例如最终用户的赞成/反对投票，提供自由形式的反馈等。通常，此类输入必须经过额外的处理才能呈现给模型。'
- en: '**Defining a “Constitutional”** **set of instructions** that lay out specific
    human supervision (human alignment) principles for the GenAI system to follow.'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定义“宪法”** **一套具体的人类监督（人类对齐）原则**，供GenAI系统遵循。'
- en: '**Prompt Engineering**, meaning defining “code like” prompts, or coding in
    natural language.'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Prompt Engineering**，即定义“类代码”的提示，或者用自然语言编写代码。'
- en: '**Integration** with other systems to check the validity of results.'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**整合**到其他系统以检查结果的有效性。'
- en: There is little consensus over the best approaches here, how to measure results,
    etc. For myself I especially would like to flag that many of these approaches
    have been focused on text, limited multi-modal (but still text output), and media
    generation. While this may seem extensive it’s a relatively limited sub section
    of the more general concept of humans attaching repeatable meaning to arbitrary
    real world concepts.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，最佳方法以及如何衡量结果等问题上没有太多共识。对于我个人而言，我特别想指出许多方法都集中在文本上，有限的多模态（但仍然是文本输出）和媒体生成上。虽然这可能看起来很广泛，但它只是更一般的人类将可重复的含义附加到任意现实世界概念的子集。
- en: In addition to the lack of consensus, there is also conflicting research in
    this space. For example, two common ends of the spectrum are some claiming emergent
    behavior and others that the benchmarks were cherry picked and that it’s a false
    result ( e.g that the test set is conflated with the training data). While it
    seems clear that human supervision has something to do with it, exactly what level,
    and how much, and what technique is an open question in the GenAI case. In fact,
    some results show that small human aligned models can work as well or better than
    large models.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 除了缺乏共识之外，在这个领域还存在矛盾的研究。例如，两种普遍的极端观点是一些人声称出现了新的行为模式，而另一些人则认为基准测试被精心挑选，这是一个错误的结果（例如，测试集与训练数据混淆）。尽管看起来人类监督对此有所影响，但到底影响到什么程度，以及如何影响，采用什么技术，这些在GenAI案例中都是一个开放的问题。事实上，一些结果显示，小型与人类对齐的模型可以与大型模型同样或更好地工作。
- en: 'While you may notice some differences in terminology, most of the principles
    in this book still apply to GenAI Alignment. Specifically, all forms of Direct
    Supervision are training data supervision. A few notes before wrapping up GenAI
    coverage: I don’t specifically cover Prompt Engineering in this book, nor other
    GenAI specific concepts. However, if you are looking to build a GenAI system,
    you will still need data, and high quality supervision will remain a critical
    part of GenAI systems for the foreseeable future.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可能会注意到术语上的一些差异，但本书中的大多数原则仍适用于GenAI对齐。具体而言，所有形式的直接监督都是训练数据的监督。在总结GenAI覆盖范围之前的几点注意事项：本书未特别涵盖提示工程，也未涵盖其他GenAI特定概念。但是，如果您打算构建GenAI系统，仍然需要数据，而高质量的监督将继续是可预见的未来GenAI系统的关键组成部分。
- en: Summary
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter has introduced high level ideas around Training Data for Machine
    Learning.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了机器学习训练数据的高层次概念。
- en: 'Let’s recap why Training Data is important:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下为什么训练数据如此重要：
- en: Consumers and businesses are increasing expectations around having ML built-in,
    both for existing and new systems, increasing the importance of Training Data.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 消费者和企业对内置机器学习的期望正在增加，无论是现有系统还是新系统，都增加了对训练数据重要性的认识。
- en: It serves as the foundation of developing and maintaining modern ML programs.
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它作为开发和维护现代机器学习程序的基础。
- en: Training data is an Art and a new paradigm. It’s a set of ideas around new,
    Data driven programs, controlled by humans, separate from classic ML comprised
    of new of philosophies, concepts, and implementations.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练数据是一门艺术和一种新的范式。这是一套关于新的、由数据驱动的程序的思想，由人类控制，与传统机器学习分开，由新的哲学、概念和实施组成。
- en: It forms the foundation of new AI/ML products, maintaining revenue from existing
    lines of business, by replacing or improving costs through AI/ML upgrades, and
    is a fertile ground for R&D.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它构成了新AI/ML产品的基础，通过AI/ML升级取代或改进现有业务线的成本，并且是研发的肥沃土壤。
- en: As a technologist or as a subject matter expert, it’s now an important skillset
    to have.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为技术专家或主题专家，现在拥有这一技能集是至关重要的。
- en: The art of Training Data is distinct from Data Science. It’s the control of
    the system. The goal for the system to learn. Training Data is not an algorithm
    or a single dataset. It’s a paradigm that spans people from Subject Matter Experts,
    to Data Scientists, to Engineering and more. It’s a way to think about systems
    that opens up new use cases and opportunities.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据的艺术与数据科学有所不同。它是系统的控制。系统学习的目标。训练数据不是一个算法或单一的数据集。它是一个跨越从主题专家、数据科学家到工程师等人的思维方式，开启新用例和机会的范式。
- en: 'Before reading on, I encourage you to feel comfortable with the high level
    ideas introduced earlier:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续阅读之前，我鼓励您对早些时候介绍的高层次概念感到自在：
- en: Schema, Raw Data, Quality, Integrations, and The Human Role are all key concerns.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 架构、原始数据、质量、集成以及人类角色都是关键问题。
- en: Classic Training Data is about discovery while modern Training Data is about
    copying existing knowledge.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经典训练数据是关于发现，而现代训练数据是关于复制现有知识。
- en: Deep Learning algorithms generate models based on training data. Training Data
    defines the goal and the algorithm defines how to work towards this goal.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习算法生成基于训练数据的模型。训练数据定义了目标，算法定义了如何朝着这个目标努力。
- en: Training data that is validated “in a lab” will likely fail in the field. This
    can be avoided by primarily using field data as the starting point, by aligning
    the system design, and by expecting to rapidly update models.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实验室验证的训练数据很可能在现场失败。通过主要使用现场数据作为起点、通过调整系统设计，并期望快速更新模型，可以避免这种情况。
- en: High level conceptual understanding of Training Data ideas, assumptions, processes,
    and tooling.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对训练数据理念、假设、过程和工具的高层次概念理解。
- en: Training Data is like Code
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据就像代码。
- en: In the next chapter we will cover getting setup with your Training Data System
    and trade-offs of tools.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍如何设置您的训练数据系统以及工具的权衡。
- en: ^([1](ch01.xhtml#idm45486441047360-marker)) Without further deductions outside
    our scope of concern.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.xhtml#idm45486441047360-marker)) 超出我们关注范围的进一步推论。
- en: ^([2](ch01.xhtml#idm45486432521344-marker)) From [https://en.wikipedia.org/wiki/Stanley_(vehicle)](https://en.wikipedia.org/wiki/Stanley_(vehicle))
    “Stanley was characterized by a machine learning based approach to obstacle detection.
    To correct a common error made by Stanley early in development, the Stanford Racing
    Team created a log of “human reactions and decisions” and fed the data into a
    learning algorithm tied to the vehicle’s controls; this action served to greatly
    reduce Stanley’s errors. The computer log of humans driving also made Stanley
    more accurate in detecting shadows, a problem that had caused many of the vehicle
    failures in the 2004 DARPA Grand Challenge.”
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch01.xhtml#idm45486432521344-marker)) 来自 [https://en.wikipedia.org/wiki/Stanley_(vehicle)](https://en.wikipedia.org/wiki/Stanley_(vehicle))，“斯坦利以基于机器学习的方法进行障碍物检测而闻名。在斯坦利早期开发中纠正的一个常见错误之后，斯坦福赛车队创建了一个记录‘人类反应和决策’的日志，并将数据馈送到与车辆控制连接的学习算法中；这一行动极大地减少了斯坦利的错误。人类驾驶的计算机日志还使得斯坦利在检测阴影方面更加准确，这是导致2004年DARPA大挑战中许多车辆失败的问题。”
- en: ^([3](ch01.xhtml#idm45486432365104-marker)) Defense Advanced Research Projects
    Agency (DARPA)
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch01.xhtml#idm45486432365104-marker)) 防务高级研究计划局（DARPA）
- en: ^([4](ch01.xhtml#idm45486432332832-marker)) There are statistical methods to
    coordinate experts opinions but these are always “additional”, there still has
    to be an existing opinion.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch01.xhtml#idm45486432332832-marker)) 有统计方法来协调专家意见，但这些方法始终是“额外的”，仍然需要有一个现有的观点。
- en: ^([5](ch01.xhtml#idm45486432456544-marker)) I’m oversimplifying here. In more
    detail, the key difference is that while a data science AutoML training product
    and hosting may be complex itself, there are simply less people working on it.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch01.xhtml#idm45486432456544-marker)) 这里我进行了简化。更详细地说，关键区别在于，虽然数据科学的AutoML训练产品和托管本身可能很复杂，但参与的人数较少。
- en: ^([6](ch01.xhtml#idm45486432212944-marker)) https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch01.xhtml#idm45486432212944-marker)) [https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/](https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/)
