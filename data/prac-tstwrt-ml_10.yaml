- en: Appendix B. Other Interpretability and Explainability Tool Kits
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录B. 其他可解释性和解释性工具包
- en: 'Many libraries include interpretability and explainability techniques under
    one umbrella. Some of these difficult-to-categorize tool kits include:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 许多库在一个统一的框架下包含了可解释性和可解释性技术。其中一些难以分类的工具包括：
- en: '[Meta’s HiPlot](https://oreil.ly/sc6o5)'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Meta''s HiPlot](https://oreil.ly/sc6o5)'
- en: '[iModels](https://oreil.ly/SJtGJ)'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[iModels](https://oreil.ly/SJtGJ)'
- en: '[Omni eXplainable AI (OmniXAI)](https://oreil.ly/q5L4I)'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Omni可解释AI（OmniXAI）](https://oreil.ly/q5L4I)'
- en: Interpretable or Fair Modeling Packages
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释性或公平建模包
- en: 'Beyond the general categories of inherently interpretable models discussed
    earlier in this chapter, here are a few other tools for models that are interpretable
    by their very nature:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 除了本章早期讨论的固有可解释性模型的一般类别外，以下是一些因其本质而可解释的模型工具：
- en: Bayesian Case Model (2014), available as a download from [Duke Interpretable
    ML Lab](https://oreil.ly/BnzXd)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯案例模型（2014年），可以从[Duke Interpretable ML Lab](https://oreil.ly/BnzXd)下载
- en: '[Bayesian Ors-Of-Ands (2017)](https://oreil.ly/ENecK)^([1](app02.html#idm45621828674608))'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[贝叶斯或与门（2017）](https://oreil.ly/ENecK)^([1](app02.html#idm45621828674608))'
- en: '[Bayesian Rule List (BRL)](https://oreil.ly/vMzgG)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[贝叶斯规则列表（BRL）](https://oreil.ly/vMzgG)'
- en: '[Explainable Boosting Machine (EBM)/GA2M](https://oreil.ly/wMKxi)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释提升机器（EBM）/ GA2M](https://oreil.ly/wMKxi)'
- en: '[Optimal Sparse Decision Trees](https://oreil.ly/J74Y7)^([2](app02.html#idm45621828668832))'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Optimal Sparse Decision Trees](https://oreil.ly/J74Y7)^([2](app02.html#idm45621828668832))'
- en: '[XGBoost Monotonic](https://oreil.ly/EuHRb)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGBoost Monotonic](https://oreil.ly/EuHRb)'
- en: '[Rule-based Representation Learner](https://oreil.ly/giZKb)^([3](app02.html#idm45621828664416))'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基于规则的表示学习器](https://oreil.ly/giZKb)^([3](app02.html#idm45621828664416))'
- en: '[pySS3](https://oreil.ly/BQJNX)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pySS3](https://oreil.ly/BQJNX)'
- en: '[Risk-SLIM](https://oreil.ly/vwOLq)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Risk-SLIM](https://oreil.ly/vwOLq)'
- en: '[sklearn-expertsys](https://oreil.ly/rxlCA)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[sklearn-expertsys](https://oreil.ly/rxlCA)'
- en: '[skope-rules](https://oreil.ly/rAYpw)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[skope-rules](https://oreil.ly/rAYpw)'
- en: '[Super-sparse linear integer models (SLIMs)](https://oreil.ly/DK9uI)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超稀疏线性整数模型（SLIMs）](https://oreil.ly/DK9uI)'
- en: '[tensorflow/lattice](https://oreil.ly/rLCnQ)^([4](app02.html#idm45621828654752))'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tensorflow/lattice](https://oreil.ly/rLCnQ)^([4](app02.html#idm45621828654752))'
- en: '[“This Looks Like That”](https://oreil.ly/b6hhG)^([5](app02.html#idm45621828649728))'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“这看起来像那样”](https://oreil.ly/b6hhG)^([5](app02.html#idm45621828649728))'
- en: Other Python Packages for General Explainability
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他用于一般可解释性的Python包
- en: 'There are also more general-purpose tools for explaining and models and decisions:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 还有更多用于解释模型和决策的通用工具：
- en: '[acd](https://oreil.ly/ttG1V)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[acd](https://oreil.ly/ttG1V)'
- en: '[AI Fairness 360](https://oreil.ly/BRLBu)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI Fairness 360](https://oreil.ly/BRLBu)'
- en: '[AI Explainability 360](https://oreil.ly/mgklQ)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI Explainability 360](https://oreil.ly/mgklQ)'
- en: '[ALEPython](https://oreil.ly/K6AVe)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ALEPython](https://oreil.ly/K6AVe)'
- en: '[Aletheia](https://oreil.ly/sX3UM)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Aletheia](https://oreil.ly/sX3UM)'
- en: '[allennlp](https://oreil.ly/P48tS)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[allennlp](https://oreil.ly/P48tS)'
- en: '[Alibi](https://oreil.ly/F3vaH)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Alibi](https://oreil.ly/F3vaH)'
- en: '[anchor](https://oreil.ly/2m0VK)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[anchor](https://oreil.ly/2m0VK)'
- en: '[casme](https://oreil.ly/uCsyS)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[casme](https://oreil.ly/uCsyS)'
- en: '[captum](https://oreil.ly/aB3Ec)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[captum](https://oreil.ly/aB3Ec)'
- en: '[checklist](https://oreil.ly/SHYDR)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[checklist](https://oreil.ly/SHYDR)'
- en: '[contextual-AI](https://oreil.ly/BhgxZ)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[contextual-AI](https://oreil.ly/BhgxZ)'
- en: '[ContrastiveExplanation (Foil Trees)](https://oreil.ly/sKEpf)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[对比解释（箔树）](https://oreil.ly/sKEpf)'
- en: '[counterfit](https://oreil.ly/Qq1Hh)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[counterfit](https://oreil.ly/Qq1Hh)'
- en: '[dalex](https://oreil.ly/a6WUT)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[dalex](https://oreil.ly/a6WUT)'
- en: '[DeepExplain](https://oreil.ly/YzwSC)^([6](app02.html#idm45621828622992))'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepExplain](https://oreil.ly/YzwSC)^([6](app02.html#idm45621828622992))'
- en: '[deeplift](https://oreil.ly/5wdJW)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[deeplift](https://oreil.ly/5wdJW)'
- en: '[deepvis](https://oreil.ly/aYdSg)^([7](app02.html#idm45621828618576))'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[deepvis](https://oreil.ly/aYdSg)^([7](app02.html#idm45621828618576))'
- en: '[DiCE](https://oreil.ly/6psFD)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DiCE](https://oreil.ly/6psFD)'
- en: '[ecco](https://oreil.ly/3eLYy)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ecco](https://oreil.ly/3eLYy)'
- en: '[eli5](https://oreil.ly/cJKz7)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[eli5](https://oreil.ly/cJKz7)'
- en: '[explainerdashboard](https://oreil.ly/6BhYa)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[explainerdashboard](https://oreil.ly/6BhYa)'
- en: '[foolbox](https://oreil.ly/VTuQe)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[foolbox](https://oreil.ly/VTuQe)'
- en: '[Grad-CAM (GitHub topic)](https://oreil.ly/C7v9W)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Grad-CAM（GitHub主题）](https://oreil.ly/C7v9W)'
- en: '[gplearn](https://oreil.ly/L5XMH)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[gplearn](https://oreil.ly/L5XMH)'
- en: '[hate-functional-tests](https://oreil.ly/adgLq)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[hate-functional-tests](https://oreil.ly/adgLq)'
- en: '[iNNvestigate neural nets](https://oreil.ly/X2e23)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[iNNvestigate神经网络](https://oreil.ly/X2e23)'
- en: '[Integrated-Gradients](https://oreil.ly/S1DsD)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Integrated-Gradients](https://oreil.ly/S1DsD)'
- en: '[interpret](https://oreil.ly/TvbpB)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[interpret](https://oreil.ly/TvbpB)'
- en: '[interpret_with_rules](https://oreil.ly/W0Uwo)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[interpret_with_rules](https://oreil.ly/W0Uwo)'
- en: '[imodels](https://oreil.ly/U9t8K)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[imodels](https://oreil.ly/U9t8K)'
- en: '[Keras-vis](https://oreil.ly/qCesj)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Keras-vis](https://oreil.ly/qCesj)'
- en: '[keract](https://oreil.ly/noOby)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[keract](https://oreil.ly/noOby)'
- en: '[L2X](https://oreil.ly/MuGyI)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[L2X](https://oreil.ly/MuGyI)'
- en: '[lime](https://oreil.ly/ov991)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[lime](https://oreil.ly/ov991)'
- en: '[lit](https://oreil.ly/wRA51)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[lit](https://oreil.ly/wRA51)'
- en: '[lofo-importance](https://oreil.ly/OvSxX)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[lofo-importance](https://oreil.ly/OvSxX)'
- en: '[lrp_toolbox](https://oreil.ly/MH6Sf)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[lrp_toolbox](https://oreil.ly/MH6Sf)'
- en: '[MindsDB](https://oreil.ly/AcbYM)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MindsDB](https://oreil.ly/AcbYM)'
- en: '[MLextend](https://oreil.ly/wqGFX)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLextend](https://oreil.ly/wqGFX)'
- en: '[OptBinning](https://oreil.ly/4awhW)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OptBinning](https://oreil.ly/4awhW)'
- en: '[PDPbox](https://oreil.ly/IomoW)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PDPbox](https://oreil.ly/IomoW)'
- en: '[pyBreakDown](https://oreil.ly/gnYm6)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pyBreakDown](https://oreil.ly/gnYm6)'
- en: '[PyCEbox](https://oreil.ly/S7oUd)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyCEbox](https://oreil.ly/S7oUd)'
- en: '[pymc3](https://oreil.ly/cFFOd)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pymc3](https://oreil.ly/cFFOd)'
- en: '[pytorch-innvestigate](https://oreil.ly/nrY9x)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pytorch-innvestigate](https://oreil.ly/nrY9x)'
- en: '[rationale](https://oreil.ly/bYMVa)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[rationale](https://oreil.ly/bYMVa)'
- en: '[RISE](https://oreil.ly/boIn8)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RISE](https://oreil.ly/boIn8)'
- en: '[sage](https://oreil.ly/xMp3p)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[sage](https://oreil.ly/xMp3p)'
- en: '[SALib](https://oreil.ly/ie6Ob)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SALib](https://oreil.ly/ie6Ob)'
- en: '[Skater](https://oreil.ly/sTZMV)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Skater](https://oreil.ly/sTZMV)'
- en: '[tensorflow/cleverhans](https://oreil.ly/JLVJ7)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tensorflow/cleverhans](https://oreil.ly/JLVJ7)'
- en: '[tensorflow/lucid](https://oreil.ly/1F0i5)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tensorflow/lucid](https://oreil.ly/1F0i5)'
- en: '[tensorflow/fairness-indicators](https://oreil.ly/iIo4x)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tensorflow/fairness-indicators](https://oreil.ly/iIo4x)'
- en: '[tensorflow/model-analysis](https://oreil.ly/5exci):'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tensorflow/model-analysis](https://oreil.ly/5exci):'
- en: '[tensorflow/tcav](https://oreil.ly/Q5iAb)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tensorflow/tcav](https://oreil.ly/Q5iAb)'
- en: '[tensorfuzz](https://oreil.ly/8bCZo)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tensorfuzz](https://oreil.ly/8bCZo)'
- en: '[TensorWatch](https://oreil.ly/oUGVb)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorWatch](https://oreil.ly/oUGVb)'
- en: '[TextFooler](https://oreil.ly/dZA6z)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TextFooler](https://oreil.ly/dZA6z)'
- en: '[tf-explain](https://oreil.ly/sBtir)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tf-explain](https://oreil.ly/sBtir)'
- en: '[treeinterpreter](https://oreil.ly/AeULo)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[treeinterpreter](https://oreil.ly/AeULo)'
- en: '[woe](https://oreil.ly/i0MQT)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[woe](https://oreil.ly/i0MQT)'
- en: '[xai](https://oreil.ly/dtgKo)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[xai](https://oreil.ly/dtgKo)'
- en: '[xdeep](https://oreil.ly/uz28K)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[xdeep](https://oreil.ly/uz28K)'
- en: '[yellowbrick](https://oreil.ly/N9r9e)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[yellowbrick](https://oreil.ly/N9r9e)'
- en: '^([1](app02.html#idm45621828674608-marker)) Tong Wang et al., [“A Bayesian
    Framework for Learning Rule Sets for Interpretable Classification”](https://oreil.ly/98-8k),
    *The Journal of Machine Learning Research* 18, no. 1 (2017): 2357–93.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](app02.html#idm45621828674608-marker)) Tong Wang等人，《一种用于可解释分类学习规则集的贝叶斯框架》，[*机器学习研究杂志*
    18卷，第1期（2017年）：2357–93](https://oreil.ly/98-8k)。
- en: ^([2](app02.html#idm45621828668832-marker)) Xiyang Hu et al., [“Optimal Sparse
    Decision Trees”](https://arxiv.org/abs/1904.12847), *33rd Conference on Neural
    Information Processing Systems (NeurIPS 2019)*, April 29, 2019.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](app02.html#idm45621828668832-marker)) Xiyang Hu等人，《最佳稀疏决策树》，[*第33届神经信息处理系统（NeurIPS
    2019）*，2019年4月29日](https://arxiv.org/abs/1904.12847)。
- en: ^([3](app02.html#idm45621828664416-marker)) Zhuo Wang et al., [“Scalable Rule-Based
    Representation Learning for Interpretable Classification”](https://arxiv.org/abs/2109.15103),
    *NeurIPS 2021; Interpretable ML; Neuro-Symbolic AI*, September 30, 2021.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](app02.html#idm45621828664416-marker)) Zhuo Wang等人，《可扩展的基于规则的表示学习用于可解释分类》，[*NeurIPS
    2021；可解释机器学习；神经符号人工智能*，2021年9月30日](https://arxiv.org/abs/2109.15103)。
- en: ^([4](app02.html#idm45621828654752-marker)) Maya Gupta et al., [“Monotonic Calibrated
    Interpolated Look-Up Tables”](https://oreil.ly/W87tM), *Journal of Machine Learning
    Research* 17, no. 109 (2016).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](app02.html#idm45621828654752-marker)) Maya Gupta等人，《单调校准的插值查找表》，[*机器学习研究杂志*
    17卷，第109期（2016年）](https://oreil.ly/W87tM)。
- en: '^([5](app02.html#idm45621828649728-marker)) Chaofan Chen et al., [“This Looks
    Like That: Deep Learning for Interpretable Image Recognition”](https://arxiv.org/abs/1806.10574v5),
    *Advances in Neural Information Processing Systems 32 (NeurIPS 2019)*, June 27,
    2018.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](app02.html#idm45621828649728-marker)) Chaofan Chen等人，《这看起来像那个：用于可解释图像识别的深度学习》，[*神经信息处理系统进展（NeurIPS
    2019）*，2018年6月27日](https://arxiv.org/abs/1806.10574v5)。
- en: ^([6](app02.html#idm45621828622992-marker)) Marco Ancona et al., [“Towards Better
    Understanding of Gradient-Based Attribution Methods for Deep Neural Networks](https://oreil.ly/lsg2s),
    *ICLR 2018 Conference Bling Submissions*, February 15, 2018.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](app02.html#idm45621828622992-marker)) Marco Ancona等人，《朝着更好理解基于梯度的深度神经网络归因方法》，[*ICLR
    2018会议论文集*，2018年2月15日](https://oreil.ly/lsg2s)。
- en: ^([7](app02.html#idm45621828618576-marker)) Jason Yosinski et al., [“Understanding
    Neural Networks Through Deep Visualization”](https://oreil.ly/xDvhy), *Deep Learning
    Workshop, 31st International Conference on Machine Learning*, June 26, 2015.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](app02.html#idm45621828618576-marker)) Jason Yosinski等人，《通过深度可视化理解神经网络》，[*第31届国际机器学习会议深度学习研讨会*，2015年6月26日](https://oreil.ly/xDvhy)。
