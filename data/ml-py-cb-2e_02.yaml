- en: Chapter 2\. Loading Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 载入数据
- en: 2.0 Introduction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.0 简介
- en: The first step in any machine learning endeavor is to get the raw data into
    our system. The raw data might be a logfile, dataset file, database, or cloud
    blob store such as Amazon S3\. Furthermore, often we will want to retrieve data
    from multiple sources.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 任何机器学习工作的第一步是将原始数据导入到我们的系统中。原始数据可以是日志文件、数据集文件、数据库，或者像亚马逊 S3 这样的云存储。此外，通常我们会希望从多个来源检索数据。
- en: The recipes in this chapter look at methods of loading data from a variety of
    sources, including CSV files and SQL databases. We also cover methods of generating
    simulated data with desirable properties for experimentation. Finally, while there
    are many ways to load data in the Python ecosystem, we will focus on using the
    pandas library’s extensive set of methods for loading external data, and using
    scikit-learn—​an open source machine learning library in Python—​for generating
    simulated data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的示例将介绍从多种来源加载数据的方法，包括 CSV 文件和 SQL 数据库。我们还将介绍如何使用具有可配置属性的模拟数据生成方法进行实验。最后，虽然在
    Python 生态系统中有许多加载数据的方式，但我们将重点介绍使用 pandas 库的广泛方法来加载外部数据，以及使用 scikit-learn——一个开源的
    Python 机器学习库——来生成模拟数据。
- en: 2.1 Loading a Sample Dataset
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.1 载入一个示例数据集
- en: Problem
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to load a preexisting sample dataset from the scikit-learn library.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望加载 scikit-learn 库中预先存在的示例数据集。
- en: Solution
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'scikit-learn comes with a number of popular datasets for you to use:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 自带许多流行的数据集供您使用：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Discussion
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: 'Often we do not want to go through the work of loading, transforming, and cleaning
    a real-world dataset before we can explore some machine learning algorithm or
    method. Luckily, scikit-learn comes with some common datasets we can quickly load.
    These datasets are often called “toy” datasets because they are far smaller and
    cleaner than a dataset we would see in the real world. Some popular sample datasets
    in scikit-learn are:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常不希望在能够探索一些机器学习算法或方法之前，就必须加载、转换和清理真实世界的数据集。幸运的是，scikit-learn 提供了一些常见的数据集，我们可以快速加载。这些数据集通常被称为“玩具”数据集，因为它们比真实世界中的数据集要小得多，也更干净。scikit-learn
    中一些流行的示例数据集包括：
- en: '`load_iris`'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`load_iris`'
- en: Contains 150 observations on the measurements of iris flowers. It is a good
    dataset for exploring classification algorithms.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 包含 150 个鸢尾花测量数据的观察结果。这是一个很好的数据集，用于探索分类算法。
- en: '`load_digits`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`load_digits`'
- en: Contains 1,797 observations from images of handwritten digits. It is a good
    dataset for teaching image classification.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 包含 1,797 个手写数字图像的观察结果。这是一个很好的数据集，适合用于图像分类的教学。
- en: 'To see more details on any of these datasets, you can print the `DESCR` attribute:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看这些数据集的更多细节，请打印 `DESCR` 属性：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: See Also
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[scikit-learn toy datasets](https://oreil.ly/WS1gc)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[scikit-learn 玩具数据集](https://oreil.ly/WS1gc)'
- en: '[The Digit Dataset](https://oreil.ly/0hukv)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数字数据集](https://oreil.ly/0hukv)'
- en: 2.2 Creating a Simulated Dataset
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.2 创建一个模拟数据集
- en: Problem
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to generate a dataset of simulated data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要生成一个模拟数据集。
- en: Solution
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'scikit-learn offers many methods for creating simulated data. Of those, three
    methods are particularly useful: `make_regression`, `make_classification`, and
    `make_blobs`.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 提供了许多用于创建模拟数据的方法。其中，三种方法特别有用：`make_regression`、`make_classification`
    和 `make_blobs`。
- en: 'When we want a dataset designed to be used with linear regression, `make_regression`
    is a good choice:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们需要一个设计用于线性回归的数据集时，`make_regression` 是一个不错的选择：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If we are interested in creating a simulated dataset for classification, we
    can use `make_classification`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有兴趣创建一个用于分类的模拟数据集，我们可以使用 `make_classification`：
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, if we want a dataset designed to work well with clustering techniques,
    scikit-learn offers `make_blobs`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果我们需要一个设计用于聚类技术的数据集，scikit-learn 提供了 `make_blobs`：
- en: '[PRE8]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Discussion
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: As might be apparent from the solutions, `make_regression` returns a feature
    matrix of float values and a target vector of float values, while `make_classification`
    and `make_blobs` return a feature matrix of float values and a target vector of
    integers representing membership in a class.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从解决方案中可以看出，`make_regression` 返回一个浮点值的特征矩阵和一个浮点值的目标向量，而 `make_classification`
    和 `make_blobs` 返回一个浮点值的特征矩阵和一个整数的目标向量，代表类的成员身份。
- en: scikit-learn’s simulated datasets offer extensive options to control the type
    of data generated. scikit-learn’s documentation contains a full description of
    all the parameters, but a few are worth noting.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 的模拟数据集提供了广泛的选项来控制生成数据的类型。scikit-learn 的文档包含了所有参数的详细描述，但有几个值得注意。
- en: In `make_regression` and `make_classification`, `n_informative` determines the
    number of features that are used to generate the target vector. If `n_informative`
    is less than the total number of features (`n_features`), the resulting dataset
    will have redundant features that can be identified through feature selection
    techniques.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `make_regression` 和 `make_classification` 中，`n_informative` 确定用于生成目标向量的特征数量。如果
    `n_informative` 小于总特征数 (`n_features`)，则生成的数据集将具有冗余特征，可通过特征选择技术识别。
- en: In addition, `make_classification` contains a `weights` parameter that allows
    us to simulate datasets with imbalanced classes. For example, `weights = [.25,
    .75]` would return a dataset with 25% of observations belonging to one class and
    75% of observations belonging to a second class.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`make_classification` 包含 `weights` 参数，允许我们模拟不平衡类别的数据集。例如，`weights = [.25,
    .75]` 将返回一个数据集，其中25%的观测属于一类，75%的观测属于第二类。
- en: 'For `make_blobs`, the `centers` parameter determines the number of clusters
    generated. Using the `matplotlib` visualization library, we can visualize the
    clusters generated by `make_blobs`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `make_blobs`，`centers` 参数确定生成的簇数量。使用 `matplotlib` 可视化库，我们可以可视化 `make_blobs`
    生成的簇：
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![mpc2 02in01](assets/mpc2_02in01.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 02in01](assets/mpc2_02in01.png)'
- en: See Also
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[`make_regression` documentation](https://oreil.ly/VrtN3)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`make_regression` 文档](https://oreil.ly/VrtN3)'
- en: '[`make_classification` documentation](https://oreil.ly/rehc-)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`make_classification` 文档](https://oreil.ly/rehc-)'
- en: '[`make_blobs` documentation](https://oreil.ly/1LZAI)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`make_blobs` 文档](https://oreil.ly/1LZAI)'
- en: 2.3 Loading a CSV File
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.3 加载CSV文件
- en: Problem
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to import a comma-separated value (CSV) file.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要导入逗号分隔值（CSV）文件。
- en: Solution
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use the pandas library’s `read_csv` to load a local or hosted CSV file into
    a pandas DataFrame:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pandas库的 `read_csv` 将本地或托管的CSV文件加载到pandas DataFrame中：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '|  | integer | datetime | category |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | integer | datetime | category |'
- en: '| --- | --- | --- | --- |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 5 | 2015-01-01 00:00:00 | 0 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 5 | 2015-01-01 00:00:00 | 0 |'
- en: '| 1 | 5 | 2015-01-01 00:00:01 | 0 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 5 | 2015-01-01 00:00:01 | 0 |'
- en: Discussion
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: There are two things to note about loading CSV files. First, it is often useful
    to take a quick look at the contents of the file before loading. It can be very
    helpful to see how a dataset is structured beforehand and what parameters we need
    to set to load in the file. Second, `read_csv` has over 30 parameters and therefore
    the documentation can be daunting. Fortunately, those parameters are mostly there
    to allow it to handle a wide variety of CSV formats.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 关于加载CSV文件有两件事情需要注意。首先，在加载之前快速查看文件内容通常很有用。事先了解数据集的结构以及我们需要设置的参数是非常有帮助的。其次，`read_csv`
    有超过30个参数，因此文档可能令人望而却步。幸运的是，这些参数大多是为了处理各种CSV格式而设定的。
- en: CSV files get their names from the fact that the values are literally separated
    by commas (e.g., one row might be `2,"2015-01-01 00:00:00",0`); however, it is
    common for CSV files to use other separators, such as tabs (which are referred
    to as TSV files). The pandas `sep` parameter allows us to define the delimiter
    used in the file. Although it is not always the case, a common formatting issue
    with CSV files is that the first line of the file is used to define column headers
    (e.g., `integer, datetime, category` in our solution). The `header` parameter
    allows us to specify if or where a header row exists. If a header row does not
    exist, we set `header=None`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: CSV文件的名称源于数值之间确实以逗号分隔（例如，一行可能是 `2,"2015-01-01 00:00:00",0`）；然而，常见的CSV文件使用其他分隔符，如制表符（称为TSV文件）。pandas的`sep`参数允许我们定义文件中使用的分隔符。尽管并非总是如此，CSV文件常见的格式问题是文件的第一行用于定义列标题（例如，在我们的解决方案中是
    `integer, datetime, category`）。`header`参数允许我们指定是否存在标题行以及其位置。如果不存在标题行，我们设置`header=None`。
- en: 'The `read_csv` function returns a pandas DataFrame: a common and useful object
    for working with tabular data that we’ll cover in more depth throughout this book.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_csv` 函数返回一个pandas DataFrame：这是处理表格数据常见且有用的对象，在本书中我们将更深入地讨论它。'
- en: 2.4 Loading an Excel File
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.4 加载Excel文件
- en: Problem
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to import an Excel spreadsheet.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要导入Excel电子表格。
- en: Solution
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use the pandas library’s `read_excel` to load an Excel spreadsheet:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pandas库的 `read_excel` 加载Excel电子表格：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '|  | integer | datetime | category |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '|  | integer | datetime | category |'
- en: '| --- | --- | --- | --- |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | 5 | 2015-01-01 00:00:00 | 0 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '|  | 5 | 2015-01-01 00:00:00 | 0 |'
- en: '| 0 | 5 | 2015-01-01 00:00:01 | 0 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 5 | 2015-01-01 00:00:01 | 0 |'
- en: '| 1 | 9 | 2015-01-01 00:00:02 | 0 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 9 | 2015-01-01 00:00:02 | 0 |'
- en: Discussion
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: This solution is similar to our solution for reading CSV files. The main difference
    is the additional parameter, `sheet_name`, that specifies which sheet in the Excel
    file we wish to load. `sheet_name` can accept both strings, containing the name
    of the sheet, and integers, pointing to sheet positions (zero-indexed). If we
    need to load multiple sheets, we include them as a list. For example, `sheet_name=[0,1,2,
    "Monthly Sales"]` will return a dictionary of pandas DataFrames containing the
    first, second, and third sheets, and the sheet named `Monthly Sales`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 此解决方案类似于我们用于读取 CSV 文件的解决方案。主要区别在于附加参数 `sheet_name`，它指定了我们希望加载的 Excel 文件中的哪个工作表。`sheet_name`
    可以接受包含工作表名称的字符串和指向工作表位置（从零开始计数）的整数。如果我们需要加载多个工作表，我们将它们包含在列表中。例如，`sheet_name=[0,1,2,
    "Monthly Sales"]` 将返回一个包含第一个、第二个和第三个工作表以及名为 `Monthly Sales` 的工作表的 pandas DataFrame
    字典。
- en: 2.5 Loading a JSON File
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.5 加载 JSON 文件
- en: Problem
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to load a JSON file for data preprocessing.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要加载一个 JSON 文件进行数据预处理。
- en: Solution
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'The pandas library provides `read_json` to convert a JSON file into a pandas
    object:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库提供了 `read_json` 来将 JSON 文件转换为 pandas 对象：
- en: '[PRE13]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '|  | category | datetime | integer |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | 类别 | 时间 | 整数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 0 | 2015-01-01 00:00:00 | 5 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 2015-01-01 00:00:00 | 5 |'
- en: '| 1 | 0 | 2015-01-01 00:00:01 | 5 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0 | 2015-01-01 00:00:01 | 5 |'
- en: Discussion
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Importing JSON files into pandas is similar to the last few recipes we have
    seen. The key difference is the `orient` parameter, which indicates to pandas
    how the JSON file is structured. However, it might take some experimenting to
    figure out which argument (`split`, `records`, `index`, `columns`, or `values`)
    is the right one. Another helpful tool pandas offers is `json_normalize`, which
    can help convert semistructured JSON data into a pandas DataFrame.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 将 JSON 文件导入 pandas 类似于我们之前看到的几个示例。主要区别在于 `orient` 参数，它指示 pandas JSON 文件的结构。但是，可能需要一些试验才能弄清楚哪个参数（`split`、`records`、`index`、`columns`
    或 `values`）是正确的。另一个 pandas 提供的有用工具是 `json_normalize`，它可以帮助将半结构化的 JSON 数据转换为 pandas
    DataFrame。
- en: See Also
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[`json_normalize` documentation](https://oreil.ly/nuvIB)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`json_normalize` 文档](https://oreil.ly/nuvIB)'
- en: 2.6 Loading a Parquet File
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.6 加载 Parquet 文件
- en: Problem
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to load a Parquet file.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要加载一个 Parquet 文件。
- en: Solution
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'The pandas `read_parquet` function allows us to read in Parquet files:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 的 `read_parquet` 函数允许我们读取 Parquet 文件：
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '|  | category | datetime | integer |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | 类别 | 时间 | 整数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 0 | 2015-01-01 00:00:00 | 5 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 2015-01-01 00:00:00 | 5 |'
- en: '| 1 | 0 | 2015-01-01 00:00:01 | 5 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0 | 2015-01-01 00:00:01 | 5 |'
- en: Discussion
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Parquet is a popular data storage format in the large data space. It is often
    used with big data tools such as Hadoop and Spark. While PySpark is outside the
    focus of this book, it’s highly likely companies operating on a large scale will
    use an efficient data storage format such as Parquet, and it’s valuable to know
    how to read it into a dataframe and manipulate it.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Parquet 是大数据领域中流行的数据存储格式。它通常与 Hadoop 和 Spark 等大数据工具一起使用。虽然 PySpark 超出了本书的重点，但大规模运营的公司很可能会使用高效的数据存储格式，比如
    Parquet，了解如何将其读入数据框架并对其进行操作是很有价值的。
- en: See Also
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Apache Parquet documentation](https://oreil.ly/M5bRq)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Apache Parquet 文档](https://oreil.ly/M5bRq)'
- en: 2.7 Loading an Avro File
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.7 加载 Avro 文件
- en: Problem
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to load an Avro file into a pandas DataFrame.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要将 Avro 文件加载到 pandas DataFrame 中。
- en: Solution
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'The use the `pandavro` library’s `read_avro` method:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `pandavro` 库的 `read_avro` 方法：
- en: '[PRE15]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '|  | category | datetime | integer |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|  | 类别 | 时间 | 整数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 0 | 2015-01-01 00:00:00 | 5 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 2015-01-01 00:00:00 | 5 |'
- en: '| 1 | 0 | 2015-01-01 00:00:01 | 5 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0 | 2015-01-01 00:00:01 | 5 |'
- en: Discussion
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Apache Avro is an open source, binary data format that relies on schemas for
    the data structure. At the time of writing, it is not as common as Parquet. However,
    large binary data formats such as Avro, thrift, and Protocol Buffers are growing
    in popularity due to their efficient nature. If you work with large data systems,
    you’re likely to run into one of these formats in the near future.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Avro 是一种开源的二进制数据格式，依赖于数据结构。在撰写本文时，它还不像 Parquet 那样普遍。但是，由于其高效的特性，大型二进制数据格式（如
    Avro、thrift 和 Protocol Buffers）正变得越来越流行。如果您使用大型数据系统，很可能在不久的将来会遇到其中一种格式。
- en: See Also
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Apache Avro documentation](https://oreil.ly/Y1TJA)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Apache Avro 文档](https://oreil.ly/Y1TJA)'
- en: 2.8 Querying a SQLite Database
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.8 查询 SQLite 数据库
- en: Problem
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to load data from a database using structured query language (SQL).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要使用结构化查询语言(SQL)从数据库加载数据。
- en: Solution
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'pandas’ `read_sql_query` allows us to make an SQL query to a database and load
    it:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: pandas的`read_sql_query`允许我们向数据库发出SQL查询并加载数据：
- en: '[PRE16]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '|  | first_name | last_name | age | preTestScore | postTestScore |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|  | 名字 | 姓氏 | 年龄 | 预测试分数 | 后测试分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 0 | Jason | Miller | 42 | 4 | 25 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 0 | Jason | Miller | 42 | 4 | 25 |'
- en: '| 1 | Molly | Jacobson | 52 | 24 | 94 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 1 | Molly | Jacobson | 52 | 24 | 94 |'
- en: Discussion
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: SQL is the lingua franca for pulling data from databases. In this recipe we
    first use `create_engine` to define a connection to an SQL database engine called
    SQLite. Next we use pandas’ `read_sql_query` to query that database using SQL
    and put the results in a DataFrame.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: SQL是从数据库提取数据的通用语言。在这个配方中，我们首先使用`create_engine`定义了一个连接到名为SQLite的SQL数据库引擎。接下来，我们使用pandas的`read_sql_query`使用SQL查询该数据库，并将结果放入DataFrame中。
- en: SQL is a language in its own right and, while beyond the scope of this book,
    it is certainly worth knowing for anyone wanting to learn about machine learning.
    Our SQL query, `SELECT * FROM data`, asks the database to give us all columns
    (`*`) from the table called `data`.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: SQL是一门独立的语言，虽然超出本书的范围，但对于希望学习机器学习的任何人来说，了解它肯定是值得的。我们的SQL查询`SELECT * FROM data`要求数据库给我们表名为`data`的所有列(`*`)。
- en: Note that this is one of a few recipes in this book that will not run without
    extra code. Specifically, `create_engine('sqlite:///sample.db')` assumes that
    an SQLite database already exists.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这是本书中几个配方之一，如果没有额外的代码将无法运行。具体来说，`create_engine('sqlite:///sample.db')`假定SQLite数据库已经存在。
- en: See Also
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[SQLite](https://oreil.ly/8Y91T)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SQLite](https://oreil.ly/8Y91T)'
- en: '[W3Schools SQL Tutorial](https://oreil.ly/A7H1m)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[W3Schools SQL教程](https://oreil.ly/A7H1m)'
- en: 2.9 Querying a Remote SQL Database
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.9 查询远程SQL数据库
- en: Problem
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to connect to, and read from, a remote SQL database.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要连接并从远程SQL数据库中读取数据。
- en: Solution
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Create a connection with `pymysql` and read it into a dataframe with pandas:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pymysql`建立连接，并用pandas将其读入数据框：
- en: '[PRE17]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '|  | integer | datetime | category |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '|  | 整数 | 日期时间 | 类别 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 5 | 2015-01-01 00:00:00 | 0 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 5 | 2015-01-01 00:00:00 | 0 |'
- en: '| 1 | 5 | 2015-01-01 00:00:01 | 0 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 5 | 2015-01-01 00:00:01 | 0 |'
- en: Discussion
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Of all of the recipes presented in this chapter, this is probably the one we
    will use most in the real world. While connecting and reading from an example
    `sqlite` database is useful, it’s likely not representative of tables you’ll need
    to connect to in an enterprise environment. Most SQL instances that you’ll connect
    to will require you to connect to the host and port of a remote machine, specifying
    a username and password for authentication. This example requires you [to start
    a running SQL instance locally](https://oreil.ly/Sxjqz) that mimics a remote server
    on localhost so that you can get a sense of the workflow.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中呈现的所有配方中，这可能是我们在现实世界中最常使用的一个。虽然连接并从示例`sqlite`数据库中读取数据很有用，但它可能不代表您将需要连接的企业环境中的表。您将连接的大多数SQL实例都将要求您连接到远程计算机的主机和端口，并指定用于身份验证的用户名和密码。此示例需要您[在本地启动运行的SQL实例](https://oreil.ly/Sxjqz)，以模仿远程服务器上的工作流程。
- en: See Also
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[PyMySQL documentation](https://oreil.ly/8zSnj)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyMySQL文档](https://oreil.ly/8zSnj)'
- en: '[pandas Read SQL documentation](https://oreil.ly/Yb7sH)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pandas读取SQL文档](https://oreil.ly/Yb7sH)'
- en: 2.10 Loading Data from a Google Sheet
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.10 从Google表格加载数据
- en: Problem
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to read in data directly from a Google Sheet.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要直接从Google表格中读取数据。
- en: Solution
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use pandas `read_CSV` and pass a URL that exports the Google Sheet as a CSV:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pandas的`read_CSV`并传递一个将Google表格导出为CSV的URL：
- en: '[PRE18]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '|  | integer | datetime | category |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|  | 整数 | 日期时间 | 类别 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 5 | 2015-01-01 00:00:00 | 0 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 5 | 2015-01-01 00:00:00 | 0 |'
- en: '| 1 | 5 | 2015-01-01 00:00:01 | 0 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 5 | 2015-01-01 00:00:01 | 0 |'
- en: Discussion
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: While Google Sheets can easily be downloaded, it’s sometimes helpful to be able
    to read them directly into Python without any intermediate steps. The `/export?format=csv`
    query parameter at the end of the URL above creates an endpoint from which we
    can either download the file or read it into pandas.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Google表格可以轻松下载，但直接在Python中读取它们而无需任何中间步骤有时会很有帮助。上述URL末尾的`/export?format=csv`查询参数创建了一个端点，我们可以从中下载文件或将其读入pandas。
- en: See Also
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Google Sheets API](https://oreil.ly/GRLzg)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Google表格API](https://oreil.ly/GRLzg)'
- en: 2.11 Loading Data from an S3 Bucket
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.11 从S3存储桶加载数据
- en: Problem
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to read a CSV file from an S3 bucket you have access to.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要从您有访问权限的S3存储桶中读取CSV文件。
- en: Solution
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Add storage options to pandas giving it access to the S3 object:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 向pandas添加存储选项，使其可以访问S3对象：
- en: '[PRE19]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '|  | integer | datetime | category |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  | 整数 | 日期时间 | 类别 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 5 | 2015-01-01 00:00:00 | 0 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 5 | 2015-01-01 00:00:00 | 0 |'
- en: '| 1 | 5 | 2015-01-01 00:00:01 | 0 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 5 | 2015-01-01 00:00:01 | 0 |'
- en: Discussion
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Many enterprises now keep data in cloud provider blob stores such as Amazon
    S3 or Google Cloud Storage (GCS). It’s common for machine learning practitioners
    to connect to these sources to retrieve data. Although the S3 URI (`s3://machine-learning-python-cookbook/data.csv`)
    is public, it still requires you to provide your own AWS access credentials to
    access it. It’s worth noting that public objects also have HTTP URLs from which
    they can download files, [such as this one for the CSV file](https://oreil.ly/byelc).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 许多企业现在将数据保存在云提供商的Blob存储中，如Amazon S3或Google Cloud Storage（GCS）。机器学习从业者通常连接到这些来源以检索数据。虽然S3
    URI（`s3://machine-learning-python-cookbook/data.csv`）是公共的，但仍然需要您提供自己的AWS访问凭据才能访问它。值得注意的是，公共对象还有HTTP
    URL，可以从中下载文件，[比如这个CSV文件的链接](https://oreil.ly/byelc)。
- en: See Also
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Amazon S3](https://oreil.ly/E-CZX)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Amazon S3](https://oreil.ly/E-CZX)'
- en: '[AWS Security Credentials](https://oreil.ly/aHBBb)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS安全凭证](https://oreil.ly/aHBBb)'
- en: 2.12 Loading Unstructured Data
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.12 加载非结构化数据
- en: Problem
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to load unstructured data like text or images.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要加载文本或图像等非结构化数据。
- en: Solution
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use the base Python `open` function to load the information:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基本的Python `open`函数加载信息：
- en: '[PRE20]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Discussion
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: While structured data can easily be read in from CSV, JSON, or various databases,
    unstructured data can be more challenging and may require custom processing down
    the line. Sometimes it’s helpful to open and read in files using Python’s basic
    `open` function. This allows us to open files and then read the content of that
    file.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然结构化数据可以轻松从CSV、JSON或各种数据库中读取，但非结构化数据可能更具挑战性，可能需要稍后进行定制处理。有时使用Python的基本`open`函数打开并读取文件会很有帮助。这样我们就可以打开文件然后读取文件的内容。
- en: See Also
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Python’s open function](https://oreil.ly/Xuuom)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python的open函数](https://oreil.ly/Xuuom)'
- en: '[Context managers in Python](https://oreil.ly/UyZnL)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python中的上下文管理器](https://oreil.ly/UyZnL)'
