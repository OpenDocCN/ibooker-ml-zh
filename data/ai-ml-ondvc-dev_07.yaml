- en: Chapter 7\. Text Processing Apps with ML Kit on iOS
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 7 章\. 在 iOS 上使用 ML Kit 进行文本处理应用程序
- en: In [Chapter 6](ch06.html#computer_vision_apps_with_ml_kit_on_ios), you saw how
    to use ML Kit in your iOS apps for some computer vision scenarios including image
    recognition and object detection. Perhaps the next largest segment of ML apps
    are those which perform natural language processing tasks. So in this chapter
    we’ll look at a few examples of how models from ML Kit provide some common machine
    learning tasks for you, including extracting entities from text, such as recognizing
    an email address or a date; performing handwriting recognition, turning strokes
    into text; and analyzing a conversation to generate a smart reply. If you want
    to create apps that use other natural language processing concepts with custom
    models, such as classifying text, you’ll need to build your own models, and we’ll
    explore that in later chapters.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 6 章](ch06.html#computer_vision_apps_with_ml_kit_on_ios)中，您了解了如何在 iOS 应用程序中使用
    ML Kit 处理一些计算机视觉场景，包括图像识别和物体检测。也许 ML 应用程序的下一个最大领域是执行自然语言处理任务。因此，在本章中，我们将看一些示例，了解
    ML Kit 模型如何为您提供一些常见的机器学习任务，包括从文本中提取实体，例如识别电子邮件地址或日期；执行手写识别，将笔画转换为文本；以及分析对话以生成智能回复。如果您想创建使用自定义模型的其他自然语言处理概念的应用程序，例如分类文本，您需要构建自己的模型，我们将在后面的章节中探讨这一点。
- en: Entity Extraction
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实体提取
- en: Often you’ll want to extract vital information from text. You’ve no doubt seen
    apps that can determine when there’s an address in a piece of text and automatically
    generate a link to a map of that address, or others that understand an email address
    and generate a link that lets you launch your email app to send mail to that address.
    This concept is called *entity extraction*, and in this section you’ll explore
    a turnkey model that performs this for you. This is a really cool implementation
    of ML, because if you consider how a rules-based approach would solve this problem,
    you would expect to write a lot of code!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 您经常需要从文本中提取重要信息。毫无疑问，您已经见过可以确定文本中是否有地址并自动生成该地址地图链接的应用程序，或者了解电子邮件地址并生成链接，让您启动电子邮件应用程序发送邮件至该地址的应用程序。这个概念称为*实体提取*，在本节中，您将探索一个可以为您执行此操作的即插即用模型。这是
    ML 的一个非常酷的实现，因为如果考虑到一个基于规则的方法如何解决这个问题，您会期望编写大量的代码！
- en: So, consider [Figure 7-1](#running_entity_extraction_on_ios), where I’ve sent
    a message to my friend Nizhoni with some details in it. As a human reading, this
    you’ll automatically extract valuable information from it and parse it. You’ll
    see words like “tomorrow at 5PM” and automatically infer a date and time. Code
    for that would have lots of if...then statements!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，请考虑[图 7-1](#running_entity_extraction_on_ios)，我已向我的朋友 Nizhoni 发送了一条带有一些细节的消息。作为人类阅读这段话时，您会自动从中提取有价值的信息并解析它。您会看到诸如“明天下午5点”的词语，并自动推断日期和时间。为此编写代码会有大量的
    if...then 语句！
- en: '![](assets/aiml_0701.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0701.png)'
- en: Figure 7-1\. Running entity extraction on iOS
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-1\. 在 iOS 上运行实体提取
- en: As you can see beneath the text, a list was generated with the entities that
    were found. So, for example, the “tomorrow at 5PM” was extracted as a datetime.
    Others like phone numbers and email addresses were also extracted correctly. Often
    a value will match multiple patterns; for example, the ISBN of the book starts
    with a three-digit number, which matches the pattern of a phone number, so it
    was detected as both entities!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在文本下面所看到的，生成了一个包含找到的实体的列表。例如，“明天下午5点”被提取为日期时间。其他如电话号码和电子邮件地址也被正确提取。通常一个值会匹配多个模式；例如，书籍的
    ISBN 号以三位数字开头，这与电话号码的模式匹配，因此被检测为两个实体！
- en: Let’s now explore how you can create this app!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们探索一下如何创建这个应用程序！
- en: 'Step 1: Create the App and Add the ML Kit Pods'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '步骤 1: 创建应用程序并添加 ML Kit Pods'
- en: Using Xcode, create a new app. When you’re done, close Xcode and create a Podfile
    in the directory where the *.xcproject* resides.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Xcode 创建一个新的应用程序。完成后，关闭 Xcode 并在 *.xcproject* 文件所在的目录中创建一个 Podfile。
- en: 'Edit the Podfile to include the *GoogleMLKit/EntityExtraction* pod like this:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑 Podfile，像这样包括 *GoogleMLKit/EntityExtraction* pod：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The value after `target` should be the name of your project, so in this case
    I created a project called *MLKitEntityExample*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`target` 后面的值应该是你项目的名称，在这个例子中我创建了一个名为 *MLKitEntityExample* 的项目。'
- en: Once you’re done, run `**pod install**`; CocoaPods will update your project
    to use the ML Kit dependencies and generate a *.xcworkspace* file that you should
    open to go to the next step.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，运行 `**pod install**`；CocoaPods 将更新您的项目以使用 ML Kit 依赖项，并生成一个 *.xcworkspace*
    文件，您应该打开该文件以进行下一步操作。
- en: 'Step 2: Create the Storyboard with Actions and Outlets'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二步：创建带有操作和输出的故事板
- en: As you saw in [Figure 7-1](#running_entity_extraction_on_ios), the user interface
    for this app is really simple. Add a TextView, a Button, and a Label control in
    a layout similar to what you can see in [Figure 7-1](#running_entity_extraction_on_ios).
    Make sure that the TextView is editable by checking the editable box in the properties
    inspector after you put it on the storyboard.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在[图 7-1](#running_entity_extraction_on_ios)中看到的那样，这个应用的用户界面非常简单。在布局中添加一个
    TextView、一个 Button 和一个 Label 控件，布局类似于您在[图 7-1](#running_entity_extraction_on_ios)中看到的样子。确保在将其放置在故事板后，通过检查属性检查器中的可编辑框来使
    TextView 可编辑。
- en: Your storyboard designer should look like [Figure 7-2](#designing_the_user_interface_in_the_sto)
    when you’re done.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当您完成时，您的故事板设计器应该类似于[图 7-2](#designing_the_user_interface_in_the_sto)。
- en: '![](assets/aiml_0702.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0702.png)'
- en: Figure 7-2\. Designing the user interface in the storyboard editor
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-2\. 在故事板编辑器中设计用户界面
- en: Next you should create outlets for the TextView and Label, called `txtInput`
    and `txtOutput`, respectively. Also create an action for the button and call it
    `doExtraction`. If you’re not familiar with the process of outlets and actions,
    check back to Chapters [3](ch03.html#introduction_to_ml_kit) and [6](ch06.html#computer_vision_apps_with_ml_kit_on_ios)
    for more guided examples.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您应该为 TextView 和 Label 创建 outlets，分别命名为 `txtInput` 和 `txtOutput`。还要为按钮创建一个动作，并将其命名为
    `doExtraction`。如果您不熟悉 outlets 和 actions 的过程，请返回第 [3](ch03.html#introduction_to_ml_kit)
    章和第 [6](ch06.html#computer_vision_apps_with_ml_kit_on_ios) 章获取更多指导示例。
- en: 'When you’re done, the following code should be in your `ViewController` class:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您的 `ViewController` 类应包含以下代码：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Step 3: Allow Your View Controller to be Used for Text Entry'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三步：允许您的视图控制器用于文本输入
- en: 'When the user taps on the text view at the top, they’ll be able to edit its
    contents via their device keyboard. However, the keyboard won’t go away by default
    when they’re done. To give this functionality, you need to update your `ViewController`
    to be a `UITextViewDelegate` like this:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户点击顶部的文本视图时，他们将能够通过设备键盘编辑其内容。但是，默认情况下，键盘在完成后不会自动消失。要实现此功能，您需要更新 `ViewController`
    以成为 `UITextViewDelegate`，如下所示：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once that’s done, you can add this function to make the keyboard leave when
    the user presses Enter:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您可以添加以下函数，以使键盘在用户按下 Enter 键时离开：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Finally, you have to inform iOS that the `txtInput` control will delegate TextView
    events to this `ViewController` by adding this code to your `viewDidLoad` function:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您需要通过将以下代码添加到 `viewDidLoad` 函数中，告知 iOS，`txtInput` 控件将 TextView 事件委托给此 `ViewController`：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You’re now ready to allow the user to input text. So, next up, let’s look at
    how to extract entities in this text!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以允许用户输入文本了。接下来，让我们看看如何从这段文本中提取实体！
- en: 'Step 4: Initialize the Model'
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四步：初始化模型
- en: 'ML Kit’s entity extractor supports many language models, so the first thing
    you should do is to define which one you want by using `EntityExtractorOptions`.
    In this case, I’m specifying that I want to use an English entity extractor:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit 的实体提取器支持许多语言模型，因此您首先需要通过使用 `EntityExtractorOptions` 来定义您想要的语言模型。在本例中，我指定要使用英文实体提取器：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: There are a number of different languages supported, with the complete list
    at [*https://developers.google.com/ml-kit/language/entity-extraction*](https://developers.google.com/ml-kit/language/entity-extraction)*.*
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 支持多种不同的语言，完整列表请参见 [*https://developers.google.com/ml-kit/language/entity-extraction*](https://developers.google.com/ml-kit/language/entity-extraction)*.*
- en: 'The model isn’t guaranteed to be on the device when your user presses the button,
    so you can use code like this in your `viewDidLoad` to download it, and set a
    Boolean flag indicating that it’s available which you’ll check later:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户按下按钮时，不能保证模型已在设备上，因此您可以在 `viewDidLoad` 中使用以下代码来下载它，并设置一个布尔标志指示它是否可用，稍后将进行检查：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Step 5: Extract Entities from Text'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第五步：从文本中提取实体
- en: 'Earlier, when you created the action for the button, you got a function called
    `doExtraction`. Within this you want to call `extractEntities`, which you’ll create
    shortly, but only if the model is available. You downloaded the model in step
    3, and set `modelAvailable` to true when it was done, so you can use this code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，当您为按钮创建操作时，您获取了一个名为`doExtraction`的函数。在其中，您希望调用`extractEntities`，您将很快创建它，但仅当模型可用时。在步骤
    3 中下载了模型，并且当完成时将`modelAvailable`设置为`true`，因此可以使用以下代码：
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You can now create the `extractEntities` function, and within it, you can use
    the `entityExtractor` you just created with the text within `txtInput` to get
    the entities within the text.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以创建`extractEntities`函数，并在其中使用刚刚创建的`entityExtractor`与`txtInput`中的文本一起获取文本中的实体。
- en: 'Start by creating the code to extract the entities like this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 首先创建用于提取实体的代码如下：
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here you’ve passed the text to the `entityExtractor` within its `annotateText`
    method. It will give you a callback on completion, and the callback will contain
    results and error data structures. Results will be a list of annotations, and
    each annotation will be a list of entities.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您将文本传递给`entityExtractor`的`annotateText`方法。它将在完成时给您一个回调，并且回调将包含结果和错误数据结构。结果将是一组注释的列表，每个注释将是一组实体的列表。
- en: An entity has an `entityType` property defining the annotation type, such as
    email, address or ISBN. The entity has a range property containing the location
    and length of the text. So, if an email address is at the 20th character, and
    it is 15 characters long, then `annotation.range.location` will be 20, and `annotation.range.length`
    will be 15\. You can use this to slice the string to get the desired text.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一个实体具有`entityType`属性，定义了注释类型，例如电子邮件、地址或ISBN。实体具有一个范围属性，包含文本的位置和长度。因此，如果电子邮件地址位于第20个字符，并且长度为15个字符，则`annotation.range.location`将为20，`annotation.range.length`将为15。您可以使用这个来切割字符串以获取所需的文本。
- en: 'Here’s the complete code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是完整的代码：
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Swift string slicing is more complicated than you might think! The reason for
    this is that a common way of attacking apps is with strings and with code that
    naively slices strings, potentially causing a buffer underflow or a buffer overflow.
    As a result, Swift is designed to guard against naive string slicing with `Mid()`
    or `Left()` type functions that you may be familiar with. In the preceding code
    we calculate a `startLoc` and an `endLoc`, and then set `mySubString` to be the
    slice from the start to the end. This is *not* supported in Swift and an extension
    was necessary to get it to work. Do not use this code in any kind of production
    app and check how you manage your strings before publishing any app!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Swift 字符串切片比你想象的更复杂！原因在于，攻击应用程序的常见方式是使用字符串和过于天真的字符串切片代码，这可能导致缓冲区下溢或溢出。因此，Swift
    设计了`Mid()`或`Left()`等类型的函数来防范这种天真的字符串切片。在前面的代码中，我们计算了`startLoc`和`endLoc`，然后设置`mySubString`为从开始到结束的切片。这在
    Swift 中是*不*支持的，需要进行扩展才能使其正常工作。请勿在任何生产应用程序中使用此代码，并在发布任何应用程序之前检查如何管理字符串！
- en: 'Here’s the code for the string slicing extension:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是字符串切片扩展的代码：
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: And that’s pretty much everything that you need to get started with entity extraction
    with ML Kit on iOS. This is just scratching the surface, but hopefully this gives
    you an idea of how easy ML Kit can make this task!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在 iOS 上使用 ML Kit 开始实体提取所需的全部内容。这只是初步探索，但希望这能让你了解 ML Kit 可以如何轻松完成这项任务！
- en: Handwriting Recognition
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手写识别
- en: Another example of where it would be complex to write code to solve a task is
    in handwriting recognition, where the user draws on their screen with a stylus
    or finger and it’s your job to turn their scribbles into text. Fortunately ML
    Kit makes this a lot easier too, and you’ll explore how to do that in this section.
    So, for example, consider [Figure 7-3](#app_that_recognizes_handwriting), where
    I’ve drawn some letters with my finger, and the app detected them to say the word
    “hello.”
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是手写识别，如果用户用笔或手指在屏幕上绘制，你需要将他们的涂鸦转换为文本。幸运的是，ML Kit 也大大简化了这一过程，您将在本节中了解如何实现这一点。例如，考虑[图
    7-3](#app_that_recognizes_handwriting)，我用手指写了一些字母，应用程序检测到它们并将其识别为单词“hello”。
- en: '![](assets/aiml_0703.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0703.png)'
- en: Figure 7-3\. App that recognizes handwriting
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-3\. 应用程序，识别手写
- en: Using ML Kit to create this type of app is really straightforward! Let’s explore.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ML Kit 创建此类型的应用程序非常简单！让我们来探索一下。
- en: 'Step 1: Create the App and Add the ML Kit Pods'
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1：创建应用程序并添加 ML Kit Pods
- en: 'As before, create a simple single view app, and when you’re done, add a Podfile
    to the same directory as the *.xcproject*. Edit the Podfile to include the ML
    Kit Digital Ink libraries:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，请创建一个简单的单视图应用程序。完成后，在*.xcproject*相同目录下添加一个Podfile。编辑Podfile以包含ML Kit Digital
    Ink库：
- en: '[PRE11]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you aren’t calling your project *MLKitInkExample*, then the name of your
    project should be specified as the `target` instead. Run `**pod install**` and
    then open the *.xcworkspace* that gets generated for you.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的项目不称为*MLKitInkExample*，那么应将您的项目名称指定为`target`。运行`**pod install**`，然后打开为您生成的*.xcworkspace*。
- en: 'Step 2: Create the Storyboard, Actions, and Outlets'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤2：创建故事板、操作和出口
- en: The drawing surface will be a UIImageView, so draw a big one that covers most
    of the screen on the storyboard. Also add a button and change its label to Detect,
    as shown in [Figure 7-4](#creating_the_storyboard).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图表面将是一个UIImageView，因此请在故事板上绘制一个覆盖大部分屏幕的大图像视图。还添加一个按钮，并将其标签更改为“检测”，如[图7-4](#creating_the_storyboard)所示。
- en: '![](assets/aiml_0704.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0704.png)'
- en: Figure 7-4\. Creating the storyboard
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-4\. 创建故事板
- en: When you’re done, create an outlet for the image view (call it `mainImageView`)
    and an action for the button ((call it `recognizeInk`). To the action add a call
    to a function called `doRecognition()`. Don’t worry if Xcode complains that that
    function doesn’t exist yet. You’ll create it soon.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，请为图像视图创建一个出口（称为`mainImageView`），并为按钮创建一个操作（称为`recognizeInk`）。在操作中添加一个调用名为`doRecognition()`的函数。如果Xcode抱怨该函数尚不存在，请不用担心。您很快会创建它。
- en: 'Your code should look like this:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您的代码应如下所示：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Step 3: Strokes, Points, and Ink'
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤3：笔画、点和墨水
- en: 'When using ML Kit to recognize handwriting, you will pass it an ink object.
    This object is made up of a number of strokes, and each stroke is a number of
    points. For example, consider the letter Z. This could be made up of three strokes:
    one for the top line, one for the diagonal, and one for the bottom line. The ink
    would be the collection of strokes, and each stroke would be a number of points
    that were gathered as the user drew the lines.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用ML Kit识别手写时，您将向其传递一个墨水对象。该对象由多个笔画组成，每个笔画都由多个点组成。例如，考虑字母Z。它可能由三笔构成：一笔用于顶部线，一笔用于对角线，一笔用于底部线。墨水将是笔画的集合，每笔都将是用户绘制线条时收集的点的数量。
- en: 'So, before we capture the user’s input when they drag their finger around the
    screen, we’ll need these data structures set up for us:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在捕捉用户在屏幕上拖动手指时的输入之前，我们需要为我们设置这些数据结构：
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You’ll see the ink object set up later.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到稍后设置的墨水对象。
- en: 'Step 4: Capture User Input'
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤4：捕获用户输入
- en: Next you’ll want to gather the user’s input when they draw on the UIImage with
    their finger or stylus. This is done by overriding three different functions—`touchesBegan`,
    `touchesMoved,` and `touchesEnded`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将希望在用户用手指或笔在UIImage上绘制时收集用户的输入。这是通过覆盖三个不同函数`touchesBegan`、`touchesMoved`和`touchesEnded`来完成的。
- en: 'The first, `touchesBegan`, is fired when the user starts drawing something.
    Their finger first touches the screen. Here, we want to initialize the array of
    points and start it with the point where our drawing begins:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个是`touchesBegan`，当用户开始绘制某些内容时触发。他们的手指首先触摸屏幕。在这里，我们希望初始化点数组，并以绘制开始的点开始它：
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Because the sequence in which strokes and stroke points are recorded is important
    to the model, we also need a timestamp, so you can see that it is collected here
    also and used to initialize the `StrokePoint`.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 因为记录笔画和笔画点的顺序对模型很重要，我们还需要一个时间戳，这样您就可以看到它在这里被收集并用于初始化`StrokePoint`。
- en: The next event to capture is the `touchesMoved` event, which occurs when the
    user’s finger passes across the surface before they lift it. In this case we want
    to get the current point from the touch location, but this time we append it to
    the points array, instead of creating a new array. We’ll also need a timestamp
    like before. The `drawLine` function will draw from the last (aka previous) point
    to the current point, and then set the last point to the current point.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获的下一个事件是`touchesMoved`事件，当用户的手指在抬起之前在表面上移动时发生。在这种情况下，我们希望从触摸位置获取当前点，但这次将其追加到点数组中，而不是创建新的数组。我们还需要像以前一样的时间戳。`drawLine`函数将从上一个点（即上一个点）绘制到当前点，然后将上一个点设置为当前点。
- en: 'Here’s the code:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码：
- en: '[PRE15]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When the user removes their finger from the screen at the end of the stroke,
    the `touchesEnded` event will fire. There is no “new” point here to add, so the
    `lastPoint` that you’ve been keeping track of becomes the final point to have
    in the list. You can create a new `StrokePoint` using it, and add that to the
    list of points in this stroke, finalizing the stroke.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户在笔画结束时从屏幕上移开手指时，将触发`touchesEnded`事件。这里没有“新”点要添加，因此您一直跟踪的`lastPoint`将成为列表中的最后一个点。您可以使用它创建一个新的`StrokePoint`，并将其添加到此笔画中的点列表中，从而完成笔画。
- en: 'The finalized stroke will then be added to the list of strokes by initializing
    a new `Stroke` object using the points that have been collected since this touch
    began:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过使用收集自此触摸开始以来的点来初始化一个新的`Stroke`对象，最终笔画将添加到笔画列表中：
- en: '[PRE16]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: I won’t show the code for drawing the line here, but you can find it in the
    GitHub repo for this book.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会在这里展示绘制线条的代码，但您可以在本书的GitHub存储库中找到它。
- en: 'Step 5: Initialize the Model'
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5步：初始化模型
- en: Now that you have an app that can capture the user’s drawings on the `UIImage`
    and have those represented as a list of strokes, you have everything you need
    to pass to the model to get an inference about them, which should hopefully be
    an accurate conversion of handwriting into text!
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经有一个可以在`UIImage`上捕捉用户绘图并将其表示为一系列笔画的应用程序，您可以将所有这些传递给模型以获得关于它们的推断，这应该是将手写转换为文本的准确表示！
- en: Before you can do that, of course, you need a model! In this step, you’ll download
    and initialize the model so that later you can turn your strokes into Ink and
    have it infer from them.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在此之前，您需要一个模型！在这一步中，您将下载并初始化模型，以便稍后将您的笔画转换为Ink并从中推断。
- en: 'First, you’ll need to check if the model is available. You can do this by specifying
    your language and using `DigitalInkRecognitionModelIdentifier` to see if it’s
    available. Here’s the code:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要检查模型是否可用。您可以通过指定语言并使用`DigitalInkRecognitionModelIdentifier`来查看它是否可用。以下是代码：
- en: '[PRE17]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: If this identifier is nil, you have a problem and need to check your setup or
    internet connection. Make sure also that it’s a supported language; the list of
    supported languages can be found in the [*ML Kit documentation*](https://oreil.ly/4ZoiJ)*.*
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果此标识符为nil，则表示存在问题，您需要检查您的设置或互联网连接。还要确保它是受支持的语言；支持的语言列表可以在[*ML Kit documentation*](https://oreil.ly/4ZoiJ)*.*中找到。
- en: 'Once you have a working model, you can download it. You do this by initializing
    a `DigitalInkRecognitionModel` object with the identifier, and then by using a
    model manager to download it. To set up the model manager, you’ll need to initialize
    a `conditions` object, which controls properties about how the model can or can
    not be downloaded. So, in this example, I’ve set one up that allows for cellular
    access (and not just WiFi), as well as allowing the model to download in the background:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有一个工作模型，您可以下载它。您可以通过使用标识符初始化`DigitalInkRecognitionModel`对象，然后使用模型管理器下载它来实现这一点。要设置模型管理器，您需要初始化一个`conditions`对象，该对象控制模型的下载属性。因此，在这个例子中，我设置了一个允许使用蜂窝数据访问（而不仅仅是WiFi）以及允许后台下载模型的条件：
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Once the model is downloaded, you can create a recognizer object from it. Following
    the familiar pattern, you define an options object (`DigitalInkRecognizerOptions`),
    which in this case you initialize with the model you just downloaded. Once you
    have that, you can then instantiate a recognizer from `DigitalInkRecognizer` using
    these options.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型下载完成，您就可以从中创建一个识别器对象。按照熟悉的模式，您定义一个选项对象（`DigitalInkRecognizerOptions`），在这种情况下，您使用刚刚下载的模型进行初始化。有了这个选项对象后，您就可以使用`DigitalInkRecognizer`从中实例化一个识别器。
- en: 'Here’s the code:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是代码：
- en: '[PRE19]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: If you’ve gotten this far, you should now have a working recognizer. I’ve taken
    a little bit of a shortcut here and just expected the model download to work and
    to be finished before I instantiated the `DigitalInkRecognizerOptions`. There
    is a chance that this could fail (poor network conditions, for example), and as
    a result, this isn’t the best pattern. It would be better to do some kind of asynchronous
    callback that only initializes the recognizer upon successful model download,
    but for the purposes of this tutorial, I wanted to keep it simple.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经完成到这一步，现在应该已经有一个可用的识别器了。我在这里有点走捷径，只是期望模型下载能够正常工作并在我实例化`DigitalInkRecognizerOptions`之前完成。当然，这可能会失败（例如，网络条件差），因此这不是最佳模式。最好是进行某种异步回调，仅在成功下载模型后初始化识别器，但出于本教程的目的，我希望保持简单。
- en: 'Step 6: Do the Ink Recognition'
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 6：进行墨水识别
- en: Now that you have a recognizer, it’s simply a matter of converting your strokes
    into ink, passing them to the recognizer, and parsing the results you get back.
    Let’s explore the code for this.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您有了识别器，只需将笔画转换为墨水，将其传递给识别器，并解析您收到的结果。让我们来看看如何编写这段代码。
- en: 'First, here’s how to turn the strokes into ink:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，这是如何将笔画转换为墨水：
- en: '[PRE20]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next, you can use the recognizer with its recognize method, passing it the
    ink and catching a completion callback:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您可以使用识别器及其识别方法，传递墨水并捕获完成回调：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The completion callback will contain a result and an error, so be sure to set
    them up to begin your completion callback. The result will be a `DigitalInkRecognitionResult`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 完成回调将包含结果和错误，请务必设置它们以开始您的完成回调。结果将是一个 `DigitalInkRecognitionResult`：
- en: '[PRE22]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'A valid result will have many candidates, where it has multiple potential matches.
    So for example, if you look back to [Figure 7-3](#app_that_recognizes_handwriting),
    my “h” might be mistaken for an “n,” and the final “lo” might be mistaken for
    a “b.”’ The engine will return back various candidates in order of priority, so
    it might have “hello,” “nello,” “helb,” “nelb,” etc. To keep things simple, this
    code will just take the first candidate using `results.candidates.first`:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的结果会有许多候选项，其中包含多个潜在的匹配项。例如，如果您回顾[图 7-3](#app_that_recognizes_handwriting)，我的“h”可能会被误认为是“n”，最后的“lo”可能会被误认为是“b”。引擎将按优先顺序返回各种候选项，因此可能会有“hello”、“nello”、“helb”、“nelb”等等。为了简单起见，此代码将仅采用第一个候选项，使用
    `results.candidates.first`：
- en: '[PRE23]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The `alertTitle` and `alertText` values are strings that will be used to set
    up the alert dialog. You saw this on the righthand side of [Figure 7-3](#app_that_recognizes_handwriting).
    The important property to note is `candidate.text`, which is the text interpretation
    of the current candidate. As we’re just taking the first candidate, it’s the one
    that ML Kit determined to be the most likely match.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`alertTitle` 和 `alertText` 的值是将用于设置警报对话框的字符串。您可以在[图 7-3](#app_that_recognizes_handwriting)的右侧看到这一点。要注意的重要属性是
    `candidate.text`，它是当前候选项的文本解释。由于我们只取第一个候选项，这是 ML Kit 确定为最有可能匹配的选项。'
- en: 'After this, you just want to display the alert box, clear the image, and reset
    the strokes and points so you can try again:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您只需显示警报框，清除图像，并重置笔画和点，以便再次尝试：
- en: '[PRE24]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: And that’s it! Try it out and experiment! I’d love to see how it works with
    other languages too!
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是全部！试一试，做些实验！我很想看看它如何与其他语言配合工作！
- en: Smart Reply to Conversations
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 智能回复对话
- en: Another fun example of a turnkey model you can use in your apps is the Smart
    Reply model. You’ve probably used sites like LinkedIn where, as you are chatting
    with somebody, you have suggested responses. Or if you’re an Android user, many
    of the messaging apps include smart replies, as you can see in [Figure 7-5](#smart_reply_in_android_instant_messages),
    where I’m being invited for breakfast and the smart reply has given some suggested
    responses. It’s also done an entity extraction to get the date “tomorrow at 9:30AM”
    and turned it into a link to create a calendar entry!
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的例子是您可以在应用程序中使用的即插即用模型——智能回复模型。您可能已经使用过类似 LinkedIn 的网站，在与某人聊天时，会提供建议的回复。或者，如果您是
    Android 用户，许多消息应用程序包括智能回复，正如您在[图 7-5](#smart_reply_in_android_instant_messages)中所看到的那样，我被邀请参加早餐，智能回复给出了一些建议的回复。它还进行了实体提取，获取了日期“明天上午9:30”并将其转换为链接以创建日历条目！
- en: Other than that, there are smart reply options for ‘“Sure,” “What time?” and
    “Yes.” These have been generated with the context of the statement (it’s a question),
    as well as the vernacular I have used while chatting in the past. I say “sure”
    a lot when invited to stuff!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，还有“‘当然’、“‘几点’和‘是’”的智能回复选项。这些选项是根据语境（这是一个问题）以及我在过去聊天中使用的俗语生成的。我在被邀请时经常说“当然”！
- en: Building an app that uses the ML Kit Smart Reply APIs to get similar functionality
    is very straightforward. Let’s explore how to do that next.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个应用程序，使用 ML Kit 智能回复 API 来获得类似功能非常简单。让我们探讨如何做到这一点。
- en: '![](assets/aiml_0705.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0705.png)'
- en: Figure 7-5\. Smart reply in Android instant messages
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-5\. Android 即时消息中的智能回复
- en: 'Step 1: Create an App and Integrate ML Kit'
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1：创建应用程序并集成 ML Kit
- en: As before, using Xcode creates a simple single view app. When it’s done, put
    the following Podfile in the same directory as your *.xcproject:*
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 与以前一样，使用 Xcode 创建一个简单的单视图应用程序。完成后，将以下 Podfile 放置在与您的 *.xcproject 相同的目录中：
- en: '[PRE25]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In this case, my project was called *MLKitSmartReplyExample*, so be sure to
    use whatever your project name is as the `target` in place of mine. Run `**pod
    install**`, and after it’s done, open the *.xcworkspace* to continue.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我的项目名为*MLKitSmartReplyExample*，所以请确保使用你的项目名作为`target`，而不是我的。 运行`**pod
    install**`，完成后打开*.xcworkspace*继续操作。
- en: 'Step 2: Create Storyboard, Outlets, and Actions'
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤2：创建故事板、出口和操作
- en: To keep this app simple, create a storyboard that has two labels and a button.
    The topmost label will contain a simulated conversation between me and a friend.
    When the user presses the button the Smart Reply model will be used to generate
    a likely reply. The reply will be rendered in the second label. So, from a storyboard
    perspective, your UI should look something like [Figure 7-6](#creating_the_smart_reply_view).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持这个应用程序简单，创建一个包含两个标签和一个按钮的故事板。 最上面的标签将包含我和朋友之间的模拟对话。 当用户按下按钮时，智能回复模型将用于生成一个可能的回复。
    回复将呈现在第二个标签中。 因此，从故事板的角度来看，您的UI应该像[图7-6](#creating_the_smart_reply_view)这样。
- en: Once you’re done with this, create outlets called `conversationLabel` and `txtSuggestions`
    for the upper and lower labels, respectively. For the button, create an action
    called `generateReply` and put a call to the function `getSmartReply()` within
    it. Don’t worry if Xcode complains—you’ll write that function shortly.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，请为上方和下方的标签创建名为`conversationLabel`和`txtSuggestions`的出口。 对于按钮，请创建名为`generateReply`的操作，并在其中调用函数`getSmartReply()`。
    如果Xcode抱怨，不要担心——你很快就会写这个函数。
- en: '![](assets/aiml_0706.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0706.png)'
- en: Figure 7-6\. Creating the Smart Reply view
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-6\. 创建智能回复视图
- en: 'When you’re done, your code should look like this:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您的代码应如下所示：
- en: '[PRE26]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Step 3: Create a Simulated Conversation'
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤3：创建模拟对话
- en: The quickest way to see the model in action is to have a conversation that we
    can pass to it, so let’s create a simple one here. I’ve created an `initializeConversation()`
    function that creates conversation items and adds them to an array of `TextMessage`
    types.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 看到模型运行的最快方法是进行一个我们可以传递给它的对话，所以让我们在这里创建一个简单的对话。 我创建了一个`initializeConversation()`函数，它创建了对话项目并将它们添加到`TextMessage`类型的数组中。
- en: 'So, at the class level you should initialize the array:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在类级别上，您应初始化数组：
- en: '[PRE27]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Then, `initializeConversation` will begin to populate the array. A `TextMessage`
    type contains details about a message including its contents, timestamp, who it’s
    from, and most importantly, if it is a local user (i.e., you) or a remote user
    (i.e., someone else). So, to create a conversation, I wrote a helper function
    that overloads `addConversationItem` based on whether it’s me or my friend sending
    the message. Here’s the function in full:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`initializeConversation`将开始填充数组。 `TextMessage`类型包含有关消息的详细信息，包括其内容、时间戳、发送者及其是否为本地用户（即您）或远程用户（即其他人）。
    因此，为了创建对话，我编写了一个辅助函数，根据消息发送者（是我还是我的朋友）重载`addConversationItem`。 以下是完整函数：
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Notice that some of the calls to `addConversation` have a `fromUser:` parameter,
    and some do not. Those that do not are simulated to be from me, while those that
    do will be simulated from a remote user. So, the `addConversation` overloads that
    implement this are here.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，一些对`addConversation`的调用有一个`fromUser:`参数，而另一些则没有。 那些没有的被模拟成来自我，而那些有的则被模拟成来自远程用户。
    因此，这里实现了这些的`addConversation`重载。
- en: 'First we add a conversation item from me. Note that the `TextMessage` is created
    with `userID` as `"Me"`, and not something that is passed to the function, and
    the `isLocalUser` property is set to `true`:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们添加了一条来自我的对话项。 请注意，`TextMessage`创建时`userID`为`"Me"`，而不是传递给函数的内容，并且`isLocalUser`属性设置为`true`：
- en: '[PRE29]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here’s the overload for when the `fromUser:` property is set. In this case,
    note that the `TextMessage` is created with the `userID` that is passed in from
    that property, and `isLocalUser` is set to `false` :'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这是设置`fromUser:`属性时的重载。 在这种情况下，请注意`TextMessage`是使用从该属性传入的`userID`创建的，并且`isLocalUser`设置为`false`：
- en: '[PRE30]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In both cases the `conversationLabel` is updated with the message and the user,
    and the conversation is updated with the message. You can see what this looks
    like in [Figure 7-7](#simulating_a_conversation).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，`conversationLabel`将更新消息和用户，对话将更新消息。 您可以在[Figure 7-7](#simulating_a_conversation)中看到这是什么样子。
- en: '![](assets/aiml_0707.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0707.png)'
- en: Figure 7-7\. Simulating a conversation
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-7\. 模拟对话
- en: 'Step 4: Get Smart Reply'
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤4：获取智能回复
- en: 'Now that you have a conversation and it’s stored as an array of `TextMessage`
    types, you can simply call `SmartReply.smartReply()` and use the `suggestReplies`
    method for that conversation to get a set of smart replies. Earlier, in the button
    action, you coded it to call `getSmartReply()`. You can create that function now,
    and have it call the Smart Reply model:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有了一个对话，并且它被存储为一个 `TextMessage` 类型的数组，您只需调用 `SmartReply.smartReply()` 并对该对话使用
    `suggestReplies` 方法，以获取一组智能回复。在前面，在按钮动作中，您编写了调用 `getSmartReply()` 的代码。您现在可以创建该函数，并让它调用智能回复模型：
- en: '[PRE31]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This will get the suggested replies for your conversation, and if there’s no
    error, they’ll be in the result variable. `result` will be a list of suggestion
    types, and these contain a `suggestion.text` property with the contents of the
    suggestion. So, if you want to create a text list of all the suggested replies,
    you simply need this code:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为您的对话获取建议的回复，如果没有错误，它们将在结果变量中。 `result` 将是一个建议类型的列表，这些列表包含一个 `suggestion.text`
    属性，其中包含建议的内容。因此，如果您想创建所有建议回复的文本列表，您只需使用以下代码：
- en: '[PRE32]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Here, if the result status is a success, you can see that we loop through `result.suggestions`,
    building the suggested replies list. When you run the app, you’ll see a list of
    suggested replies. This is shown in [Figure 7-8](#viewing_the_suggested_replies).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，如果结果状态是成功的，您可以看到我们循环遍历 `result.suggestions`，构建建议的回复列表。当您运行应用程序时，您将看到一个建议回复的列表。这在
    [Figure 7-8](#viewing_the_suggested_replies) 中显示。
- en: '![](assets/aiml_0708.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0708.png)'
- en: Figure 7-8\. Viewing the suggested replies
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-8\. 查看建议的回复
- en: In a real app you could make these a pickable list, and when the user selects
    one it populates the reply box with the suggested text, just like the Android
    SMS app shown in [Figure 7-5](#smart_reply_in_android_instant_messages)!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个真实的应用程序中，您可以将它们制作成一个可选列表，当用户选择其中一个时，它将填充回复框与建议的文本，就像 Android 短信应用程序中显示的 [Figure 7-5](#smart_reply_in_android_instant_messages)
    一样！
- en: This is just a simple example of what’s possible with Smart Reply, and hopefully
    this will show you how easy it is to incorporate into your apps!
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是 Smart Reply 可能性的一个简单示例，希望这能展示出将其轻松整合到您的应用程序中有多么简单！
- en: Summary
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: This chapter took you through a number of scenarios where you could use a turnkey
    model in ML Kit to get ML functionality in an iOS app. You started with entity
    detection where you could quickly and easily parse common entities such as email
    or time/date out of a string. You then looked at using digital ink to capture
    a user’s strokes on the screen and parse that into text—effectively recognizing
    handwriting! Finally, you dug into the Smart Reply APIs that help you speed up
    conversations with suggested replies. All of these models run using TensorFlow
    Lite on the backend (and if you were eagle eyed you might have seen mentions of
    this in the debugger!), so in [Chapter 8](ch08.html#going_deeper_understanding_tensorflow_l)
    we’ll switch gears and get an overview of how this technology works to bring ML
    to mobile.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了多种情景，您可以在 ML Kit 中使用即插即用模型，在 iOS 应用程序中获得 ML 功能。您从实体检测开始，可以快速简便地解析字符串中的常见实体，如电子邮件或时间/日期。然后，您看了看如何使用数字墨水捕捉用户在屏幕上的笔划，并将其解析为文本——有效地识别手写！最后，您深入了解了
    Smart Reply API，帮助您加快建议回复的速度。所有这些模型都在后端使用 TensorFlow Lite 运行（如果您眼尖的话，可能已经在调试器中看到了这方面的提及！），因此在
    [Chapter 8](ch08.html#going_deeper_understanding_tensorflow_l) 中，我们将转换视角，全面了解这项技术如何在移动设备上实现
    ML 功能。
