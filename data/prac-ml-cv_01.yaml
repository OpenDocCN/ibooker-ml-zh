- en: Chapter 1\. Machine Learning for Computer Vision
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章\. 计算机视觉的机器学习
- en: 'Imagine that you are sitting in a garden, observing what’s going on around
    you. There are two systems in your body that are at work: your eyes are acting
    as sensors and creating representations of the scene, while your cognitive system
    is making sense of what your eyes are seeing. Thus, you might see a bird, a worm,
    and some movement and realize that the bird has walked down the path and is eating
    a worm (see [Figure 1-1](#human_vision_involves_our_sensory_and_co)).'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你坐在花园里，观察周围的一切。你身体里有两个系统在工作：你的眼睛作为传感器创建场景的表示，而你的认知系统正在理解你的眼睛所看到的东西。因此，你可能看到一只鸟，一只虫子和一些动静，并意识到鸟已经走下小路，正在吃虫子（见
    [图 1-1](#human_vision_involves_our_sensory_and_co)）。
- en: '![](Images/pmlc_0101.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0101.png)'
- en: Figure 1-1\. Human vision involves our sensory and cognitive systems.
  id: totrans-3
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-1\. 人类视觉涉及我们的感知和认知系统。
- en: Computer vision tries to imitate human vision capabilities by providing methods
    for image formation (mimicking the human *sensory* system) and machine perception
    (mimicking the human *cognitive* system). Imitation of the human sensory system
    is focused on hardware and on the design and placement of sensors such as cameras.
    The modern approach to imitating the human cognitive system consists of machine
    learning (ML) methods that are used to extract information from images. It is
    these methods that we cover in this book.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉试图通过提供图像形成的方法（模拟人类的*感知*系统）和机器感知（模拟人类的*认知*系统）来模仿人类视觉能力。模仿人类感知系统侧重于硬件以及设计和摆放诸如摄像机之类的传感器。而现代模仿人类认知系统的方法包括从图像中提取信息的机器学习（ML）方法。本书将涵盖这些方法。
- en: When we see a photograph of a daisy, for example, our human cognitive system
    is able to recognize it as a daisy (see [Figure 1-2](#an_image_classification_machine_learning)).
    The machine learning models for image classification that we build in this book
    imitate this human capability by starting from photographs of daisies.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当我们看到一朵雏菊的照片时，我们的人类认知系统能够识别它为雏菊（见 [图 1-2](#an_image_classification_machine_learning)）。本书中构建的图像分类机器学习模型通过从雏菊的照片开始，模仿这种人类能力。
- en: '![](Images/pmlc_0102.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0102.png)'
- en: Figure 1-2\. An image classification machine learning model imitates the human
    cognitive system.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-2\. 一个图像分类的机器学习模型模仿了人类认知系统。
- en: Machine Learning
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: If you were reading a book on computer vision in the early 2010s, the methods
    used to extract information from photographs would not have involved machine learning.
    Instead, you would have been learning about denoising, edge finding, texture detection,
    and morphological (shape-based) operations. With advancements in artificial intelligence
    (more specifically, advances in machine learning), this has changed.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在2010年代初读关于计算机视觉的书，从照片中提取信息的方法不会涉及机器学习。相反，你会学习去噪、边缘检测、纹理检测和形态学（基于形状）操作。随着人工智能的进步（更具体地说，是机器学习的进步），这种情况已经改变。
- en: Artificial intelligence (AI) explores methods by which computers can mimic human
    capabilities. *Machine learning* is a subfield of AI that teaches computers to
    do this by showing them a large amount of data and instructing them to learn from
    it. *Expert systems* is another subfield of AI—expert systems teach computers
    to mimic human capabilities by programming the computers to follow human logic.
    Prior to the 2010s, computer vision tasks like image classification were commonly
    done by building bespoke image filters to implement the logic laid out by experts.
    Nowadays, image classification is achieved through convolutional networks, a form
    of deep learning (see [Figure 1-3](#computer_vision_is_a_subfield_of_ai_that)).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）探索计算机如何模仿人类的能力。*机器学习* 是AI的一个子领域，通过展示大量数据并指导计算机从中学习来教导计算机如何实现这一点。*专家系统*
    是AI的另一个子领域，专家系统通过编程让计算机遵循人类逻辑来模仿人类的能力。在2010年代之前，像图像分类这样的计算机视觉任务通常是通过构建定制的图像滤波器来实现专家制定的逻辑。如今，图像分类通过卷积网络实现，这是一种深度学习的形式（见
    [图 1-3](#computer_vision_is_a_subfield_of_ai_that)）。
- en: '![](Images/pmlc_0103.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0103.png)'
- en: Figure 1-3\. Computer vision is a subfield of AI that tries to mimic the human
    visual system; while it used to rely on an expert systems approach, today it’s
    done with machine learning.
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-3\. 计算机视觉是人工智能的一个子领域，试图模仿人类视觉系统；尽管过去依赖专家系统方法，但今天已经转向机器学习。
- en: Take, for example, the image of the daisy in [Figure 1-2](#an_image_classification_machine_learning).
    A machine learning approach teaches a computer to recognize the type of flower
    in an image by showing the computer lots of images along with their *labels* (or
    correct answers). So, we’d show the computer lots of images of daisies, lots of
    images of tulips, and so on. Based on such a *labeled training dataset,* the computer
    learns how to classify an image that it has not encountered before. How this happens
    is discussed in Chapters [2](ch02.xhtml#ml_models_for_vision) and [3](ch03.xhtml#image_vision).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以[图1-2](#an_image_classification_machine_learning)中雏菊的图像为例。机器学习方法通过向计算机展示大量图像及其*标签*（或正确答案）来教会计算机识别图像中的花卉类型。因此，我们会向计算机展示大量雏菊的图像，大量郁金香的图像等等。基于这样的*带标签的训练数据集*，计算机学习如何对它以前没有遇到过的图像进行分类。这个过程在[第2章](ch02.xhtml#ml_models_for_vision)和[第3章](ch03.xhtml#image_vision)中有详细讨论。
- en: In an expert system approach, on the other hand, we would start by interviewing
    a human botanist on how they classify flowers. If the botanist explained that
    *bellis perennis* (the scientific name for a daisy) consists of white elongated
    petals around a yellow center and green, rounded leaves, we would attempt to devise
    image processing filters to match these criteria. For example, we’d look for the
    prevalence of white, yellow, and green in the image. Then we’d devise edge filters
    to identify the borders of the leaves and matched morphological filters to see
    if they match the expected rounded shape. We might smooth the image in HSV (hue,
    saturation, value) space to determine the color of the center of the flower as
    compared to the color of the petals. Based on these criteria, we might come up
    with a score for an image that rates the likelihood that it is a daisy. Similarly,
    we’d design and apply different sets of rules for roses, tulips, sunflowers, and
    so on. To classify a new image, we’d pick the category whose score is highest
    for that image.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在专家系统的方法中，我们会首先采访人类植物学家，了解他们如何分类花朵。如果植物学家解释说*bellis perennis*（雏菊的学名）由白色的细长花瓣围绕着黄色中心和绿色圆形叶子组成，我们会尝试设计图像处理滤波器以匹配这些标准。例如，我们会寻找图像中白色、黄色和绿色的普遍性。然后，我们会设计边缘滤波器来识别叶子的边界，并匹配形态学滤波器来查看它们是否符合预期的圆形形状。我们可能会在HSV（色调、饱和度、亮度）空间中平滑图像，以确定花朵中心的颜色与花瓣颜色的比较情况。基于这些标准，我们可能会为图像评分，评估其为雏菊的可能性。同样地，我们会为玫瑰、郁金香、向日葵等设计并应用不同的规则集。要对新图像进行分类，我们会选择得分最高的类别。
- en: This description illustrates the considerable bespoke work that was needed to
    create image classification models. This is why image classification used to have
    limited applicability.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这个描述说明了创造图像分类模型所需的大量定制工作。这就是为什么图像分类曾经的适用性有限。
- en: That all changed in 2012 with the publication of the [AlexNet paper](https://dl.acm.org/doi/10.1145/3065386).
    The authors—Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton—were able
    to greatly outperform any existing image classification method by applying convolutional
    networks (covered in [Chapter 3](ch03.xhtml#image_vision)) to the benchmark dataset
    used in the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC). They achieved
    a top-5^([1](ch01.xhtml#ch01fn01)) error of 15.3%, while the error rate of the
    runner-up was over 26%. Typical improvements in competitions like this are on
    the order of 0.1%, so the improvement that AlexNet demonstrated was one hundred
    times what most people expected! This was an attention-grabbing performance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 2012年，随着[AlexNet论文](https://dl.acm.org/doi/10.1145/3065386)的发表，一切都改变了。作者——Alex
    Krizhevsky、Ilya Sutskever和Geoffrey E. Hinton——通过将卷积网络（在[第3章](ch03.xhtml#image_vision)介绍）应用于ImageNet大规模视觉识别挑战(ILSVRC)中使用的基准数据集，大大超越了任何现有的图像分类方法。他们的前五错误率为15.3%^([1](ch01.xhtml#ch01fn01))，而亚军的错误率超过26%。像这样的比赛通常的改进幅度大约为0.1%，所以AlexNet展示的进步是大多数人意料之外的一百倍！这是引人注目的表现。
- en: 'Neural networks had been around since the [1970s](https://oreil.ly/IRHqY),
    and convolutional neural networks (CNNs) themselves had been around for more than
    two decades by that point—Yann LeCun introduced the idea in [1989](https://oreil.ly/EqY3a).
    So what was new about AlexNet? Four things:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自20世纪70年代起，神经网络已经存在，而卷积神经网络（CNN）自那时起已经存在了二十多年——Yann LeCun在[1989年](https://oreil.ly/EqY3a)提出了这个想法。那么，AlexNet有何新意呢？有四点：
- en: Graphics processing units (GPUs)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图形处理单元（GPU）
- en: Convolutional neural networks are a great idea, but they are computationally
    very expensive. The authors of AlexNet implemented a convolutional network on
    top of the graphics rendering libraries provided by special-purpose chips called
    GPUs. GPUs were, at the time, being used primarily for high-end visualization
    and gaming. The paper grouped the convolutions to fit the model across two GPUs.
    GPUs made convolutional networks feasible to train (we’ll talk about distributing
    model training across GPUs in [Chapter 7](ch07.xhtml#training_pipeline)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络是一个很好的想法，但计算上非常昂贵。AlexNet的作者们在专用芯片称为GPU提供的图形渲染库上实现了一个卷积网络。当时，GPU主要用于高端可视化和游戏。该论文将卷积分组以适应模型跨两个GPU。GPU使得卷积网络的训练变得可行（我们将在[第7章](ch07.xhtml#training_pipeline)讨论在多GPU上分布模型训练）。
- en: Rectified linear unit (ReLU) activation
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 矫正线性单元（ReLU）激活
- en: AlexNet’s creators used a non-saturating activation function called ReLU in
    their neural network. We’ll talk more about neural networks and activation functions
    in [Chapter 2](ch02.xhtml#ml_models_for_vision); for now, it’s sufficient to know
    that using a piecewise linear non-saturating activation function enabled their
    model to converge much faster.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet的创作者在他们的神经网络中使用了一种非饱和激活函数称为ReLU。我们稍后会在[第2章](ch02.xhtml#ml_models_for_vision)详细讨论神经网络和激活函数；现在，知道使用分段线性非饱和激活函数使他们的模型收敛速度大大加快就足够了。
- en: Regularization
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化
- en: The problem with ReLUs—and the reason they hadn’t been used much until 2012—was
    that, because they didn’t saturate, the neural network’s weights became numerically
    unstable. The authors of AlexNet used a regularization technique to keep the weights
    from becoming too large. We’ll discuss regularization in [Chapter 2](ch02.xhtml#ml_models_for_vision)
    too.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ReLU存在的问题——以及它们直到2012年之前为什么没有被广泛使用的原因——是因为它们不会饱和，神经网络的权重会变得数值不稳定。AlexNet的作者们使用了一种正则化技术来防止权重变得过大。我们在[第2章](ch02.xhtml#ml_models_for_vision)也会讨论正则化技术。
- en: Depth
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 深度
- en: With the ability to train faster, they were able to train a more complex model
    that had more neural network layers. We say a model with more layers is *deeper*;
    the importance of depth will be discussed in [Chapter 3](ch03.xhtml#image_vision).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 有了更快的训练能力，他们能够训练一个更复杂的模型，拥有更多的神经网络层。我们称具有更多层次的模型为*深层*；深度的重要性将在[第3章](ch03.xhtml#image_vision)中讨论。
- en: It is worth recognizing that it was the increased depth of the neural network
    (allowed by the combination of the first three ideas) that made AlexNet world-beating.
    That CNNs could be sped up using GPUs had been proven in [2006](https://oreil.ly/9p3Ba).
    The ReLU activation function itself wasn’t new, and regularization was a well-known
    statistical technique. Ultimately, the model’s exceptional performance was due
    to the authors’ insight that they could combine all of these to train a deeper
    convolutional neural network than had been done before.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，正是神经网络的增加深度（由前三个想法的组合允许）使得AlexNet具有世界领先的性能。证明了可以使用GPU加速CNN的技术在[2006年](https://oreil.ly/9p3Ba)已经成为事实。ReLU激活函数本身并不新鲜，正则化是一种众所周知的统计技术。最终，模型的异常性能归功于作者们的洞察力，他们能够结合所有这些因素训练比以往任何时候都更深的卷积神经网络。
- en: Depth is so important to the resurging interest in neural networks that the
    whole field has come to be referred to as *deep learning*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 深度对神经网络再次引起兴趣如此重要，以至于整个领域被称为*深度学习*。
- en: Deep Learning Use Cases
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习的应用案例
- en: 'Deep learning is a branch of machine learning that uses neural networks with
    many layers. Deep learning outperformed the previously existing methods for computer
    vision, and has now been successfully applied to many other forms of unstructured
    data: video, audio, natural language text, and so on.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个分支，它使用具有多层的神经网络。深度学习在计算机视觉方面超过了先前存在的方法，并且现在已成功应用于许多其他形式的非结构化数据：视频、音频、自然语言文本等。
- en: Deep learning gives us the ability to extract information from images without
    having to create bespoke image processing filters or code up human logic. When
    doing image classification using deep learning, we need hundreds or thousands
    or even millions of images (the more, the better), for which we know the correct
    label (like “tulip” or “daisy”). These labeled images can be used to train an
    image classification deep learning model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习使我们能够从图像中提取信息，而无需创建定制的图像处理滤波器或编写人类逻辑代码。在使用深度学习进行图像分类时，我们需要成百上千甚至数百万张图片（越多越好），其中我们知道正确的标签（如“郁金香”或“雏菊”）。这些带标签的图像可用于训练图像分类深度学习模型。
- en: 'As long as you can formulate a task in terms of learning from data, it is possible
    to use computer vision machine learning methods to address the problem. For example,
    consider the problem of optical character recognition (OCR)—taking a scanned image
    and extracting the text from it. The earliest approaches to OCR involved teaching
    the computer to do pattern matching against what individual letters look like.
    This turns out to be a challenging approach, for various reasons. For example:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 只要能够用数据学习任务，就可以使用计算机视觉机器学习方法来解决问题。例如，考虑光学字符识别（OCR）的问题——从扫描图像中提取文本。最早的OCR方法涉及教导计算机进行模式匹配，匹配各个字母的外观。出于各种原因，这被证明是一种具有挑战性的方法。例如：
- en: There are many fonts, so a single letter can be written in many ways.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有很多字体，所以一个字母可以用多种方式写成。
- en: Letters come in different sizes, so the pattern matching has to be scale-invariant.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字母有不同的大小，因此模式匹配必须是尺度不变的。
- en: Bound books cannot be laid flat, so the scanned letters are distorted.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 装订的书无法平放，因此扫描的字母会失真。
- en: It is not enough to recognize individual letters; we need to extract the entire
    text. The rules of what forms a word, a line, or a paragraph are complex (see
    [Figure 1-4](#optical_character_recognition_based_on_r)).
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 认识到单个字母是不够的；我们需要提取整段文字。构成单词、行或段落的规则是复杂的（见[图 1-4](#optical_character_recognition_based_on_r)）。
- en: '![](Images/pmlc_0104.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0104.png)'
- en: Figure 1-4\. Optical character recognition based on rules requires identifying
    lines, breaking them into words, and then identifying the component letters of
    each word.
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-4\. 基于规则的光学字符识别需要识别行，将其分成单词，然后识别每个单词的组成字母。
- en: On the other hand, with the use of deep learning, OCR can be quite easily formulated
    as an image classification system. There are many books that have already been
    digitized, and it’s possible to train the model by showing it a scanned image
    from a book and using the digitized text as a label.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，利用深度学习，OCR可以很容易地被制定为图像分类系统。已经有许多书籍被数字化，可以通过向模型展示来自书籍的扫描图像并使用数字化的文本作为标签来训练模型。
- en: Computer vision methods provide solutions for a variety of real-world problems.
    Besides OCR, computer vision methods have been successfully applied to medical
    diagnosis (using images such as X-rays and MRIs), automating retail operations
    (such as reading QR codes, recognizing empty shelves, checking the quality of
    vegetables, etc.), surveillance (monitoring crop yield from satellite images,
    monitoring wildlife cameras, intruder detection, etc.), fingerprint recognition,
    and automotive safety (following cars at a safe distance, identifying changes
    in speed limits from road signs, self-parking cars, self-driving cars, etc.).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉方法为各种实际问题提供了解决方案。除了OCR，计算机视觉方法还成功应用于医学诊断（使用图像如X光和MRI）、自动化零售运营（如读取QR码、识别空货架、检查蔬菜质量等）、监视（从卫星图像监测农作物产量、监控野生动物摄像头、入侵者检测等）、指纹识别和汽车安全（保持安全距离跟随车辆、识别道路标志速限变化、自动停车车辆、自动驾驶车辆等）。
- en: Computer vision has found use in many industries. In government, it has been
    used for monitoring satellite images, in building smart cities, and in customs
    and security inspections. In healthcare, it has been used to identify eye disease
    and to find early signs of cancer from mammograms. In agriculture, it has been
    used to spot malfunctioning irrigation pumps, assess crop yields, and identify
    leaf disease. In manufacturing, it finds a use on factory floors for quality control
    and visual inspection. In insurance, it has been used to automatically assess
    damage to vehicles after an accident.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉已经在许多行业中找到了用途。在政府部门中，它已被用于监控卫星图像，建设智能城市，以及海关和安全检查。在医疗领域，它被用来识别眼部疾病，并从乳房X光中发现癌症的早期迹象。在农业中，它被用来检测故障的灌溉泵，评估作物产量，并识别叶片病害。在制造业中，它在工厂生产线上用于质量控制和视觉检查。在保险业中，它被用于事故后自动评估车辆损伤。
- en: Summary
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Computer vision helps computers understand the content of digital images such
    as photographs. Starting with a seminal paper in 2012, deep learning approaches
    to computer vision have become wildly successful. Nowadays, we find successful
    uses of computer vision across a large number of industries.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉帮助计算机理解数字图像（如照片）的内容。从2012年的一篇开创性论文开始，深度学习方法在计算机视觉领域取得了巨大成功。如今，我们在许多行业中发现了计算机视觉的成功应用。
- en: We’ll start our journey in [Chapter 2](ch02.xhtml#ml_models_for_vision) by creating
    our first machine learning models.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第2章](ch02.xhtml#ml_models_for_vision)开始我们的旅程，创建我们的第一个机器学习模型。
- en: ^([1](ch01.xhtml#ch01fn01-marker)) *Top-5 accuracy* means that we consider the
    model to be correct if it returns the correct label for an image within its top
    five results.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.xhtml#ch01fn01-marker)) *Top-5 accuracy* 意味着，如果模型在其前五个结果中返回了正确的图像标签，我们认为该模型是正确的。
