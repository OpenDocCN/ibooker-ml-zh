- en: Chapter 14\. Using TensorFlow Lite in iOS Apps
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二步是将TensorFlow Lite添加到它中去。
- en: '[Chapter 12](ch12.xhtml#an_introduction_to_tensorflow_lite) introduced you
    to TensorFlow Lite and how you can use it to convert your TensorFlow models into
    a power-efficient, compact format that can be used on mobile devices. In [Chapter 13](ch13.xhtml#using_tensorflow_lite_in_android_apps)
    you then explored creating Android apps that use TensorFlow Lite models. In this
    chapter you’ll do the same thing but with iOS, creating a couple of simple apps,
    and seeing how you can do inference on a TensorFlow Lite model using the Swift
    programming language.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '![在Xcode中创建一个新的iOS应用程序](Images/aiml_1401.png)'
- en: You’ll need a Mac if you want to follow along with the examples in this chapter,
    as the development tool to use is Xcode, which is only available on Mac. If you
    don’t have it already, you can install it from the App Store. It will give you
    everything you need, including an iOS Simulator on which you can run iPhone and
    iPod apps without a physical device.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要按照本章的示例进行操作，您需要一台Mac电脑，因为开发工具Xcode仅在Mac上可用。如果您还没有安装它，可以从App Store安装。它将为您提供一切所需，包括iOS模拟器，您可以在其中运行iPhone和iPod应用程序，而无需物理设备。
- en: Creating Your First TensorFlow Lite App with Xcode
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Xcode创建您的第一个TensorFlow Lite应用程序
- en: Once you have Xcode up and running, you can follow the steps outlined in this
    section to create a simple iOS app that incorporates the Y = 2X – 1 model from
    [Chapter 12](ch12.xhtml#an_introduction_to_tensorflow_lite). While it’s an extremely
    simple scenario, and definite overkill for a machine learning app, the skeleton
    structure is the same as that used for more complex apps, and I’ve found it a
    useful way of demonstrating how to use models in an app.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[第12章](ch12.xhtml#an_introduction_to_tensorflow_lite)向您介绍了TensorFlow Lite及如何将TensorFlow模型转换为可在移动设备上使用的高效紧凑格式。在[第13章](ch13.xhtml#using_tensorflow_lite_in_android_apps)中，您将探索创建使用TensorFlow
    Lite模型的Android应用程序。在本章中，您将使用iOS执行相同的操作，创建几个简单的应用程序，并了解如何使用Swift编程语言对TensorFlow
    Lite模型进行推断。'
- en: Step 1\. Create a Basic iOS App
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图14-1。在Xcode中创建一个新的iOS应用程序
- en: Open Xcode and select File → New Project. You’ll be asked to pick the template
    for your new project. Choose Single View App, which is the simplest template ([Figure 14-1](#creating_a_new_ios_application_in_xcode)),
    and click Next.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![选择您的新项目的选项](Images/aiml_1402.png)'
- en: After that you’ll be asked to choose options for your new project, including
    a name for the app. Call it *firstlite*, and make sure that the language is Swift
    and the user interface is Storyboard ([Figure 14-2](#choosing_options_for_your_new_project)).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，您将被要求选择您的新项目的选项，包括应用程序的名称。称其为*firstlite*，确保语言是Swift，用户界面是Storyboard（见[图14-2](#choosing_options_for_your_new_project)）。
- en: '![Creating a new iOS application in Xcode](Images/aiml_1401.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: 要向iOS项目添加依赖项，您可以使用一种称为[CocoaPods](https://cocoapods.org)的技术，这是一个具有数千个库的依赖管理项目，可以轻松集成到您的应用程序中。为此，您需要创建一个称为Podfile的规范文件，其中包含有关您的项目及您想要使用的依赖项的详细信息。这是一个简单的文本文件*Podfile*（无扩展名），您应该将其放在与Xcode为您创建的*firstlite.xcodeproj*文件相同的目录中。其内容如下：
- en: Figure 14-1\. Creating a new iOS application in Xcode
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 打开Xcode并选择文件 → 新建项目。您将被要求选择新项目的模板。选择Single View App，这是最简单的模板（见[图14-1](#creating_a_new_ios_application_in_xcode)），然后点击下一步。
- en: '![Choosing options for your new project](Images/aiml_1402.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: 图14-2。选择您的新项目的选项
- en: Figure 14-2\. Choosing options for your new project
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 第14章。在iOS应用程序中使用TensorFlow Lite
- en: Click Next to create a basic iOS app that will run on an iPhone or iPad simulator.
    The next step is to add TensorFlow Lite to it.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“下一步”以创建一个基本的iOS应用程序，可以在iPhone或iPad模拟器上运行。
- en: Step 2\. Add TensorFlow Lite to Your Project
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤1。创建一个基本的iOS应用程序
- en: 'To add dependencies to an iOS project, you can use a technology called [CocoaPods](https://cocoapods.org),
    a dependency management project with many thousands of libraries that can be easily
    integrated into your app. To do so, you create a specification called a Podfile,
    which contains details about your project and the dependencies you want to use.
    This is a simple text file called *Podfile* (no extension), and you should put
    it in the same directory as the *firstlite.xcodeproj* file that was created for
    you by Xcode. Its contents should be as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤2。将TensorFlow Lite添加到您的项目中
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The important part is the line that reads `pod 'TensorFlowLiteSwift'`, which
    indicates that the TensorFlow Lite Swift libraries need to be added to the project.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 关键部分是这一行 `pod 'TensorFlowLiteSwift'`，表示需要将 TensorFlow Lite Swift 库添加到项目中。
- en: 'Next, using Terminal, change to the directory containing the Podfile and issue
    the following command:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用终端切换到包含 Podfile 的目录，并执行以下命令：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The dependencies will be downloaded and added to your project, stored in a new
    folder called *Pods*. You’ll also have an *.xcworkspace* file added, as shown
    in [Figure 14-3](#your_file_structure_after_running_pod_i). Use this one in the
    future to open your project, and not the *.xcodeproj* file.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖项将被下载并添加到项目中，存储在名为 *Pods* 的新文件夹中。您还将添加一个 *.xcworkspace* 文件，如 [图 14-3](#your_file_structure_after_running_pod_i)
    所示。将来使用这个文件打开项目，而不是 *.xcodeproj* 文件。
- en: '![Your file structure after running pod install](Images/aiml_1403.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![运行 pod install 后的文件结构](Images/aiml_1403.png)'
- en: Figure 14-3\. Your file structure after running pod install
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-3\. 运行 pod install 后的文件结构
- en: You now have a basic iOS app, and you have added the TensorFlow Lite dependencies.
    The next step is to create your user interface.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在拥有一个基本的 iOS 应用程序，并已添加了 TensorFlow Lite 依赖项。下一步是创建用户界面。
- en: Step 3\. Create the User Interface
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 3 步\. 创建用户界面
- en: The Xcode storyboard editor is a visual tool that allows you to create a user
    interface. After opening your workspace, you’ll see a list of source files on
    the left. Select *Main.storyboard*, and using the controls palette, you can drag
    and drop controls onto the view for an iPhone screen ([Figure 14-4](#adding_controls_to_the_storyboard)).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Xcode 故事板编辑器是一个可视化工具，允许您创建用户界面。打开工作区后，您将在左侧看到一列源文件。选择 *Main.storyboard*，并使用控件面板，您可以将控件拖放到
    iPhone 屏幕的视图上（见 [图 14-4](#adding_controls_to_the_storyboard)）。
- en: '![Adding controls to the storyboard](Images/aiml_1404.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![向故事板添加控件](Images/aiml_1404.png)'
- en: Figure 14-4\. Adding controls to the storyboard
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-4\. 向故事板添加控件
- en: If you can’t find the controls palette, you can access it by clicking the +
    at the top right of the screen (highlighted in [Figure 14-4](#adding_controls_to_the_storyboard)).
    Using it, add a Label, and change the text to “Enter a Number.” Then add another
    one with the text “Result goes here.” Add a Button and change its caption to “Go,”
    and finally add a Text Field. Arrange them similarly to what you can see in [Figure 14-4](#adding_controls_to_the_storyboard).
    It doesn’t have to be pretty!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果找不到控件面板，可以通过点击屏幕右上角的 + 号（在 [图 14-4](#adding_controls_to_the_storyboard) 中突出显示）来访问它。使用它，添加一个标签，并将文本更改为“输入数字”。然后再添加一个文本，“结果在这里”。添加一个按钮，并将其标题更改为“Go”，最后添加一个文本字段。将它们排列得与
    [图 14-4](#adding_controls_to_the_storyboard) 中看到的类似即可。它不必漂亮！
- en: Now that the controls are laid out, you want to be able to refer to them in
    code. In storyboard parlance you do this using either *outlets* (when you want
    to address the control to read or set its contents) or *actions* (when you want
    to execute some code when the user interacts with the control).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，控件已布局完成，您希望能够在代码中引用它们。在故事板术语中，您可以使用 *outlets*（当您希望访问控件以读取或设置其内容时）或 *actions*（当您希望在用户与控件交互时执行某些代码时）来实现这一点。
- en: The easiest way to wire this up is to have a split screen, with the storyboard
    on one side and the *ViewController.swift* code that underlies it on the other.
    You can achieve this by selecting the split screen control (highlighted in [Figure 14-5](#splitting_the_screen)),
    clicking on one side and selecting the storyboard, and then clicking on the other
    side and selecting *ViewController.swift*.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的连接方法是将屏幕分成两部分，一边是故事板，另一边是支持其下的 *ViewController.swift* 代码。您可以通过选择分屏控制（在 [图
    14-5](#splitting_the_screen) 中突出显示），点击一侧选择故事板，然后点击另一侧选择 *ViewController.swift*
    来实现这一点。
- en: '![Splitting the screen](Images/aiml_1405.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![分割屏幕](Images/aiml_1405.png)'
- en: Figure 14-5\. Splitting the screen
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-5\. 分割屏幕
- en: Once you’ve done this, you can start creating your outlets and actions by dragging
    and dropping. With this app, the user types a number into the text field, presses
    Go, and then runs inference on the value they typed. The result will be rendered
    in the label that says “Result goes here.”
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，你可以通过拖放开始创建输出口和动作。在这个应用中，用户在文本字段中输入数字，点击 Go，然后对其值进行推断。结果将呈现在标签上，标签上写着“结果在这里”。
- en: This means you’ll need to read or write to two controls, reading the contents
    of the text field to get what the user typed in, and writing the result to the
    “Results goes here” label. Thus, you’ll need two outlets. To create them, hold
    down the Ctrl key and drag the control on the storyboard onto the *ViewController.swift*
    file, dropping it just below the class definition. A pop-up will appear asking
    you to define it ([Figure 14-6](#creating_an_outlet)).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你需要读取或写入两个控件，从文本字段读取用户输入的内容，并将结果写入“结果显示区”标签。因此，你需要两个 outlet。要创建它们，按住 Ctrl
    键，将控件从 storyboard 拖动到 *ViewController.swift* 文件中，并将其放置在类定义的正下方。将会出现一个弹出窗口要求你定义它（[图
    14-6](#creating_an_outlet)）。
- en: '![Creating an outlet](Images/aiml_1406.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![创建一个 outlet](Images/aiml_1406.png)'
- en: Figure 14-6\. Creating an outlet
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-6\. 创建一个 outlet
- en: Ensure the connection type is Outlet, and create an outlet for the text field
    called `txtUserData` and one for the label called `txtResult`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 确保连接类型为 Outlet，并创建一个文本字段的 outlet，名为 `txtUserData`，以及一个标签的 outlet，名为 `txtResult`。
- en: Next, drag the button over to the *ViewController.swift* file. In the pop-up,
    ensure that the connection type is Action and the event type is Touch Up Inside.
    Use this to define an action called `btnGo` ([Figure 14-7](#adding_an_action_)).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将按钮拖到 *ViewController.swift* 文件中。在弹出窗口中，确保连接类型为 Action，事件类型为 Touch Up Inside。使用此操作定义一个名为
    `btnGo` 的 action（[图 14-7](#adding_an_action_)）。
- en: '![Adding an action ](Images/aiml_1407.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![添加一个 action](Images/aiml_1407.png)'
- en: Figure 14-7\. Adding an action
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-7\. 添加一个 action
- en: 'At this point your *ViewController.swift* file should look like this—note the
    `IBOutlet` and `IBAction` code:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此时你的 *ViewController.swift* 文件应该看起来像这样—注意 `IBOutlet` 和 `IBAction` 的代码：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now that the UI is squared away, the next step will be to create the code that
    will handle the inference. Instead of having this in the same Swift file as the
    `ViewController` logic, you’ll place it in a separate code file.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 UI 部分已经准备好，接下来的步骤将是创建处理推理的代码。不将其放在与 `ViewController` 逻辑相同的 Swift 文件中，而是放在一个单独的代码文件中。
- en: Step 4\. Add and Initialize the Model Inference Class
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 4\. 添加并初始化模型推理类
- en: To keep the UI separate from the underlying model inference, you’ll create a
    new Swift file containing a `ModelParser` class. This is where all the work of
    getting the data into the model, running the inference, and then parsing the results
    will happen. In Xcode, choose File → New File and select Swift File as the template
    type ([Figure 14-8](#adding_a_new_swift_file)).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将 UI 与底层模型推理分离，你将创建一个新的 Swift 文件，其中包含一个名为 `ModelParser` 的类。这里将完成将数据输入模型、运行推理，然后解析结果的所有工作。在
    Xcode 中，选择文件 → 新建文件，并选择 Swift 文件作为模板类型（[图 14-8](#adding_a_new_swift_file)）。
- en: '![Adding a new Swift file](Images/aiml_1408.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![添加一个新的 Swift 文件](Images/aiml_1408.png)'
- en: Figure 14-8\. Adding a new Swift file
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-8\. 添加一个新的 Swift 文件
- en: Call this *ModelParser*, and ensure that the checkbox targeting it to the firstlite
    project is checked ([Figure 14-9](#adding_modelparserdotswift_to_your_proj)).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 将其命名为 *ModelParser*，确保选中将其定向到 firstlite 项目的复选框（[图 14-9](#adding_modelparserdotswift_to_your_proj)）。
- en: '![Adding ModelParser.swift to your project](Images/aiml_1409.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![将 ModelParser.swift 添加到你的项目中](Images/aiml_1409.png)'
- en: Figure 14-9\. Adding ModelParser.swift to your project
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-9\. 将 ModelParser.swift 添加到你的项目中
- en: 'This will add a *ModelParser.swift* file to your project that you can edit
    to add the inference logic. First, ensure that the imports at the top of the file
    include `TensorFlowLite`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在你的项目中添加一个 *ModelParser.swift* 文件，你可以编辑它以添加推理逻辑。首先确保文件顶部的导入包括 `TensorFlowLite`：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You’ll pass a reference to the model file, *model.tflite*, to this class—you
    haven’t added it yet, but you will soon:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型文件的引用传递给这个类，*model.tflite*，你还没有添加它，但很快会添加：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This `typealias` and `enum` make the code a little more compact. You’ll see
    them in use in a moment. Next you’ll need to load the model into an interpreter,
    so first declare the interpreter as a private variable to the class:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此 `typealias` 和 `enum` 使得代码更加紧凑。稍后你将看到它们的使用。接下来，你需要将模型加载到解释器中，因此首先将解释器声明为类的私有变量：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Swift requires variables to be initialized, which you can do within an `init`
    function. The following function will take two input parameters. The first, `modelFileInfo`,
    is the `FileInfo` type you just declared. The second, `threadCount`, is the number
    of threads to use to initialize the interpreter, which we’ll set to `1`. Within
    this function you’ll create a reference to the model file that you described earlier
    (*model.tflite*):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Swift要求变量进行初始化，您可以在`init`函数中完成此操作。下面的函数将接受两个输入参数。第一个是您刚刚声明的`FileInfo`类型的`modelFileInfo`。第二个是要用于初始化解释器的线程数`threadCount`，我们将其设置为`1`。在此函数中，您将创建对先前描述的模型文件的引用（*model.tflite*）：
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once you have the path to the model file in the bundle, you can load it:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获取了捆绑中模型文件的路径，即可加载它：
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Step 5\. Perform the Inference
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5步。执行推断
- en: Within the `ModelParser` class, you can then do the inference. The user will
    type a string value in the text field, which will be converted to a float, so
    you’ll need a function that takes a float, passes it to the model, runs the inference,
    and parses the return value.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ModelParser`类中，您可以进行推断。用户将在文本字段中键入一个字符串值，该值将转换为浮点数，因此您需要一个函数，接受一个浮点数，将其传递给模型，运行推断并解析返回值。
- en: 'Start by creating a function called `runModel`. Your code will need to catch
    errors, so start it with a `do{`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先创建一个名为`runModel`的函数。您的代码需要捕获错误，因此以`do{`开头：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, you’ll need to allocate tensors on the interpreter. This initializes
    it and readies it for inference:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要在解释器上分配张量。这将初始化并准备好进行推断：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then you’ll create the input tensor. As Swift doesn’t have a `Tensor` data
    type, you’ll need to write the data directly to memory in an `UnsafeMutableBufferPointer`.
    You can specify the type of this, which will be `Float`, and write one value (as
    you only have one float), starting from the address of the variable called `data`.
    This will effectively copy all the bytes for the float into the buffer:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您将创建输入张量。由于Swift没有`Tensor`数据类型，您需要直接将数据写入`UnsafeMutableBufferPointer`中的内存。您可以指定其类型为`Float`，并写入一个值（因为只有一个浮点数），从名为`data`的变量的地址开始。这将有效地将浮点数的所有字节复制到缓冲区中：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'With the data in the buffer, you can then copy it to the interpreter at input
    0\. You only have one input tensor, so you can specify it as the buffer:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 有了缓冲区中的数据，您可以将其复制到输入0处的解释器中。因为只有一个输入张量，所以可以将其指定为缓冲区：
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To execute the inference, you invoke the interpreter:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行推断，您需要调用解释器：
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'There’s only one output tensor, so you can read it by taking the output at
    0:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 只有一个输出张量，因此可以通过获取索引为0的输出来读取它：
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Similar to when inputting the values, you’re dealing with low-level memory,
    which is unsafe data. It’s in an array of `Float32` values (it only has one element
    but still needs to be treated as an array), which can be read like this:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于输入值时处理低级内存，这是不安全的数据。它是由`Float32`值的数组组成（虽然只有一个元素，但仍需视为数组），可以像这样读取它：
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: If you’re not familiar with the `??` syntax, this says to make the results an
    array of `Float32` by copying the output tensor into it, and if that fails, to
    make it an empty array. For this code to work, you’ll need to implement an `Array`
    extension; the full code for that will be shown in a moment.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不熟悉`??`语法，这意味着将输出张量复制到`Float32`数组中，并在失败时使其成为空数组。为使此代码正常工作，您需要实现一个`Array`扩展；稍后将显示其完整代码。
- en: 'Once you have the results in an array, the first element will be your result.
    If this fails, just return `nil`:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦将结果放入数组中，第一个元素将是您的结果。如果失败，只需返回`nil`：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The function began with a `do{`, so you’ll need to catch any errors, print
    them, and return `nil` in that event:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 函数以`do{`开头，因此您需要捕获任何错误，将其打印出来，并在这种情况下返回`nil`：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Finally, still in *ModelParser.swift*, you can add the `Array` extension that
    handles the unsafe data and loads it into an array:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在*ModelParser.swift*中，您可以添加处理不安全数据并将其加载到数组中的`Array`扩展：
- en: '[PRE17]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This is a handy helper that you can use if you want to parse floats directly
    out of a TensorFlow Lite model.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想直接从TensorFlow Lite模型中解析浮点数，这是一个方便的帮助器。
- en: Now that the class for parsing the model is done, the next step is to add the
    model to your app.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，解析模型的类已经完成，下一步是将模型添加到您的应用程序中。
- en: Step 6\. Add the Model to Your App
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第6步。将模型添加到您的应用程序中
- en: To add the model to your app, you’ll need a *models* directory within the app.
    In Xcode, right-click on the *firstlite* folder and select New Group ([Figure 14-10](#adding_a_new_group_to_your_app)).
    Call the new group *models*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要将模型添加到应用程序中，您需要在应用程序中创建一个*models*目录。在 Xcode 中，右键单击*firstlite*文件夹，选择新建组（[图 14-10](#adding_a_new_group_to_your_app)）。将新组命名为*models*。
- en: '![Adding a new group to your app](Images/aiml_1410.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![向您的应用程序添加新组](Images/aiml_1410.png)'
- en: Figure 14-10\. Adding a new group to your app
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-10\. 向应用程序添加新组
- en: You can get the model by training the simple Y = 2X – 1 sample from [Chapter 12](ch12.xhtml#an_introduction_to_tensorflow_lite).
    If you don’t have it already, you can use the Colab in the book’s [GitHub repository](https://oreil.ly/AQgL_).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过训练来自[第 12 章](ch12.xhtml#an_introduction_to_tensorflow_lite)的简单 Y = 2X -
    1 示例来获取模型。如果您尚未拥有它，可以使用该书的 GitHub 仓库中的 Colab。
- en: Once you have the converted model file (called *model.tflite*), you can drag
    and drop it into Xcode on the models group you just added. Select “Copy items
    if needed” and ensure you add it to the target firstlite by checking the box beside
    it ([Figure 14-11](#adding_the_model_to_your_project)).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您转换了模型文件（名为*model.tflite*），您可以将其拖放到刚刚添加的模型组中。选择“需要时复制项目”，并确保将其添加到目标*firstlite*中，勾选其旁边的框（[图
    14-11](#adding_the_model_to_your_project)）。
- en: '![Adding the model to your project](Images/aiml_1411.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![将模型添加到您的项目中](Images/aiml_1411.png)'
- en: Figure 14-11\. Adding the model to your project
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-11\. 将模型添加到您的项目中
- en: The model will now be in your project and available for inference. The final
    step is to complete the user interface logic—then you’ll be ready to go!
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 模型现在将会在您的项目中，并可用于推断。最后一步是完成用户界面逻辑——然后您就可以开始了！
- en: Step 7\. Add the UI Logic
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 7\. 添加 UI 逻辑
- en: Earlier, you created the storyboard containing the UI description and began
    editing the *ViewController.swift* file containing the UI logic. As most of the
    work of inference has now been offloaded to the `ModelParser` class, the UI logic
    should be very light.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，您创建了包含 UI 描述的 storyboard，并开始编辑包含 UI 逻辑的*ViewController.swift*文件。由于推断的大部分工作现在已经被转移到`ModelParser`类中，因此
    UI 逻辑应该非常轻量级。
- en: 'Start by adding a private variable declaring an instance of the `ModelParser`
    class:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过添加一个私有变量来声明`ModelParser`类的实例：
- en: '[PRE18]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Previously, you created an action on the button called `btnGo`. This will be
    called when the user touches the button. Update that to execute a function called
    `doInference` when the user takes that action:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，您在名为`btnGo`的按钮上创建了一个动作。当用户触摸该按钮时，将更新为执行名为`doInference`的函数：
- en: '[PRE19]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next you’ll construct the `doInference` function:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将构建`doInference`函数：
- en: '[PRE20]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The text field that the user will enter data into is called `txtUserData`.
    Read this value, and if it’s empty just set the result to `0.00` and don’t bother
    with any inference:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 用户将输入数据的文本字段称为`txtUserData`。读取此值，如果为空，则将结果设置为`0.00`，并且不进行任何推断操作：
- en: '[PRE21]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Otherwise, convert it to a float. If this fails, exit the function:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，请将其转换为浮点数。如果转换失败，请退出该函数：
- en: '[PRE22]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If the code has reached this point, you can now run the model, passing it that
    input. The `ModelParser` will do the rest, returning you either a result or `nil`.
    If the return value is `nil`, then you’ll exit the function:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果代码已经到达这一点，现在可以运行模型，将输入传递给它。`ModelParser`将会做剩下的工作，并返回一个结果或`nil`。如果返回值为`nil`，则将退出该函数：
- en: '[PRE23]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, if you’ve reached this point, you have a result, so you can load it
    into the label (called `txtResult`) by formatting the float as a string:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您已经到达这一步，那么您就有了一个结果，因此可以通过将浮点数格式化为字符串加载到标签（称为`txtResult`）中：
- en: '[PRE24]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'That’s it! The complexity of the model loading and inference has been handled
    by the `ModelParser` class, keeping your `ViewController` very light. For convenience,
    here’s the complete listing:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！模型加载和推断的复杂性由`ModelParser`类处理，使得您的`ViewController`非常轻量级。为方便起见，这里是完整的清单：
- en: '[PRE25]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: You’ve now done everything you need to get the app working. Run it, and you
    should see it in the simulator. Type a number in the text field, press the button,
    and you should see a result in the results field, as shown in [Figure 14-12](#running_the_app_in_the_iphone_simulator).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已经完成了使应用程序工作所需的所有操作。运行它，您应该在模拟器中看到它。在文本字段中输入一个数字，按下按钮，您应该在结果字段中看到一个结果，如[图
    14-12](#running_the_app_in_the_iphone_simulator)所示。
- en: '![Running the app in the iPhone Simulator](Images/aiml_1412.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![在 iPhone 模拟器中运行应用程序](Images/aiml_1412.png)'
- en: Figure 14-12\. Running the app in the iPhone Simulator
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14-12\. 在 iPhone 模拟器中运行应用程序
- en: 'While this was a long journey for a very simple app, it should provide a good
    template to help you understand how TensorFlow Lite works. In this walkthrough
    you saw how to:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这对于一个非常简单的应用程序来说是一个漫长的旅程，但它应该提供了一个很好的模板，帮助您理解 TensorFlow Lite 的工作原理。在本教程中，您看到了如何：
- en: Use pods to add the TensorFlow Lite dependencies.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 pods 添加 TensorFlow Lite 依赖项。
- en: Add a TensorFlow Lite model to your app.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向您的应用程序添加 TensorFlow Lite 模型。
- en: Load the model into an interpreter.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型加载到解释器中。
- en: Access the input tensors, and write directly to their memory.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问输入张量，并直接将其写入内存。
- en: Read the memory from the output tensors and copy that to high-level data structures
    like float arrays.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从输出张量中读取内存，并将其复制到像浮点数组这样的高级数据结构中。
- en: Wire it all up to a user interface with a storyboard and view controller.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 storyboard 和视图控制器将所有内容连接到用户界面。
- en: In the next section, you’ll move beyond this simple scenario and look at handling
    more complex data.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将超越这个简单的场景，看看如何处理更复杂的数据。
- en: Moving Beyond “Hello World”—Processing Images
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越“Hello World”—处理图像
- en: In the previous example you saw how to create a full app that uses TensorFlow
    Lite to do very simple inference. However, despite the simplicity of the app,
    the process of getting data into the model and parsing data out of the model can
    be a little unintuitive because you’re handling low-level bits and bytes. As you
    get into more complex scenarios, such as managing images, the good news is that
    the process isn’t that much more complicated.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，您看到了如何创建一个完整的应用程序，使用 TensorFlow Lite 进行非常简单的推断。但是，尽管应用程序很简单，将数据输入模型并解析模型输出的过程可能有点不直观，因为您在处理低级的位和字节。随着您涉及更复杂的情况，如管理图像，好消息是这个过程并不会变得太复杂。
- en: Consider the Dogs vs. Cats model you created in [Chapter 12](ch12.xhtml#an_introduction_to_tensorflow_lite).
    In this section you’ll see how to create an iOS app in Swift with a trained model
    that, given an image of a cat or a dog, will be able to infer what is in the picture.
    The full app code is available in the [GitHub repo](https://github.com/lmoroney/tfbook)
    for this book.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑您在[第 12 章](ch12.xhtml#an_introduction_to_tensorflow_lite)中创建的 Dogs vs. Cats
    模型。在本节中，您将看到如何使用训练有素的模型创建一个 Swift iOS 应用程序，该应用程序可以根据猫或狗的图像推断出图像中的内容。该书的完整应用代码可以在
    [GitHub 仓库](https://github.com/lmoroney/tfbook) 中找到。
- en: 'First, recall that the tensor for an image has three dimensions: width, height,
    and color depth. So, for example, when using the MobileNet architecture that the
    Dogs vs. Cats mobile sample is based on, the dimensions are 224 × 224 × 3—each
    image is 224 × 224 pixels and has 3 bytes for color depth. Note that each pixel
    is represented by a value between 0 and 1 indicating the intensity of that pixel
    on the red, green, and blue channels.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，回想一下图像的张量有三个维度：宽度、高度和颜色深度。例如，当使用基于 Dogs vs. Cats 移动样本的 MobileNet 架构时，尺寸为
    224 × 224 × 3 ——每个图像为 224 × 224 像素，并且颜色深度为 3 字节。请注意，每个像素由介于 0 和 1 之间的值表示，指示该像素在红色、绿色和蓝色通道上的强度。
- en: In iOS, images are typically represented as instances of the `UIImage` class,
    which has a useful `pixelBuffer` property that returns a buffer of all the pixels
    in the image.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在 iOS 中，图像通常表示为 `UIImage` 类的实例，该类具有一个有用的 `pixelBuffer` 属性，返回图像中所有像素的缓冲区。
- en: 'Within the `CoreImage` libraries, there’s a `CVPixelBufferGetPixelFormatType`
    API that will return the type of the pixel buffer:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `CoreImage` 库中，有一个 `CVPixelBufferGetPixelFormatType` API，可以返回像素缓冲区的类型：
- en: '[PRE26]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This will typically be a 32-bit image with channels for alpha (aka transparency),
    red, green, and blue. However, there are multiple variants, generally with these
    channels in different orders. You’ll want to ensure that it’s one of these formats,
    as the rest of the code won’t work if the image is stored in a different format:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是一个带有 alpha（即透明度）、红色、绿色和蓝色通道的 32 位图像。但是，有多种变体，通常这些通道的顺序不同。您需要确保它是这些格式之一，否则如果图像存储在不同的格式中，则其余代码将无法工作：
- en: '[PRE27]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'As the desired format is 224 × 224, which is square, the best thing to do next
    is to crop the image to the largest square in its center, using the `centerThumbnail`
    property, and then scale this down to 224 × 224:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 因为期望的格式是 224 × 224，即正方形，下一步最好的做法是裁剪图像到其中心的最大正方形，使用 `centerThumbnail` 属性，然后将其缩小到
    224 × 224：
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Now that you have the image resized to 224 × 224, the next step is to remove
    the alpha channel. Remember that the model was trained on 224 × 224 × 3, where
    the 3 is the RGB channels, so there is no alpha.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已将图像调整大小为 224 × 224，下一步是删除 alpha 通道。请记住，该模型是在 224 × 224 × 3 上训练的，其中 3 是 RGB
    通道，因此没有 alpha 通道。
- en: 'Now that you have a pixel buffer, you need to extract the RGB data from it.
    This helper function achieves that for you by finding the alpha channel and slicing
    it out:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了一个像素缓冲区，需要从中提取RGB数据。这个辅助函数通过查找alpha通道并切片来帮助你实现这一点：
- en: '[PRE29]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This code uses an extension called `Data` that copies the raw bytes into an
    array:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码使用名为`Data`的扩展，将原始字节复制到数组中：
- en: '[PRE30]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now you can pass the thumbnail pixel buffer you just created to `rgbDataFromBuffer`:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以将刚刚创建的缩略图像素缓冲区传递给`rgbDataFromBuffer`：
- en: '[PRE31]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'At this point you have the raw RGB data that is in the format the model expects,
    and you can copy it directly to the input tensor:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了模型期望格式的原始RGB数据，你可以直接复制到输入张量中：
- en: '[PRE32]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You can then invoke the interpreter and read the output tensor:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以调用解释器并读取输出张量：
- en: '[PRE33]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In the case of Dogs vs. Cats, you have as output a float array with two values,
    the first being the probability that the image is of a cat and the second that
    it’s a dog. This is the same results code as you saw earlier, and it uses the
    same `Array` extension from the previous example:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在狗与猫的情况下，输出是一个包含两个值的浮点数组，第一个值表示图像是猫的概率，第二个值表示图像是狗的概率。这与之前看到的结果代码相同，并使用了上一个示例中的相同`Array`扩展：
- en: '[PRE34]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: As you can see, although this is a more complex example, the same design pattern
    holds. You must understand your model’s architecture, and the raw input and output
    formats. You must then structure your input data in the way the model expects—which
    often means getting down to raw bytes that you write into a buffer, or at least
    simulate using an array. You then have to read the raw stream of bytes coming
    out of the model and create a data structure to hold them. From the output perspective
    this will almost always be something like we’ve seen in this chapter—an array
    of floats. With the helper code you’ve implemented, you’re most of the way there!
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，尽管这是一个更复杂的示例，但相同的设计模式仍然适用。你必须了解模型的架构，以及原始输入和输出格式。然后，你必须按照模型期望的方式结构化输入数据，通常意味着获取写入缓冲区的原始字节，或者至少模拟使用数组。接着，你必须读取模型输出的原始字节流，并创建一个数据结构来保存它们。从输出的角度来看，这几乎总是类似于本章中看到的一样——一个浮点数数组。有了你实现的辅助代码，你已经完成了大部分工作！
- en: TensorFlow Lite Sample Apps
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow Lite示例应用
- en: 'The TensorFlow team has built a large set of sample apps and is constantly
    adding to it. Armed with what you’ve learned in this chapter, you’ll be able to
    explore these and understand their input/output logic. At the time of writing,
    for iOS there are sample apps for:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow团队已经构建了大量的示例应用，并不断增加。掌握本章学到的知识，你将能够探索这些应用并理解它们的输入/输出逻辑。截至撰写本文时，iOS平台上有以下示例应用：
- en: Image classification
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类
- en: Read the device’s camera and classify up to a thousand different items.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 读取设备的摄像头，并对多达一千种不同物品进行分类。
- en: Object detection
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 物体检测
- en: Read the device’s camera and give bounding boxes to objects that are detected.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 读取设备的摄像头，并为检测到的物体提供边界框。
- en: Pose estimation
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 姿势估计
- en: Take a look at the figures in the camera and infer their poses.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 查看摄像头中的图像，并推断它们的姿势。
- en: Speech recognition
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 语音识别
- en: Recognize common verbal commands.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 识别常见的口头命令。
- en: Gesture recognition
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 手势识别
- en: Train a model for hand gestures and recognize them in the camera.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为手势训练一个模型，并在摄像头中识别它们。
- en: Image segmentation
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分割
- en: Similar to object detection, but predict which class each pixel in an image
    belongs to.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于物体检测，但预测图像中每个像素属于哪个类别。
- en: Digit classifier
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 数字分类器
- en: Recognize handwritten digits.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 识别手写数字。
- en: Summary
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter you learned how to incorporate TensorFlow Lite into iOS apps
    by taking a comprehensive walkthrough of building a simple app that used the interpreter
    to invoke a model to perform inference. In particular, you saw how when dealing
    with models you have to get low-level with the data, ensuring that your input
    matches what the model expects. You also saw how to parse the raw data that comes
    out of the model. This is just the beginning of a long and fun journey toward
    putting machine learning into the hands of iOS users. In the next chapter we’ll
    move away from native mobile development to look at how TensorFlow.js can be used
    to train and run inference on models in the browser.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了如何将TensorFlow Lite整合到iOS应用程序中，通过全面的步骤演示构建一个简单应用程序，使用解释器调用模型进行推理。特别是，您看到处理模型时必须对数据进行低级处理，确保您的输入与模型预期的匹配。您还看到了如何解析模型输出的原始数据。这只是将机器学习引入iOS用户手中的长期而有趣的旅程的开端。在下一章中，我们将摆脱原生移动开发，看看如何使用TensorFlow.js在浏览器上训练和运行模型推理。
