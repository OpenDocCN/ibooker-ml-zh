- en: Appendix B. Setting Up a Kubernetes Cluster on Google Cloud
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 附录 B. 在 Google Cloud 上设置 Kubernetes 集群
- en: This appendix provides a brief overview of how to create a Kubernetes cluster
    on Google Cloud that can run our example project. If Kubernetes is new to you,
    take a look at [Appendix A](index_split_023.html#filepos1605424) and our suggested
    reading at the end of [Chapter 9](index_split_016.html#filepos996706). While the
    exact commands we will cover only apply to Google Cloud, the overall setup process
    is the same with other managed Kubernetes services like AWS EKS or Microsoft Azure’s
    AKS.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本附录简要介绍了如何在 Google Cloud 上创建一个能够运行我们示例项目的 Kubernetes 集群。如果您对 Kubernetes 还不熟悉，请查看[附录
    A](index_split_023.html#filepos1605424)以及我们在[第 9 章](index_split_016.html#filepos996706)末尾推荐的阅读内容。虽然我们将涵盖的确切命令仅适用于
    Google Cloud，但是与其他托管 Kubernetes 服务如 AWS EKS 或 Microsoft Azure 的 AKS 相比，整体设置流程是相同的。
- en: Before You Get Started
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前
- en: For the following installation steps, we assume you have an account with Google
    Cloud. If you don’t have an account, you can [create one](https://oreil.ly/TFM-4).
    Furthermore, we assume that you have installed Kubernetes `kubectl` (client version
    1.18.2 or higher) on your local computer and that you can also execute Google
    Cloud’s SDK `gcloud` (version 289.0.0 or higher).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 对于接下来的安装步骤，我们假设您已经拥有 Google Cloud 的账户。如果您没有账户，您可以[创建一个](https://oreil.ly/TFM-4)。此外，我们假设您已经在本地计算机上安装了
    Kubernetes `kubectl`（客户端版本 1.18.2 或更高版本），并且您也可以执行 Google Cloud 的 SDK `gcloud`（版本
    289.0.0 或更高版本）。
- en: WATCH YOUR CLOUD INFRASTRUCTURE COSTS
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意您的云基础设施成本
- en: Operating Kubernetes clusters can accumulate significant infrastructure costs.
    Therefore, we highly recommend to watch your infrastructure costs by setting billing
    alerts and budgets. Details can be found in the [Google Cloud documentation](https://oreil.ly/ubjAa).
    We also recommend turning off idling compute instances because they accrue costs
    even if they are idling and no pipeline task is being computed.
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 经营 Kubernetes 集群可能会累积显著的基础设施成本。因此，我们强烈建议通过设置账单警报和预算来监控您的基础设施成本。详情请参阅[Google
    Cloud 文档](https://oreil.ly/ubjAa)。我们还建议关闭空闲的计算实例，因为它们即使处于空闲状态并且没有在计算管道任务时也会产生成本。
- en: Steps on how to install a `kubectl` client for your operating system can be
    found as part of the [Kubernetes documentation](https://oreil.ly/syf_v). The [Google
    Cloud documentation](https://oreil.ly/ZmhG5) provides step-by-step details on
    how to install their client for your operating system.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如何为您的操作系统安装 `kubectl` 客户端的详细步骤可以在[Kubernetes 文档](https://oreil.ly/syf_v)中找到。[Google
    Cloud 文档](https://oreil.ly/ZmhG5)提供了如何为您的操作系统安装他们的客户端的逐步详细说明。
- en: Kubernetes on Google Cloud
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 在 Google Cloud 上
- en: In the following five sections, we take you through the step-by-step process
    of creating a Kubernetes cluster from scratch with Google Cloud.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的五个部分中，我们将逐步介绍如何使用 Google Cloud 从头开始创建 Kubernetes 集群的过程。
- en: Selecting a Google Cloud Project
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 Google Cloud 项目
- en: For the Kubernetes cluster, we need to create a new Google Cloud project or
    select an existing project in the [Google Cloud Project dashboard](https://oreil.ly/LQS99).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Kubernetes 集群，我们需要在[Google Cloud 项目仪表板](https://oreil.ly/LQS99)中创建一个新的 Google
    Cloud 项目或选择一个现有项目。
- en: Please note the project ID for the following steps. We will deploy our cluster
    in the project with the ID `oreilly-book`, as shown in [Figure B-1](#filepos1658080).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意接下来的步骤需要项目 ID。我们将在名为`oreilly-book`的项目中部署我们的集群，如[图 B-1](#filepos1658080)所示。
- en: '![](images/00015.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00015.jpg)'
- en: Figure B-1\. Google Cloud Project dashboard
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B-1\. Google Cloud 项目仪表板
- en: Setting Up Your Google Cloud Project
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 设置您的 Google Cloud 项目
- en: 'Before creating a Kubernetes cluster, let’s set up your Google Cloud project.
    In the terminal of your operating system, you can authenticate your Google Cloud
    SDK client with:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建 Kubernetes 集群之前，让我们设置您的 Google Cloud 项目。在您操作系统的终端中，您可以通过以下命令对您的 Google Cloud
    SDK 客户端进行身份验证：
- en: '`$` `gcloud auth login`'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `gcloud auth login`'
- en: 'Then update the SDK client with:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然后更新 SDK 客户端：
- en: '`$` `gcloud components update`'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `gcloud components update`'
- en: After you have successfully authenticated and updated the SDK client, let’s
    configure a few basics. First, we’ll set the GCP project as the default project
    and pick a compute zone as a default zone. In our example, we have chosen `us-central-1`.
    You can find a list of all available zones in the [Google Cloud documentation](https://oreil.ly/5beJg).
    Pick a zone either closest to your physical location or where the required Google
    Cloud services are available (not all services are available in all zones).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '在成功进行身份验证并更新 SDK 客户端之后，让我们配置一些基础设置。首先，我们将把 GCP 项目设置为默认项目，并选择一个计算区域作为默认区域。在我们的示例中，我们选择了
    `us-central-1`。您可以在[Google Cloud 文档](https://oreil.ly/5beJg)中找到所有可用区域的列表。选择一个最接近您物理位置或所需的
    Google Cloud 服务可用的区域（并非所有服务在所有区域都可用）。 '
- en: 'By setting these default values, we don’t have to specify them later on in
    following commands. We also will request to enable Google Cloud’s container APIs.
    The last step is only needed once per project:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通过设置这些默认值，我们在后续命令中无需再指定它们。我们还将请求启用 Google Cloud 的容器 API。此最后一步仅需每个项目执行一次：
- en: '`$` `export` `PROJECT_ID``=``<``your gcp project id``>` ![](images/00002.jpg)`$`
    `export` `GCP_REGION``=``us-central1-c` ![](images/00075.jpg)`$` `gcloud config`
    `set` `project` `$PROJECT_ID``$` `gcloud config` `set` `compute/zone` `$GCP_REGION``$`
    `gcloud services` `enable` `container.googleapis.com` ![](images/00064.jpg)'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `export` `PROJECT_ID``=``<``your gcp project id``>` ![](images/00002.jpg)`$`
    `export` `GCP_REGION``=``us-central1-c` ![](images/00075.jpg)`$` `gcloud config`
    `set` `project` `$PROJECT_ID``$` `gcloud config` `set` `compute/zone` `$GCP_REGION``$`
    `gcloud services` `enable` `container.googleapis.com` ![](images/00064.jpg)'
- en: '![](images/00002.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00002.jpg)'
- en: Replace with the project ID from the previous step.
  id: totrans-23
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用前一步骤中的项目 ID 替换。
- en: '![](images/00075.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00075.jpg)'
- en: Select your preferred zone or region.
  id: totrans-25
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 选择您偏好的区域或地域。
- en: '![](images/00064.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00064.jpg)'
- en: Enable APIs.
  id: totrans-27
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 启用 API。
- en: Creating a Kubernetes Cluster
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 Kubernetes 集群
- en: 'With our Google Cloud project ready to go, we can now create a Kubernetes cluster
    with a number of compute nodes as part of the cluster. In our example cluster
    called `kfp-oreilly-book`, we allow the cluster to run between zero and five nodes
    at any point in time in our pool called `kfp-pool`, and the desired number of
    available nodes is three. We also assign a service account to the cluster. Through
    the service account, we can control access permissions for requests from the cluster
    nodes. To learn more about service accounts at Google Cloud, we recommend the
    [online documentation](https://oreil.ly/7Ar4X):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 Google Cloud 项目准备就绪后，现在可以创建一个 Kubernetes 集群，该集群包含一些计算节点作为集群的一部分。在我们的示例集群
    `kfp-oreilly-book` 中，我们允许集群在名为 `kfp-pool` 的池中的任意时间点运行零到五个节点，并且期望的可用节点数量为三个。我们还为集群分配了一个服务账号。通过服务账号，我们可以控制来自集群节点的请求的访问权限。要了解更多有关
    Google Cloud 服务账号的信息，请查看[在线文档](https://oreil.ly/7Ar4X)：
- en: '`$` `export` `CLUSTER_NAME``=``kfp-oreilly-book` `$` `export` `POOL_NAME``=``kfp-pool`
    `$` `export` `MAX_NODES``=``5` `$` `export` `NUM_NODES``=``3` `$` `export` `MIN_NODES``=``0`
    `$` `export` `SERVICE_ACCOUNT``=``service-account@oreilly-book.iam.gserviceaccount.com`'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `export` `CLUSTER_NAME``=``kfp-oreilly-book` `$` `export` `POOL_NAME``=``kfp-pool`
    `$` `export` `MAX_NODES``=``5` `$` `export` `NUM_NODES``=``3` `$` `export` `MIN_NODES``=``0`
    `$` `export` `SERVICE_ACCOUNT``=``service-account@oreilly-book.iam.gserviceaccount.com`'
- en: 'With the cluster parameters now defined in an environment variable, we can
    execute the following command:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在环境变量中定义了集群参数，我们可以执行以下命令：
- en: '`$` `gcloud container clusters create` `$CLUSTER_NAME``\` `--zone` `$GCP_REGION``\`
    `--machine-type n1-standard-4` `\` `--enable-autoscaling` `\` `--min-nodes``=``$MIN_NODES``\`
    `--num-nodes``=``$NUM_NODES``\` `--max-nodes``=``$MAX_NODES``\` `--service-account``=``$SERVICE_ACCOUNT`'
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `gcloud container clusters create` `$CLUSTER_NAME``\` `--zone` `$GCP_REGION``\`
    `--machine-type n1-standard-4` `\` `--enable-autoscaling` `\` `--min-nodes``=``$MIN_NODES``\`
    `--num-nodes``=``$NUM_NODES``\` `--max-nodes``=``$MAX_NODES``\` `--service-account``=``$SERVICE_ACCOUNT`'
- en: 'For our demo pipeline, we selected the instance type `n1-standard-4`, which
    provides 4 CPUs and 15 GB of memory per node. These instances provide enough compute
    resources to train and evaluate our machine learning model and its datasets. You
    can find a complete list of available instance types by running the following
    SDK command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的演示流水线，我们选择了实例类型 `n1-standard-4`，每个节点提供 4 个 CPU 和 15 GB 内存。这些实例提供足够的计算资源来训练和评估我们的机器学习模型及其数据集。您可以通过运行以下
    SDK 命令找到所有可用实例类型的完整列表：
- en: '`$` `gcloud compute machine-types list`'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `gcloud compute machine-types list`'
- en: 'If you would like to add a GPU to the cluster, you can specify the GPU type
    and the number of GPUs by adding the `accelerator` argument, as shown in the following
    example:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在集群中添加 GPU，你可以通过添加 `accelerator` 参数来指定 GPU 类型和数量，如下例所示：
- en: '`$` `gcloud container clusters create` `$CLUSTER_NAME``\` `...       --accelerator``=``type``=``nvidia-tesla-v100,count``=``1`'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `gcloud container clusters create` `$CLUSTER_NAME``\` `...       --accelerator``=``type``=``nvidia-tesla-v100,count``=``1`'
- en: The creation of the Kubernetes cluster can take a few minutes until all the
    resources are fully assigned to your project and available. The time depends on
    your requested resources and the number of nodes. For our demo cluster, you can
    expect to wait approximately 5 minutes until all the resources are available.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 Kubernetes 集群可能需要几分钟，直到所有资源完全分配给你的项目并可用为止。这个时间取决于你请求的资源和节点数。对于我们的演示集群，你可以期待等待约5分钟，直到所有资源都可用。
- en: Accessing Your Kubernetes Cluster with kubectl
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 kubectl 访问你的 Kubernetes 集群
- en: 'When your newly created cluster is available, you can set up your `kubectl`
    to access the cluster. The Google Cloud SDK provides a command to register the
    cluster with your local `kubectl` configuration:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的新创建的集群可用时，你可以设置你的`kubectl`来访问这个集群。Google Cloud SDK提供了一个命令来注册这个集群到你本地的`kubectl`配置：
- en: '`$` `gcloud container clusters get-credentials` `$CLUSTER_NAME` `--zone` `$GCP_REGION`'
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `gcloud container clusters get-credentials` `$CLUSTER_NAME` `--zone` `$GCP_REGION`'
- en: 'After updating the `kubectl` configuration, you can check if the correct cluster
    is selected by running the following command:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在更新`kubectl`配置后，你可以通过运行以下命令来检查是否选择了正确的集群：
- en: '`$` `kubectl config current-context gke_oreilly-book_us-central1-c_kfp-oreilly-book`'
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `kubectl config current-context gke_oreilly-book_us-central1-c_kfp-oreilly-book`'
- en: Using Your Kubernetes Cluster with kubectl
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 使用你的 Kubernetes 集群与 kubectl
- en: 'Because your local `kubectl` can connect with your remote Kubernetes cluster,
    all `kubectl` commands, such as our Kubeflow Pipelines steps mentioned in the
    following and in [Chapter 12](index_split_019.html#filepos1378763), will be executed
    on the remote cluster:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因为你的本地`kubectl`可以连接到远程的 Kubernetes 集群，所有像我们在下面提到的 Kubeflow Pipelines 步骤和 [第12章](index_split_019.html#filepos1378763)
    中提到的命令都将在远程集群上执行：
- en: '`$` `export` `PIPELINE_VERSION``=``0.5.0` `$` `kubectl apply -k` `"github.com/kubeflow/pipelines/manifests/kustomize/"``\``"cluster-scoped-resources?ref=``$PIPELINE_VERSION``"``$`
    `kubectl` `wait` `--for` `condition``=``established` `\` `--timeout``=``60s crd/applications.app.k8s.io`
    `$` `kubectl apply -k` `"github.com/kubeflow/pipelines/manifests/kustomize/"``\``"env/dev?ref=``$PIPELINE_VERSION``"`'
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `export` `PIPELINE_VERSION``=``0.5.0` `$` `kubectl apply -k` `"github.com/kubeflow/pipelines/manifests/kustomize/"``\``"cluster-scoped-resources?ref=``$PIPELINE_VERSION``"``$`
    `kubectl` `wait` `--for` `condition``=``established` `\` `--timeout``=``60s crd/applications.app.k8s.io`
    `$` `kubectl apply -k` `"github.com/kubeflow/pipelines/manifests/kustomize/"``\``"env/dev?ref=``$PIPELINE_VERSION``"`'
- en: Persistent Volume Setups for Kubeflow Pipelines
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow Pipelines 的持久卷设置
- en: In [“Exchange Data Through Persistent Volumes”](index_split_025.html#filepos1692492),
    we’ll discuss the setup of persistent volumes in our Kubeflow Pipelines setup.
    The complete configuration of the persistent volume and its claim can be seen
    in the following code blocks. The presented setup is specific to the Google Cloud
    environment.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [“通过持久卷交换数据”](index_split_025.html#filepos1692492)，我们将讨论在我们的 Kubeflow Pipelines
    设置中设置持久卷的过程。持久卷及其声明的完整配置可以在以下代码块中看到。所展示的设置是针对 Google Cloud 环境的。
- en: '[Example B-1](#filepos1674105) shows the configuration of the persistent volume
    for our Kubernetes cluster:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 B-1](#filepos1674105) 展示了我们 Kubernetes 集群的持久卷配置：'
- en: Example B-1\. Persistent volume configuration
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 B-1\. 持久卷配置
- en: '`apiVersion``:` `v1` `kind``:` `PersistentVolume` `metadata``:``name``:` `tfx-pv`
    `namespace``:` `kubeflow` `annotations``:``kubernetes.io/createdby``:` `gce-pd-dynamic-provisioner`
    `pv.kubernetes.io/bound-by-controller``:``"yes"``pv.kubernetes.io/provisioned-by``:`
    `kubernetes.io/gce-pd` `spec``:``accessModes``:` `- ReadWriteOnce` `capacity``:``storage``:`
    `20Gi` `claimRef``:``apiVersion``:` `v1` `kind``:` `PersistentVolumeClaim` `name``:`
    `tfx-pvc` `namespace``:` `kubeflow` `gcePersistentDisk``:``fsType``:` `ext4` `pdName``:`
    `tfx-pv-disk` `nodeAffinity``:``required``:``nodeSelectorTerms``:` `-` `matchExpressions``:`
    `-` `key``:` `failure-domain.beta.kubernetes.io/zone` `operator``:` `In` `values``:`
    `- us-central1-c         -` `key``:` `failure-domain.beta.kubernetes.io/region`
    `operator``:` `In` `values``:` `- us-central1` `persistentVolumeReclaimPolicy``:`
    `Delete` `storageClassName``:` `standard` `volumeMode``:` `Filesystem` `status``:``phase``:`
    `Bound`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`apiVersion`:`v1` `kind`:`PersistentVolume` `metadata`:`name`:`tfx-pv` `namespace`:`kubeflow`
    `annotations`:`kubernetes.io/createdby`:`gce-pd-dynamic-provisioner` `pv.kubernetes.io/bound-by-controller`:`"yes"`
    `pv.kubernetes.io/provisioned-by`:`kubernetes.io/gce-pd` `spec`:`accessModes`:`-
    ReadWriteOnce` `capacity`:`storage`:`20Gi` `claimRef`:`apiVersion`:`v1` `kind`:`PersistentVolumeClaim`
    `name`:`tfx-pvc` `namespace`:`kubeflow` `gcePersistentDisk`:`fsType`:`ext4` `pdName`:`tfx-pv-disk`
    `nodeAffinity`:`required`:`nodeSelectorTerms`:`- matchExpressions`:`- key`:`failure-domain.beta.kubernetes.io/zone`
    `operator`:`In` `values`:`- us-central1-c` `- key`:`failure-domain.beta.kubernetes.io/region`
    `operator`:`In` `values`:`- us-central1` `persistentVolumeReclaimPolicy`:`Delete`
    `storageClassName`:`standard` `volumeMode`:`Filesystem` `status`:`phase`:`Bound`'
- en: 'Once the persistent volume is created, we can claim a portion or all of the
    available storage through a persistent volume claim. The configuration file can
    be seen in [Example B-2](#filepos1681670):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦持久卷被创建，我们可以通过持久卷声明索取可用存储的部分或全部。 配置文件可见于 [示例 B-2](#filepos1681670)：
- en: Example B-2\. Persistent volume claim configuration
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 B-2\. 持久卷声明配置
- en: '`kind``:` `PersistentVolumeClaim` `apiVersion``:` `v1` `metadata``:``name``:`
    `tfx-pvc` `namespace``:` `kubeflow` `spec``:``accessModes``:` `- ReadWriteOnce`
    `resources``:``requests``:``storage``:` `20Gi`'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`kind`:`PersistentVolumeClaim` `apiVersion`:`v1` `metadata`:`name`:`tfx-pvc`
    `namespace`:`kubeflow` `spec`:`accessModes`:`- ReadWriteOnce` `resources`:`requests`:`storage`:`20Gi`'
- en: With the presented configuration, we have now created a persistent volume and
    its claim in the Kubernetes cluster. The volume can now be mounted as discussed
    in [“Pipeline Setup”](index_split_019.html#filepos1401991) or used as discussed
    in the section [“Exchange Data Through Persistent Volumes”](index_split_025.html#filepos1692492)
    of the following appendix.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用所提供的配置，我们现在在 Kubernetes 集群中创建了持久卷及其声明。 如 [“Pipeline Setup”](index_split_019.html#filepos1401991)
    中所讨论的，该卷现在可以被挂载，或如附录中的 [“Exchange Data Through Persistent Volumes”](index_split_025.html#filepos1692492)
    中所讨论的那样使用。
