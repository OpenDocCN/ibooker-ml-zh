- en: 'Chapter 5\. Putting It All Together: Content-Based Recommender'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。将所有内容整合起来：基于内容的推荐系统
- en: Throughout this part of the book, we’ve introduced some of the most basic components
    in a recommendation system. In this chapter, we’ll get hands-on. We’re going to
    design and implement a recommendation system for images from Pinterest. This chapter,
    along with the book’s other “Putting It All Together” chapters, will show you
    how to work with datasets by using open source tools. The material for this kind
    of chapter refers to code hosted on GitHub that you will need to download and
    play with in order to properly experience the content.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的这一部分中，我们介绍了推荐系统中最基本的一些组件。在本章中，我们将亲自动手。我们将为来自Pinterest的图像设计并实现推荐系统。这一章以及本书的其他“将所有内容整合起来”章节将向您展示如何使用开源工具处理数据集。这类章节的材料是指在GitHub上托管的代码，您需要下载并与之互动，以便全面体验内容。
- en: Since this is the first practical hands-on chapter, here are some extra setup
    instructions for the development environment. We developed this code on Windows
    running in a Windows Subsystem for Linux (WSL) Ubuntu virtual machine. The code
    should run fine on Linux machines, with more technical adaptation for macOS and
    a lot more for Windows, in which case it would be better to run it on a WSL2 Ubuntu
    virtual machine. You can look at the setup for WSL in the [Microsoft documentation
    for Windows](https://oreil.ly/VWPhi). We picked Ubuntu for the image. You will
    also need [NVIDIA CUDA](https://oreil.ly/rnCw4) and [cuDNN](https://oreil.ly/LHa-I)
    if you have an NVIDIA GPU and want to use it.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是第一个实践操作章节，这里提供了开发环境的额外设置说明。我们在运行Windows子系统Linux（WSL）Ubuntu虚拟机的Windows上开发了这段代码。该代码应该可以在Linux机器上正常运行，对于macOS需要更多的技术适配，而对于Windows，则最好在WSL2
    Ubuntu虚拟机上运行。您可以查看[Windows的Microsoft文档](https://oreil.ly/VWPhi)来了解WSL的设置。我们选择Ubuntu作为映像。如果您有NVIDIA
    GPU并希望使用它，您还需要[NVIDIA CUDA](https://oreil.ly/rnCw4)和[cuDNN](https://oreil.ly/LHa-I)。
- en: 'We will be using the [Shop the Look (STL) dataset](https://oreil.ly/PxfJn)
    from [“Complete the Look: Scene-Based Complementary Product Recommendation”](https://oreil.ly/2EDnZ)
    by Wang-Cheng Kang et al.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用[“完成外观：基于场景的补充产品推荐”](https://oreil.ly/2EDnZ)中的[Shop the Look (STL) 数据集](https://oreil.ly/PxfJn)，作者是康旺诚（Wang-Cheng
    Kang）等人。
- en: In this chapter, we will show you how to build a content-based recommender.
    Recall that a content-based recommender uses indirect, generalizable representations
    of the items you wish to represent. Imagine, for instance, that you want to recommend
    a cake but cannot use the name of a cake. Instead, you might use descriptions
    of the cake or its ingredients as the content features.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将向您展示如何构建基于内容的推荐系统。请记住，基于内容的推荐系统使用间接的、可推广的项目表示。例如，假设您想推荐一个蛋糕，但不能使用蛋糕的名称。相反，您可以使用蛋糕的描述或其成分作为内容特征。
- en: With the STL dataset, we will try to match scenes, which are pictures of a person
    in a particular setting, with products that might go well with the scene. The
    training set contains pairs of scenes with single products, and we want to use
    the content recommender to extend recommendations to the entire catalog of products
    and sort them in some kind of ranking order. The content recommender, because
    it uses indirect content features to make recommendations, can be used to recommend
    new products that haven’t been in the recommendation system or to warm-start a
    recommendation system with manually curated data before users start using it and
    a feedback loop is established. In the case of the STL dataset, we’ll focus on
    the visual appearance of the scene and the products.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 使用STL数据集，我们将尝试将场景（人物在特定环境中的图片）与可能与场景搭配的产品匹配。训练集包含场景与单个产品的配对，我们希望使用内容推荐系统将推荐扩展到整个产品目录，并按某种排序顺序进行排序。基于内容的推荐系统利用间接的内容特征进行推荐，可用于推荐尚未包含在推荐系统中的新产品，或者在用户开始使用之前手动策划数据和建立反馈循环。在STL数据集的情况下，我们将重点放在场景和产品的视觉外观上。
- en: We will generate content embeddings via a convolutional neural network (CNN)
    architecture, and then train the embedding via a triplet loss and show how to
    create a content recommendation system.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过卷积神经网络（CNN）架构生成内容嵌入，然后通过三元损失训练嵌入，并展示如何创建内容推荐系统。
- en: 'This chapter covers the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Revision control software
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修订控制软件
- en: Python build systems
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 构建系统
- en: Random-item recommender
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机项目推荐
- en: Obtaining the STL dataset images
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取STL数据集的图像
- en: Definition of CNN
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN 的定义
- en: Model training in JAX, Flax, and Optax
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JAX、Flax 和 Optax 中的模型训练
- en: Input pipeline
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入流水线
- en: Revision Control Software
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 版本控制软件
- en: '*Revision control software* is a software system that keeps track of code changes.
    Think of it as a database that tracks versions of code you have written, while
    providing added functionality like showing the differences between each version
    of code and allowing you to revert to a previous version.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*版本控制软件*是一种跟踪代码更改的软件系统。可以将其视为跟踪您编写的代码版本的数据库，同时提供显示每个代码版本之间差异的附加功能，并允许您恢复到先前版本。'
- en: There are many kinds of revision control systems. We host the code for this
    book on [GitHub](https://oreil.ly/DsolH).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多种版本控制系统。我们在[GitHub](https://oreil.ly/DsolH)上托管本书的代码。
- en: The revision control software we use is called [Git](https://git-scm.com). Code
    changes are done in batches called a *patch*, and each patch is uploaded to a
    source control repository like GitHub so that it can be cloned and worked on by
    many people at the same time.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的版本控制软件名为[Git](https://git-scm.com)。代码更改以*patch*批次的形式进行，每个*patch*都会上传到类似GitHub的源代码控制存储库，以便许多人同时克隆并进行工作。
- en: 'You can use this command to clone the book code sample repository:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用此命令克隆书中代码示例存储库：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For this chapter, look in the directory *ESRecsys/pinterest* for instructions
    on how to run the code in detail. This chapter will mostly focus on descriptions
    and pointers to the repository so that you’ll able to get a feel for these systems
    in practice.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一章，查看目录 *ESRecsys/pinterest* 以了解如何详细运行代码的说明。这一章主要侧重于描述和指向存储库，以便你能够实际感受这些系统。
- en: Python Build Systems
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python构建系统
- en: Python *packages* are libraries that provide functionality beyond the standard
    Python libraries. These include ML packages such as TensorFlow and JAX but also
    more utilitarian packages like the absl flags library or machine learning operations
    (MLOps) libraries like [Weights & Biases](https://wandb.ai).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Python *包*是提供超出标准 Python 库功能的库。这些包括诸如 TensorFlow 和 JAX 等 ML 包，但也包括更实用的包，例如 absl
    标志库或机器学习操作（MLOps）库，如[Weights & Biases](https://wandb.ai)。
- en: These packages are usually hosted on [the Python Package Index](https://pypi.org).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包通常托管在[Python软件包索引](https://pypi.org)上。
- en: 'Take a look at the file *requirements.txt*:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 查看文件 *requirements.txt*：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can see that we have picked a small set of Python packages to install for
    our dependencies. The format is package name, two equal signs, and then the version
    of the package.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到我们选择了一小组Python包来安装我们的依赖项。格式为包名、两个等号，然后是包的版本。
- en: 'Other build systems that work with Python include the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他与Python一起工作的构建系统，包括以下内容：
- en: '[pip](https://oreil.ly/QNevQ)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pip](https://oreil.ly/QNevQ)'
- en: '[Bazel](https://oreil.ly/3BdIC)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Bazel](https://oreil.ly/3BdIC)'
- en: '[Anaconda](https://oreil.ly/4z182)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Anaconda](https://oreil.ly/4z182)'
- en: For this chapter, we will use pip.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一章，我们将使用 pip。
- en: Before installing the packages, however, you might want to read up on [Python
    virtual environments](https://oreil.ly/fnQKD). Python virtual environments are
    a way to keep track of Python package dependencies per project so that if different
    projects use different versions of the same package, they won’t interfere with
    one another because each project has its own Python virtual environment to run
    in.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在安装包之前，您可能想要了解一下[Python虚拟环境](https://oreil.ly/fnQKD)。Python虚拟环境是一种跟踪每个项目的Python包依赖关系的方法，因此，如果不同项目使用不同版本的相同包，它们不会相互干扰，因为每个项目都有自己的Python虚拟环境来运行。
- en: 'You can create and activate a Python virtual environment by typing the following
    into a Unix shell:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在Unix shell中键入以下内容来创建和激活Python虚拟环境：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first command creates a Python virtual environment, and the second one activates
    it. You will have to activate a virtual environment every time you open a new
    shell so that Python knows what environment to work in.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令创建一个Python虚拟环境，第二个命令激活它。每次打开新的shell时，您都需要激活一个虚拟环境，以便Python知道要在哪个环境中工作。
- en: After the virtual environment is created, you can then use pip to install packages
    into the virtual environment, and those newly installed packages will not affect
    the system-level packages.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 创建虚拟环境后，您可以使用pip将软件包安装到虚拟环境中，新安装的软件包不会影响系统级软件包。
- en: 'You can do this by running this command in the *ESRecsys/pinterest* directory:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在 *ESRecsys/pinterest* 目录中运行此命令来执行此操作：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This will install the specified packages and any subpackages that they might
    depend on into the virtual environment.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这将安装指定的软件包及其可能依赖的任何子软件包到虚拟环境中。
- en: Random-Item Recommender
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机项目推荐器
- en: The first program we will look at is a random-item recommender ([Example 5-1](#example0501)).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要看的程序是一个随机项目推荐器（[示例 5-1](#example0501)）。
- en: Example 5-1\. Setting up flags
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-1\. 设置标志
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here we use the absl flags library to pass in arguments to the program such
    as the path to the JSON catalog file that contains the STL scene, and product
    pairs.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用absl标志库来传递程序参数，例如包含STL场景和产品配对的JSON目录文件的路径。
- en: Flags can have different types like string and integer, and you can mark them
    as required. If a required flag is not passed to the program, it will complain
    and stop running. Flags can be accessed via their value method.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 标志可以有不同的类型，如字符串和整数，并且您可以将它们标记为必需的。如果未传递必需的标志到程序中，程序将报错并停止运行。可以通过它们的值方法访问标志。
- en: We load and parse the STL dataset by using the JSON Python library, and then
    we randomly shuffle the catalog and dump the top few results in HTML.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用JSON Python库加载和解析STL数据集，然后随机洗牌目录并将前几个结果转储到HTML中。
- en: 'You can run the random-item recommender via the following command:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下命令来运行随机项目推荐器：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After completion, you can open the *output.html* file with your web browser
    and see some random items from the catalog. [Figure 5-1](#random_item_figure)
    shows a sample.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您可以使用Web浏览器打开*output.html*文件，查看目录中的一些随机项目。[图 5-1](#random_item_figure) 展示了一个示例。
- en: '![Random items from the Pinterest shop the look dataset](assets/brpj_0501.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![来自Pinterest商店“看看”数据集的随机项目](assets/brpj_0501.png)'
- en: Figure 5-1\. Random-item recommender
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1\. 随机项目推荐器
- en: The *fashion-catalog.json* file contains descriptions of products and their
    Pinterest ID, while *fashion.json* contains pairings of a scene with a recommended
    product.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*fashion-catalog.json* 文件包含产品描述及其Pinterest ID，而*fashion.json* 包含场景与推荐产品的配对信息。'
- en: Next, we’ll look at how to recommend multiple new items for a single scene by
    training an ML model on scene-product pairings.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看看如何通过对场景-产品配对进行训练ML模型来为单个场景推荐多个新项目。
- en: It is generally a good idea to create a random-item recommender the first time
    you encounter a corpus just so you have an idea of the kind of items in the corpus
    and you have a baseline to compare to.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当您第一次遇到一个语料库时，创建一个随机项目推荐器通常是一个好主意，这样您可以了解语料库中的项目类型，并有一个比较的基准。
- en: Obtaining the STL Dataset Images
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取STL数据集图像
- en: The first step in the process of creating a content-based recommender is fetching
    the content. In this case, the STL dataset’s content is mostly images, with some
    metadata about the image (like the type of product). We will be using just the
    image content for this chapter.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 创建基于内容的推荐系统的第一步是获取内容。在这种情况下，STL数据集的内容主要是图像，还包括一些关于图像的元数据（如产品类型）。本章节我们将仅使用图像内容。
- en: You can look at the code in *fetch_images.py* to see how this is done, by using
    the Python standard library urllib to fetch the images. Be aware that doing too
    much fetching on someone else’s website might trigger their bot defenses and cause
    them to blacklist your IP address, so it might be a wise idea to rate-limit fetches
    or find some other way to get the data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看*fetch_images.py*中的代码，了解如何使用Python标准库urllib获取图像。请注意，在其他网站上进行过多的抓取可能会触发其机器人防御机制，并导致将您的IP地址列入黑名单，因此限制抓取速率或找到其他获取数据的方法可能是个明智的选择。
- en: We have downloaded thousands of image files and put them together into an archive
    as a Weights & Biases artifact. Since the archive is already in this artifact,
    you don’t need to scrape the images yourself, but the code we’ve supplied will
    allow you to do so.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经下载了成千上万个图像文件，并将它们放在一个Weights & Biases工件中。由于存档已经包含在此工件中，您无需自行抓取这些图像，但我们提供的代码将允许您这样做。
- en: You can read up on artifacts in the [Weights & Biases documentation](https://oreil.ly/NXTYP).
    Artifacts are an MLOps concept that version and package together archives of data
    and track producers and consumers of the data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[Weights & Biases文档](https://oreil.ly/NXTYP)中了解有关工件的更多信息。工件是MLOps概念，用于版本控制和打包数据的归档，并跟踪数据的生产者和消费者。
- en: 'You can download the image artifact by running the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过运行以下命令来下载图像文件：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The images will then be in the local directory *artifacts/shop_the_look:v1*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图像将会位于本地目录*artifacts/shop_the_look:v1*中。
- en: Convolutional Neural Network Definition
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络定义
- en: Now that we have the images, the next step is figuring out how to represent
    the data. Images come in different sizes and are a complex type of content to
    analyze. We can use the raw pixels as the representation of our content, but the
    drawback is that tiny changes in pixel values can cause large differences in the
    distance between images. We do not want that. Rather, we want to somehow learn
    what is important in the images and ignore parts of the image, such as the background
    color, that might not be as important.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了图像，下一步是找出如何表示数据。图像有不同的大小，是一种复杂的内容类型进行分析。我们可以使用原始像素作为我们内容的表示，但缺点是像素值的微小变化可能会导致图像之间的距离差异很大。我们不希望这样。相反，我们希望某种方式学习图像中重要的内容，忽略像背景颜色这样的图像部分，这些部分可能不那么重要。
- en: For this task, we will use a [convolutional neural network (CNN)](https://oreil.ly/r6KpS)
    to compute an embedding vector for the image. An *embedding vector* is a kind
    of feature vector for the image that is learned from data and is of fixed size.
    We use embedding vectors for our representation because we want our database to
    be small and compact, easy to score over large numbers of images in the corpus,
    and relevant to the task at hand, which is to match products to a given scene
    image.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个任务，我们将使用[卷积神经网络（CNN）](https://oreil.ly/r6KpS)来计算图像的嵌入向量。*嵌入向量* 是从数据中学习到的图像的一种特征向量，大小固定。我们使用嵌入向量作为我们的表示，因为我们希望我们的数据库小而紧凑，易于在大量图像中进行评分，并与手头的任务相关，即将产品匹配到给定场景图像。
- en: The neural network architecture we use is a variant of residual networks, or
    Resnet. Refer to [“Deep Residual Learning for Image Recognition”](https://oreil.ly/XQYUh)
    by Kaiming He et al. for details about the architecture and for references on
    CNNs. Briefly, a convolution layer repeatedly applies a small filter of typically
    3 × 3 size over an image. This results in a feature map of the same resolution
    as the input if the stride is (1, 1) (which means apply the filter with a 1-pixel
    step in the x direction and a 1-pixel step in the y direction), or quarter size
    if the stride is (2, 2). The residual skip connection is just a shortcut from
    the previous input layer to the next, so in effect, the nonlinear part of the
    networks learns the residual from the linear skip part, hence the name residual
    network.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的神经网络架构是残差网络的一种变体，或称为ResNet。有关架构的详细信息和CNN的参考，请参阅Kaiming He等人的[“深度残差学习用于图像识别”](https://oreil.ly/XQYUh)。简而言之，卷积层重复地在图像上应用一个通常为3×3大小的小滤波器。如果步幅为（1，1）（这意味着在x方向和y方向上以1像素步幅应用滤波器），则这会产生与输入相同分辨率的特征图，如果步幅为（2，2），则为四分之一大小。残差跳跃连接只是从前一个输入层到下一个的一种快捷方式，因此实际上，网络的非线性部分学习线性跳跃部分的残差，因此得名残差网络。
- en: 'Additionally, we use the BatchNorm layer, details of which can be found at
    [“Batch Normalization: Accelerating Deep Network Training by Reducing Internal
    Covariate Shift”](https://oreil.ly/qM-yg) by Sergey Ioffe and Christian Szegedy,
    and the [“Searching for Activation Functions”](https://oreil.ly/9Zlqb) by Prajit
    Ramachandran, Barret Zoph, and Quoc V. Le.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，我们使用BatchNorm层，其详细信息可以在[Sergey Ioffe和Christian Szegedy的“批归一化：通过减少内部协变量偏移加速深度网络训练”](https://oreil.ly/qM-yg)和[Prajit
    Ramachandran，Barret Zoph和Quoc V. Le的“搜索激活函数”](https://oreil.ly/9Zlqb)中找到。
- en: Once we specify the model, we also need to optimize it for the task.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们指定了模型，我们还需要为任务进行优化。
- en: Model Training in JAX, Flax, and Optax
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在JAX、Flax和Optax中进行模型训练
- en: Optimizing our model should be pretty straightforward in any ML framework. Here
    we show how to do it easily with [JAX](https://oreil.ly/pcmCU), [Flax](https://oreil.ly/RtzDn),
    and [Optax](https://oreil.ly/vOCvF). *JAX* is a lower-level NumPy-like ML library,
    and *Flax* is a higher-level neural network library that provides functionality
    such as neural network modules and embedding layers. *Optax* is a library that
    does optimization that we will use to minimize our loss function.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何ML框架中优化我们的模型应该是相当简单的。这里我们展示如何使用[JAX](https://oreil.ly/pcmCU)，[Flax](https://oreil.ly/RtzDn)和[Optax](https://oreil.ly/vOCvF)轻松地完成这项任务。*JAX*
    是一个类似于NumPy的低级ML库，*Flax* 是一个更高级的神经网络库，提供神经网络模块和嵌入层等功能。*Optax* 是一个库，用于优化我们将用来最小化损失函数的内容。
- en: If you are familiar with NumPy, JAX is quite easy to pick up. JAX shares the
    same API as NumPy but has the capability of running the resulting code on vector
    processors such as GPUs or TPUs by doing JIT compilation. JAX device arrays and
    NumPy arrays can be easily converted back and forth, which makes it easy to develop
    for the GPU and yet easy to debug on the CPU.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉NumPy，学习JAX会很容易。JAX与NumPy共享相同的API，但通过即时编译具备在矢量处理器（如GPU或TPU）上运行生成的代码的能力。JAX设备数组和NumPy数组可以轻松相互转换，这使得在GPU上开发变得简单，但在CPU上进行调试也很容易。
- en: In addition to learning how to represent the images, we also need to specify
    how they are related to one another.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 除了学习如何表示图像外，我们还需要指定它们之间的关系。
- en: 'Since the embedding vectors are of fixed dimensions, the easiest similarity
    score is simply the dot product of the two vectors. See [“Similarity from Co-occurrence”](ch09.html#sim_measures)
    for other kinds of similarity measures. So, given an image for a scene, we compute
    the scene embedding and do the same for the product to obtain a product embedding,
    and take the dot product of the two to obtain a score for the closeness of fit
    of a scene <math alttext="ModifyingAbove s With right-arrow"><mover accent="true"><mi>s</mi>
    <mo>→</mo></mover></math> to a product <math alttext="ModifyingAbove p With right-arrow"><mover
    accent="true"><mi>p</mi> <mo>→</mo></mover></math> :'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 由于嵌入向量具有固定的维度，最简单的相似度分数只是两个向量的点积。参见[“共现相似度”](ch09.html#sim_measures)获取其他类型的相似度度量方法。因此，给定一个场景的图像，我们计算场景嵌入，并对产品执行相同操作以获取产品嵌入，然后取两者的点积以获取场景
    <math alttext="ModifyingAbove s With right-arrow"><mover accent="true"><mi>s</mi>
    <mo>→</mo></mover></math> 与产品 <math alttext="ModifyingAbove p With right-arrow"><mover
    accent="true"><mi>p</mi> <mo>-></mo></mover></math> 的拟合紧密程度分数：
- en: <math alttext="s c o r e left-parenthesis ModifyingAbove s With right-arrow
    comma ModifyingAbove p With right-arrow right-parenthesis equals ModifyingAbove
    s With right-arrow asterisk ModifyingAbove p With right-arrow" display="block"><mrow><mi>s</mi>
    <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi> <mrow><mo>(</mo> <mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><mi>p</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <mover accent="true"><mi>s</mi> <mo>→</mo></mover>
    <mo>*</mo> <mover accent="true"><mi>p</mi> <mo>→</mo></mover></mrow></math>
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="s c o r e left-parenthesis ModifyingAbove s With right-arrow
    comma ModifyingAbove p With right-arrow right-parenthesis equals ModifyingAbove
    s With right-arrow asterisk ModifyingAbove p With right-arrow" display="block"><mrow><mi>s</mi>
    <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi> <mrow><mo>(</mo> <mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><mi>p</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <mover accent="true"><mi>s</mi> <mo>→</mo></mover>
    <mo>*</mo> <mover accent="true"><mi>p</mi> <mo>→</mo></mover></mrow></math>
- en: We use CNNs to obtain the embedding of an image.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用CNN来获取图像的嵌入。
- en: We use separate CNNs for the scene and product, however, because they come from
    different kinds of images. Scenes tend to show the context we’re matching products
    to and contain people and the setting, whereas products tend to be catalog images
    of shoes and bags with a blank background, so we need different neural networks
    to determine what is important in the image.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为场景和产品使用单独的CNN，因为它们来自不同类型的图像。场景往往显示我们要匹配产品的背景和人物设置，而产品则往往是鞋子和包的目录图像，背景是空白的，因此我们需要不同的神经网络来确定图像中重要的内容。
- en: Once we have the score, that alone is not sufficient, though. We need to make
    sure that a good match of a scene and product, which we call the *positive product*,
    is higher scoring than a negative product. The positive product is a good match
    for the scene, and the negative product is a not-so-good match for the scene.
    The positive product comes from the training data, and the negative product comes
    from randomly sampling the catalog. A loss that can capture the relationship between
    a positive scene-product pair (A, B) and negative scene-product pair (A, C) is
    called *triplet loss*. Let’s go into some detail for defining the [triplet loss](https://oreil.ly/alBxu).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了分数，仅仅这些还不够。我们需要确保一个场景和产品的良好匹配，我们称之为*正面产品*，比负面产品得分更高。正面产品是场景的良好匹配，而负面产品是场景的不太良好匹配。正面产品来自训练数据，而负面产品来自随机采样的目录。能够捕捉正面场景-产品对（A,
    B）和负面场景-产品对（A, C）之间关系的损失称为*三元损失*。让我们详细定义一下[三元损失](https://oreil.ly/alBxu)。
- en: 'Suppose we want the score for the positive scene-product pair to be one more
    than a negative scene-product pair. We then have the following inequality:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望正面场景-产品对的分数比负面场景-产品对多一个。那么我们有以下不等式：
- en: <math alttext="s c o r e left-parenthesis s c e n e comma p o s Subscript p
    r o d u c t Baseline right-parenthesis greater-than s c o r e left-parenthesis
    s c e n e comma n e g Subscript p r o d u c t Baseline right-parenthesis plus
    1" display="block"><mrow><mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo>
    <mi>p</mi> <mi>o</mi> <msub><mi>s</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>></mo> <mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo>
    <mi>n</mi> <mi>e</mi> <msub><mi>g</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>+</mo> <mn>1</mn></mrow></math>
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="s c o r e left-parenthesis s c e n e comma p o s Subscript p
    r o d u c t Baseline right-parenthesis greater-than s c o r e left-parenthesis
    s c e n e comma n e g Subscript p r o d u c t Baseline right-parenthesis plus
    1" display="block"><mrow><mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo>
    <mi>p</mi> <mi>o</mi> <msub><mi>s</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>></mo> <mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo>
    <mi>n</mi> <mi>e</mi> <msub><mi>g</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>+</mo> <mn>1</mn></mrow></math>
- en: The 1 is just an arbitrary constant we use, called a *margin*, to make sure
    that the positive scene-product score is larger than the negative scene-product
    score.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 1只是我们使用的一个任意常数，称为*间隔*，以确保正面场景-产品分数大于负面场景-产品分数。
- en: 'Since the process of gradient descent minimizes a function, we then convert
    the preceding inequality into a loss function by moving all terms to one side:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 由于梯度下降的过程是最小化一个函数，我们将前述不等式转化为损失函数，通过将所有项移到一边实现：
- en: <math alttext="0 greater-than 1 plus s c o r e left-parenthesis s c e n e comma
    n e g Subscript p r o d u c t Baseline right-parenthesis minus s c o r e left-parenthesis
    s c e n e comma p o s Subscript p r o d u c t Baseline right-parenthesis" display="block"><mrow><mn>0</mn>
    <mo>></mo> <mn>1</mn> <mo>+</mo> <mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo>
    <mi>n</mi> <mi>e</mi> <msub><mi>g</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>-</mo> <mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo>
    <mi>p</mi> <mi>o</mi> <msub><mi>s</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow></mrow></math>
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="0 greater-than 1 plus s c o r e left-parenthesis s c e n e comma
    n e g Subscript p r o d u c t Baseline right-parenthesis minus s c o r e left-parenthesis
    s c e n e comma p o s Subscript p r o d u c t Baseline right-parenthesis" display="block"><mrow><mn>0</mn>
    <mo>></mo> <mn>1</mn> <mo>+</mo> <mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo>
    <mi>n</mi> <mi>e</mi> <msub><mi>g</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>-</mo> <mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo>
    <mi>p</mi> <mi>o</mi> <msub><mi>s</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow></mrow></math>
- en: 'As long as the quantity on the right side is larger than 0, we want to minimize
    it; but if it is already less than 0, we do not. Therefore, we encode the quantity
    in a rectified linear unit, which is represented by the function `max(0, *x*)`.
    We can thus write out our loss function as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 只要右侧的数量大于0，我们希望将其最小化；但如果已经小于0，则不进行操作。因此，我们将数量编码为修正线性单元，其由函数`max(0, *x*)`表示。因此，我们可以将我们的损失函数写成如下形式：
- en: <math alttext="l o s s left-parenthesis s c e n e comma p o s Subscript p r
    o d u c t Baseline comma n e g Subscript p r o d u c t Baseline right-parenthesis
    equals"><mrow><mi>l</mi> <mi>o</mi> <mi>s</mi> <mi>s</mi> <mo>(</mo> <mi>s</mi>
    <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo> <mi>p</mi> <mi>o</mi> <msub><mi>s</mi>
    <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>,</mo> <mi>n</mi> <mi>e</mi> <msub><mi>g</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo> <mo>=</mo></mrow></math> <math alttext="m a x left-parenthesis 0 comma
    1 plus s c o r e left-parenthesis s c e n e comma n e g Subscript p r o d u c
    t Baseline right-parenthesis minus s c o r e left-parenthesis s c e n e comma
    p o s Subscript p r o d u c t Baseline right-parenthesis right-parenthesis"><mrow><mi>m</mi>
    <mi>a</mi> <mi>x</mi> <mo>(</mo> <mn>0</mn> <mo>,</mo> <mn>1</mn> <mo>+</mo> <mi>s</mi>
    <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi> <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi>
    <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo> <mi>n</mi> <mi>e</mi> <msub><mi>g</mi>
    <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>-</mo> <mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo>
    <mi>p</mi> <mi>o</mi> <msub><mi>s</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow></math>
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <math alttext="l o s s left-parenthesis s c e n e comma p o s Subscript p r
    o d u c t Baseline comma n e g Subscript p r o d u c t Baseline right-parenthesis
    equals"><mrow><mi>l</mi> <mi>o</mi> <mi>s</mi> <mi>s</mi> <mo>(</mo> <mi>s</mi>
    <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo> <mi>p</mi> <mi>o</mi> <msub><mi>s</mi>
    <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>,</mo> <mi>n</mi> <mi>e</mi> <msub><mi>g</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo> <mo>=</mo></mrow></math> <math alttext="m a x left-parenthesis 0 comma
    1 plus s c o r e left-parenthesis s c e n e comma n e g Subscript p r o d u c
    t Baseline right-parenthesis minus s c o r e left-parenthesis s c e n e comma
    p o s Subscript p r o d u c t Baseline right-parenthesis right-parenthesis"><mrow><mi>m</mi>
    <mi>a</mi> <mi>x</mi> <mo>(</mo> <mn>0</mn> <mo>,</mo> <mn>1</mn> <mo>+</mo> <mi>s</mi>
    <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi> <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi>
    <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo> <mi>n</mi> <mi>e</mi> <msub><mi>g</mi>
    <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>-</mo> <mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mo>,</mo>
    <mi>p</mi> <mi>o</mi> <msub><mi>s</mi> <mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow></math>
- en: Since we usually minimize loss functions, this ensures that as long as the `score(scene,
    neg_product)` is 1 more than `score(scene, pos_product)`, the optimization procedure
    will try to minimize the score of the negative pair while increasing the score
    of the positive pair.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们通常会最小化损失函数，这确保只要`score(scene, neg_product)`比`score(scene, pos_product)`多1，优化过程将尝试减少负对的分数，同时增加正对的分数。
- en: 'The next example covers the following modules in order so that they make sense
    as they follow the flow of data from reading to training to making recommendations:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例按顺序涵盖以下模块，以便它们在数据从读取到训练再到制作推荐的流程中具有意义：
- en: '*input__pipeline.py*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*input__pipeline.py*'
- en: How the data is read
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如何读取数据
- en: '*models.py*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*models.py*'
- en: How the neural networks are specified
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如何指定神经网络
- en: '*train_shop_the_look.py*'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*train_shop_the_look.py*'
- en: How the neural network is fit using Optax
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用Optax拟合神经网络
- en: '*make_embeddings.py*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*make_embeddings.py*'
- en: How to make a compact database of scene and products
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如何制作一个紧凑的场景和产品数据库
- en: '*make_recommendations.py*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*make_recommendations.py*'
- en: How to use the compact database of embeddings to create a list of product recommendations
    per scene
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用嵌入的紧凑数据库创建每个场景的产品推荐列表
- en: Input Pipeline
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 输入流水线
- en: '[Example 5-2](#example0502) shows the code for *input_pipeline.py*. We use
    the ML library [TensorFlow](https://oreil.ly/hsqPr) for its data pipeline.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 5-2](#example0502)展示了*input_pipeline.py*的代码。我们使用ML库[TensorFlow](https://oreil.ly/hsqPr)来进行数据流水线处理。'
- en: Example 5-2\. TensorFlow data pipeline
  id: totrans-100
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-2\. TensorFlow数据流水线
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You can see that `create_dataset` takes in three filenames: that of a scene,
    then a positive match and a negative match. For this example, the negative match
    is simply selected at random from the catalog. We cover more sophisticated ways
    of picking the negative in [Chapter 12](ch12.html#LossFunctions). The image filenames
    are processed by reading the file, decoding the image, cropping it to a fixed
    size, and then rescaling the data so that it becomes a floating-point image centered
    around 0 and with small values between –1 and 1\. We do this because most neural
    networks are initialized with the assumption that the data they get is roughly
    normally distributed, and so if you pass in too large a value, it would be far
    out of the norm of the expected input range.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到 `create_dataset` 接受三个文件名：场景的文件名，然后是正匹配和负匹配。对于这个示例，负匹配只是从目录中随机选择的。我们在 [第
    12 章](ch12.html#LossFunctions) 中介绍了选择负面的更复杂的方法。图像文件名通过读取文件，解码图像，裁剪到固定大小，然后重新缩放数据，使其成为围绕
    0 居中并具有在 –1 和 1 之间的小值的浮点图像来处理。我们这样做是因为大多数神经网络被初始化时假定它们接收到的数据大致上是正态分布的，因此如果您传入的值太大，它将远远超出预期输入范围的正常值。
- en: '[Example 5-3](#example0503) shows how to specify our CNN and STL model with
    Flax.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 5-3](#example0503) 展示了如何使用 Flax 指定我们的 CNN 和 STL 模型。'
- en: Example 5-3\. Defining the CNN model
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-3\. 定义 CNN 模型
- en: '[PRE8]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here we use Flax’s neural network class `Module`. The annotation `nn.compact`
    is there so we do not have to specify a setup function for simple neural network
    architectures like this one and can simply specify the layers in the `call` function.
    The `call` function accepts two parameters, an image `*x*` and a Boolean `train`
    that tells the module whether we are calling it in training mode. The reason we
    need the Boolean training is that the BatchNorm layers are updated only during
    training and are not updated when the network is fully learned.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了 Flax 的神经网络类 `Module`。注释 `nn.compact` 存在是为了对于像这样的简单神经网络架构，我们不必指定一个设置函数，而是可以简单地在
    `call` 函数中指定层。`call` 函数接受两个参数，一个图像 `*x*` 和一个布尔值 `train`，告诉模块我们是否在训练模式下调用它。我们需要布尔值训练的原因是
    BatchNorm 层仅在训练期间更新，并在网络完全学习时不会更新。
- en: If you look at the CNN specification code, you can see how we set up the residual
    network. We can freely mix neural network functions like `swish` with JAX functions
    like `mean`. The `swish` function is a nonlinear activation for the neural network
    that transforms the input in such a way as to weight some values of activation
    more than others.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看 CNN 规范代码，您可以看到我们如何设置残差网络。我们可以自由地混合神经网络函数，比如 `swish`，和 JAX 函数，比如 `mean`。`swish`
    函数是神经网络的非线性激活函数，它将输入转换为一种方式，以便对某些激活值给予更高的权重。
- en: 'The STL model, on the other hand, has a more complicated setup, so we have
    to specify the setup code to create two CNN towers: one for the scene and another
    for the product. A *CNN tower* is just a copy of the same architecture but has
    different weights for different image types. As mentioned earlier, we have a different
    tower for each type of image because each represents different things; one tower
    is for the scene (which provides the context to which we are matching products),
    and a separate tower is for the products. As a result, we add in two different
    methods for converting scene and product images into scene and product embeddings.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，STL 模型具有更复杂的设置，因此我们必须指定设置代码来创建两个 CNN tower：一个用于场景，另一个用于产品。*CNN tower* 只是相同架构的副本，但对于不同的图像类型具有不同的权重。如前所述，我们对于每种图像类型都有一个不同的
    tower，因为每种代表不同的事物；一个 tower 用于场景（提供我们匹配产品的上下文），另一个 tower 用于产品。因此，我们添加了两种不同的方法，用于将场景和产品图像转换为场景和产品嵌入。
- en: The call is also different. It doesn’t have the annotation compact because we
    have a more complicated setup. In the call function for the STL model, we first
    compute the scene embedding, then the positive product embedding, and then the
    positive score. After that, we do the same for the negative score. We then return
    the positive score, negative score, and all three embedding vectors. We return
    the embedding vectors as well as the scores because we want to ensure that the
    model generalizes to new, unseen data as in a held-out validation set, so we want
    to make sure the embedding vectors are not too large. The concept of capping their
    size is called *regularization*.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 调用也是不同的。它没有注释紧凑，因为我们有一个更复杂的设置。在 STL 模型的调用函数中，我们首先计算场景嵌入，然后计算正产品嵌入和正分数。之后，我们对负分数进行同样的操作。然后，我们返回正分数、负分数和所有三个嵌入向量。我们返回嵌入向量以及分数，因为我们希望确保模型泛化到新的、未见过的数据，例如保留验证集，因此我们希望确保嵌入向量不会过大。限制它们大小的概念称为*正则化*。
- en: Now let’s take a look at *train_shop_the_look.py* ([Example 5-4](#example0504)).
    We’ll break it into separate function calls and discuss them one by one.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下 *train_shop_the_look.py* ([示例 5-4](#example0504))。我们将其分解为单独的函数调用，并逐一讨论它们。
- en: Example 5-4\. Generating triplets for training
  id: totrans-111
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-4\. 生成训练用三元组
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The code fragment reads in the scene-product JSON database and generates triplets
    of scene, positive product, and negative products for the input pipeline. The
    interesting part to note here is how JAX handles random numbers. JAX’s philosophy
    is functional in nature, meaning that functions are pure and have no side effects.
    Random-number generators carry state, so in order to make JAX random-number generators
    function, you have to pass in the state to the random-number generator. The mechanism
    for this is to have a pseudo random number generator key, PNRGKey, as the object-carrying
    state. We initialize one arbitrarily from the number 0\. Whenever we wish to use
    the key, though, we have to split it into two by using `jax.random.split`, then
    use one to generate the next random number and a subkey to perform the random
    action. In this case, we use the subkey to select a random negative from the entire
    corpus of products for our negative. We cover more complex ways to sample the
    negative in [Chapter 12](ch12.html#LossFunctions), but randomly selecting a negative
    is the simplest way to construct the triplet for triplet loss.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 代码片段读取场景产品的 JSON 数据库，并为输入流水线生成场景、正产品和负产品的三元组。这里值得注意的有趣部分是 JAX 如何处理随机数。JAX 的理念是功能性的，意味着函数是纯净的，没有副作用。随机数生成器带有状态，因此为了使
    JAX 的随机数生成器能够工作，你必须将状态传递给随机数生成器。其机制是使用伪随机数生成器密钥 PNRGKey 作为携带状态的对象。我们任意地从数字 0 初始化一个。然而，每当我们希望使用密钥时，我们必须使用
    `jax.random.split` 将其分成两部分，然后使用其中一部分生成下一个随机数，使用子密钥执行随机操作。在本例中，我们使用子密钥从整个产品语料库中选择一个随机负例。在[第 12
    章](ch12.html#LossFunctions)中，我们介绍了更复杂的负例抽样方法，但随机选择一个负例是构建三元组损失的最简单方法。
- en: Similar to the way the negatives are selected, we again use JAX’s random functionality
    to generate a list of indices to swap, in order to shuffle the array for the training
    step. Random shuffling is important in stochastic gradient descent to break up
    any kind of structure in the training data to ensure that the gradients are stochastic.
    We use JAX’s random shuffling mechanism for better reproducibility so that experiments
    are more likely to be the same, given the same initial data and settings.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于选择负例的方式，我们再次使用 JAX 的随机功能生成要交换的索引列表，以便在训练步骤中对数组进行洗牌。在随机梯度下降中，随机洗牌对于打破训练数据的任何结构都是重要的，以确保梯度是随机的。我们使用
    JAX 的随机洗牌机制来提高再现性，以便在相同的初始数据和设置下实验更有可能是相同的。
- en: The next pair of functions we will look at are listed in [Example 5-5](#example0505)
    and show how the train and eval steps are written. The train step takes the state
    of the model, which contains the model parameters as well as the gradient information,
    which varies depending on the optimizer being used. This step also takes in batches
    of scenes, positive products, and negative products in order to construct the
    triplet loss. In addition to optimizing for the triplet loss, we want to minimize
    the size of the embeddings whenever they go outside the unit sphere. The process
    of minimizing the size of the embeddings is called *regularization*, so we add
    it to the triplet loss to obtain the final loss.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看一下的下一对函数列在 [示例 5-5](#example0505) 中，展示了训练和评估步骤的编写方式。训练步骤采用了模型状态，其中包含模型参数以及梯度信息，这取决于所使用的优化器。此步骤还接受场景批次、正产品和负产品，以构建三元损失。除了优化三元损失外，我们还希望在嵌入超出单位球时最小化其大小。最小化嵌入大小的过程称为*正则化*，因此我们将其添加到三元损失中以获得最终损失。
- en: Example 5-5\. Training and evaluation steps
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-5\. 训练和评估步骤
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Flax, being written on top of JAX, is also functional in philosophy, so the
    existing state is used to compute the gradient of the loss function, which when
    applied returns a new state variable. This ensures that the functions remain pure
    and the state variables are mutable.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Flax 基于 JAX 编写，同样具有功能哲学，因此使用现有状态计算损失函数的梯度，应用后返回一个新的状态变量。这确保函数保持纯粹且状态变量可变。
- en: This functional philosophy is what allows JAX to JIT compile or use JIT functions
    so they run fast on CPU, GPU, or TPU.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 正是这种功能哲学使得 JAX 能够即时编译或使用即时函数，从而在 CPU、GPU 或 TPU 上运行得更快。
- en: The eval step, in comparison, is rather simple. It just computes the triplet
    loss without the regularization loss as our evaluation metric. Again, we cover
    more sophisticated evaluation metrics in [Chapter 11](ch11.html#PersonalRecMetrics).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，评估步骤相对简单。它仅计算三元损失，不考虑正则化损失作为我们的评估指标。我们将在 [第 11 章](ch11.html#PersonalRecMetrics)
    中介绍更复杂的评估指标。
- en: Finally, let’s take a look at the body of the training program, shown in [Example 5-6](#example0506).
    We store our hyperparameters such as learning rate, regularization, and output
    size in a config dictionary. We do this so we can pass the config dictionary on
    to the Weights & Biases MLOps service for safekeeping and also so we can do hyperparameter
    sweeps.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们来看看训练程序的主体部分，如 [示例 5-6](#example0506) 所示。我们将学习率、正则化以及输出大小等超参数存储在配置字典中。我们这样做是为了将配置字典传递给
    Weights & Biases MLOps 服务进行安全存储，同时也能进行超参数调优。
- en: Example 5-6\. Main body of code for training the model
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-6\. 训练模型的主体代码
- en: '[PRE11]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: A *hyperparameter sweep* is a tuning service that helps you find optimal values
    for hyperparameters such as learning rate by running many trials of different
    values and searches for the best one. Having the configuration as a dictionary
    allows us to reproduce the best parameters by running a hyperparameter sweep and
    then saving the best one for the final model.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*超参数调优*是一个调整服务，通过运行许多不同数值的试验来帮助您找到诸如学习率之类的超参数的最佳值，并寻找最佳值。将配置作为字典允许我们通过运行超参数调优并保存最佳参数来复现最佳参数用于最终模型。'
- en: In [Figure 5-2](#wandb_figure), you can see what a Weights & Biases hyperparameter
    sweep looks like. On the left, we have all the runs in the sweep; each run is
    trying a different set of values that we have specified in the config dictionary.
    In the middle, we see how the final evaluation loss changes over time with the
    number of trials on the sweep. On the right, we have a plot indicating the importance
    of the hyperparameter in affecting the evaluation loss. Here we can see that the
    learning rate has the most effect on the eval loss, followed by the regularization
    amount.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 5-2](#wandb_figure) 中，您可以看到 Weights & Biases 超参数调优的示例。左侧显示了调优中的所有运行；每个运行尝试不同的数值组合，我们在配置字典中指定了这些值。中间显示了随着调优试验次数变化的最终评估损失。右侧显示了影响评估损失的超参数重要性图。在这里，我们可以看到学习率对评估损失有最大影响，其次是正则化量。
- en: '![brpj 0502](assets/brpj_0502.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![brpj 0502](assets/brpj_0502.png)'
- en: Figure 5-2\. Weights & Biases hyperparameter sweep
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-2\. Weights & Biases 超参数调优
- en: On the bottom right of the figure, a parallel coordinates plot shows how each
    parameter affects the evaluation loss. To read the plot, follow each line and
    see where it ends up on the final evaluation loss. The optimal hyperparameters
    can be found by tracing the line from the bottom-right target value of evaluation
    loss back to the left, through the values chosen for the hyperparameters. In this
    case, the optimal value selected is a `learning_rate` of 0.0001618, a regularization
    of 0.2076, and an `output_size` of 64.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在图的右下角，平行坐标图显示了每个参数如何影响评估损失。阅读图表时，请跟随每条线并查看其在最终评估损失上的位置。通过追踪从右下方评估损失的目标值到左侧的线路，可以找到最佳超参数。在这种情况下，选择的最佳数值为学习率为`0.0001618`，正则化为`0.2076`，输出大小为64。
- en: The rest of the code is mostly setting up the model and hooking up the input
    pipeline to the model. Deciding when to log metrics and model serialization is
    mostly self-explanatory. The details can be read in the Flax documentation.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的其余部分主要是设置模型并将输入流水线连接到模型。决定何时记录指标和模型序列化在很大程度上是不言自明的。详情可以参阅Flax文档。
- en: In saving the model, notice that two methods are used. One is a checkpoint,
    and the other is Flax serialization. We have both because the checkpoint is used
    when training jobs are canceled and we need to recover the step at which the job
    was canceled so we can resume training. The final serialization is used when the
    training is done.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在保存模型时，请注意使用了两种方法。一种是检查点，另一种是Flax序列化。我们之所以两者都有，是因为当训练作业被取消时，需要使用检查点来恢复作业取消的步骤，以便能够恢复训练。最终的序列化在训练完成时使用。
- en: We also save a copy of the model as a [Weights & Biases artifact](https://oreil.ly/gmGGt).
    This way, the Weights & Biases platform can keep track of the hyperparameters
    that created the model, the exact code and the exact Git hash that generated the
    model, and the lineage of the model. This lineage consists of upstream artifacts
    used to generate the model (such as the training data), the state of the job used
    to create the model, and an added back link to all future jobs that might use
    the artifact. This makes it easier to reproduce models at a point in time or trace
    back which model was used and at what time in production. This comes in super
    handy when you have a larger organization and folks are hunting around for information
    on how a model was created. By using artifacts, they can simply look in one place
    for the code and training data artifacts to reproduce a model.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将模型保存为[Weights & Biases artifact](https://oreil.ly/gmGGt)的副本。这样，Weights &
    Biases平台可以跟踪创建模型的超参数、确切的代码和生成模型的确切Git哈希，以及模型的衍生线。这条衍生线包括用于生成模型的上游工件（如训练数据）、用于创建模型的作业状态，以及未来可能使用该工件的所有作业的反向链接。在您的组织较大且人员正在寻找有关如何创建模型的信息时，这将非常方便。通过使用工件，他们可以简单地查找代码和训练数据工件的位置以复现模型。
- en: Now that we have trained the models, we want to generate embeddings for the
    scene and the product database. The nice thing about using the dot product as
    a scoring function as opposed to using a model is that you can generate scene
    and product embeddings independently and then scale out these computations at
    inference time. This kind of scaling will be introduced in [Chapter 8](ch08.html#ch:wikipedia-e2e),
    but for now the relevant part of *make_embeddings.py* is shown in [Example 5-7](#example0507).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练了模型，我们希望为场景和产品数据库生成嵌入。与使用模型作为评分函数不同之处在于，您可以独立生成场景和产品嵌入，然后在推断时扩展这些计算。这种扩展将在[第8章](ch08.html#ch:wikipedia-e2e)介绍，但现在我们将显示*make_embeddings.py*的相关部分，如[示例5-7](#example0507)所示。
- en: Example 5-7\. Finding the top-*k* recommendations
  id: totrans-133
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例5-7. 寻找前*k*个推荐
- en: '[PRE12]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As you can see, we simply use the same Flax serialization library to load the
    model, and then call the appropriate method of the model by using the `apply`
    function. We then save the vectors in a JSON file, since we have already been
    using JSON for the scene and product databases.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，我们简单地使用相同的Flax序列化库加载模型，然后使用`apply`函数调用模型的适当方法。然后我们将向量保存在JSON文件中，因为我们已经在场景和产品数据库中使用JSON。
- en: Finally, we’ll use the scoring code in *make_recommendations.py* to generate
    product recommendations for sample scenes ([Example 5-8](#example0508)).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用*make_recommendations.py*中的评分代码为样本场景生成产品推荐（[示例5-8](#example0508)）。
- en: Example 5-8\. Core retrieval definition
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 5-8\. 核心检索定义
- en: '[PRE13]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The most relevant code fragment is the scoring code, where we have a scene embedding
    and want to use JAX to score all the product embeddings instead of a single scene
    embedding. Here we use Lax, a sublibrary of JAX that supplies direct API calls
    to XLA, the underlying ML compiler for JAX, in order to access accelerated functions
    like `top_k`. In addition, we compile the function `find_top_k` by using JAX’s
    JIT. You can pass pure Python functions that contain JAX commands to `jax.jit`
    in order to compile them to a specific target architecture such as a GPU using
    XLA. Notice we have a special argument called `static_argnames`; this allows us
    to inform JAX that `k` is fixed and doesn’t change much so that JAX is able to
    compile a purpose-built `top_k_finder` for a fixed value of `k`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 最相关的代码片段是评分代码，我们在其中有一个场景嵌入，并希望使用 JAX 来评分所有产品嵌入，而不是单个场景嵌入。在这里，我们使用了 JAX 的一个子库
    Lax，提供了直接调用 XLA 的 API，XLA 是 JAX 的底层 ML 编译器，用于访问像`top_k`这样的加速函数。此外，我们通过使用 JAX 的
    JIT 编译函数 `find_top_k`。您可以将包含 JAX 命令的纯 Python 函数传递给 `jax.jit`，以便将它们编译到特定的目标架构，例如使用
    XLA 的 GPU。请注意我们有一个特殊的参数 `static_argnames`；这允许我们告知 JAX，`k` 是固定的，并且不会经常更改，以便 JAX
    能够为一个固定值 `k` 编译一个特定用途的 `top_k_finder`。
- en: '[Figure 5-3](#recommended_items_indoor) shows sample product recommendations
    for a scene in which a woman is wearing a red shirt. The products recommended
    include red velvet and dark pants.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-3](#recommended_items_indoor) 展示了一个女性穿红衬衫场景的产品推荐示例。推荐的产品包括红色天鹅绒和深色裤子。'
- en: '![Recommended items for person wearing a red shirt indoors](assets/brpj_0503.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![穿红衬衫室内推荐物品](assets/brpj_0503.png)'
- en: Figure 5-3\. Recommended items for an indoor scene
  id: totrans-142
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-3\. 室内场景推荐物品
- en: '[Figure 5-4](#recommmended_items_outdoor) shows another scene: a woman is wearing
    a red coat outdoors, and the matching accessories are a yellow handbag and yellow
    pants.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-4](#recommmended_items_outdoor) 展示了另一个场景：一个女性在户外穿着红色外套，搭配的配件是黄色手提包和黄色裤子。'
- en: 'We have pregenerated some results that are stored as an artifact that you can
    view by typing in the following command:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预先生成了一些结果，并将其存储为一个工件，您可以通过输入以下命令查看：
- en: '[PRE14]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: One thing you may notice is that the yellow bag and pants get recommended a
    lot. It may be possible that the embedding vector for the yellow bag is large,
    so it gets matched to a lot of scenes. This is called the *popular item problem*
    and is a common issue with recommendation systems. We cover some business logic
    to handle diversity and popularity in later chapters, but this is a problem that
    can happen with recommendation systems that you might want to keep an eye out
    for.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到黄色包和裤子经常被推荐。黄色包的嵌入向量可能很大，因此会与许多场景匹配。这被称为*流行物品问题*，是推荐系统中的一个常见问题。我们将在后面的章节中涵盖一些处理多样性和流行度的业务逻辑，但这是一个您可能希望留意的推荐系统问题。
- en: '![Recommended items for person wearing a red shirt outdoors](assets/brpj_0504.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![穿红衬衫户外推荐物品](assets/brpj_0504.png)'
- en: Figure 5-4\. Recommended items for an outdoor scene
  id: totrans-148
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-4\. 户外场景推荐物品
- en: Summary
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: And with that, we conclude the first “Putting It All Together” chapter. We covered
    how to use JAX and Flax to read real-world data, train a model, and find the top
    recommended items for a look. If you haven’t played with the code yet, hop on
    over to the GitHub repo to give it a whirl! We hope that providing a real-world
    working example of an end-to-end content-based recommender will give you a better
    feel for how the theory translates into practice. Enjoy playing with the code!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们完成了第一个“全面介绍”章节。我们讲解了如何使用 JAX 和 Flax 来读取现实世界的数据，训练模型，并找出一个外观的顶级推荐物品。如果你还没有尝试过这些代码，请移步到
    GitHub 仓库来试试看吧！我们希望通过提供一个实际工作的内容推荐器的示例，让你更好地理解理论如何转化为实践。享受与代码的互动吧！
