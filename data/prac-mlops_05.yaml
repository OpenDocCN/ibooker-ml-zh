- en: Chapter 5\. AutoML and KaizenML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章 自动机器学习（AutoML）与改善机器学习（KaizenML）
- en: By Noah Gift
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：Noah Gift
- en: Held down too hard by rules, partial thoughts cannot blossom. Rules without
    ideas is prison. Ideas without rules is chaos. Bonsai teaches us balance. Balancing
    rules against innovation is a pervasive problem in all of life. I once saw a play
    entitled “The Game of Life.” The message was that one is often asked to play the
    game for high stakes before anybody has explained the rules. Moreover, it’s not
    so easy to tell if you are winning. It often seems that beginners (and young people
    generally) need rules or broad theories for guidance. Then, as experience accumulates,
    the many exceptions and variations gradually invalidate the rules at the same
    time that the rules become less needed. A great advantage of bonsai over Life
    is that one can learn from fatal mistakes.
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 过于受规则束缚，部分想法无法绽放。没有思想的规则是监狱，没有规则的思想是混乱。盆景教给我们平衡。在生活的各个方面，平衡规则与创新是一个普遍存在的问题。我曾经看过一出名为《人生游戏》的戏剧。它传达的信息是，在任何人解释规则之前，人们常常被要求为高风险玩游戏。此外，要判断自己是否赢得了比赛也不是那么容易。通常情况下，初学者（尤其是年轻人）需要规则或广泛的理论作为指导。然后，随着经验的积累，许多例外和变化逐渐使规则失效，同时规则的需求也减少了。盆景相比于人生的一大优势在于人们可以从致命的错误中学习。
- en: ''
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Dr. Joseph Bogen
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Joseph Bogen 博士
- en: It is an exciting time to be involved in build machine learning systems. Machine
    learning, i.e., learning from data, has a clear value to humanity in solving problems
    from autonomous vehicles to more effective cancer screening and treatment. At
    the same time, automation plays a critical role in enabling this advancement in
    the automation of model creation, AutoML, and the rest of the tasks surrounding
    machine learning, something I call KaizenML.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是参与构建机器学习系统的一个激动人心的时刻。机器学习，即从数据中学习，对解决从自动驾驶车辆到更有效的癌症筛查和治疗等问题具有明确的价值。与此同时，自动化在推动这一领域的进展中扮演了关键角色，包括模型创建的自动化、AutoML
    和机器学习周围其他任务的自动化，我称之为KaizenML。
- en: While AutoML is focused strictly on creating a model from clean data, KaizenML
    is about automating *everything* about the machine learning process and improving
    it. Let’s dive into both topics starting with the reason why AutoML is so essential.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 AutoML 严格专注于从干净数据中创建模型，但 KaizenML 则致力于自动化*机器学习*过程中的一切并对其进行改进。让我们深入讨论这两个主题，从
    AutoML 为何如此重要开始。
- en: Note
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Experts in machine learning, like Andrew Ng, now acknowledge that a data-centric
    approach has merits over a model-centric process. Another way of stating this
    is that Kaizen, i.e., continuous improvement of the entire system from the data
    to the software, to the model, to the feedback loop from the customer, is essential.
    KaizenML, in my mind, means you are improving all aspects of a machine learning
    system: data quality, software quality, and model quality.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 像安德鲁·吴（Andrew Ng）这样的机器学习专家现在承认，数据中心的方法比模型中心的过程更有优势。另一种表述是，改善，即从数据到软件再到模型，再到来自客户的反馈循环的整个系统的持续改进，是至关重要的。在我看来，KaizenML
    意味着你正在改善机器学习系统的所有方面：数据质量、软件质量和模型质量。
- en: AutoML
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AutoML
- en: The author Upton Sinclair famously said, “it’s difficult to get a man to understand
    something when his salary depends on his not understanding it.” An excellent example
    of the Upton Sinclair quote in action is the misinformation from social media
    documented in the Netflix documentary, *The Social Dilemma*. Suppose you work
    at a company that spreads misinformation at scale and gets paid very well. In
    that case, it is almost impossible to accept that you are an actor in that process,
    and your company does, in fact, profit handsomely from misinformation. It contributes
    to your excellent salary and lifestyle.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 作者厄普顿·辛克莱尔（Upton Sinclair）曾经著名地说过：“当一个人的薪水依赖于他不理解某事时，要让他理解某事是困难的。” 厄普顿·辛克莱尔的这句话在
    Netflix 的纪录片《社交迷局》中所记录的社交媒体误导中得到了很好的体现。假设你在一家大规模传播误导信息并因此获得丰厚报酬的公司工作。在这种情况下，几乎不可能接受你是这一过程中的参与者，而且你的公司实际上从误导信息中获得了丰厚的利润。这为你提供了优厚的薪水和生活方式的贡献。
- en: Similarly, I have come up with something I call the Automator’s law. Once the
    conversation about automating a task begins, then eventually, the automation occurs.
    Some examples include replacing data centers with cloud computing and replacing
    telephone switchboard operators with machines. Many companies have held on to
    their data centers with “white knuckles,” saying the cloud was the root of all
    evil in the world. Yet, eventually, they either switched to the cloud or are in
    the process of switching to the cloud.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我想出了一些我称之为“自动化定律”的东西。一旦开始讨论自动化任务，最终自动化就会发生。一些例子包括用云计算取代数据中心和用机器取代电话总机操作员。许多公司紧紧抓住他们的数据中心，说云是世界上所有邪恶的根源。然而，最终，他们要么转向云，要么正在过渡到云中。
- en: It took almost 100 years, from around 1880 to 1980, to fully automate switching
    calls by hand to make a machine do them, but it happened. Machines are great at
    automating labor-intensive manual tasks. If your job involved switching telephone
    calls in 1970, you might have scoffed at the idea of automating what you did since
    you understood how difficult the task was. Today, with data science, it may be
    that we are switchboard operators furiously pushing hyperparameter values into
    Python functions and sharing our results on Kaggle, unaware that all of this is
    in the process of being automated away.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从大约1880年到1980年左右，完全自动化手动切换电话通话花了近100年时间，使一台机器可以完成这些任务，但这确实发生了。机器非常擅长自动化劳动密集型的手动任务。如果你的工作在1970年涉及切换电话通话，你可能会嘲笑自动化你所做的事情的想法，因为你理解这个任务有多么困难。今天，通过数据科学，可能我们正在像狂热地将超参数值推入Python函数并在Kaggle上分享结果的电话总机操作员一样，不知道所有这一切正在被自动化地进行中。
- en: 'In the book, *How We Know What Isn’t So*, Thomas Gilovich points out self-handicapping
    strategies:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在书中，《我们如何知道什么不是真的》，托马斯·吉洛维奇指出了自我限制策略：
- en: There really are two classes of self-handicapping strategies, real and feigned.
    “Real” self-handicapping involves placing visible obstacles to success in one’s
    own path. The obstacles make one less likely to succeed, but they provide a ready
    excuse for failure. The student who neglects to study before an exam or the aspiring
    actor who drinks before an audition are good examples. Sometimes failure is all
    but guaranteed, but at least one will not be thought to be lacking in the relevant
    ability (or so it is hoped).
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 实际上有两类自我限制策略，真实和假装的。 “真实”自我限制涉及将可见的成功障碍放置在自己的道路上。这些障碍使成功的可能性较小，但它们为失败提供了一个现成的借口。在考试前不学习的学生或在试镜前饮酒的有抱负的演员都是很好的例子。有时候失败几乎是必然的，但至少不会被认为缺乏相关能力（或者至少希望如此）。
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “Feigned” self-handicapping, on the other hand, is in certain respects a less
    risky strategy, one in which the person merely claims that there were difficult
    obstacles in the path to success. This kind of self-handicapping consists simply
    of making excuses for possible bad performance, either before or after the fact.
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “假”自我限制，另一方面，从某些方面来说，是一种风险较小的策略，这种策略仅仅是声称在成功的道路上存在困难障碍。这种自我限制仅仅是为可能的糟糕表现找借口，无论是事前还是事后。
- en: When data science initiatives fail, it is easy to dive into either of these
    self-handicapping strategies. An example of this in data science could be by not
    using AutoML when it could help with certain aspects of a project; this is a “real”
    handicap to its success. However, one of the golden rules of software engineering
    is to use the best tools you can for the task at hand. The reason to use the best
    tools available is they reduce the complexity of the software developed. An excellent
    example of a “best in class” tool that reduces complexity is GitHub Actions because
    it is simple to create automated testing. Another example is an editor like Visual
    Studio Code because of its ability to perform code completion, syntax highlighting,
    and linting with minimal configuration. Both of these tools dramatically increase
    developer productivity by simplifying the process of creating software.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学计划失败时，很容易陷入其中任何一种自我限制策略。在数据科学中的一个例子可能是在项目的某些方面不使用AutoML；这对项目的成功来说是一个“真正”的障碍。然而，软件工程的一个黄金法则是在手头任务中使用最好的工具。使用可用的最佳工具的原因是它们减少了开发的软件的复杂性。一个减少复杂性的“最佳类”工具的绝佳例子是GitHub
    Actions，因为它可以简化自动化测试的创建。另一个例子是像Visual Studio Code这样的编辑器，因为它能够进行代码完成、语法高亮和最小配置的linting。这两种工具通过简化软件创建的过程显著提高了开发人员的生产力。
- en: With data science, this mantra of “use the best tools available” needs evangelism.
    Alternatively, if a data science project fails, as they often do, a self-handicapping
    strategy could be to say the problem was too challenging. In either case, an embrace
    of automation, when appropriate, is the solution to self-handicapping.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，“使用最佳可用工具”的口号需要宣传。或者，如果一个数据科学项目失败（通常情况下会失败），自我限制的策略可能是说问题太具挑战性了。在任何情况下，当适用时，自动化的采纳是自我限制的解决方案。
- en: Let’s compare food to machine learning in [Figure 5-1](#Figure-5-1). Notice
    that food comes in many forms, from the flour you buy at the store to make your
    own pizza to the one you have delivered to your house. Just because one is much
    more complex than another (i.e., making a pizza from scratch versus ordering a
    ready-made hot pizza) it doesn’t mean that the home delivery option isn’t also
    considered food. Difficulty, or lack thereof, does not equate with completeness
    or realness.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较食物与机器学习在 [图 5-1](#Figure-5-1) 中。请注意，食物有多种形式，从你在商店购买的面粉制作披萨到送货上门的披萨。即使其中一种比另一种复杂得多（例如，从头开始制作披萨与订购现成的热披萨），也并不意味着送货上门的选择就不算是食物。难度与否并不等同于完整性或真实性。
- en: Similarly, not accepting reality doesn’t mean that it’s not happening. Another
    way of describing denying reality is to call it “magical thinking.” Many magical
    thinkers said at the start of the COVID-19 pandemic, “This is just like the flu,”
    as a way to reassure themselves (and others) that the danger was not as bad as
    it appeared to be. The data in 2021 says something entirely different, though.
    COVID-19 in the USA approached about 75% of the deaths of all combined forms of
    heart disease, currently the leading cause of death in the USA. Similarly, Justin
    Fox in a [Bloomberg article](https://oreil.ly/0sXwI) using the CDC data shows
    that this pandemic is multiple times more deadly for most age groups than influenza.
    See [Figure 5-2](#Figure-5-2).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，不接受现实并不意味着事情并未发生。形容否认现实的另一种方式是称之为“魔幻思维”。许多魔幻思想家在 COVID-19 疫情初期说：“这只是流感”，试图安抚自己（及他人），认为危险并没有看起来那么严重。然而，2021年的数据完全说明了不同的情况。在美国，COVID-19
    的死亡人数接近所有形式心脏病的死亡人数的75%，而心脏病目前是美国的主要死因。同样，贾斯汀·福克斯在一篇使用 CDC 数据的[彭博新闻文章](https://oreil.ly/0sXwI)中指出，对大多数年龄段来说，这场大流行比流感致命多次。见
    [图 5-2](#Figure-5-2)。
- en: '![pmlo 0501](Images/pmlo_0501.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0501](Images/pmlo_0501.png)'
- en: Figure 5-1\. Food versus ML
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-1\. 食物与 ML 的比较
- en: '![pmlo 0502](Images/pmlo_0502.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0502](Images/pmlo_0502.png)'
- en: 'Figure 5-2\. Covid versus the flu and pneumonia (source: [Bloomberg News](https://oreil.ly/pUEFc))'
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-2\. COVID-19 与流感和肺炎的比较（来源：[彭博新闻](https://oreil.ly/pUEFc)）
- en: 'AutoML is an inflection point for data scientists because it shares similarities
    to other historical trends: automation and magical thinking. Anything that can
    automate will automate. Accepting this trend instead of fighting it will lead
    to massively more productive workflows in machine learning. AutoML, in particular,
    may be one of the most critical technologies to embrace to implement the MLOps
    philosophy fully.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML 对数据科学家来说是一个拐点，因为它与其他历史趋势（自动化和魔幻思维）类似。任何能自动化的都将自动化。接受这一趋势而不是与之抗争将会在机器学习的工作流程中大大提升生产力。特别是，AutoML
    可能是全面实施 MLOps 理念中最关键的技术之一。
- en: Before the COVID-19 outbreak, a research scientist from UC Berkeley, Dr. Jennifer
    Doudna, and collaborator Dr. Emmanuelle Charpentier worked on the difficult task
    of researching gene editing. When the COVID-19 pandemic began, Dr. Doudna knew
    she needed to quickly convert this research into a groundbreaking way to accelerate
    the creation of a vaccine. As a result, she started work to “save the world.”
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在 COVID-19 爆发之前，加州大学伯克利分校的研究科学家珍妮弗·道德纳博士与合作者埃玛纽埃尔·夏朋提尔博士致力于研究基因编辑的艰巨任务。当 COVID-19
    疫情开始时，道德纳博士意识到她需要迅速将这项研究转化为一种开创性的方法，以加速疫苗的研发。因此，她开始了“拯救世界”的工作。
- en: Note
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: How is COVID-19 drug discovery related to MLOps? A critical problem in data
    science is getting a research solution into production. Similarly, a fundamental
    problem with medical research is getting the discovery into the hands of a patient
    who benefits from it.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: COVID-19 药物发现与 MLOps 有何关联？数据科学中的一个关键问题是将研究解决方案投入生产。同样，医学研究的一个基本问题是将发现带到从中受益的患者手中。
- en: 'In *The Code Breaker: Jennifer Doudna, Gene Editing, and the Future of the
    Human Race* (Simon & Schuster Australia), Walter Isaacson describes how Dr. Doudna
    was “…now a strong believer that basic research should be combined with translational
    research, moving discoveries from bench to bedside…” The now Nobel Prize–winning
    scientist Dr. Jennifer Doudna is co-credited, along with Dr. Emmanuelle Charpentier,
    with creating the research that led to gene editing and commercial application
    of these CRISPR mechanisms.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在《*破译者：詹妮弗·道德纳、基因编辑与人类未来*》（Simon & Schuster Australia）中，沃尔特·艾萨克森描述了道德纳博士现在“…现在强烈认为基础研究应与转化研究结合，将发现从实验室推广到床边…”
    现在，诺贝尔奖获得者詹妮弗·道德纳博士与埃曼纽尔·夏朋蒂埃博士共同创造了导致基因编辑和CRISPR机制商业应用的研究。
- en: One of her rivals, Dr. Feng Zhang, who eventually worked on a competing vaccine,
    Moderna, mentioned that the UC Berkeley lab wasn’t working on applying this in
    human cells. His critique is that his lab was working on using the CRISPR research
    by targeting human cells, while Dr. Doudna was focused strictly on the research.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 她的竞争对手之一，最终参与竞争疫苗现代纳公司的冯·张博士提到，加州大学伯克利分校实验室并未致力于将其应用于人类细胞。他批评说，他的实验室正在利用CRISPR研究来针对人类细胞，而道德纳博士则专注于研究本身。
- en: This critique is the heart of a patent dispute about who gets to claim credit
    for these discoveries, i.e., how much work was research and how much was the application
    of the research? Doesn’t this sound a bit similar to the data science versus software
    engineering disputes? Ultimately, Dr. Doudna did, in fact, “get it to production”
    in the form of the Pfizer vaccine. I recently got this vaccine, and like many
    people, I am thrilled it made it to production.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种批评是关于谁应该声称这些发现的专利争议的核心，即多少工作是研究，多少是研究应用？这听起来有点像数据科学与软件工程的争论，不是吗？最终，道德纳博士确实“将其投入生产”形式化为辉瑞疫苗。我最近接种了这种疫苗，像许多人一样，我为其投入生产感到高兴。
- en: What else could we collectively accomplish if we had the same sense of urgency
    as the scientists “operationalizing” the vaccine for COVID-19? When I was an engineering
    manager at startups, I liked to ask people hypothetical questions. Some variant
    of “What if you had to save the world on a deadline”? I like this question because
    it cuts to the heart of things quickly. It cuts to the nature of the problem because
    if the clock is ticking on saving millions of lives, you work only on the essential
    components of the problem.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们像“运作”COVID-19疫苗的科学家们一样急迫地解决问题，我们还能共同完成什么？当我在初创企业担任工程经理时，我喜欢问人们假设性问题。一些变体问题是“如果你必须在截止日期前拯救世界呢”？我喜欢这个问题，因为它能迅速切中要害。它迅速切入问题的本质，因为如果时钟在倒计时拯救数百万生命，你只会解决问题的基本要素。
- en: 'There is an incredible documentary on Netflix entitled *World War II in Colour*.
    What is impressive about the documentary is that it shows the actual restored
    and colorized footage of tragic historical events. This really helps you imagine
    what it might have been like to be present during those events. Along those lines,
    imagine yourself in a situation where you need to solve a technical problem that
    would save the world. Of course, if you get it wrong, everyone you know will suffer
    a horrible fate. However, AutoML or any form of automation coupled with a sense
    of urgency in solving only the necessary components of a problem can lead to better
    outcomes globally: i.e., drug discovery and cancer detection.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Netflix有一部令人难以置信的纪录片名为《*第二次世界大战的彩色影像*》。关于这部纪录片令人印象深刻的地方在于，它展示了那些历史悲剧事件的真实修复和上色的影像。这真的帮助你想象当时亲历那些事件是什么感觉。在这些线索中，想象一下自己身处一个需要解决能拯救世界的技术问题的情境。当然，如果你搞错了，你所知道的每个人都将遭受可怕的命运。然而，自动机器学习或任何形式的自动化结合问题的紧急性，只解决问题的必要组成部分，可以导致全球更好的结果：例如，药物发现和癌症检测。
- en: This form of situational thinking adds a clarifying component to deciding how
    to solve a problem. Either what you are doing matters, or it doesn’t. It is very
    similar to the way the scientists working on COVID-19 vaccines thought. Either
    what the scientists did led to a faster COVID-19 vaccine, or it didn’t. As a result,
    every day wasted was a day that more people worldwide succumbed to the virus.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情境思维方式为决定如何解决问题增加了一个澄清的组成部分。无论你在做什么，都很重要，否则就无关紧要。这与工作在COVID-19疫苗上的科学家们的方式非常相似。要么科学家们所做的导致了更快的COVID-19疫苗，要么没有。因此，每天的浪费都是更多全球人口被病毒夺去的一天。
- en: Similarly, I remember going to a fancy startup in the Bay Area around 2016 and
    remarking on how they received 30M funding from many top-name venture capital
    firms. The COO then privately told me how he was very concerned that they had
    no actual product or way to make money. They received even more money many years
    later, and I am still unsure what their actual product is.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我记得在2016年左右去过旧金山湾区的一个时髦初创公司，并评论说他们从许多顶级风险投资公司获得了3000万美元的资金。首席运营官私下告诉我，他非常担心他们没有实际产品或赚钱的途径。多年后，他们甚至获得了更多的资金，但我仍然不确定他们的实际产品是什么。
- en: Because this company cannot create revenue, it fundraises. If you cannot fundraise,
    then you must create revenue. Likewise, if you cannot put your model into production
    with machine learning, you continue to do “ML research,” i.e., working away at
    tweaking hyperparameters on a Kaggle project. So a good question for Kaggle practitioners
    to ask is, “Are we sure we aren’t just automating our job of tweaking hyperparameters
    by training Google’s AutoML technology?”
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这家公司无法创造收入，所以进行筹款。如果你无法筹款，那么你必须创造收入。同样，如果你无法将你的机器学习模型投入生产，你就会继续做“ML研究”，即在Kaggle项目上不断调整超参数。因此，Kaggle从业者应该问的一个好问题是，“我们确定我们不只是通过训练谷歌的AutoML技术来自动化调整超参数的工作吗？”
- en: We gravitate toward what we excel at doing. There are many beautiful things
    about focusing on what you do well, such as it leading to a successful career.
    Still, there are also times to challenge yourself to temporarily think situationally
    about solving a problem in the most urgent manner possible, much like Drs. Doudna
    and Zhang did with COVID-19\. Does this change the approach you use? For example,
    if I had four hours to train a model and put it into production to save the world,
    I would write as little code as possible and use off-the-shelf automation tools
    like Azure AutoML, Apple Create ML, Google AutoML, H20, or Ludwig. In that case,
    the follow-up question becomes, why am I writing *any* code, or at least writing
    the least amount of code possible for all machine learning engineering projects?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们倾向于擅长的事情。专注于自己擅长的事情有许多美好之处，比如会带来成功的职业生涯。然而，有时候也需要挑战自己，暂时从解决问题的最紧急方式出发，就像Doudna博士和Zhang博士在COVID-19方面所做的那样。这会改变你的方法吗？例如，如果我有四个小时来训练一个模型并将其投入生产以拯救世界，我会尽量少写代码，并使用Azure
    AutoML、Apple Create ML、Google AutoML、H20或Ludwig等现成的自动化工具。在这种情况下，后续问题就变成了，为什么我要写*任何*代码，或者至少为所有机器学习工程项目写尽可能少的代码？
- en: 'The world needs high-quality machine learning models in production, particularly
    because there are many urgent problems to solve: finding a cure for cancer, optimizing
    clean energy, improving drug discovery, and creating safer transportation. One
    way society can collectively do this is to automate what can be automated now
    and focus on finding ways to automate what cannot be automated today.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 世界需要高质量的机器学习模型投入生产，特别是因为有许多紧急问题需要解决：寻找治愈癌症的方法，优化清洁能源，改进药物发现和创造更安全的交通。社会可以通过现在可以自动化的事物来集体做到这一点，并致力于找到今天无法自动化的事物的自动化方法。
- en: AutoML is the automation of the tasks related to training a model on clean data.
    Not all problems are so simple in the real world, though, and as a result *everything*
    related to machine learning needs automation. This gap is where KaizenML steps
    in. Kaizen, in Japanese, means continuous improvement. With KazienML, you continuously
    improve and automate as the central way you develop machine learning systems.
    Let’s dive into that concept next.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML是与在干净数据上训练模型相关的任务自动化。然而，在现实世界中，并非所有问题都那么简单，因此与机器学习相关的*所有*事物都需要自动化。这就是KaizenML介入的地方。Kaizen在日语中意味着持续改进。有了KazienML，您可以持续改进和自动化作为开发机器学习系统的核心方式。接下来让我们深入探讨这个概念。
- en: MLOps Industrial Revolution
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps工业革命
- en: Many students and practitioners of machine learning find AutoML to be a polarizing
    topic. Data science is a behavior; AutoML is a technique—they are a small part
    of building an ML system, and they are complementary. AutoML is polarizing because
    data scientists assume it will replace their job, when in fact, AutoML is 5% of
    a gigantic process of automation and continuous improvement, i.e., MLOps/ML engineering/KaizenML,
    as described in [Figure 5-3](#Figure-5-3-1).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习的学生和从业者认为AutoML是一个极具争议的话题。数据科学是一种行为，而AutoML是一种技术——它们只是构建ML系统的一小部分，它们是互补的。AutoML之所以具有争议，是因为数据科学家们认为它会取代他们的工作，然而事实上，AutoML只是自动化和持续改进的一个极小部分，即MLOps/ML工程/KaizenML，如[图5-3](#Figure-5-3-1)所述。
- en: '![AutoML is a tiny part of KaizenML](Images/pmlo_0503.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![AutoML 是 KaizenML 的一个微小部分](Images/pmlo_0503.png)'
- en: Figure 5-3\. AutoML is a tiny part of KaizenML
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-3\. AutoML 是 KaizenML 的一个微小部分
- en: The industrial revolution from 1760–1840 was a period of dramatic movement of
    human tasks to automated ones powered by steam and coal machines. This automation
    led to a rise in population, GDP, and quality of life. Later, around 1870, the
    second industrial revolution occurred, allowing for mass production and new electrical
    grid systems.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从1760年到1840年的工业革命是人类任务由蒸汽和煤炭机器驱动的自动化过程中的一段充满戏剧性的时期。这种自动化导致人口增长、国内生产总值和生活质量的提高。后来，大约在1870年，第二次工业革命发生了，允许大规模生产和新的电网系统。
- en: There is an excellent series on Disney+ called [*Made in a Day*.](https://oreil.ly/nLA7Y)
    The first episode shows how Tesla uses robots for car development phases. The
    robots screw in things, bolt things on, and weld parts together. When looking
    at this factory, I think about how humans are assisting the robots. Essentially,
    they feed the robots work that they cannot yet fully automate themselves.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Disney+ 上有一部名为 [*Made in a Day*](https://oreil.ly/nLA7Y) 的优秀系列。第一集展示了特斯拉如何使用机器人进行汽车开发阶段。机器人会螺丝紧东西、将东西螺栓在一起并焊接零件。当看到这个工厂时，我想到人类是如何协助机器人的。基本上，他们把那些他们自己尚不能完全自动化的工作交给了机器人。
- en: Likewise, when looking at traditional data science workflows full of unique
    snowflake configurations, with humans “bolting on” hyperparameters, it makes me
    think of an early Ford assembly plant in the second industrial revolution. Eventually,
    manual human tasks get automated, and the first thing that is automated is the
    easiest to automate.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，当观察到充满独特雪花配置的传统数据科学工作流程，并且人类“紧固”超参数时，让我想到第二次工业革命中早期的福特装配厂。最终，手动的人类任务被自动化，而第一件被自动化的事情是最容易自动化的。
- en: Another question people ask is whether many aspects of machine learning techniques
    are even necessary, like manually adjusting hyperparameters, i.e., picking the
    number of clusters. Imagine going to a Tesla factory full of advanced robotics
    and telling the automation engineers that humans can also weld parts together.
    This statement would be a non sequitur. Of course, we humans can perform tasks
    that machines do better than us, but should we? Likewise, with many tedious and
    manual aspects of machine learning, machines do a better job.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 人们还问的另一个问题是，机器学习技术的许多方面是否真的必要，比如手动调整超参数，即选择聚类数。想象一下去到一个充满先进机器人技术的特斯拉工厂，并告诉自动化工程师人类也可以焊接零件。这种说法是不合逻辑的。当然，我们人类可以执行比我们更好的机器任务，但我们应该吗？同样地，对于许多繁琐和手动的机器学习方面，机器表现得更好。
- en: What may occur soon in machine learning and artificial intelligence is that
    the technique is essentially commoditized. Instead, the automation itself and
    the ability to execute the automation is the key. The TV show about physical manufacturing
    has the name “Made in a Day” because cars or guitars manufacture in just one day!
    Many companies doing machine learning cannot build one software-based model in
    an entire year, though how could this possibly be the future process?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习和人工智能领域可能很快发生的事情是，技术本质上会成为商品化。相反，自动化本身及其执行能力才是关键。关于物理制造的电视节目名称为“Made in
    a Day”，因为汽车或吉他只需一天制造！许多从事机器学习的公司在整整一年内都无法建立一个基于软件的模型，尽管这可能是未来的过程。
- en: One possible scenario that I see happening soon is that at least 80% of data
    science manual training models are replaced with commoditized open source AutoML
    tools or downloaded pre-built models. This future could happen as both open source
    projects like Ludwig or commercial projects like Apple CreateML advance in sophistication.
    Software for training machine learning models could turn into something like the
    Linux kernel, free and ubiquitous.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我看到可能很快发生的一个场景是，至少80%的数据科学手动训练模型将被商品化的开源 AutoML 工具或下载的预构建模型所取代。这一未来可能会因开源项目（如
    Ludwig）或商业项目（如 Apple CreateML）的发展而实现。用于训练机器学习模型的软件可能会变成像 Linux 内核那样自由和无处不在。
- en: 'If they are in their current form, data science could go bimodal; either you
    get paid $1M/year, or you’re entry-level. Most competitive advantages go into
    traditional software engineering best practices: data/users, automation, execution,
    and solid product management and business practices. A data scientist could become
    a standard skill like accounting, writing, or critical thinking in other cases
    instead of a job title alone. You could call this the MLOps industrial revolution.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果按照现有形式进行，数据科学可能会呈双峰分布；要么你年薪百万美元，要么你是初级人员。大部分竞争优势都来自传统软件工程的最佳实践：数据/用户、自动化、执行力，以及坚实的产品管理和业务实践。数据科学家可能会成为一种标准技能，就像会计、写作或其他情况下的批判性思维一样，而不仅仅是一个职业头衔。你可以称之为
    MLOps 工业革命。
- en: '[Figure 5-4](#Figure-5-4) is an example of this in practice. Imagine Kaggle
    as a feedback loop that Google uses to make its AutoML tools much better. Why
    wouldn’t they use the human data scientists’ training models to make better AutoML
    services? In data science 1.0, humans are manually “clicking buttons” just like
    the switchboard operators of the past. Meanwhile, if they wanted, Google could
    use these humans to train their AutoML systems to do these manual data science
    tasks. In data science 2.0, which in many cases is already here, automated tools
    thoroughly train the previously trained models in Kaggle.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-4](#Figure-5-4) 是这一实践的一个例子。想象一下 Kaggle 就像一个反馈环路，谷歌利用它来改进其 AutoML 工具。为什么他们不利用人类数据科学家训练模型来提升他们的
    AutoML 服务呢？在数据科学 1.0 中，人类手动“点击按钮”，就像过去的电话接线员一样。与此同时，如果他们愿意，谷歌可以利用这些人类来训练他们的 AutoML
    系统来执行这些手动数据科学任务。在许多情况下已经出现的数据科学 2.0 中，自动化工具彻底训练了之前在 Kaggle 上训练过的模型。'
- en: '![pmlo 0504](Images/pmlo_0504.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0504](Images/pmlo_0504.png)'
- en: Figure 5-4\. Kaggle automation
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-4\. Kaggle 自动化
- en: 'The MLOps industrial revolution is happening before our eyes as machines play
    an increasing role in machine learning and data science. What skills do you invest
    in if these changes are under way? Be world-class at automation and execution
    both technically and from a business perspective. Also, couple these capabilities
    with solid domain expertise. In the book *How Innovation Works: And Why It Flourishes
    in Freedom* (Harper), author Matt Ridley clearly explains how ideas are not the
    basis of innovation but the combination of the ideas into execution. Essentially,
    does it work or not, and will someone pay you for it?'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习和数据科学中，随着机器在其中的角色日益增加，MLOps 工业革命正在我们眼前发生。如果这些变化正在进行中，你应该投资于哪些技能呢？无论从技术还是业务的角度来看，都要在自动化和执行方面达到世界级水平。此外，要结合坚实的领域专业知识。在《创新如何运作：为何在自由中蓬勃发展》（Harper）一书中，作者马特·里德利清楚地解释了创新并不是构想的基础，而是将构想结合到执行中的过程。本质上是，它是否有效，是否会有人为此付费？
- en: Kaizen Versus KaizenML
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kaizen 与 KaizenML
- en: One problem with talking about data science, AutoML, and MLOps (KaizenML) is
    that people often misunderstand what each one is. Data science is not a solution
    any more than statistics is a solution to a problem; it is behavioral. AutoML
    is just a technique, like continuous integration (CI); it automates trivial tasks.
    Subsequently, AutoML is not directly competing with data science; cruise control,
    or semi-autonomous driving for that matter, doesn’t compete with a car driver.
    The driver still must control the vehicle and act as the central arbitrator of
    what happens. Likewise, even with extensive automation in machine learning, a
    human must make executive decisions about the bigger picture.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 谈论数据科学、AutoML 和 MLOps（KaizenML）存在一个问题，那就是人们经常误解它们各自的含义。数据科学不再是解决方案，就像统计学不是解决问题的方案一样；它是一种行为。AutoML
    只是一种技术，就像持续集成（CI）一样；它自动化了琐碎的任务。因此，AutoML 并不直接与数据科学竞争；而像巡航控制或半自动驾驶这样的技术，也不会与司机竞争。司机仍然必须控制车辆，并充当发生事件的中央仲裁者。同样地，即使在机器学习中有了广泛的自动化，人类仍然必须就更大的局面做出执行决策。
- en: KaizenML/MLOps is a systems methodology that leads to models in production.
    Machine learning models running in production solving customer problems is the
    outcome of MLOps. In [Figure 5-5](#Figure-5-5), you can see a hypothetical MLOps
    industrial revolution that could occur in the future. Data and the expertise in
    handling data effectively becomes a competitive advantage since it is a scarce
    resource. As AutoML technology progresses, it is possible many things data scientists
    do today go away. It is uncommon to find modern vehicles without a form of cruise
    control or with manual transmission. Likewise, it may be infrequent for data scientists
    to adjust hyperparameters in the future. What could happen then is that current
    data scientists turn into ML engineers or domain experts who “do data science”
    as part of their job.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: KaizenML/MLOps是一种系统方法论，导致模型投入生产。在[图 5-5](#Figure-5-5)中，您可以看到未来可能发生的假设的MLOps工业革命。数据及其有效处理的专业知识因为是一种稀缺资源而成为竞争优势。随着AutoML技术的进步，今天许多数据科学家做的事情可能会消失。现代车辆很少不配备某种形式的巡航控制或手动变速器。同样，将来数据科学家很少需要调整超参数也可能会不常见。那么当前的数据科学家可能会转变为ML工程师或领域专家，他们作为工作的一部分“从事数据科学”。
- en: '![pmlo 0505](Images/pmlo_0505.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0505](Images/pmlo_0505.png)'
- en: Figure 5-5\. MLOps industrial revolution
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-5\. MLOps工业革命
- en: 'One issue with talking only about AutoML versus data science is that it trivializes
    the more significant automation and continuous improvement issues. The automation
    of machine learning techniques is so polarizing that the core issue disappears:
    everything should be automated, not just the tedious aspects of ML-like hyperparameter
    tuning. Automation through continuous improvement allows data scientists, ML engineers,
    and entire organizations to focus on what matters, i.e., execution. As you can
    see illustrated in [Figure 5-6](#Figure-5-6), Kaizen is a Japanese term for continuous
    improvement. In post–World War II, Japan builds its automobile industry around
    this concept. Essentially, if you find something broken or unoptimized, you fix
    it. Likewise, with KaizenML, every aspect of machine learning, from feature engineering
    to AutoML, is improved.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅谈论AutoML与数据科学的问题在于，它淡化了更重要的自动化和持续改进问题。机器学习技术的自动化如此极化，以至于核心问题被忽视：一切都应该自动化，不仅仅是像超参数调优这样单调乏味的部分。通过持续改进的自动化使数据科学家、机器学习工程师和整个组织能够专注于重要的事情，即执行。正如您可以在[图 5-6](#Figure-5-6)中看到的那样，改善是日本的一个术语，意为持续改进。二战后，日本围绕这一概念建立了其汽车工业。本质上，如果发现了问题或未经优化的地方，就应该修复它。同样，通过KaizenML，从特征工程到AutoML，机器学习的每个方面都在不断改进。
- en: '![pmlo 0506](Images/pmlo_0506.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0506](Images/pmlo_0506.png)'
- en: Figure 5-6\. Kaizen or AutoML
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-6\. Kaizen或AutoML
- en: Every human on earth should do data science and programming because these are
    forms of critical thinking. The recent pandemic was a big wake-up call about how
    important to an individual’s life understanding data science is. Many people died
    because they didn’t understand the data that showed COVID-19 was not, in fact,
    just like the flu; it was much, much more deadly. Likewise, stories abound about
    people refusing to get a vaccine because they incorrectly calculated the risk
    the vaccine posed to themselves versus the risk COVID-19 posed to themselves or
    vulnerable members of their community. Understanding data science can save your
    life, and therefore, anyone should have access to the tools data scientists have.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 地球上的每个人都应该做数据科学和编程，因为这些都是批判性思维的形式。最近的大流行病是一个关于理解数据科学对个人生活至关重要的重要警示。许多人死于他们没有理解到显示COVID-19并不像流感那样仅仅是因为它更加致命的数据；同样，关于人们因错误计算疫苗对他们自己或其社区脆弱成员的风险相对于COVID-19对他们自己的风险的故事也充斥着。理解数据科学可以拯救你的生命，因此，任何人都应该有数据科学家所拥有的工具。
- en: These tools are “human rights” that don’t belong in the hands of an elite priesthood.
    It is a non sequitur to suggest “elite” people only can write simple programs,
    understand machine learning, or do data science. Automation will make data science
    and programming easy enough that every human being will do it, and in many cases,
    they can do so using even the existing automation available.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具是“人权”，不应该只属于精英僧侣的手中。暗示“精英”人士才能写简单程序、理解机器学习或从事数据科学是不合逻辑的。自动化将使数据科学和编程变得足够简单，以至于每个人都可以做到，而且在许多情况下，他们甚至可以利用现有的自动化来做到。
- en: KaizenML/MLOps is about a narrow focus on solving problems with machine learning
    and software engineering (influenced by DevOps) to lead to business value or improvement
    of the human condition, e.g., cure cancer.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: KaizenML/MLOps专注于通过机器学习和受DevOps影响的软件工程解决问题，以实现业务价值或改善人类条件，例如治愈癌症。
- en: Feature Stores
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征存储
- en: All complex software systems require automation and simplification of critical
    components. DevOps is about automating the testing and deployment of software.
    MLOps is about doing this and also improving the quality of both data and machine
    learning models. I have previously called these continuous improvements of both
    data and machine learning models KaizenML. One way to think about this is that
    DevOps + KaizenML = MLOps. KaizenML includes building Feature Stores, i.e., a
    registry of high-quality machine learning inputs and the ability to monitor data
    for drift and register and serve out ML models.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 所有复杂的软件系统都需要自动化和简化关键组件。DevOps是关于自动化软件测试和部署。MLOps不仅仅是这样，还要提高数据和机器学习模型的质量。我之前称这些对数据和机器学习模型的持续改进为KaizenML。一种思考方式是，DevOps
    + KaizenML = MLOps。KaizenML包括构建特征存储，即高质量机器学习输入的注册以及监测数据漂移、注册和服务化ML模型。
- en: In [Figure 5-7](#Figure-5-7-1), note that in manual data science, everything
    is bespoke. As a result, the data is low quality, and it is hard to even get to
    the point where a working model goes into production and solves a problem. However,
    as more things get automated from data to features, via a Feature Store, to the
    actual serving out of the model in production, it leads to a better outcome.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 5-7](#Figure-5-7-1)中，请注意在手动数据科学中，一切都是定制的。因此，数据质量较低，甚至很难使工作模型进入生产并解决问题。然而，随着从数据到特征再到实际在生产中服务模型的自动化增加，这导致了更好的结果。
- en: '![pmlo 0507](Images/pmlo_0507.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0507](Images/pmlo_0507.png)'
- en: Figure 5-7\. Feature Stores as part of KaizenML
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-7\. 特征存储作为KaizenML的一部分
- en: 'Heavily related to KaizenML, i.e., continuously improving machine learning,
    is the concept of a Feature Store. The Uber Engineering blog has a good breakdown
    of what problem a [Feature Store solves](https://oreil.ly/ej36j). According to
    Uber, it does two things:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 与KaizenML密切相关的是特征存储的概念，即持续改进的机器学习。Uber工程博客对[特征存储解决的问题](https://oreil.ly/ej36j)有很好的详细解释。根据Uber的说法，它解决了两个问题：
- en: Allows users to add features they built into a shared Feature Store.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许用户将构建的特征添加到共享的特征存储中。
- en: Once features are in the Feature Store, they are easy to use in training and
    prediction.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦特征存储中有了特征，它们就很容易在训练和预测中使用。
- en: In [Figure 5-8](#Figure-5-7-2), you can see that data science is a behavior,
    but AutoML is a technique. AutoML could be only 5% of the entire problem solved
    by automation. The data itself needs automation through ETL job management. The
    Feature Store needs automation to improve the ML inputs. Finally, the deployment
    requires automation through automated deployment (CD) and the native use of cloud
    elasticity (autoscaling). Everything requires automation with complex software
    systems, and Feature Stores are just one of many MLOps components needing continuous
    improvement, i.e., KaizenML.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 5-8](#Figure-5-7-2)中，你可以看到数据科学是一种行为，但AutoML是一种技术。AutoML可能只解决了自动化问题的5%。数据本身需要通过ETL作业管理进行自动化。特征存储需要自动化以改进ML输入。最后，部署需要通过自动部署（CD）和云弹性使用的本地化使用进行自动化。所有复杂软件系统都需要自动化，特征存储只是许多MLOps组件中需要持续改进的一个，即KaizenML。
- en: '![Feature Stores are Part of a Systems Methodology of Automation](Images/pmlo_0508.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![特征存储是系统方法论自动化的一部分](Images/pmlo_0508.png)'
- en: Figure 5-8\. Feature Stores are part of a systems methodology of automation
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-8\. 特征存储是系统方法论自动化的一部分
- en: There are many real-world use cases for Feature Stores. For example, Uber explains
    that it [used 10,000 features in the Feature Store](https://oreil.ly/iuDeG) to
    accelerate machine projects and make AutoML solutions on top. In addition, platforms
    like [Databricks](https://oreil.ly/aqFju) have Feature Stores built into their
    big data system. For example, in [Figure 5-9](#Figure-5-7-4), you can see how
    raw data is the input that gets transformed into a more refined and specialized
    feature registry that can solve both batch and online problems.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Feature Store 有许多实际用例。例如，Uber 解释称它 [在 Feature Store 中使用了 10,000 个特征](https://oreil.ly/iuDeG)，以加速机器学习项目并构建
    AutoML 解决方案。此外，像 [Databricks](https://oreil.ly/aqFju) 这样的平台已将 Feature Store 集成到其大数据系统中。例如，在
    [Figure 5-9](#Figure-5-7-4) 中，您可以看到原始数据是输入，经过转换后形成更精细和专业的特征注册表，能够解决批处理和在线问题。
- en: In [Figure 5-10](#Figure-5-7-5), notice that there are both similarities and
    differences between a traditional data warehouse and an MLOps Feature Store. A
    data warehouse feeds into business intelligence systems at a high level, and a
    Feature Store provides inputs into an ML system. Machine learning data processing
    is repetitive, including normalizing data, cleaning data, and finding appropriate
    features that improve an ML model. Creating a Feature Store system is yet one
    more way of fully embracing automation of the entire process of machine learning
    from ideation to production.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [Figure 5-10](#Figure-5-7-5) 中，请注意传统数据仓库与 MLOps 特征存储之间的相似性和差异。数据仓库主要用于高层的商业智能系统，而特征存储则为
    ML 系统提供输入。机器学习数据处理包括数据归一化、数据清洗以及寻找能够改进 ML 模型的适当特征。创建特征存储系统是完全采用从构思到生产的机器学习自动化过程的又一种方式。
- en: '![Databricks Feature Store](Images/pmlo_0509.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![Databricks Feature Store](Images/pmlo_0509.png)'
- en: Figure 5-9\. Databricks feature store
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-9\. Databricks 特征存储
- en: '![pmlo 0510](Images/pmlo_0510.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0510](Images/pmlo_0510.png)'
- en: Figure 5-10\. Data warehouse versus feature store
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-10\. 数据仓库与特征存储
- en: Next, let’s get out of the theory and practice technique using the Apple ML
    Ecosystem to build machine learning models. We will do this using its high-level
    AutoML framework, CreateML.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们离开理论，实践使用苹果 ML 生态系统构建机器学习模型的技术。我们将使用其高级 AutoML 框架 CreateML 进行操作。
- en: Apple’s Ecosystem
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 苹果生态系统
- en: Apple may seem like an unlikely candidate to enter the machine learning tools
    space until you look a bit deeper. Apple has a rich ecosystem around mobile development.
    According to [Statista](https://oreil.ly/SEnIY), the worldwide gross app revenue
    of the Apple App Store grew from 55.5 billion US Dollars in 2019 to 72.3 billion
    US Dollars in 2020\. Apple benefits from developers creating products that sell
    in its app store.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 苹果可能看起来不太可能进入机器学习工具领域，直到您深入了解。苹果在移动开发周围有着丰富的生态系统。根据 [Statista](https://oreil.ly/SEnIY)
    的数据，2019 年至 2020 年，苹果应用商店的全球总收入从 555 亿美元增长到了 723 亿美元。苹果受益于开发者在其应用商店中创建销售产品。
- en: I remember talking to a pretty dismissive professor about building “apps for
    machine learning,” presumably because he gravitated toward complexity and discovery
    in doing research. In a sense, the software industry thinks in an opposite manner
    of a researcher at a university. Writing academic papers on machine learning is
    the opposite direction of operationalizing machine learning to “build apps.” This
    ideological difference is the “idea” versus “execution” disconnect discussed earlier.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我记得曾经和一个相当轻视的教授讨论过“构建机器学习应用程序”的话题，可能是因为他偏向于复杂性和在研究中的发现。从某种意义上说，软件行业的思维方式与大学里的研究人员相反。撰写机器学习学术论文与将机器学习操作化为“构建应用程序”是两种截然不同的方向。这种“思想”与“执行”的分歧正如之前讨论的那样。
- en: Apple wants you to build apps in its app store since it takes between 15% and
    30% of every transaction. The better Apple makes the developer tools, the more
    applications live in the app store. There is an expression in business school,
    “Where do you build a Burger King? Next to McDonald’s.” This expression is a way
    of saying that you don’t need to spend the money to research where to expand because
    the top competitor already did the work. You can piggyback on their expertise—likewise,
    practitioners of machine learning can piggyback on the research Apple has done.
    They see a future in high-level automated machine learning running on specialized
    hardware.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Apple 希望你在其应用商店中构建应用程序，因为它从每笔交易中抽取 15% 至 30% 的费用。苹果使开发者工具越好，应用程序在应用商店中生存的可能性就越大。在商学院有一句话：“在哪里建立汉堡王？在麦当劳旁边。”这句话的意思是说，你不需要花钱研究扩展到哪里，因为顶级竞争对手已经做了这项工作。你可以依赖他们的专业知识——同样，机器学习的从业者可以依赖苹果的研究。他们看到未来是高级自动化机器学习在专用硬件上运行。
- en: 'Similarly, why do many VC firms fund only companies that top VC firms already
    funded? Because then they don’t need to do any work; they can profit from the
    expertise of a more knowledgeable firm. Similarly, Apple has tremendous investments
    from a hardware perspective into on-device machine learning. In particular, Apple
    develops chips itself, like the A-series: A12-A14, shown in [Figure 5-11](#Figure-5-9),
    including CPUs, GPUs, and dedicated neural network hardware.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，为什么许多风险投资公司只投资已由顶级风投公司投资的公司？因为他们不需要做任何工作；他们可以从更有经验的公司的专业知识中获利。同样，苹果在设备上的机器学习领域有着巨大的投资。特别是苹果自己开发芯片，如
    A 系列：A12-A14，如 [Figure 5-11](#Figure-5-9) 所示，包括 CPU、GPU 和专用神经网络硬件。
- en: '![Apple''s A14](Images/pmlo_0511.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![Apple''s A14](Images/pmlo_0511.png)'
- en: Figure 5-11\. Apple’s A14 chip
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-11\. Apple 的 A14 芯片。
- en: Further, newer chips include the Apple M1 architecture, which Apple uses on
    mobile devices, laptops, and desktop machines, as shown in [Figure 5-12](#Figure-5-10).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，新的芯片包括 Apple M1 架构，苹果在移动设备、笔记本电脑和台式机上使用，如 [Figure 5-12](#Figure-5-10) 所示。
- en: '![ Apple''s M1](Images/pmlo_0512.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![ Apple''s M1](Images/pmlo_0512.png)'
- en: Figure 5-12\. Apple’s M1 chip
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-12\. Apple 的 M1 芯片。
- en: The development environment makes use of this technology through Apple’s model
    format [Core ML](https://oreil.ly/jyoxD). There is also a Python package to convert
    models from third-party training libraries like TensorFlow and Keras.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 开发环境通过 Apple 的模型格式 [Core ML](https://oreil.ly/jyoxD) 使用此技术。还有一个 Python 包可以将从
    TensorFlow 和 Keras 等第三方训练库训练的模型转换为 Core ML。
- en: 'Core ML is optimized for on-device performance and works in tandem with the
    Apple hardware. There are several non-obvious workflows to consider:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Core ML 针对设备性能进行了优化，并与苹果硬件协同工作。有几种不明显的工作流程需要考虑：
- en: Use Apple’s Create ML framework to make AutoML solutions.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Apple 的 Create ML 框架来制作 AutoML 解决方案。
- en: Download a pretrained model and optionally convert it to the Core ML format.
    One location to download models from is [tfhub](https://oreil.ly/ouuNI).
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载预训练模型并可选择转换为 Core ML 格式。可以从 [tfhub](https://oreil.ly/ouuNI) 下载模型的位置之一。
- en: Train a model yourself by writing the code in another framework, then converting
    it to Core ML using [coremltools](https://oreil.ly/vYGcE).
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过其他框架编写代码自己训练模型，然后使用 [coremltools](https://oreil.ly/vYGcE) 转换为 Core ML。
- en: Let’s dig into Apple’s AutoML.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解 Apple 的 AutoML。
- en: 'Apple’s AutoML: Create ML'
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apple 的 AutoML：Create ML。
- en: 'One of the core innovations with Apple’s ML platform is how it exposes power
    AutoML technology enclosed in an intuitive GUI. Apple Create ML lets you do the
    following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Apple 的 ML 平台的核心创新之一是，它将封装在直观 GUI 中的强大 AutoML 技术暴露给用户。Apple Create ML 让你可以做以下事情：
- en: Create Core ML models
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 Core ML 模型。
- en: Preview the model performance
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预览模型性能。
- en: Train models on the Mac (taking advantage of their M1 chip stack)
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Mac 上训练模型（利用其 M1 芯片堆栈）。
- en: 'Use training control: i.e., pause, save and resume training'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用训练控制：即暂停、保存和恢复训练。
- en: Use eGPU (external GPUs)
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用外置 GPU（eGPU）。
- en: Additionally, it tackles various domains from image, video, motion, sound, text,
    and tabular. Let’s dive into AutoML with Apple’s CreateML. Notice the entire list
    of many automated forms of machine learning in [Figure 5-13](#Figure-5-12) and
    how they ultimately converge to the same Core ML model that runs on iOS.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，它处理各种领域，包括图像、视频、动作、声音、文本和表格。让我们通过 Apple 的 CreateML 深入探讨 AutoML。注意 [Figure 5-13](#Figure-5-12)
    中许多自动化机器学习形式的完整列表，以及它们最终如何收敛到在 iOS 上运行的同一 Core ML 模型。
- en: '![pmlo 0513](Images/pmlo_0513.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0513](Images/pmlo_0513.png)'
- en: Figure 5-13\. Create ML
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-13\. Create ML。
- en: 'To get started with Create ML, do the following:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 Create ML，请执行以下操作：
- en: Download [XCode](https://oreil.ly/dOCQj).
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载 [XCode](https://oreil.ly/dOCQj)。
- en: Open up XCode and right-click the icon to launch Create ML ([Figure 5-14](#Figure-5-13)).
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 XCode 并右键点击图标以启动 Create ML（参见 [Figure 5-14](#Figure-5-13)）。
- en: '![pmlo 0514](Images/pmlo_0514.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0514](Images/pmlo_0514.png)'
- en: Figure 5-14\. Open Create ML
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-14\. 打开 Create ML
- en: Next, use the Image Classifier template (see [Figure 5-15](#Figure-5-14)).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用图像分类器模板（见 [Figure 5-15](#Figure-5-14)）。
- en: '![pmlo 0515](Images/pmlo_0515.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0515](Images/pmlo_0515.png)'
- en: Figure 5-15\. Image Classifier Template
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-15\. 图像分类器模板
- en: You can grab a smaller version of the Kaggle dataset “cats and dogs” in the
    [GitHub repository for the book](https://oreil.ly/XMB82). Drop the `cats-dogs-small`
    dataset onto the UI for Create ML (see [Figure 5-16](#Figure-5-15)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [书籍的 GitHub 存储库](https://oreil.ly/XMB82) 中获取“猫和狗”的较小版本的 Kaggle 数据集。将 `cats-dogs-small`
    数据集拖放到 Create ML 的 UI 中（参见 [Figure 5-16](#Figure-5-15)）。
- en: '![pmlo 0516](Images/pmlo_0516.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0516](Images/pmlo_0516.png)'
- en: Figure 5-16\. Upload data
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-16\. 上传数据
- en: Also, [drop the test data](https://oreil.ly/JRNmt) onto the test section of
    the UI for Create ML.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 还有，[将测试数据](https://oreil.ly/JRNmt) 拖放到 Create ML 的测试部分。
- en: Next, train the model by clicking the train icon. Note that you can train the
    model multiple times by right-clicking Model Sources. You may want to experiment
    with this because it allows you to test with “Augmentations” like Noise, Blur,
    Crop, Expose, Flip, and Rotate (see [Figure 5-17](#Figure-5-16)). These will enable
    you to create a more robust model that is more generalizable against real-world
    data.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，通过点击训练图标来训练模型。请注意，您可以通过右键单击模型来源多次训练模型。您可能希望尝试这样做，因为它允许您使用“增强”（如噪声、模糊、裁剪、曝光、翻转和旋转）测试，这些将使您能够创建更具一般适用性的更健壮模型（见
    [Figure 5-17](#Figure-5-16)）。
- en: '![pmlo 0517](Images/pmlo_0517.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0517](Images/pmlo_0517.png)'
- en: Figure 5-17\. Trained model
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-17\. 训练后的模型
- en: This small dataset should only take a few seconds to train the model (especially
    if you have the newer Apple M1 hardware). You can test it out by finding internet
    pictures of cats and dogs, downloading them, and dragging them into the preview
    icon (see [Figure 5-18](#Figure-5-17)).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这个小数据集只需几秒钟就可以训练模型（尤其是如果您有更新的 Apple M1 硬件）。您可以通过查找互联网上的猫和狗图片、下载并将它们拖到预览图标中进行测试（见
    [Figure 5-18](#Figure-5-17)）。
- en: '![pmlo 0518](Images/pmlo_0518.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0518](Images/pmlo_0518.png)'
- en: Figure 5-18\. Preview
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-18\. 预览
- en: A final step is to download the model and use it in an iOS application. Note
    that in [Figure 5-19](#Figure-5-18), I use the OS X Finder menu and name the model
    and save it to my desktop. This final step may be the terminal step for a hobbyist
    who wants to build a bespoke iOS application that runs just on their phone. Once
    you save the model, you could optionally convert it to another format like [ONNX](https://onnx.ai)
    and then run it on a cloud platform like Microsoft Azure.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是下载模型并在 iOS 应用程序中使用。请注意，在 [Figure 5-19](#Figure-5-18) 中，我使用 OS X Finder
    菜单命名模型并保存到我的桌面。这一最终步骤可能是那些希望构建仅在其手机上运行的定制 iOS 应用程序的业余爱好者的终端步骤。保存模型后，您可以选择将其转换为另一种格式，例如
    [ONNX](https://onnx.ai)，然后在诸如 Microsoft Azure 的云平台上运行它。
- en: '![pmlo 0519](Images/pmlo_0519.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0519](Images/pmlo_0519.png)'
- en: Figure 5-19\. Create ML model
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-19\. 创建 ML 模型
- en: Great work! You trained your first model that required zero code. The future
    will be fantastic as more of these tools evolve and get into the hands of consumers.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 很棒！您已经训练了您的第一个不需要任何代码的模型。随着更多这些工具的演进并进入消费者手中，未来将会非常美好。
- en: 'Optional next steps:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 可选的下一步骤：
- en: You can train a more complex model by [downloading a larger Kaggle dataset](https://oreil.ly/uzj4c)
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以通过 [下载更大的 Kaggle 数据集](https://oreil.ly/uzj4c) 来训练更复杂的模型
- en: You can try other types of AutoML
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以尝试其他类型的 AutoML
- en: You can experiment with augmentation
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以尝试使用增强技术
- en: Now that you know how to train a model using Create ML, let’s go a bit deeper
    into how you further leverage Apple’s Core ML tools.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解如何使用 Create ML 训练模型，让我们深入了解如何进一步利用 Apple 的 Core ML 工具。
- en: Apple’s Core ML Tools
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apple 的 Core ML 工具
- en: One of the more exciting workflows available for the Apple ecosystem is downloading
    models and converting them to the Core ML tools via a Python library. There are
    many locations to grab pretrained models, including TensorFlow Hub.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Apple 生态系统中更令人兴奋的工作流之一是通过 Python 库下载模型并将其转换为 Core ML 工具。有许多地方可以获取预训练模型，包括 TensorFlow
    Hub。
- en: In this example, let’s walk through the code in [this Colab notebook](https://oreil.ly/BBs71).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，让我们演示在 [此 Colab 笔记本](https://oreil.ly/BBs71) 中的代码。
- en: 'First, install the `coremltools` library:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，安装 `coremltools` 库：
- en: '[PRE0]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, download the model (based on the [official quickstart guide](https://oreil.ly/Z5vpq)).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，下载模型（基于 [官方快速入门指南](https://oreil.ly/Z5vpq)）。
- en: 'Import tensorflow as tf:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 tensorflow 库：
- en: '[PRE1]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Convert the model and set the metadata for the model to the correct parameters:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 转换模型并设置模型的元数据为正确的参数：
- en: '[PRE2]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now update the metadata of the model:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在更新模型的元数据：
- en: '[PRE3]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Finally, save the model, download it from Colab, and open it in XCode to predict
    (see [Figure 5-20](#Figure-5-19)).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，保存模型，在 Colab 下载并在 XCode 中打开进行预测（参见 [图5-20](#Figure-5-19)）。
- en: '![pmlo 0520](Images/pmlo_0520.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0520](Images/pmlo_0520.png)'
- en: Figure 5-20\. Download model
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-20\. 下载模型
- en: '[PRE4]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[Figure 5-21](#Figure-5-20) shows an example prediction.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-21](#Figure-5-20) 展示了一个预测示例。'
- en: '![pmlo 0521](Images/pmlo_0521.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0521](Images/pmlo_0521.png)'
- en: Figure 5-21\. Stingray predict
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-21\. 鳐鱼预测
- en: The big takeaway is this process is even easier than using AutoML. Therefore,
    it may make more sense to download a model created by experts with access to expensive
    compute clusters than train it yourself in many cases. Apple’s Core ML framework
    allows both the use case of bespoke AutoML as well as using pretrained models.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程的重要一点是，它比使用 AutoML 还要简单。因此，在许多情况下，下载由专家创建的模型（这些专家可以访问昂贵的计算集群）可能比自己训练模型更有意义。Apple
    的 Core ML 框架允许使用定制的 AutoML 或预训练模型。
- en: Google’s AutoML and Edge Computer Vision
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌的 AutoML 和边缘计算机视觉
- en: In the last few years, I have taught hundreds of students in a class called
    “Applied Computer Vision” at top data science universities. The premise of the
    course is to build solutions quickly using the most high-level tools available,
    including Google AutoML and edge hardware like the [Coral.AI](https://coral.ai)
    chip that contains a TPU or the Intel Movidius.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年里，我在顶尖数据科学大学教授了数百名学生一门名为“应用计算机视觉”的课程。课程的前提是使用最高级的工具快速构建解决方案，包括 Google AutoML
    和边缘硬件，如包含 TPU 的 Coral.AI 芯片或 Intel Movidius。
- en: '[Figure 5-22](#Figure-5-21) shows two examples of small form-factor edge machine
    learning solutions.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-22](#Figure-5-21) 展示了两个小型边缘机器学习解决方案的示例。'
- en: '![pmlo 0522](Images/pmlo_0522.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0522](Images/pmlo_0522.png)'
- en: Figure 5-22\. Edge hardware
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-22\. 边缘硬件
- en: One of the surprising things about teaching the class is how quickly students
    can take “off the shelf” solutions, piece them together, and come up with a solution
    that solves a problem. I have seen projects including mask detection, license
    plate detection, and trash sorting applications running on mobile devices with
    little to no code. We are in a new era, the MLOps era, and it is easier to put
    code into working applications.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 教授这门课程时，令人惊讶的是学生们多快能够采用“现成的”解决方案，将它们组合起来，并提出解决问题的方案。我见过在移动设备上运行的项目，包括口罩检测、车牌检测和垃圾分类应用，几乎没有编写代码。我们正处于一个新时代，MLOps
    时代，将代码投入到工作应用程序中变得更加容易。
- en: Like Apple and Google, many companies build a vertically integrated stack that
    provides a machine learning framework, operating systems, and specialized hardware
    like an ASIC (application-specific integrated circuit) that performs particular
    machine learning tasks. For example, the TPU, or TensorFlow Processing Unit, is
    actively developed with regular updates to the chip design. The edge version is
    a purpose-built ASIC that runs ML models. This tight integration is essential
    for organizations looking for the rapid creation of real-world machine learning
    solutions.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 像苹果和谷歌一样，许多公司构建了一个垂直集成的堆栈，提供了机器学习框架、操作系统和专用硬件，如 ASIC（专用集成电路），用于执行特定的机器学习任务。例如，TPU
    或 TensorFlow 处理单元正在积极开发中，定期更新芯片设计。边缘版本是一个专门设计的 ASIC，用于运行 ML 模型。这种紧密集成对于寻求快速创建真实世界机器学习解决方案的组织至关重要。
- en: 'There are several critical approaches to computer vision on the GCP platform
    (similar to other cloud platforms, the service names are different). These options
    appear in order of difficulty:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: GCP 平台上有几种关键的计算机视觉方法（与其他云平台类似，服务名称不同）。这些选项按难度排序如下：
- en: Write machine learning code that trains a model
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写训练模型的机器学习代码
- en: Use Google AutoML Vision
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Google AutoML Vision
- en: Download a pretrained model from [TensorFlow Hub](https://tfhub.dev) or another
    location
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 [TensorFlow Hub](https://tfhub.dev) 或其他位置下载预训练模型
- en: Use the [Vision AI API](https://oreil.ly/7pX3S)
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 [Vision AI API](https://oreil.ly/7pX3S)
- en: 'Let’s examine a Google AutoML Vision workflow that ends in a computer vision
    model deployed to an iOS device. This workflow is essentially the same, whether
    you use a sample dataset that Google provides or your own:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一个 Google AutoML Vision 工作流程，该流程以部署到 iOS 设备的计算机视觉模型结束。无论您使用 Google 提供的样本数据集还是自己的数据集，该工作流程基本相同：
- en: Launch Google Cloud Console and open a cloud shell.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 Google Cloud 控制台并打开云 Shell。
- en: 'Enable the Google AutoML Vision API and give your project permission to it;
    you would set both the `PROJECT_ID` and `USERNAME`:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用 Google AutoML Vision API，并为项目授予权限；您需要设置 `PROJECT_ID` 和 `USERNAME`：
- en: '[PRE5]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Upload training data and labels via a CSV file to Google Cloud Storage.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 CSV 文件将训练数据和标签上传到 Google Cloud Storage。
- en: 'If you set a ``${BUCKET} ` variable `export BUCKET=$FOOBAR``, then three commands
    are all you need to copy Google sample data. Here is one example for Cloud Classification
    (cirrus, cumulonimbus, cumulus). You can find a walkthrough on Google Qwiklabs
    under [“Classify Images of Clouds in the Cloud with AutoML Vision”](https://qwiklabs.com).
    The `gs://spls/gsp223/images/` location holds the data in this example, and the
    `sed` command swaps out the specific paths:'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您设置了 `${BUCKET}` 变量 `export BUCKET=$FOOBAR`，那么只需三个命令就能复制 Google 的样本数据。这里以云分类（卷积云、积云、层云）为例。您可以在
    Google Qwiklabs 中找到有关“使用 AutoML Vision 在云中对云图像进行分类”的详细步骤。在这个示例中，数据位于 `gs://spls/gsp223/images/`
    位置，`sed` 命令替换了具体路径：
- en: '[PRE6]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Additional Datasets Ideal for Google AutoML
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 适用于 Google AutoML 的额外数据集
- en: Two other datasets you may also want to try to include are [tf_flowers data](https://oreil.ly/nknp3)
    and [cats and dogs data](https://oreil.ly/nEJOd). Yet another idea is uploading
    your data.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可能还想尝试的其他两个数据集是 [tf_flowers 数据](https://oreil.ly/nknp3) 和 [猫狗数据](https://oreil.ly/nEJOd)。另一个想法是上传您的数据。
- en: Visually inspect the data.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视觉检查数据。
- en: One of the valuable aspects of Google’s Cloud AutoML systems is using high-level
    tools to inspect the data, add new labels, or fix data quality control issues.
    Notice in [Figure 5-23](#Figure-5-22) that you have the ability to toggle between
    the different classification categories, which happen to be flowers.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Google Cloud AutoML 系统的一个有价值的方面是使用高级工具检查数据，添加新标签或修复数据质量控制问题。请注意，在 [图 5-23](#Figure-5-22)
    中，您可以在不同的分类类别之间切换，这些分类类别恰好是花卉。
- en: '![pmlo 0523](Images/pmlo_0523.png)'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![pmlo 0523](Images/pmlo_0523.png)'
- en: Figure 5-23\. Inspect data
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-23\. 检查数据
- en: Train the model and evaluate.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型并评估。
- en: Training the model is a button click in the console. Google has collected these
    options into its product [Google Vertex AI](https://oreil.ly/P5m7Y). Notice in
    [Figure 5-24](#Figure-5-21-1) that there are a series of actions from Notebooks
    to Batch Predictions on the left panel. When creating a new training job, AutoML
    is an option, as well as AutoML Edge.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在控制台中点击按钮即可训练模型。Google 将这些选项汇集到其产品 [Google Vertex AI](https://oreil.ly/P5m7Y)
    中。请注意，在 [图 5-24](#Figure-5-21-1) 中，左侧面板上有一系列操作，从笔记本到批量预测。创建新的训练作业时，AutoML 和 AutoML
    Edge 都是选项。
- en: '![Google Vertex AI](Images/pmlo_0524.png)'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![Google Vertex AI](Images/pmlo_0524.png)'
- en: Figure 5-24\. Google Vertex AI
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-24\. Google Vertex AI
- en: Afterward, evaluate the trained model using the built-in tools (see [Figure 5-25](#Figure-5-22-1)).
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，使用内置工具评估训练好的模型（见 [图 5-25](#Figure-5-22-1)）。
- en: '![pmlo 0525](Images/pmlo_0525.png)'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![pmlo 0525](Images/pmlo_0525.png)'
- en: Figure 5-25\. Evaluate data
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-25\. 评估数据
- en: 'Do something with the model: predict online or download.'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理模型：在线预测或下载。
- en: 'With Google AutoML vision, there is the ability to create an online hosted
    endpoint or download the model and make predictions on an edge device: iOS, Android,
    Javascript, Coral Hardware, or a container (see [Figure 5-26](#Figure-5-23)).'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用 Google AutoML Vision，可以创建在线托管的端点或下载模型，并在边缘设备上进行预测：iOS、Android、Javascript、Coral
    硬件或容器（见 [图 5-26](#Figure-5-23)）。
- en: '![pmlo 0526](Images/pmlo_0526.png)'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![pmlo 0526](Images/pmlo_0526.png)'
- en: Figure 5-26\. Download model
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-26\. 下载模型
- en: The main takeaway is that Google Cloud offers a well-traveled path from uploading
    training data to training with minimal or no code required to build machine learning
    solutions that deploy to edge devices. These options are all integrated as part
    of Google’s managed machine learning platform Vertex AI.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的要点是，Google Cloud 提供了一个经过验证的路径，从上传训练数据到无需或最小编码进行机器学习解决方案构建，可部署到边缘设备。这些选项都集成在
    Google 的托管机器学习平台 Vertex AI 中。
- en: Next, let’s dive into Azure’s AutoML solutions, which like Google’s, have a
    complete story about managing the lifecycle of MLOps.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们深入了解 Azure 的 AutoML 解决方案，与 Google 类似，有关于管理 MLOps 生命周期的完整故事。
- en: Azure’s AutoML
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure 的 AutoML
- en: There are two primary ways to access the Azure AutoML. One is the console, and
    the other is programmatic access to the AutoML [Python SDK](https://oreil.ly/EKA0b).
    Let’s take a look at the console first.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 访问 Azure 自动机器学习有两种主要方法。一种是通过控制台，另一种是通过 AutoML 的 [Python SDK](https://oreil.ly/EKA0b)
    进行编程访问。让我们先看看控制台。
- en: To get started doing AutoML on Azure, you need to launch an instance of Azure
    ML Studio and select the Automated ML option (see [Figure 5-27](#Figure-5-24)).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Azure 上开始使用 AutoML，你需要启动一个 Azure ML Studio 实例，并选择自动化 ML 选项（见 [图5-27](#Figure-5-24)）。
- en: '![pmlo 0527](Images/pmlo_0527.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0527](Images/pmlo_0527.png)'
- en: Figure 5-27\. Azure AutoML
  id: totrans-199
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-27\. Azure 自动机器学习
- en: Next, create a dataset either by uploading it or using an open dataset. In this
    example, I use the data from the [Kaggle Social Power NBA project](https://oreil.ly/Bsjly)
    (see [Figure 5-28](#Figure-5-25)).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个数据集，可以是上传的数据或使用公开数据集。在这个例子中，我使用了来自 [Kaggle 社交力量 NBA 项目](https://oreil.ly/Bsjly)
    的数据（见 [图5-28](#Figure-5-25)）。
- en: Then, I spin up a classification job to predict which position a player could
    play based on the features in the dataset. Note that many different types of machine
    learning predictions are available, including numerical regression and time-series
    forecasting. You will need to set up storage and a cluster if you have not already
    done so (see [Figure 5-29](#Figure-5-26)) .
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我启动了一个分类作业，预测基于数据集中的特征一个球员可能打哪个位置。请注意，有许多不同类型的机器学习预测可用，包括数值回归和时间序列预测。如果你还没有设置存储和集群，你需要设置它们（见
    [图5-29](#Figure-5-26)）。
- en: '![pmlo 0528](Images/pmlo_0528.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0528](Images/pmlo_0528.png)'
- en: Figure 5-28\. Azure AutoML create dataset
  id: totrans-203
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-28\. Azure 自动机器学习创建数据集
- en: '![pmlo 0529](Images/pmlo_0529.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0529](Images/pmlo_0529.png)'
- en: Figure 5-29\. Azure AutoML classify
  id: totrans-205
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-29\. Azure 自动机器学习分类
- en: Once jobs complete, you can also ask Azure ML Studio to “explain” how it got
    to its predictions. A machine learning system explains how a model comes up with
    forecasts via “explainability,” which is a critical upcoming capability of AutoML
    systems. You can see these explanatory capabilities in [Figure 5-30](#Figure-5-27).
    Notice how deep integration into the ML Studio solution gives this platform technology
    an extensive feel.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 作业完成后，你也可以要求 Azure ML Studio “解释”它是如何得出预测的。机器学习系统通过“可解释性”来解释模型生成预测的过程，这是自动机器学习系统中一个关键的即将推出的能力。你可以在
    [图5-30](#Figure-5-27) 中看到这些解释能力。注意，这个平台技术通过与 ML Studio 解决方案的深度集成提供了广泛的感觉。
- en: '![pmlo 0530](Images/pmlo_0530.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0530](Images/pmlo_0530.png)'
- en: Figure 5-30\. Azure AutoML explain
  id: totrans-208
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-30\. Azure 自动机器学习解释
- en: 'Let’s take a look at the other approach. You can use Python to call the same
    API available from the Azure ML Studio console. This official [Microsoft tutorial](https://oreil.ly/io66Z)
    explains it in detail, but the critical section is shown here:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看另一种方法。你可以使用 Python 调用 Azure ML Studio 控制台中可用的相同 API。这个官方的 [Microsoft 教程](https://oreil.ly/io66Z)
    详细解释了它，但关键部分在这里展示：
- en: '[PRE7]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: AWS AutoML
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS 自动机器学习
- en: As the largest cloud provider, AWS also has many AutoML solutions. One of the
    earliest solutions includes a tool with a bad name, “Machine Learning,” that is
    no longer widely available but was an AutoML solution. Now the recommended solution
    is SageMaker AutoPilot ([Figure 5-31](#Figure-5-28)). You can view many examples
    of SageMaker Autopilot in action from the [official documentation](https://oreil.ly/fDJiE).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最大的云服务提供商，AWS 也提供了许多自动机器学习解决方案。最早的解决方案之一包括一个名字不太好听的工具，“机器学习”，虽然现在已经不再广泛使用，但它曾是一个自动机器学习解决方案。现在推荐的解决方案是
    SageMaker AutoPilot（见 [图5-31](#Figure-5-28)）。你可以从[官方文档](https://oreil.ly/fDJiE)中查看许多
    SageMaker Autopilot 的示例。
- en: '![pmlo 0531](Images/pmlo_0531.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0531](Images/pmlo_0531.png)'
- en: Figure 5-31\. SageMaker Autopilot
  id: totrans-214
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-31\. SageMaker Autopilot
- en: Let’s walk through how to do an Autopilot experiment with AWS SageMaker. First,
    as shown in [Figure 5-32](#Figure-5-28-1), open SageMaker Autopilot and select
    a new task.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一起来看看如何使用 AWS SageMaker 进行 Autopilot 实验。首先，如 [图5-32](#Figure-5-28-1) 所示，打开
    SageMaker Autopilot 并选择一个新任务。
- en: '![Sagemaker Autopilot Task](Images/pmlo_0532.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![Sagemaker Autopilot 任务](Images/pmlo_0532.png)'
- en: Figure 5-32\. SageMaker Autopilot task
  id: totrans-217
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-32\. SageMaker Autopilot 任务
- en: Next, I upload the [“NBA Players Data Kaggle Project”](https://oreil.ly/G1TIi)
    into Amazon S3\. Now that I have data to work with, I create an experiment as
    shown in [Figure 5-33](#Figure-5-28-2). Notice that I select for a target the
    draft position. This classification is because I want to create a prediction model
    that shows what draft position an NBA player deserves based on their performance.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将[“NBA 球员数据 Kaggle 项目”](https://oreil.ly/G1TIi)上传到 Amazon S3。现在我有了可以使用的数据，我根据[图 5-33](#Figure-5-28-2)中显示的方式创建一个实验。注意，我选择的目标是选秀位置。这种分类是因为我想创建一个预测模型，显示
    NBA 球员根据他们的表现应该获得的选秀位置。
- en: '![Create Autopilot Experiment](Images/pmlo_0533.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![创建 Autopilot 实验](Images/pmlo_0533.png)'
- en: Figure 5-33\. Create Autopilot experiment
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-33\. 创建 Autopilot 实验
- en: Once I submit the experiment, SageMaker Autopilot goes through a preprocessing
    stage through Model Tuning, as [Figure 5-34](#Figure-5-28-3) shows.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我提交实验，SageMaker Autopilot 将经历一个预处理阶段，通过模型调优，如[图 5-34](#Figure-5-28-3)所示。
- en: Now that the AutoML pipeline is running, you can see the resources it uses in
    the Resources tab, as shown in [Figure 5-35](#Figure-5-28-4).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 AutoML 流水线正在运行，您可以在资源选项卡中看到它使用的资源，如[图 5-35](#Figure-5-28-4)所示。
- en: '![Running Autopilot Experiment](Images/pmlo_0534.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![运行 Autopilot 实验](Images/pmlo_0534.png)'
- en: Figure 5-34\. Run Autopilot experiment
  id: totrans-224
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-34\. 运行 Autopilot 实验
- en: '![Running Autopilot Experiment](Images/pmlo_0535.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![运行 Autopilot 实验](Images/pmlo_0535.png)'
- en: Figure 5-35\. Autopilot instances
  id: totrans-226
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-35\. Autopilot 实例
- en: When the training is complete, you can see a list of models and their accuracy,
    as shown in [Figure 5-36](#Figure-5-28-5). Note that SageMaker was able to create
    a highly accurate classification model with an accuracy of .999945.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练完成时，您可以看到一个模型列表及其准确度，如[图 5-36](#Figure-5-28-5)所示。请注意，SageMaker 能够创建一个准确率达到
    .999945 的高精度分类模型。
- en: '![Completed Autopilot Run](Images/pmlo_0536.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![完成 Autopilot 运行](Images/pmlo_0536.png)'
- en: Figure 5-36\. Completed Autopilot run
  id: totrans-229
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-36\. 完成的 Autopilot 运行
- en: Finally, as shown in [Figure 5-37](#Figure-5-28-6), once the job is complete,
    you can right-click the model you want to control and either deploy it to production
    or open it in trail details mode to inspect explainability and/or metrics or charts.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如[图 5-37](#Figure-5-28-6)所示，一旦任务完成，您可以右键点击要控制的模型，要么部署到生产环境，要么在详细模式中打开以检查可解释性和/或度量或图表。
- en: SageMaker Autopilot is a complete solution for AutoML and MLOps, and if your
    organization is already using AWS, it does seem straightforward to integrate this
    platform into your existing workflows. It seems especially useful when working
    with larger datasets and with problems where reproducibility is critically essential.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 是一种完整的 AutoML 和 MLOps 解决方案，如果您的组织已经在使用 AWS，那么将这个平台集成到现有工作流中似乎是直接的。特别是在处理更大数据集和需要重现性关键的问题时，它显得特别有用。
- en: '![Running Autopilot Experiment](Images/pmlo_0537.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![运行 Autopilot 实验](Images/pmlo_0537.png)'
- en: Figure 5-37\. Autopilot model
  id: totrans-233
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-37\. Autopilot 模型
- en: Next, let’s discuss some of the open source AutoML solutions that are emerging.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论一些新兴的开源 AutoML 解决方案。
- en: Open Source AutoML Solutions
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开源 AutoML 解决方案
- en: I still remember fondly my days of working on Unix clusters while working at
    Caltech in 2000\. This particular time was a transitionary time for Unix, though,
    because even though in many cases Solaris was superior to Linux, it couldn’t compete
    with the price of the Linux operating system, which was free.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我依然怀念在 2000 年在 Caltech 工作时使用 Unix 集群的日子。那个时候 Unix 正在过渡，尽管在许多情况下 Solaris 优于 Linux，但它无法与免费的
    Linux 操作系统的价格竞争。
- en: I see a similar thing happening with open source AutoML solutions. The ability
    to train and run models using high-level tools appears to head toward commodification.
    So let’s take a look at some of the options in open source.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我看到开源 AutoML 解决方案也在发生类似的事情。使用高级工具训练和运行模型的能力似乎正在向商品化方向发展。因此，让我们看看一些开源选项。
- en: Ludwig
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ludwig
- en: One of the more promising approaches to open source AutoML is [Ludwig AutoML](https://oreil.ly/wIFo4).
    In [Figure 5-38](#Figure-5-29), the output from a Ludwig run shows the metrics
    useful to evaluate the strength of the model. The advantage to open source is
    that a corporation does not control it! Here is an example project that shows
    text classification using [Ludwig via Colab notebook](https://oreil.ly/tb88B).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 开源 AutoML 中更有前途的方法之一是[Ludwig AutoML](https://oreil.ly/wIFo4)。在[图 5-38](#Figure-5-29)中，从
    Ludwig 运行的输出显示了评估模型强度有用的指标。开源的优势在于没有公司控制它！这里有一个示例项目，展示了使用[Ludwig 通过 Colab 笔记本进行文本分类](https://oreil.ly/tb88B)。
- en: 'First, install Ludwig and set up a download:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，安装 Ludwig 并设置下载：
- en: '[PRE8]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, the model is just a command line invocation. This step then trains the
    model:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，模型只是一个命令行调用。然后训练模型：
- en: '[PRE9]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![pmlo 0538](Images/pmlo_0538.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0538](Images/pmlo_0538.png)'
- en: Figure 5-38\. Ludwig
  id: totrans-245
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-38\. Ludwig
- en: You can find many additional excellent examples of Ludwig in its [official documentation](https://oreil.ly/SMNqY).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在官方文档中找到 Ludwig 的许多优秀示例：[official documentation](https://oreil.ly/SMNqY)。
- en: One of the more exciting aspects of Ludwig is that it is under active development.
    As part of the Linux Foundation, they recently released version 4, which you can
    see in [Figure 5-39](#Figure-5-30_1). It adds many additional features like working
    with remote filesystems and distributed out-of-memory tools like Dask and Ray.
    Finally, Ludwig has a deep integration with MLflow. The Ludwig roadmap shows that
    it will continue to support and enhance this integration.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: Ludwig 更令人兴奋的一个方面是它正在积极开发中。作为 Linux Foundation 的一部分，他们最近发布了版本 4，你可以在 [Figure 5-39](#Figure-5-30_1)
    中看到。它添加了许多额外功能，如与远程文件系统和分布式内存工具（如 Dask 和 Ray）的深度集成。最后，Ludwig 与 MLflow 有深入的集成。Ludwig
    的路线图显示它将继续支持和增强这一集成。
- en: '![Ludwig  Version 4](Images/pmlo_0539.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![Ludwig 版本 4](Images/pmlo_0539.png)'
- en: Figure 5-39\. Ludwig version 4
  id: totrans-249
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-39\. Ludwig 版本 4
- en: FLAML
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FLAML
- en: Another entrant into open source AutoML is [FLAML](https://oreil.ly/TxRe0).
    It has a design that accounts for cost-effective hyperparameter optimization.
    You can see the FLAML logo in [Figure 5-40](#Figure-5-30_2).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个开源 AutoML 的新进入者是 [FLAML](https://oreil.ly/TxRe0)。它的设计考虑了成本效益的超参数优化。你可以在 [Figure 5-30_2](#Figure-5-30_2)
    中看到 FLAML 的标志。
- en: '![pmlo 0540](Images/pmlo_0540.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0540](Images/pmlo_0540.png)'
- en: Figure 5-40\. FLAML from Microsoft Research
  id: totrans-253
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-40\. FLAML 来自微软研究
- en: 'One of the primary use cases for FLAML is to automate an entire modeling process
    with as little as three lines of code. You can see this in the following example:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: FLAML 的主要用例之一是仅用三行代码自动化整个建模过程。你可以在以下示例中看到：
- en: '[PRE10]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'A more comprehensive example shows that in a Jupyter notebook, you first install
    the library `!pip install -q flaml`, then configure the AutoML configuration.
    Then it kicks off a training job to select the optimized classification model:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 更详细的示例显示在 Jupyter 笔记本中，首先安装库 `!pip install -q flaml`，然后配置 AutoML 配置。然后启动训练作业以选择优化的分类模型：
- en: '[PRE11]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You can see in [Figure 5-41](#Figure-5-31) that, after multiple iterations,
    it selects an XGBClassifier with a set of optimized hyperparameters.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如你可以在 [Figure 5-31](#Figure-5-31) 中看到，在多次迭代后，它选择了一个带有一组优化超参数的 XGBClassifier。
- en: '![FLAML output from model selection](Images/pmlo_0541.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![FLAML 模型选择的输出](Images/pmlo_0541.png)'
- en: Figure 5-41\. FLAML output from model selection
  id: totrans-260
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-41\. FLAML 模型选择的输出
- en: What is exciting about these open source frameworks is their ability to make
    complicated things possible and easy things automated. Next up, let’s take a look
    at how model explainability works with a project walkthrough.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这些开源框架的令人兴奋之处在于它们能够实现复杂的事情并自动化简单的事情。接下来，让我们看看模型解释在项目演示中是如何工作的。
- en: Note
  id: totrans-262
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: 'There is no shortage of open source AutoML frameworks. Here are some additional
    frameworks to look at for AutoML:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 开源 AutoML 框架不计其数。以下是一些用于 AutoML 的额外框架：
- en: AutoML
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动机器学习
- en: '[H2O AutoML](https://oreil.ly/OanPd)'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[H2O AutoML](https://oreil.ly/OanPd)'
- en: '[Auto-sklearn](https://oreil.ly/wrchl)'
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Auto-sklearn](https://oreil.ly/wrchl)'
- en: '[tpot](https://oreil.ly/lZz6k)'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tpot](https://oreil.ly/lZz6k)'
- en: '[PyCaret](https://pycaret.org)'
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyCaret](https://pycaret.org)'
- en: '[AutoKeras](https://autokeras.com)'
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AutoKeras](https://autokeras.com)'
- en: Model Explainability
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型解释能力
- en: An important aspect of automation in machine learning is to automate model explainability.
    MLOps platforms all can use this capability as yet another dashboard for the team
    to look at during work. For example, an MLOps team starting at work in the morning
    may look at the CPU and memory usage of servers *and* the explainability report
    of the model they trained last night.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化机器学习中的一个重要方面是自动化模型解释能力。MLOps 平台可以使用这一能力作为团队工作期间的另一个仪表板。例如，一个 MLOps 团队在早晨开始工作时可能会查看服务器的
    CPU 和内存使用情况以及他们昨晚训练的模型的解释性报告。
- en: Cloud-based MLOps frameworks like AWS SageMaker, Azure ML Studio, and Google
    Vertex AI have built-in model explainability, but you can implement it yourself
    with open source software as well. Let’s walk through an explainability workflow
    to see how this works using this [model explainability GitHub project](https://oreil.ly/lQpBT).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 像AWS SageMaker、Azure ML Studio和Google Vertex AI等基于云的MLOps框架具有内置的模型可解释性，但您也可以使用开源软件自行实现。让我们通过一个模型可解释性GitHub项目来详细介绍这个工作流程：[model
    explainability GitHub项目](https://oreil.ly/lQpBT)。
- en: Note
  id: totrans-273
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Two popular open source Model Explainability frameworks are ELI5 and SHAP. Here
    is a bit more information about each one.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ELI5和SHAP是两个流行的开源模型可解释性框架。以下是关于每个框架的更多信息。
- en: ELI5
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ELI5
- en: '[ELI5](https://oreil.ly/7yDZb) stands for “explain like I am five.” It allows
    you to visualize and debug machine learning models and supports several frameworks,
    including sklearn.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '[ELI5](https://oreil.ly/7yDZb) 代表“像我五岁那样解释”。它允许您可视化和调试机器学习模型，并支持包括sklearn在内的多个框架。'
- en: SHAP
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP
- en: '[SHAP](https://oreil.ly/LgjDL) is a “game-theoretic” approach to explain the
    output of machine learning models. In particular, it has excellent visualizations
    as well as explanations.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '[SHAP](https://oreil.ly/LgjDL) 是解释机器学习模型输出的“博弈论”方法。特别是它具有出色的可视化和解释能力。'
- en: 'First, using a [Jupyter notebook](https://oreil.ly/Fddra), let’s ingest NBA
    data from the 2016–2017 season and print out the first few rows using the `head`
    command. This data contains AGE, POSITION, FG (Field Goals/Game), and social media
    data like Twitter retweets:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用[Jupyter notebook](https://oreil.ly/Fddra)，让我们导入2016-2017赛季的NBA数据，并使用`head`命令打印出前几行。此数据包含年龄、位置、场均命中率（FG）以及Twitter转发等社交媒体数据：
- en: '[PRE12]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Next, let’s create a new feature called a `winning_season`, which allows us
    to predict whether a player will be part of a team with a winning season. For
    example, in [Figure 5-42](#Figure-5-32), you can see plotting the NBA player’s
    age versus the wins to discover a potential age-based pattern.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建一个名为`winning_season`的新特征，这使得我们可以预测球员是否会成为赛季胜利球队的一部分。例如，在[图 5-42](#Figure-5-32)中，您可以看到绘制NBA球员年龄与胜利次数的图表，以发现潜在的基于年龄的模式。
- en: '![Winning Season Feature](Images/pmlo_0542.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![赢球季节特征](Images/pmlo_0542.png)'
- en: Figure 5-42\. Winning season feature
  id: totrans-283
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-42\. 赢球季节特征
- en: 'Now, let’s move on to modeling and predict wins. But first, let’s clean up
    the data a bit and drop columns that aren’t necessary and drop missing values:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续建模并预测胜利。但首先，让我们稍微清理一下数据，并丢弃不必要的列和丢失的值：
- en: '[PRE13]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'After this cleanup, the `shape` command prints out the number of rows, 239,
    and columns, 7:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此清理后，`shape`命令打印出行数239和列数7：
- en: '[PRE14]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next up, let’s train the model by first splitting the data, then using logistic
    regression:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们通过首先分割数据，然后使用逻辑回归来训练模型：
- en: '[PRE15]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'You should see an output similar to the following result that shows the model
    training is successful:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似以下结果的输出，显示模型训练成功：
- en: '[PRE16]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, let’s move on to the fun part explaining how the model came up with its
    SHAP framework predictions. But, first, SHAP needs installation:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续解释模型如何提出其SHAP框架预测的有趣部分。但是，首先需要安装SHAP：
- en: '[PRE17]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, let’s use `xgboost`, another classification algorithm, to explain to
    the model since SHAP has outstanding support for it:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们使用`xgboost`，另一种分类算法，来解释模型，因为SHAP对它有出色的支持：
- en: '[PRE18]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In [Figure 5-43](#Figure-5-33), you can see a force plot in SHAP showing the
    features in red push the prediction higher, and the features in blue push the
    prediction lower.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 5-43](#Figure-5-33)中，您可以看到SHAP的力量图，显示红色特征推高预测值，而蓝色特征推低预测值。
- en: '![SHAP output xgboost](Images/pmlo_0543.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![SHAP输出xgboost](Images/pmlo_0543.png)'
- en: Figure 5-43\. SHAP output xgboost
  id: totrans-298
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-43\. SHAP输出xgboost
- en: '[PRE19]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In [Figure 5-44](#Figure-5-34), a summary plot shows the absolute mean value
    of what features drive the model. So, for example, you can see how “off the court”
    metrics like Twitter and Salary are essential factors in why the model predicts
    wins the way it does.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 5-44](#Figure-5-34)中，汇总图显示了驱动模型的特征绝对平均值。因此，例如，您可以看到“场外”指标如Twitter和薪水是为何模型以其方式预测胜利的重要因素。
- en: '![SHAP Feature Importance](Images/pmlo_0544.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![SHAP特征重要性](Images/pmlo_0544.png)'
- en: Figure 5-44\. SHAP feature importance
  id: totrans-302
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-44\. SHAP特征重要性
- en: 'Let’s see how another open source tool works; this time, let’s use ELI5\. First,
    install it with `pip`:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看另一个开源工具是如何工作的；这次，让我们使用ELI5。首先，使用`pip`安装它：
- en: '[PRE20]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next up, permutation importance performs on the original logistic regression
    model created earlier. This process works by measuring the amount of accuracy
    decrease by removing features:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，排列重要性对先前创建的原始逻辑回归模型执行。这个过程通过测量去除特征后准确度的降低来工作：
- en: '[PRE21]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You can see in [Figure 5-45](#Figure-5-35) that the original logistic regression
    model has a different feature importance than the XGBoost model. In particular,
    note that the age of a player has a negative correlation with wins.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [图 5-45](#Figure-5-35) 中看到，原始的逻辑回归模型与 XGBoost 模型具有不同的特征重要性。特别要注意的是，球员的年龄与胜利之间存在负相关。
- en: '![ELI5 Permutation Importance](Images/pmlo_0545.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![ELI5 Permutation Importance](Images/pmlo_0545.png)'
- en: Figure 5-45\. ELI5 permutation importance
  id: totrans-309
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-45\. ELI5 排列重要性
- en: Explainability is an essential aspect of MLOps. Just as we have dashboards and
    metrics for software systems, there should also be explainability for how an AI/ML
    system came to its prediction. This explainability can lead to healthier outcomes
    for both stakeholders of the business and the business itself.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性是 MLOps 的一个重要方面。正如我们为软件系统拥有仪表板和指标一样，AI/ML 系统如何进行预测也应该有可解释性。这种可解释性可以导致业务利益相关者和业务本身的更健康的结果。
- en: Next, let’s wrap up everything covered in the chapter.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们总结本章涵盖的所有内容。
- en: Conclusion
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: AutoML is an essential new capability for any team doing MLOps. AutoML improves
    the ability for a team to push models into production, work on complex problems,
    and ultimately work on what matters. It is essential to point out that Automated
    Modeling, i.e., AutoML, is not the only component of KaizenML or continuous improvement.
    In the oft-cited paper [“Hidden Technical Debt in Machine Learning Systems”](https://oreil.ly/ZZfjY)
    the authors mention that modeling is a trivial amount of the work in a real-world
    ML system. Likewise, it should be no surprise that AutoML, i.e., the automation
    of modeling, is a small part of what needs to be automated. Everything from data
    ingestion to feature storage to modeling to training to deployment to an evaluation
    of the model in production is a candidate for full automation. KaizenML means
    you are constantly improving every single part of the machine learning system.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML 是任何进行 MLOps 的团队的重要新能力。AutoML 提高了团队将模型推向生产、处理复杂问题以及最终处理重要事务的能力。需要指出的是，自动建模，即
    AutoML，并不是 KaizenML 或持续改进的唯一组成部分。在经常引用的论文 [“Hidden Technical Debt in Machine Learning
    Systems”](https://oreil.ly/ZZfjY) 中，作者提到建模在真实世界的 ML 系统中只是很少一部分工作量。同样，自动建模，即对建模的自动化，只是需要自动化的一小部分。从数据摄取到特征存储再到建模再到训练再到部署再到在生产环境中评估模型的所有工作都有可能进行全面自动化。KaizenML
    意味着您正在不断改进机器学习系统的每一个部分。
- en: Just as automated transmission and cruise-control systems assist an expert driver,
    automation of the subcomponents of a production machine learning system makes
    the humans in charge of the ML decisions better. Things can and should be automated,
    including modeling aspects, software engineering best practices, testing, data
    engineering, and other essential components. Continuous improvement is a cultural
    change that doesn’t have an end date and fits into any organization wanting to
    make impactful changes with AI and machine learning.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 就像自动变速器和巡航控制系统帮助专家驾驶员一样，生产机器学习系统的子组件的自动化使负责 ML 决策的人类变得更好。事情可以也应该自动化，包括建模方面、软件工程最佳实践、测试、数据工程以及其他重要组件。持续改进是一种文化变革，没有结束日期，适用于任何希望通过
    AI 和机器学习进行有重大影响变革的组织。
- en: A final takeaway is that there are many free or nearly free AutoML solutions.
    Just as developers worldwide use free or roughly free high-level tools like build
    servers and code editors to improve software, ML practitioners should use automation
    tools of all types to enhance their productivity.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的收获是，有许多免费或几乎免费的 AutoML 解决方案。正如全球开发人员使用免费或大致免费的高级工具（如构建服务器和代码编辑器）来改善软件一样，ML
    从业者应该使用各种类型的自动化工具来提高他们的生产力。
- en: Next up is the chapter on monitoring and logging. I call this “data science
    for operations.” Before you jump into that topic, take a look at the following
    exercises and critical thinking questions.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是关于监控和日志记录的章节。我称之为“运维中的数据科学”。在深入讨论这个主题之前，请看以下练习和关键思考问题。
- en: Exercises
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Download XCode and use Apple’s Create ML to train a model from a sample dataset
    you find on Kaggle, or another open dataset location.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载 XCode 并使用 Apple 的 Create ML 来从在 Kaggle 或其他开放数据集位置找到的样本数据集训练模型。
- en: Use Google’s AutoML Computer Vision platform to train a model and deploy it
    to a [Coral.AI device](https://coral.ai).
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Google的AutoML计算机视觉平台来训练模型，并部署到[Coral.AI设备](https://coral.ai)。
- en: Use Azure ML Studio to train a model and explore the explainability features
    of Azure ML Studio.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Azure ML Studio训练模型，并探索Azure ML Studio的可解释性功能。
- en: Use [ELI5](https://oreil.ly/Nwrck) to explain a machine learning model.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[ELI5](https://oreil.ly/Nwrck)来解释机器学习模型。
- en: Use [Ludwig](https://oreil.ly/GRjgG) to train a machine learning model.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[Ludwig](https://oreil.ly/GRjgG)来训练机器学习模型。
- en: Select a SageMaker Automatic Model Tuning example from the [official SageMaker
    examples](https://oreil.ly/fe71a) and run through it on your AWS Account.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从[官方SageMaker示例](https://oreil.ly/fe71a)中选择一个SageMaker自动模型调优的示例，并在您的AWS账户上运行它。
- en: Critical Thinking Discussion Questions
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批判性思维讨论问题
- en: Why is AutoML only part of the automation story with modern machine learning?
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么AutoML只是现代机器学习自动化故事的一部分？
- en: How could the [NIH](https://nih.gov) (National Institutes of Health) use a Feature
    Store to increase the speed of medical discoveries?
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[国立卫生研究院（NIH）](https://nih.gov)如何利用特征存储来加快医学发现的速度？'
- en: By 2025, what parts of machine learning will be fully automated and what aspects
    will not? By 2035, what parts of machine learning will be fully automated and
    what factors will not?
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 到2025年，机器学习的哪些部分将完全自动化，哪些方面不会？到2035年，机器学习的哪些部分将完全自动化，哪些因素不会？
- en: How could vertically integrated AI platforms (chips, frameworks, data, and more)
    give particular companies a competitive advantage?
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 垂直集成的AI平台（芯片、框架、数据等）如何给特定公司带来竞争优势？
- en: How does the chess software industry provide insights into how AI and humans
    work together for improved outcomes in solving problems for AutoML?
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何运用国际象棋软件行业的见解，深化AI和人类合作，以改善AutoML问题解决的结果？
- en: How does a data-centric approach differ from a model-centric approach to machine
    learning? How about a KaizenML approach where data, software, and modeling are
    all treated as equally important?
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中心的方法与模型中心的方法在机器学习中有何不同？对于KaizenML方法，其中数据、软件和建模都被同等重视，有何不同？
