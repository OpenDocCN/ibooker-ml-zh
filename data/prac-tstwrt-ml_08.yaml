- en: Chapter 8\. An Ecosystem of Trust
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 生态系统的信任
- en: So far in this book, you have learned about the tools required to embark on
    the journey of becoming an effective responsible ML practitioner. But are they
    enough? What else do you need to build, deploy, and iterate on ML systems that
    a diverse group of stakeholders can trust? Beyond the individual tools and techniques
    covered earlier, you need to know how to put these different pieces together to
    reach an ML-driven solution for your business problem while minimizing downstream
    risks. This sounds daunting at first, but there are resources in this growing
    field that can help achieve this goal.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本书中，您已经了解了成为有效负责任的机器学习从业者所需的工具。但这些是否足够？您还需要哪些内容来构建、部署和迭代能够让各种利益相关者信任的机器学习系统？除了前面介绍的个别工具和技术外，您还需要知道如何将这些不同的部分组合在一起，以解决业务问题的机器学习驱动解决方案，同时最小化下游风险。起初听起来可能令人生畏，但在这个增长领域中有一些资源可以帮助实现这一目标。
- en: This chapter will cover tools, tactics, and frameworks that provide a bird’s-eye
    view of what’s going on within and across ML models inside a company. To begin
    with, you’ll learn about technical tools for implementing ML pipelines and about
    guidelines and strategies to navigate the human-in-the-loop steps in ML pipelines
    effectively. You’ll be introduced to a few concepts and resources that help gain
    a cross-project outlook on ML workflows inside your company. Finally, you’ll see
    how all this knowledge can come together by exploring a deep-dive example of implementing
    an ML-based recommender system. If you are a product or engineering leader, the
    resources in this chapter will help you effectively collaborate with business
    stakeholders on implementing trusted ML. If you are an ML engineer or data scientist,
    you will gain valuable context for understanding trade-offs and constraints while
    determining the technical steps in a project.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖提供公司内部和跨越机器学习模型的鸟瞰视图的工具、策略和框架。首先，您将了解实施机器学习管道的技术工具以及有效导航人在环机器学习管道中的步骤的指南和策略。您将介绍一些概念和资源，帮助您在公司内部的机器学习工作流程中获得跨项目的视角。最后，通过探索实施基于机器学习的推荐系统的深度示例，您将看到所有这些知识如何结合在一起。如果您是产品或工程领导者，本章中的资源将帮助您与业务利益相关者有效合作，实施可信机器学习。如果您是机器学习工程师或数据科学家，您将获得有价值的背景知识，了解在项目中确定技术步骤时的权衡和约束条件。
- en: Tooling
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工具
- en: Chapters [1](ch01.html#chapter1) to [5](ch05.html#chapter5) focused on open
    source tooling for each aspect of trust. However, those tools are not sufficient
    for an end-to-end ML workflow. Many of them do not scale for the computational
    needs and dataset sizes of industry ML projects. They may also presuppose some
    knowledge that is not always readily available for a new project, such as that
    needed to choose metrics, data availability, and clear stakeholder needs. Keeping
    in mind such limitations, let’s dive a bit deeper into what else you might require
    to operationalize technical knowledge on trustworthy ML.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 第[1](ch01.html#chapter1)到[5](ch05.html#chapter5)章节侧重于信任每个方面的开源工具。然而，这些工具对于端到端的机器学习工作流程并不足够。它们中的许多并不适用于行业机器学习项目的计算需求和数据集大小。它们可能还预设了一些并不总是为新项目提供的知识，例如选择指标、数据可用性和明确的利益相关者需求。在考虑这些限制的同时，让我们更深入地探讨一下，您可能需要什么来使可信机器学习的技术知识操作化。
- en: LiFT
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LiFT
- en: Unfortunately, most technical tooling openly available in the trustworthy ML
    space is just not scalable to large amounts of data. When you want to analyze
    huge datasets in applications such as web-scale recommendations, LinkedIn Fairness
    Toolkit (LiFT)^([1](ch08.html#idm45621830884688)) is the only open source, scalable
    solution available. The tool kit’s [Spark/Scala library](https://oreil.ly/iuWLn)
    is mainly aimed at measuring a number of fairness metrics that are applicable
    to (a) data-level or model-level output labels and (b) discrete or continuous
    output and discrete sensitive features. The only mitigation technique LiFT offers
    is the equality of opportunity transformation.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，大多数技术工具在可信的机器学习领域公开可用，但并不适用于大量数据的扩展。当您希望分析像是Web规模推荐等应用中的大数据集时，[LinkedIn
    Fairness Toolkit (LiFT)](ch08.html#idm45621830884688)是唯一一个提供开源且可扩展解决方案的工具。该工具包的[Spark/Scala库](https://oreil.ly/iuWLn)主要用于测量适用于数据级或模型级输出标签的公平度量指标，以及适用于离散或连续输出和离散敏感特征的公平度量指标。LiFT提供的唯一缓解技术是机会平等转换。
- en: There are valuable take-home lessons in LiFT. You absolutely need to focus on
    R&D to come up with the latest and greatest methods in fairness, explainability,
    privacy, safety, and robustness. But when it comes to applicability to real problems,
    the story is a bit different. Ultimately, you are limited by the scale and quality
    of your data, the complexity of the methods you apply, the timeline of your project,
    and the business goals. Coming up with a workable solution within these constraints
    is tricky. For example, for a petabyte-scale problem involving customer data,
    you are probably never going to be able to apply the in-processing bias mitigation
    techniques from AI Fairness 360\. Instead, you might need to settle for a post-processing
    method or a homebrew solution custom-made for your internal computing architecture.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在LiFT中有宝贵的经验教训。你绝对需要专注于研发，以提出公平性、可解释性、隐私性、安全性和鲁棒性的最新方法。但是当涉及到在实际问题上的适用性时，情况就有些不同了。最终，你受到数据规模和质量、应用方法的复杂性、项目时间表和业务目标的限制。在这些约束条件下找到可行的解决方案是棘手的。例如，对于涉及客户数据的PB级问题，你可能永远无法应用AI
    Fairness 360中的处理中偏差缓解技术。相反，你可能需要采用后处理方法或为内部计算架构量身定制的自制解决方案。
- en: Datasheets
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据表
- en: 'Datasheets for Datasets is another tool that helps build trust in applied ML
    workflows.^([2](ch08.html#idm45621830875680)) Basically, the paper distills salient
    features of a dataset in a predefined schema for future use. Datasheets organizes
    these features into seven sections—each section comprises a set of questions.
    The answers to these questions should supply information about different stages
    of data collection and potential usage:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集数据表是帮助建立应用机器学习工作流程信任的另一工具^([2](ch08.html#idm45621830875680))。基本上，该论文将数据集的显著特征提炼出来，以预定义的模式组织为未来使用而准备的数据表。数据表将这些特征分为七个部分——每个部分包含一组问题。这些问题的答案应该提供有关数据收集的不同阶段和潜在用途的信息：
- en: '*Motivation*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*动机*'
- en: This section records the reasons for collecting a dataset, along with information
    such as funding agency and data collector. The onus is on the data collector to
    write down information useful for downstream consumers of the data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本节记录了收集数据集的原因，以及资助机构和数据收集者等信息。数据收集者有责任记录对数据下游消费者有用的信息。
- en: '*Composition*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*构成*'
- en: This section aims to empower the dataset user to make informed decisions about
    the usefulness of this dataset for their task. Some of the questions are about
    how a dataset relates to information about people. This can be important for compliance
    purposes, for example with the European Union’s General Data Protection Regulation
    (GDPR).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本节旨在让数据集用户能够就其在任务中的有用性做出知情决策。一些问题涉及数据集与个人信息的相关性。这对于遵守例如欧盟的通用数据保护条例（GDPR）等法规可能很重要。
- en: '*Collection*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*收集*'
- en: If you’re a dataset curator, you should read the questions before collecting
    data to anticipate potential issues, then answer after you’ve collected the data.
    If you’re a dataset consumer, these answers will tell you of data collection-related
    issues (e.g., missing data, sampling imbalance) that may impact how you can use
    the dataset for your purposes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是数据集策展人，你应该在收集数据之前阅读这些问题，以预测潜在问题，然后在收集数据后回答。如果你是数据集使用者，这些答案将告诉你与数据收集相关的问题（例如，缺失数据、抽样不平衡），这些问题可能会影响你如何为你的目的使用数据集。
- en: '*Pre-processing*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*预处理*'
- en: The intention here is to store information about the ETL processing of raw data.
    Again, dataset creators need to read these questions before collecting data, and
    consumers need to read the answers before using the data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的意图是存储有关原始数据的ETL处理的信息。再次强调，数据集创建者需要在收集数据之前阅读这些问题，消费者需要在使用数据之前阅读答案。
- en: '*Uses*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*用途*'
- en: Dataset creators should give thought to what applications this dataset can or
    cannot be used for and record those in this section to guide dataset consumers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集创建者应该考虑此数据集可以或不能用于哪些应用，并将其记录在本节中，以指导数据集消费者。
- en: '*Distribution*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*分发*'
- en: Similar to *uses*, these questions ask dataset curators to record some guidelines
    for dataset consumers. In this case, the guidelines are concerned with details
    about distributing the dataset, such as licenses, unique identifiers such as DOI,
    and any restrictions.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 与*用途*类似，这些问题要求数据集策展人记录一些关于数据集消费者的指导方针。在这种情况下，指导方针关注的是分发数据集的详细信息，例如许可证、DOI等唯一标识符以及任何限制。
- en: '*Maintenance*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*维护*'
- en: Business-critical datasets are actively maintained and updated. That information
    may be useful to dataset consumers. For example, if you want to deploy an ML model
    in production, knowing the update schedule of the underlying dataset would help
    you to decide when to update your production model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 业务关键数据集正在积极维护和更新。这些信息可能对数据集使用者有用。例如，如果您想要在生产环境中部署ML模型，了解底层数据集的更新时间表将帮助您决定何时更新您的生产模型。
- en: Throughout these seven sections, there are multiple questions that touch upon
    trust aspects of downstream usage of datasets. Let’s look at the questions, provided
    by Gebru et al. in “Datasheets for Datasets,” in [Table 8-1](#table-datasheets).
    For the broader list of questions, look back at Gebru et al., “Datasheets for
    Datasets,” or [this GitHub repository](https://oreil.ly/EoB3V). The repository
    gives the questions in the form of a template that you can download and use to
    build your own datasheet. It also references a few examples of datasheets. Examples
    of datasheets integrated into ML pipelines are discussed [later](#sec-example)
    in this chapter.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这七个部分中，有多个问题涉及数据集下游使用的信任方面。让我们来看一下这些问题，由Gebru等人在《数据集数据表》中提供，详见[表8-1](#table-datasheets)。查看更广泛的问题列表，请参考Gebru等人的《数据集数据表》，或者访问[此GitHub仓库](https://oreil.ly/EoB3V)。该仓库提供了问题的模板形式，您可以下载并用于创建您自己的数据表。它还引用了一些数据表的示例。本章稍后将讨论集成到ML管道中的数据表示例（见#sec-example）。
- en: Table 8-1\. Datasheet questions that touch upon elements of trust
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-1. 触及信任要素的数据表问题
- en: '| Section | Question |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 部分 | 问题 |'
- en: '| --- | --- |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Composition | Does the dataset identify any subpopulations (e.g., by age,
    gender)? |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 组成 | 数据集是否识别任何子人群（例如按年龄、性别）？ |'
- en: '|  | Is it possible to identify individuals (i.e., one or more natural persons),
    either directly or indirectly (i.e., in combination with other data) from the
    dataset? |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '|  | 是否可能直接或间接地（即与其他数据结合）从数据集中识别个人（即一个或多个自然人）？ |'
- en: '|  | Does the dataset contain data that might be considered sensitive in any
    way (e.g., data that reveals race or ethnic origins, sexual orientations, religious
    beliefs, political opinions or union memberships, or locations; financial or health
    data; biometric or genetic data; forms of government identification, such as Social
    Security numbers; criminal history)? |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|  | 数据集是否包含可能在任何方面被视为敏感的数据（例如显示种族或族裔起源、性取向、宗教信仰、政治观点或工会会员身份、地理位置的数据；财务或健康数据；生物识别或遗传数据；政府身份识别形式，如社会安全号码；犯罪记录）？
    |'
- en: '| Collection | Did you collect the data from the individuals in question directly,
    or obtain it via third parties or other sources (e.g., websites)? |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 收集 | 您是直接从相关个体收集数据，还是通过第三方或其他来源（例如网站）获取的？ |'
- en: '|  | Were the individuals in question notified about the data collection? |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  | 是否已通知相关个体有关数据收集的事宜？ |'
- en: '|  | Did the individuals in question consent to the collection and use of their
    data? |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '|  | 个体是否同意收集和使用他们的数据？ |'
- en: '|  | If consent was obtained, were the consenting individuals provided with
    a mechanism to revoke their consent in the future or for certain uses? |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  | 如果获得了同意，那么被授权的个体是否提供了未来撤销同意或特定用途的机制？ |'
- en: '|  | Has an analysis of the potential impact of the dataset and its use on
    data subjects (e.g., a data protection impact analysis) been conducted? |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|  | 是否对数据集及其使用对数据主体的潜在影响进行了分析（例如，数据保护影响分析）？ |'
- en: '| Uses | Is there anything about the composition of the dataset or the way
    it was collected and pre-processed/cleaned/labeled that might impact future uses?
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 用途 | 数据集的组成或收集、预处理/清洗/标记方式是否会影响将来的使用？ |'
- en: '|  | Are there tasks for which the dataset should not be used? |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | 有哪些任务不应使用该数据集？ |'
- en: '| Distribution | Do any export controls or other regulatory restrictions apply
    to the dataset or to individual instances? |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 分发 | 数据集或个别实例是否受到任何出口控制或其他监管限制？ |'
- en: '| Maintenance | If the dataset relates to people, are there applicable limits
    on the retention of the data associated with the instances (e.g., were the individuals
    in question told that their data would be retained for a fixed period of time
    and then deleted)? |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 维护 | 如果数据集涉及人员，那么与实例相关的数据的保留是否受到适用的限制（例如，相关个体是否被告知其数据将在固定期限后删除）？ |'
- en: Model Cards
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型卡片
- en: Technically, datasheets can contain information about *any* dataset, which may
    or may not be used to build an ML model. In contrast, model cards are more directly
    related to ML, especially trustworthy ML.^([3](ch08.html#idm45621830828048)) Model
    cards contain metadata—​including acceptable thresholds and evaluations—of released
    or deployed ML models. The evaluations not only record performance metrics such
    as accuracy and mean-squared error (MSE), but they also encompass trust metrics
    relevant to the particular use case tackled by the ML model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，数据表可以包含关于*任何*数据集的信息，这些数据集可能用于构建或不用于构建 ML 模型。相比之下，模型卡与 ML 更直接相关，尤其是可信赖的
    ML。[^3] 模型卡包含发布或部署的 ML 模型的元数据，包括可接受的阈值和评估。评估不仅记录了准确度和均方误差（MSE）等性能指标，还包括与 ML 模型处理的特定用例相关的信任指标。
- en: 'As originally proposed, model cards should contain the following sections.
    These can be tailored to fit the purposes of your own use case—or the use cases
    your organization deals with in general. Here’s a small summary of what each section
    deals with:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最初建议，模型卡应包含以下几个部分。这些可以根据您自己的用例或您的组织通常处理的用例进行定制。以下是每个部分涉及的小结：
- en: '*Model details*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型细节*'
- en: Contains metadata such as the person or organization that developed the model,
    model version, model type (supervised/unsupervised, classification/regression
    etc.), resource (paper, GitHub repository), citation details, license, and how
    to give feedback.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 包含元数据，如开发模型的人员或组织、模型版本、模型类型（监督/无监督、分类/回归等）、资源（论文、GitHub 仓库）、引用详细信息、许可证以及如何提供反馈。
- en: '*Intended use*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*预期用途*'
- en: Contains primary purpose of the model (e.g., classify images of cats versus
    dogs), primary users (e.g., organizations, Kaggle competitors), and out-of-scope
    uses.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 包含模型的主要目的（例如分类猫和狗的图像）、主要用户（例如组织、Kaggle 竞争者）以及超出范围的用途。
- en: '*Factors*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*因素*'
- en: 'Contains the information on factors that can influence performance of the model.
    The authors of model cards divide these factors into three categories: *groups*
    (important subgroups of the sample, such as races, genders, or their combinations
    for models where each sample relates to one or more individuals), *instrumentation*
    (details of the data collection environment, such as camera hardware details for
    a face detection model), and *environment* (details of the deployed environment,
    such as the light condition for a computer vision model).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 包含可以影响模型性能的因素信息。模型卡的作者将这些因素分为三类：*群体*（样本的重要子群，如种族、性别或它们的组合，对于每个样本与一个或多个个体相关的模型）、*仪器设备*（数据收集环境的详细信息，例如面部检测模型的摄像头硬件详情）、以及*环境*（部署环境的详细信息，例如计算机视觉模型的光照条件）。
- en: '*Metrics*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*度量*'
- en: Includes the types of performance, trust, or any other custom metrics used for
    evaluation of the model, their acceptable thresholds, validation details such
    as uncertainty metrics (e.g., standard deviation, confidence interval) and validation
    method (e.g., tenfold cross-validation, single train-test split).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 包括性能类型、信任度或任何其他用于评估模型的自定义指标，其可接受的阈值，验证细节如不确定性指标（例如标准差、置信区间）以及验证方法（例如十折交叉验证、单次训练测试拆分）。
- en: '*Evaluation data*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*评估数据*'
- en: Contains details on evaluation data such as the dataset’s composition, motivation
    for choosing this data, and any pre-processing done on the data.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 包含评估数据的详细信息，例如数据集的组成、选择该数据的动机以及对数据进行的任何预处理。
- en: '*Training data*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*训练数据*'
- en: Contains the same information as evaluation data, except for the cases where
    the training data is proprietary or protected. In that case, high-level information
    on the training data should be provided.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 包含与评估数据相同的信息，除非训练数据是专有的或受保护的。在这种情况下，应提供有关训练数据的高级信息。
- en: '*Quantitative analyses*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*定量分析*'
- en: Contains evaluation results, including the values of the metrics reported in
    the metrics section, measuring the relevant factors on the evaluation data used.
    Each factor is evaluated separately, and the relevant intersections of various
    factors are also reported (e.g., disparate impact for Black versus White, female
    versus male, or Black women versus others).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 包含评估结果，包括度量部分报告的指标值，在使用的评估数据上测量相关因素。每个因素都是单独评估的，还报告了各种因素的相关交集（例如，黑人与白人、女性与男性、或黑人女性与其他人之间的不均衡影响）。
- en: '*Ethical considerations*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*伦理考虑*'
- en: Consciously documents the ethical considerations behind model development. Such
    considerations can include any use of sensitive data, health and safety concerns,
    relevant risks and harms and mitigation strategies for them, and potential applications
    of the model that pose risks.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有意识地记录了模型开发背后的伦理考虑。这些考虑可以包括对敏感数据的任何使用，健康和安全问题，相关的风险和危害以及针对它们的缓解策略，以及可能存在风险的模型应用。
- en: '*Caveats and recommendations*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*警告和建议*'
- en: Contains any concerns and information not presented in the sections that precede
    it.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 包含了在前面章节中未提到的任何关注点和信息。
- en: A major difference between model cards and datasheets that you probably have
    already noticed is that trust considerations are much more prominent in model
    cards. This makes sense, since models are more actionable than data. And as we
    discussed earlier in this book, there’s so much that can go wrong with ML models
    if the ML team does not give any consideration to trust issues during model development.
    For these reasons, model cards advises ML practitioners to proactively consider,
    measure, and document ethical aspects of each and every model they develop.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到的模型卡和数据表之间的一个重要区别是，信任考虑在模型卡中更为突出。这是有道理的，因为模型比数据更具行动性。正如我们在本书早期讨论的那样，如果机器学习团队在模型开发过程中不考虑信任问题，那么机器学习模型可能出现许多问题。因此，模型卡建议机器学习从业者积极考虑、衡量和记录每个模型的伦理方面。
- en: '[This GitHub repository](https://oreil.ly/sBFog) gives a template for model
    cards that you can download and use. It also contains a few examples of model
    cards of fairly well-known ML models. Beyond one-off examples, [HuggingFace](https://oreil.ly/ytnqM)
    mandates the creation of a model card for pre-trained model submissions (e.g.,
    `bert-base-uncased`). If you work in NLP and have worked with pre-trained models
    from their platform, chances are you’ve come across model cards already!'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[这个GitHub存储库](https://oreil.ly/sBFog)提供了一个模型卡的模板，您可以下载并使用。它还包含一些相当知名的机器学习模型的模型卡示例。除了一次性示例之外，[HuggingFace](https://oreil.ly/ytnqM)要求为预训练模型提交创建模型卡（例如`bert-base-uncased`）。如果您在自然语言处理领域工作，并且使用过他们平台上的预训练模型，那么您很可能已经接触过模型卡！'
- en: DAG Cards
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DAG卡
- en: Datasheets contain data metadata and model cards contain model metadata. DAG
    Cards—proposed very recently—are the next step in this evolution.^([4](ch08.html#idm45621830798720))
    They contain ML pipeline metadata. DAG cards structure all salient information
    in an ML pipeline, including the processing and transformation of data and model
    training, evaluation, and deployment, in one single place. Following the [Airflow](https://oreil.ly/smAav)
    platform used to build data-engineering pipelines, DAG cards represent all this
    information in a modularized manner using DAGs.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据表包含数据元数据，而模型卡包含模型元数据。最近提出的DAG卡是这一演变的下一步。^([4](ch08.html#idm45621830798720))
    它们包含机器学习管道的所有关键信息。DAG卡在一个地方结构化了所有这些信息，包括数据和模型的处理和转换、模型的训练、评估和部署。类似于用于构建数据工程管道的[Airflow](https://oreil.ly/smAav)平台，DAG卡使用DAGs以模块化方式表示所有这些信息。
- en: The good thing about DAG Cards is that there’s little overhead and manual work
    involved. Metaflow and Weights & Biases (W&B) are widely used tools for running
    ML model pipelines and for doing model training, respectively. Given that you’re
    using these two tools, you can just download the DAG Cards code from [GitHub](https://oreil.ly/GqYhW)
    to extract and display information about the model training pipeline DAG. DAG
    Cards drive transparency by summarizing this code-generated information into a
    human-readable document. Traditionally, Confluence pages or internal wikis do
    the job of communicating information about ML models inside a company. But such
    documentation isn’t tightly coupled with code and needs to be updated manually.
    Most importantly, the number of details and amount of structure in these documents
    heavily depends on who is writing them. DAG Cards solve this problem. A DAG Card
    is self-sufficient documentation that is helpful to both the hands-on coding team
    and hands-off people such as product managers and business stakeholders.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: DAG卡的优点在于几乎没有额外的手动工作。Metaflow和Weights & Biases（W&B）是广泛使用的工具，用于运行ML模型管道和进行模型训练。如果您使用这两个工具，您可以从[GitHub](https://oreil.ly/GqYhW)下载DAG卡代码，以提取和显示有关模型训练管道DAG的信息。DAG卡通过将这些由代码生成的信息总结为可读文档来推动透明度。传统上，Confluence页面或内部维基负责在公司内部传达有关ML模型的信息。但这类文档与代码的耦合不强，并且需要手动更新。最重要的是，这些文档中的细节和结构程度很大程度上取决于编写者。DAG卡解决了这个问题。DAG卡是一种自足的文档，对于实际编码团队和产品经理等非直接参与的人员都很有帮助。
- en: Even though DAG cards don’t directly contribute to trustworthy ML development,
    they enable an ML team—and the associated product team—to summarize existing trust
    considerations and look out for unaddressed concerns. In the (non-ML) software
    world, a [software bill of materials](https://oreil.ly/l6HRK) (SBOM) enables proactive
    security and risk monitoring of a complex software by maintaining a structured
    inventory of its building blocks. In a way, DAG Cards are the equivalent of SBOM,
    but in the applied ML world.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管DAG卡不直接促进可信ML开发，但它们使ML团队和相关产品团队能够总结现有的信任考量，并关注未解决的问题。在（非ML）软件世界中，软件材料清单（SBOM）通过维护其构建块的结构化清单来维护复杂软件的积极安全性和风险监控。在某种程度上，DAG卡相当于应用ML世界中的SBOM。
- en: '[Figure 8-1](#img-dagcards) outlines the generic structure of a DAG Card, outlining
    its different components and the information presented in it.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-1](#img-dagcards)概述了DAG卡的通用结构，列出了其不同组件及其所呈现的信息。'
- en: '![ptml 0801](assets/ptml_0801.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0801](assets/ptml_0801.png)'
- en: Figure 8-1\. A schematic representation of a DAG Card
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-1. DAG卡的示意图表示
- en: Note
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There are a few other tools that serve similar purposes as datasheets, model
    cards, and DAG cards combined. For example, you can check out [Dataset Nutrition
    Labels](https://oreil.ly/3WN0M) and [AI FactSheets 360](https://oreil.ly/ASpCv)
    that also help bring transparency in ML model development pipelines through metadata
    documentation.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他工具，它们的功能类似于数据表、模型卡和DAG卡的结合体。例如，您可以查看[数据集营养标签](https://oreil.ly/3WN0M)和[AI事实表360](https://oreil.ly/ASpCv)，它们也通过元数据文档帮助增强ML模型开发管道的透明度。
- en: Human-in-the-Loop Steps
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人在回路步骤
- en: Technical tooling for and documentation of the end-to-end workflow for ML models
    are necessary, but not sufficient, to enable trust. Your company also needs to
    have a shared rubric about how to approach the human steps of ML workflow. Such
    steps include determining relevant harms at the beginning of an ML project, determining
    sources of data, deciding when to collect additional data, and risk assessment
    at multiple phases of a project. Remember [Figure 7-2](ch07.html#img-system)?
    It shows that trust considerations are relevant to not only ML models, but also
    to the product and marketing strategy, domain knowledge, and operational goals
    of a company.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型端到端工作流的技术工具和文档非常必要，但仅此还不足以建立信任。您的公司还需要有一个关于如何处理ML工作流的人类步骤的共享标准。这些步骤包括在ML项目开始时确定相关危害、确定数据来源、决定何时收集额外数据以及在项目多个阶段进行风险评估。记住[图 7-2](ch07.html#img-system)吗？它显示信任考量不仅与ML模型相关，还涉及公司的产品和营销策略、领域知识以及运营目标。
- en: Let’s take a look at a few best practices that can help structure human-in-the-loop
    steps in an ML development workflow.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些能帮助结构化ML开发工作流中人在回路步骤的最佳实践。
- en: Oversight Guidelines
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督指南
- en: Model cards mandate recording considerations given to ethical issues for each
    and every ML project. But how do you actually go about this? On one hand, the
    ML development team doesn’t usually know about broader issues such as the details
    of regulations and compliance guidelines. On the other hand, the subject matter
    experts (SMEs) whom an ML team can consult to better understand these issues won’t
    be thrilled to sit down and talk about the same things for each and every project.
    So it’s pretty clear that you need a sweet spot between these two extremes.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 模型卡要求记录考虑到每个机器学习项目的伦理问题。但是你如何实际操作呢？一方面，机器学习开发团队通常不了解更广泛的问题，如法规和合规指南的细节。另一方面，机器学习团队可以咨询的专业主题专家（SMEs）可能不会因为每个项目都坐下来谈论相同的事情而感到高兴。因此，很明显，你需要在这两个极端之间找到一个平衡点。
- en: 'Human oversight guidelines (HOG) can help in this situation.^([5](ch08.html#idm45621830769280))
    Basically, these are frequently asked questions (FAQ)-style documents, broken
    down by SME expertise. There are two types of SMEs who may write a HOG:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 人类监督指南（HOG）可以帮助解决这种情况。^([5](ch08.html#idm45621830769280)) 基本上，这些是按照SME专业知识划分的常见问题（FAQ）风格文档。可能编写HOG的两种类型的SME有：
- en: Domain experts
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 领域专家
- en: For example, legal, public relations (PR), or privacy professionals from the
    respective departments in the company
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，公司中相应部门的法律、公共关系（PR）或隐私专业人员
- en: Use-case experts
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 用例专家
- en: For example, senior-level product managers, solution architects, or engineers
    who have deep experience in a specific group of use cases, like fraud, advertising,
    finance, or health data
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，有深厚经验的高级产品经理、解决方案架构师或工程师，专注于特定用例组，如欺诈、广告、金融或健康数据。
- en: Curating a general set of questions and answers beforehand from the SME helps
    *scale* the human-level oversight from that SME over all ML teams in a company.
    This needs to be a one-time, cross-functional effort, led by entities such as
    ML governance, product management, or AI ethics teams. The team(s) in charge of
    this effort would start with a sample list of questions and work with a particular
    SME to finalize the HOG document with a list of questions and their answers. They
    then make the final document available for ML development and product teams to
    consult. These documents become the first line of defense against trust concerns.
    At different stages of the ML model development pipeline, an ML team would consult
    the documents to get guidance. If the best way to move forward is still unclear,
    they would reach out to the SME who wrote that document for specific guidance.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 事先从专业主题专家（SME）策划一组通用的问题和答案有助于在公司所有机器学习团队中*扩展*人类级别的监督。这需要是一次性的、跨职能的工作，由ML治理、产品管理或AI伦理团队领导。负责此项工作的团队将从一份样本问题列表开始，并与特定的SME合作，最终完成带有问题列表及其答案的HOG文档。然后，他们将最终文档提供给ML开发和产品团队参考。这些文档成为对信任问题的第一道防线。在机器学习模型开发管道的不同阶段，机器学习团队将参考这些文档获取指导。如果前进的最佳方式仍不清楚，他们将联系编写该文档的SME以获取具体的指导。
- en: Let’s now look at two sets of HOG questions, one for a domain expert and another
    for a use-case expert. Only a short list of questions and one sample answer are
    listed for each HOG. You’ll find the full documents in the [GitHub for this chapter](https://oreil.ly/qj4C2).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一下两组HOG问题，一组是领域专家的，另一组是用例专家的。每个HOG仅列出少量问题和一个示例答案。你可以在[本章的GitHub](https://oreil.ly/qj4C2)找到完整的文档。
- en: 'Here are the sample questions for a privacy SME for HOG creation:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个隐私SME编写HOG的示例问题：
- en: What types of data fall under the purview of a privacy review?
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些数据类型在隐私审查范围内？
- en: What laws/regulations are there for this data and its use?
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于这些数据及其使用，有哪些法律/法规？
- en: What type of privacy risks should ML projects be aware of when using this data?
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用这些数据时，机器学习项目应该注意哪些类型的隐私风险？
- en: Are there external examples of these risks? If so, please supply those examples.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否有这些风险的外部例子？如果有，请提供这些例子。
- en: What characteristics would enable an ML team to assess whether a project is
    low, medium, or high risk? Are there ways to mitigate related risks?
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么特征能让机器学习团队评估项目是低风险、中风险还是高风险？有没有减少相关风险的方法？
- en: Are there data elements that need specific approval to use in risk mitigation?
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否有需要特定批准才能在风险缓解中使用的数据元素？
- en: What metrics are typically used to measure privacy risks? Are there standard
    acceptable thresholds for these metrics?
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通常用于衡量隐私风险的指标是什么？这些指标是否有标准可接受的阈值？
- en: What vetting is done for third-party data, and what liabilities do we risk in
    using the data?
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于第三方数据进行了哪些审查，使用这些数据存在哪些责任风险？
- en: Are there privacy concerns on reuse of data/model elements?
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据/模型元素重复使用方面是否存在隐私问题？
- en: Whom should a data scientist contact for additional information?
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家需要联系谁获取额外信息？
- en: 'A privacy SME might answer the second question as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 隐私专家可能会如下回答第二个问题：
- en: Based on the geographic region the data elements from an individual are collected
    from, one or more laws may apply. GDPR applies to data—including what is publicly
    available—obtained from a natural person from the EU. In the US, data on residents
    of California, Virginia, and Colorado is subject to protection under laws in the
    respective jurisdictions. De-identified and publicly available data does not fall
    under these laws, but aggregate information does in Virginia and Colorado. You
    can consult [Bloomberg Law](https://oreil.ly/edMqw) for more information or reach
    out to me.
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 根据个人数据元素收集的地理区域，可能适用一种或多种法律。例如，GDPR适用于从欧盟自然人获取的数据，包括公开可获取的数据。在美国，加利福尼亚州、弗吉尼亚州和科罗拉多州居民的数据受各自司法管辖区的保护。去标识化和公开可获取的数据不适用这些法律，但在弗吉尼亚州和科罗拉多州，聚合信息适用。您可以咨询[Bloomberg
    Law](https://oreil.ly/edMqw)获取更多信息或与我联系。
- en: Note that some questions for the privacy SME are general, whereas others are
    specific to privacy risks. In the answer, the SME provides high-level guidance,
    with pointers to additional information.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，一些问题是为隐私专家提出的概括性问题，而其他问题则专门涉及隐私风险。在答案中，专家提供高层指导，并提供额外信息的指引。
- en: For the use-case HOG, let’s imagine that a company maintains an online platform
    for buying and selling consumer goods and needs to develop guidelines for ML projects
    related to advertising on this platform. The ML governance team can reach out
    to a senior engineer who has built ML systems for the company in this domain with
    these questions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用案例HOG，让我们想象一家公司维护一个在线平台，用于买卖消费品，并需要为该平台上的广告机器学习项目制定指南。机器学习治理团队可以联系在该领域为公司构建过机器学习系统的高级工程师，向其提出这些问题。
- en: 'Here are sample questions for a use-case SME in the area of advertising:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于广告领域使用案例SME的示例问题：
- en: Usage of what types of data can have trust concerns in the domain of targeted
    advertising?
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在定向广告领域，哪些类型的数据使用可能存在信任问题？
- en: What privacy, legal, or other requirements are there to get access to such data?
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要获取此类数据，有哪些隐私、法律或其他要求？
- en: Is it possible to use publicly available or aggregated data to avoid trust issues?
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否可以使用公开可用或汇总数据来避免信任问题？
- en: What laws/regulations are there in this domain?
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一领域有哪些法律/法规？
- en: What metrics, thresholds, and mitigation techniques can be used to detect and
    mitigate trust issues in advertising use cases?
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在广告使用案例中，可以使用哪些指标、阈值和缓解技术来检测和缓解信任问题？
- en: Who are the resource persons outside the ML team who may be consulted?
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在机器学习团队之外，可以咨询哪些资源人员？
- en: 'A use-case SME might answer the first question as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用案例SME可能会如下回答第一个问题：
- en: Usage of sensitive personal information (SPI) and personally identifiable information
    (PII) is important to think about from a privacy angle. Using PII is not allowed,
    while using SPI such as racial origin or geolocation needs approval. If there
    are features in the data that correlate with sensitive features such as race and
    gender, there may be fairness issues if you do not account for the sensitive features
    in the ML pipeline.
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从隐私角度考虑，使用敏感个人信息（SPI）和可识别个人信息（PII）非常重要。不允许使用PII，而使用SPI如种族或地理位置则需获得批准。如果数据中的特征与敏感特征如种族和性别相关联，如果在机器学习流程中不考虑这些敏感特征，可能会出现公平性问题。
- en: Stages of Assessment
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估阶段
- en: Given indirect and direct guidance from SMEs, as a tech lead or product manager,
    how do you actually go about assessing trust concerns for the ML project you’re
    leading, and then how do you proceed to build the model pipeline? When you sit
    with the technical team to determine and act on technical steps of the pipeline
    (i.e., data processing, model training, validation, and deployment), make it a
    point to also discuss trust-related concerns at these stages. Let’s walk through
    the details of how to approach these tasks in a structured manner. Note that parts
    of this overall process of involving humans in the ML loop were introduced in
    [Chapter 7](ch07.html#chapter7).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在来自SME的直接和间接指导下，作为技术负责人或产品经理，您如何实际评估您领导的ML项目的信任问题，然后如何继续构建模型管道？当您与技术团队一起确定和执行管道的技术步骤（即数据处理、模型训练、验证和部署）时，务必也讨论这些阶段的信任相关问题。让我们详细了解如何有条理地处理这些任务的细节。请注意，涉及人类参与ML循环的整体过程的部分内容在[第7章](ch07.html#chapter7)中介绍过。
- en: Scoping
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 范围界定
- en: When you scope the project to determine data sources, models, and the delivery
    mechanism, make sure to also determine what aspects of trust are important. Use
    a set of questions, modeled after the [questions](ch07.html#trust-questions) given
    in [Chapter 7](ch07.html#chapter7), to evaluate the importance of each trust aspect.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在您界定项目范围以确定数据来源、模型和交付机制时，请确保确定哪些信任方面是重要的。使用一组问题，模仿[第7章](ch07.html#trust-questions)中提供的问题，评估每个信任方面的重要性。
- en: After this, you need to decide on quantifiers for each trust aspect. For example,
    if you would like to avoid racial discrimination when showing certain types of
    ads (e.g., educational opportunities, job postings, or home buying), you would
    need demographic data. In your business context, what’s the most reliable source
    of demographic data? Are there issues related to data quality, access restrictions,
    or ethics of data use? Should you use individual-level versus aggregate-level
    data? What trade-offs are there of using one data source or another? Discuss these
    questions with your stakeholders, then make informed decisions to move forward.
    Most importantly, keep a record of these decisions for future reference and transparency.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，您需要为每个信任方面确定量化指标。例如，如果您希望在展示某些类型广告时避免种族歧视（例如教育机会、职位发布或购房信息），您将需要人口统计数据。在您的业务背景下，人口统计数据的最可靠来源是什么？是否存在与数据质量、访问限制或数据使用伦理相关的问题？您应该使用个体级别还是聚合级别的数据？使用一种数据源而不是另一种的权衡是什么？与利益相关者讨论这些问题，然后做出明智的决策继续前进。最重要的是，记录这些决策以供将来参考和透明度。
- en: Let’s break down these human steps based on what stages of the ML pipeline you
    need to perform them in.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们根据您需要在ML管道的哪些阶段执行这些人类步骤进行详细解析。
- en: Data collection
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集
- en: 'Data science/ML is an iterative process. You collect some datasets, do some
    exploratory analysis to figure out if you need more data, collect more data, get
    back to the exploratory step, and only move forward to model building when the
    data you have is *good enough* to proceed further. While doing so, don’t forget
    to consider trust elements. This can mean, based on the use case, performing one
    or more of the following steps:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学/机器学习是一个迭代过程。您收集一些数据集，进行一些探索性分析以确定是否需要更多数据，收集更多数据，回到探索步骤，并且仅在您拥有的数据足够好以进一步进行时才进行模型构建。在这个过程中，不要忘记考虑信任元素。这可以意味着根据用例执行以下一个或多个步骤：
- en: Making sure PII is not present in the data
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保数据中不存在个人身份信息（PII）
- en: Checking for and rectifying missing feature(s), values missing at random, and
    any correlation of missing values with sensitive features
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查并纠正缺失特征、随机缺失的值以及任何缺失值与敏感特征的相关性
- en: Doing similar due diligence for outliers
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对异常值进行类似的尽职调查
- en: Ensuring that important sample subgroups have enough data points to work with
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保重要样本子群体具有足够的数据点供使用
- en: Determining whether one or more non-sensitive features can serve as a proxy
    for a sensitive feature; if so, deciding between sanitizing those features, dropping
    them, or taking a note to account for them during model building
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定一个或多个非敏感特征是否可以作为敏感特征的代理；如果可以，决定是清理这些特征、丢弃它们，还是在模型构建过程中考虑它们。
- en: Based on the deficiencies that come out of the preceding steps, you may need
    to collect more data. Make sure to go through the same steps to make sure the
    gaps you had found are plugged.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 基于前述步骤的不足，您可能需要收集更多数据。确保经过相同的步骤，确保您发现的差距已经弥补。
- en: Model training
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练
- en: Now that you have decided on metrics and thresholds for the important trust
    aspects, in this stage you go through the model-training steps, evaluating each
    step using the guidelines from [“Evaluation and Feedback”](ch07.html#evaluation-and-feedback).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经为重要的信任方面确定了度量和阈值，在这个阶段，您将通过使用来自[“评估与反馈”](ch07.html#evaluation-and-feedback)的指南，审查模型训练步骤。
- en: Model validation
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型验证
- en: The post-model human-level steps will be different depending on whether you
    are dealing with a new model or you’re in the inference phase of an already deployed
    model. If it’s the former, this is the time to perform and evaluate any post-processing
    debiasing or addition of privacy noise, if you hadn’t done so during model training.
    If explainability is a priority, use post hoc explanations and make sure they
    are to the liking of the stakeholder. If you’re just doing inference on a deployed
    model, the investigations are a bit detailed. You need to check for data drift,^([6](ch08.html#idm45621830701200))
    concept drift,^([7](ch08.html#idm45621830699200)) and changes in the composition
    and quality of upstream datasets. You also need to check your trust metrics to
    make sure they are within thresholds and/or not displaying anomalous behaviors
    compared to historical inference data. Again, use [“Trustworthiness and MLOps”](ch07.html#mlops)
    to tackle these tasks. If you find any problems, you may need to dig deeper into
    the test data to use the latest batch to diagnose and then mitigate them by retraining
    the model.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 后模型人类水平的步骤会因为你是处理新模型还是处于已部署模型推理阶段而有所不同。如果是前者，现在是执行和评估任何后处理去偏置或在模型训练期间未执行的添加隐私噪声的时候了。如果可解释性是优先考虑的话，使用事后解释并确保它们符合利益相关者的喜好。如果只是在已部署模型上做推理，调查会比较详细。你需要检查数据漂移^([6](ch08.html#idm45621830701200))，概念漂移^([7](ch08.html#idm45621830699200))以及上游数据集的组成和质量变化。你还需要检查信任度指标，确保它们在阈值内并/或与历史推理数据相比未显示异常行为。同样，使用[“信赖性和MLOps”](ch07.html#mlops)来处理这些任务。如果发现任何问题，可能需要深入研究测试数据以使用最新的批次诊断，然后通过重新训练模型来减轻问题。
- en: The Need for a Cross-Project Approach
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跨项目方法的需求
- en: Moving beyond project-level tooling and documentation, let’s explore a holistic
    approach to looking at industry projects on trustworthy ML. Industry ML projects
    tend to be on topics that are broadly or closely related. They also tend to reuse
    data, code, models, or pieces of ML pipelines. Given that, it only makes sense
    to make common repositories of information ML projects across a company can use.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 超越项目级别的工具和文档，让我们探索一个全面的方法来看待与可信ML相关的行业项目。行业ML项目往往涉及广泛或紧密相关的主题。它们还倾向于重复使用数据、代码、模型或ML管道的部分。考虑到这一点，将信息ML项目的常见存储库整合到公司的各个项目中是合理的。
- en: The security community figured this out a few decades ago and started sharing
    and codifying information on security flaws in software systems. For example,
    the intrusion detection system [Snort](https://snort.org) is built on open source
    sharing and usage of signatures and rules to detect security threats on internet
    networks in real time. [MITRE ATT&CK](https://oreil.ly/6PZF8), [Cyber Kill Chain](https://oreil.ly/eJdzi),
    and the [NIST Cybersecurity Framework](https://oreil.ly/2YyKd) are three widely
    accepted taxonomies for classifying existing and new security threats and attacks.
    The [National Vulnerability Database (NVD)](https://oreil.ly/Sk9A3) contains granular
    information on specific instances of exploitable weaknesses (*vulnerabilities*)
    in a software.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 安全社区在几十年前就解决了这个问题，并开始分享和编码软件系统中的安全漏洞信息。例如，入侵检测系统[Snort](https://snort.org)基于开源共享和使用签名和规则来实时检测互联网网络中的安全威胁。[MITRE
    ATT&CK](https://oreil.ly/6PZF8)，[Cyber Kill Chain](https://oreil.ly/eJdzi)和[NIST网络安全框架](https://oreil.ly/2YyKd)是三种广泛接受的分类现有和新的安全威胁和攻击的方法。[国家漏洞数据库（NVD）](https://oreil.ly/Sk9A3)包含特定软件中可利用弱点（*漏洞*）的详细信息。
- en: There aren’t exact equivalents of these systems in the broader trustworthy ML
    space yet. But let’s look at a few frameworks that are steps in the right direction.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在更广泛的可信ML领域中，尚不存在这些系统的确切等价物。但让我们看一些朝正确方向迈出的框架。
- en: MITRE ATLAS
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MITRE ATLAS
- en: The [Adversarial Threat Landscape for Artificial-Intelligence Systems (ATLAS)](https://oreil.ly/ErQNx)
    maintained by MITRE is an open source knowledge base for adversarial ML attacks.
    ATLAS is modeled after the famous MITRE ATT&CK framework. They provide a taxonomy
    for adversarial ML attacks that ML practitioners can use for their own purposes.
    They can also contribute a novel attack to this knowledge base by adding information
    and classifying into an appropriate class in the ATLAS taxonomy.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 由麻省理工学院（MITRE）维护的[人工智能系统的对抗威胁景观（ATLAS）](https://oreil.ly/ErQNx)是一个开源的知识库，用于对抗性
    ML 攻击。ATLAS 参照了著名的 MITRE ATT&CK 框架。他们为 ML 从业者提供了一套分类系统，可用于他们自己的目的。他们还可以通过添加信息并将其分类到
    ATLAS 分类中，为这个知识库贡献一个新的攻击。
- en: '[Table 8-2](#table-atlas) shows the 12 broad classes of adversarial attack
    tactics in ATLAS.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 8-2](#table-atlas) 显示了 ATLAS 中的 12 大类对抗性攻击战术。'
- en: Table 8-2\. Top-level tactics, signifying attack vectors on ML systems, contained
    in MITRE ATLAS
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-2\. MITRE ATLAS 中包含的针对 ML 系统的顶级战术，表示攻击向量
- en: '|  | Tactic | ATLAS ID | Adversary objective |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '|  | 战术 | ATLAS ID | 对手的目标 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1. | Reconnaissance | AML.TA0002 | Gathering information on the ML system
    to use later |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 1. | 侦察 | AML.TA0002 | 收集关于 ML 系统的信息以供以后使用 |'
- en: '| 2. | Resource development | AML.TA0003 | Establishing resources to support
    their own operations |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 2. | 资源开发 | AML.TA0003 | 建立支持其自身操作的资源 |'
- en: '| 3. | Initial access | AML.TA0004 | Gaining access to the system containing
    the ML model artifacts |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 3. | 初始访问 | AML.TA0004 | 获取包含 ML 模型工件的系统访问权限 |'
- en: '| 4. | ML model access | AML.TA0000 | Gaining access to the ML model itself
    |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 4. | ML 模型访问 | AML.TA0000 | 获取 ML 模型本身的访问权限 |'
- en: '| 5. | Execution | AML.TA0005 | Running malicious code |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 5. | 执行 | AML.TA0005 | 运行恶意代码 |'
- en: '| 6. | Persistence | AML.TA0006 | Maintaining its own malicious access |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 6. | Persistence | AML.TA0006 | 维持其自身的恶意访问 |'
- en: '| 7. | Defense evasion | AML.TA0007 | Avoiding detection by security software
    |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 7. | 防御规避 | AML.TA0007 | 避免被安全软件检测到 |'
- en: '| 8. | Discovery | AML.TA0008 | Gaining knowledge about the system running/serving
    the ML model |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 8. | 发现 | AML.TA0008 | 获取关于运行/服务 ML 模型的系统的知识 |'
- en: '| 9. | Collection | AML.TA0009 | Collecting information relevant to its own
    goal |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 9. | 收集 | AML.TA0009 | 收集与其目标相关的信息 |'
- en: '| 10. | ML attack staging | AML.TA0001 | Tailoring the attack using their knowledge
    of the system being attacked |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 10. | ML 攻击策划 | AML.TA0001 | 利用对被攻击系统的了解来定制攻击 |'
- en: '| 11. | Exfiltration | AML.TA0010 | Stealing ML model artifacts |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 11. | 数据外泄 | AML.TA0010 | 窃取 ML 模型工件 |'
- en: '| 12. | Impact | AML.TA0011 | Manipulate, corrupt, or disrupt the functionality
    of the ML system, model, or underlying data |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 12. | Impact | AML.TA0011 | 操纵、破坏或干扰 ML 系统、模型或底层数据的功能 |'
- en: Each category has a number of techniques listed under them. The intention is,
    if you want to evaluate the vulnerability of your ML model for adversarial attacks,
    you’ll evaluate its propensity to be affected by each category of attack. In doing
    so, you’ll be informed by the case studies of historical attacks present under
    each subcategory.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 每个类别下列出了多种技术。意图是，如果您想评估您的 ML 模型对对抗性攻击的脆弱性，您将评估其对每种攻击类别的受影响程度。在这样做时，您将受到每个子类别下历史攻击案例的启发。
- en: Let’s go back to the HopSkipJump attack introduced in [Chapter 4](ch04.html#chapter4)
    and look at what a *case study* submission of that example in the ATLAS format
    could look like.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到介绍在 [第 4 章](ch04.html#chapter4) 中的 HopSkipJump 攻击，并看看在 ATLAS 格式中的一个*案例研究*提交可能会是什么样子。
- en: '[PRE0]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that the ATLAS taxonomy allows you to box the example under a broad tactic
    ([Defense Evasion, AML.TA0007](https://oreil.ly/rJzOC)) and a specific technique
    ([Evade ML Model, AML.T0015](https://oreil.ly/GBBJn)).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，ATLAS 分类允许您将示例放入一个广泛的战术（[防御规避，AML.TA0007](https://oreil.ly/rJzOC)）和一个具体的技术（[规避
    ML 模型，AML.T0015](https://oreil.ly/GBBJn)）下。
- en: Benchmarks
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准
- en: Moving on from attacks to defenses, [RobustBench](https://oreil.ly/P1E9z) provides
    standardized quality benchmarks for existing adversarial robustness methods. Similar
    to Kaggle competitions, RobustBench takes a leaderboard approach. Their leaderboard
    is divided into combinations of well-known computer vision (CV) datasets (CIFAR-10,
    CIFAR-100, ImageNet) and robustness techniques ( <math alttext="script l 2"><msub><mi>ℓ</mi>
    <mn>2</mn></msub></math> norm, <math alttext="script l Subscript normal infinity"><msub><mi>ℓ</mi>
    <mi>∞</mi></msub></math> norm). For each combination, the performance of relevant
    methods is presented on the leaderboard, using metrics such as standard and robust
    classification accuracy. RobustBench also provides access to these models through
    its [Model Zoo](https://oreil.ly/pvOXv). If you’re working in CV and have valid
    reason to believe the dataset you’re dealing with may need robust techniques,
    RobustBench is a great starting point.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 从攻击转向防御，[RobustBench](https://oreil.ly/P1E9z)为现有的对抗鲁棒性方法提供了标准化的质量基准。类似于Kaggle竞赛，RobustBench采用排行榜方式。他们的排行榜分为众所周知的计算机视觉（CV）数据集（CIFAR-10、CIFAR-100、ImageNet）和鲁棒性技术（
    <math alttext="script l 2"><msub><mi>ℓ</mi> <mn>2</mn></msub></math> 范数、 <math
    alttext="script l Subscript normal infinity"><msub><mi>ℓ</mi> <mi>∞</mi></msub></math>
    范数）的组合。对于每个组合，相关方法的性能以标准和鲁棒分类精度等指标在排行榜上展示。RobustBench还通过其[Model Zoo](https://oreil.ly/pvOXv)提供对这些模型的访问。如果你在CV领域工作，并且有充分的理由认为你处理的数据集可能需要鲁棒技术，那么RobustBench是一个很好的起点。
- en: '[OpenXAI](https://oreil.ly/XPpyk) is a recent tool kit that does about the
    same thing, but in *explainable AI* (XAI). The only difference is that RobustBench
    focuses more on benchmarks, whereas OpenXAI focuses on the tool kit. The motivation
    of OpenXAI stems directly from the automation bias discussion in [Chapter 7](ch07.html#chapter7):
    not all explanation methods are reliable. They can be fooled by adversaries, and
    humans often trust them too much even when they are wrong. For this reason, if
    you either (a) have a dataset and are looking for an XAI method to apply to it,
    or (b) came up with a new XAI method and want to check how it performs, OpenXAI
    is a good place to go.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[OpenXAI](https://oreil.ly/XPpyk)是一个最近推出的工具包，它主要处理*可解释人工智能*（XAI）。唯一的区别在于，RobustBench更专注于基准测试，而OpenXAI专注于工具包。OpenXAI的动机直接源于自动化偏见讨论中的[第7章](ch07.html#chapter7)：并非所有的解释方法都是可靠的。它们可能会被对手欺骗，即使错误时，人类通常也会过于信任它们。因此，如果你（a）有一个数据集，并正在寻找一个适用于它的XAI方法；或者（b）提出了一种新的XAI方法，并希望检查其表现，那么OpenXAI是一个很好的选择。'
- en: AI Incident Database
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI事件数据库
- en: To get a sense of what could go wrong in the future, you should know what went
    wrong in the past. In the context of ML projects, this means looking at failure
    cases of ML systems that are relevant to the one that you’re developing. To this
    end, the [AI Incident Database (AIID)](https://oreil.ly/ohGPZ) provides a crowdsourced
    repository of harms by deployed AI/ML systems. To utilize AIID internally, you
    can take two approaches. You can either take the information from this repository
    and use it to avoid making the same mistakes in your own work. Or you can expand
    upon it to include more granular information about internal ML projects that do
    not necessarily need to be failures.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对未来可能出现的问题有所了解，你应该了解过去发生了什么问题。在ML项目的背景下，这意味着查看与你正在开发的项目相关的ML系统失败案例。为此，[AI事件数据库（AIID）](https://oreil.ly/ohGPZ)提供了一个部署AI/ML系统引起的伤害的众包存储库。为了在内部利用AIID，你可以采取两种方法。你可以从这个存储库中获取信息，并用来避免在自己的工作中犯同样的错误。或者你可以扩展这些信息，包括关于不一定需要是失败的内部ML项目的更细粒度信息。
- en: As an example, let’s look at the advertising example from earlier. While scoping
    an ML project in this domain, it would help the technical team to know about past
    related failures. AIID can help with this. A search for the keyword *advertising*
    in AIID gives 53 results of crowdsourced AI failures ([Figure 8-2](#fig-ad-1)).
    These results include cases of racial discrimination in Google online ad placement
    (first link) and housing ad recommendations on Facebook (last link).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们来看看先前的广告示例。在这个领域内界定一个机器学习项目时，了解过去相关失败案例对技术团队非常有帮助。AIID可以提供帮助。在AIID中搜索关键词*广告*，会得到53个众包AI失败案例的结果（[图 8-2](#fig-ad-1)）。这些结果包括谷歌在线广告放置中的种族歧视案例（第一个链接）和Facebook的房屋广告推荐（最后一个链接）。
- en: '![ptml 0802](assets/ptml_0802.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0802](assets/ptml_0802.png)'
- en: Figure 8-2\. Search results from AIID for the keyword “advertising”
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-2\. AIID关键词“广告”的搜索结果
- en: The records of past relevant failures can guide the ML team and product manager
    to better human-level decision making when scoping the project, such as when choosing
    sensitive features and reliable data sources.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 过去相关失败的记录可以指导ML团队和产品经理在规划项目范围时做出更好的人类级决策，比如在选择敏感特征和可靠数据源时。
- en: Bug Bounties
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Bug Bounties
- en: Another standard practice in cybersecurity that is starting to make its way
    into the trustworthy ML community is that of bug bounties. Bug bounties incentivize
    developers and engineers to find evidence of bugs or vulnerabilities in software
    systems.^([8](ch08.html#idm45621830386960)) Twitter’s [algorithmic bias bounty
    challenge](https://oreil.ly/ELka8) was the first such effort in the area of trustworthy
    ML. The organizers of this bounty recently launched a non-profit [Bias Buccaneers](https://oreil.ly/A87rj)
    dedicated solely to third-party bias bounties.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个开始进入值得信赖的ML社区的标准做法是漏洞赏金。漏洞赏金鼓励开发人员和工程师在软件系统中找到漏洞或弱点的证据。Twitter的[算法偏见赏金挑战](https://oreil.ly/ELka8)是该领域的首个尝试。此赏金的组织者最近推出了一个非营利性组织[Bias
    Buccaneers](https://oreil.ly/A87rj)，专门致力于第三方偏见赏金。
- en: Two more relevant initiatives are the [Inverse Scaling Prize](https://oreil.ly/rtLwj)
    by Anthropic and the [AI Audit Challenge](https://oreil.ly/6nXcB) by Stanford
    HAI. If you can organize a similar competition or hackathon in your company that
    is focused on ML bugs, go for it! Even without the monetary motivation, bug bounties
    are a great place for gaining hands-on experience in this area that goes beyond
    the concepts and examples in this book. Publicly available models or datasets
    are good starting points for such exercises. For example, the model cards of some
    widely used pre-trained models hosted in Hugging Face have information related
    to potential biases in their predictions. These can be expanded into complete
    evaluations of a certain type of bias.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 另外两个相关的倡议是Anthropic的[反向缩放奖](https://oreil.ly/rtLwj)和斯坦福HAI的[AI审计挑战](https://oreil.ly/6nXcB)。如果您可以在公司组织类似的ML漏洞竞赛或黑客马拉松，那就去做吧！即使没有金钱动机，漏洞赏金也是在这一领域获得实践经验的好地方，超越了这本书中的概念和示例。一些托管在Hugging
    Face中的广泛使用的预训练模型的模型卡片包含有关其预测潜在偏见的信息。这些可以扩展为对某种类型偏见的完整评估。
- en: Tip
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Consider the example given under the *Limitations and bias* section of the `bert-base-uncased`
    [model card](https://oreil.ly/5nGcu). Based on the outputs, can you think of a
    bias metric to quantify the difference of sentiments around professions stereotypically
    associated with women and those stereotypically associated with men? How will
    you test if this this metric is significant enough to conclude the model is biased
    on the task of filling in masked words in the context given in the example?
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在`bert-base-uncased` [模型卡片](https://oreil.ly/5nGcu)的*限制和偏见*部分给出的示例。基于输出，你能想出一个偏见度量标准，来量化围绕与女性刻板印象相关联的职业和与男性刻板印象相关联的职业之间情感差异吗？你将如何测试这个度量标准是否足够显著，从而得出结论：该模型在给定示例中填充掩码词的任务上存在偏见？
- en: 'Deep Dive: Connecting the Dots'
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度挖掘：串联各种线索
- en: Let’s finish this section with an example of how you and your team can bring
    together the preceding tools and techniques to make informed decisions about workflows
    in your ML projects. Going beyond single projects, you’re going to look at why
    it’s important to look from a holistic point of view while thinking about ML governance.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来结束本节，展示您和您的团队如何将前述工具和技术整合起来，以在ML项目中做出明智的工作流决策。超越单个项目，您将看到为什么从整体角度考虑ML治理是如此重要。
- en: Consider the problem of constructing a user timeline in a social network platform.
    This is a typical ranking problem, where you use several data sources to construct
    a ranked list of (mostly) recent posts to present to the user. You typically want
    to make the higher-ranked posts relevant to the user so that they spend more time
    on the platform.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑在社交网络平台上构建用户时间线的问题。这是一个典型的排名问题，您使用多个数据源构建一个（主要是）最近的帖子排名列表，以展示给用户。通常希望使排名较高的帖子与用户相关，以便他们在平台上花费更多时间。
- en: Let’s follow the structure of DAG cards to build a modular ML pipeline that
    consists of nodes connected by a DAG. Each node will store salient information
    about a specific stage of the ML model. As your team figures out additional steps
    in the model-building process, add those in as separate nodes in the model pipeline
    DAG. Here’s a generic skeleton of the high-level DAG that you’re going to populate
    as you go forward. This is a starting point not only for the current recommendation
    system example but also for general ML pipelines.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照DAG卡片的结构来构建一个模块化的ML流水线，由DAG连接的节点组成。每个节点将存储ML模型特定阶段的重要信息。当您的团队在模型构建过程中找到额外的步骤时，请将它们作为单独的节点添加到模型流水线DAG中。这是您将随着进展填充的高级DAG的通用框架。这不仅是当前推荐系统示例的起点，也适用于通用的ML流水线。
- en: '[PRE1]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Data
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据
- en: 'Let’s put some detail into the `data` node. Under this, you’ll have a bunch
    of subnodes, each consisting of one source of data. So what data sources do you
    need to consider for a recommendation system that can output a user-specific ranked
    list? Let’s set aside the complex recommendation engines that modern social platforms
    like Twitter, LinkedIn, or Facebook have and consider only the following types
    of data:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为`data`节点添加一些细节。在此下面，您将拥有一堆子节点，每个节点都包含一个数据源。那么，对于能够输出用户特定排名列表的推荐系统，您需要考虑哪些数据源？让我们搁置像Twitter、LinkedIn或Facebook这样现代社交平台拥有的复杂推荐引擎，并仅考虑以下类型的数据：
- en: Activity patterns of the user or similar group of users in the recent past (e.g.,
    posts viewed, liked, or shared)
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户或最近一段时间内类似用户组的活动模式（例如查看、点赞或分享的帖子）
- en: User-specific features
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特定于用户的特征
- en: Aggregations of a user’s or user group’s historical usage data
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户或用户组的历史使用数据的聚合
- en: Third-party data
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三方数据
- en: Post-specific features
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帖子特定特征
- en: Metadata such as hashtags, time of the day, day of week
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元数据，如哈希标签、时间和星期几
- en: Historical activity data on the post or similar posts
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帖子或类似帖子的历史活动数据
- en: Inferred features at several levels
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个层次的推断特征
- en: User segment obtained from a user segmentation model
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从用户分割模型获取的用户段
- en: Semantic representation of post content using embeddings
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用嵌入表示的帖子内容的语义表示
- en: Post topic tags inferred from a topic prediction model
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从主题预测模型推断的帖子主题标签
- en: Let’s look at the sources of these datasets ([Figure 8-3](#fig-rec-dag-1)).
    When it comes to ensuring trust, things can get very complicated, very quickly.
    The inferred features are outcomes of ML models themselves. So any trust issue
    in these upstream models can not only affect their outputs but can also propagate
    to the recommendation engine itself.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这些数据集的来源（见图8-3）。在确保信任方面，事情可能会变得非常复杂，非常迅速。推断出的特征是ML模型本身的结果。因此，这些上游模型中的任何信任问题不仅会影响它们的输出，还可能传播到推荐引擎本身。
- en: '![ptml 0803](assets/ptml_0803.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0803](assets/ptml_0803.png)'
- en: Figure 8-3\. Data nodes and their sources in recommendation system example
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-3. 推荐系统示例中数据节点及其来源
- en: 'Following [“Datasheets”](#datasheets), you can codify details about the data
    node in the form of datasheets. This requires a bit of nuance in our example.
    For the first two datasets, you can simply link to their datasheets, optionally
    with some high-level details. For the other three, you need to go into a bit more
    detail since they are model-generated datasets and won’t have their own datasheets.
    Building out full datasheets may not be necessary, but at the very least the following
    elements should be there:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[“数据表格”](#datasheets)的指导，您可以将数据节点的详细信息编码为数据表格的形式。在我们的示例中，这需要一些细微的差别。对于前两个数据集，您可以简单地链接到它们的数据表格，也可以附加一些高级别的详细信息。对于其他三个数据集，您需要更详细地描述，因为它们是模型生成的数据集，不会有自己的数据表格。虽然不一定需要构建完整的数据表格，但至少应包括以下元素：
- en: A short description of the model that generates these features
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成这些特征的模型简要描述
- en: A short description of what each feature represents
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个特征代表的简要描述
- en: Caveats and insights into the reliability of these features
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对这些特征可靠性的注意事项和见解
- en: Unique ID or link to the DAG card of the model that generates these features
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成这些特征的模型的唯一ID或DAG卡片链接
- en: Once you have all the information, a skeleton of the structure of the data node
    would look something like this.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您获取了所有信息，数据节点结构的骨架会看起来像这样。
- en: '[PRE2]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Pre-Processing
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理
- en: 'In this stage, your task is to *featurize* parts of the different datasets,
    in order to prepare the actual dataset to be used for model training and evaluation.
    Because you are still dealing with datasets, the Datasheets for Datasets framework
    is useful again to decide what information to persist for later use. Remember
    from [“Datasheets”](#datasheets) that a datasheet has seven components: *Motivation*,
    *Composition*, *Collection*, *Pre-processing*, *Uses*, *Distribution*, and *Maintenance*.
    You don’t need the first two in this case, since the project is already scoped
    and the data is already there. Among the other five, the actual details of the
    data wrangling you’ll do will go into *Pre-processing*. These include standard
    steps in an ML workflow (e.g., feature transformation, binning, filtering and
    grouping, missing data imputation) and trust-specific steps (more on that soon).'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，您的任务是对不同数据集的部分进行*特征化*，以准备实际用于模型训练和评估的数据集。因为您仍在处理数据集，因此数据集数据表框架再次非常有用，以决定要将哪些信息保留以备后用。请记住，从[“数据表”](#datasheets)中得知，数据表有七个组成部分：*动机*，*组成*，*收集*，*预处理*，*用途*，*分发*和*维护*。在这种情况下，您不需要前两个，因为项目已经规划好，并且数据已经就绪。在其余的五个中，您将进行的数据整理的实际细节将会放入*预处理*中。这些包括ML工作流中的标准步骤（例如特征转换，分箱，过滤和分组，缺失数据插补）和特定于信任的步骤（更多内容即将发布）。
- en: For the rest of the steps, some information can actually be reused from the
    same steps of the two model-generated datasets. You can include any additional
    comments as a separate field. For the three inferred datasets, you can refer to
    the datasheets of those models, with more comments to explain downstream changes.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 对于剩下的步骤，实际上可以重复使用两个模型生成的数据集相同步骤中的一些信息。您可以将任何额外的评论作为单独的字段包含进来。对于三个推断数据集，您可以参考这些模型的数据表，以及有关下游变更的更多评论来解释。
- en: Based on the preceding, here’s a structure of what the `preprocessing` node
    could look like. The `*` wildcard indicates all subfields under a certain field
    for `source_information` and the same field combinations as `source_information`
    for the last three components.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述内容，这里是`preprocessing`节点的结构示例。 `*` 通配符表示`source_information`某一字段下的所有子字段，最后三个组件的字段组合与`source_information`相同。
- en: '[PRE3]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The precursor models may have used common data sources. For this reason, you
    may need to do a post-processing step to select unique fields whenever you combine
    multiple datasheets.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 前置模型可能使用了共同的数据源。因此，当你合并多个数据表时，可能需要进行后处理步骤以选择唯一字段。
- en: Model Training
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: This step will look similar to the actions you took using datasheets for pre-processing,
    but using model cards. Let’s start with a blank model card structure, then add
    specific information to train our recommendation system model in some components
    of that model card. Finally, slot some inherited links into the other components
    to fill out your model card so it connects with other models that feed in the
    inferred features.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤将类似于使用数据表对预处理采取的操作，但是使用模型卡。让我们从空白的模型卡结构开始，然后在该模型卡的某些组件中添加特定的信息来训练我们的推荐系统模型。最后，将一些继承的链接槽入其他组件，以填充模型卡，使其与提供推断特征的其他模型连接起来。
- en: The four model card fields *Model details*, *Intended use*, *Evaluation data*,
    *Training data* can contain information specific to the current model. Other fields
    can contain information and tracebacks to the same information on the models generating
    inferred features. Of course, information on the model details, intended use,
    evaluation data, and training data of the inferred feature models matter too.
    But you’d expect these to be looked at during the project-scoping phase of those
    models.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 四个模型卡字段 *模型详情*，*预期用途*，*评估数据*，*训练数据* 可包含特定于当前模型的信息。其他字段可以包含与生成推断特征模型相同信息和追溯信息。当然，推断特征模型的模型详情、预期用途、评估数据和训练数据信息也很重要。但在项目规划阶段，你应该期望在这些模型上查看这些信息。
- en: With the same conventions as before, here’s a structure to record the metadata
    for the `model_training` node.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前相同的约定，这里是用于记录`model_training`节点元数据的结构。
- en: '[PRE4]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Model Inference
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型推断
- en: This part comes in handy post-deployment for observability and troubleshooting
    the deployed model. The idea is to record details about the datasets the model
    is generating predictions for and about the predictions themselves, like metrics
    and alerts. Following suit from the other sections, you’d also want to include
    hooks to the inference phases of the precursor models of the inferred features
    so that you can proactively monitor the downstream effects of a deployed model.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 此部分在模型部署后对可观察性和故障排除非常有用。其想法是记录关于模型生成预测数据集以及预测本身的细节，例如指标和警报。为了跟进先前部分的做法，您还应包括对推理阶段的前驱模型的挂钩，以便可以主动监控已部署模型的下游影响。
- en: 'For an example schema of this node, look at the following sketched-out structure.
    There are three categories of metadata to be stored: `data`, `metrics`, and `alerts`.
    Under each category and its subcategories, dictionary entries correspond to changing
    elements such as evaluation dataset, metric values, and alert details. The timestamps
    for each such entry are stored to query back in the future.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 关于此节点的示例架构，请参阅以下草图结构。有三类需要存储的元数据：`数据`、`指标`和`警报`。在每个类别及其子类别下，字典条目对应于如评估数据集、指标值和警报详细信息等变化元素。每个此类条目的时间戳都被存储以便未来查询。
- en: '[PRE5]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Trust Components
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信任组件
- en: Given that your code is annotated in a standardized format, it’s not too difficult
    to build wrappers around parts of the model pipelines to extract the relevant
    text and inherited pointers to build the preceding DAG card structure. The original
    DAG cards did this at the node level using wrappers around the Metaflow and W&B
    functions. This takes care of many of the trust aspects as well. For example,
    you can record the chosen trust metrics and their computed values, then get alerted
    when a trust metric value goes beyond acceptable levels—at the data, model, or
    inference stages. Using the inherited pointers, you can also pass information,
    metrics, and alerts upstream to precursor models and downstream to other models
    that use your model’s output.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于您的代码以标准化格式注释，围绕模型管道的部分构建包装不是太困难，以提取相关文本和继承指针以构建前述的DAG卡结构。原始的DAG卡是在节点级别使用Metaflow和W&B功能的包装器来处理这些信任方面的许多问题。例如，您可以记录所选的信任指标及其计算值，然后在数据、模型或推理阶段信任指标值超出可接受水平时获得警报。使用继承指针，还可以将信息、指标和警报传递给使用您模型输出的前驱模型的上游和下游其他模型。
- en: But what about information on the human-level considerations? How do you store
    and reuse this information? In [“Human-in-the-Loop Steps”](#human), you learned
    about oversight documents and assessment steps. For future reference, you need
    to store some information on this human-level due diligence.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 但是关于人为层面考虑的信息呢？如何存储和重复使用这些信息？在[“人在环路中的步骤”](#human)中，您了解了监督文件和评估步骤。为了将来参考，您需要存储一些关于这种人为层面尽职调查的信息。
- en: To do so, you can take a two-pronged approach. Firstly, add an extra `scoping`
    node to the high-level DAG card in order to record the mostly human-level considerations
    that kick off a project. These are basically condensed meeting notes from the
    cross-functional stakeholder meetings that ML teams have at the start of a project.
    Secondly, add an extra `risk_assessment` step at the end of each node. This works
    as a sign-off to move on to the next stage of the ML pipeline.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，您可以采取双管齐下的方法。首先，在高级DAG卡中添加额外的`范围`节点，以记录启动项目时主要是人为层面的考虑。这些基本上是来自跨功能利益相关者会议的简化会议记录，这些会议通常在项目开始时由ML团队进行。其次，在每个节点的最后添加额外的`风险评估`步骤。这作为签署以进入ML管道下一阶段的批准。
- en: Following the guidelines from [“Stages of Assessment”](#stages-of), here’s a
    sample structure in the scoping phase.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 按照[“评估阶段”](#stages-of)的指导原则，以下是范围阶段的一个示例结构。
- en: '[PRE6]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here are the functions of various fields:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 各个字段的功能如下：
- en: '`motivation`'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`motivation`'
- en: Records reasons to start on a new project.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 记录开始新项目的原因。
- en: '`data_identification`'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`data_identification`'
- en: Identifies relevant data sources, and summarizes the rationale of why certain
    data sources were selected or not selected.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 标识相关数据源，并总结为何选择或未选择某些数据源的理由。
- en: '`trust_elicitation`'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '`trust_elicitation`'
- en: Identifies the important trust aspects and their priorities for your project.
    Use the rubric from [“Important Aspects of Trust”](ch07.html#trust-questions)
    for this purpose.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 确定项目的重要信任方面及其优先级。为此目的使用[“信任的重要方面”](ch07.html#trust-questions)中的评分表。
- en: '`metric_elicitation`'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`metric_elicitation`'
- en: Describes what metrics are required to evaluate the model. The metrics include
    both conventional performance metrics and trust metrics.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 描述了评估模型所需的指标。这些指标包括传统的性能指标和信任指标。
- en: '`risk_assessment`'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`risk_assessment`'
- en: Summarizes the trust-related risks and prioritizes them in terms of importance.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 总结了与信任相关的风险，并根据重要性进行了优先级排列。
- en: For the second part (i.e., adding risk assessment steps to the other stages),
    `scoping.risk_assessment` gives your team a starting point to revisit in light
    of new work in subsequent stages. For the `risk_assessment` steps in each of these
    stages, the team can (hopefully) start ticking things off in light of new information
    from that stage, as well as adding new line items to check in the next stage.
    At the end of a stage, your team should also evaluate if you can realistically
    fix all the unmitigated, high-priority risks. If you think you can’t, stop! In
    that case, you have two choices. You either stop working on the project altogether
    or revisit the same stage after doing some extra work. Based on what stage you
    are at, this extra work can be additional data collection (`data`, `preprocessing`),
    changing mitigation techniques (`model_training`), or model retraining (`model_inference`).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二部分（即在其他阶段添加风险评估步骤），`scoping.risk_assessment`为您的团队提供了一个重新审视的起点，以考虑随后阶段的新工作信息。在每个阶段的风险评估步骤中，团队可以（希望能够）开始勾选其中的事项，以及在下一个阶段添加新的检查事项。在阶段结束时，您的团队还应评估是否能够真实地解决所有未减轻的高优先级风险。如果认为无法解决，请停止！在这种情况下，您有两个选择。要么完全停止项目工作，要么在完成额外工作后重新审视同一阶段。根据您所处的阶段，此额外工作可以是额外的数据收集（`data`，`preprocessing`），更改缓解技术（`model_training`）或模型重新训练（`model_inference`）。
- en: Let’s consider how a list of prioritized risks might look in our example. Based
    on human-level considerations in the earlier steps under `scoping`, suppose the
    ML team has identified a number of trust concerns that need to be considered before
    they even begin data collection. [Table 8-3](#table-risk1) lists out these concerns
    and their resolution status (essentially `scoping.risk_assessment.list`).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑在我们的示例中优先级风险列表可能会是什么样子。根据`scoping`阶段的人为考虑，在甚至开始数据收集之前，假设ML团队已经识别出需要考虑的许多信任问题。[表8-3](#table-risk1)列出了这些问题及其解决状态（基本上是`scoping.risk_assessment.list`）。
- en: Table 8-3\. Sample risk assessment checklist at the `scoping` stage
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-3\. `scoping`阶段样本风险评估检查表
- en: '| Issue | Step taken | Resolved |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | 采取的步骤 | 已解决 |'
- en: '| --- | --- | --- |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Potential bias in user features data for user group A versus user group B
    |  | False |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 用户组A与用户组B在用户特征数据中存在潜在偏见 |  | False |'
- en: '| Potential bias in post features data for user group A versus user group B
    |  | False |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 用户组A与用户组B在帖子特征数据中存在潜在偏见 |  | False |'
- en: '| Potential bias in predictive accuracy of topic tags for topic group C versus
    topic group D | Sufficiently addressed by `topic_tags.*.risk_assessment` | True
    |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 主题标签预测准确性对比，对比组C与对比组D | `topic_tags.*.risk_assessment`已充分解决 | True |'
- en: '| Need to adhere to age-appropriate content safety and privacy guidelines per
    the California Age-Appropriate Design Code Act^([a](ch08.html#idm45621828957152))
    |  | False |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 需要遵守加州适龄内容安全和隐私指南设计法案^([a](ch08.html#idm45621828957152)) |  | False |'
- en: '| Need to explain recommendations using user history features per UX requirement
    |  | False |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 需要根据UX要求使用用户历史特征解释建议 |  | False |'
- en: '| ^([a](ch08.html#idm45621828957152-marker)) Kari Paul, [“First-of-its-Kind
    Legislation Will Keep California’s Children Safer While Online”](https://oreil.ly/9Gw5F),
    *The Guardian*, August 30, 2022. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| ^([a](ch08.html#idm45621828957152-marker)) Kari Paul，《[加州儿童在线安全法案将首次施行](https://oreil.ly/9Gw5F)》，《卫报》，2022年8月30日。
    |'
- en: 'Note that only one of the potential issues has the resolution field filled
    up. This makes sense: since this issue pertains to one of the inferred feature
    models, it is enough to check the `risk_assessment` steps of that project. Even
    though the rest of the concerns are not solved, the project team feels confident
    enough to move ahead with data collection.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，潜在问题中只有一个填写了解决方案字段。这是有道理的：因为这个问题涉及到一个推断特征模型，仅检查该项目的`risk_assessment`步骤就足够了。尽管其余问题尚未解决，但项目团队对进行数据收集感到足够有信心，可以继续推进。
- en: Guided by the previous risk assessment, the team makes sure to obtain demographic
    data for users. Therefore, even though `data.risk_assessment` doesn’t resolve
    any more issues than were documented in [Table 8-3](#table-risk1), the team is
    well positioned to tackle all but the explainability issue in the next stages
    ([Table 8-4](#table-risk2), only showing rows with new information).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的风险评估指导下，团队确保获取用户的人口统计数据。因此，即使 `data.risk_assessment` 解决的问题不超过 [表 8-3](#table-risk1)
    中记录的问题，但团队在下个阶段（仅显示具有新信息的行）已经准备好解决所有问题，除了可解释性问题（[表 8-4](#table-risk2)）。
- en: Table 8-4\. Sample risk assessment checklist at the `data` stage
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-4\. 数据阶段的样本风险评估检查表
- en: '| Issue | Step taken | Resolved |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | 执行步骤 | 已解决 |'
- en: '| --- | --- | --- |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Potential bias in user features data for user group A versus user group B
    | Collected demographic data to perform evaluation in `preprocessing` | False
    |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 用户组 A 与用户组 B 的用户特征数据中的潜在偏差 | 收集人口统计数据以在 `preprocessing` 中进行评估 | False |'
- en: '| Potential bias in post features data for user group A versus user group B
    | Collected demographic data to perform evaluation in `preprocessing` | False
    |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| 用户组 A 与用户组 B 的后特征数据中的潜在偏差 | 收集人口统计数据以在 `preprocessing` 中进行评估 | False |'
- en: In `preprocessing`, the team checks for data biases in the crafted features
    and finds biases in user features but not in post features. This closes one of
    the open issues ([Table 8-5](#table-risk3)).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `preprocessing` 中，团队检查了精心制作的特征中的数据偏差，并发现了用户特征中的偏差，但未在后特征中发现。这解决了一个未解决的问题（[表 8-5](#table-risk3)）。
- en: Table 8-5\. Sample risk assessment checklist at the `preprocessing` stage
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-5\. 预处理阶段的样本风险评估检查表
- en: '| Issue | Step taken | Resolved |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | 执行步骤 | 已解决 |'
- en: '| --- | --- | --- |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Potential bias in user features data for user group A versus user group B
    | Biases found in x, y, z features; see details in `pre​pro⁠cessing.other_steps`
    | False |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 用户组 A 与用户组 B 的用户特征数据中的潜在偏差 | 在 x、y、z 特征中发现了偏差；详细信息请参见 `pre​pro⁠cessing.other_steps`
    | False |'
- en: '| Potential bias in post features data for user group A versus user group B
    | No biases found in relevant features; see details in `pre​pro⁠cessing.other_steps`
    | True |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 用户组 A 与用户组 B 的后特征数据中的潜在偏差 | 未在相关特征中发现偏差；详细信息请参见 `pre​pro⁠cessing.other_steps`
    | True |'
- en: The team now trains the recommendation model, uses post-processing steps to
    perform bias mitigation by implementing safety and privacy filters, and adds a
    post hoc explainability layer to obtain explanation requirements from the product
    side ([Table 8-6](#table-risk4)).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在团队正在训练推荐模型，并使用后处理步骤执行偏差缓解，通过实施安全和隐私过滤器，并添加事后可解释性层以从产品方面获得解释需求（[表 8-6](#table-risk4)）。
- en: Table 8-6\. Sample risk assessment checklist at the `model_training` stage
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-6\. 模型训练阶段的样本风险评估检查表
- en: '| Issue | Step taken | Resolved |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | 执行步骤 | 已解决 |'
- en: '| --- | --- | --- |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Potential bias in user features data for user group A versus user group B
    | Used postprocessing mitigation to mitigate biases; see details in `model_training.metrics`
    | True |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 用户组 A 与用户组 B 的用户特征数据中的潜在偏差 | 使用后处理缓解偏差；详细信息请参见 `model_training.metrics` |
    True |'
- en: '| Need to adhere to age-appropriate content safety and privacy guidelines per
    the California Age-Appropriate Design Code Act^([a](ch08.html#idm45621828918640))
    | Added privacy and safety filters; see `model_training.metrics` and `model_training.ethical_considerations`
    | True |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 需要遵循适龄内容安全和隐私指南，根据加州适龄设计法案^([a](ch08.html#idm45621828918640)) | 添加了隐私和安全过滤器；请参见
    `model_training.metrics` 和 `model_training.ethical_considerations` | True |'
- en: '| Need to explain recommendations using user history features per UX requirement
    | Explanations implemented; see details in `model_training.metrics` | True |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 根据用户历史特征解释推荐的需求符合 UX 要求 | 已实施解释；详细信息请参见 `model_training.metrics` | True |'
- en: '| ^([a](ch08.html#idm45621828918640-marker)) Paul, “First-of-its-Kind Legislation
    Will Keep California’S Children Safer While Online.” |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| ^([a](ch08.html#idm45621828918640-marker)) 保罗，“加州首个类似法案将使儿童在网上更安全。” |'
- en: Since all trust issues are resolved, the product side decides to move ahead
    with model deployment. Once it is deployed, `model_inference.risk_assessment`
    will check that measurements of the trust metrics used in the model pipeline are
    within acceptable bounds. The `issue` fields would largely remain similar, while
    the `step_taken` fields would refer to specific fields under `model_inference.metric`,
    and the `resolved` status can be derived from the respective `model_inference.alerts`
    for a metric or group of metrics.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有信任问题都已解决，产品端决定继续进行模型部署。一旦部署完成，`model_inference.risk_assessment`将检查模型管道中使用的信任指标的测量结果是否在可接受范围内。`issue`字段基本保持不变，而`step_taken`字段将引用`model_inference.metric`下的特定字段，并且可以从相应的`model_inference.alerts`中推导出`resolved`状态，用于度量或一组度量。
- en: Tip
  id: totrans-259
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Can you work out the details of the exact schema for `model_inference.risk_assessment`?
    There is more than one right answer—give it a shot!
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 您能否详细说明`model_inference.risk_assessment`的确切模式？有不止一种正确答案—试试看！
- en: Conclusion
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this chapter, you learned about the tools and frameworks that enable you
    to implement production-grade ML *pipelines* in your company in a trusted manner.
    To do so, you need to:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解到了工具和框架，这些工具和框架使您能够以可信的方式在公司中实现生产级别的ML *管道*。为此，您需要：
- en: 'Use tools that actually get the job done within the constraints of your company:
    both technical and regulatory'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用实际能够在公司技术和法规约束条件下完成工作的工具：
- en: Preserve metadata information on ML pipelines for future reuse to inform similar
    projects
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保留ML管道的元数据信息，以便将来重复使用，为类似项目提供信息
- en: Codify human-level considerations to guide future projects
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将人类水平的考虑因素编码，以指导未来的项目。
- en: Connect ML pipelines and share learnings to facilitate troubleshooting
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接机器学习管道并分享学习成果，以便于故障排除。
- en: This holistic approach is transparent by definition. Whoever the stakeholder
    is, they will know exactly what considerations led to the design decisions in
    an ML pipeline, what the technical specs of model components are, and, most importantly,
    how to follow up when something goes wrong.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这种整体方法在定义上是透明的。无论利益相关者是谁，他们都会准确了解导致ML管道设计决策的所有考虑因素，模型组件的技术规格是什么，以及当出现问题时如何跟进。
- en: '^([1](ch08.html#idm45621830884688-marker)) Siram Vasudevan and Krishnaram Kenthapadi,
    [“LiFT: A Scalable Framework for Measuring Fairness in ML Applications”](https://dl.acm.org/doi/10.1145/3340531.3412705),
    *CIKM-2020* (October 2020): 2773–80.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '^([1](ch08.html#idm45621830884688-marker)) Siram Vasudevan 和 Krishnaram Kenthapadi，[“LiFT:
    A Scalable Framework for Measuring Fairness in ML Applications”](https://dl.acm.org/doi/10.1145/3340531.3412705)，*CIKM-2020*（2020年10月）：2773–80。'
- en: '^([2](ch08.html#idm45621830875680-marker)) Timnit Gebru et al., [“Datasheets
    for Datasets”](https://oreil.ly/xPSjM), *Communications of the ACM 2021* 64, no.
    12 (December 2021): 86–92.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch08.html#idm45621830875680-marker)) Timnit Gebru 等，[“Datasheets for Datasets”](https://oreil.ly/xPSjM)，*Communications
    of the ACM 2021* 64卷，第12期（2021年12月）：86–92。
- en: '^([3](ch08.html#idm45621830828048-marker)) Margaret Mitchell et al., [“Model
    Cards for Model Reporting”](https://dl.acm.org/doi/10.1145/3287560.3287596), *Proceedings
    of the Conference on Fairness, Accountability, and Transparency* (January 2019):
    220–9.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch08.html#idm45621830828048-marker)) Margaret Mitchell 等，[“Model Cards
    for Model Reporting”](https://dl.acm.org/doi/10.1145/3287560.3287596)，*Proceedings
    of the Conference on Fairness, Accountability, and Transparency*（2019年1月）：220–9。
- en: ^([4](ch08.html#idm45621830798720-marker)) Jacopo Tagliabue et al., [“DAG Card
    Is the New Model Card”](https://arxiv.org/abs/2110.13601), *arXiv preprint* (2021).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch08.html#idm45621830798720-marker)) Jacopo Tagliabue 等，[“DAG Card Is
    the New Model Card”](https://arxiv.org/abs/2110.13601)，*arXiv preprint*（2021年）。
- en: ^([5](ch08.html#idm45621830769280-marker)) Emily Dodwell et al., [“Towards Integrating
    Fairness Transparently in Industrial Applications”](https://arxiv.org/abs/2006.06082),
    *arXiv preprint* (2020).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch08.html#idm45621830769280-marker)) Emily Dodwell 等，[“Towards Integrating
    Fairness Transparently in Industrial Applications”](https://arxiv.org/abs/2006.06082)，*arXiv
    preprint*（2020年）。
- en: ^([6](ch08.html#idm45621830701200-marker)) Srikanth Machiraju, [“Why Data Drift
    Detection Is Important and How Do You Automate it in 5 Simple Steps”](https://oreil.ly/6iA64),
    *Towards Data Science* (blog), November 1, 2021.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch08.html#idm45621830701200-marker)) Srikanth Machiraju，[“Why Data Drift
    Detection Is Important and How Do You Automate it in 5 Simple Steps”](https://oreil.ly/6iA64)，*Towards
    Data Science*（博客），2021年11月1日。
- en: ^([7](ch08.html#idm45621830699200-marker)) Jason Brownlee, [“A Gentle Introduction
    to Concept Drift in Machine Learning”](https://oreil.ly/gsBxn), *Machine Learning
    Mastery* (blog), December 15, 2017.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch08.html#idm45621830699200-marker)) Jason Brownlee，[“A Gentle Introduction
    to Concept Drift in Machine Learning”](https://oreil.ly/gsBxn)，*Machine Learning
    Mastery*（博客），2017年12月15日。
- en: ^([8](ch08.html#idm45621830386960-marker)) For example, see [Google’s Open Source
    Software Vulnerability Rewards Program](https://oreil.ly/bf7GI).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch08.html#idm45621830386960-marker)) 例如，请查看[Google 的开源软件漏洞奖励计划](https://oreil.ly/bf7GI)。
