- en: Chapter 3\. Data Engineering Fundamentals
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '-   第三章 数据工程基础'
- en: The rise of ML in recent years is tightly coupled with the rise of big data.
    Large data systems, even without ML, are complex. If you haven’t spent years and
    years working with them, it’s easy to get lost in acronyms. There are many challenges
    and possible solutions that these systems generate. Industry standards, if there
    are any, evolve quickly as new tools come out and the needs of the industry expand,
    creating a dynamic and ever-changing environment. If you look into the data stack
    for different tech companies, it might seem like each is doing its own thing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来ML的崛起与大数据的崛起紧密相连。即使没有ML，大数据系统也是复杂的。如果您没有花费多年时间与它们一起工作，很容易在首字母缩写中迷失方向。这些系统产生许多挑战和可能的解决方案。行业标准（如果有的话）随着新工具的出现和行业需求的扩展而迅速演变，形成一个动态和不断变化的环境。如果您查看不同技术公司的数据堆栈，可能会觉得每个公司都在做自己的事情。
- en: In this chapter, we’ll cover the basics of data engineering that will, hopefully,
    give you a steady piece of land to stand on as you explore the landscape for your
    own needs. We’ll start with different sources of data that you might work with
    in a typical ML project. We’ll continue to discuss the formats in which data can
    be stored. Storing data is only interesting if you intend on retrieving that data
    later. To retrieve stored data, it’s important to know not only how it’s formatted
    but also how it’s structured. Data models define how the data stored in a particular
    data format is structured.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍数据工程的基础知识，希望能够为您在探索自己需求的领域中提供稳固的基础。我们将从您在典型ML项目中可能使用的不同数据来源开始讨论。我们将继续讨论数据可以存储的格式。只有当您打算稍后检索数据时，存储数据才有意义。为了检索存储的数据，重要的是不仅要了解其格式，还要了解其结构。数据模型定义了以特定数据格式存储的数据的结构。
- en: 'If data models describe the data in the real world, databases specify how the
    data should be stored on machines. We’ll continue to discuss data storage engines,
    also known as databases, for the two major types of processing: transactional
    and analytical.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据模型描述了现实世界中的数据，数据库则规定了数据应该如何存储在机器上。我们将继续讨论数据存储引擎，也称为数据库，用于两种主要处理类型：事务处理和分析处理。
- en: When working with data in production, you usually work with data across multiple
    processes and services. For example, you might have a feature engineering service
    that computes features from raw data, and a prediction service to generate predictions
    based on computed features. This means that you’ll have to pass computed features
    from the feature engineering service to the prediction service. In the following
    section of the chapter, we’ll discuss different modes of data passing across processes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中处理数据时，通常会跨多个进程和服务处理数据。例如，您可能有一个特征工程服务，从原始数据计算特征，并且一个预测服务，基于计算出的特征生成预测。这意味着您需要将特征工程服务计算出的特征传递给预测服务。在本章的接下来的部分中，我们将讨论跨进程传递数据的不同模式。
- en: 'During the discussion of different modes of data passing, we’ll learn about
    two distinct types of data: historical data in data storage engines, and streaming
    data in real-time transports. These two different types of data require different
    processing paradigms, which we’ll discuss in the section [“Batch Processing Versus
    Stream Processing”](#batch_processing_versus_stream_processi).'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论不同数据传递模式时，我们将了解到两种不同类型的数据：数据存储引擎中的历史数据和实时传输中的流数据。这两种不同类型的数据需要不同的处理范式，我们将在“批处理与流处理”部分讨论。
- en: Knowing how to collect, process, store, retrieve, and process an increasingly
    growing amount of data is essential to people who want to build ML systems in
    production. If you’re already familiar with data systems, you might want to move
    directly to [Chapter 4](ch04.xhtml#training_data) to learn more about how to sample
    and generate labels to create training data. If you want to learn more about data
    engineering from a systems perspective, I recommend Martin Kleppmann’s excellent
    book [*Designing Data-Intensive Applications*](https://oreil.ly/KGLXZ) (O’Reilly,
    2017).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 了解如何收集、处理、存储、检索和处理越来越多的数据对于希望建立生产ML系统的人来说至关重要。如果您已经熟悉数据系统，可能希望直接转到[第四章](ch04.xhtml#training_data)，了解如何采样和生成标签以创建训练数据。如果您想从系统的角度了解更多关于数据工程的内容，我推荐Martin
    Kleppmann的优秀著作[*设计数据密集型应用*](https://oreil.ly/KGLXZ)（O'Reilly出版，2017年）。
- en: Data Sources
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据源
- en: An ML system can work with data from many different sources. They have different
    characteristics, can be used for different purposes, and require different processing
    methods. Understanding the sources your data comes from can help you use your
    data more efficiently. This section aims to give a quick overview of different
    data sources to those unfamiliar with data in production. If you’ve already worked
    with ML in production for a while, feel free to skip this section.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统可以处理来自许多不同来源的数据。它们具有不同的特征，可用于不同的目的，并且需要不同的处理方法。了解数据来源可以帮助您更有效地使用数据。本节旨在向不熟悉生产数据的人快速概述不同的数据来源。如果您已经在生产中使用机器学习一段时间了，请随意跳过本节。
- en: One source is *user input data*, data explicitly input by users. User input
    can be text, images, videos, uploaded files, etc. If it’s even remotely possible
    for users to input wrong data, they are going to do it. As a result, user input
    data can be easily malformatted. Text might be too long or too short. Where numerical
    values are expected, users might accidentally enter text. If you let users upload
    files, they might upload files in the wrong formats. User input data requires
    more heavy-duty checking and processing.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一个来源是*用户输入数据*，即用户明确输入的数据。用户输入可以是文本、图像、视频、上传的文件等。如果用户可能输入错误数据，他们就会这样做。因此，用户输入数据很容易格式错误。文本可能过长或过短。在需要数值的地方，用户可能会意外输入文本。如果允许用户上传文件，他们可能会上传格式错误的文件。用户输入数据需要进行更严格的检查和处理。
- en: On top of that, users also have little patience. In most cases, when we input
    data, we expect to get results back immediately. Therefore, user input data tends
    to require fast processing.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，用户也具有很少的耐心。在大多数情况下，当我们输入数据时，我们希望立即得到结果。因此，用户输入数据往往需要快速处理。
- en: Another source is *system-generated data*. This is the data generated by different
    components of your systems, which include various types of logs and system outputs
    such as model predictions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个来源是*系统生成的数据*。这是由系统的不同组件生成的数据，包括各种类型的日志和系统输出，如模型预测。
- en: Logs can record the state and significant events of the system, such as memory
    usage, number of instances, services called, packages used, etc. They can record
    the results of different jobs, including large batch jobs for data processing
    and model training. These types of logs provide visibility into how the system
    is doing. The main purpose of this visibility is for debugging and potentially
    improving the application. Most of the time, you don’t have to look at these types
    of logs, but they are essential when something is on fire.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 日志可以记录系统的状态和重要事件，例如内存使用情况，实例数量，调用的服务，使用的软件包等。它们可以记录不同作业的结果，包括用于数据处理和模型训练的大批处理作业。这些类型的日志可以显示系统的运行情况。此可视性的主要目的是用于调试和可能改进应用程序。大多数情况下，您不必查看这些类型的日志，但是在出现问题时它们至关重要。
- en: Because logs are system generated, they are much less likely to be malformatted
    the way user input data is. Overall, logs don’t need to be processed as soon as
    they arrive, the way you would want to process user input data. For many use cases,
    it’s acceptable to process logs periodically, such as hourly or even daily. However,
    you might still want to process your logs fast to be able to detect and be notified
    whenever something interesting happens.^([1](ch03.xhtml#ch01fn57))
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由于日志是系统生成的，与用户输入数据可能会格式错误的情况相比，它们不太可能格式错误。总体而言，日志不需要在到达时立即处理，就像您希望处理用户输入数据那样。对于许多用例，定期处理日志是可以接受的，例如每小时或甚至每天一次。但是，您可能仍然希望快速处理日志，以便能够检测并在发生有趣事件时收到通知。^([1](ch03.xhtml#ch01fn57))
- en: Because debugging ML systems is hard, it’s a common practice to log everything
    you can. This means that your volume of logs can grow very, very quickly. This
    leads to two problems. The first is that it can be hard to know where to look
    because signals are lost in the noise. There have been many services that process
    and analyze logs, such as Logstash, Datadog, Logz.io, etc. Many of them use ML
    models to help you process and make sense of your massive number of logs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 因为调试机器学习系统很困难，通常的做法是尽可能记录所有内容。这意味着您的日志量可能会非常迅速地增长。这会导致两个问题。第一个问题是很难确定从哪里查找，因为信号可能会淹没在噪音中。已经有很多服务可以处理和分析日志，例如Logstash、Datadog、Logz.io等。其中许多服务使用机器学习模型来帮助您处理和理解大量的日志。
- en: The second problem is how to store a rapidly growing number of logs. Luckily,
    in most cases, you only have to store logs for as long as they are useful and
    can discard them when they are no longer relevant for you to debug your current
    system. If you don’t have to access your logs frequently, they can also be stored
    in low-access storage that costs much less than higher-frequency-access storage.^([2](ch03.xhtml#ch01fn58))
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个问题是如何存储迅速增长的日志数量。幸运的是，在大多数情况下，你只需在它们对于调试当前系统有用的时间内保存日志，并在不再相关时将其丢弃。如果你不经常访问日志，它们也可以存储在低访问存储中，成本远低于高频访问存储。^([2](ch03.xhtml#ch01fn58))
- en: The system also generates data to record users’ behaviors, such as clicking,
    choosing a suggestion, scrolling, zooming, ignoring a pop-up, or spending an unusual
    amount of time on certain pages. Even though this is system-generated data, it’s
    still considered part of user data and might be subject to privacy regulations.^([3](ch03.xhtml#ch01fn59))
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 系统还生成数据记录用户的行为，如点击、选择建议、滚动、缩放、忽略弹出窗口或在某些页面上花费不寻常的时间。尽管这是系统生成的数据，仍然被视为用户数据的一部分，并可能受到隐私法规的约束。^([3](ch03.xhtml#ch01fn59))
- en: There are also *internal databases*, generated by various services and enterprise
    applications in a company. These databases manage their assets such as inventory,
    customer relationship, users, and more. This kind of data can be used by ML models
    directly or by various components of an ML system. For example, when users enter
    a search query on Amazon, one or more ML models process that query to detect its
    intention—if someone types in “frozen,” are they looking for frozen foods or Disney’s
    *Frozen* franchise?—then Amazon needs to check its internal databases for the
    availability of these products before ranking them and showing them to users.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 公司中由各种服务和企业应用程序生成的*内部数据库*也存在。这些数据库管理它们的资产，如库存、客户关系、用户等等。这种数据可以直接被机器学习模型使用，或者被机器学习系统的各个组件使用。例如，当用户在亚马逊上输入搜索查询时，一个或多个机器学习模型会处理该查询以检测其意图——如果有人输入“冷冻”，他们是在寻找冷冻食品还是迪士尼的*冰雪奇缘*系列？——然后亚马逊需要检查其内部数据库以查看这些产品的可用性，然后对它们进行排名并向用户展示。
- en: Then there’s the wonderfully weird world of *third-party data*. First-party
    data is the data that your company already collects about your users or customers.
    Second-party data is the data collected by another company on their own customers
    that they make available to you, though you’ll probably have to pay for it. Third-party
    data companies collect data on the public who aren’t their direct customers.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是神奇而古怪的*第三方数据*世界。第一方数据是你的公司已经收集的关于用户或客户的数据。第二方数据是由另一家公司收集的关于他们自己客户的数据，他们可以向你提供，尽管你可能需要付费。第三方数据公司收集不是他们直接客户的公众数据。
- en: The rise of the internet and smartphones has made it much easier for all types
    of data to be collected. It used to be especially easy with smartphones since
    each phone used to have a unique advertiser ID—iPhones with Apple’s Identifier
    for Advertisers (IDFA) and Android phones with their Android Advertising ID (AAID)—which
    acted as a unique ID to aggregate all activities on a phone. Data from apps, websites,
    check-in services, etc. are collected and (hopefully) anonymized to generate activity
    history for each person.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网和智能手机的兴起使得所有类型的数据收集变得更加容易。以前在智能手机上尤其容易，因为每部手机都有一个唯一的广告商ID——iPhone有苹果的广告标识符（IDFA），而Android手机有他们的Android广告ID（AAID）——它作为一个唯一ID聚合了手机上的所有活动。来自应用程序、网站、签到服务等的数据被收集并（希望）匿名化，以生成每个人的活动历史。
- en: Data of all kinds can be bought, such as social media activities, purchase history,
    web browsing habits, car rentals, and political leaning for different demographic
    groups getting as granular as men, age 25–34, working in tech, living in the Bay
    Area. From this data, you can infer information such as people who like brand
    A also like brand B. This data can be especially helpful for systems such as recommender
    systems to generate results relevant to users’ interests. Third-party data is
    usually sold after being cleaned and processed by vendors.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 各种类型的数据都可以购买，例如社交媒体活动、购买历史、网页浏览习惯、汽车租赁以及不同人口统计群体的政治倾向，如男性、年龄在25至34岁之间、从事技术行业、居住在湾区的人。从这些数据中，你可以推断出喜欢A品牌的人也喜欢B品牌。这些数据对于诸如推荐系统之类的系统特别有帮助。第三方数据通常在供应商经过清洗和处理后出售。
- en: However, as users demand more data privacy, companies have been taking steps
    to curb the usage of advertiser IDs. In early 2021, Apple made their IDFA opt-in.
    This change has reduced significantly the amount of third-party data available
    on iPhones, forcing many companies to focus more on first-party data.^([4](ch03.xhtml#ch01fn60))
    To fight back this change, advertisers have been investing in workarounds. For
    example, the China Advertising Association, a state-supported trade association
    for China’s advertising industry, invested in a device fingerprinting system called
    CAID that allowed apps like TikTok and Tencent to keep tracking iPhone users.^([5](ch03.xhtml#ch01fn61))
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着用户对数据隐私的需求增加，公司们一直在采取措施限制广告主ID的使用。2021年初，苹果使其IDFA选择加入。这一变化显著减少了iPhone上可用的第三方数据量，迫使许多公司更多地关注第一方数据。^([4](ch03.xhtml#ch01fn60))为了对抗这一变化，广告主一直在投资寻找解决方案。例如，中国广告协会，作为中国广告行业的国家支持的贸易协会，投资于一种名为CAID的设备指纹系统，使得像抖音和腾讯这样的应用程序可以继续跟踪iPhone用户。^([5](ch03.xhtml#ch01fn61))
- en: Data Formats
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据格式
- en: 'Once you have data, you might want to store it (or “persist” it, in technical
    terms). Since your data comes from multiple sources with different access patterns,^([6](ch03.xhtml#ch01fn62))
    storing your data isn’t always straightforward and, for some cases, can be costly.
    It’s important to think about how the data will be used in the future so that
    the format you use will make sense. Here are some of the questions you might want
    to consider:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您拥有数据，您可能希望将其存储（或者从技术术语上说“持久化”）。由于您的数据来自不同访问模式的多个来源，^([6](ch03.xhtml#ch01fn62))存储数据并不总是简单的，而且对于某些情况可能会很昂贵。重要的是要考虑数据在未来如何使用，以便选择合适的格式。以下是您可能需要考虑的一些问题：
- en: How do I store multimodal data, e.g., a sample that might contain both images
    and texts?
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何存储多模态数据，例如可能同时包含图像和文本的样本？
- en: Where do I store my data so that it’s cheap and still fast to access?
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我应该将数据存储在哪里，以便既便宜又快速地访问？
- en: How do I store complex models so that they can be loaded and run correctly on
    different hardware?
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何存储复杂模型以便它们可以在不同硬件上正确加载和运行？
- en: The process of converting a data structure or object state into a format that
    can be stored or transmitted and reconstructed later is *data serialization*.
    There are many, many data serialization formats. When considering a format to
    work with, you might want to consider different characteristics such as human
    readability, access patterns, and whether it’s based on text or binary, which
    influences the size of its files. [Table 3-1](#common_data_formats_and_where_they_are)
    consists of just a few of the common formats that you might encounter in your
    work. For a more comprehensive list, check out the wonderful Wikipedia page [“Comparison
    of Data-Serialization Formats”](https://oreil.ly/sgceY).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据结构或对象状态转换为可以存储或传输并在以后重建的格式的过程称为*数据序列化*。有许多许多数据序列化格式。在选择要使用的格式时，您可能需要考虑不同的特性，例如人类可读性、访问模式以及它是基于文本还是二进制的，这会影响其文件大小。[表 3-1](#common_data_formats_and_where_they_are)只包含您在工作中可能遇到的一些常见格式。欲了解更全面的列表，请参阅优秀的维基百科页面[“数据序列化格式比较”](https://oreil.ly/sgceY)。
- en: Table 3-1\. Common data formats and where they are used
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-1\. 常见数据格式及其使用场景
- en: '| Format | Binary/Text | Human-readable | Example use cases |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 格式 | 二进制/文本 | 人类可读 | 示例用例 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| JSON | Text | Yes | Everywhere |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| JSON | 文本 | 是 | 到处都有 |'
- en: '| *CSV* | *Text* | *Yes* | *Everywhere* |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| *CSV* | *文本* | *是* | *到处都有* |'
- en: '| *Parquet* | *Binary* | *No* | *Hadoop, Amazon Redshift* |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| *Parquet* | *二进制* | *否* | *Hadoop, 亚马逊Redshift* |'
- en: '| Avro | Binary primary | No | Hadoop |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| Avro | 二进制主要 | 否 | Hadoop |'
- en: '| Protobuf | Binary primary | No | Google, TensorFlow (TFRecord) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| Protobuf | 二进制主要 | 否 | Google, TensorFlow (TFRecord) |'
- en: '| Pickle | Binary | No | Python, PyTorch serialization |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Pickle | 二进制 | 否 | Python, PyTorch序列化 |'
- en: 'We’ll go over a few of these formats, starting with JSON. We’ll also go over
    the two formats that are common and represent two distinct paradigms: CSV and
    Parquet.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论其中几种格式，首先是JSON。我们还将讨论两种常见的格式，它们代表了两种不同的范式：CSV和Parquet。
- en: JSON
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JSON
- en: 'JSON, JavaScript Object Notation, is everywhere. Even though it was derived
    from JavaScript, it’s language-independent—most modern programming languages can
    generate and parse JSON. It’s human-readable. Its key-value pair paradigm is simple
    but powerful, capable of handling data of different levels of structuredness.
    For example, your data can be stored in a structured format like the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: JSON，即 JavaScript 对象表示法，随处可见。尽管它源自 JavaScript，但它与语言无关——大多数现代编程语言都可以生成和解析 JSON。它是人类可读的。它的键-值对范式简单而强大，能够处理不同结构水平的数据。例如，您的数据可以以以下结构化格式存储：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The same data can also be stored in an unstructured blob of text like the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的数据也可以存储在以下非结构化文本块中：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Because JSON is ubiquitous, the pain it causes can also be felt everywhere.
    Once you’ve committed the data in your JSON files to a schema, it’s pretty painful
    to retrospectively go back to change the schema. JSON files are text files, which
    means they take up a lot of space, as we’ll see in the section [“Text Versus Binary
    Format”](#text_versus_binary_format).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 JSON 是无处不在的，它带来的痛苦也是普遍存在的。一旦您将 JSON 文件中的数据提交给某个模式，要回溯更改该模式就相当痛苦。JSON 文件是文本文件，这意味着它们占用大量空间，正如我们将在
    [“文本格式与二进制格式”](#text_versus_binary_format) 部分中看到的那样。
- en: Row-Major Versus Column-Major Format
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行优先格式与列优先格式的比较
- en: The two formats that are common and represent two distinct paradigms are CSV
    and Parquet. CSV (comma-separated values) is row-major, which means consecutive
    elements in a row are stored next to each other in memory. Parquet is column-major,
    which means consecutive elements in a column are stored next to each other.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 两种常见的格式代表两种不同的范例，分别是 CSV 和 Parquet。CSV（逗号分隔值）是行优先的，这意味着同一行内的连续元素在内存中是相邻存储的。Parquet
    是列优先的，这意味着同一列内的连续元素在内存中是相邻存储的。
- en: Because modern computers process sequential data more efficiently than nonsequential
    data, if a table is row-major, accessing its rows will be faster than accessing
    its columns in expectation. This means that for row-major formats, accessing data
    by rows is expected to be faster than accessing data by columns.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 因为现代计算机比非顺序数据更有效地处理顺序数据，如果表是行优先的，预计按行访问数据将比按列访问数据更快。这意味着对于行优先格式，预计按行访问数据将比按列访问数据更快。
- en: Imagine we have a dataset of 1,000 examples, and each example has 10 features.
    If we consider each example as a row and each feature as a column, as is often
    the case in ML, then the row-major formats like CSV are better for accessing examples,
    e.g., accessing all the examples collected today. Column-major formats like Parquet
    are better for accessing features, e.g., accessing the timestamps of all your
    examples. See [Figure 3-1](#row_major_versus_column_major_formats).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们有一个包含 1,000 个示例的数据集，每个示例有 10 个特征。如果我们将每个示例视为一行，每个特征视为一列，这在机器学习中经常发生，那么像
    CSV 这样的行优先格式更适合访问示例，例如，访问今天收集到的所有示例。像 Parquet 这样的列优先格式更适合访问特征，例如，访问所有示例的时间戳。参见
    [图 3-1](#row_major_versus_column_major_formats)。
- en: '![](Images/dmls_0301.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0301.png)'
- en: Figure 3-1\. Row-major versus column-major formats
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. 行优先与列优先格式
- en: 'Column-major formats allow flexible column-based reads, especially if your
    data is large with thousands, if not millions, of features. Consider if you have
    data about ride-sharing transactions that has 1,000 features but you only want
    4 features: time, location, distance, price. With column-major formats, you can
    read the four columns corresponding to these four features directly. However,
    with row-major formats, if you don’t know the sizes of the rows, you will have
    to read in all columns then filter down to these four columns. Even if you know
    the sizes of the rows, it can still be slow as you’ll have to jump around the
    memory, unable to take advantage of caching.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 列优先格式允许基于列灵活读取数据，特别是当数据量大且有成千上万的特征时。考虑一下，如果你有关于共享乘车交易的数据，该数据有 1,000 个特征，但你只需要
    4 个特征：时间、位置、距离、价格。使用列优先格式，你可以直接读取与这四个特征对应的四列数据。然而，使用行优先格式，如果你不知道行的大小，你将不得不读取所有列，然后筛选出这四列数据。即使你知道行的大小，由于需要在内存中跳跃，无法利用缓存，速度仍然可能较慢。
- en: Row-major formats allow faster data writes. Consider the situation when you
    have to keep adding new individual examples to your data. For each individual
    example, it’d be much faster to write it to a file where your data is already
    in a row-major format.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 行优先格式允许更快的数据写入。考虑当您不断向数据中添加新的个体示例时的情况。对于每个个体示例，将其写入已经处于行优先格式的文件中会更快。
- en: Overall, row-major formats are better when you have to do a lot of writes, whereas
    column-major ones are better when you have to do a lot of column-based reads.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，当你需要大量写操作时，行主要格式更好，而当你需要大量基于列的读操作时，列主要格式更好。
- en: Note
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: I use CSV as an example of the row-major format because it’s popular and generally
    recognizable by everyone I’ve talked to in tech. However, some of the early reviewers
    of this book pointed out that they believe CSV to be a horrible data format. It
    serializes nontext characters poorly. For example, when you write float values
    to a CSV file, some precision might be lost—0.12345678901232323 could be arbitrarily
    rounded up as “0.12345678901”—as complained about in a [Stack Overflow thread](https://oreil.ly/HjTMM)
    and [Microsoft Community thread](https://oreil.ly/cbvQu). People on [Hacker News](https://oreil.ly/ziCmo)
    have passionately argued against using CSV.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我用 CSV 作为行主要格式的示例，因为它很受欢迎，几乎所有我在技术领域交流过的人都能认识。然而，本书的一些早期审阅者指出，他们认为 CSV 是一个糟糕的数据格式。它会将非文本字符序列化得很差。例如，当你将浮点数值写入
    CSV 文件时，可能会丢失一些精度 —— `0.12345678901232323` 可能会被任意四舍五入为 `0.12345678901` —— 正如在
    [Stack Overflow thread](https://oreil.ly/HjTMM) 和 [Microsoft Community thread](https://oreil.ly/cbvQu)
    中所抱怨的那样。[Hacker News](https://oreil.ly/ziCmo) 上的一些人则激烈地反对使用 CSV。
- en: Text Versus Binary Format
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本与二进制格式
- en: CSV and JSON are text files, whereas Parquet files are binary files. Text files
    are files that are in plain text, which usually means they are human-readable.
    Binary files are the catchall that refers to all nontext files. As the name suggests,
    binary files are typically files that contain only 0s and 1s, and are meant to
    be read or used by programs that know how to interpret the raw bytes. A program
    has to know exactly how the data inside the binary file is laid out to make use
    of the file. If you open text files in your text editor (e.g., VS Code, Notepad),
    you’ll be able to read the texts in them. If you open a binary file in your text
    editor, you’ll see blocks of numbers, likely in hexadecimal values, for corresponding
    bytes of the file.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: CSV 和 JSON 是文本文件，而 Parquet 文件是二进制文件。文本文件是指通常是人类可读的纯文本文件。二进制文件是一个泛指，指的是所有非文本文件。顾名思义，二进制文件通常只包含
    0 和 1，并且是为那些知道如何解释原始字节的程序所设计的。如果你在文本编辑器中打开文本文件（例如 VS Code、记事本），你可以读取其中的文本内容。如果你在文本编辑器中打开二进制文件，你会看到一些数字块，可能是十六进制值，对应文件的字节。
- en: Binary files are more compact. Here’s a simple example to show how binary files
    can save space compared to text files. Consider that you want to store the number
    `1000000`. If you store it in a text file, it’ll require 7 characters, and if
    each character is 1 byte, it’ll require 7 bytes. If you store it in a binary file
    as int32, it’ll take only 32 bits or 4 bytes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制文件更紧凑。这里有一个简单的例子来展示二进制文件如何节省空间，与文本文件相比。假设你想存储数字 `1000000`。如果你将其存储在文本文件中，将需要
    7 个字符，如果每个字符占用 1 字节，那么就需要 7 字节。如果你将其存储在二进制文件中作为 int32，只需要 32 位或 4 字节。
- en: As an illustration, I use *interviews.csv*, which is a CSV file (text format)
    of 17,654 rows and 10 columns. When I converted it to a binary format (Parquet),
    the file size went from 14 MB to 6 MB, as shown in [Figure 3-3](#when_stored_in_csv_formatcomma_my_inter).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，我使用 *interviews.csv*，这是一个包含 17,654 行和 10 列的 CSV 文件（文本格式）。当我将其转换为二进制格式（Parquet）时，文件大小从
    14 MB 缩小到 6 MB，如 [Figure 3-3](#when_stored_in_csv_formatcomma_my_inter) 所示。
- en: AWS recommends using the Parquet format because “the Parquet format is up to
    2x faster to unload and consumes up to 6x less storage in Amazon S3, compared
    to text formats.”^([8](ch03.xhtml#ch01fn64))
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 建议使用 Parquet 格式，因为“Parquet 格式在 Amazon S3 中的卸载速度高达原来的 2 倍，并且比文本格式消耗的存储空间少达
    6 倍。”^([8](ch03.xhtml#ch01fn64))
- en: '![](Images/dmls_0303.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0303.png)'
- en: Figure 3-3\. When stored in CSV format, my interview file is 14 MB. But when
    stored in Parquet, the same file is 6 MB.
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. 当以 CSV 格式存储时，我的面试文件大小为 14 MB。但当以 Parquet 格式存储相同文件时，文件大小为 6 MB。
- en: Data Models
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据模型
- en: Data models describe how data is represented. Consider cars in the real world.
    In a database, a car can be described using its make, its model, its year, its
    color, and its price. These attributes make up a data model for cars. Alternatively,
    you can also describe a car using its owner, its license plate, and its history
    of registered addresses. This is another data model for cars.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 数据模型描述了数据的表示方式。考虑现实世界中的汽车。在数据库中，汽车可以通过其品牌、型号、年份、颜色和价格来描述。这些属性构成了汽车的数据模型。或者，你也可以通过其所有者、车牌号和注册地址历史来描述汽车。这是汽车的另一个数据模型。
- en: How you choose to represent data not only affects the way your systems are built,
    but also the problems your systems can solve. For example, the way you represent
    cars in the first data model makes it easier for people looking to buy cars, whereas
    the second data model makes it easier for police officers to track down criminals.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您选择如何表示数据不仅影响系统构建的方式，还影响系统能够解决的问题。例如，第一个数据模型中的汽车表示方式使得寻找购买汽车的人变得更容易，而第二个数据模型使得警察追踪罪犯变得更容易。
- en: 'In this section, we’ll study two types of models that seem opposite to each
    other but are actually converging: relational models and NoSQL models. We’ll go
    over examples to show the types of problems each model is suited for.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将研究看似相反但实际上正在趋同的两种模型：关系模型和 NoSQL 模型。我们将通过示例展示每种模型适合解决的问题类型。
- en: Relational Model
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关系模型
- en: Relational models are among the most persistent ideas in computer science. Invented
    by Edgar F. Codd in 1970,^([9](ch03.xhtml#ch01fn65)) the relational model is still
    going strong today, even getting more popular. The idea is simple but powerful.
    In this model, data is organized into relations; each relation is a set of tuples.
    A table is an accepted visual representation of a relation, and each row of a
    table makes up a tuple,^([10](ch03.xhtml#ch01fn66)) as shown in [Figure 3-4](#in_a_relationcomma_the_order_of_neither).
    Relations are unordered. You can shuffle the order of the rows or the order of
    the columns in a relation and it’s still the same relation. Data following the
    relational model is usually stored in file formats like CSV or Parquet.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 关系模型是计算机科学中最持久的理念之一。由埃德加·F·科德在 1970 年发明，^([9](ch03.xhtml#ch01fn65)) 关系模型至今仍然非常流行，甚至变得越来越受欢迎。这个理念简单而强大。在这个模型中，数据被组织成关系；每个关系是一组元组。表是关系的一种接受的视觉表示，表的每一行构成一个元组，^([10](ch03.xhtml#ch01fn66))
    如图 [Figure 3-4](#in_a_relationcomma_the_order_of_neither) 所示。关系是无序的。您可以对关系中的行或列进行重新排序，它仍然是同一个关系。遵循关系模型的数据通常存储在诸如
    CSV 或 Parquet 的文件格式中。
- en: '![](Images/dmls_0304.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0304.png)'
- en: Figure 3-4\. In a relation, the order of neither the rows nor the columns matters
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. 在一个关系中，既不考虑行的顺序也不考虑列的顺序
- en: It’s often desirable for relations to be normalized. Data normalization can
    follow normal forms such as the first normal form (1NF), second normal form (2NF),
    etc., and readers interested can read more about it on [Wikipedia](https://oreil.ly/EbrCk).
    In this book, we’ll go through an example to show how normalization works and
    how it can reduce data redundancy and improve data integrity.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通常希望关系能够被规范化。数据规范化可以遵循诸如第一范式（1NF）、第二范式（2NF）等正规形式，有兴趣的读者可以在 [维基百科](https://oreil.ly/EbrCk)
    上进一步了解。在本书中，我们将通过一个示例展示规范化的工作原理以及它如何减少数据冗余并提高数据完整性。
- en: Consider the relation Book shown in [Table 3-2](#initial_book_relation). There
    are a lot of duplicates in this data. For example, rows 1 and 2 are nearly identical,
    except for format and price. If the publisher information changes—for example,
    its name changes from “Banana Press” to “Pineapple Press”—or its country changes,
    we’ll have to update rows 1, 2, and 4\. If we separate publisher information into
    its own table, as shown in Tables [3-3](#updated_book_relation) and [3-4](#publisher_relation),
    when a publisher’s information changes, we only have to update the Publisher relation.^([11](ch03.xhtml#ch01fn67))
    This practice allows us to standardize spelling of the same value across different
    columns. It also makes it easier to make changes to these values, either because
    these values change or when you want to translate them into different languages.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到在 [Table 3-2](#initial_book_relation) 中显示的关系 Book。这些数据中存在大量重复项。例如，行 1 和行
    2 几乎相同，只有格式和价格不同。如果出版商信息发生变化——例如，其名称从“香蕉出版社”变为“菠萝出版社”——或者其国家发生变化，我们将不得不更新行 1、2
    和 4。如果我们将出版商信息分离到自己的表中，如表 [3-3](#updated_book_relation) 和 [3-4](#publisher_relation)
    所示，当出版商信息发生变化时，我们只需更新 Publisher 关系。^([11](ch03.xhtml#ch01fn67)) 这种做法使我们能够统一跨不同列中相同值的拼写。它还使得更容易对这些值进行更改，无论是因为这些值发生变化还是当您希望将它们翻译成不同的语言时。
- en: Table 3-2\. Initial Book relation
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-2\. 初始图书关系
- en: '| Title | Author | Format | Publisher | Country | Price |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 标题 | 作者 | 格式 | 出版商 | 国家 | 价格 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Harry Potter | J.K. Rowling | Paperback | Banana Press | UK | $20 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 哈利·波特 | J.K. 罗琳 | 平装书 | 香蕉出版社 | 英国 | $20 |'
- en: '| Harry Potter | J.K. Rowling | E-book | Banana Press | UK | $10 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 哈利·波特 | J.K. 罗琳 | 电子书 | 香蕉出版社 | 英国 | $10 |'
- en: '| Sherlock Holmes | Conan Doyle | Paperback | Guava Press | US | $30 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 夏洛克·福尔摩斯 | 柯南·道尔 | 平装 | Guava Press | 美国 | $30 |'
- en: '| The Hobbit | J.R.R. Tolkien | Paperback | Banana Press | UK | $30 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 霍比特人 | J.R.R. 托尔金 | 平装 | Banana Press | 英国 | $30 |'
- en: '| Sherlock Holmes | Conan Doyle | Paperback | Guava Press | US | $15 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 夏洛克·福尔摩斯 | 柯南·道尔 | 平装 | Guava Press | 美国 | $15 |'
- en: Table 3-3\. Updated Book relation
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-3\. 更新的图书关系
- en: '| Title | Author | Format | Publisher ID | Price |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 标题 | 作者 | 格式 | 出版商 ID | 价格 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Harry Potter | J.K. Rowling | Paperback | 1 | $20 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 哈利·波特 | J.K. 罗琳 | 平装 | 1 | $20 |'
- en: '| Harry Potter | J.K. Rowling | E-book | 1 | $10 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 哈利·波特 | J.K. 罗琳 | 电子书 | 1 | $10 |'
- en: '| Sherlock Holmes | Conan Doyle | Paperback | 2 | $30 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 夏洛克·福尔摩斯 | 柯南·道尔 | 平装 | 2 | $30 |'
- en: '| The Hobbit | J.R.R. Tolkien | Paperback | 1 | $30 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 霍比特人 | J.R.R. 托尔金 | 平装 | 1 | $30 |'
- en: '| Sherlock Holmes | Conan Doyle | Paperback | 2 | $15 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 夏洛克·福尔摩斯 | 柯南·道尔 | 平装 | 2 | $15 |'
- en: Table 3-4\. Publisher relation
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-4\. 出版商关系
- en: '| Publisher ID | Publisher | Country |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 出版商 ID | 出版商 | 国家 |'
- en: '| --- | --- | --- |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | Banana Press | UK |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 1 | Banana Press | 英国 |'
- en: '| 2 | Guava Press | US |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Guava Press | 美国 |'
- en: One major downside of normalization is that your data is now spread across multiple
    relations. You can join the data from different relations back together, but joining
    can be expensive for large tables.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化的一个主要缺点是你的数据现在分布在多个关系中。你可以将不同关系中的数据再次联接在一起，但对于大表来说，联接可能是昂贵的。
- en: Databases built around the relational data model are relational databases. Once
    you’ve put data in your databases, you’ll want a way to retrieve it. The language
    that you can use to specify the data that you want from a database is called a
    *query language*. The most popular query language for relational databases today
    is SQL. Even though inspired by the relational model, the data model behind SQL
    has deviated from the original [relational model](https://oreil.ly/g4waq). For
    example, SQL tables can contain row duplicates, whereas true relations can’t contain
    duplicates. However, this subtle difference has been safely ignored by most people.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 建立在关系数据模型之上的数据库称为关系数据库。一旦你把数据放入数据库中，你会想要一种方法来检索它。你可以用来指定从数据库中获取数据的语言称为*查询语言*。如今最流行的关系数据库查询语言是
    SQL。尽管受到关系模型的启发，SQL 背后的数据模型已经偏离了原始的[关系模型](https://oreil.ly/g4waq)。例如，SQL 表可以包含行重复，而真实的关系不能包含重复。然而，大多数人安全地忽略了这种细微差别。
- en: The most important thing to note about SQL is that it’s a declarative language,
    as opposed to Python, which is an imperative language. In the imperative paradigm,
    you specify the steps needed for an action and the computer executes these steps
    to return the outputs. In the declarative paradigm, you specify the outputs you
    want, and the computer figures out the steps needed to get you the queried outputs.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 SQL 最重要的一点是它是一种声明式语言，与 Python 相对，Python 是一种命令式语言。在命令式范式中，你指定执行一个动作所需的步骤，计算机执行这些步骤以返回输出。在声明式范式中，你指定你想要的输出，计算机则会找出获取查询输出所需的步骤。
- en: With an SQL database, you specify the pattern of data you want—the tables you
    want the data from, the conditions the results must meet, the basic data transformations
    such as join, sort, group, aggregate, etc.—but not how to retrieve the data. It
    is up to the database system to decide how to break the query into different parts,
    what methods to use to execute each part of the query, and the order in which
    different parts of the query should be executed.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SQL 数据库中，你指定想要的数据模式——你要从哪些表中获取数据，结果必须满足的条件，基本的数据转换如联接、排序、分组、聚合等——但不指定如何检索数据。由数据库系统决定如何将查询分解为不同部分，使用什么方法执行查询的每个部分，以及应该执行查询的不同部分的顺序。
- en: With certain added features, SQL can be [Turing-complete](https://oreil.ly/npL5B),
    which means that, in theory, SQL can be used to solve any computation problem
    (without making any guarantee about the time or memory required). However, in
    practice, it’s not always easy to write a query to solve a specific task, and
    it’s not always feasible or tractable to execute a query. Anyone working with
    SQL databases might have nightmarish memories of painfully long SQL queries that
    are impossible to understand and nobody dares to touch for fear that things might
    break.^([12](ch03.xhtml#ch01fn68))
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在特定的增强功能下，SQL可以是[Turing-complete](https://oreil.ly/npL5B)，这意味着理论上SQL可以用来解决任何计算问题（不保证时间或内存的需求）。然而，在实践中，编写一个解决特定任务的查询并不总是容易，执行查询也不总是可行或可控的。任何使用SQL数据库的人可能对那些极其难以理解且谁都不敢碰的痛苦漫长的SQL查询有噩梦般的回忆^([12](ch03.xhtml#ch01fn68))。
- en: Figuring out how to execute an arbitrary query is the hard part, which is the
    job of query optimizers. A query optimizer examines all possible ways to execute
    a query and finds the fastest way to do so.^([13](ch03.xhtml#ch01fn69)) It’s possible
    to use ML to improve query optimizers based on learning from incoming queries.^([14](ch03.xhtml#ch01fn70))
    Query optimization is one of the most challenging problems in database systems,
    and normalization means that data is spread out on multiple relations, which makes
    joining it together even harder. Even though developing a query optimizer is hard,
    the good news is that you generally only need one query optimizer and all your
    applications can leverage it.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 弄清楚如何执行任意查询是难点，这是查询优化器的工作。查询优化器会检查执行查询的所有可能方式，并找到最快的方式来执行^([13](ch03.xhtml#ch01fn69))。可以使用机器学习来改进基于来访查询的查询优化器^([14](ch03.xhtml#ch01fn70))。查询优化是数据库系统中最具挑战性的问题之一，而归一化意味着数据分布在多个关系上，这使得将其连接在一起变得更加困难。尽管开发查询优化器很难，好消息是通常你只需要一个查询优化器，所有应用程序都可以利用它。
- en: NoSQL
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NoSQL
- en: 'The relational data model has been able to generalize to a lot of use cases,
    from ecommerce to finance to social networks. However, for certain use cases,
    this model can be restrictive. For example, it demands that your data follows
    a strict schema, and schema management is painful. In a survey by Couchbase in
    2014, frustration with schema management was the #1 reason for the adoption of
    their nonrelational database.^([16](ch03.xhtml#ch01fn72)) It can also be difficult
    to write and execute SQL queries for specialized applications.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 关系数据模型已经能够推广到许多用例，从电子商务到金融再到社交网络。然而，对于某些用例，这种模型可能会有限制。例如，它要求您的数据遵循严格的模式，而模式管理是痛苦的。在Couchbase
    2014年的一项调查中，对模式管理的挫折感是他们采用非关系数据库的第一原因^([16](ch03.xhtml#ch01fn72))。对于专业应用程序编写和执行SQL查询也可能会很困难。
- en: The latest movement against the relational data model is NoSQL. Originally started
    as a hashtag for a meetup to discuss nonrelational databases, NoSQL has been retroactively
    reinterpreted as Not Only SQL,^([17](ch03.xhtml#ch01fn73)) as many NoSQL data
    systems also support relational models. Two major types of nonrelational models
    are the document model and the graph model. The document model targets use cases
    where data comes in self-contained documents and relationships between one document
    and another are rare. The graph model goes in the opposite direction, targeting
    use cases where relationships between data items are common and important. We’ll
    examine each of these two models, starting with the document model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最新的反对关系数据模型的运动是NoSQL。最初作为一个关于非关系数据库讨论的聚会的标签开始，NoSQL已经被追溯地重新解释为Not Only SQL^([17](ch03.xhtml#ch01fn73))，因为许多NoSQL数据系统也支持关系模型。两种主要的非关系模型是文档模型和图模型。文档模型针对的是数据以自包含文档形式存在，文档之间的关系很少的用例。而图模型则恰恰相反，针对的是数据项之间关系频繁且重要的用例。我们将分别研究这两种模型，首先从文档模型开始。
- en: Document model
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文档模型
- en: The document model is built around the concept of “document.” A document is
    often a single continuous string, encoded as JSON, XML, or a binary format like
    BSON (Binary JSON). All documents in a document database are assumed to be encoded
    in the same format. Each document has a unique key that represents that document,
    which can be used to retrieve it.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 文档模型围绕“文档”的概念构建。文档通常是一个单一连续的字符串，编码为JSON、XML或类似BSON（二进制JSON）的二进制格式。文档数据库中的所有文档都假定以相同的格式编码。每个文档都有一个唯一的键，表示该文档，可以用来检索它。
- en: A collection of documents could be considered analogous to a table in a relational
    database, and a document analogous to a row. In fact, you can convert a relation
    into a collection of documents that way. For example, you can convert the book
    data in Tables [3-3](#updated_book_relation) and [3-4](#publisher_relation) into
    three JSON documents as shown in Examples [3-1](#ex_harry_potter), [3-2](#ex_sherlock_holmes),
    and [3-3](#ex_the_hobbit). However, a collection of documents is much more flexible
    than a table. All rows in a table must follow the same schema (e.g., have the
    same sequence of columns), while documents in the same collection can have completely
    different schemas.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 文档的集合可以类比为关系数据库中的表，而文档类比为一行。实际上，你可以通过这种方式将一个关系转换为文档的集合。例如，你可以将表[3-3](#updated_book_relation)中的书籍数据和表[3-4](#publisher_relation)中的数据转换为三个JSON文档，如示例[3-1](#ex_harry_potter)，[3-2](#ex_sherlock_holmes)和[3-3](#ex_the_hobbit)所示。然而，文档的集合比表格更加灵活。表中的所有行必须遵循相同的模式（例如具有相同的列序列），而同一集合中的文档可以具有完全不同的模式。
- en: 'Example 3-1\. Document 1: harry_potter.json'
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '示例3-1. 文档1: harry_potter.json'
- en: '[PRE2]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Example 3-2\. Document 2: sherlock_holmes.json'
  id: totrans-107
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '示例3-2. 文档2: sherlock_holmes.json'
- en: '[PRE3]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Example 3-3\. Document 3: the_hobbit.json'
  id: totrans-109
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '示例3-3. 文档3: the_hobbit.json'
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Because the document model doesn’t enforce a schema, it’s often referred to
    as schemaless. This is misleading because, as discussed previously, data stored
    in documents will be read later. The application that reads the documents usually
    assumes some kind of structure of the documents. Document databases just shift
    the responsibility of assuming structures from the application that writes the
    data to the application that reads the data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 由于文档模型不强制执行模式，因此通常被称为无模式。这是具有误导性的，因为如前所述，存储在文档中的数据将在以后读取。读取文档的应用程序通常假设文档具有某种结构。文档数据库只是将假设结构的责任从写入数据的应用程序转移到读取数据的应用程序。
- en: The document model has better locality than the relational model. Consider the
    book data example in Tables [3-3](#updated_book_relation) and [3-4](#publisher_relation)
    where the information about a book is spread across both the Book table and the
    Publisher table (and potentially also the Format table). To retrieve information
    about a book, you’ll have to query multiple tables. In the document model, all
    information about a book can be stored in a document, making it much easier to
    retrieve.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 文档模型比关系模型具有更好的局部性。考虑书籍数据示例，在表[3-3](#updated_book_relation)和表[3-4](#publisher_relation)中，关于书籍的信息分布在书表和出版商表（可能还有格式表）中。要检索有关书籍的信息，您必须查询多个表。在文档模型中，所有有关书籍的信息都可以存储在一个文档中，这样更容易检索。
- en: However, compared to the relational model, it’s harder and less efficient to
    execute joins across documents compared to across tables. For example, if you
    want to find all books whose prices are below $25, you’ll have to read all documents,
    extract the prices, compare them to $25, and return all the documents containing
    the books with prices below $25.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与关系模型相比，跨文档执行连接操作更加困难且效率较低。例如，如果你想找出所有价格低于$25的书籍，你将需要读取所有文档，提取价格，将其与$25进行比较，并返回所有包含价格低于$25的书籍的文档。
- en: Because of the different strengths of the document and relational data models,
    it’s common to use both models for different tasks in the same database systems.
    More and more database systems, such as PostgreSQL and MySQL, support them both.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 由于文档和关系数据模型的不同优势，通常在同一数据库系统中为不同任务使用两种模型是常见的。越来越多的数据库系统，如PostgreSQL和MySQL，都支持这两种模型。
- en: Graph model
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图模型
- en: The graph model is built around the concept of a “graph.” A graph consists of
    nodes and edges, where the edges represent the relationships between the nodes.
    A database that uses graph structures to store its data is called a graph database.
    If in document databases, the content of each document is the priority, then in
    graph databases, the relationships between data items are the priority.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图模型建立在“图”概念周围。图由节点和边组成，其中边表示节点之间的关系。使用图结构存储数据的数据库称为图数据库。如果在文档数据库中，每个文档的内容是优先考虑的，那么在图数据库中，数据项之间的关系是优先考虑的。
- en: 'Because the relationships are modeled explicitly in graph models, it’s faster
    to retrieve data based on relationships. Consider an example of a graph database
    in [Figure 3-5](#an_example_of_a_simple_graph_database). The data from this example
    could potentially come from a simple social network. In this graph, nodes can
    be of different data types: person, city, country, company, etc.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 因为关系在图模型中被明确地建模，所以基于关系检索数据更快。考虑一个简单图数据库的例子，见[图 3-5](#an_example_of_a_simple_graph_database)。这个例子的数据可能来自一个简单的社交网络。在这个图中，节点可以是不同的数据类型：person（人）、city（城市）、country（国家）、company（公司）等。
- en: '![](Images/dmls_0305.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0305.png)'
- en: Figure 3-5\. An example of a simple graph database
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5\. 一个简单图数据库的示例
- en: Imagine you want to find everyone who was born in the USA. Given this graph,
    you can start from the node USA and traverse the graph following the edges “within”
    and “born_in” to find all the nodes of the type “person.” Now, imagine that instead
    of using the graph model to represent this data, we use the relational model.
    There’d be no easy way to write an SQL query to find everyone who was born in
    the USA, especially given that there are an unknown number of hops between *country*
    and *person*—there are three hops between Zhenzhong Xu and USA while there are
    only two hops between Chloe He and USA. Similarly, there’d be no easy way for
    this type of query with a document database.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想要找到所有在**美国**出生的人。给定这个图，你可以从节点**美国**开始，并沿着“within”和“born_in”边遍历图，以找到所有类型为“person”的节点。现在，想象一下，如果我们不使用图模型来表示这些数据，而是使用关系模型。那么，很难编写SQL查询来找到所有在**美国**出生的人，特别是考虑到*country*和*person*之间有未知数量的跳数——在**美国**和Zhenzhong
    Xu之间有三个跳数，而在**美国**和Chloe He之间只有两个跳数。同样地，对于文档数据库，这种类型的查询也不容易。
- en: Many queries that are easy to do in one data model are harder to do in another
    data model. Picking the right data model for your application can make your life
    so much easier.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 许多在一种数据模型中容易处理的查询，在另一种数据模型中就比较困难。选择适合你的应用程序的正确数据模型可以大大简化你的生活。
- en: Structured Versus Unstructured Data
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结构化数据与非结构化数据
- en: 'Structured data follows a predefined data model, also known as a data schema.
    For example, the data model might specify that each data item consists of two
    values: the first value, “name,” is a string of at most 50 characters, and the
    second value, “age,” is an 8-bit integer in the range between 0 and 200\. The
    predefined structure makes your data easier to analyze. If you want to know the
    average age of people in the database, all you have to do is to extract all the
    age values and average them out.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据遵循预定义的数据模型，也称为数据模式。例如，数据模型可以指定每个数据项包含两个值：第一个值“name”是一个最多50个字符的字符串，第二个值“age”是一个范围在0到200之间的8位整数。预定义的结构使得你的数据更容易分析。如果你想知道数据库中人们的平均年龄，你只需提取所有年龄值并计算平均值。
- en: The disadvantage of structured data is that you have to commit your data to
    a predefined schema. If your schema changes, you’ll have to retrospectively update
    all your data, often causing mysterious bugs in the process. For example, you’ve
    never kept your users’ email addresses before but now you do, so you have to retrospectively
    update email information to all previous users. One of the strangest bugs one
    of my colleagues encountered was when they could no longer use users’ ages with
    their transactions, and their data schema replaced all the null ages with 0, and
    their ML model thought the transactions were made by people 0 years old.^([18](ch03.xhtml#ch01fn74))
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据的缺点在于你必须将数据提交给预定义的模式。如果你的模式发生变化，你将不得不回顾性地更新所有数据，这往往会在过程中引起一些难以解释的错误。例如，以前你从未保存过用户的电子邮件地址，但现在你需要保存，所以你必须回顾性地更新所有先前用户的电子邮件信息。我的一位同事遇到的最奇怪的错误之一是，他们不能再使用用户的年龄与他们的交易，他们的数据模式将所有空年龄替换为0，他们的机器学习模型认为这些交易是由0岁的人完成的。^([18](ch03.xhtml#ch01fn74))
- en: Because business requirements change over time, committing to a predefined data
    schema can become too restricting. Or you might have data from multiple data sources
    that are beyond your control, and it’s impossible to make them follow the same
    schema. This is where unstructured data becomes appealing. Unstructured data doesn’t
    adhere to a predefined data schema. It’s usually text but can also be numbers,
    dates, images, audio, etc. For example, a text file of logs generated by your
    ML model is unstructured data.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 因为业务需求随时间变化，承诺预定义的数据架构可能变得太限制性。或者您可能有来自多个数据源的数据，这些数据超出您的控制范围，不可能使它们遵循相同的架构。这就是非结构化数据变得吸引人的地方。非结构化数据不遵循预定义的数据架构。通常它是文本，但也可以是数字、日期、图像、音频等。例如，您的机器学习模型生成的日志文本文件就是非结构化数据。
- en: Even though unstructured data doesn’t adhere to a schema, it might still contain
    intrinsic patterns that help you extract structures. For example, the following
    text is unstructured, but you can notice the pattern that each line contains two
    values separated by a comma, the first value is textual, and the second value
    is numerical. However, there is no guarantee that all lines must follow this format.
    You can add a new line to that text even if that line doesn’t follow this format.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 即使非结构化数据不遵循架构，它仍然可能包含有助于您提取结构的内在模式。例如，以下文本是非结构化的，但您可以注意到每行包含两个由逗号分隔的值的模式，第一个值是文本，第二个值是数字。但并不保证所有行都必须遵循此格式。即使这行不遵循此格式，您也可以向该文本添加新行。
- en: '[PRE5]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Unstructured data also allows for more flexible storage options. For example,
    if your storage follows a schema, you can only store data following that schema.
    But if your storage doesn’t follow a schema, you can store any type of data. You
    can convert all your data, regardless of types and formats, into bytestrings and
    store them together.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 非结构化数据还允许更灵活的存储选项。例如，如果您的存储遵循架构，您只能存储符合该架构的数据。但是如果您的存储不遵循架构，您可以存储任何类型的数据。您可以将所有数据，无论其类型和格式如何，转换为字节串并将它们一起存储。
- en: A repository for storing structured data is called a data warehouse. A repository
    for storing unstructured data is called a data lake. Data lakes are usually used
    to store raw data before processing. Data warehouses are used to store data that
    has been processed into formats ready to be used. [Table 3-5](#the_key_differences_between_structured)
    shows a summary of the key differences between structured and unstructured data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 存储结构化数据的仓库称为数据仓库。存储非结构化数据的仓库称为数据湖。数据湖通常用于在处理之前存储原始数据。数据仓库用于存储已经处理成可用格式的数据。[表 3-5](#the_key_differences_between_structured)
    概述了结构化数据和非结构化数据之间的关键差异。
- en: Table 3-5\. The key differences between structured and unstructured data
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-5\. 结构化数据和非结构化数据的关键差异
- en: '| Structured data | Unstructured data |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 结构化数据 | 非结构化数据 |'
- en: '| --- | --- |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Schema clearly defined | Data doesn’t have to follow a schema |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 架构明确定义 | 数据无需遵循架构 |'
- en: '| Easy to search and analyze | Fast arrival |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 易于搜索和分析 | 快速到达 |'
- en: '| Can only handle data with a specific schema | Can handle data from any source
    |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 只能处理具有特定架构的数据 | 可处理来自任何源的数据 |'
- en: '| Schema changes will cause a lot of troubles | No need to worry about schema
    changes (yet), as the worry is shifted to the downstream applications that use
    this data |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 架构更改将导致许多问题 | 无需担心架构更改（至少现在不用），因为这种担心转移到使用这些数据的下游应用程序上了 |'
- en: '| Stored in data warehouses | Stored in data lakes |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 存储在数据仓库中 | 存储在数据湖中 |'
- en: Data Storage Engines and Processing
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据存储引擎和处理
- en: Data formats and data models specify the interface for how users can store and
    retrieve data. Storage engines, also known as databases, are the implementation
    of how data is stored and retrieved on machines. It’s useful to understand different
    types of databases as your team or your adjacent team might need to select a database
    appropriate for your application.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 数据格式和数据模型指定了用户存储和检索数据的接口。存储引擎，也被称为数据库，是数据在机器上存储和检索的实现方式。理解不同类型的数据库很有用，因为你的团队或相邻团队可能需要选择适合你的应用的数据库。
- en: Typically, there are two types of workloads that databases are optimized for,
    transactional processing and analytical processing, and there’s a big difference
    between them, which we’ll cover in this section. We will then cover the basics
    of the ETL (extract, transform, load) process that you will inevitably encounter
    when building an ML system in production.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，数据库针对两种类型的工作负载进行了优化，即事务处理和分析处理，在这一部分我们将详细介绍它们之间的主要区别。然后我们将介绍您在构建生产中的ML系统时必然会遇到的ETL（抽取、转换、加载）过程的基础知识。
- en: Transactional and Analytical Processing
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事务性处理和分析处理
- en: 'Traditionally, a transaction refers to the action of buying or selling something.
    In the digital world, a transaction refers to any kind of action: tweeting, ordering
    a ride through a ride-sharing service, uploading a new model, watching a YouTube
    video, and so on. Even though these different transactions involve different types
    of data, the way they’re processed is similar across applications. The transactions
    are inserted as they are generated, and occasionally updated when something changes,
    or deleted when they are no longer needed.^([19](ch03.xhtml#ch01fn75)) This type
    of processing is known as *online transaction processing* (OLTP).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，交易指的是买卖行为。在数字世界中，交易指任何类型的行为：发推文、通过共享乘车服务预订车辆、上传新模型、观看YouTube视频等等。尽管这些不同的交易涉及不同类型的数据，但它们在应用程序中的处理方式是类似的。交易在生成时插入，当发生变化时偶尔更新，或者在不再需要时删除。^([19](ch03.xhtml#ch01fn75))
    这种处理方式被称为*在线事务处理*（OLTP）。
- en: Because these transactions often involve users, they need to be processed fast
    (low latency) so that they don’t keep users waiting. The processing method needs
    to have high availability—that is, the processing system needs to be available
    any time a user wants to make a transaction. If your system can’t process a transaction,
    that transaction won’t go through.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这些交易经常涉及用户，所以需要快速处理（低延迟），以免让用户等待。处理方法需要具有高可用性——也就是说，处理系统在用户想要进行交易时需要随时可用。如果您的系统无法处理某个交易，该交易将无法进行。
- en: 'Transactional databases are designed to process online transactions and satisfy
    the low latency, high availability requirements. When people hear transactional
    databases, they usually think of ACID (atomicity, consistency, isolation, durability).
    Here are their definitions for those needing a quick reminder:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 事务性数据库旨在处理在线交易并满足低延迟、高可用性的要求。当人们听到事务性数据库时，他们通常会想到ACID（原子性、一致性、隔离性、持久性）。以下是对这些术语的定义，以供需要快速回顾的人参考：
- en: Atomicity
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 原子性
- en: To guarantee that all the steps in a transaction are completed successfully
    as a group. If any step in the transaction fails, all other steps must fail also.
    For example, if a user’s payment fails, you don’t want to still assign a driver
    to that user.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 确保交易中的所有步骤作为一个组成功完成。如果交易中的任何一步失败，所有其他步骤也必须失败。例如，如果用户的付款失败，你不希望仍然为该用户分配司机。
- en: Consistency
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性
- en: To guarantee that all the transactions coming through must follow predefined
    rules. For example, a transaction must be made by a valid user.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 确保所有经过的交易都必须遵循预定义的规则。例如，交易必须由有效用户进行。
- en: Isolation
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 隔离性
- en: To guarantee that two transactions happen at the same time as if they were isolated.
    Two users accessing the same data won’t change it at the same time. For example,
    you don’t want two users to book the same driver at the same time.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 确保两个交易在同时发生时就像它们被隔离一样。两个访问相同数据的用户不会同时更改它。例如，你不希望两个用户同时预订同一司机。
- en: Durability
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 持久性
- en: To guarantee that once a transaction has been committed, it will remain committed
    even in the case of a system failure. For example, after you’ve ordered a ride
    and your phone dies, you still want your ride to come.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 确保一旦交易已提交，即使在系统故障的情况下也将保持提交状态。例如，当你订了一辆车但手机没电时，你仍希望你的车能来。
- en: However, transactional databases don’t necessarily need to be ACID, and some
    developers find ACID to be too restrictive. According to Martin Kleppmann, “systems
    that do not meet the ACID criteria are sometimes called BASE, which stands for
    *B*asically *A*vailable, *S*oft state, and *E*ventual consistency. This is even
    more vague than the definition of ACID.”^([20](ch03.xhtml#ch01fn76))
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，事务性数据库不一定需要遵循ACID原则，一些开发人员认为ACID过于限制。根据Martin Kleppmann的说法，“不符合ACID标准的系统有时被称为BASE，它代表*基本上可用*、*软状态*和*最终一致性*。这比ACID的定义更加模糊。”^([20](ch03.xhtml#ch01fn76))
- en: Because each transaction is often processed as a unit separately from other
    transactions, transactional databases are often row-major. This also means that
    transactional databases might not be efficient for questions such as “What’s the
    average price for all the rides in September in San Francisco?” This kind of analytical
    question requires aggregating data in columns across multiple rows of data. Analytical
    databases are designed for this purpose. They are efficient with queries that
    allow you to look at data from different viewpoints. We call this type of processing
    *online analytical processing* (OLAP).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 每个事务通常作为一个单独的单位进行处理，与其他事务分开，因此事务性数据库通常是面向行的。这也意味着事务性数据库对于诸如“在旧金山9月份所有乘车的平均价格是多少？”这样的问题可能不够高效。这种分析性问题需要跨多行数据的列进行数据聚合。分析性数据库就是为此目的而设计的。它们可以有效地处理允许您从不同视角查看数据的查询。我们称这种处理方式为*在线分析处理*（OLAP）。
- en: However, both the terms OLTP and OLAP have become outdated, as shown in [Figure 3-6](#olap_and_oltp_are_outdated_termscomma_a),
    for three reasons. First, the separation of transactional and analytical databases
    was due to limitations of technology—it was hard to have databases that could
    handle both transactional and analytical queries efficiently. However, this separation
    is being closed. Today, we have transactional databases that can handle analytical
    queries, such as [CockroachDB](https://oreil.ly/UsPCr). We also have analytical
    databases that can handle transactional queries, such as [Apache Iceberg](https://oreil.ly/pgAfK)
    and [DuckDB](https://oreil.ly/jVTHZ).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，OLTP和OLAP这两个术语都已经过时，如[图3-6](#olap_and_oltp_are_outdated_termscomma_a)所示，原因有三。首先，事务性和分析性数据库的分离是由技术限制造成的——很难拥有能够有效处理事务性和分析性查询的数据库。然而，这种分离正在逐渐消失。今天，我们有能够处理分析性查询的事务性数据库，例如[CockroachDB](https://oreil.ly/UsPCr)。我们还有能够处理事务性查询的分析性数据库，例如[Apache
    Iceberg](https://oreil.ly/pgAfK)和[DuckDB](https://oreil.ly/jVTHZ)。
- en: '![](Images/dmls_0306.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图3-6](Images/dmls_0306.png)'
- en: Figure 3-6\. OLAP and OLTP are outdated terms, as of 2021, according to [Google
    Trends](https://oreil.ly/O8gAH)
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-6\. 根据[Google Trends](https://oreil.ly/O8gAH)，截至2021年，OLAP和OLTP已经过时。
- en: Second, in the traditional OLTP or OLAP paradigms, storage and processing are
    tightly coupled—how data is stored is also how data is processed. This may result
    in the same data being stored in multiple databases and using different processing
    engines to solve different types of queries. An interesting paradigm in the last
    decade has been to decouple storage from processing (also known as compute), as
    adopted by many data vendors including Google’s BigQuery, Snowflake, IBM, and
    Teradata.^([21](ch03.xhtml#custom_ch3fn1)) In this paradigm, the data can be stored
    in the same place, with a processing layer on top that can be optimized for different
    types of queries.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的OLTP或OLAP范式中，存储和处理紧密耦合——数据存储方式也是数据处理方式。这可能导致同一数据存储在多个数据库中，并使用不同的处理引擎来解决不同类型的查询。在过去的十年中，一个有趣的范式是将存储与处理（也称为计算）解耦，这被许多数据供应商采纳，包括Google的BigQuery、Snowflake、IBM和Teradata。^([21](ch03.xhtml#custom_ch3fn1))
    在这种范式中，数据可以存储在同一个地方，上面有一个处理层，可以针对不同类型的查询进行优化。
- en: Third, “online” has become an overloaded term that can mean many different things.
    Online used to just mean “connected to the internet.” Then, it grew to also mean
    “in production”—we say a feature is online after that feature has been deployed
    in production.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，“在线”已经成为一个具有多重含义的过载术语。在线过去只是指“连接到互联网”。然后，它扩展到还意味着“在生产中”—我们说一个功能在部署到生产环境后就是在线的。
- en: 'In the data world today, *online* might refer to the speed at which your data
    is processed and made available: online, nearline, or offline. According to Wikipedia,
    online processing means data is immediately available for input/output. Nearline,
    which is short for near-online, means data is not immediately available but can
    be made online quickly without human intervention. *Offline* means data is not
    immediately available and requires some human intervention to become online.^([22](ch03.xhtml#custom_ch3fn3))'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今的数据世界中，*在线*可能指的是数据处理和可用性的速度：在线、准在线或离线。根据维基百科，在线处理意味着数据立即可供输入/输出使用。准在线，即近在线，意味着数据不是立即可用，但可以在无需人工干预的情况下快速变为在线状态。*离线*意味着数据不是立即可用，需要一些人工干预才能变为在线状态。^([22](ch03.xhtml#custom_ch3fn3))
- en: 'ETL: Extract, Transform, and Load'
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ETL：提取、转换和加载
- en: In the early days of the relational data model, data was mostly structured.
    When data is *extracted* from different sources, it’s first *transformed* into
    the desired format before being *loaded* into the target destination such as a
    database or a data warehouse. This process is called *ETL*, which stands for extract,
    transform, and load.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在关系数据模型的早期阶段，数据大多是结构化的。当数据从不同的源中 *提取* 出来时，首先需要 *转换* 成所需的格式，然后再 *加载* 到目标位置，如数据库或数据仓库。这个过程被称为
    *ETL*，即提取、转换和加载。
- en: Even before ML, ETL was all the rage in the data world, and it’s still relevant
    today for ML applications. ETL refers to the general purpose processing and aggregating
    of data into the shape and the format that you want.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在机器学习出现之前，ETL 在数据世界也非常流行，对于机器学习应用至今仍然非常重要。ETL 指的是将数据处理和聚合成您所需的形状和格式的通用处理。
- en: Extract is extracting the data you want from all your data sources. Some of
    them will be corrupted or malformatted. In the extracting phase, you need to validate
    your data and reject the data that doesn’t meet your requirements. For rejected
    data, you might have to notify the sources. Since this is the first step of the
    process, doing it correctly can save you a lot of time downstream.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Extract 是从所有数据源中提取您想要的数据。其中一些可能已损坏或格式错误。在提取阶段，您需要验证数据并拒绝不符合要求的数据。对于被拒绝的数据，您可能需要通知数据源。由于这是流程的第一步，正确执行可以节省大量的时间。
- en: Transform is the meaty part of the process, where most of the data processing
    is done. You might want to join data from multiple sources and clean it. You might
    want to standardize the value ranges (e.g., one data source might use “Male” and
    “Female” for genders, but another uses “M” and “F” or “1” and “2”). You can apply
    operations such as transposing, deduplicating, sorting, aggregating, deriving
    new features, more data validating, etc.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: Transform 是流程的关键部分，大部分数据处理都在这里完成。您可能需要从多个来源连接数据并清理它。您可能需要标准化值范围（例如，一个数据源可能使用“男性”和“女性”，而另一个数据源使用“M”和“F”或“1”和“2”）。您可以应用操作，如转置、去重、排序、聚合、衍生新特征、更多数据验证等。
- en: Load is deciding how and how often to load your transformed data into the target
    destination, which can be a file, a database, or a data warehouse.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Load 是决定如何以及多久将您的转换数据加载到目标位置，可以是文件、数据库或数据仓库。
- en: The idea of ETL sounds simple but powerful, and it’s the underlying structure
    of the data layer at many organizations. An overview of the ETL process is shown
    in [Figure 3-7](#an_overview_of_the_etl_process).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ETL 的概念听起来简单但很强大，并且它是许多组织数据层的基础结构。ETL 过程的概述如 [图 3-7](#an_overview_of_the_etl_process)
    所示。
- en: '![](Images/dmls_0307.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0307.png)'
- en: Figure 3-7\. An overview of the ETL process
  id: totrans-169
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-7\. ETL 过程概述
- en: When the internet first became ubiquitous and hardware had just become so much
    more powerful, collecting data suddenly became so much easier. The amount of data
    grew rapidly. Not only that, but the nature of data also changed. The number of
    data sources expanded, and data schemas evolved.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当互联网首次普及并且硬件变得更加强大时，收集数据突然变得更加容易。数据量迅速增长。不仅如此，数据的性质也发生了变化。数据源的数量扩展了，数据模式也在演变。
- en: 'Finding it difficult to keep data structured, some companies had this idea:
    “Why not just store all data in a data lake so we don’t have to deal with schema
    changes? Whichever application needs data can just pull out raw data from there
    and process it.” This process of loading data into storage first then processing
    it later is sometimes called *ELT* (extract, load, transform). This paradigm allows
    for the fast arrival of data since there’s little processing needed before data
    is stored.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 由于难以保持数据结构化，一些公司提出了这样的想法：“为什么不将所有数据存储在数据湖中，这样我们就不必处理模式变更了？任何需要数据的应用程序都可以直接从那里提取原始数据并进行处理。”
    这种先将数据加载到存储中，然后再进行处理的过程有时称为 *ELT*（提取、加载、转换）。这种范式允许数据快速到达，因为存储数据之前需要的处理很少。
- en: However, as data keeps on growing, this idea becomes less attractive. It’s inefficient
    to search through a massive amount of raw data for the data that you want.^([23](ch03.xhtml#ch01fn77))
    At the same time, as companies switch to running applications on the cloud and
    infrastructures become standardized, data structures also become standardized.
    Committing data to a predefined schema becomes more feasible.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着数据的持续增长，这种思路变得不那么吸引人。在大量原始数据中搜索所需数据是低效的。[^23] 与此同时，随着公司转向在云上运行应用程序和基础设施标准化，数据结构也变得标准化。将数据提交到预定义的模式变得更为可行。
- en: As companies weigh the pros and cons of storing structured data versus storing
    unstructured data, vendors evolve to offer hybrid solutions that combine the flexibility
    of data lakes and the data management aspect of data warehouses. For example,
    Databricks and Snowflake both provide data lakehouse solutions.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 随着公司权衡结构化数据与非结构化数据存储的利弊，供应商不断发展，提供结合数据湖的灵活性和数据仓库的数据管理方面的混合解决方案。例如，Databricks
    和 Snowflake 都提供数据湖仓库解决方案。
- en: Modes of Dataflow
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据流的模式
- en: 'In this chapter, we’ve been discussing data formats, data models, data storage,
    and processing for data used within the context of a single process. Most of the
    time, in production, you don’t have a single process but multiple. A question
    arises: how do we pass data between different processes that don’t share memory?'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了数据格式、数据模型、数据存储以及在单个进程上下文中使用的数据处理。在生产环境中，大多数情况下，并不只有单个进程，而是多个进程同时存在。一个问题是：我们如何在不共享内存的不同进程之间传递数据？
- en: 'When data is passed from one process to another, we say that the data flows
    from one process to another, which gives us a dataflow. There are three main modes
    of dataflow:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据从一个进程传递到另一个进程时，我们称该数据从一个进程流向另一个进程，这形成了一个数据流。数据流有三种主要的模式：
- en: Data passing through databases
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过数据库传递数据
- en: Data passing through services using requests such as the requests provided by
    REST and RPC APIs (e.g., POST/GET requests)
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用 REST 和 RPC API（例如 POST/GET 请求）等请求的服务传递数据
- en: Data passing through a real-time transport like Apache Kafka and Amazon Kinesis
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过实时传输如 Apache Kafka 和 Amazon Kinesis 传递数据
- en: We’ll go over each of them in this section.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本节详细介绍每一种模式。
- en: Data Passing Through Databases
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过数据库传递数据
- en: The easiest way to pass data between two processes is through databases, which
    we’ve discussed in the section [“Data Storage Engines and Processing”](#data_storage_engines_and_processing).
    For example, to pass data from process A to process B, process A can write that
    data into a database, and process B simply reads from that database.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个进程之间传递数据的最简单方法是通过数据库，我们在[“数据存储引擎和处理”](#data_storage_engines_and_processing)一节中已经讨论过这一点。例如，要将数据从进程
    A 传递给进程 B，进程 A 可以将数据写入数据库，而进程 B 则从该数据库中读取数据。
- en: This mode, however, doesn’t always work because of two reasons. First, it requires
    that both processes must be able to access the same database. This might be infeasible,
    especially if the two processes are run by two different companies.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方式并不总是适用，原因有两个。首先，它要求两个进程必须能够访问同一个数据库。这可能是不可行的，特别是如果两个进程由两家不同的公司运行。
- en: Second, it requires both processes to access data from databases, and read/write
    from databases can be slow, making it unsuitable for applications with strict
    latency requirements—e.g., almost all consumer-facing applications.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，它要求两个进程都能够从数据库访问数据，而数据库的读写速度可能较慢，这使得它不适合对延迟要求严格的应用程序，例如几乎所有面向消费者的应用程序。
- en: Data Passing Through Services
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过服务传递数据
- en: One way to pass data between two processes is to send data directly through
    a network that connects these two processes. To pass data from process B to process
    A, process A first sends a request to process B that specifies the data A needs,
    and B returns the requested data through the same network. Because processes communicate
    through requests, we say that this is *request-driven*.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 传递数据的一种方式是通过连接这两个进程的网络直接发送数据。为了将数据从进程 B 传递给进程 A，进程 A 首先向进程 B 发送一个请求，指定 A 需要的数据，然后
    B 通过同一网络返回请求的数据。因为进程通过请求进行通信，所以我们称之为*请求驱动*。
- en: This mode of data passing is tightly coupled with the service-oriented architecture.
    A service is a process that can be accessed remotely, e.g., through a network.
    In this example, B is exposed to A as a service that A can send requests to. For
    B to be able to request data from A, A will also need to be exposed to B as a
    service.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据传递方式与面向服务的架构密切相关。服务是可通过网络远程访问的进程。在本示例中，B被公开为A可以向其发送请求的服务。为了使B能够从A请求数据，A还需要向B公开为服务。
- en: Two services in communication with each other can be run by different companies
    in different applications. For example, a service might be run by a stock exchange
    that keeps track of the current stock prices. Another service might be run by
    an investment firm that requests the current stock prices and uses them to predict
    future stock prices.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 两个相互通信的服务也可以由不同公司在不同应用程序中运行。例如，一个服务可能由股票交易所运行，用于跟踪当前股票价格。另一个服务可能由投资公司运行，请求当前股票价格并使用它们来预测未来股票价格。
- en: Two services in communication with each other can also be parts of the same
    application. Structuring different components of your application as separate
    services allows each component to be developed, tested, and maintained independently
    of one another. Structuring an application as separate services gives you a microservice
    architecture.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 两个相互通信的服务也可以是同一个应用程序的一部分。将应用程序的不同组件构建为单独的服务允许每个组件独立开发、测试和维护。将应用程序构建为单独的服务提供了微服务架构。
- en: 'To put the microservice architecture in the context of ML systems, imagine
    you’re an ML engineer working on the price optimization problem for a company
    that owns a ride-sharing application like Lyft. In reality, Lyft has [hundreds
    of services](https://oreil.ly/6fl8f) in its microservice architecture, but for
    the sake of simplicity, let’s consider only three services:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将微服务架构置于ML系统的背景下，想象你是一名ML工程师，为拥有类似Lyft的乘车共享应用的公司解决价格优化问题。实际上，Lyft在其微服务架构中拥有[数百个服务](https://oreil.ly/6fl8f)，但为了简单起见，我们只考虑三个服务：
- en: Driver management service
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 司机管理服务
- en: Predicts how many drivers will be available in the next minute in a given area.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 预测在指定区域下一分钟内将有多少司机可用。
- en: Ride management service
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 乘车管理服务
- en: Predicts how many rides will be requested in the next minute in a given area.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 预测在指定区域下一分钟内将有多少乘车请求。
- en: Price optimization service
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 价格优化服务
- en: Predicts the optimal price for each ride. The price for a ride should be low
    enough for riders to be willing to pay, yet high enough for drivers to be willing
    to drive and for the company to make a profit.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 预测每次乘车的最佳价格。乘车价格应低到足以使乘客愿意支付，但足够高以使司机愿意开车，并使公司获利。
- en: Because the price depends on supply (the available drivers) and demand (the
    requested rides), the price optimization service needs data from both the driver
    management and ride management services. Each time a user requests a ride, the
    price optimization service requests the predicted number of rides and predicted
    number of drivers to predict the optimal price for this ride.^([24](ch03.xhtml#ch01fn78))
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 因为价格取决于供应（可用司机）和需求（请求的乘车），价格优化服务需要来自司机管理和乘车管理服务的数据。每当用户请求乘车时，价格优化服务请求预测的乘车次数和预测的司机数量，以预测此乘车的最佳价格。^([24](ch03.xhtml#ch01fn78))
- en: The most popular styles of requests used for passing data through networks are
    REST (representational state transfer) and RPC (remote procedure call). Their
    detailed analysis is beyond the scope of this book, but one major difference is
    that REST was designed for requests over networks, whereas RPC “tries to make
    a request to a remote network service look the same as calling a function or method
    in your programming language*.*” Because of this, “REST seems to be the predominant
    style for public APIs. The main focus of RPC frameworks is on requests between
    services owned by the same organization, typically within the same data center.”^([25](ch03.xhtml#ch01fn79))
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 通过网络传递数据的最流行的请求方式包括REST（表述性状态转移）和RPC（远程过程调用）。它们的详细分析超出了本书的范围，但一个主要区别在于REST设计用于网络请求，而RPC“试图使对远程网络服务的请求看起来与调用编程语言中的函数或方法相同*.*”由于这一点，“REST似乎是公共API的主要风格。RPC框架的主要重点是在同一组织内部服务之间的请求，通常在同一数据中心内。”^([25](ch03.xhtml#ch01fn79))
- en: Implementations of a REST architecture are said to be RESTful. Even though many
    people think of REST as HTTP, REST doesn’t exactly mean HTTP because HTTP is just
    an implementation of REST.^([26](ch03.xhtml#custom_ch3fn4))
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 实现 REST 架构的实现被称为 RESTful。尽管许多人将 REST 视为 HTTP，但 REST 并不完全意味着 HTTP，因为 HTTP 只是
    REST 的一种实现方式。^([26](ch03.xhtml#custom_ch3fn4))
- en: Data Passing Through Real-Time Transport
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过实时传输进行数据传递
- en: 'To understand the motivation for real-time transports, let’s go back to the
    preceding example of the ride-sharing app with three simple services: driver management,
    ride management, and price optimization. In the last section, we discussed how
    the price optimization service needs data from the ride and driver management
    services to predict the optimal price for each ride.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解实时传输的动机，让我们回到前面的例子，即具有三个简单服务（司机管理、乘车管理和价格优化）的乘车共享应用程序。在上一节中，我们讨论了价格优化服务需要从乘车和司机管理服务获取数据，以预测每次乘车的最佳价格。
- en: Now, imagine that the driver management service also needs to know the number
    of rides from the ride management service to know how many drivers to mobilize.
    It also wants to know the predicted prices from the price optimization service
    to use them as incentives for potential drivers (e.g., if you get on the road
    now you can get a 2x surge charge). Similarly, the ride management service might
    also want data from the driver management and price optimization services. If
    we pass data through services as discussed in the previous section, each of these
    services needs to send requests to the other two services, as shown in [Figure 3-8](#in_the_request_driven_architecturecomma).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，想象一下司机管理服务还需要从乘车管理服务获取乘车次数，以便知道需要动员多少司机。它还想从价格优化服务那里获取预测价格，作为激励潜在司机的手段（例如，如果现在上路，您可以获得2倍的高峰费）。类似地，乘车管理服务可能还需要来自司机管理和价格优化服务的数据。如果我们像前一节讨论的那样通过服务传递数据，那么每个服务都需要向另外两个服务发送请求，如[图 3-8](#in_the_request_driven_architecturecomma)所示。
- en: '![](Images/dmls_0308.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0308.png)'
- en: Figure 3-8\. In the request-driven architecture, each service needs to send
    requests to two other services
  id: totrans-204
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-8\. 在请求驱动的架构中，每个服务需要向另外两个服务发送请求
- en: With only three services, data passing is already getting complicated. Imagine
    having hundreds, if not thousands of services like what major internet companies
    have. Interservice data passing can blow up and become a bottleneck, slowing down
    the entire system.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 即使只有三个服务，数据传递已经变得复杂。想象一下像大型互联网公司那样拥有数百甚至数千个服务。服务间的数据传递可能会爆炸，并成为减慢整个系统的瓶颈。
- en: 'Request-driven data passing is synchronous: the target service has to listen
    to the request for the request to go through. If the price optimization service
    requests data from the driver management service and the driver management service
    is down, the price optimization service will keep resending the request until
    it times out. And if the price optimization service is down before it receives
    a response, the response will be lost. A service that is down can cause all services
    that require data from it to be down.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 请求驱动的数据传递是同步的：目标服务必须监听请求才能进行请求。如果价格优化服务请求来自司机管理服务的数据，而司机管理服务已经停机，则价格优化服务将继续重新发送请求直至超时。如果价格优化服务在收到响应之前停机，则响应将丢失。一个停机的服务可能导致所有需要其数据的服务停机。
- en: What if there’s a broker that coordinates data passing among services? Instead
    of having services request data directly from each other and creating a web of
    complex interservice data passing, each service only has to communicate with the
    broker, as shown in [Figure 3-9](#with_a_brokercomma_a_service_only_has_t). For
    example, instead of having other services request the driver management services
    for the predicted number of drivers for the next minute, what if whenever the
    driver management service makes a prediction, this prediction is broadcast to
    a broker? Whichever service wants data from the driver management service can
    check that broker for the most recent predicted number of drivers. Similarly,
    whenever the price optimization service makes a prediction about the surge charge
    for the next minute, this prediction is broadcast to the broker.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有一个协调数据在服务之间传递的代理，会怎么样？而不是让服务直接从彼此请求数据并创建复杂的服务间数据传递网络，每个服务只需与代理通信，如[图 3-9](#with_a_brokercomma_a_service_only_has_t)所示。例如，不是让其他服务请求驱动管理服务获取下一分钟的预测驾驶员数量，而是每当驱动管理服务做出预测时，将此预测广播给代理？希望从驱动管理服务获取数据的任何服务都可以检查代理，获取最新的预测驾驶员数量。同样，每当价格优化服务对下一分钟的高峰费用做出预测时，也会将此预测广播给代理。
- en: '![](Images/dmls_0309.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0309.png)'
- en: Figure 3-9\. With a broker, a service only has to communicate with the broker
    instead of with other services
  id: totrans-209
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-9\. 有了代理，服务只需与代理通信，而不是与其他服务通信。
- en: Technically, a database can be a broker—each service can write data to a database
    and other services that need the data can read from that database. However, as
    mentioned in the section [“Data Passing Through Databases”](#data_passing_through_databases),
    reading and writing from databases are too slow for applications with strict latency
    requirements. Instead of using databases to broker data, we use in-memory storage
    to broker data. Real-time transports can be thought of as in-memory storage for
    data passing among services.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，数据库可以是代理——每个服务可以将数据写入数据库，需要数据的其他服务可以从该数据库读取数据。然而，如“通过数据库传递数据”一节所述，从数据库读取和写入对于具有严格延迟要求的应用程序来说太慢了。我们使用内存存储而不是数据库来代理数据。实时传输可以被看作是服务之间数据传递的内存存储。
- en: A piece of data broadcast to a real-time transport is called an event. This
    architecture is, therefore, also called *event-driven*. A real-time transport
    is sometimes called an event bus.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 广播到实时传输的一段数据称为事件。因此，这种架构也被称为*事件驱动*。实时传输有时也称为事件总线。
- en: Request-driven architecture works well for systems that rely more on logic than
    on data. Event-driven architecture works better for systems that are data-heavy.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更多依赖逻辑而不是数据的系统，请求驱动的架构效果良好。对于数据密集型系统，事件驱动的架构更加合适。
- en: The two most common types of real-time transports are pubsub, which is short
    for publish-subscribe, and message queue. In the pubsub model, any service can
    publish to different topics in a real-time transport, and any service that subscribes
    to a topic can read all the events in that topic. The services that produce data
    don’t care about what services consume their data. Pubsub solutions often have
    a retention policy—data will be retained in the real-time transport for a certain
    period of time (e.g., seven days) before being deleted or moved to a permanent
    storage (like Amazon S3). See [Figure 3-10](#incoming_events_are_stored_in_in_memory).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 两种最常见的实时传输类型是发布订阅（pubsub）和消息队列。在发布订阅模型中，任何服务都可以发布到实时传输的不同主题，订阅主题的任何服务都可以读取该主题中的所有事件。生成数据的服务不关心哪些服务消费它们的数据。发布订阅解决方案通常有保留策略——数据将在实时传输中保留一段时间（例如七天），然后被删除或移动到永久存储（如Amazon
    S3）。参见[图 3-10](#incoming_events_are_stored_in_in_memory)。
- en: '![](Images/dmls_0310.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0310.png)'
- en: Figure 3-10\. Incoming events are stored in in-memory storage before being discarded
    or moved to more permanent storage
  id: totrans-215
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-10\. 进入的事件存储在内存存储中，然后被丢弃或移到更持久的存储中。
- en: In a message queue model, an event often has intended consumers (an event with
    intended consumers is called a message), and the message queue is responsible
    for getting the message to the right consumers.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在消息队列模型中，事件通常有预期的消费者（带有预期消费者的事件称为消息），消息队列负责将消息传递给正确的消费者。
- en: Examples of pubsub solutions are Apache Kafka and Amazon Kinesis.^([27](ch03.xhtml#ch01fn80))
    Examples of message queues are Apache RocketMQ and RabbitMQ. Both paradigms have
    gained a lot of traction in the last few years. [Figure 3-11](#companies_that_use_apache_kafka_and_rab)
    shows some of the companies that use Apache Kafka and RabbitMQ.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 发布订阅解决方案的例子有Apache Kafka和Amazon Kinesis。消息队列的例子有Apache RocketMQ和RabbitMQ。在过去几年中，这两种范式都获得了很大的关注。[图3-11](#companies_that_use_apache_kafka_and_rab)显示了一些使用Apache
    Kafka和RabbitMQ的公司。
- en: '![](Images/dmls_0311.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0311.png)'
- en: 'Figure 3-11\. Companies that use Apache Kafka and RabbitMQ. Source: Screenshot
    from [Stackshare](https://oreil.ly/OqAgL)'
  id: totrans-219
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-11. 使用Apache Kafka和RabbitMQ的公司。来源：来自[Stackshare的截图](https://oreil.ly/OqAgL)
- en: Batch Processing Versus Stream Processing
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批处理与流处理的比较
- en: Once your data arrives in data storage engines like databases, data lakes, or
    data warehouses, it becomes historical data. This is opposed to streaming data
    (data that is still streaming in). Historical data is often processed in batch
    jobs—jobs that are kicked off periodically. For example, once a day, you might
    want to kick off a batch job to compute the average surge charge for all the rides
    in the last day.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的数据到达像数据库、数据湖或数据仓库这样的数据存储引擎，它就变成了历史数据。这与流数据（仍在流动的数据）相对。历史数据通常在批处理作业中进行处理，这些作业定期启动。例如，每天一次，您可能希望启动一个批处理作业来计算最近一天内所有乘车的平均激增费用。
- en: When data is processed in batch jobs, we refer to it as *batch processing*.
    Batch processing has been a research subject for many decades, and companies have
    come up with distributed systems like MapReduce and Spark to process batch data
    efficiently.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据在批处理作业中处理时，我们称之为*批处理*。批处理已经是研究的主题已有数十年之久，公司已经提出了像MapReduce和Spark这样的分布式系统来有效处理批量数据。
- en: When you have data in real-time transports like Apache Kafka and Amazon Kinesis,
    we say that you have streaming data. *Stream processing* refers to doing computation
    on streaming data. Computation on streaming data can also be kicked off periodically,
    but the periods are usually much shorter than the periods for batch jobs (e.g.,
    every five minutes instead of every day). Computation on streaming data can also
    be kicked off whenever the need arises. For example, whenever a user requests
    a ride, you process your data stream to see what drivers are currently available.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 当你拥有像Apache Kafka和Amazon Kinesis这样的实时传输数据时，我们称之为流数据。*流处理* 指的是对流数据进行计算。流数据上的计算也可以定期启动，但这些周期通常比批处理作业的周期要短得多（例如，每五分钟而不是每天）。流数据上的计算也可以在需要时随时启动。例如，每当用户请求搭乘时，您可以处理数据流以查看当前可用的司机。
- en: Stream processing, when done right, can give low latency because you can process
    data as soon as data is generated, without having to first write it into databases.
    Many people believe that stream processing is less efficient than batch processing
    because you can’t leverage tools like MapReduce or Spark. This is not always the
    case, for two reasons. First, streaming technologies like Apache Flink are proven
    to be highly scalable and fully distributed, which means they can do computation
    in parallel. Second, the strength of stream processing is in stateful computation.
    Consider the case where you want to process user engagement during a 30-day trial.
    If you kick off this batch job every day, you’ll have to do computation over the
    last 30 days every day. With stream processing, it’s possible to continue computing
    only the new data each day and joining the new data computation with the older
    data computation, preventing redundancy.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 当正确进行流处理时，可以实现低延迟，因为您可以在生成数据后立即处理数据，而无需首先将其写入数据库。许多人认为流处理比批处理效率低，因为您不能利用像MapReduce或Spark这样的工具。但并非总是如此，原因有两点。首先，像Apache
    Flink这样的流处理技术已被证明具有高可伸缩性和完全分布式，这意味着它们可以并行进行计算。其次，流处理的优势在于状态计算。考虑这样一种情况：您希望处理30天试用期间的用户参与情况。如果每天启动这个批处理作业，您将不得不每天在过去30天内进行计算。而使用流处理，可以只计算每天的新数据，并将新数据的计算与旧数据的计算结合起来，避免冗余计算。
- en: Because batch processing happens much less frequently than stream processing,
    in ML, batch processing is usually used to compute features that change less often,
    such as drivers’ ratings (if a driver has had hundreds of rides, their rating
    is less likely to change significantly from one day to the next). *Batch features*—features
    extracted through batch processing—are also known as *static features*.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 因为批处理比流处理频率低得多，在机器学习中，通常用于计算不经常变化的特征，比如司机的评分（如果司机完成了数百次乘车，其评分不太可能在一天之内发生显著变化）。通过批处理提取的特征称为*批量特征*，也被称为*静态特征*。
- en: Stream processing is used to compute features that change quickly, such as how
    many drivers are available right now, how many rides have been requested in the
    last minute, how many rides will be finished in the next two minutes, the median
    price of the last 10 rides in this area, etc. Features about the current state
    of the system like these are important to make the optimal price predictions.
    *Streaming features*—features extracted through stream processing—are also known
    as *dynamic features*.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理用于计算变化快速的特征，例如当前有多少司机可用，过去一分钟内有多少乘车请求，接下来两分钟内会完成多少乘车，这个区域最近10次乘车的中位数价格等。这些关于系统当前状态的特征对于进行最佳价格预测非常重要。通过流处理提取的特征称为*流特征*，也被称为*动态特征*。
- en: For many problems, you need not only batch features or streaming features, but
    both. You need infrastructure that allows you to process streaming data as well
    as batch data and join them together to feed into your ML models. We’ll discuss
    more on how batch features and streaming features can be used together to generate
    predictions in [Chapter 7](ch07.xhtml#model_deployment_and_prediction_service).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多问题，您不仅需要批量特征或流特征，而是两者兼备。您需要能够处理流数据和批量数据并将它们结合起来输入到机器学习模型中的基础设施。我们将在[第7章](ch07.xhtml#model_deployment_and_prediction_service)进一步讨论如何将批处理特征和流处理特征结合使用以生成预测。
- en: To do computation on data streams, you need a stream computation engine (the
    way Spark and MapReduce are batch computation engines). For simple streaming computation,
    you might be able to get away with the built-in stream computation capacity of
    real-time transports like Apache Kafka, but Kafka stream processing is limited
    in its ability to deal with various data sources.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 要对数据流进行计算，您需要一个流计算引擎（就像 Spark 和 MapReduce 是批量计算引擎一样）。对于简单的流计算，您可能可以利用实时传输工具如
    Apache Kafka 的内置流计算能力，但是 Kafka 流处理在处理各种数据源时存在一定限制。
- en: For ML systems that leverage streaming features, the streaming computation is
    rarely simple. The number of stream features used in an application such as fraud
    detection and credit scoring can be in the hundreds, if not thousands. The stream
    feature extraction logic can require complex queries with join and aggregation
    along different dimensions. To extract these features requires efficient stream
    processing engines. For this purpose, you might want to look into tools like Apache
    Flink, KSQL, and Spark Streaming. Of these three engines, Apache Flink and KSQL
    are more recognized in the industry and provide a nice SQL abstraction for data
    scientists.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 对于利用流特征的机器学习系统，流计算很少是简单的。在应用程序中使用的流特征数量，如欺诈检测和信用评分，可能达到数百甚至数千个。流特征提取逻辑可能需要使用不同维度的联接和聚合进行复杂查询。要提取这些特征需要高效的流处理引擎。为此，您可能希望研究类似
    Apache Flink、KSQL 和 Spark Streaming 的工具。在这三个引擎中，Apache Flink 和 KSQL 在行业中更为认可，并为数据科学家提供了良好的
    SQL 抽象。
- en: Stream processing is more difficult because the data amount is unbounded and
    the data comes in at variable rates and speeds. It’s easier to make a stream processor
    do batch processing than to make a batch processor do stream processing. Apache
    Flink’s core maintainers have been arguing for years that batch processing is
    a special case of stream processing.^([28](ch03.xhtml#ch01fn81))
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理更加困难，因为数据量是无界的，数据以可变的速率和速度进入。让流处理器执行批处理比让批处理器执行流处理更容易。Apache Flink 的核心维护者多年来一直在争论批处理是流处理的一个特例。^([28](ch03.xhtml#ch01fn81))
- en: Summary
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter is built on the foundations established in [Chapter 2](ch02.xhtml#introduction_to_machine_learning_system)
    around the importance of data in developing ML systems. In this chapter, we learned
    it’s important to choose the right format to store our data to make it easier
    to use the data in the future. We discussed different data formats and the pros
    and cons of row-major versus column-major formats as well as text versus binary
    formats.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 本章建立在[第 2 章](ch02.xhtml#introduction_to_machine_learning_system)中关于数据在开发 ML
    系统中的重要性的基础上。在本章中，我们了解到选择正确的格式存储数据对将来使用数据更加容易是很重要的。我们讨论了不同的数据格式以及行优先与列优先格式以及文本与二进制格式的优缺点。
- en: 'We continued to cover three major data models: relational, document, and graph.
    Even though the relational model is the most well known given the popularity of
    SQL, all three models are widely used today, and each is good for a certain set
    of tasks.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续涵盖三种主要数据模型：关系型、文档型和图形型。尽管关系模型是最为人所知的，鉴于 SQL 的流行，但今天所有三种模型都被广泛应用，每种模型都适用于一定范围的任务。
- en: When talking about the relational model compared to the document model, many
    people think of the former as structured and the latter as unstructured. The division
    between structured and unstructured data is quite fluid—the main question is who
    has to shoulder the responsibility of assuming the structure of data. Structured
    data means that the code that writes the data has to assume the structure. Unstructured
    data means that the code that reads the data has to assume the structure.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到关系模型相对于文档模型时，许多人认为前者是结构化的，后者是非结构化的。结构化和非结构化数据之间的区分是相当模糊的——主要问题是谁必须承担假设数据结构的责任。结构化数据意味着编写数据的代码必须假设结构。非结构化数据意味着读取数据的代码必须假设结构。
- en: 'We continued the chapter with data storage engines and processing. We studied
    databases optimized for two distinct types of data processing: transactional processing
    and analytical processing. We studied data storage engines and processing together
    because traditionally storage is coupled with processing: transactional databases
    for transactional processing and analytical databases for analytical processing.
    However, in recent years, many vendors have worked on decoupling storage and processing.
    Today, we have transactional databases that can handle analytical queries and
    analytical databases that can handle transactional queries.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续本章讨论数据存储引擎和处理。我们研究了针对两种不同类型数据处理进行优化的数据库：事务处理和分析处理。我们一起研究了数据存储引擎和处理，因为传统上存储与处理是耦合在一起的：用于事务处理的事务性数据库和用于分析处理的分析数据库。然而，在近年来，许多供应商已经致力于解耦存储和处理。今天，我们有能够处理分析查询的事务性数据库以及能够处理事务查询的分析数据库。
- en: When discussing data formats, data models, data storage engines, and processing,
    data is assumed to be within a process. However, while working in production,
    you’ll likely work with multiple processes, and you’ll likely need to transfer
    data between them. We discussed three modes of data passing. The simplest mode
    is passing through databases. The most popular mode of data passing for processes
    is data passing through services. In this mode, a process is exposed as a service
    that another process can send requests for data. This mode of data passing is
    tightly coupled with microservice architectures, where each component of an application
    is set up as a service.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 当讨论数据格式、数据模型、数据存储引擎和处理时，假定数据在一个过程中。然而，在生产中工作时，您可能会与多个进程一起工作，并且可能需要在它们之间传输数据。我们讨论了三种数据传递模式。最简单的模式是通过数据库传递。用于进程的数据传递最流行的模式是通过服务传递数据。在这种模式中，一个进程被公开为另一个进程可以请求数据的服务。这种数据传递模式与微服务架构紧密耦合，其中应用程序的每个组件都设置为一个服务。
- en: 'A mode of data passing that has become increasingly popular over the last decade
    is data passing through a real-time transport like Apache Kafka and RabbitMQ.
    This mode of data passing is somewhere between passing through databases and passing
    through services: it allows for asynchronous data passing with reasonably low
    latency.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 过去十年中变得越来越流行的一种数据传递模式是通过类似 Apache Kafka 和 RabbitMQ 的实时传输传递数据。这种数据传递模式介于通过数据库传递和通过服务传递之间：它允许异步数据传递，延迟相当低。
- en: As data in real-time transports have different properties from data in databases,
    they require different processing techniques, as discussed in the section [“Batch
    Processing Versus Stream Processing”](#batch_processing_versus_stream_processi).
    Data in databases is often processed in batch jobs and produces static features,
    whereas data in real-time transports is often processed using stream computation
    engines and produces dynamic features. Some people argue that batch processing
    is a special case of stream processing, and stream computation engines can be
    used to unify both processing pipelines.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 由于实时传输中的数据与数据库中的数据具有不同的属性，它们需要不同的处理技术，如在“批处理与流处理对比”章节讨论的那样。数据库中的数据通常通过批处理作业处理并生成静态特征，而实时传输中的数据通常使用流计算引擎处理并生成动态特征。有人认为批处理是流处理的一个特例，流计算引擎可以统一这两种处理流水线。
- en: Once we have our data systems figured out, we can collect data and create training
    data, which will be the focus of the next chapter.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们解决了我们的数据系统问题，我们就可以收集数据并创建训练数据，这将是下一章的重点。
- en: ^([1](ch03.xhtml#ch01fn57-marker)) “Interesting” in production usually means
    catastrophic, such as a crash or when your cloud bill hits an astronomical amount.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.xhtml#ch01fn57-marker)) “在生产环境中‘有趣’通常意味着灾难性的事情，比如崩溃或者你的云账单飙升到天文数字。”
- en: ^([2](ch03.xhtml#ch01fn58-marker)) As of November 2021, AWS S3 Standard, the
    storage option that allows you to access your data with the latency of milliseconds,
    costs about five times more per GB than S3 Glacier, the storage option that allows
    you to retrieve your data with a latency from between 1 minute to 12 hours.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch03.xhtml#ch01fn58-marker)) 截至2021年11月，AWS S3标准存储选项允许您在毫秒级的延迟内访问数据，每GB的成本约为S3冰川的五倍，后者允许您在1分钟至12小时的延迟内检索数据。
- en: '^([3](ch03.xhtml#ch01fn59-marker)) An ML engineer once mentioned to me that
    his team only used users’ historical product browsing and purchases to make recommendations
    on what they might like to see next. I responded: “So you don’t use personal data
    at all?” He looked at me, confused. “If you meant demographic data like users’
    age, location, then no, we don’t. But I’d say that a person’s browsing and purchasing
    activities are extremely personal.”'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch03.xhtml#ch01fn59-marker)) 一位机器学习工程师曾经对我说，他的团队只使用用户的历史产品浏览和购买记录来推荐他们可能希望看到的内容。我回答道：“所以你根本不使用个人数据？”他看着我，一脸困惑。“如果你指的是用户的年龄、位置等人口统计数据，那么不，我们不使用。但我认为一个人的浏览和购买活动是非常私密的。”
- en: ^([4](ch03.xhtml#ch01fn60-marker)) John Koetsier, “Apple Just Crippled IDFA,
    Sending an $80 Billion Industry Into Upheaval,” *Forbes*, June 24, 2020, [*https://oreil.ly/rqPX9*](https://oreil.ly/rqPX9).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch03.xhtml#ch01fn60-marker)) John Koetsier，“苹果刚刚削弱了IDFA，将一个价值800亿美元的行业推向混乱”，*福布斯*，2020年6月24日，[*https://oreil.ly/rqPX9*](https://oreil.ly/rqPX9)。
- en: ^([5](ch03.xhtml#ch01fn61-marker)) Patrick McGee and Yuan Yang, “TikTok Wants
    to Keep Tracking iPhone Users with State-Backed Workaround,” *Ars Technica*, March
    16, 2021, [*https://oreil.ly/54pkg*](https://oreil.ly/54pkg).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch03.xhtml#ch01fn61-marker)) Patrick McGee和Yuan Yang，“TikTok希望通过国家支持的方法继续跟踪iPhone用户”，*Ars
    Technica*，2021年3月16日，[*https://oreil.ly/54pkg*](https://oreil.ly/54pkg)。
- en: ^([6](ch03.xhtml#ch01fn62-marker)) “Access pattern” means the pattern in which
    a system or program reads or writes data.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch03.xhtml#ch01fn62-marker)) “访问模式”指系统或程序读取或写入数据的模式。
- en: ^([7](ch03.xhtml#ch01fn63-marker)) For more pandas quirks, check out my [Just
    pandas Things](https://oreil.ly/sFkJX) GitHub repository.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch03.xhtml#ch01fn63-marker)) 欲了解更多关于pandas的特性，请查看我的[Just pandas Things](https://oreil.ly/sFkJX)
    GitHub仓库。
- en: '^([8](ch03.xhtml#ch01fn64-marker)) “Announcing Amazon Redshift Data Lake Export:
    Share Data in Apache Parquet Format,” Amazon AWS, December 3, 2019, [*https://oreil.ly/ilDb6*](https://oreil.ly/ilDb6).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch03.xhtml#ch01fn64-marker)) “宣布亚马逊Redshift数据湖导出：以Apache Parquet格式共享数据”，亚马逊AWS，2019年12月3日，[*https://oreil.ly/ilDb6*](https://oreil.ly/ilDb6)。
- en: '^([9](ch03.xhtml#ch01fn65-marker)) Edgar F. Codd, “A Relational Model of Data
    for Large Shared Data Banks,” *Communications of the ACM* 13, no. 6 (June 1970):
    377–87.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch03.xhtml#ch01fn65-marker)) Edgar F. Codd，“大型共享数据银行的数据关系模型”，*ACM通讯*，1970年6月，第13卷，第6期：377–87。
- en: ^([10](ch03.xhtml#ch01fn66-marker)) For detail-oriented readers, not all tables
    are relations.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch03.xhtml#ch01fn66-marker)) 对于注重细节的读者，不是所有的表都是关系表。
- en: ^([11](ch03.xhtml#ch01fn67-marker)) You can further normalize the Book relation,
    such as separating format into a separate relation.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch03.xhtml#ch01fn67-marker)) 您可以进一步将书籍关系进行归一化，例如将格式分离到一个单独的关系中。
- en: ^([12](ch03.xhtml#ch01fn68-marker)) Greg Kemnitz, a coauthor of the original
    Postgres paper, [shared on Quora](https://oreil.ly/W0gQa) that he once wrote a
    reporting SQL query that was 700 lines long and visited 27 different tables in
    lookups or joins. The query had about 1,000 lines of comments to help him remember
    what he was doing. It took him three days to compose, debug, and tune.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch03.xhtml#ch01fn68-marker)) 原Postgres论文的合著者Greg Kemnitz在[Quora分享](https://oreil.ly/W0gQa)，曾经写过一个包含700行的报告SQL查询，涉及27个不同表的查找或连接。该查询有大约1,000行的注释，帮助他记住自己的操作。他花了三天时间来撰写、调试和优化这个查询。
- en: '^([13](ch03.xhtml#ch01fn69-marker)) Yannis E. Ioannidis, “Query Optimization,”
    *ACM Computing Surveys* (CSUR) 28, no. 1 (1996): 121–23, [*https://oreil.ly/omXMg*](https://oreil.ly/omXMg)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch03.xhtml#ch01fn69-marker)) Yannis E. Ioannidis, “查询优化,” *ACM Computing
    Surveys*（CSUR）28卷1期（1996年）：121-23，[https://oreil.ly/omXMg](https://oreil.ly/omXMg)。
- en: '^([14](ch03.xhtml#ch01fn70-marker)) Ryan Marcus et al., “Neo: A Learned Query
    Optimizer,” *arXiv* preprint arXiv:1904.03711 (2019), [*https://oreil.ly/wHy6p*](https://oreil.ly/wHy6p).'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch03.xhtml#ch01fn70-marker)) Ryan Marcus等，“Neo：一个学习的查询优化器,” *arXiv*预印本arXiv:1904.03711（2019年），[https://oreil.ly/wHy6p](https://oreil.ly/wHy6p)。
- en: ^([15](ch03.xhtml#ch01fn71-marker)) Matthias Boehm, Alexandre V. Evfimievski,
    Niketan Pansare, and Berthold Reinwald, “Declarative Machine Learning—A Classification
    of Basic Properties and Types,” *arXiv*, May 19, 2016, [*https://oreil.ly/OvW07*](https://oreil.ly/OvW07).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch03.xhtml#ch01fn71-marker)) Matthias Boehm, Alexandre V. Evfimievski,
    Niketan Pansare, 和 Berthold Reinwald, “声明式机器学习——基本属性和类型分类,” *arXiv*, 2016年5月19日，[https://oreil.ly/OvW07](https://oreil.ly/OvW07)。
- en: ^([16](ch03.xhtml#ch01fn72-marker)) James Phillips, “Surprises in Our NoSQL
    Adoption Survey,” *Couchbase*, December 16, 2014, [*https://oreil.ly/ueyEX*](https://oreil.ly/ueyEX).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch03.xhtml#ch01fn72-marker)) James Phillips, “我们NoSQL采用调查中的惊喜,” *Couchbase*,
    2014年12月16日，[https://oreil.ly/ueyEX](https://oreil.ly/ueyEX)。
- en: '^([17](ch03.xhtml#ch01fn73-marker)) Martin Kleppmann, [*Designing Data-Intensive
    Applications*](https://oreil.ly/fniWG) (Sebastopol, CA: O’Reilly, 2017).'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '^([17](ch03.xhtml#ch01fn73-marker)) Martin Kleppmann，《设计数据密集型应用》（[https://oreil.ly/fniWG](https://oreil.ly/fniWG)）（Sebastopol,
    CA: O’Reilly, 2017）。'
- en: ^([18](ch03.xhtml#ch01fn74-marker)) In this specific example, replacing the
    null age values with –1 solved the problem.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch03.xhtml#ch01fn74-marker)) 在这个具体的例子中，用-1替换空年龄值解决了问题。
- en: ^([19](ch03.xhtml#ch01fn75-marker)) This paragraph, as well as many parts of
    this chapter, is inspired by Martin Kleppmann’s [*Designing Data-Intensive Applications*](https://oreil.ly/f9C48).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch03.xhtml#ch01fn75-marker)) 本段以及本章的许多部分受Martin Kleppmann的《设计数据密集型应用》（[https://oreil.ly/f9C48](https://oreil.ly/f9C48)）启发。
- en: ^([20](ch03.xhtml#ch01fn76-marker)) Kleppmann, [*Designing Data-Intensive Applications*](https://oreil.ly/LFHN5).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](ch03.xhtml#ch01fn76-marker)) Kleppmann，《设计数据密集型应用》（[https://oreil.ly/LFHN5](https://oreil.ly/LFHN5)）。
- en: '^([21](ch03.xhtml#custom_ch3fn1-marker)) Tino Tereshko, “Separation of Storage
    and Compute in BigQuery,” Google Cloud blog, November 29, 2017, [*https://oreil.ly/utf7z*](https://oreil.ly/utf7z);
    Suresh H., “Snowflake Architecture and Key Concepts: A Comprehensive Guide,” Hevo
    blog, January 18, 2019, [*https://oreil.ly/GyvKl*](https://oreil.ly/GyvKl); Preetam
    Kumar, “Cutting the Cord: Separating Data from Compute in Your Data Lake with
    Object Storage,” IBM blog, September 21, 2017, [*https://oreil.ly/Nd3xD*](https://oreil.ly/Nd3xD);
    “The Power of Separating Cloud Compute and Cloud Storage,” Teradata, last accessed
    April 2022, [*https://oreil.ly/f82gP*](https://oreil.ly/f82gP).'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch03.xhtml#custom_ch3fn1-marker)) Tino Tereshko, “在BigQuery中分离存储和计算,”
    Google Cloud博客，2017年11月29日，[https://oreil.ly/utf7z](https://oreil.ly/utf7z)；Suresh
    H., “Snowflake架构与关键概念：一份全面的指南,” Hevo博客，2019年1月18日，[https://oreil.ly/GyvKl](https://oreil.ly/GyvKl)；Preetam
    Kumar, “切断电缆：使用对象存储在数据湖中分离数据与计算,” IBM博客，2017年9月21日，[https://oreil.ly/Nd3xD](https://oreil.ly/Nd3xD)；“分离云计算和云存储的威力,”
    Teradata，最后访问于2022年4月，[https://oreil.ly/f82gP](https://oreil.ly/f82gP)。
- en: ^([22](ch03.xhtml#custom_ch3fn3-marker)) Wikipedia, s.v. “Nearline storage,”
    last accessed April 2022, [*https://oreil.ly/OCmiB*](https://oreil.ly/OCmiB).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch03.xhtml#custom_ch3fn3-marker)) Wikipedia, s.v. “Nearline storage,”
    最后访问于2022年4月，[https://oreil.ly/OCmiB](https://oreil.ly/OCmiB)。
- en: ^([23](ch03.xhtml#ch01fn77-marker)) In the first draft of this book, I had cost
    as a reason why you shouldn’t store everything. However, as of today, storage
    has become so cheap that the storage cost is rarely a problem.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](ch03.xhtml#ch01fn77-marker)) 在本书的初稿中，我将成本作为不应存储所有内容的原因。然而，如今存储成本如此低廉，以至于存储成本很少是一个问题。
- en: ^([24](ch03.xhtml#ch01fn78-marker)) In practice, the price optimization might
    not have to request the predicted number of rides/drivers every time it has to
    make a price prediction. It’s a common practice to use the cached predicted number
    of rides/drivers and request new predictions every minute or so.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](ch03.xhtml#ch01fn78-marker)) 实际上，价格优化可能不需要每次都请求预测的乘车次数/司机数量来进行价格预测。使用缓存的预测乘车次数/司机数量并每分钟或更频繁地请求新的预测是常见做法。
- en: ^([25](ch03.xhtml#ch01fn79-marker)) Kleppmann, [*Designing Data-Intensive Applications*](https://oreil.ly/LFHN5).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ^([25](ch03.xhtml#ch01fn79-marker)) Kleppmann，《*设计数据密集型应用*》（[链接](https://oreil.ly/LFHN5)）。
- en: ^([26](ch03.xhtml#custom_ch3fn4-marker)) Tyson Trautmann, “Debunking the Myths
    of RPC and REST,” *Ethereal Bits*, December 4, 2012 (accessed via the Internet
    Archive), [*https://oreil.ly/4sUrL*](https://oreil.ly/4sUrL).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ^([26](ch03.xhtml#custom_ch3fn4-marker)) Tyson Trautmann，《“揭秘RPC和REST的神话”》，*Ethereal
    Bits*，2012年12月4日（通过互联网档案馆访问），[链接](https://oreil.ly/4sUrL)。
- en: ^([27](ch03.xhtml#ch01fn80-marker)) If you want to learn more about how Apache
    Kafka works, Mitch Seymour has a great [animation](https://oreil.ly/kBZzU) to
    explain it using otters!
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ^([27](ch03.xhtml#ch01fn80-marker)) 如果你想了解更多关于Apache Kafka如何工作的信息，Mitch Seymour有一个很棒的[动画](https://oreil.ly/kBZzU)，用水獭来解释它！
- en: ^([28](ch03.xhtml#ch01fn81-marker)) Kostas Tzoumas, “Batch Is a Special Case
    of Streaming,” *Ververica*, September 15, 2015, [*https://oreil.ly/IcIl2*](https://oreil.ly/IcIl2).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ^([28](ch03.xhtml#ch01fn81-marker)) Kostas Tzoumas，《“批处理是流处理的一种特例”》，*Ververica*，2015年9月15日，[链接](https://oreil.ly/IcIl2)。
