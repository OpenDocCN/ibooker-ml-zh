- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序言
- en: We live in a world where machine learning (ML) systems are used in increasingly
    high-stakes domains like medicine, law, and defense. Model decisions can result
    in economic gains or losses in the millions or billions of dollars. Because of
    the high-stakes nature of their decisions and consequences, it is important for
    these ML systems to be trustworthy. This can be a problem when the ML systems
    are not secure, may fail unpredictably, have notable performance disparities across
    sample groups, and/or struggle to explain their decisions. We wrote this book
    to help your ML models stand up on their own in the real world.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生活在一个机器学习系统（ML）在医学、法律和国防等越来越重要的领域中被使用的世界。模型决策可能导致数百万甚至数十亿美元的经济收益或损失。由于其决策和后果的高风险性质，这些ML系统的可信性至关重要。当ML系统不安全、可能无法预测地失败、在样本群体中表现差异显著和/或难以解释其决策时，这可能是一个问题。我们撰写这本书是为了帮助你的ML模型在现实世界中独立立足。
- en: Implementing Machine Learning in Production
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在生产中实施机器学习
- en: If you’re reading this book, you are probably already aware of the incredibly
    outsized importance of ML. Regardless of the fields of application, ML techniques
    touch all of our lives. Google Brain cofounder Andrew Ng was not exaggerating
    when he [described AI as “the new electricity”](https://oreil.ly/p0xWy). After
    all, what we have on our hands could best be described as a universal function
    approximator. Much like electricity, ML can be dangerous if not handled properly.
    Like a discharge from a high-voltage wire colliding with a mylar balloon, cases
    of ML failure can be unexpected and scary.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在阅读这本书，你可能已经意识到ML的巨大重要性。无论应用领域如何，ML技术都影响着我们生活的方方面面。Google Brain的联合创始人Andrew
    Ng在描述AI为“新电力”时并没有夸大其词。毕竟，我们手头上的东西最好可以描述为一个通用函数逼近器。就像电力一样，如果处理不当，ML可能会很危险。就像高压线碰撞到镀铝膜气球一样，ML失败的案例可能是意外和令人恐惧的。
- en: Deploying ML applications in the real world is quite different from working
    on models in closed environments. Academic datasets often do not carry the full
    variation of real-world data. Data that our models interact with in the future
    may not resemble the data of the past, especially if someone cut corners in getting
    this data. It could include all sorts of biases that the model could learn from,
    thereby putting whoever deployed it in a hairy ethical and/or legal situation.
    The situation may be made worse by the fact that you cannot fully explain why
    your ML model is behaving the way it does. Even if all goes well on those fronts,
    you’re not out of the woods yet. Hackers are getting more sophisticated every
    year and may eventually figure out how to steal sensitive data just by querying
    your deployed model.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中部署ML应用与在封闭环境中工作模型大不相同。学术数据集通常不包含真实世界数据的全部变化。将来我们的模型互动的数据可能与过去的数据不同，特别是如果有人在获取这些数据时走捷径。这可能包含各种可能让模型学习的偏见，从而使部署它的人陷入棘手的伦理和/或法律境地。即使在这些方面一切顺利，你也不是安全的。黑客每年变得更加复杂，最终可能会找出如何通过查询你部署的模型来窃取敏感数据的方法。
- en: The prognosis isn’t all doom and gloom, though. There are well-studied best
    practices for curating datasets, both for real-world data and synthetic data.
    There are plenty of ways to measure just how different new incoming data is from
    the data you already have. Just as there are ways of spotting and fixing bias
    in ML, there are new ways of making your ML pipelines explainable and interpretable
    in general. As for security and robustness, some of the largest ML companies in
    the world are releasing tool kits for helping you obscure sensitive model details
    from nosy outsiders.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前景并非全是悲观与绝望。有许多经过深入研究的最佳实践，用于管理数据集，无论是真实世界的数据还是合成数据。有很多方法可以衡量新进数据与已有数据的差异。正如有办法发现和修复机器学习中的偏见一样，也有新的方法使你的机器学习流水线在一般情况下更易于解释和理解。至于安全性和健壮性，全球一些最大的机器学习公司正在发布工具包，帮助你隐藏敏感模型细节，避免外人窥探。
- en: All these ways of repairing the metaphorical wiring of your ML pipeline are
    discussed in this book, from classic solutions to the cutting edge.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书讨论了修复你的ML流水线象征性接线的所有方法，从经典解决方案到前沿技术。
- en: The Transformer Convergence
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变压器的收敛
- en: In the late 2010s and early 2020s, not long before we began writing this book,
    a deep learning model architecture called “transformer” had been making waves
    in the natural language processing (NLP) space. Over the course of this writing,
    the pace of transformer adoption has only accelerated. This approach is quickly
    becoming a standard tool in computer vision, tabular data processing, and even
    reinforcement learning. It’s a huge departure from how deep learning worked in
    the early 2010s, when each task and domain had such unique and distinct architectures
    that it was hard for a computer vision expert to fully understand NLP research
    (and it was often difficult for NLP researchers to understand computer vision
    methods in meaningful depth as well).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始写作这本书的不久之前，即在2010年末和2020年初，一个名为“变压器”的深度学习模型架构已经在自然语言处理（NLP）领域引起轰动。随着时间推移，变压器的采用速度只有加快。这种方法迅速成为计算机视觉、表格数据处理甚至强化学习的标准工具。这与2010年代初期的深度学习工作方式有了巨大的不同，当时每个任务和领域都有独特和明确的架构，这使得计算机视觉专家很难完全理解NLP研究（同样，NLP研究人员也很难深入理解计算机视觉方法）。
- en: The transformer is an ML architecture that first appeared in the 2017 paper
    “Attention Is All You Need.”^([1](preface01.html#idm45621850012944)) In previous
    neural network approaches, such as convolutional neural networks (CNNs) and recurrent
    neural networks (RNNs), the system would first focus on local patches of input
    data and then build up to the whole. By contrast, with a transformer model, every
    element of the input data connects (or pays attention to) every other element.
    This approach means that the transformer can make sense of the entire dataset
    it’s trained on.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器是一种机器学习架构，最早出现在2017年的论文“Attention Is All You Need”中。^([1](preface01.html#idm45621850012944))
    在以往的神经网络方法中，如卷积神经网络（CNN）和循环神经网络（RNN），系统首先集中在输入数据的局部区域，然后才逐步扩展到整体。相比之下，使用变压器模型，输入数据的每个元素都与其他每个元素连接（或者关注）。这种方法意味着变压器可以理解其训练的整个数据集。
- en: This ability to make connections between data points across an entire dataset
    is key to the transformer’s usefulness. Transformer models have become front-runners
    on tasks such as question answering, text prediction, and translation. More recently,
    this has extended beyond NLP to vision domains like image classification.^([2](preface01.html#idm45621850812160))
    This convergence around transformers is a recent phenomenon, but it’s clear that
    it will continue to grow into the future.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器能够在整个数据集中的数据点之间建立连接，这是其有用性的关键。变压器模型已经成为诸如问答、文本预测和翻译等任务的领先者。最近，这种应用已经扩展到超越自然语言处理的视觉领域，如图像分类。^([2](preface01.html#idm45621850812160))
    变压器在这些领域的普及是最近的现象，但很明显，它将在未来继续发展。
- en: While transformers should not be used for every single problem (for example,
    there are plenty of circumstances where less computational- and memory-intensive
    methods work best), we make transformer-based models a focus of this book given
    the recent trend in this area.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管变压器不适用于每一个问题（例如，许多情况下，计算和内存消耗较少的方法效果最佳），但鉴于这一领域的最新趋势，我们把基于变压器的模型作为本书的重点。
- en: An Explosion of Large and Highly Capable ML Models
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大规模且高能力的机器学习模型的爆发
- en: Not only have transformers become ubiquitous, but they’ve also been used to
    put into the hands of many people AI systems whose capabilities would have seemed
    like science fiction just a decade ago. In 2019, OpenAI released GPT-3, a language
    model that can generate text that is in many cases indistinguishable from human-written
    text. Even as companies are building their products around these models,^([3](preface01.html#idm45621850479904))
    we are still discovering new capabilities. For example, in 2022, it was discovered
    that one could greatly boost GPT-3’s performance on reasoning benchmarks like
    MultiArith (jumping from 17.7% to 78.7% accuracy) and GSM8K (jumping from 10.4%
    to 40.7% accuracy). How was this amazing leap in capability achieved? It simply
    involved prompting GPT-3 to complete an answer that was prefilled with `"Let's
    think step by step"` before each answer.^([4](preface01.html#idm45621849744880))
    The strangeness does not stop there, as this prompting can cause language models
    to output reasoning steps that may not necessarily arrive at an answer at all
    (you need further prompting and querying to get the actual answer).^([5](preface01.html#idm45621852247232))^,^([6](preface01.html#idm45621851046832))
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器已经变得无处不在，并且它们已经被用来将许多人手中的 AI 系统赋予了科幻般的能力，这在仅仅十年前似乎还是不可思议的。2019 年，OpenAI 发布了
    GPT-3，这是一个语言模型，能够生成在许多情况下与人类写作的文本难以区分的文本。即使公司们正在围绕这些模型构建他们的产品，^([3](preface01.html#idm45621850479904))
    我们仍然在发现新的能力。例如，在 2022 年，人们发现可以极大地提升 GPT-3 在像 MultiArith（从 17.7% 提升到 78.7% 准确率）和
    GSM8K（从 10.4% 提升到 40.7% 准确率）这样的推理基准上的性能。这种惊人的能力飞跃是如何实现的呢？简单地说，只需在每个答案之前预填写 `"让我们一步一步地思考"`
    的提示，就能促使 GPT-3 完成答案。^([4](preface01.html#idm45621849744880)) 但是奇怪的不仅仅在于此，因为这种提示可能导致语言模型输出的推理步骤并不一定能得出答案（你需要进一步的提示和查询才能得到实际的答案）。^([5](preface01.html#idm45621852247232))^,^([6](preface01.html#idm45621851046832))
- en: Another notable ML model that came about at the time we were writing this book
    was StableDiffusion, a text-to-image model that can generate images from text
    descriptions. It was trained in the same manner as text-to-image models like [OpenAI’s
    DALL·E 2](https://oreil.ly/DCZPc), [Google’s Imagen](https://oreil.ly/TSU2A),
    [Google’s Parti](https://oreil.ly/ZLAUJ), and [MidJourney](https://oreil.ly/LOIJO)
    and thus had roughly similar quality of output. Unlike these other models, the
    underlying code and the full model weights were released to the public. The release
    of this capable model was a big deal for the ML safety community. It went against
    the ethos of keeping highly capable ML models private until their consequences
    and safety can be evaluated. In the case of StableDiffusion, the authors released
    a variety of harm-reduction tools at the same time the highly capable model was
    released.^([7](preface01.html#idm45621849940144))^,^([8](preface01.html#idm45621850949952))
    While this best practice should be encouraged, it also highlights how underresourced
    a lot of ML safety initiatives were, even for much lower-stakes ML models and
    pipelines.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们撰写本书的同时，另一个显著的机器学习模型是 StableDiffusion，这是一个文本到图像的模型，可以根据文本描述生成图像。它是通过与文本到图像模型（如
    [OpenAI 的 DALL·E 2](https://oreil.ly/DCZPc)，[Google 的 Imagen](https://oreil.ly/TSU2A)，[Google
    的 Parti](https://oreil.ly/ZLAUJ)，以及 [MidJourney](https://oreil.ly/LOIJO)）相同的方式进行训练的，因此其输出的质量大致相似。与其他模型不同的是，该模型的底层代码和完整模型权重都已公开发布。这种能力强大的模型的发布对机器学习安全社区来说是一件大事。它违背了将高能力的机器学习模型保持私密，直到评估其后果和安全性的伦理。在
    StableDiffusion 的情况下，作者们发布了多种减少伤害的工具，与发布高能力模型同时进行。^([7](preface01.html#idm45621849940144))^,^([8](preface01.html#idm45621850949952))
    虽然这种最佳实践应受到鼓励，但也突显了许多机器学习安全倡议在资源匮乏方面的问题，即使是对于风险较低的机器学习模型和流水线。
- en: After all, we’ve seen many similar new image/language models pouring out of
    competing companies and teams like Google, DeepMind, OpenAI, and Microsoft. Since
    these projects are being built in parallel, and with comparable results, the generation
    of new ideas is not a bottleneck. In some cases, it might suggest that progress
    won’t be slowed down by just one team or organization opting out, which creates
    perverse incentives. One team might decide to get ahead by not imposing limitations
    on its text or image generation tool. While teams at larger organizations have
    been slow to develop products because of these safety concerns, it’s also hard
    to stop an engineer from one of these teams from defecting to a startup that wants
    to move much faster in making a product. Since these similar projects are being
    developed in parallel, it seems secrecy no longer offers as much protection as
    it once did.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 毕竟，我们看到了许多类似的新的图像/语言模型从Google、DeepMind、OpenAI和Microsoft等竞争公司和团队中涌现出来。由于这些项目是并行构建的，并且有着可比较的结果，新思想的产生并不是瓶颈。在某些情况下，这可能意味着进展不会因为一个团队或组织选择退出而放缓，这会产生反常的激励机制。一个团队可能决定通过不对其文本或图像生成工具施加限制来取得领先优势。虽然大型组织的团队因为这些安全问题而开发产品进展缓慢，但很难阻止这些团队中的工程师加入到想要更快推进产品的初创公司中去。由于这些类似项目是并行开发的，看来保密不再像过去那样提供如此多的保护。
- en: As such, it seems like one of the most promising ways to make sure safety is
    considered is for the organizations to be as public as possible about both their
    perception of safety risks and their proposed solutions for those risks.^([9](preface01.html#idm45621851058592))
    It’s for this reason that we wrote this book.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，看起来确保安全性被考虑的最有前途的方法之一是让组织尽可能公开他们对安全风险的看法以及他们对这些风险的解决方案的建议。^([9](preface01.html#idm45621851058592))
    正是出于这个原因，我们写了这本书。
- en: Why We Wrote This Book
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么我们写这本书
- en: As people who have both conducted research in ML and worked on ML systems that
    have been successfully deployed, we’ve noticed that the gap between building an
    initial ML model for a static dataset and deployment is large. A major part of
    this gap is in lack of trustworthiness. There are so many ways in which ML models
    that work in development can fail in production. Many large companies have dedicated
    responsible AI and safety teams to analyze the potential risks and consequences
    of both their current and potential future ML systems.^([10](preface01.html#idm45621860757776))
    Unfortunately, the vast majority of teams and companies using ML do not have the
    bandwidth to do this. Even in cases where such teams exist, they are often underresourced,
    and the model development cycles may be too fast for the safety team to keep up
    with for fear that a competitor will release a similar model first.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作为既进行过ML研究又成功部署ML系统的人们，我们注意到，初步建立静态数据集的ML模型与部署之间的差距很大。这个差距的主要部分在于缺乏可信度。有很多种方式，开发中工作的ML模型在生产中可能会失败。许多大公司都有专门的负责AI和安全的团队来分析他们当前和潜在未来ML系统的潜在风险和后果。^([10](preface01.html#idm45621860757776))
    不幸的是，大多数使用ML的团队和公司没有足够的带宽来做到这一点。即使存在这样的团队，在这些团队中，它们通常都资源不足，模型开发周期可能过快，以至于安全团队担心竞争对手会先发布类似的模型。
- en: 'We wrote this book to lower the barrier to entry for understanding how to create
    ML models that are trustworthy. While a lot of titles already exist on this subject,
    we wanted to create a resource that was accessible to people without a background
    in machine learning research that teaches frameworks and ways to think about trustworthiness,
    as well as some methods to evaluate and improve the trustworthiness of models.
    This includes:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们写这本书的目的是降低理解如何创建值得信赖的ML模型的门槛。尽管已经有很多关于这个主题的标题，但我们希望创建一个对没有机器学习研究背景的人也可以理解的资源，教授框架和思考可信度的方法，以及一些评估和改进模型可信度的方法。
- en: Code blocks to copy and paste into your own projects
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以复制粘贴到你自己项目中的代码块
- en: Lists of links to open source projects and resources
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链接列表到开源项目和资源
- en: Links to in-depth code tutorials, many of which can be explored in-browser
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链接到深入的代码教程，其中许多可以在浏览器中探索
- en: While there’s no replacement for experience, in order to get experience, you
    need to know where to start in the first place. This book is meant to provide
    that much-needed foundation for releasing your machine learning applications into
    the noisy, messy, sometimes hostile real world. This work stands on the shoulders
    of countless other researchers, engineers, and more—we hope this work will help
    translate some of that work for people working to deploy ML systems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管经验是无法替代的，但为了积累经验，你需要知道从何处开始。这本书旨在为将你的机器学习应用程序发布到嘈杂、混乱、有时敌对的真实世界中提供所需的基础。这项工作依赖于无数其他研究人员、工程师等的成果，我们希望这项工作能够帮助那些致力于部署ML系统的人们翻译部分工作。
- en: Who This Book Is For
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书的目标读者
- en: This book is written for anyone who is currently working with machine learning
    models and wants to be sure that the fruits of their labor will not cause unintended
    harm when released into the real world.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本书适合所有当前使用机器学习模型并希望确保他们的劳动成果在释放到真实世界时不会造成意外伤害的人。
- en: The primary audience of the book is engineers and data scientists who have some
    familiarity with machine learning. Parts of the book should be accessible to non-engineers,
    such as product managers and executives with a conceptual understanding of ML.
    Some of you may be building ML systems that make higher-stakes decisions than
    you encountered in your previous job or in academia. We assume you are familiar
    with the very basics of deep learning and with Python for the code samples.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的主要受众是具有一定机器学习基础的工程师和数据科学家。书中的部分内容应该对非工程师也是可理解的，比如具有ML概念理解的产品经理和高管。你们中的一些人可能正在构建比之前的工作或学术中更重要决策的ML系统。我们假设你们对深度学习的基础知识和Python的代码示例有所了解。
- en: An initial reading will allow engineers to gain a solid understanding of trustworthiness
    and how it may apply to the ML systems you are using. As you continue on your
    ML career, you can refer back and adapt code snippets from the book to evaluate
    and ensure aspects of trustworthiness in your systems.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 初次阅读将使工程师对信任度有坚实的理解，并了解它如何适用于你正在使用的ML系统。随着你在ML职业生涯的继续，你可以回头并从书中调整和适应代码片段，以评估和确保你系统的信任度方面。
- en: AI Safety and Alignment
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI安全与对齐
- en: There’s a big field of study focused on the problems of AI safety and AI alignment.
    *AI alignment* is the problem of how to make AI systems that do what humans want
    without unintended side effects. This is a subset of *AI safety*, which deals
    with mitigating a far wider-reaching space of possible problems with AI systems.
    These problems range from perpetuating societal biases without possibility of
    correction, to being used by humans in domains like warfare or fraud or cybercrime,
    to exhibiting behaviors that no human of any culture or affiliation would ever
    want.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个广泛的研究领域专注于AI安全和AI对齐问题。*AI对齐* 是如何制造符合人类意愿且没有意外副作用的AI系统的问题。这是*AI安全* 的一个子集，涉及减轻AI系统可能出现的更广泛问题空间。这些问题范围从无法修正地延续社会偏见，到被人类用于战争、欺诈或网络犯罪领域，再到展现出任何文化或从属都不会希望的行为。
- en: AI alignment is seen as the *solution* to AI safety risks because it involves
    getting the AI to fully understand and reliably respect human values. There is
    truly an enormous amount of writing about trustworthy machine learning from a
    theoretical and/or academic perspective.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: AI对齐被视为解决AI安全风险的*解决方案*，因为它涉及让AI完全理解并可靠尊重人类的价值观。关于值得信赖的机器学习从理论和/或学术角度来看，有大量的文献。
- en: One problem is that a lot of this writing tries to clearly define terms from
    psychology (e.g., *intent*, *desire*, *goal*, and *motivation*) and philosophy
    (e.g., *value system* and *utility*), but few of these definitions would be useful
    to an engineer who is actually tasked with building the AI system. Humans might
    one day build an AI system that truly mimics the human brain down to the level
    of neurons and synapses, and in that scenario such philosophical and psychological
    descriptors would be useful. However, speaking from one of the authors’ prior
    experiences as a wet lab neuroscientist, modern neural networks have very little
    in common with the human brain at all. Real living neurons are not like logic
    gates, usually requiring something like 10,000 coupled and nonlinear differential
    equations to describe their behavior. Simulating a single neuron is usually a
    task for an entire dedicated artificial neural network rather than just a single
    weight and bias.^([11](preface01.html#idm45621860373872)) It’s not clear that
    we can ever arrive at a way to prove mathematically that our AI system won’t ever
    cause harm. Still, as organizations like Cohere, OpenAI, and Al21 Labs have shown,^([12](preface01.html#idm45621859749792))
    there’s still a lot that can be done to preempt common problems and institute
    best practices.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一个问题是，很多这样的文章试图清晰地定义心理学（例如，*意图*、*欲望*、*目标*和*动机*）和哲学（例如，*价值体系*和*效用*）术语，但是这些定义对于实际负责构建AI系统的工程师来说几乎没有用处。也许有一天人类会建造一个真正模拟人脑到神经元和突触水平的AI系统，在那种情况下，这些哲学和心理学描述符将会很有用。然而，从作者之一先前作为湿实验室神经科学家的经验来看，现代神经网络与人脑几乎没有什么共同之处。真实的活体神经元不像逻辑门，通常需要大约1万个耦合和非线性微分方程来描述它们的行为。模拟单个神经元通常是一个整个专用人工神经网络的任务，而不仅仅是一个单一的权重和偏差。^([11](preface01.html#idm45621860373872))我们现在还不清楚，是否能够找到一种数学上的方法来证明我们的AI系统不会对人类造成伤害。然而，正如Cohere、OpenAI和Al21
    Labs等组织所展示的，^([12](preface01.html#idm45621859749792))仍然有很多事情可以做来预防常见问题并建立最佳实践。
- en: Another challenge is that a lot of AI safety literature focuses on hypothetical
    future scenarios like artificial general intelligence (AGI) and self-improving
    AI systems.^([13](preface01.html#idm45621859746848))^,^([14](preface01.html#idm45621859744080))
    This isn’t completely removed from the real world. During the writing of this
    book, the world has seen the release of AI models like OpenAI’s DALL·E 2 (which
    can synthesize high-quality images from just a text prompt), and DeepMind’s Gato
    (a single “generalist” transformer model that can solve language tasks, vision
    tasks, and reinforcement learning tasks).^([15](preface01.html#idm45621859742336))
    In response to these releases, prediction markets updated their estimates of when
    a general AI agent could come about (like the kind predicted in AI safety literature)
    to be sooner rather than later.^([16](preface01.html#idm45621860515536)) Disastrous
    scenarios involving strong AI systems unaligned with human values are now much
    easier to imagine.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个挑战是，很多AI安全文献集中在像人工通用智能（AGI）和自我改进的AI系统这样的假设未来场景上。^([13](preface01.html#idm45621859746848))^,^([14](preface01.html#idm45621859744080))这并不完全脱离现实世界。在撰写本书期间，世界已经见证了像OpenAI的DALL·E
    2（可以仅通过文本提示合成高质量图像）和DeepMind的Gato（一个单一的“通用”转换器模型，可以解决语言任务、视觉任务和强化学习任务）这样的AI模型的发布。^([15](preface01.html#idm45621859742336))针对这些发布，预测市场更新了它们关于类似于AI安全文献中预测的通用AI代理可能出现的时间的估计，变得比以往更快。^([16](preface01.html#idm45621860515536))现在更容易想象涉及与人类价值不一致的强AI系统的灾难性场景。
- en: But AI safety is *not* something to worry about in some vague yet ominous future.
    It’s something to worry about right now. Dangers of unaligned AI systems are a
    very present threat even with less general AI systems. Threats include flash market
    crashes driven by AI trading bots,^([17](preface01.html#idm45621860512080)) repurposing
    drug discovery AI to make chemical weapons just by changing a positive sign to
    a negative sign in an algorithm,^([18](preface01.html#idm45621860504304)) and
    small combat drones with AI-enabled facial recognition capabilities that can be
    used for ethnic cleansing.^([19](preface01.html#idm45621857233904)) High-level
    philosophical arguments about the possible behavior of ultra-smart AI singletons,
    however true, will be useless without more detailed instructions on how to diagnose
    and correct problems like these.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，AI安全并不是某种模糊而不祥的未来需要担心的事情。它是当下需要担心的事情。未对齐的AI系统的危险是一个非常现实的威胁，即使是具有较少通用AI系统也是如此。威胁包括由AI交易机器人驱动的闪电市场崩盘（参见[17](preface01.html#idm45621860512080)），通过在算法中将正号改为负号来改造药物发现AI以制造化学武器（参见[18](preface01.html#idm45621860504304)），以及具有AI启用的面部识别能力的小型作战无人机可用于种族清洗（参见[19](preface01.html#idm45621857233904)）。然而，关于超智能AI单体的可能行为的高层哲学论证，尽管是真实的，但在没有更详细的指导如何诊断和纠正这些问题的情况下将是无用的。
- en: Tip
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: While it’s not clear whether the world will end in a “paperclip maximizer”–style
    event, an extreme scenario like this is a useful mental tool for remembering that
    optimization functions can turn disastrous if not monitored carefully.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管世界是否会以“纸夹子最大化器”风格的事件结束尚不清楚，但这样的极端情景对于记住优化功能如果不小心监控可能会变得灾难性是一个有用的心理工具。
- en: For an even better mental tool for evaluating AI safety claims and research,
    we recommend reading José Luis Ricón Fernández de la Puente’s [“Set Sail For Fail?
    On AI Risk”](https://oreil.ly/Li3Xm) on the Nintil blog.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更好地评估AI安全性声明和研究的心理工具，我们建议阅读José Luis Ricón Fernández de la Puente在Nintil博客上的[“Set
    Sail For Fail? On AI Risk”](https://oreil.ly/Li3Xm)。
- en: Since there is no shortage of debate on the subject, we decided to help people
    taking the engineering approach by compiling a resource full of practical tools
    and code snippets in this book. Rather than trying to craft an unambiguous definition
    of “trust,” we assume the reader knows “trust” when they see it. We focus on listing
    out some of the more common practical failure cases that would cause someone not
    to trust a machine learning system and provide some tools to help you avoid those
    pitfalls. You need practical tools for fixing arbitrary or narrow-minded AI systems
    that have been given enormous amounts of power over human lives.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于关于这一主题的辩论没有短缺，我们决定通过编制一个充满实用工具和代码片段的资源来帮助采取工程方法的人们。我们不试图制定“信任”的明确定义，而是假定读者在看到时知道“信任”。我们重点列出一些更常见的可能导致某人不信任机器学习系统的实际失败案例，并提供一些工具来帮助您避免这些陷阱。您需要修复赋予人类生活巨大权力的任意或狭隘AI系统的实用工具。
- en: The good news is that fixes for such problems often do have solutions more feasible
    than getting zero negative consequences from wishing on a monkey’s paw.^([20](preface01.html#idm45621859905440))
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 修复这类问题的好消息是，通常有解决方案，其可行性远远超过只希望猴子的手掌上不会出现任何负面后果。（参见[20](preface01.html#idm45621859905440)）
- en: Use of HuggingFace PyTorch for AI Models
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用HuggingFace PyTorch进行AI模型
- en: Throughout the code examples from the book, we make heavy use of HuggingFace’s
    Transformers library. With a few exceptions, we focus mainly on the implementations
    of these models in PyTorch. This framework, developed at Meta,^([21](preface01.html#idm45621858167120))
    operates according to many of the same mathematical principles that guide machine
    learning models written in other frameworks like TensorFlow and JAX. While code
    samples might differ for other frameworks, the underlying principles are the same.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的代码示例中，我们大量使用HuggingFace的Transformers库。除了少数例外，我们主要关注这些模型在PyTorch中的实现。这个在Meta开发的框架（参见[21](preface01.html#idm45621858167120)）根据许多与其他框架（如TensorFlow和JAX）编写的机器学习模型相同的数学原理运行。虽然其他框架的代码示例可能有所不同，但底层原理是相同的。
- en: Over the course of writing, HuggingFace has grown in popularity as a tool for
    sharing parameters for AI models. This started with language models but has extended
    to computer vision models, text-to-image models, audio models, and even reinforcement
    learning models.^([22](preface01.html#idm45621858164784))
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在写作过程中，HuggingFace作为分享AI模型参数的工具已经越来越受欢迎。这始于语言模型，但已扩展到计算机视觉模型、文本到图像模型、音频模型甚至强化学习模型（参见[22](preface01.html#idm45621858164784)）。
- en: Warning
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Always make sure that you trust the author behind whatever model you are downloading
    from HuggingFace. For some time, HuggingFace used the Python pickle module for
    downloading models. As YouTuber Yannic Kilcher explains [in his video](https://youtu.be/2ethDz9KnLk),
    just about any arbitrary executable code can be stored in a pickle file. This
    could conceivably include malicious code, as demonstrated in concept by the HuggingFace
    [totally-harmless model](https://oreil.ly/ovsWe).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 请务必信任您从 HuggingFace 下载模型的作者。有一段时间，HuggingFace 使用 Python pickle 模块下载模型。正如 YouTuber
    Yannic Kilcher 在他的视频中解释的那样，几乎任何任意可执行代码都可以存储在 pickle 文件中。这可能包括恶意代码，正如 HuggingFace
    的 [完全无害模型](https://oreil.ly/ovsWe) 概念所示。
- en: The fix for this security hole was [the torch-save patch](https://oreil.ly/ib7qu).
    Since the video’s release, HuggingFace has patched this vulnerability and added
    a warning to the site about arbitrary code execution. Always double-check that
    you trust the author of the model you are downloading.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此安全漏洞的修复是 [torch-save 补丁](https://oreil.ly/ib7qu)。自视频发布以来，HuggingFace 已修复了此漏洞，并在网站上添加了有关任意代码执行的警告。请始终仔细检查您信任的模型作者。
- en: Foundations
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础
- en: 'To assist you in getting the most from this book, here are some definitions
    of foundational terms as well as links to further information:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您从本书中获得最大收益，以下是一些基础术语的定义以及进一步信息的链接：
- en: Word embeddings
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 词嵌入
- en: Word embeddings are vector representations of words, such that one word is mapped
    to a vector that encodes its semantic meaning. Some popular embeddings include
    GloVe and Word2Vec.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 词嵌入是词的向量表示形式，使得一个词被映射到编码其语义含义的向量。一些流行的嵌入包括 GloVe 和 Word2Vec。
- en: Language models
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型
- en: Language models are models that learn to predict the probability of a token
    given a context. They can be either autoregressive models or masked language models.
    Autoregressive models take the tokens up to a particular time step as the context,
    whereas masked language models take context from both before and after the token
    that is being predicted.^([23](preface01.html#idm45621858545328))
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型是学习在给定上下文中预测令牌概率的模型。它们可以是自回归模型或掩码语言模型。自回归模型将到特定时间步的令牌作为上下文，而掩码语言模型则从正在预测的令牌之前和之后的上下文中获取信息。^([23](preface01.html#idm45621858545328))
- en: Attention
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Attention is a technique used in various machine learning models to weight how
    much of each token in a sequence to take into account in creating the embedding
    of the representation at the current step.^([24](preface01.html#idm45621856964016))
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种机器学习模型中，注意力是一种技术，用于衡量在当前步骤的表示的嵌入中考虑每个令牌的程度^([24](preface01.html#idm45621856964016))。
- en: Conventions Used in This Book
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书中使用的约定
- en: 'The following typographical conventions are used in this book:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了以下排版约定：
- en: '*Italic*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*斜体*'
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 指示新术语、URL、电子邮件地址、文件名和文件扩展名。
- en: '`Constant width`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`常量宽度`'
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 用于程序列表以及在段落内引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。
- en: '**`Constant width bold`**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**`常量宽度粗体`**'
- en: Shows commands or other text that should be typed literally by the user.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 显示用户应直接输入的命令或其他文本。
- en: '*`Constant width italic`*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*`常量宽度斜体`*'
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 显示应由用户提供的值或根据上下文确定的值替换的文本。
- en: Tip
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: This element signifies a tip or suggestion. In Chapters [7](ch07.html#chapter7)
    and [8](ch08.html#chapter8), it signifies an exercise or prompt.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示提示或建议。在第 [7](ch07.html#chapter7) 章和第 [8](ch08.html#chapter8) 章中，它表示练习或提示。
- en: Note
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This element signifies a general note.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示一般注释。
- en: Warning
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: This element indicates a warning or caution.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素指示警告或注意事项。
- en: Using Code Examples
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用代码示例
- en: Supplemental material (code examples, exercises, etc.) is available for download
    at [*https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning*](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在 [*https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning*](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning)
    下载补充材料（代码示例、练习等）。
- en: If you have a technical question or a problem using the code examples, please
    send email to [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有技术问题或在使用示例代码时遇到问题，请发送电子邮件至[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)。
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing examples
    from O’Reilly books does require permission. Answering a question by citing this
    book and quoting example code does not require permission. Incorporating a significant
    amount of example code from this book into your product’s documentation does require
    permission.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在帮助您完成工作。一般来说，如果本书提供示例代码，您可以在您的程序和文档中使用它。除非您重复使用大部分代码，否则无需获得我们的许可。例如，编写一个使用本书多个代码片段的程序不需要许可。出售或分发O’Reilly书籍中的示例代码需要许可。引用本书并引用示例代码回答问题不需要许可。将本书大量示例代码整合到您产品的文档中需要许可。
- en: 'We appreciate, but generally do not require, attribution. An attribution usually
    includes the title, author, publisher, and ISBN. For example: “*Practicing Trustworthy
    Machine Learning* by Yada Pruksachatkun, Matthew McAteer, and Subhabrata Majumdar
    (O’Reilly). Copyright 2023 Yada Pruksachatkun, Matthew McAteer, and Subhabrata
    Majumdar, 978-1-098-12027-6.”'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们赞赏，但通常不需要署名。署名通常包括标题、作者、出版商和ISBN。例如：“*《可信机器学习实践》*，作者Yada Pruksachatkun、Matthew
    McAteer和Subhabrata Majumdar（O’Reilly）。版权所有 2023 Yada Pruksachatkun、Matthew McAteer和Subhabrata
    Majumdar，978-1-098-12027-6。”
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您认为您使用的示例代码超出了公平使用或上述许可，请随时与我们联系，电子邮件至[*permissions@oreilly.com*](mailto:permissions@oreilly.com)。
- en: O’Reilly Online Learning
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O’Reilly在线学习
- en: Note
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For more than 40 years, [*O’Reilly Media*](https://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 40多年来，[*O’Reilly Media*](https://oreilly.com)已为公司提供技术和商业培训、知识和见解，帮助其取得成功。
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*https://oreilly.com*](https://oreilly.com).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们独特的专家和创新者网络通过书籍、文章和我们的在线学习平台分享他们的知识和专长。O’Reilly的在线学习平台让您随需应变地访问现场培训课程、深入学习路径、交互式编码环境，以及来自O’Reilly和其他200多家出版商的大量文本和视频。欲了解更多信息，请访问[*https://oreilly.com*](https://oreilly.com)。
- en: How to Contact Us
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何联系我们
- en: 'Please address comments and questions concerning this book to the publisher:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 请将有关本书的评论和问题寄给出版商：
- en: O’Reilly Media, Inc.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: O’Reilly Media, Inc.
- en: 1005 Gravenstein Highway North
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1005 Gravenstein Highway North
- en: Sebastopol, CA 95472
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加利福尼亚州塞巴斯托波尔市95472
- en: 800-998-9938 (in the United States or Canada)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 800-998-9938（美国或加拿大）
- en: 707-829-0515 (international or local)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0515（国际或本地）
- en: 707-829-0104 (fax)
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0104（传真）
- en: Due to the complexity of the topic of trustworthiness, while we have tried to
    include some major themes from work in this area, it is impossible to create a
    completely comprehensive resource. Additionally, due to the audience for this
    book, we’ve taken a simpler, more conversational approach to teaching the material
    than you find in academia.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 由于信任主题的复杂性，尽管我们试图包含该领域的一些主要主题，但创建一个完全全面的资源是不可能的。另外，由于本书的受众，我们采取了比学术界更简单、更对话式的教学方法。
- en: If you see factual errors in this book (or particularly glaring omissions),
    please let us know. We will not only happily correct the errors, but the first
    person to report any particular error will get mention in the acknowledgments
    of the next edition.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在本书中发现事实错误（或特别明显的遗漏），请告知我们。我们不仅会乐意纠正错误，还会在下一版的致谢中首先提到报告任何特定错误的人。
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/ptml*](https://oreil.ly/ptml).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有这本书的网页，列出勘误、示例和任何额外信息。您可以访问这个页面：[*https://oreil.ly/ptml*](https://oreil.ly/ptml)。
- en: Email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com) to comment
    or ask technical questions about this book.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 发送电子邮件至[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)，以评论或提出关于本书的技术问题。
- en: For news and information about our books and courses, visit [*https://oreilly.com*](https://oreilly.com).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们的书籍和课程的新闻和信息，请访问[*https://oreilly.com*](https://oreilly.com)。
- en: 'Find us on LinkedIn: [*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在LinkedIn上找到我们：[*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)。
- en: 'Follow us on Twitter: [*https://twitter.com/oreillymedia*](https://twitter.com/oreillymedia).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 关注我们的Twitter：[*https://twitter.com/oreillymedia*](https://twitter.com/oreillymedia)。
- en: 'Watch us on YouTube: [*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 观看我们的YouTube频道：[*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)。
- en: Acknowledgments
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to acknowledge Divesh Shrivastava, Kush Varshney, Jiahao Chen,
    Vinay Prabhu, Josh Albrecht, Kanjun Qiu, Chelsea Sierra Voss, Jwala Dhamala, Trista
    Cao, Andrew Trask, Yonah Borns-Weil, Alexander Ziller, Antonio Lopardo, Benjamin
    Szymkow, Bobby Wagner, Emma Bluemke, Jean-Mickael Nounahon, Jonathan Passerat-Palmbach,
    Kritika Prakash, Nick Rose, Théo Ryffel, Zarreen Naowal Reza, and Georgios Kaissis
    for reviewing our chapters. If you are interested in formally reviewing as well,
    please let us know!
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢Divesh Shrivastava、Kush Varshney、Jiahao Chen、Vinay Prabhu、Josh Albrecht、Kanjun
    Qiu、Chelsea Sierra Voss、Jwala Dhamala、Trista Cao、Andrew Trask、Yonah Borns-Weil、Alexander
    Ziller、Antonio Lopardo、Benjamin Szymkow、Bobby Wagner、Emma Bluemke、Jean-Mickael
    Nounahon、Jonathan Passerat-Palmbach、Kritika Prakash、Nick Rose、Théo Ryffel、Zarreen
    Naowal Reza和Georgios Kaissis，因为他们审阅了我们的章节。如果您也有兴趣进行正式审阅，请告知我们！
- en: ^([1](preface01.html#idm45621850012944-marker)) Ashish Vaswani et al., [“Attention
    Is All You Need”](https://oreil.ly/ASQqB), *NeurIPS Proceedings* (2017).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](preface01.html#idm45621850012944-marker)) 阿希什·瓦斯瓦尼等人，[“注意力机制是你所需要的一切”](https://oreil.ly/ASQqB)，*NeurIPS会议论文*
    (2017).
- en: ^([2](preface01.html#idm45621850812160-marker)) Kai Han et al., [“A Survey on
    Vision Transformer”](https://arxiv.org/abs/2012.12556), *IEEE Transactions on
    Pattern Analysis and Machine Intelligence* (2022).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](preface01.html#idm45621850812160-marker)) 韩凯等人，[“视觉Transformer综述”](https://arxiv.org/abs/2012.12556)，*IEEE模式识别与机器智能期刊*
    (2022)。
- en: ^([3](preface01.html#idm45621850479904-marker)) Matthew McAteer’s blog provides
    [examples of companies building on top of GPT-3](https://oreil.ly/OY8lh).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](preface01.html#idm45621850479904-marker)) 马修·麦克阿提尔的博客提供了[公司基于GPT-3构建的例子](https://oreil.ly/OY8lh)。
- en: ^([4](preface01.html#idm45621849744880-marker)) Takeshi Kojima et al., [“Large
    Language Models Are Zero-Shot Reasoners”](https://arxiv.org/abs/2205.11916), *arXiv
    preprint* (2022).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](preface01.html#idm45621849744880-marker)) 小岛武志等人，[“大型语言模型是零-shot推理者”](https://arxiv.org/abs/2205.11916)，*arXiv预印本*
    (2022).
- en: '^([5](preface01.html#idm45621852247232-marker)) See Antonia Creswell et al.
    (who are affiliated with DeepMind) on using prompting for interpretable composable
    reasoning: [“Selection-Inference: Exploiting Large Language Models for Interpretable
    Logical Reasoning”](https://arxiv.org/abs/2205.09712), *arXiv preprint* (2022).'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](preface01.html#idm45621852247232-marker)) 参见DeepMind附属的安东尼娅·克雷斯威尔等人，讨论使用提示进行可解释的组合推理：[“选择推理：利用大型语言模型进行可解释逻辑推理”](https://arxiv.org/abs/2205.09712)，*arXiv预印本*
    (2022).
- en: ^([6](preface01.html#idm45621851046832-marker)) This isn’t even getting into
    the possible consequences of talking about prompt engineering in a book that’s
    accessible on the internet and thus might be used as part of the training data
    in a future large language model like a GPT-3 successor.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](preface01.html#idm45621851046832-marker)) 这甚至还没有涉及到在互联网上可访问的书籍中讨论提示工程的可能后果，因此这些书籍可能会成为未来大型语言模型（如GPT-3的后继者）的训练数据的一部分。
- en: ^([7](preface01.html#idm45621849940144-marker)) See Stability.ai’s [announcement
    on Twitter](https://oreil.ly/quHFV) of their Deep Fake detection initiative using
    the new OpenCLIP models among other techniques.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](preface01.html#idm45621849940144-marker)) 参见Stability.ai关于他们的Deep Fake检测倡议的[推特公告](https://oreil.ly/quHFV)，使用了新的OpenCLIP模型等技术。
- en: ^([8](preface01.html#idm45621850949952-marker)) Beyond text-to-image models
    like StableDiffusion, other organizations are following a similar approach in
    releasing large models. Meta AI released the 175-billion parameter [Open Pretrained
    Transformer](https://oreil.ly/aqf6R), comparable in size to GPT-3, as open source.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](preface01.html#idm45621850949952-marker)) 除了类似 StableDiffusion 的文本到图像模型外，其他组织也在采用类似的方法发布大型模型。Meta
    AI 发布了与 GPT-3 规模相当的 1750 亿参数的[开源预训练 Transformer](https://oreil.ly/aqf6R)。
- en: ^([9](preface01.html#idm45621851058592-marker)) This also has the bonus effect
    of letting would-be defectors know that they are defecting, and it increases the
    reputational cost of implementing an unsafe AI system while decreasing the cost
    of reducing AI risk.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](preface01.html#idm45621851058592-marker)) 这还有一个额外的效果，让潜在的叛徒知道他们正在叛逆，增加了实施不安全
    AI 系统的声誉成本，同时减少了减少 AI 风险的成本。
- en: ^([10](preface01.html#idm45621860757776-marker)) For example, in 2021 DeepMind’s
    ethics team published the paper [“Ethical and Social Risks of Harm from Language
    Models”](https://oreil.ly/dxzTb), and OpenAI updated their [stance on AI safety
    on their blog in March 2022](https://oreil.ly/89Jqu).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](preface01.html#idm45621860757776-marker)) 例如，2021 年 DeepMind 的伦理团队发表了名为《语言模型的伦理和社会风险》的论文，而
    OpenAI 在 2022 年 3 月更新了他们关于 AI 安全的[立场](https://oreil.ly/89Jqu)。
- en: ^([11](preface01.html#idm45621860373872-marker)) Allison Whitten, [“How Computationally
    Complex Is a Single Neuron?”](https://oreil.ly/OSMJP), *Quanta Magazine*, September
    2, 2021\. This article summarizes the results of the paper by David Beniaguev
    et al., [“Single Cortical Neurons Are Deep Artificial Neural Networks”](https://oreil.ly/V3jyp),
    *Neuron* (2021).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](preface01.html#idm45621860373872-marker)) Allison Whitten，《一个神经元的计算复杂性有多高？》，《Quanta
    Magazine》，2021 年 9 月 2 日。这篇文章总结了 David Beniaguev 等人的论文《单个皮层神经元是深度人工神经网络》（2021），[链接](https://oreil.ly/OSMJP)。
- en: ^([12](preface01.html#idm45621859749792-marker)) Cohere Team, [“Best Practices
    for Deploying Language Models”](https://oreil.ly/3rFni), *co:here*, June 2, 2022.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](preface01.html#idm45621859749792-marker)) Cohere 团队，《部署语言模型的最佳实践》，《co:here》，2022
    年 6 月 2 日，[链接](https://oreil.ly/3rFni)。
- en: ^([13](preface01.html#idm45621859746848-marker)) Nick Bostrom’s [“Superintelligence”](https://oreil.ly/7OAxP)
    outlines scenarios in which such a system could emerge from any of the various
    AI research labs and then grow beyond the ability of humans to contain it.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](preface01.html#idm45621859746848-marker)) 尼克·博斯特罗姆的《超智能》描绘了这样一种情景：这样的系统可能来自任何一个各种
    AI 研究实验室，然后超出人类控制的能力，[链接](https://oreil.ly/7OAxP)。
- en: ^([14](preface01.html#idm45621859744080-marker)) Popular internet essayist Gwern
    wrote [“It Looks Like You’re Trying to Take Over the World”](https://oreil.ly/hzDHT),
    a short story designed to help readers imagine a scenario where AI research not
    too far from the current state of the art could cause a catastrophe.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](preface01.html#idm45621859744080-marker)) 受欢迎的网络散文家 Gwern 撰写了《看起来你正试图掌控世界》的[短篇小说](https://oreil.ly/hzDHT)，旨在帮助读者想象
    AI 研究在当前技术水平下可能引发灾难的情景。
- en: ^([15](preface01.html#idm45621859742336-marker)) See DeepMind’s project page
    for what they call [“A Generalist Agent”](https://oreil.ly/bczvt), including demonstrations
    and examples of the model in action.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](preface01.html#idm45621859742336-marker)) 参见 DeepMind 的项目页面，了解他们称之为《通用代理程序》的[示范和实例](https://oreil.ly/bczvt)。
- en: ^([16](preface01.html#idm45621860515536-marker)) See the Metaculus prediction
    market’s [plots of predictions over time](https://oreil.ly/k7kWZ) on questions
    related to AI.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](preface01.html#idm45621860515536-marker)) 查看 Metaculus 预测市场关于与 AI 相关问题的[预测随时间变化的图表](https://oreil.ly/k7kWZ)。
- en: ^([17](preface01.html#idm45621860512080-marker)) David Pogue, [“Algorithmic
    Trading Caused the Flash Crash”](https://oreil.ly/zEyj0), *Yahoo! Finance*, February
    6, 2018.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](preface01.html#idm45621860512080-marker)) David Pogue，《算法交易导致闪崩》，《Yahoo!
    Finance》，2018 年 2 月 6 日，[链接](https://oreil.ly/zEyj0)。
- en: ^([18](preface01.html#idm45621860504304-marker)) Justine Calma, [“AI Suggested
    40,000 New Possible Chemical Weapons in Just Six Hours”](https://oreil.ly/mJLpv),
    *The Verge*, March 17, 2022.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](preface01.html#idm45621860504304-marker)) Justine Calma，《AI 在短短六小时内建议了
    40,000 种新的可能化学武器》，《The Verge》，2022 年 3 月 17 日，[链接](https://oreil.ly/mJLpv)。
- en: ^([19](preface01.html#idm45621857233904-marker)) Stuart Russell et al., [“Why
    You Should Fear *Slaughterbots*—A Response”](https://oreil.ly/4uwnu), *IEEE Spectrum*,
    January 23, 2018.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](preface01.html#idm45621857233904-marker)) Stuart Russell 等，《为什么你应该担心
    *Slaughterbots*—一个回应》，《IEEE Spectrum》，2018 年 1 月 23 日，[链接](https://oreil.ly/4uwnu)。
- en: '^([20](preface01.html#idm45621859905440-marker)) See, for example, this explanation
    of the stock exchange that intentionally slows down trades with 38 miles of fiber
    optic cable: Tom Scott, [“How to Slow Down a Stock Exchange”](https://youtu.be/d8BcCLLX4N4),
    video, February 4, 2019.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](preface01.html#idm45621859905440-marker)) 参见此解释，关于故意用38英里的光纤电缆减慢交易速度的股票交易所：Tom
    Scott，《[如何减缓股票交易所](https://youtu.be/d8BcCLLX4N4)》，视频，2019年2月4日。
- en: '^([21](preface01.html#idm45621858167120-marker)) Meta announced that PyTorch
    would move to the independent PyTorch Foundation (incubated by the Linux Foundation):
    [“Announcing the PyTorch Foundation: A New Era for the Cutting-Edge AI Framework”](https://oreil.ly/0t10a),
    September 12, 2022.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](preface01.html#idm45621858167120-marker)) Meta宣布PyTorch将移交给独立的PyTorch基金会（由Linux基金会孵化）：《[宣布PyTorch基金会：AI框架的新时代](https://oreil.ly/0t10a)》，2022年9月12日。
- en: '^([22](preface01.html#idm45621858164784-marker)) For more information, see
    this announcement of the integration of Stable-Baselines3, the most popular Deep
    Reinforcement Learning library, with the HuggingFace Hub: [“Welcome Stable-baselines3
    to the Hugging Face Hub”](https://oreil.ly/eigfk), January 21, 2022.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](preface01.html#idm45621858164784-marker)) 欲了解更多信息，请参阅Stable-Baselines3，最受欢迎的深度强化学习库，与HuggingFace
    Hub集成的公告：《[欢迎Stable-baselines3加入Hugging Face Hub](https://oreil.ly/eigfk)》，2022年1月21日。
- en: ^([23](preface01.html#idm45621858545328-marker)) For more information on the
    various types of NLP language models you can find, see Devyanshu Shukla, [“A Quick
    Introduction to Language Models in Natural Language Processing”](https://oreil.ly/KNmLp),
    *Medium* (blog), March 16, 2020.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](preface01.html#idm45621858545328-marker)) 欲了解更多关于各种类型的NLP语言模型，详见Devyanshu
    Shukla，《[自然语言处理中的语言模型简介](https://oreil.ly/KNmLp)》，*Medium*（博客），2020年3月16日。
- en: ^([24](preface01.html#idm45621856964016-marker)) Lilian Weng, [“Attention? Attention!”](https://oreil.ly/ZB0n5),
    *Lil’Log* (blog) June 24, 2018.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](preface01.html#idm45621856964016-marker)) Lilian Weng，《[关注？注意！](https://oreil.ly/ZB0n5)》，*Lil’Log*（博客），2018年6月24日。
