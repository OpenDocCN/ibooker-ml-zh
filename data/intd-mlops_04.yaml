- en: Chapter 3\. Key MLOps Features
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章。MLOps的关键特性
- en: Mark Treveil
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Mark Treveil
- en: MLOps affects many different roles across the organization and, in turn, many
    parts of the machine learning life cycle. This chapter introduces the five key
    components of MLOps (development, deployment, monitoring, iteration, and governance)
    at a high level as a foundation for Chapters [4](ch04.html#developing_models)
    through [8](ch08.html#model_governance), which delve into the more technical details
    and requirements of these components.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps 影响组织中许多不同的角色，反过来又影响机器学习生命周期的许多部分。本章以高层次介绍MLOps的五个关键组成部分（开发、部署、监控、迭代和治理），作为第4章至第8章的基础，这些章节深入探讨了这些组成部分的技术细节和要求。
- en: A Primer on Machine Learning
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习入门
- en: To understand the key features of MLOps, it’s essential first to understand
    how machine learning works and be intimately familiar with its specificities.
    Though often overlooked in its role as a part of MLOps, ultimately algorithm selection
    (or how machine learning models are built) can have a direct impact on MLOps processes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解MLOps的关键特性，首先必须了解机器学习的工作原理，并熟悉其特定性。尽管作为MLOps的一部分经常被忽视，但算法选择（或者说机器学习模型的构建方式）最终可以直接影响MLOps的流程。
- en: At its core, machine learning is the science of computer algorithms that automatically
    learn and improve from experience rather than being explicitly programmed. The
    algorithms analyze sample data, known as training data, to build a software model
    that can make predictions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的核心是计算机算法的科学，这些算法能够从经验中自动学习和改进，而不是被明确地程序化。这些算法分析样本数据（称为训练数据），构建能够进行预测的软件模型。
- en: For example, an image recognition model might be able to identify the type of
    electricity meter from a photograph by searching for key patterns in the image
    that distinguish each type of meter. Another example is an insurance recommender
    model, which might suggest additional insurance products that a specific existing
    customer is most likely to buy based on the previous behavior of similar customers.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，图像识别模型可以通过搜索图像中区分每种电表的关键模式来识别电表类型。另一个例子是保险推荐模型，它可能根据类似客户的先前行为，建议现有特定客户最有可能购买的附加保险产品。
- en: When faced with unseen data, be it a photo or a customer, the ML model uses
    what it has learned from previous data to make the best prediction it can based
    on the assumption that the unseen data is somehow related to the previous data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 面对未见数据，无论是照片还是客户，ML模型利用其从先前数据学到的知识进行预测，假设未见数据与先前数据有某种关联，以此做出最佳预测。
- en: ML algorithms use a wide range of mathematical techniques, and the models can
    take many different forms, from simple decision trees to logistic regression algorithms
    to much more complex deep learning models (see [“What Is a Machine Learning Model?”](ch04.html#what_is_a_machine_learning_modelquestio)
    for details).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ML算法使用各种数学技术，模型可以采用多种不同的形式，从简单的决策树到逻辑回归算法，再到更复杂的深度学习模型（详情见[“什么是机器学习模型？”](ch04.html#what_is_a_machine_learning_modelquestio)）。
- en: Model Development
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型开发
- en: Let’s take a deeper look into ML model development as a whole for an even more
    complete understanding of its components, all of which can have an impact on MLOps
    after deployment.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地了解整个ML模型开发过程，以便更全面地理解其各个组成部分，所有这些部分在部署后都可能对MLOps产生影响。
- en: Establishing Business Objectives
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建立业务目标
- en: The process of developing a machine learning model typically starts with a business
    objective, which can be as simple as reducing fraudulent transactions to < 0.1%
    or having the ability to identify people’s faces on their social media photos.
    Business objectives naturally come with performance targets, technical infrastructure
    requirements, and cost constraints; all of these factors can be captured as key
    performance indicators, or KPIs, which will ultimately enable the business performance
    of models in production to be monitored.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 开发机器学习模型的过程通常从业务目标开始，可以简单到将欺诈交易降低到小于0.1%，或者具备识别社交媒体照片上人物面部的能力。业务目标自然伴随着性能目标、技术基础设施要求和成本约束；所有这些因素都可以作为关键绩效指标（KPI），最终能够监控在生产中模型的业务表现。
- en: It’s important to recognize that ML projects don’t happen in a vacuum. They
    are generally part of a larger project that in turn impacts technologies, processes,
    and people. That means part of establishing objectives also includes change management,
    which may even provide some guidance for how the ML model should be built. For
    example, the required degree of transparency will strongly influence the choice
    of algorithms and may drive the need to provide explanations together with predictions
    so that predictions are turned into valuable decisions at the business level.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要认识到，机器学习项目不是孤立进行的。它们通常是更大项目的一部分，反过来又影响技术、流程和人员。这意味着建立目标的一部分还包括变更管理，这甚至可能为如何构建机器学习模型提供一些指导。例如，所需的透明度程度将强烈影响算法选择，并可能推动提供预测及解释的需要，以便将预测转化为业务层面的有价值决策。
- en: Data Sources and Exploratory Data Analysis
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据来源与探索性数据分析
- en: With clear business objectives defined, it is time to bring together subject
    matter experts and data scientists to begin the journey of developing the ML model.
    This starts with the search for suitable input data. Finding data sounds simple,
    but in practice, it can be the most arduous part of the journey.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在明确业务目标的情况下，是时候邀请领域专家和数据科学家一起开始开发机器学习模型的旅程了。这从寻找合适的输入数据开始。寻找数据听起来简单，但在实践中，这可能是旅程中最艰难的部分。
- en: 'Key questions for finding data to build ML models include:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找构建机器学习模型所需数据的关键问题包括：
- en: What relevant datasets are available?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有哪些相关数据集可用？
- en: Is this data sufficiently accurate and reliable?
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些数据是否足够准确可靠？
- en: How can stakeholders get access to this data?
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利益相关者如何获取这些数据？
- en: What data properties (known as *features*) can be made available by combining
    multiple sources of data?
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过结合多个数据源，可以获取哪些数据属性（称为*特征*）？
- en: Will this data be available in real time?
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些数据是否可以实时获取？
- en: Is there a need to label some of the data with the “ground truth” that is to
    be predicted, or does unsupervised learning make sense? If so, how much will this
    cost in terms of time and resources?
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否需要使用“地面真实性”标记一些数据，或者无监督学习是否合理？如果是，这将在时间和资源方面造成多大成本？
- en: What platform should be used?
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该使用什么平台？
- en: How will data be updated once the model is deployed?
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型部署后数据如何更新？
- en: Will the use of the model itself reduce the representativeness of the data?
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型本身的使用是否会降低数据的代表性？
- en: How will the KPIs, which were established along with the business objectives,
    be measured?
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与业务目标一起建立的关键绩效指标（KPI），如何进行度量？
- en: 'The constraints of data governance bring even more questions, including:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据治理的限制带来了更多问题，包括：
- en: Can the selected datasets be used for this purpose?
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选定的数据集能否用于此目的？
- en: What are the terms of use?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用条款是什么？
- en: Is there personally identifiable information (PII) that must be redacted or
    anonymized?
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有必要对必须被删除或匿名化的个人身份信息（PII）进行处理？
- en: Are there features, such as gender, that legally cannot be used in this business
    context?
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有法律上不能在此业务背景下使用的特征，比如性别？
- en: Are minority populations sufficiently well represented that the model has equivalent
    performances on each group?
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 少数族群的代表性是否足够，使模型在每个群体上表现等效？
- en: Since data is the essential ingredient to power ML algorithms, it always helps
    to build an understanding of the patterns in data before attempting to train models.
    Exploratory data analysis (EDA) techniques can help build hypotheses about the
    data, identify data cleaning requirements, and inform the process of selecting
    potentially significant features. EDA can be carried out visually for intuitive
    insight and statistically if more rigor is required.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据是驱动机器学习算法的基本成分，因此在尝试训练模型之前，建立对数据模式的理解总是有帮助的。探索性数据分析（EDA）技术可以帮助建立关于数据的假设，识别数据清理需求，并指导选择可能重要的特征的过程。EDA可以通过可视化进行直观洞察，如果需要更严谨，则可以进行统计分析。
- en: Feature Engineering and Selection
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程与选择
- en: EDA leads naturally into feature engineering and feature selection. Feature
    engineering is the process of taking raw data from the selected datasets and transforming
    it into “features” that better represent the underlying problem to be solved.
    “Features” are arrays of numbers of fixed size, as it is the only object that
    ML algorithms understand. Feature engineering includes data cleansing, which can
    represent the largest part of an ML project in terms of time spent. For details,
    see [“Feature Engineering and Selection”](ch04.html#feature_engineering_and_selectio).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: EDA自然地引导到特征工程和特征选择。特征工程是将来自选定数据集的原始数据转化为更好地代表待解决问题的“特征”的过程。“特征”是固定大小的数字数组，因为这是ML算法唯一理解的对象。特征工程包括数据清洗，这可能是ML项目中时间消耗最大的部分。详情请参阅[“特征工程与选择”](ch04.html#feature_engineering_and_selectio)。
- en: Training and Evaluation
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练与评估
- en: After data preparation by way of feature engineering and selection, the next
    step is training. The process of training and optimizing a new ML model is iterative;
    several algorithms may be tested, features can be automatically generated, feature
    selections may be adapted, and algorithm hyperparameters tuned. In addition to—or
    in many cases because of—its iterative nature, training is also the most intensive
    step of the ML model life cycle when it comes to computing power.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在通过特征工程和选择准备数据之后，下一步是训练。训练和优化新的ML模型的过程是迭代的；可以测试多种算法，可以自动生成特征，可以调整特征选择，可以调整算法超参数。除了或者说正是因为其迭代的性质，训练也是ML模型生命周期中在计算能力方面最为密集的步骤。
- en: Keeping track of the results of each experiment when iterating becomes complex
    quickly. Nothing is more frustrating to data scientists than not being able to
    re-create the best results because they cannot remember the precise configuration.
    An experiment tracking tool can greatly simplify the process of remembering the
    data, the features selection, and model parameters alongside the performance metrics.
    These enable experiments to be compared side-by-side, highlighting the differences
    in performance.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在迭代过程中跟踪每个实验的结果变得非常复杂。对数据科学家来说，没有能力重新创建最佳结果是非常令人沮丧的，因为他们无法记住精确的配置。实验跟踪工具可以极大简化记忆数据、特征选择和模型参数以及性能指标的过程。这些使得可以并列比较实验，突显性能上的差异。
- en: Deciding what is the best solution requires both quantitative criteria, such
    as accuracy or average error, and qualitative criteria regarding the explainability
    of the algorithm or its ease of deployment.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 决定最佳解决方案需要定量标准（如准确率或平均误差）和关于算法可解释性或部署易用性的定性标准。
- en: Reproducibility
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可重复性
- en: While many experiments may be short-lived, significant versions of a model need
    to be saved for possible later use. The challenge here is reproducibility, which
    is an important concept in experimental science in general. The aim in ML is to
    save enough information about the environment the model was developed in so that
    the model can be reproduced with the same results from scratch.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然许多实验可能是短暂的，但模型的重要版本需要保存以备可能的后续使用。这里的挑战是可重复性，这是实验科学中一个重要的概念。在机器学习中，目标是保存关于模型开发环境的足够信息，以便可以从头开始复制模型并得到相同的结果。
- en: Without reproducibility, data scientists have little chance of being able to
    confidently iterate on models, and worse, they are unlikely to be able to hand
    over the model to DevOps to see if what was created in the lab can be faithfully
    reproduced in production. True reproducibility requires version control of all
    the assets and parameters involved, including the data used to train and evaluate
    the model, as well as a record of the software environment (see [“Version Management
    and Reproducibility”](ch04.html#version_management_and_reproducibility) for details).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 没有可重复性，数据科学家很难自信地迭代模型，更糟糕的是，他们不太可能将模型交给DevOps，看看实验室中创建的内容是否能够在生产中忠实地复制。真正的可重复性需要对所有涉及的资产和参数进行版本控制，包括用于训练和评估模型的数据，以及软件环境的记录（详见[“版本管理与可重复性”](ch04.html#version_management_and_reproducibility)）。
- en: Responsible AI
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负责任的AI
- en: Being able to reproduce the model is only part of the operationalization challenge;
    the DevOps team also needs to understand how to verify the model (i.e., what does
    the model do, how should it be tested, and what are the expected results?). Those
    in highly regulated industries are likely required to document even more detail,
    including how the model was built and how it was tuned. In critical cases, the
    model may be independently recoded and rebuilt.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 能够复现模型只是操作化挑战的一部分；DevOps团队还需要理解如何验证模型（即模型的作用是什么，如何进行测试，预期结果是什么？）。那些处于高度监管行业的人可能需要记录更多的细节，包括模型的构建过程和调优过程。在关键情况下，模型可能会被独立重新编码和重建。
- en: Documentation is still the standard  solution to this communication challenge.
    Automated model document generation, whereby a tool automatically creates documentation
    associated with any trained model, can make the task less onerous. But in almost
    all cases, some documentation will need to be written by hand to explain the choices
    made.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 文档仍然是解决这种沟通挑战的标准方案。自动化模型文档生成，即工具自动创建与任何训练模型相关的文档，可以减少工作负担。但在几乎所有情况下，仍需手工编写一些文档来解释所做的选择。
- en: It is a fundamental consequence of their statistical nature that ML models are
    challenging to understand. While model algorithms come with standard performance
    measures to assess their efficacy, these don’t explain how the predictions are
    made. The “how” is important as a way to sanity-check the model or help better
    engineer features, and it may be necessary to ensure that fairness requirements
    (e.g., around features like sex, age, or race) have been met. This is the field
    of explainability, which is connected to Responsible AI as discussed in [Chapter 1](ch01.html#why_now_and_challenges)
    and which will be discussed in further detail in [Chapter 4](ch04.html#developing_models).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型由于其统计性质的基本特性，难以理解是其一个基本结果。虽然模型算法配备了标准性能指标来评估其效果，但这些指标并不能解释预测是如何做出的。理解“如何”对于检查模型或帮助更好地设计特征非常重要，并且可能需要确保已满足公平性要求（例如性别、年龄或种族等特征）。这是解释性的领域，与负责任的人工智能（如第[1章](ch01.html#why_now_and_challenges)所讨论的那样），并将在第[4章](ch04.html#developing_models)中进一步详细讨论。
- en: 'Explainability techniques are becoming increasingly important as global concerns
    grow about the impact of unbridled AI. They offer a way to mitigate uncertainty
    and help prevent unintended consequences. The techniques most commonly used today
    include:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 随着全球对无限制AI影响的关注增加，解释性技术变得越来越重要。它们提供了减少不确定性和帮助预防意外后果的方法。目前最常用的技术包括：
- en: Partial dependence plots, which look at the marginal impact of features on the
    predicted outcome
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部分依赖图，研究特征对预测结果的边际影响。
- en: Subpopulation analyses, which look at how the model treats specific subpopulations
    and that are the basis of many fairness analyses
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 子群体分析，即分析模型如何处理特定子群体的分析，这是许多公平性分析的基础。
- en: Individual model predictions, such as [Shapley values](https://oreil.ly/OC8OK),
    which explain how the value of each feature contributes to a specific prediction
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个体模型预测，例如[Shapley值](https://oreil.ly/OC8OK)，解释每个特征值如何影响特定预测。
- en: What-if analysis, which helps the ML model user to understand the sensitivity
    of the prediction to its inputs
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设分析，帮助ML模型用户理解预测对其输入的敏感性。
- en: As we’ve seen in this section, even though model development happens very early
    on, it’s still an important place to incorporate MLOps practices. Any MLOps work
    done up front during the model development stage will make the models easier to
    manage down the line (especially when pushing to production).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本节中所见，即使模型开发非常早期，仍然是一个重要的地方来融合MLOps实践。在模型开发阶段进行的任何MLOps工作将使模型在后续更易管理（特别是推向生产时）。
- en: Productionalization and Deployment
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产化和部署
- en: Productionalizing and deploying models is a key component of MLOps that presents
    an entirely different set of technical challenges than developing the model. It
    is the domain of the software engineer and the DevOps team, and the organizational
    challenges in managing the information exchange between the data scientists and
    these teams must not be underestimated. As touched on in [Chapter 1](ch01.html#why_now_and_challenges),
    without effective collaboration between the teams, delays or failures to deploy
    are inevitable.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型推向生产并部署是MLOps的关键组成部分，它面临与开发模型完全不同的一组技术挑战。这是软件工程师和DevOps团队的领域，管理数据科学家与这些团队之间信息交流的组织挑战不容小觑。正如在[第1章](ch01.html#why_now_and_challenges)中提到的，如果团队之间缺乏有效的协作，推迟或部署失败是不可避免的。
- en: Model Deployment Types and Contents
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型部署类型和内容
- en: 'To understand what happens in these phases, it’s helpful to take a step back
    and ask: what exactly is going into production, and what does a model consist
    of? There are commonly two types of model deployment:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解这些阶段中发生了什么，有助于退后一步并问一问：究竟要投入生产的是什么，模型由什么组成？通常有两种类型的模型部署：
- en: Model-as-a-service, or live-scoring model
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 模型即服务，或实时评分模型
- en: Typically the model is deployed into a simple framework to provide a REST API
    endpoint (the means from which the API can access the resources it needs to perform
    the task) that responds to requests in real time.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通常模型会部署到一个简单的框架中，以提供REST API端点（API访问资源所需执行任务的方式），实时响应请求。
- en: Embedded model
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入式模型
- en: Here the model is packaged into an application, which is then published. A common
    example is an application that provides batch-scoring of requests.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，模型被打包成一个应用程序，然后发布。一个常见的例子是提供批处理请求的应用程序。
- en: What to-be-deployed models consist of depends, of course, on the technology
    chosen, but typically they comprise a set of code (commonly Python, R, or Java)
    and data artifacts. Any of these can have version dependencies on runtimes and
    packages that need to match in the production environment because the use of different
    versions may cause model predictions to differ.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 被部署的模型包含的内容取决于所选择的技术，但通常包括一组代码（通常是Python、R或Java）和数据工件。其中任何一个都可能对运行时和软件包有版本依赖性，需要与生产环境中匹配，因为使用不同版本可能会导致模型预测不同。
- en: 'One approach to reducing dependencies on the production environment is to export
    the model to a portable format such as PMML, PFA, ONNX, or POJO. These aim to
    improve model portability between systems and simplify deployment. However, they
    come at a cost: each format supports a limited range of algorithms, and sometimes
    the portable models behave in subtly different ways than the original. Whether
    or not to use a portable format is a choice to be made based on a thorough understanding
    of the technological and business context.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 降低对生产环境依赖的一种方法是将模型导出为便携格式，如PMML、PFA、ONNX或POJO。这些旨在提高系统间模型的可移植性并简化部署。然而，它们也带来了一些成本：每种格式只支持有限的算法范围，有时便携模型的行为与原始模型略有不同。是否使用便携格式应基于对技术和业务背景的深入理解做出选择。
- en: Model Deployment Requirements
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型部署要求
- en: 'So what about the productionalization process between completing model development
    and physically deploying into production—what needs to be addressed? One thing
    is for sure: rapid, automated deployment is always preferred to labor-intensive
    processes.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 那么在完成模型开发和物理部署之间的生产过程中，需要解决哪些问题呢？有一件事是确定的：快速、自动化的部署始终优于繁重的过程。
- en: For short-lifetime, self-service applications, there often isn’t much need to
    worry about testing and validation. If the maximum resource demands of the model
    can be securely capped by technologies such as Linux cgroups, then a fully automated
    single-step push-to-production may be entirely adequate. It is even possible to
    handle simple user interfaces with frameworks like Flask when using this lightweight
    deployment mode. Along with integrated data science and machine learning platforms,
    some business rule management systems may also allow some sort of autonomous deployment
    of basic ML models.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于短寿命周期、自助式应用，通常不需要太担心测试和验证。如果可以通过诸如Linux cgroups之类的技术安全地限制模型的最大资源需求，那么完全自动化的单步推送至生产环境可能完全足够。在使用这种轻量级部署模式时，甚至可以通过像Flask这样的框架处理简单的用户界面。除了集成数据科学和机器学习平台外，一些业务规则管理系统也可能允许基本ML模型的某种自主部署。
- en: 'In customer-facing, mission-critical use cases, a more robust CI/CD pipeline
    is required. This typically involves:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在面向客户、任务关键的使用案例中，需要一个更强大的CI/CD流水线。这通常包括：
- en: Ensuring all coding, documentation and sign-off standards have been met
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保所有编码、文档和签署标准都得到满足
- en: Re-creating the model in something approaching the production environment
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在接近生产环境中重新创建模型
- en: Revalidating the model accuracy
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新验证模型的准确性
- en: Performing explainability checks
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行可解释性检查
- en: Ensuring all governance requirements have been met
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保满足所有治理要求
- en: Checking the quality of any data artifacts
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查任何数据工件的质量
- en: Testing resource usage under load
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在负载下测试资源使用情况
- en: Embedding into a more complex application, including integration tests
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 嵌入到更复杂的应用程序中，包括集成测试
- en: In heavily regulated industries (e.g., finance and pharmaceuticals), governance
    and regulatory checks will be extensive and are likely to involve manual intervention.
    The desire in MLOps, just as in DevOps, is to automate the CI/CD pipeline as far
    as possible. This not only speeds up the deployment process, but it enables more
    extensive regression testing and reduces the likelihood of errors in the deployment.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在严格管制的行业（例如金融和制药业），治理和监管检查将会非常严格，并且可能需要手动干预。MLOps的愿望与DevOps一样，就是尽可能地自动化CI/CD流水线。这不仅加快了部署过程，还能进行更广泛的回归测试，并减少部署中出错的可能性。
- en: Monitoring
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: Once a model is deployed to production, it is crucial that it continue to perform
    well over time. But good performance means different things to different people,
    in particular to the DevOps team, to data scientists, and to the business.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型部署到生产环境中，它能够持续良好地运行至关重要。但良好的性能对不同的人意味着不同的事情，特别是对DevOps团队、数据科学家和业务而言。
- en: DevOps Concerns
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DevOps的关注点
- en: 'The concerns of the DevOps team are very familiar and include questions like:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps团队的关注点非常熟悉，包括诸如：
- en: Is the model getting the job done quickly enough?
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是否能够快速完成工作？
- en: Is it using a sensible amount of memory and processing time?
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是否在合理的内存和处理时间范围内运行？
- en: This is traditional IT performance monitoring, and DevOps teams know how to
    do this well already. The resource demands of ML models are not so different from
    traditional software in this respect.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是传统的IT性能监控，而DevOps团队已经知道如何做得很好了。在这方面，ML模型的资源需求与传统软件并没有太大的不同。
- en: Scalability of compute resources can be an important consideration, for example,
    if you are retraining models in production. Deep learning models have greater
    resource demands than much simpler decision trees. But overall, the existing expertise
    in DevOps teams for monitoring and managing resources can be readily applied to
    ML models.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 计算资源的可扩展性可能是一个重要考虑因素，例如，如果你正在生产环境中重新训练模型。深度学习模型比简单的决策树具有更高的资源需求。但总体而言，DevOps团队在监控和管理资源方面的现有专业知识可以轻松应用于ML模型。
- en: Data Scientist Concerns
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学家的关注点
- en: 'The data scientist is interested in monitoring ML models for a new, more challenging
    reason: they can degrade over time, since ML models are effectively models of
    the data they were trained on. This is not a problem faced by traditional software,
    but it is inherent to machine learning. ML mathematics builds a concise representation
    of the important patterns in the training data with the hope that this is a good
    reflection of the real world. If the training data reflects the real world well,
    then the model should be accurate and, thus, useful.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家对监控ML模型感兴趣是出于一个更具挑战性的原因：它们可能会随时间而退化，因为ML模型实际上是对它们训练数据的模型。这不是传统软件面临的问题，但它是机器学习固有的。ML数学建立了对训练数据中重要模式的简明表达，希望这能很好地反映现实世界。如果训练数据很好地反映了现实世界，那么模型应该是准确的，因此是有用的。
- en: But the real world doesn’t stand still. The training data used to build a fraud
    detection model six months ago won’t reflect a new type of fraud that has started
    to occur in the last three months. If a given website starts to attract an increasingly
    younger user base, then a model that generates advertisements is likely to produce
    less and less relevant adverts. At some point, the performance will become unacceptable,
    and model retraining becomes necessary. How soon models need to be retrained depends
    on how fast the real world is changing and how accurate the model needs to be,
    but also, importantly, on how easy it is to build and deploy a better model.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 但现实世界并不停留。六个月前用于构建欺诈检测模型的训练数据不会反映出最近三个月开始出现的新类型欺诈行为。如果某个网站开始吸引越来越年轻的用户群体，那么生成广告的模型可能会生成越来越不相关的广告。在某一点上，性能将变得不可接受，需要重新训练模型。模型需要多快重新训练取决于现实世界的变化速度以及模型需要多准确，但同样重要的是，取决于构建和部署更好模型的难易程度。
- en: But first, how can data scientists tell a model’s performance is degrading?
    It’s not always easy. There are two common approaches, one based on ground truth
    and the other on input drift.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，数据科学家如何判断模型的性能正在恶化呢？这并不总是容易。有两种常见方法，一种基于真相，另一种基于输入漂移。
- en: Ground truth
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 真相
- en: The ground truth, put simply, is the correct answer to the question that the
    model was asked to solve—for example, “Is this credit card transaction actually
    fraudulent?” In knowing the ground truth for all the predictions a model has made,
    one can judge how well that model is performing.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 真相（ground truth），简而言之，是模型被要求解决的问题的正确答案，例如，“这笔信用卡交易实际上是欺诈的吗？” 通过了解模型所做预测的所有真相，可以评估该模型的表现如何。
- en: Sometimes ground truth is obtained rapidly after a prediction—for example, in
    models that decide which advertisements to display to a user on a web page. The
    user is likely to click on the advertisements within seconds, or not at all. However,
    in many use cases, obtaining the ground truth is much slower. If a model predicts
    that a transaction is fraudulent, how can this be confirmed? In some cases, verification
    may only take a few minutes, such as a phone call placed to the cardholder. But
    what about the transactions the model thought were OK but actually weren’t? The
    best hope is that they will be reported by the cardholder when they review their
    monthly transactions, but this could happen up to a month after the event (or
    not at all).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，在预测之后可以迅速获取真相，例如，在决定向用户展示哪些广告的模型中。用户可能在几秒钟内点击广告，或者根本不点击。然而，在许多用例中，获取真相要慢得多。如果一个模型预测某笔交易是欺诈的，如何确认这一点？在某些情况下，确认可能只需要几分钟，例如给持卡人打电话。但是，如果模型认为交易正常，实际上并非如此怎么办？最好的希望是当持卡人查看他们的月度交易记录时，他们会报告这些问题，但这可能会延迟一个月或完全不发生。
- en: In the fraud example, ground truth isn’t going to enable data science teams
    to monitor performance accurately on a daily basis. If the situation requires
    rapid feedback, then input drift may be a better approach.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在欺诈的例子中，真相不能让数据科学团队每天准确监测性能。如果情况需要快速反馈，那么输入漂移可能是一个更好的方法。
- en: Input drift
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输入漂移
- en: Input drift is based on the principle that a model is only going to predict
    accurately if the data it was trained on is an accurate reflection of the real
    world. So if a comparison of recent requests to a deployed model against the training
    data shows distinct differences, then there is a strong likelihood that the model
    performance is compromised. This is the basis of input drift monitoring. The beauty
    of this approach is that all the data required for this test already exists, so
    there is no need to wait for ground truth or any other information.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 输入漂移基于一个原则，即如果模型训练的数据准确反映了现实世界，模型才能准确预测。因此，如果最近请求与部署模型的训练数据之间的比较显示出明显差异，那么模型的性能可能会受到损害。这就是输入漂移监测的基础。这种方法的美妙之处在于，用于此测试的所有数据已经存在，因此无需等待真相或任何其他信息。
- en: Identifying drift is one of the most important components of an adaptable MLOps
    strategy, and one that can bring agility to the organization’s enterprise AI efforts
    overall. [Chapter 7](ch07.html#monitoring_and_feedback_loop) will go into more
    technical depth about data scientists’ concerns when it comes to model monitoring.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 识别漂移是可适应的 MLOps 策略中最重要的组成部分之一，也是能够为组织的企业 AI 努力带来敏捷性的组成部分。[第 7 章](ch07.html#monitoring_and_feedback_loop)
    将更深入地探讨数据科学家在模型监控方面的关注点。
- en: Business Concerns
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 业务关注点
- en: 'The business has a holistic outlook on monitoring, and some of its concerns
    might include questions like:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 业务对监控有全面的观点，其中一些关注点可能包括以下问题：
- en: Is the model delivering value to the enterprise?
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型为企业带来了价值吗？
- en: Do the benefits of the model outweigh the cost of developing and deploying it?
    (And how can we measure this?)
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的益处是否超过开发和部署它的成本？（如何衡量这一点？）
- en: 'The KPIs identified for the original business objective are one part of this
    process. Where possible, these should be monitored automatically, but this is
    rarely trivial. The objective of reducing fraud to less than 0.1% of transactions
    in our previous example is reliant on establishing the ground truth. But even
    monitoring this doesn’t answer the question: what is the net gain to the business
    in dollars?'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 原始业务目标确定的关键绩效指标是这一过程的一部分。在可能的情况下，这些应该自动监控，但这很少是微不足道的。在我们之前的示例中，将欺诈率降低到交易的0.1%以下的目标取决于建立基础事实。但即使是这样监控，也无法回答一个问题：业务的净收益是多少美元？
- en: This is an age-old challenge for software, and with ever-increasing expenditure
    on ML, the pressure for data scientists to demonstrate value is only going to
    grow. In the absence of a “dollar-o-meter,” effectively monitoring the business
    KPIs is the best option available (see [“Design and Manage Experiments”](ch10.html#design_and_manage_experiments)).
    The choice of the baseline is important here and should ideally allow for differentiation
    of the value of the ML subproject specifically, rather than that of the global
    project. For example, the ML performance can be assessed with respect to a rule-based
    decision model based on subject matter expertise to set apart the contribution
    of decision automation and of ML per se.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这是软件的古老挑战，随着对机器学习支出的不断增加，数据科学家展示价值的压力只会增加。在缺乏“美元计量器”的情况下，有效监控业务关键绩效指标是最佳选择（参见[“设计和管理实验”](ch10.html#design_and_manage_experiments)）。在这里选择基线很重要，理想情况下应允许区分
    ML 子项目的价值，而不是全局项目的价值。例如，可以通过基于主题专业知识的基于规则的决策模型评估 ML 性能，以区分决策自动化和 ML 本身的贡献。
- en: Iteration and Life Cycle
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迭代与生命周期
- en: Developing and deploying improved versions of a model is an essential part of
    the MLOps life cycle, and one of the more challenging. There are various reasons
    to develop a new model version, one of which is model performance degradation
    due to model drift, as discussed in the prior section. Sometimes there is a need
    to reflect refined business objectives and KPIs, and other times, it’s just that
    the data scientists have come up with a better way to design the model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 开发和部署改进版本的模型是 MLOps 生命周期中必不可少的部分，也是更具挑战性的部分之一。有各种原因可以开发新的模型版本，其中之一是由于模型漂移导致模型性能下降，正如前一节所讨论的。有时需要反映精炼的业务目标和关键绩效指标，而其他时候，只是数据科学家提出了更好的设计模型的方法。
- en: Iteration
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迭代
- en: In some fast-moving business environments, new training data becomes available
    every day. Daily retraining and redeployment of the model are often automated
    to ensure that the model reflects recent experience as closely as possible.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些快速变化的业务环境中，每天都会有新的训练数据可用。通常会自动化每日重新训练和重新部署模型，以确保模型尽可能准确地反映最近的经验。
- en: 'Retraining an existing model with the latest training data is the simplest
    scenario for iterating a new model version. But while there are no changes to
    feature selection or algorithm, there are still plenty of pitfalls. In particular:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 重新使用最新训练数据重新训练现有模型是迭代新模型版本的最简单情况。但即使没有特征选择或算法变化，仍然存在许多陷阱。特别是：
- en: Does the new training data look as expected? Automated validation of the new
    data through predefined metrics and checks is essential.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的训练数据看起来如预期吗？通过预定义的指标和检查自动验证新数据至关重要。
- en: Is the data complete and consistent?
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据完整且一致吗？
- en: Are the distributions of features broadly similar to those in the previous training
    set? Remember that the goal is to refine the model, not radically change it.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征的分布是否与先前训练集中的分布大致相似？请记住，目标是优化模型，而不是根本性地改变它。
- en: With a new model version built, the next step is to compare the metrics with
    the current live model version. Doing so requires evaluating both models on the
    same development dataset, whether it be the previous or latest version. If metrics
    and checks suggest a wide variation between the models, automated scripts should
    not be redeployed, and manual intervention should be sought.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 构建新模型版本后的下一步是将指标与当前的实时模型版本进行比较。为此，需要在相同的开发数据集上评估两个模型，无论是先前版本还是最新版本。如果指标和检查表明两个模型之间存在较大差异，则不应重新部署自动化脚本，并应寻求手动干预。
- en: Even in the “simple” automated retraining scenario with new training data, there
    is a need for multiple development datasets based on scoring data reconciliation
    (with ground truth when it becomes available), data cleaning and validation, the
    previous model version, and a set of carefully considered checks. Retraining in
    other scenarios is likely to be even more complicated, rendering automated redeployment
    unlikely.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在“简单”的自动化重新训练场景中使用新的训练数据，也需要基于评分数据协调（在可用时与真实情况一致）、数据清理和验证、先前的模型版本以及一系列经过深思熟虑的检查来创建多个开发数据集。在其他情景下重新训练可能会更加复杂，从而使自动化部署变得不太可能。
- en: As an example, consider retraining motivated by the detection of significant
    input drift. How can the model be improved? If new training data is available,
    then retraining with this data is the action with the highest cost-benefit ratio,
    and it may suffice. However, in environments where it’s slow to obtain the ground
    truth, there may be little new labeled data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 举例来说，考虑到由于重要的输入漂移而进行的重新训练。如何改进模型？如果有新的训练数据可用，那么使用这些数据进行重新训练是具有最高成本效益比的行动，而且可能足够了。然而，在获取真实情况速度较慢的环境中，可能没有太多新的标记数据。
- en: This case requires direct invention from data scientists who need to understand
    the cause of the drift and work out how the existing training data could be adjusted
    to more accurately reflect the latest input data. Evaluating a model generated
    by such changes is difficult. The data scientist has to spend time assessing the
    situation—time that increases with the amount of modeling debt—as well as estimate
    the potential impact on performance and design custom mitigation measures. For
    example, removing a specific feature or sampling the existing rows of training
    data may lead to a better-tuned model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 本案例需要数据科学家的直接干预，他们需要理解漂移的原因，并找出如何调整现有的训练数据以更准确地反映最新的输入数据。评估通过这些更改生成的模型是困难的。数据科学家必须花时间评估情况——这段时间随着建模债务的增加而增加——并估计对性能的潜在影响，并设计定制的缓解措施。例如，去除特定特征或对现有的训练数据行进行抽样可能会导致调整更好的模型。
- en: The Feedback Loop
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反馈循环
- en: In large enterprises, DevOps best practices typically dictate that the live
    model scoring environment and the model retraining environment are distinct. As
    a result, the evaluation of a new model version on the retraining environment
    is likely to be compromised.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型企业中，DevOps 最佳实践通常规定，实时模型评分环境和模型重新训练环境是分开的。因此，在重新训练环境中评估新模型版本可能会受到影响。
- en: One approach to mitigating this uncertainty is shadow testing, where the new
    model version is deployed into the live environment alongside the existing model.
    All live scoring is handled by the incumbent model version, but each new request
    is then scored again by the new model version and the results logged, but not
    returned to the requestor. Once sufficient requests have been scored by both versions,
    the results can be compared statistically. Shadow scoring also gives more visibility
    to the SMEs on the future versions of the model and may thus allow for a smoother
    transition.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解这种不确定性的一种方法是影子测试，其中新模型版本与现有模型一起部署到实时环境中。所有实时评分由现任模型版本处理，但每个新请求将由新模型版本再次评分并记录结果，但不返回给请求者。一旦足够的请求由两个版本评分，结果就可以进行统计比较。影子评分还为SME（专家小组成员）提供了更多关于模型未来版本的可见性，因此可能允许更平稳的过渡。
- en: In the advertisement generation model previously discussed, it is impossible
    to tell if the ads selected by the model are good or bad without allowing the
    end user the chance to click on them. In this use case, shadow testing has limited
    benefits, and A/B testing is more common.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前讨论的广告生成模型中，无法确定模型选择的广告是好是坏，除非允许最终用户点击它们。在这种情况下，影子测试的好处有限，而A/B测试更为常见。
- en: In A/B testing, both models are deployed into the live environment, but input
    requests are split between the two models. Each request is processed by one or
    the other model, not both. Results from the two models are logged for analysis
    (but never for the same request). Drawing statistically meaningful conclusions
    from an A/B test requires careful planning of the test.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在A/B测试中，两个模型都部署到实时环境中，但输入请求被分配到两个模型之间。每个请求只由其中一个模型处理，而不是两个都处理。两个模型的结果被记录以供分析（但不是针对同一请求）。从A/B测试中得出统计上显著的结论需要仔细规划测试过程。
- en: '[Chapter 7](ch07.html#monitoring_and_feedback_loop) will cover the how-to of
    A/B testing in more detail, but as a preview, the simplest form of A/B testing
    is often referred to as a fixed-horizon test. That’s because in the search for
    a statistically meaningful conclusion, one has to wait until the carefully predetermined
    number of samples have been tested. “Peeking” at the result before the test is
    finished is unreliable. However, if the test is running live in a commercial environment,
    every bad prediction is likely to cost money, so not being able to stop a test
    early could be expensive.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](ch07.html#monitoring_and_feedback_loop)将更详细地介绍A/B测试的操作方法，但预览时，最简单形式的A/B测试通常被称为固定时间段测试。这是因为在寻找统计上显著的结论时，必须等到测试了事先精心确定的样本数量。在测试完成之前窥视结果是不可靠的。然而，如果测试在商业环境中实时运行，每一个糟糕的预测都可能花费金钱，因此不能早期停止测试可能会很昂贵。'
- en: 'Bayesian, and in particular multi-armed bandit, tests are an increasingly popular
    alternative to the “frequentist” fixed-horizon test, with the aim of drawing conclusions
    more quickly. Multi-armed bandit testing is adaptive: the algorithm that decides
    the split between models adapts according to live results and reduces the workload
    of underperforming models. While multi-armed bandit testing is more complex, it
    can reduce the business cost of sending traffic to a poorly performing model.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯，特别是多臂老虎机测试，越来越受欢迎，作为“频率主义者”固定时间段测试的替代方案，旨在更快地得出结论。多臂老虎机测试是自适应的：决定模型之间分配的算法根据实时结果进行调整，并减少表现不佳模型的工作负载。虽然多臂老虎机测试更复杂，但可以降低将流量发送到表现不佳模型的业务成本。
- en: Governance
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 治理
- en: Governance is the set of controls placed on a business to ensure that it delivers
    on its responsibilities to all stakeholders, from shareholders and employees to
    the public and national governments. These responsibilities include financial,
    legal, and ethical obligations. Underpinning all three of these is the fundamental
    principle of fairness.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 治理是对企业施加的一系列控制措施，以确保其履行对所有利益相关者的责任，从股东和员工到公众和国家政府。这些责任包括财务、法律和道德义务。这三者的基础是公平原则。
- en: Legal obligations are the easiest to understand. Businesses were constrained
    by regulations long before the advent of machine learning. Many regulations target
    specific industries; for example, financial regulations aim to protect the public
    and wider economy from finance mismanagement and fraud, while pharmaceutical industries
    must comply with rules to safeguard the health of the public. Business practice
    is impacted by broader legislation to protect vulnerable sectors of society and
    to ensure a level playing field on criteria such as sex, race, age, or religion.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 法律义务是最容易理解的。在机器学习出现之前，企业就受到法规的约束。许多法规针对特定行业；例如，金融法规旨在保护公众和更广泛的经济免受金融管理和欺诈的危害，而制药行业必须遵守规则以保障公众健康。商业实践受到更广泛的立法影响，以保护社会中的弱势群体，并确保在性别、种族、年龄或宗教等标准上的公平竞争。
- en: Recently, governments across the world have imposed regulations to protect the
    public from the impact of the use of personal data by businesses.  The 2016 EU
    General Data Protection Regulation (GDPR) and the 2018 California Consumer Privacy
    Act (CCPA) typify this trend, and their impact on ML—with its total dependency
    on data—has been immense. For example, GDPR attempts to protect personal data
    from industrial misuse with a goal of limiting the potential discrimination against
    individuals.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，全球各国政府已经实施了保护公众免受企业使用个人数据影响的法规。2016年的欧盟通用数据保护条例（GDPR）和2018年的加州消费者隐私法案（CCPA）代表了这一趋势，它们对完全依赖数据的机器学习的影响巨大。例如，GDPR试图保护个人数据免受工业滥用，并旨在限制可能对个人造成的歧视。
- en: Governments are now starting to turn their regulatory eye to ML specifically,
    hoping to mitigate the negative impact of its use. The European Union is leading
    the way with planned legislation to define the acceptable uses of various forms
    of AI. This is not necessarily about reducing use; for example, it may enable
    beneficial applications of facial recognition technology that are currently restricted
    by data privacy regulations. But what is clear is that businesses will have to
    take heed of yet more regulation when applying ML.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，各国政府开始特别关注机器学习，希望减少其使用可能带来的负面影响。欧盟正在领先，计划制定法律来定义各种形式人工智能的可接受使用方式。这并不一定意味着减少使用；例如，可能会推动面部识别技术的有益应用，目前受数据隐私法规限制。但显然的是，企业在应用机器学习时将不得不注意更多的监管。
- en: Do businesses care about moral responsibilities to society, beyond formal legislation?
    Increasingly, the answer is yes, as seen in the current development of environmental,
    social, and governance (ESG) performance indicators. Trust matters to consumers,
    and a lack of trust is bad for business. With increasing public activism on the
    subject, businesses are engaging with ideas of Responsible AI, the ethical, transparent,
    and accountable application of AI technology. Trust matters to shareholders, too,
    and full disclosure of ML risks is on its way.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 企业是否关心超越法定法规的对社会的道德责任？答案越来越是肯定的，如当前环境、社会和治理（ESG）绩效指标的发展所示。信任对消费者至关重要，缺乏信任对业务不利。随着公众在这一议题上的活跃参与增加，企业正在探讨负责任人工智能的理念，即道德、透明和可问责的人工智能技术应用。股东也重视信任，机器学习风险的全面披露正在逐步实现。
- en: 'Applying good governance to MLOPs is challenging. The processes are complex,
    the technology is opaque, and the dependence on data is fundamental. Governance
    initiatives in MLOps broadly fall into one of two categories:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 将良好的治理应用于MLOps是具有挑战性的。这些过程复杂，技术不透明，对数据的依赖性是基础性的。MLOps中的治理倡议大体上可以分为两类：
- en: Data governance
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 数据治理
- en: A framework for ensuring appropriate use and management of data
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 确保适当使用和管理数据的框架
- en: Process governance
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 过程治理
- en: The use of well-defined processes to ensure all governance considerations have
    been addressed at the correct point in the life cycle of the model and that a
    full and accurate record has been kept
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用明确定义的流程确保在模型生命周期的正确阶段处理所有治理考虑，并且保持完整和准确的记录
- en: Data Governance
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据治理
- en: 'Data governance concerns itself with the data being used, especially that for
    model training, and it can address questions like:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 数据治理关注正在使用的数据，特别是模型训练的数据，并且可以解决如下问题：
- en: What is the data’s provenance?
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的来源是什么？
- en: How was the original data collected and under what terms of use?
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始数据是如何收集的，使用条款是什么？
- en: Is the data accurate and up to date?
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是否准确且更新？
- en: Is there PII or other forms of sensitive data that should not be used?
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否存在个人身份信息（PII）或其他敏感数据不应使用？
- en: ML projects usually involve significant pipelines, consisting of data cleaning,
    combination, and transformation steps. Understanding the data lineage is complex,
    especially at the feature level, but it is essential for compliance with GDPR-style
    regulations. How can teams—and more broadly organizations, as it matters at the
    top as well—be sure that no PII is used to train a given model? Anonymizing or
    pseudo-anonymizing data is not always a sufficient solution to managing personal
    information. If these processes are not performed correctly, it can still be possible
    to single out an individual and their data, contrary to the requirements of GDPR.^([3](ch03.html#ch01fn4))
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习项目通常涉及大量的流水线，包括数据清洗、组合和转换步骤。理解数据衍生线在特征级别尤为复杂，但对于遵守类似GDPR的法规却是必不可少的。团队——乃至更广泛的组织，因为这对其顶层也很重要——如何确保没有使用个人身份信息来训练给定模型？对数据进行匿名化或伪匿名化并非总是管理个人信息的充分解决方案。如果这些过程执行不正确，仍然可能单独识别出个人及其数据，与GDPR的要求相违背。^([3](ch03.html#ch01fn4))
- en: Inappropriate biases in models can arise quite accidentally despite the best
    intentions of data scientists. An ML recruitment model famously discriminated
    against women by identifying that certain schools—all-female schools—were less
    well represented in the company’s upper management, which reflected the historical
    dominance of men in the organization.^([4](ch03.html#ch01fn5)) The point is that
    making predictions based on experience is a powerful technique, but sometimes
    the consequences are not only counter-productive, but illegal.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管数据科学家的初衷最好，模型中可能会意外地产生不恰当的偏见。一个机器学习招聘模型曾因识别某些全女子学校在公司高层管理中代表性不足而著名，这反映了该组织历史上男性的主导地位。^([4](ch03.html#ch01fn5))
    关键在于基于经验进行预测是一种强大的技术，但有时其后果不仅是适得其反，还可能违法。
- en: 'Data governance tools that can address these problems are in their infancy.
    Most focus on answering these two questions about data lineage:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 目前能够解决这些问题的数据治理工具还处于初期阶段。大多数工具集中在回答数据衍生线的两个问题上：
- en: Where did the information in this dataset come from, and what does this tell
    me about how I can use it?
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个数据集的信息来源是什么，以及这告诉我如何使用它？
- en: How is this dataset used, and if I change it in some way, what are the implications
    downstream?
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个数据集如何使用，如果我对其进行某些更改，对下游有何影响？
- en: Neither question is easy to answer fully and accurately in real-world data preparation
    pipelines. For example, if a data scientist writes a Python function to in-memory
    process several input datasets and output a single dataset, how can one be sure
    from what information each cell of the new dataset was derived?
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在真实世界的数据准备流水线中，两个问题都不容易全面准确地回答。例如，如果数据科学家编写了一个Python函数来处理多个输入数据集并输出一个单一数据集，那么如何确保新数据集中每个单元格的信息来源？
- en: Process Governance
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流程治理
- en: 'Process governance focuses on formalizing the steps in the MLOps process and
    associating actions with them. Typically these actions are reviews, sign-offs,
    and the capture of supporting materials, such as documentation. The aim is twofold:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 流程治理专注于规范MLOps流程中的步骤，并与之相关联的行动。通常这些行动包括审查、签字以及文档等支持材料的获取。其目的有两个：
- en: To ensure every governance-related consideration is made at the correct time
    and correctly acted upon. For example, models should not be deployed to production
    until all validation checks have been passed.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保每个与治理相关的考虑在正确的时间做出并得到正确执行。例如，模型在所有验证检查都通过之前不应部署到生产环境。
- en: To enable oversight from outside of the strict MLOps process. Auditors, risk
    managers, compliance officers, and the business as a whole all have an interest
    in being able to track progress and review decisions at a later stage.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以便从严格的MLOps流程之外进行监督。审计员、风险管理人员、合规官员以及整个业务都有兴趣能够在后期跟踪进展和审查决策。
- en: 'Effective implementation of process governance is hard:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 流程治理的有效实施是困难的：
- en: Formal processes for the ML life cycle are rarely easy to define accurately.
    The understanding of the complete process is usually spread across the many teams
    involved, often with no one person having a detailed understanding of it as a
    whole.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习生命周期的正式流程很少能准确定义。对整个过程的理解通常分散在参与其中的多个团队之间，往往没有一个人能全面理解整体。
- en: For the process to be applied successfully, every team must be willing to adopt
    it wholeheartedly.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要成功应用这一流程，每个团队都必须全力采纳。
- en: If the process is just too heavy-weight for some use-cases, teams will certainly
    subvert it, and much of the benefit will be lost.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果某些用例中的流程过于繁重，团队们肯定会绕过它，很多好处也将会丧失。
- en: Today, process governance is most commonly found in organizations with a traditionally
    heavy burden of regulation and compliance, such as finance. Outside of these,
    it is rare. With ML creeping into all spheres of commercial activity and with
    rising concern about Responsible AI, we will need new and innovative solutions
    to this problem that can work for all businesses.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，流程治理在传统上具有繁重的监管和合规负担的组织中最为普遍，如金融领域。在这些领域之外，这种情况则比较罕见。随着机器学习渗透到商业活动的各个领域，并且对负责任的AI日益关注，我们将需要针对所有企业可行的新的和创新的解决方案来解决这个问题。
- en: Closing Thoughts
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结思考
- en: Given this overview of features required for and processes affected by MLOps,
    it’s clearly not something data teams—or even the data-driven organization at
    large—can ignore. Nor is it an item to check off of a list (“yes, we do MLOps!”),
    but rather a complex interplay between technologies, processes, and people that
    requires discipline and time to do correctly.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对MLOps所需功能和受影响流程的概述，显然这不是数据团队——甚至整个数据驱动组织可以忽视的事情。这也不是一个勾掉清单上项目的事项（“是的，我们在做MLOps！”），而是技术、流程和人员之间复杂的相互作用，需要纪律和时间才能正确执行。
- en: The following chapters go deeper into each of the ML model life cycle components
    at play in MLOps, providing a look at how each should be done to get closer to
    the ideal MLOps implementation.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 后续章节将深入探讨MLOps中每个ML模型生命周期组件的作用，展示每个组件如何实现以更接近理想的MLOps实施。
- en: ^([1](ch03.html#ch01fn2-marker)) Describing the blue-green deployment technique
    will require more space than we have here. For more information, see [Martin Fowler’s
    blog](https://oreil.ly/Uuobx).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.html#ch01fn2-marker)) 描述蓝绿部署技术需要比我们这里提供的空间更多。更多信息请参阅[Martin Fowler的博客](https://oreil.ly/Uuobx)。
- en: ^([2](ch03.html#ch01fn3-marker)) Delve into [the differences between GDPR and
    CCPA](https://oreil.ly/zS7o6).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch03.html#ch01fn3-marker)) 深入了解[GDPR和CCPA之间的区别](https://oreil.ly/zS7o6)。
- en: ^([3](ch03.html#ch01fn4-marker)) For more on anonymization, pseudo-anonymization,
    and why they don’t solve all data privacy woes, we recommend [*Executing Data
    Privacy-Compliant Data Projects* by Dataiku](https://oreil.ly/bK1Yu).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch03.html#ch01fn4-marker)) 关于匿名化、伪匿名化以及它们为何不能解决所有数据隐私问题的更多信息，请参阅[*数据隐私合规数据项目实施指南*
    by Dataiku](https://oreil.ly/bK1Yu)。
- en: ^([4](ch03.html#ch01fn5-marker)) In 2018, Amazon famously [scrapped an AI recruiting
    tool because of its bias against women](https://oreil.ly/tI5Sy).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch03.html#ch01fn5-marker)) 2018年，亚马逊因其针对女性的偏见而声名狼藉地[废除了一款AI招聘工具](https://oreil.ly/tI5Sy)。
