- en: Chapter 3\. Designing Your Data Team
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章 设计您的数据团队
- en: 'When designing a data platform, there are several technical aspects to take
    into consideration: performance, cost, operational overhead, operational excellence,
    integration of new analytical and ML approaches, etc. However, these technical
    aspects will fall to the wayside if you don’t address the culture of the company—new
    technologies require a willingness from employees to change their mental models
    and ways of working. Another key aspect to keep in mind is the skills that existing
    employees currently possess and will need to pick up. In some cases, employees
    who learn new skills and change their way of working will end up in a different
    role than the role they had before the data platform was in place.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计数据平台时，有几个技术方面需要考虑：性能、成本、运营开销、运营卓越、整合新的分析和机器学习方法等。然而，如果不解决公司文化——新技术需要员工愿意改变他们的心智模型和工作方式——这些技术方面将会被忽视。另一个要牢记的关键方面是现有员工目前拥有的技能以及他们需要掌握的技能。在某些情况下，学习新技能并改变工作方式的员工最终可能会进入不同于数据平台建立前所处角色的新角色。
- en: In this chapter, we explore how organizations can plan and orchestrate these
    changes in mental models, workflows, technical skills, and roles. Every organization
    is unique, and so building a data platform will involve devising a granular plan
    for each division and employee in it. In this chapter, we describe what such a
    granular plan would look like for different types of organizations.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了组织如何规划和编排这些关于心智模型、工作流、技术技能和角色的变革。每个组织都是独特的，因此构建数据平台将涉及为每个部门和员工制定细致的计划。在本章中，我们描述了这样一个细致计划在不同类型的组织中可能是什么样子。
- en: Classifying Data Processing Organizations
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据处理组织的分类
- en: Organizations can succeed by employing different strategies based on their talent.
    There is no universal “best” approach. A sports team with a strong defense should
    play to their strengths and focus on defense, not try to copy the offense of a
    team with skilled offensive players. Similarly, if your organization has a strong
    team of data analysts, it should focus on its people rather than attempting to
    transform into an organization full of data engineers.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 组织可以通过采用基于其人才的不同策略来取得成功。没有普遍适用的“最佳”方法。一个具有强大防守的体育团队应该发挥其优势，专注于防守，而不是试图复制拥有技术攻击手的球队的进攻。同样，如果您的组织拥有强大的数据分析团队，它应该专注于其人员，而不是试图转变为一个充满数据工程师的组织。
- en: Decide on the best strategy for your organization based on the skills of your
    workforce and the complexity of your use cases. Do you need a small but highly
    capable (and expensive) group of data engineers? Or should you leverage a large
    and already present workforce of data analysts to enrich and transform data that
    can be acted on? How much domain knowledge do these workers need? Would training
    the current workforce to carry out higher-value work be realistic? Or should you
    invest in generative AI or no-code tools and make such foundational pieces of
    technology available to the larger workforce?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的员工技能和使用案例的复杂性，决定您的组织的最佳策略。您是否需要一小部分高能力（并且昂贵）的数据工程师？或者应该利用大量已经存在的数据分析师团队来丰富和转换可以采取行动的数据？这些工作者需要多少领域知识？培训当前工作人员以执行更高价值的工作是否现实？还是应该投资于生成式AI或无代码工具，并使这些基础性技术对更大规模的工作人员可用？
- en: The best technology approach will also vary within the organization—the composition
    of the workforce will vary between the sales team and the factory floor. So the
    granular plan involves detailing the best technology approach for each business
    unit. Technology-wise, the plan will also make choices between an approach based
    on standard ETL (hard skills on ETL tools required) and a modern one based on
    ELT (more general SQL skills required).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 技术方法的最佳选择在组织内部也会有所不同——工作人员的构成在销售团队和工厂生产线之间会有所不同。因此，细致计划包括为每个业务单元详细说明最佳的技术方法。从技术上讲，该计划还将在基于标准ETL（需要ETL工具的硬技能）和基于ELT（需要更普遍SQL技能）的方法之间进行选择。
- en: Consider the traditional persona value chain as sketched in [Figure 3-1](#data_processing_traditional_persona_val).
    You can see that every data user in an organization has a small and specialized
    set of technical skills. If an organization wants to increase the scope of its
    data analysis team, it also has to scale the size of its data engineering and
    data science teams to make sure enough people have the right technical skills
    to support the data analysts.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑如图[3-1](#data_processing_traditional_persona_val)所示的传统人物价值链。您可以看到组织中的每个数据用户都拥有一小部分专业技能。如果一个组织希望扩展其数据分析团队的范围，它还必须扩展其数据工程和数据科学团队的规模，以确保有足够的人拥有正确的技术技能来支持数据分析师。
- en: '![Data processing: traditional persona value chain](assets/adml_0301.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![数据处理：传统人物价值链](assets/adml_0301.png)'
- en: 'Figure 3-1\. Data processing: traditional persona value chain'
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. 数据处理：传统人物价值链
- en: The new paradigms provided by the public cloud have opened up new possibilities
    for how data processing, data analysis, and algorithm development are done. Cloud
    technologies make new ways of working now possible—they allow analysts to carry
    out batch or real-time data processing tasks that used to be managed by data engineers
    while also allowing them to experiment with off-the-shelf data science solutions.
    Additionally, the potential scope of any given persona—the skills they have and
    the duties they are responsible for—has increased. As data technology becomes
    more accessible, data workers are able to take on new tasks and address the data
    value chain without the bottlenecks associated with the traditional persona value
    chain. This is leading to a convergence of skills across roles, allowing existing
    teams to more easily scale to additional responsibilities. The distinction between
    data analysts focused on solving problems using an ELT approach with SQL code
    and data engineers/data scientists more aligned with an ETL approach and general-purpose
    code (e.g., Python, Java, Scala, etc.) is becoming less clear. Blended approaches
    (as depicted in [Figure 3-2](#data_processing_persona_framework)) are becoming
    more common because they can take advantage of the best of both ETL and ELT patterns.
    The majority of the organizations we see today fall into this blended model, though
    the balance of roles and how much of the data processing has to be done via either
    ETL or ELT vary depending on the type of the organization.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 公共云提供的新范式为数据处理、数据分析和算法开发打开了新的可能性。云技术使得现在能够采用新的工作方式——分析师可以执行以前由数据工程师管理的批处理或实时数据处理任务，并尝试使用现成的数据科学解决方案。此外，每个人物的潜在范围——他们的技能和职责——也有所增加。随着数据技术变得更加易于访问，数据工作者能够承担新任务并在没有传统人物价值链瓶颈的情况下处理数据价值链。这导致角色技能的融合，使得现有团队更容易扩展到额外的责任。数据分析师专注于使用ELT方法和SQL代码解决问题，而数据工程师/数据科学家更倾向于ETL方法和通用代码（如Python、Java、Scala等），二者之间的区别变得不那么明显。混合方法（如[图
    3-2](#data_processing_persona_framework)所示）变得更为普遍，因为它们可以充分利用ETL和ELT模式的优势。今天我们看到的大多数组织都属于这种混合模型，尽管角色的平衡和数据处理的ETL或ELT方式的比例因组织类型而异。
- en: '![Data processing: persona framework](assets/adml_0302.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![数据处理：人物框架](assets/adml_0302.png)'
- en: 'Figure 3-2\. Data processing: persona framework'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. 数据处理：人物框架
- en: In simpler terms, data workers are now able to do more with the data they have,
    and they are able to do it more efficiently. This is because the technology is
    more accessible and because data workers are able to blend their skills with those
    of other data professionals. This is leading to a more efficient and effective
    way of processing data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，数据工作者现在能够更高效地利用他们手头的数据。这是因为技术更易于获取，也因为数据工作者能够将他们的技能与其他数据专业人士的技能相结合。这导致了一种更有效率和有效的数据处理方式。
- en: 'Organizations can be broadly classified under three types: *data analysis driven*,
    *data engineering driven*, and *data science driven*. In the following sections,
    we will cover an idealized way of building a data processing organization for
    each of these types. In reality, companies will consist of different divisions
    or business units that fall into these categories, and so they will find themselves
    applying all the strategies. Some teams will be a combination of roles, and so
    the transformation will involve a blended approach. As you consider the different
    types of users who will be part of your data team, remember what you learned in
    [Chapter 2](ch02.html#strategic_steps_to_innovate_with_data): “To maximize the
    leverage you get from data, apply product management principles.” You should always
    use product management principles to develop your data product strategy, be customer-centric,
    discover products through whiteboarding and prototyping, and find the right balance
    between standardization and flexibility.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 组织可以广泛分类为三种类型：*数据分析驱动*、*数据工程驱动*和*数据科学驱动*。在接下来的几节中，我们将讨论为每种类型建立数据处理组织的理想方式。事实上，公司将包括不同的部门或业务单位，这些部门或单位属于这些类别，因此它们将发现自己应用所有这些策略。一些团队将结合多种角色，因此转型将涉及混合方法。在考虑您的数据团队中将成为不同类型用户时，请记住您在[第二章](ch02.html#strategic_steps_to_innovate_with_data)学到的内容：“为了最大化从数据中获得的影响，请应用产品管理原则。”您应始终使用产品管理原则来制定您的数据产品战略，以客户为中心，通过白板绘图和原型制作发现产品，并在标准化与灵活性之间找到合适的平衡。
- en: Data Analysis–Driven Organization
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析驱动的组织
- en: 'A data analysis–driven organization is one in which data analysts play a central
    role in decision making. It is important to note that whether an organization
    is analyst driven is not a black-and-white issue but rather a spectrum of overlapping
    characteristics:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析驱动的组织是一种数据分析师在决策制定中扮演核心角色的组织。需要注意的是，一个组织是否以分析为驱动力不是非黑即白的问题，而是一系列重叠特征的谱系：
- en: Mature industry
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 成熟的行业
- en: These organizations are well-known and established businesses with well-established
    (and perhaps outdated) systems. The industry in which they operate is typically
    mature and stable. The primary work involves human analysis of a variety of products
    or situations. Canonical examples of data analysis–driven organizations are the
    merchandising units of retailers (e.g., Walmart) and commercial loan processing
    divisions of large banks (e.g., JPMorgan Chase).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组织是知名的、成熟的企业，拥有已经建立（可能是过时的）系统。它们所处的行业通常是成熟且稳定的。主要工作涉及对各种产品或情况进行人工分析。典型的以数据分析驱动为例的组织包括零售商的商品销售部门（例如沃尔玛）和大型银行的商业贷款处理部门（例如摩根大通）。
- en: Enterprise DWH (EDW) and batch ETL
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 企业数据仓库（EDW）和批量ETL
- en: In technical terms, the central information hub is an EDW that has been built
    over time with a high level of technical debt and legacy technology. The transformation
    of data within the DWH is carried out through scheduled ETL processes such as
    nightly batches. This batch process adds to the latency of serving the data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术术语上，中央信息枢纽是一种随时间建立起来的企业数据仓库，具有高度的技术债务和遗留技术。在数据仓库内部的数据转换通过诸如夜间批处理等定期ETL过程来完成。这种批处理过程增加了数据服务的延迟。
- en: Business intelligence
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 商业智能
- en: The majority of data professionals in the organization are accustomed to answering
    business questions by running SQL queries against a centralized DWH, creating
    reports and dashboards using BI tools, and using spreadsheets to access similar
    data. As a result, the internal talent pool is most comfortable with SQL, BI tools,
    and spreadsheets.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 组织中的大多数数据专业人员习惯于通过在集中式数据仓库运行 SQL 查询来回答业务问题，使用 BI 工具创建报告和仪表板，并使用电子表格访问类似的数据。因此，内部人才库最熟悉
    SQL、BI 工具和电子表格。
- en: Note that even in mature industries such as retail and finance, emerging digital
    organizations (ecommerce and fintech) may seek to capture the fastest-growing
    digital areas and customer segments with the greatest potential. Such digital
    natives may have a different workforce composition than established players (e.g.,
    Etsy versus Walmart; Paytm versus JPMorgan Chase); we wouldn’t put digital natives
    in the same category as established players.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，即使在零售和金融等成熟行业中，新兴的数字化组织（电子商务和金融科技）可能会寻求捕捉增长最快的数字领域和潜力最大的客户群体。这些数字原住民可能与成熟的参与者（例如Etsy与沃尔玛；Paytm与摩根大通）有不同的工作人员构成；我们不会将数字原住民归类为成熟的参与者。
- en: Now that you have a clearer view of what we mean by analysis-driven organizations,
    let’s discuss the main levers to pull for the transformation.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你对我们所说的以分析驱动的组织有了更清晰的认识，让我们讨论转型的主要杠杆。
- en: The Vision
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视野
- en: To democratize the use of a cloud data platform in an analysis-driven organization,
    analysts should be able to do advanced analytics through familiar interfaces such
    as spreadsheets, SQL, and BI tools. This means providing easy-to-use tools for
    bringing data into the target system and seamless connectivity to analysis and
    visualization tools.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要在以分析驱动的组织中民主化使用云数据平台，分析师应能够通过熟悉的界面（如电子表格、SQL 和 BI 工具）进行高级分析。这意味着提供易于使用的工具，将数据带入目标系统，并无缝连接到分析和可视化工具。
- en: This was once common practice with traditional EDWs. Data was enriched, transformed,
    and cleansed using SQL, and ETL tools were used to orchestrate the process. Similarly,
    materialized views and user-defined functions can be used to enrich, transform,
    and cleanse data in a modern DWH.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这曾经是传统数据仓库的常见做法。使用 SQL 对数据进行丰富化、转换和清洗，使用 ETL 工具来编排流程。同样，物化视图和用户定义函数可以用来在现代数据仓库中丰富、转换和清洗数据。
- en: However, this assumes that the analyst already has access to all the data sources.
    Creating complex ingestion pipelines used to be costly and often cumbersome. Therefore,
    data pipelines were managed outside of the DWH due to resource and cost constraints.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这假设分析师已经可以访问所有数据源。创建复杂的摄取管道曾经是昂贵且经常令人费力的。因此，由于资源和成本限制，数据管道在数据仓库之外进行管理。
- en: This is no longer the case with new cloud DWHs. The role of ingestion is now
    simply to bring data close to the cloud, and the transformation and processing
    part moves back to the cloud EDW. This leads to data being staged in a storage
    bucket or on a messaging system before being ingested into the cloud EDW.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这在新的云数据仓库中已不再适用。摄取的角色现在仅仅是将数据接近云端，转换和处理部分移回到云端数据仓库。这导致数据被暂存到存储桶或消息系统中，然后再被摄取到云端数据仓库中。
- en: All of this not only reduces the time required to make data available but also
    frees up data analysts to focus on looking for data insights using tools and interfaces
    that they are used to. Therefore, in the new world, ELT should replace ETL tooling—data
    analysts can use SQL orchestration tools such as dbt or Dataform to string together
    SQL statements to carry out ELT. Ingesting data directly from a source or staging
    area allows analysts to exploit their key SQL skills and also increases the timeliness
    of the data they receive. They don’t need to wait for a swamped data engineering
    team to implement ETL pipelines.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些不仅可以减少使数据可用所需的时间，还可以释放数据分析师专注于使用他们习惯的工具和界面寻找数据洞察。因此，在新世界中，应该使用 ELT 取代 ETL
    工具——数据分析师可以使用 SQL 编排工具如 dbt 或 Dataform 来串联 SQL 语句执行 ELT。直接从源或暂存区摄取数据允许分析师利用他们关键的
    SQL 技能，并提高他们接收数据的及时性。他们不需要等待被淹没的数据工程团队实施 ETL 管道。
- en: In conclusion, the best way to scale the use of a cloud data platform is to
    provide analysts with easy-to-use tools (such as dbt) and interfaces (such as
    Excel or Tableau) that they can easily become proficient in. This will enable
    them to do advanced analytics without having to wait for data engineering teams
    to implement complex ETL pipelines.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，扩展云数据平台的最佳方式是为分析师提供易于使用的工具（如 dbt）和界面（如 Excel 或 Tableau），他们可以轻松掌握。这将使他们能够进行高级分析，而不必等待数据工程团队实施复杂的
    ETL 管道。
- en: Once the data is available in the cloud EDW, it is time to begin the analysis.
    In the past, much data analysis was done using spreadsheets, but spreadsheets
    often struggle to handle the volume of data that needs to be analyzed in the new
    world. Even though Google Sheets and Excel have capabilities to connect live to
    DWHs, it is still somewhat clunky. We recommend that analysts be provided access
    to create visualizations and reports using modern BI tools that are capable of
    handling large datasets (e.g., Power BI, Tableau, or Looker).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据在云端数据仓库中可用，就是开始分析的时候了。过去，许多数据分析是通过电子表格完成的，但电子表格往往难以处理新世界中需要分析的大量数据。尽管 Google
    Sheets 和 Excel 具有连接实时到数据仓库的能力，但仍显得有些笨拙。我们建议分析师可以访问现代 BI 工具来创建可处理大数据集的可视化和报告（例如
    Power BI、Tableau 或 Looker）。
- en: The Personas
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人物角色
- en: The main roles in the data departments of analysis-driven organizations are
    data analysts, business analysts, and data engineers.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 分析驱动型组织中数据部门的主要角色包括数据分析师、业务分析师和数据工程师。
- en: Data analysts
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据分析师
- en: '*Data analysts* receive, understand, and fulfill requests from the business
    and make sense of the relevant data. Data analysts aim to meet the information
    needs of their organizations. They are responsible for the logical design and
    maintenance of data. Some of their tasks may include creating layouts and designs
    for tables to meet business processes as well as reorganizing and transforming
    data sources. Additionally, they are responsible for generating reports and insights
    that effectively communicate trends, patterns, or predictions that the business
    requests.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据分析师*接收、理解并完成来自业务的请求，并理解相关数据。数据分析师旨在满足组织的信息需求。他们负责数据的逻辑设计和维护。他们的一些任务可能包括创建表的布局和设计以满足业务流程，以及重新组织和转换数据源。此外，他们还负责生成有效传达业务请求的趋势、模式或预测的报告和洞察。'
- en: To build the mission for the analysis-driven organizations, it is necessary
    to expand the experience and skill set of the data analyst community in two ways.
    First, it is critical to promote the trend of data analysts learning about the
    business. Data analysts need to acquire a deep knowledge of business domains.
    Second, data analysts need to acquire the technical skills to analyze and depict
    data regardless of its volume or size. Fortunately, this is now possible using
    SQL and BI tools. The expansion of the skills of data analysts into the business
    and into big data is depicted in [Figure 3-3](#data_analyst_domain_expansions_for_the).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要建立面向分析驱动型组织的任务，有必要以两种方式扩展数据分析师社区的经验和技能集。首先，促进数据分析师学习业务的趋势至关重要。数据分析师需要深入了解业务领域。其次，数据分析师需要获取分析和描述数据的技术技能，无论数据的容量或大小如何，使用SQL和BI工具现在都是可能的。数据分析师的技能扩展到业务和大数据领域在[图3-3](#data_analyst_domain_expansions_for_the)中有所体现。
- en: '![Data analyst domain expansions for the development of a data-driven strategy](assets/adml_0303.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![数据分析师领域扩展，用于数据驱动策略的开发](assets/adml_0303.png)'
- en: Figure 3-3\. Data analyst domain expansions for the development of a data-driven
    strategy
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-3\. 数据分析师领域扩展，用于数据驱动策略的开发
- en: Business analysts
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 业务分析师
- en: '*Business analysts* are domain experts who use data to act on analytical insights.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*业务分析师*是使用数据来执行分析洞察的领域专家。'
- en: Cloud-based DWHs and serverless technologies have expanded the responsibilities
    of business analysts into what was traditionally the realm of domain experts.
    This is because analysts can now focus on adding value to the business by analyzing
    data, rather than wasting time on administrative and technical management tasks.
    Additionally, the volume and type of data that can be stored in a DWH is no longer
    a limitation, so analysts can now go deeper into the business to find insights.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 云数据仓库（Cloud-based DWHs）和无服务器技术已将业务分析师的责任扩展到传统上领域专家的范围之外。这是因为分析师现在可以专注于通过分析数据为业务增加价值，而不是浪费时间在行政和技术管理任务上。此外，可以存储在数据仓库中的数据的数量和类型不再是限制因素，因此分析师现在可以更深入地挖掘业务，寻找洞察。
- en: The DWH can function as both a landing area for data and a system of record
    for both structured and semistructured data. This means that business analysts
    have all the data they need to analyze in one place. Overall, cloud-based DWHs
    and serverless technologies have made it possible for business analysts to be
    more productive and to add more value to the business.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 数据仓库既可以作为数据的登陆区域，也可以作为结构化和半结构化数据的记录系统。这意味着业务分析师可以在一个地方获取所有需要分析的数据。总体而言，云数据仓库和无服务器技术使得业务分析师能够更加高效，并为业务增加更多的价值。
- en: While business analysts can do no-code and low-code ML models, they will struggle
    with more complex workflows that involve ML or natural language text. They will
    also not have the skills to implement sophisticated data science algorithms such
    as for ranking or recommendations. Therefore, you will still need a data science
    team if your activation needs are more complex.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管业务分析师可以进行无代码和低代码的机器学习模型，但他们在涉及机器学习或自然语言文本的更复杂工作流程中可能会遇到困难。他们也没有实施复杂的数据科学算法（例如排名或推荐）的技能。因此，如果您的激活需求更复杂，仍然需要一个数据科学团队。
- en: Data engineers
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据工程师
- en: '*Data engineers* focus on the downstream data pipeline and the first phases
    of data transformation, such as loading and integrating new sources. They also
    manage data governance and data quality processes.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据工程师* 专注于下游数据管道和数据转换的最初阶段，如加载和集成新来源。他们还管理数据治理和数据质量流程。'
- en: 'In an analysis-driven organization, the number of data engineers will be small
    because the data analyst teams will be largely self-sufficient and capable of
    building simple data pipelines and ML models. Analysis-driven organizations embrace
    the concept of ELT rather than traditional ETL. The main difference is that the
    common data processing tasks are handled after the data is loaded to the DWH.
    ELT makes extensive use of SQL logic to enhance, cleanse, normalize, refine, and
    integrate data and make it ready for analysis. There are several benefits of such
    an approach: it reduces time to act, data is loaded immediately, and it is made
    available to multiple users concurrently. Therefore, a change management strategy
    for such an organization has to focus on aspects such as SQL, views, functions,
    scheduling, etc.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个以分析为驱动的组织中，数据工程师的人数将会很少，因为数据分析团队基本上可以自给自足，能够构建简单的数据管道和机器学习模型。分析驱动的组织采用ELT而非传统的ETL的概念。主要区别在于，常见的数据处理任务在数据加载到数据仓库后处理。ELT大量使用SQL逻辑来增强、清洗、规范化、精炼和整合数据，使其准备好进行分析。这种方法有几个好处：缩短行动时间，数据立即加载，并可同时提供给多个用户使用。因此，这样的组织的变更管理策略必须关注SQL、视图、函数、调度等方面。
- en: 'Even in an analysis-driven organization, data engineering teams generally control
    extraction of data from source systems. While this can be made easier through
    the use of SQL-based tools, enabling data analysts to do some of that work, you
    still need a solid data engineering team. There are batch jobs that would still
    require creating data pipelines and that would be more suitable for ETL. For example,
    bringing data from a mainframe to a DWH would require additional processing steps:
    data types need to be mapped, COBOL books need to be converted, and so on.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在一个以分析为驱动的组织中，数据工程团队通常控制从源系统提取数据的过程。虽然可以通过使用基于SQL的工具来简化这一过程，使数据分析师能够完成部分工作，但你仍然需要一个强大的数据工程团队。还有一些批处理作业仍然需要创建数据管道，更适合使用ETL。例如，将数据从主机到数据仓库需要额外的处理步骤：需要映射数据类型，需要转换COBOL书籍等等。
- en: In addition, for use cases like real-time analytics, the data engineering teams
    will configure the streaming data sources such as Pub/Sub or Kafka topics or Kinesis
    Data Streams. The way that you deal with generic tasks is still the same—they
    can be written as generic ETL pipelines and then reconfigured by the analysts.
    For example, applying data quality validation checks from various source datasets
    to the target environment will follow a template set up by a data engineer.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于实时分析等用例，数据工程团队将配置流数据源，如Pub/Sub或Kafka主题或Kinesis数据流。处理通用任务的方式仍然相同——可以将它们编写为通用的ETL管道，然后由分析师重新配置。例如，从各种源数据集应用数据质量验证检查到目标环境将遵循数据工程师设置的模板。
- en: The Technological Framework
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术框架
- en: 'There are three fundamental principles underlying the high-level reference
    architecture for an analysis-driven organization:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一个以分析为驱动的组织的高级参考架构有三个基本原则：
- en: SQL as a standard
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: SQL作为标准
- en: Technology should be tailored to the current organizational culture. Components
    that offer a SQL interface should be prioritized, regardless of where they are
    in the data processing pipeline.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 技术应根据当前的组织文化进行定制。无论数据处理流程中的位置如何，都应优先考虑提供SQL接口的组件。
- en: From EDW/data lake to a structured data lake
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 从EDW/数据湖到结构化数据湖
- en: Information systems infrastructure and its data should be integrated to expand
    the possibilities of analytical processing on new and diverse data sources. This
    may involve merging a traditional DWH with a data lake to eliminate silos (more
    on the lakehouse architecture in [Chapter 7](ch07.html#converging_to_a_lakehouse)).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 信息系统基础设施及其数据应该集成，以扩展对新的和多样化数据源的分析处理的可能性。这可能涉及将传统的数据仓库与数据湖合并，以消除数据孤岛（有关lakehouse架构的更多信息，请参见[第7章](ch07.html#converging_to_a_lakehouse)）。
- en: '*Schema-on-read* first approach'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 先读后模式（Schema-on-read）
- en: Due to the low cost of storage, your organization no longer needs to impose
    rigid rules on data structures before data is received. Moving away from a schema-on-write
    to a schema-on-read model allows for real-time access to data. Data can be kept
    in its raw form and then transformed into the schema that will be most useful.
    Additionally, the data platform can manage the process of keeping these copies
    in sync (for example, using materialized views, change data capture, etc.). Therefore,
    do not be afraid to keep multiple copies of the same data assets.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 由于存储成本低廉，您的组织在数据接收前不再需要强加严格的数据结构规则。从写入模式的模式转变为读取模式的模式允许实时访问数据。数据可以保留其原始形式，然后转换为最有用的模式。此外，数据平台可以管理保持这些副本同步的过程（例如，使用物化视图、变更数据捕获等）。因此，请放心保留多份相同数据资产的副本。
- en: 'Combining these principles, we can define a high-level architecture like the
    one shown in [Figure 3-4](#a_high_level_informational_architecture). This informational
    architecture satisfies the three principles listed above and supports a few key
    data analysis patterns:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 结合这些原则，我们可以定义一个高层架构，类似于[图 3-4](#a_high_level_informational_architecture)所示的架构。此信息架构满足上述三个原则，并支持几种关键的数据分析模式：
- en: The “traditional” BI workloads, such as creating a dashboard or report
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “传统”的BI工作负载，例如创建仪表板或报告
- en: An ad hoc analytics interface that allows for the management of data pipelines
    through SQL (ELT)
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种临时分析接口，允许通过SQL（ELT）管理数据流水线。
- en: Enabling data science use cases with ML techniques
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ML技术启用数据科学用例
- en: Real-time streaming of data into the DWH and processing of real-time events
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据实时流入DWH并处理实时事件
- en: '![A high-level informational architecture for the analysis-driven organization](assets/adml_0304.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![用于分析驱动型组织的高层信息架构](assets/adml_0304.png)'
- en: Figure 3-4\. A high-level informational architecture for the analysis-driven
    organization
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. 用于分析驱动型组织的高层信息架构
- en: The first two patterns are quite similar to the traditional SQL data warehousing
    world, but the last two present innovations in the form of SQL abstractions for
    more advanced analytical patterns. In the realm of ML, Redshift ML or BigQuery
    ML allows data analysts to execute ML models on data stored in the DWH using standard
    SQL queries. SQL streaming extensions such as Dataflow and KSQL enable aggregating
    data streams with unbounded, real-time sources such as Pub/Sub or Kafka. This
    technology enables a world of possibilities, even without the need to invest in
    new profiles and/or roles.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 前两种模式与传统的SQL数据仓库世界非常相似，但后两种则以SQL抽象的形式提供了更先进的分析模式创新。在ML领域，Redshift ML或BigQuery
    ML允许数据分析师在DWH中存储的数据上执行ML模型，使用标准SQL查询。诸如Dataflow和KSQL之类的SQL流扩展使得能够聚合数据流，与无边界、实时源（如Pub/Sub或Kafka）一起。这项技术使得即使无需投资于新的概要文件和/或角色，也能实现许多可能性。
- en: Data preparation and transformation are key considerations when choosing between
    ELT and ETL for an analysis-driven organization. ELT should be used whenever possible,
    as it allows data to be transformed in the structured data lake using SQL. This
    approach offers the same functionality as extensive data integration suites but
    without the need to sacrifice data quality or operations monitoring. Products
    such as dbt bring a software engineering approach to data modeling and building
    data workflows; dbt effectively allows building ELT workflows similar to ETL workflows
    built by code, but instead using SQL. This allows data analysts (who are not systems
    programmers) to carry out reliable and sophisticated data transformations.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在为分析驱动型组织选择ELT和ETL时，数据准备和转换是关键考虑因素。尽可能使用ELT，因为它允许使用SQL在结构化数据湖中进行数据转换。此方法提供了与广泛的数据集成套件相同的功能，但无需牺牲数据质量或操作监控。像dbt这样的产品为数据建模和构建数据工作流程带来了软件工程方法；dbt有效地允许构建类似于代码构建的ETL工作流程的ELT工作流程，但是使用SQL而不是系统程序员。这使得数据分析师（不是系统程序员）能够进行可靠和复杂的数据转换。
- en: In simpler terms, ELT is a better option than ETL for analysis-driven organizations
    because it allows for more flexibility and control over data transformation. Additionally,
    dbt provides a software engineering approach to data modeling and building data
    workflows, which can help to improve the reliability and sophistication of data
    transformations.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，对于分析驱动型组织，ELT比ETL更好，因为它允许更灵活和控制数据转换。此外，dbt为数据建模和构建数据工作流程提供了软件工程方法，有助于提高数据转换的可靠性和复杂性。
- en: Data Engineering–Driven Organization
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据工程驱动的组织
- en: An engineering-driven organization is focused on data integration. There are
    companies (e.g., Plaid in fintech) whose business is to build integration pipelines
    for an entire industry. More commonly, this is a team that is part of a larger
    business. For example, an investment firm might have a team whose job is to discover,
    reformat, and ingest financial (e.g., stock market, companies’ SEC filings, etc.)
    and alternative (e.g., credit card spend, e-receipts, retail footfall, etc.) data
    from a large number of vendors.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以工程为驱动的组织专注于数据集成。有些公司（例如金融科技领域的 Plaid）的业务就是为整个行业构建集成管道。更常见的情况是这是一个大型企业的一部分。例如，投资公司可能有一个团队，负责从大量供应商那里发现、重新格式化和摄取财务（例如股票市场、公司的
    SEC 报告等）和替代（例如信用卡消费、电子收据、零售店客流等）数据。
- en: The Vision
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视野
- en: When your data transformation needs are complex, you need data engineers to
    play a central role in the company’s data strategy to ensure that you can build
    reliable systems cost-effectively. Data engineers are at the crossroads between
    data owners and data consumers*.*
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的数据转换需求复杂时，您需要数据工程师在公司的数据战略中扮演核心角色，以确保能够经济有效地构建可靠的系统。数据工程师处于数据所有者和数据消费者之间的交叉点。
- en: The business data owner is the designated point of contact for business teams
    that know the business and provide data for the data architecture. Data consumers
    are focused on extracting insights from the different data available in the architecture.
    Here you typically find data science teams, data analysts, BI teams, etc. These
    groups sometimes combine data from different business units and produce artifacts
    (ML models, interactive dashboards, reports, and so on). For deployment, they
    require the help of the data engineering team so that data is consistent and trusted.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 业务数据所有者是业务团队的指定联系点，了解业务并为数据架构提供数据。数据消费者专注于从架构中的不同数据中提取洞察力。在这里，您通常会找到数据科学团队、数据分析师、BI
    团队等。这些团队有时会将来自不同业务单位的数据合并，并生成成果物（机器学习模型、交互式仪表板、报告等）。在部署时，他们需要数据工程团队的帮助，以确保数据一致和可信任。
- en: 'Data engineers have the following responsibilities:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师有以下职责：
- en: Transporting data and enriching data while building integrations between analytical
    systems and operational systems (as in the real-time use cases).
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在建立分析系统和操作系统之间的集成时，传输数据并丰富数据（例如实时使用案例）。
- en: Parsing and transforming messy data coming from business units and external
    suppliers into meaningful and clean data, with documented metadata.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从业务单位和外部供应商那里解析和转换杂乱的数据，使其成为有意义且干净的数据，并记录元数据。
- en: Applying DataOps—that is, functional knowledge of the business plus software
    engineering methodologies applied to the data lifecycle. This includes monitoring
    and maintenance of data feeds.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用数据运营（DataOps），即将业务的功能知识与应用于数据生命周期的软件工程方法相结合。这包括监控和维护数据源。
- en: Deploying ML models and other data science artifacts analyzing or consuming
    data.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署机器学习模型和其他数据科学成果来分析或消费数据。
- en: 'Building complex data engineering pipelines is expensive but enables increased
    capabilities:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 构建复杂的数据工程管道是昂贵的，但可以增强能力：
- en: Enrichment
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Enrichment
- en: Data engineers create processes to collect data from different sources and combine
    it to create a more valuable dataset. This data can then be used to make better
    decisions.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师创建流程，从不同来源收集数据并将其组合以创建更有价值的数据集。这些数据随后可以用于做出更好的决策。
- en: Training datasets
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集
- en: The quality of ML models is largely driven by the data used to train those models.
    By bringing in data from multiple sources and unifying them into datasets ready
    for training ML models, data engineers can increase the productivity of data science
    teams.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的质量很大程度上取决于用于训练这些模型的数据。通过从多个来源获取数据并统一到准备用于训练机器学习模型的数据集中，数据工程师可以提高数据科学团队的生产力。
- en: Unstructured data
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 非结构化数据
- en: When the ML models need to use unstructured data (such as review text or images),
    there are special challenges. Such data usually doesn’t follow a strict schema
    as a traditional DWH would use. In addition, it needs to be scrubbed of PII (such
    as telephone numbers in chat transcripts) and unsafe-for-work content (especially
    images) and transformed (e.g., using embeddings).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当机器学习模型需要使用非结构化数据（例如评论文本或图像）时，会面临特殊挑战。这类数据通常不像传统的数据仓库使用的严格模式那样遵循严格的模式。此外，它需要清除个人身份信息（例如聊天记录中的电话号码）和不适合工作的内容（特别是图像），并进行转换（例如使用嵌入）。
- en: Productionization
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Productionization
- en: Data engineering work is also required to productionize and get value from ad
    hoc data science work. Without data engineering, data scientists will be stuck
    carrying out experiments and producing applications that work for specific use
    cases but are rarely productionized or generalized.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程工作也需要将临时数据科学工作进行产品化，并从中获取价值。没有数据工程支持，数据科学家将被困在实验和针对特定用例制作的应用程序中，这些应用程序很少能够进行产品化或泛化。
- en: Real-time analytics
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 实时分析
- en: Applications such as anomaly detection and fraud prevention require immediate
    responses. In such use cases, data consumers need to process information as data
    arrives on the fly. They have to do so with low latency. This type of real-time
    analytics requires transformation done outside of the target DWH.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测和欺诈预防等应用需要立即响应。在这些用例中，数据消费者需要在数据即时到达时进行处理。他们必须在低延迟下执行。这种实时分析需要在目标数据仓库之外进行转换。
- en: All the preceding usually requires custom applications or state-of-the art tooling.
    In reality, there are very few organizations whose engineering capabilities excel
    to such a degree that they can truly be called engineering organizations. Many
    fall into what we call a blended organization (see [Figure 3-2](#data_processing_persona_framework)).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 前面提到的所有内容通常需要定制应用程序或最先进的工具。实际上，很少有组织的工程能力能够达到真正的工程组织水平。许多组织处于我们所说的混合组织中（见[图 3-2](#data_processing_persona_framework)）。
- en: The Personas
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人物角色
- en: Data engineers develop and optimize all the processes needed to get access to
    the data and the solutions needed to perform related analysis and generate reports.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师开发和优化所有需要获取数据以及执行相关分析并生成报告的过程。
- en: Knowledge
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 知识
- en: 'The data engineering role requires a deep understanding of databases and programming
    languages, along with certain business skills to work across departments. Regardless
    of the size of the organization they are working in, data engineers need to have
    some standard skills to be successful. The most valuable knowledge includes:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程角色需要对数据库和编程语言有深入理解，同时具备跨部门工作所需的某些业务技能。无论他们所在的组织规模如何，数据工程师都需要具备某些标准技能才能成功。最有价值的知识包括：
- en: Data warehousing and data lake solutions
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 数据仓库和数据湖解决方案
- en: Cloudera Data Platform, Oracle Exadata, Amazon RedShift, Azure Synapse, Google
    BigQuery, Snowflake, Databricks, Hadoop ecosystem, etc., where data engineers
    can handle huge volumes of data.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Cloudera数据平台、Oracle Exadata、Amazon RedShift、Azure Synapse、Google BigQuery、Snowflake、Databricks、Hadoop生态系统等，数据工程师可以处理海量数据。
- en: Database systems
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库系统
- en: Database systems like SQL and NoSQL. They should know how to work on and manipulate
    RDBMSs for information storage and retrieval.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 像SQL和NoSQL这样的数据库系统。他们应该知道如何在和操作关系数据库管理系统以进行信息存储和检索。
- en: ETL tools
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ETL工具
- en: Both traditional tools such as Informatica and Ab Initio and modern frameworks
    such as Apache Beam, Spark, and Kafka.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 传统工具如Informatica和Ab Initio，以及现代框架如Apache Beam、Spark和Kafka。
- en: Programming languages
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 编程语言
- en: Python, Java, Scala.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Python、Java、Scala。
- en: Data structures and algorithms
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 数据结构与算法
- en: Data structures and algorithms allow organizing and storing data for easy access
    and manipulation, making this an essential skill for data engineers.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 数据结构与算法允许组织和存储数据以便于访问和操作，这对数据工程师来说是一项至关重要的技能。
- en: Automation and scripting
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化与脚本编写
- en: Data engineers should be able to write scripts to automate repetitive tasks
    since they have to deal with such huge amounts of data (e.g., bash, PowerShell,
    HashiCorp Terraform, Ansible, etc.).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师应该能够编写脚本来自动化重复的任务，因为他们必须处理如此庞大的数据量（例如，bash、PowerShell、HashiCorp Terraform、Ansible等）。
- en: Container technology
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 容器技术
- en: The de facto standard for moving data projects to production. Projects developed
    on a local machine can be “shipped” to a staging and production cluster (typically)
    with no issues. Data pipelines and ML models are reproducible and can run anywhere
    in the same fashion.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据项目移至生产的事实标准。在本地机器上开发的项目可以“发布”到分级和生产集群（通常）而无需问题。数据管道和ML模型可复制，并可以在任何地方以相同的方式运行。
- en: Orchestration platforms
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 编排平台
- en: Because of the proliferation of solutions and tools that need to be integrated
    to perform data engineering tasks, orchestration tools like Apache Airflow have
    become mandatory.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于需要集成的解决方案和工具的激增，像Apache Airflow这样的编排工具已成为必需品。
- en: 'Certifications measure a data engineer’s knowledge and proficiency against
    vendor and/or industry benchmarks, confirming that the individual has the necessary
    expertise to contribute to your enterprise data strategies. Examples are AWS Certified
    Data Analytics, Cloudera Certified Professional (CCP) Data Engineer, Google Professional
    Data Engineer, and Microsoft Certified: Azure Data Engineer Associate.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 认证衡量数据工程师的知识和熟练程度，与供应商和/或行业标准进行比较，确认个人具备必要的专业知识，能够为企业的数据战略做出贡献。例如，AWS认证数据分析师、Cloudera认证专业（CCP）数据工程师、Google专业数据工程师和Microsoft认证：Azure数据工程师助理。
- en: Responsibilities
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 职责
- en: 'Data engineers are responsible for making sure that the data generated and
    needed by different business units gets ingested into the architecture. This job
    requires two disparate skills: functional knowledge and data engineering/software
    development skills. This skill set is often described using the term *DataOps*
    (which evolved from DevOps methodologies developed within the past decades but
    applied to data engineering practices).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师负责确保由不同业务部门生成和需要的数据被摄入到架构中。这项工作需要两种不同的技能：功能知识和数据工程/软件开发技能。这种技能组合通常被称为*DataOps*（它源自过去几十年内开发的DevOps方法论，但应用于数据工程实践中）。
- en: 'Data engineers have another responsibility, too. They must help with the deployment
    of artifacts produced by the data consumers. Typically, the data consumers do
    not have the deep technical skills and knowledge to take the sole responsibility
    for deployment of their artifacts. This is also true for highly sophisticated
    data science teams. So data engineers must add other skills under their belt:
    ML and business intelligence platform knowledge. Let’s clarify this point: we
    don’t expect data engineers to become ML engineers. ML engineering is the process
    of deploying ML models developed by data scientists into live production systems.
    Data engineers, on the other hand, build the infrastructure that others use to
    work on data, such as data storage and data transportation. Data engineers need
    to understand ML to ensure that the data delivered to the first layer of a model
    (the input) is correct. They will also become key when delivering that first layer
    of data in the inference path, as here the data engineering skills around scale,
    high availability, etc., really need to shine.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师还有另一个责任。他们必须帮助部署由数据消费者生成的产品。通常，数据消费者没有深厚的技术技能和知识来单独负责其产品的部署。这对高度复杂的数据科学团队同样适用。因此，数据工程师必须掌握其他技能，如机器学习和业务智能平台知识。让我们澄清这一点：我们不指望数据工程师成为机器学习工程师。机器学习工程是将数据科学家开发的机器学习模型部署到实时生产系统的过程。另一方面，数据工程师建立的基础设施是供他人处理数据使用的，比如数据存储和数据传输。数据工程师需要理解机器学习，以确保传递给模型的第一层数据（输入）是正确的。在推断路径中，当数据工程技能如规模化和高可用性真正需要发挥作用时，他们也将成为关键。
- en: By taking the responsibility of parsing and transforming messy data from various
    business units, or for ingesting in real time, data engineers allow the data consumers
    to focus on creating value. Data scientists and other types of data consumers
    are abstracted away from data encodings, large files, legacy systems, and complex
    message queue configurations for streaming. The benefits of concentrating that
    knowledge in a highly skilled data engineering team are clear, notwithstanding
    that other teams (business units and consumers) may also have their data engineers
    to work as interfaces with other teams. More recently, we’ve even seen squads
    created with members of the business units (data product owners), data engineers,
    data scientists, and other roles. This effectively creates complete teams with
    autonomy and full responsibility over a data stream, from the incoming data down
    to the data-driven decisions that impact the business.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通过负责解析和转换来自各业务部门的混乱数据，或者实时摄入，数据工程师让数据消费者能够专注于创造价值。数据科学家和其他类型的数据消费者不需要关注数据编码、大文件、传统系统和复杂的消息队列配置以进行流处理。将这种知识集中在高技能的数据工程团队中的好处是显而易见的，尽管其他团队（业务部门和消费者）也可能有他们的数据工程师作为与其他团队交互的接口。最近，我们甚至看到创建了由业务单元成员（数据产品负责人）、数据工程师、数据科学家和其他角色组成的小组。这有效地创建了完整团队，拥有从传入数据到影响业务的数据驱动决策的全权负责权。
- en: The Technological Framework
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术框架
- en: The data engineering team already requires a wide range of skills. Do not make
    their job more difficult by expecting them to also maintain the infrastructure
    where they run data pipelines. Data engineers should focus on how to clean, transform,
    enrich, and prepare the data, rather than on how much memory or how many cores
    their solution may require.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程团队已经需要广泛的技能。不要让他们的工作变得更加困难，期望他们还能维护运行数据管道的基础设施。数据工程师应该专注于如何清理、转换、增强和准备数据，而不是关注他们的解决方案可能需要多少内存或多少核心。
- en: Reference architectures
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参考架构
- en: The ingestion layer is made up of Kinesis, Event Hubs, or Pub/Sub for real-time
    data and S3, Azure Data Lake, or Cloud Storage for batch data (see Figures [3-5](#example_data_engineering_driven_archit),
    [3-6](#example_data_engineering_driven_archi), and [3-7](#example_data_engineering_driven_archite)).
    It does not need any preallocated infrastructure. All of these solutions can be
    used for a variety of cases since they can automatically scale up to meet the
    demands of the input workload.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 摄取层由 Kinesis、Event Hubs 或 Pub/Sub 处理实时数据，而 S3、Azure 数据湖或 Cloud Storage 处理批量数据（参见图
    [3-5](#example_data_engineering_driven_archit)、[3-6](#example_data_engineering_driven_archi)
    和 [3-7](#example_data_engineering_driven_archite)）。它不需要任何预分配的基础设施。所有这些解决方案都可以用于各种情况，因为它们可以自动扩展以满足输入工作负载的需求。
- en: '![](assets/adml_0305.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/adml_0305.png)'
- en: Figure 3-5\. Example data engineering–driven architecture on Google Cloud
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5\. Google Cloud 上的示例数据工程驱动架构
- en: '![](assets/adml_0306.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/adml_0306.png)'
- en: Figure 3-6\. Example data engineering–driven architecture on AWS
  id: totrans-122
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-6\. AWS 上的示例数据工程驱动架构
- en: '![](assets/adml_0307.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/adml_0307.png)'
- en: Figure 3-7\. Example data engineering–driven architecture on Azure
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-7\. Azure 上的示例数据工程驱动架构
- en: Once the data has been collected, our proposed architecture follows the traditional
    three-step process of extract, transform, and load (ETL). For certain types of
    files, direct loading into Redshift, Synapse, or BigQuery (using an ELT approach)
    is also feasible.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据被收集，我们提议的架构遵循传统的提取、转换和加载（ETL）三步流程。对于某些类型的文件，也可以采用直接加载到 Redshift、Synapse
    或 BigQuery（使用 ELT 方法）的方式。
- en: In the transform layer, we primarily recommend Apache Beam as the data processing
    component because of its unified model for batch and streaming processing. Runners
    for Apache Beam include Cloud Dataflow on GCP and any managed Flink or Spark implementation
    on the other hyperscalers.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在转换层，我们主要推荐 Apache Beam 作为数据处理组件，因为其批处理和流处理的统一模型。Apache Beam 的执行器包括 GCP 上的 Cloud
    Dataflow，以及其他超大规模服务商上任何托管的 Flink 或 Spark 实现。
- en: An alternative to Dataflow in this architecture is using a Spark-based solution
    such as Amazon EMR, Databricks, Azure HDInsight, or Google Dataproc. However,
    these solutions are not serverless, and running Spark clusters idle is a major
    cost. Having said that, there are also serverless Spark alternatives that are
    provided as part of AWS SageMaker/Glue and as a service with GCP Serverless Spark.
    The main use case is for those teams that already have large amounts of code in
    Spark or Hadoop. These Spark solutions enable a direct path to the cloud without
    having to review all those pipelines.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种架构中，Dataflow 的替代方案是使用基于 Spark 的解决方案，如 Amazon EMR、Databricks、Azure HDInsight
    或 Google Dataproc。然而，这些解决方案并非无服务器，运行闲置的 Spark 集群是一笔主要成本。话虽如此，也有提供作为 AWS SageMaker/Glue
    的一部分和 GCP 无服务器 Spark 服务的无服务器 Spark 替代方案。主要用例是那些已经在 Spark 或 Hadoop 中拥有大量代码的团队。这些
    Spark 解决方案使得直接通向云的路径成为可能，而无需审查所有这些管道。
- en: Another alternative for data processing is a codeless environment for creating
    data pipelines using a drag-and-drop interface, such as that provided by AWS Glue,
    Azure Data Factory, or GCP Data Fusion. Traditional ETL tools such as Informatica,
    Ab Initio, and Talend also run in serverless mode in the cloud with underlying
    Kubernetes clusters. Some of these tools use either Hadoop/Spark solutions or
    similar proprietary compute engines behind the scenes, so everything we have mentioned
    earlier applies also to the case of the ETL tools. If your team prefers to create
    data pipelines without having to write any code, graphical ETL tools are the right
    choice.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个数据处理的选择是使用无代码环境来创建数据管道，例如由 AWS Glue、Azure Data Factory 或 GCP Data Fusion
    提供的拖放界面。传统的 ETL 工具如 Informatica、Ab Initio 和 Talend 也在云中以无服务器模式运行，底层使用 Kubernetes
    集群。其中一些工具使用 Hadoop/Spark 解决方案或类似的专有计算引擎，因此我们之前提到的所有内容也适用于 ETL 工具的情况。如果您的团队希望创建数据管道而无需编写任何代码，图形化
    ETL 工具是正确的选择。
- en: Benefits of the reference architecture
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参考架构的优点
- en: The reference architectures presented in Figures [3-5](#example_data_engineering_driven_archit),
    [3-6](#example_data_engineering_driven_archi), and [3-7](#example_data_engineering_driven_archite)
    are based on a preference for serverless NoOps technologies and streaming pipelines.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Figures [3-5](#example_data_engineering_driven_archit)，[3-6](#example_data_engineering_driven_archi)，和[3-7](#example_data_engineering_driven_archite)中呈现的参考架构基于对无服务器NoOps技术和流式管道的偏好。
- en: By using serverless technology, you eliminate the maintenance burden from the
    data engineering team and provide the necessary flexibility and scalability for
    executing complex and/or large jobs. For example, scalability is essential when
    planning for traffic spikes during Black Friday for retailers. Using serverless
    solutions allows retailers to look into how they are performing during the day.
    They no longer need to worry about resources needed to process massive data generated
    during the day.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用无服务器技术，您可以将数据工程团队的维护负担减少，并为执行复杂和/或大型作业提供必要的灵活性和可扩展性。例如，在零售商的黑色星期五期间规划交通高峰时，可伸缩性是至关重要的。使用无服务器解决方案允许零售商查看他们在一天中的表现。他们不再需要担心处理白天产生的大量数据所需的资源。
- en: The reference architectures give the data engineering team the possibility to
    write fully custom code for the data pipelines. This may be because the parsing
    requirements can be complex and no off-the-shelf solution may work. In streaming,
    the team may want to implement complex business logic at a low latency. However,
    the team should try to reuse code by creating reusable libraries and by using
    technologies such as Dataflow templates. This brings the best of both worlds (reuse
    and rewrite) while saving precious time that can be dedicated to higher-impact
    code rather than common I/O tasks.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 参考架构使数据工程团队有可能为数据管道编写完全自定义的代码。这可能是因为解析要求可能很复杂，没有现成的解决方案可能适用。在流式处理中，团队可能希望以低延迟实施复杂的业务逻辑。但是，团队应通过创建可重用库和使用Dataflow模板等技术来尝试重用代码。这既带来了两者的最佳（重用和重写），同时节省了宝贵的时间，可以用于高影响代码而不是常见的I/O任务。
- en: 'The reference architectures presented have another important feature: the possibility
    to transform existing batch pipelines to streaming.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 呈现的参考架构还具有另一个重要特征：将现有的批处理管道转换为流式处理的可能性。
- en: Data Science–Driven Organization
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学驱动的组织
- en: A data science–driven organization is an entity that maximizes the value from
    the data available to create a sustainable competitive advantage. To do so, the
    organization leans on automated algorithms that often (but not always!) employ
    ML. Rather than rely on one-off reports and analytics as an analysis-driven organization
    would, a science-driven organization attempts to make decisions in an automated
    way. For example, a bank that is data analysis driven would have data analysts
    assess each commercial loan opportunity, build an investment case, and have an
    executive sign off on it. A data science–driven fintech, on the other hand, would
    build a loan approval system that makes decisions on the majority of loans using
    some sort of automated algorithm.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学驱动的组织是一种最大化从可用数据中获得价值以创造可持续竞争优势的实体。为此，组织依赖于通常（但并非总是！）采用ML的自动化算法。与依赖一次性报告和分析的分析驱动型组织不同，科学驱动型组织试图以自动化的方式做出决策。例如，一个以数据分析驱动的银行会让数据分析师评估每个商业贷款机会，建立投资案例，并由高管签署。另一方面，一个数据科学驱动的金融科技公司将建立一个贷款批准系统，该系统使用某种自动化算法来对大多数贷款做出决策。
- en: The Vision
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 愿景
- en: 'A science-driven organization is one that extracts the maximum value from its
    data and uses ML and analytics to gain a sustainable competitive advantage. When
    building such a data science team, there are some principles that should be followed:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学驱动的组织是从其数据中提取最大价值，并利用ML和分析获得可持续竞争优势的组织。在构建这样的数据科学团队时，应遵循一些原则：
- en: Adaptability
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 适应性
- en: A platform must be adaptable enough to accommodate all types of users. For instance,
    while some data scientists/analysts are more inclined to create their own models,
    others may prefer to use no-code solutions or conduct analyses in SQL. This also
    encompasses the availability of a variety of ML and data science tools such as
    TensorFlow, R, PyTorch, Beam, or Spark. The platform should also be open enough
    to function in multicloud and on-premises environments while supporting open source
    technology when possible to avoid lock-in effects. Finally, resources should never
    become a bottleneck, as the platform must be able to scale quickly to meet an
    organization’s needs.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 平台必须具有足够的灵活性，以适应所有类型的用户。例如，虽然一些数据科学家/分析师更倾向于创建自己的模型，但其他人可能更喜欢使用无代码解决方案或在SQL中进行分析。这还包括提供各种机器学习和数据科学工具，如TensorFlow、R、PyTorch、Beam或Spark。平台还应该足够开放，以在多云和本地环境中运行，同时在可能时支持开源技术，以避免锁定效应。最后，资源永远不应成为瓶颈，因为平台必须能够快速扩展以满足组织的需求。
- en: Standardization
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化
- en: Standardization increases a platform’s efficiency by making it easier to share
    code and technical artifacts. This improves communication between teams and boosts
    their performance and creativity. Standardization also enables data science and
    ML teams to work in a modular fashion, which is essential for efficient development.
    Standardization can be achieved by using standard connectors to connect to source/target
    systems. This avoids “technical debt,” which is common in ML and data science
    workflows.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化通过使代码和技术成果更易于共享来提高平台的效率。这提升了团队之间的沟通，增强了他们的表现和创造力。标准化还使数据科学和机器学习团队能够以模块化的方式工作，这对于高效的开发至关重要。通过使用标准连接器连接到源/目标系统可以实现标准化。这避免了在机器学习和数据科学工作流中常见的“技术债务”问题。
- en: Accountability
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 责任
- en: 'Data science and ML use cases often involve sensitive topics such as fraud
    detection, medical imaging, or risk calculation. As a result, it is critical that
    a data science and ML platform helps to make these workflows as transparent, explainable,
    and secure as possible. Openness is linked to operational excellence. Collecting
    and monitoring metadata during all phases of the data science and ML workflows
    is essential to create a “paper trail” that allows you to ask questions such as:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学和机器学习用例通常涉及敏感主题，如欺诈检测、医学影像或风险计算。因此，数据科学和机器学习平台必须帮助尽可能使这些工作流程透明、可解释和安全。开放性与运营卓越性息息相关。在数据科学和机器学习工作流程的所有阶段收集和监控元数据对于创建允许您提出诸如以下问题的“纸迹”至关重要：
- en: Which data was used to train the model?
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于训练模型的数据是哪些？
- en: Which hyperparameters were used?
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用了哪些超参数？
- en: How is the model performing in production?
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型在生产中的表现如何？
- en: Did any form of data drift or model skew occur during the last period?
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在上个时期内是否发生了任何形式的数据漂移或模型偏移？
- en: In addition, a science-driven organization must have a thorough understanding
    of its models. While this is less of a problem for traditional statistical methods,
    ML models (such as deep neural networks) are much more opaque. A platform must
    provide simple tools for analyzing such models to use them with confidence. Finally,
    a mature data science platform must provide all the security measures to protect
    data and artifacts while managing resource usage on a granular level.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以科学为驱动的组织必须对其模型有深入的理解。虽然传统统计方法的这个问题较少，但机器学习模型（如深度神经网络）则更加不透明。平台必须提供简单的工具来分析这些模型，以便放心使用。最后，成熟的数据科学平台必须提供所有安全措施，以保护数据和成果，并在粒度级别管理资源使用。
- en: Business impact
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 商业影响
- en: According to [McKinsey](https://oreil.ly/O_MZs), many data science projects
    fail to progress beyond the pilot or proof-of-concept stage. As a result, it is
    more important to anticipate or measure the business impact of new initiatives
    and choose ROI than to chase the latest cool solution. Therefore, it is critical
    to identify when to buy, build, or customize ML models and connect them together
    in a single integrated stack. For example, using an out-of-the-box solution by
    calling an API rather than building a model after months of development would
    help you achieve a higher ROI and demonstrate greater value.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[麦肯锡](https://oreil.ly/O_MZs)，许多数据科学项目未能超越试点或概念验证阶段。因此，更重要的是预期或衡量新举措的商业影响，并选择回报率，而不是追求最新的时髦解决方案。因此，关键是确定何时购买、构建或定制机器学习模型，并将它们连接到单一集成堆栈中。例如，在数月的开发后，通过调用API使用现成的解决方案而不是构建模型，将帮助您实现更高的回报率并展示更大的价值。
- en: Activation
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 激活
- en: The ability to operationalize models by embedding analytics into the tools used
    by end users is key to achieve scaling in providing services to a broad set of
    users. The ability to send small batches of data to the service and have it return
    your predictions in the response allows developers with little data science expertise
    to use models. In addition, it is important to facilitate seamless deployment
    and monitoring of edge inferences and automated processes with flexible APIs.
    This allows you to distribute AI across your private and public cloud infrastructure,
    on-premises data centers, and edge devices.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 将分析嵌入到最终用户使用的工具中以操作化模型的能力对于实现向广泛用户群提供服务的扩展至关重要。能够将小批量数据发送到服务中，并在响应中返回预测结果的能力，使得具有较少数据科学专业知识的开发人员也能使用模型。此外，促进边缘推理和灵活API的自动化过程的无缝部署和监控非常重要。这使您能够在私有和公共云基础设施、本地数据中心和边缘设备上分布人工智能。
- en: Building a science-driven organization comes with several socio-technical challenges.
    Often an organization’s infrastructure is not flexible enough to react to a fast-changing
    technological landscape. A platform also needs to provide enough standardization
    to foster communication between teams and establish a technical “lingua franca.”
    Doing so is key to allowing modularized workflows between teams and establishing
    operational excellence. In addition, securely monitoring complex data science
    and ML workflows is often too opaque.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 建立以科学驱动为基础的组织面临着几个社会技术挑战。通常，组织的基础设施不够灵活，无法应对快速变化的技术环境。平台还需要提供足够的标准化，以促进团队之间的沟通，并建立技术上的“共通语言”。这一点对于允许团队之间的模块化工作流程和建立运营卓越至关重要。此外，安全地监控复杂的数据科学和机器学习工作流通常过于不透明。
- en: A science-driven organization should be built on a technical platform that is
    highly adaptable in terms of technological openness. Hence, it is critical to
    enable a wide set of personas and provide technological resources in a flexible
    and serverless manner. Whether to buy or build a solution is one of the key drivers
    of realizing ROI for the organization, and this will define the business impact
    any AI solution would make. At the same time, enabling a broad number of users
    allows activating more use cases. Finally, a platform needs to provide the tools
    and resources to make data science and ML workflows open, explanatory, and secure
    to provide the maximum form of accountability.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 基于技术开放性高度可适应的技术平台构建以科学驱动的组织至关重要。因此，关键是要使广泛的角色得到启用，并以灵活和无服务器的方式提供技术资源。是购买还是构建解决方案是实现组织投资回报率的主要驱动因素之一，这将定义任何AI解决方案可能产生的业务影响。同时，启用广泛的用户能够激活更多用例。最后，平台需要提供工具和资源，使数据科学和机器学习工作流程开放、解释性和安全，以提供最大形式的问责制。
- en: The Personas
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人物角色
- en: 'Teams in data science–driven organizations are made up of a variety of people
    with different skills and experience. However, most teams include four core roles:
    data engineers, ML engineers, data scientists, and analysts. It is important to
    note that these roles are not always clearly defined and can overlap to some extent.
    An effective organizational structure will allow for collaboration and the full
    utilization of all team members’ skills:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学驱动的组织中的团队由具有不同技能和经验的各种人员组成。然而，大多数团队包括四个核心角色：数据工程师、ML工程师、数据科学家和分析师。需要注意的是，这些角色并不总是清晰定义的，并且在某种程度上可能存在重叠。有效的组织结构将允许协作和充分利用所有团队成员的技能：
- en: Data engineers
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师
- en: Data engineers are responsible for developing data pipelines and ensuring that
    the data meets all quality standards. This includes cleaning, merging, and enriching
    data from multiple sources to turn it into information that can be used for downstream
    analytics.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师负责开发数据流水线，确保数据符合所有质量标准。这包括从多个来源清理、合并和丰富数据，将其转化为可用于下游分析的信息。
- en: ML engineers
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ML工程师
- en: ML engineers create and oversee complete ML models. While ML engineers are the
    rarest of the four personas, they become essential once an organization intends
    to run critical business workflows in production.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ML工程师负责创建和监督完整的ML模型。虽然ML工程师是四个角色中最稀缺的，但一旦组织打算在生产中运行关键业务工作流程，他们就变得至关重要。
- en: Data scientists
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家
- en: Data scientists are a bridge between data and ML engineers. Together with business
    stakeholders, they translate business needs into testable hypotheses, ensure that
    value is derived from ML workloads, and create reports to demonstrate the value
    of data.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家是数据与ML工程师之间的桥梁。他们与业务利益相关者一起，将业务需求转化为可测试的假设，确保从ML工作负载中获取价值，并创建报告以展示数据的价值。
- en: Data analysts
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析师
- en: Data analysts provide business insight and ensure that the data-driven solutions
    that the business is seeking are implemented. They answer ad hoc questions and
    provide regular reports that analyze both historical and recent data.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析师提供业务洞见，并确保实施企业正在寻求的基于数据驱动的解决方案。他们回答临时问题，并提供分析历史和最新数据的定期报告。
- en: There are various arguments for whether a company should establish centralized
    or decentralized data science teams. There are also hybrid models, such as a federated
    organization in which data scientists are embedded in a centralized organization.
    As a result, it is more important to focus on how to address these socio-technical
    challenges using the principles described before.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 公司是否应该建立集中化或分散化的数据科学团队存在各种争论。还有混合模型，例如数据科学家嵌入到中央组织的联邦组织。因此，更重要的是专注于如何使用前面描述的原则解决这些社会技术挑战。
- en: The Technological Framework
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术框架
- en: We strongly recommend standardizing on the ML pipelines infrastructure of your
    public cloud provider (i.e., Vertex AI on Google Cloud, SageMaker on AWS, or Azure
    Machine Learning on Azure) rather than cobbling together one-off training and
    deployment solutions. The reference architecture (see [Figure 3-8](#make_data_science_experimentation_repea))
    consists of an ML pipeline to automate experimentation and training. The trained
    model is deployed in a pipeline where many of the training steps are repeated
    through containerization. Use a feature store when features will be too expensive
    to compute on demand or have to be injected server side. Deploy models to endpoints.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强烈建议您在公共云提供商的ML流水线基础设施上进行标准化（例如，在Google Cloud上的Vertex AI、AWS上的SageMaker或Azure上的Azure
    Machine Learning），而不是将单次培训和部署解决方案拼凑在一起。参考架构（见[图 3-8](#make_data_science_experimentation_repea)）包括一个ML流水线，用于自动化实验和训练。训练过的模型被部署在一个通过容器化重复许多训练步骤的流水线中。当特征过于昂贵或需要在服务器端注入时，请使用特征存储。将模型部署到端点。
- en: '![Make data science experimentation repeatable and deployments robust using
    the ML pipeline product available in the public cloud](assets/adml_0308.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![使用公共云中提供的ML流水线产品使数据科学实验可重复且部署健壮](assets/adml_0308.png)'
- en: Figure 3-8\. Make data science experimentation repeatable and deployments robust
    using the ML pipeline product available in the public cloud
  id: totrans-169
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-8\. 使用公共云中提供的ML流水线产品使数据科学实验可重复且部署健壮
- en: Summary
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, you have seen different ways of designing your data team to
    ensure their success in the kind of organization you are in. The best approach
    is to find the right mix of skills and experience that will complement your existing
    team and help you achieve your business goals. The key takeaways are as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您已经看到了设计数据团队的不同方式，以确保其在您所在的组织中取得成功。最佳方法是找到合适的技能和经验组合，这将补充您现有的团队，并帮助您实现业务目标。主要收获如下：
- en: Cloud technologies facilitate access to new ways of working. The potential surface
    area of any given persona has expanded. Data workers are now able to do more with
    the data they have, and they are able to do it more efficiently.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云技术促进了新的工作方式的实现。任何给定角色的潜在作用范围已经扩大。数据工作者现在能够更有效地利用他们手头的数据。
- en: You can build a data culture whether your organization consists mostly of data
    analysts, data engineers, or data scientists. However, the path toward a data
    culture and required technologies for each organization type are different.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无论您的组织主要由数据分析师、数据工程师还是数据科学家组成，都可以构建数据文化。然而，通向数据文化的路径以及每种组织类型所需的技术是不同的。
- en: Determine which organizational classification is right for you and then begin
    establishing the vision, personas with related skills, and technological framework
    to support it.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定哪种组织分类适合您，然后开始建立与之支持相关的愿景、具备相关技能的人物角色以及技术框架。
- en: The vision of what a data platform should do also varies. In an analysis-driven
    organization, it should democratize access to data. In an engineering-driven organization,
    it’s about ensuring reliability cost-effectively. In a science-driven organization,
    it should confer competitive advantage via business impact.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据平台应该做什么的愿景也各不相同。在分析驱动型组织中，它应该民主化数据访问。在工程驱动型组织中，它关乎以成本效益的方式确保可靠性。在科学驱动型组织中，它应该通过业务影响力提供竞争优势。
- en: Analysis-driven organizations should focus on SQL skills, engineering-driven
    organizations on ETL and DataOps capabilities, and science-driven organizations
    on MLOps and AI capabilities.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析驱动型组织应专注于SQL技能，工程驱动型组织应专注于ETL和DataOps能力，而科学驱动型组织则应专注于MLOps和AI能力。
- en: The recommended architecture for an analysis-driven organization is a data warehouse
    (or lakehouse founded on a DWH); for an engineering-driven organization, it is
    a data lake (or lakehouse founded on a data lake); and for a science-driven organization,
    it is an ML pipelines architecture connected to a lakehouse. These will be covered
    in Chapters [5](ch05.html#architecting_a_data_lake) through [7](ch07.html#converging_to_a_lakehouse).
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析驱动型组织的推荐架构是数据仓库（或建立在数据仓库基础上的湖仓）；对于工程驱动型组织来说，是数据湖（或建立在数据湖基础上的湖仓）；对于科学驱动型组织来说，是与湖仓连接的ML流水线架构。这些内容将在第[5](ch05.html#architecting_a_data_lake)章至第[7](ch07.html#converging_to_a_lakehouse)章详细讨论。
- en: The following chapter will offer you a general technological migration framework
    that you can apply to migrate from a legacy environment to a modern cloud architecture.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的章节将为您提供一个通用的技术迁移框架，您可以应用它从传统环境迁移到现代化的云架构。
