- en: Chapter 2\. Create a Plan
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章\. 制定计划
- en: In the previous chapter, we covered how to estimate if ML is necessary, find
    where it could be most appropriately used, and convert a product goal to the most
    appropriate ML framing. In this chapter, we will cover the use of metrics to track
    ML and product progress and compare different ML implementations. Then, we will
    identify methods to build a baseline and plan modeling iterations.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了如何估算是否需要机器学习，找到最合适使用机器学习的地方，并将产品目标转化为最合适的机器学习框架。在本章中，我们将讨论使用指标来跟踪机器学习和产品进展，并比较不同的机器学习实现。然后，我们将识别建立基准线和规划建模迭代的方法。
- en: I have had the unfortunate opportunity to see many ML projects be doomed from
    the start due to a misalignment between product metrics and model metrics. More
    projects fail by producing good models that aren’t helpful for a product rather
    than due to modeling difficulties. This is why I wanted to dedicate a chapter
    to metrics and planning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我不幸地看到许多机器学习项目从一开始就注定要失败，因为产品指标与模型指标之间存在不匹配。更多的项目失败不是因为建立了好的模型，而是因为这些模型对产品没有帮助。这就是为什么我想要专门讨论指标和规划的原因。
- en: We will cover tips to leverage existing resources and the constraints of your
    problem to build an actionable plan, which will dramatically simplify any ML project.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论利用现有资源和问题的约束条件来构建可行计划的技巧，这将极大简化任何机器学习项目。
- en: Let’s start with defining performance metrics in more detail.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地定义性能指标。
- en: Measuring Success
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量成功
- en: 'When it comes to ML, the first model we build should be the simplest model
    that could address a product’s needs, because generating and analyzing results
    is the fastest way to make progress in ML. In the previous chapter, we covered
    three potential approaches of increasing complexity for the ML Editor. Here they
    are as a reminder:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到机器学习时，我们建立的第一个模型应该是能够解决产品需求的最简单模型，因为生成和分析结果是快速推动机器学习进展的方法。在上一章中，我们提到了三种增加复杂性的潜在方法，用于机器学习编辑器。这里提醒一下：
- en: Baseline; designing heuristics based on domain knowledge
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 基准线；基于领域知识设计启发式方法
- en: We could start with simply defining rules ourselves, based on prior knowledge
    of what makes for well-written content. We will test these rules by seeing if
    they help differentiate between well-written text and poorly written text.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从简单地定义规则开始，基于我们对写作优质内容的先前知识。我们将通过测试这些规则来看它们是否有助于区分优秀文本和糟糕文本。
- en: Simple model; classifying text as good or bad, and using the classifier to generate
    recommendations
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 简单模型；将文本分类为好或坏，并使用分类器生成推荐
- en: We could then train a simple model to differentiate between good and bad questions.
    Provided that the model performs well, we can then inspect it to see which features
    it found to be highly predictive of a good question, and use those features as
    recommendations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以训练一个简单的模型来区分好问题和坏问题。只要模型表现良好，我们可以检查它，看看它找到了哪些特征对好问题有很高的预测性，并将这些特征用作推荐。
- en: Complex model; training an end-to-end model that goes from bad text to good
    text
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂模型；训练一个从坏文本到好文本的端到端模型
- en: This is the most complex approach, both in terms of model and data, but if we
    had the resources to gather the training data and build and maintain a complex
    model, we could solve the product requirements directly.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最复杂的方法，无论是在模型还是数据方面，但如果我们有资源来收集训练数据，并构建和维护一个复杂的模型，我们就能直接解决产品需求。
- en: All of these approaches are different and may evolve as we learn more from prototypes
    along the way, but when working on ML, you should define a common set of metrics
    to compare the success of modeling pipelines.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法都是不同的，随着我们在原型过程中的学习，它们可能会发展变化，但在进行机器学习时，您应该定义一套共同的指标来比较建模管道的成功。
- en: Note
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '**You Don’t Always Need ML**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**并非总是需要机器学习**'
- en: You may have noticed that the baseline approach does not rely on ML at all.
    As we discussed in [Chapter 1](ch01.html#validating_idea), some features do not
    require ML. It is important to also realize that even features that could benefit
    from ML can often simply use a heuristic for their first version. Once the heuristic
    is being used, you may even realize that you do not need ML at all.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，基准线方法根本不依赖于机器学习。正如我们在[第一章](ch01.html#validating_idea)中讨论的那样，有些特征根本不需要机器学习。同样重要的是要意识到，即使是那些可能受益于机器学习的特征，通常也可以简单地使用启发式方法作为它们的第一个版本。一旦启发式方法被采用，您甚至可能会意识到根本不需要机器学习。
- en: Building a heuristic is also often the fastest way to build a feature. Once
    the feature is built and used, you’ll have a clearer view of your user’s needs.
    This will allow you to evaluate whether you need ML, and select a modeling approach.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 构建启发式方法通常也是构建功能的最快方式。一旦构建并使用了功能，您将更清晰地了解用户的需求。这将帮助您评估是否需要ML，并选择建模方法。
- en: In most cases, starting without ML is the fastest way to build an ML product.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，开始时没有ML是构建ML产品的最快方式。
- en: 'To that end, we will cover four categories of performance that have a large
    impact on the usefulness of any ML product: business metrics, model metrics, freshness,
    and speed. Clearly defining these metrics will allow us to accurately measure
    the performance of each iteration.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将涵盖四类对任何ML产品有重大影响的性能指标：业务指标，模型指标，新鲜度和速度。清晰定义这些指标将允许我们准确衡量每次迭代的性能。
- en: Business Performance
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 业务绩效
- en: We’ve talked about the importance of starting with a clear product or feature
    goal. Once this goal is clear, a metric should be defined to judge its success.
    This metric should be separate from any model metrics and only be a reflection
    of the product’s success. Product metrics may be as simple as the number of users
    a feature attracts or more nuanced such as the click-through rate (CTR) of the
    recommendations we provide.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了以明确的产品或功能目标开始的重要性。一旦这个目标明确，就应该定义一个度量标准来评判其成功。这个度量标准应该与任何模型指标分开，并且只是产品成功的反映。产品指标可能非常简单，例如吸引功能用户的数量，或者更复杂，例如我们提供的推荐的点击率（CTR）。
- en: Product metrics are ultimately the only ones that matter, as they represent
    the goals of your product or feature. All other metrics should be used as tools
    to improve product metrics. Product metrics, however, do not need to be unique.
    While most projects tend to focus on improving one product metric, their impact
    is often measured in terms of multiple metrics, including *guardrail metrics*,
    metrics that shouldn’t decline below a given point. For example, an ML project
    can aim to increase a given metric such as CTR, while also holding other metrics
    steady, such as the average user session length, for example.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 产品指标最终是唯一重要的，因为它们代表了您的产品或功能的目标。所有其他指标应该被用作改进产品指标的工具。然而，产品指标并不需要是唯一的。尽管大多数项目倾向于专注于改善一个产品指标，但它们的影响通常以多个指标来衡量，包括*安全指标*，即不应低于给定点的指标。例如，一个机器学习项目可以旨在提高如点击率（CTR）之类的给定指标，同时保持其他指标稳定，例如平均用户会话长度。
- en: For the ML Editor, we will pick a metric that measures the usefulness of a recommendation.
    For example, we could use the proportion of times that users follow suggestions.
    In order to compute such a metric, the interface of the ML editor should capture
    whether a user approves of a suggestion, by overlaying it above the input and
    making it clickable, for example.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于ML编辑器，我们将选择一个度量推荐的有用性的指标。例如，我们可以使用用户按照建议行动的比例。为了计算这样的指标，ML编辑器的界面应该捕捉用户是否赞同建议，例如通过在输入上方叠加并使其可点击。
- en: We’ve seen that each product lends itself to many potential ML approaches. To
    measure the effectiveness of an ML approach, you should track model performance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到每个产品都适用于许多潜在的ML方法。为了衡量ML方法的有效性，您应该跟踪模型性能。
- en: Model Performance
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型性能
- en: For most online products, the ultimate product metric that determines the success
    of a model is the proportion of visitors who use the output of a model out of
    all the visitors who could benefit from it. In the case of a recommendation system,
    for example, performance is often judged by measuring how many people click on
    recommended products (see [Chapter 8](ch08.html#final_validation) for potential
    pitfalls of this approach).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数在线产品，决定模型成功的最终产品指标是使用模型输出的访问者比例，相对于所有可能受益的访问者。例如，在推荐系统的情况下，通常通过测量有多少人点击推荐产品来评估性能（参见[第8章](ch08.html#final_validation)关于此方法的潜在问题）。
- en: When a product is still being built and not deployed yet, it is not possible
    to measure usage metrics. To still measure progress, it is important to define
    a separate success metric called an *offline metric* or a *model metric*. A good
    offline metric should be possible to evaluate without exposing a model to users,
    and be as correlated as possible with product metrics and goals.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当产品仍在建设中尚未部署时，无法测量使用度量。为了仍然衡量进展，定义一个单独的成功度量标准叫做*离线度量*或*模型度量*至关重要。一个好的离线度量应该可以在不暴露模型给用户的情况下评估，并且尽可能与产品度量和目标相关联。
- en: Different modeling approaches use different model metrics, and changing approaches
    can make it much easier to reach a level of modeling performance that is sufficient
    to accomplish product goals.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的建模方法使用不同的模型指标，改变方法可以使达到足以实现产品目标的建模性能水平变得更容易。
- en: For example, let’s say you are trying to offer helpful suggestions to users
    as they type a search query on an online retail website. You’ll measure the success
    of this feature by measuring CTR, how often users click on the suggestions you
    make.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您正在尝试为在线零售网站上用户输入搜索查询时提供有用的建议。您将通过测量点击率来衡量此功能的成功，即用户点击您提供的建议的频率。
- en: To generate the suggestions, you could build a model that attempts to guess
    the words a user will type and present the predicted completed sentence to them
    as they write. You could measure the performance of this model by computing its
    word-level accuracy, calculating how often it predicts the correct next set of
    words. Such a model would need to reach extremely high accuracy to help increase
    the product’s CTR, because a prediction error of one word would be enough to render
    a suggestion useless. This approach is sketched out on the left side of [Figure 2-1](#framing_complexity).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成建议，您可以构建一个模型，试图猜测用户将要输入的单词，并在用户输入时将预测的完整句子呈现给他们。您可以通过计算模型的单词级准确率来衡量其性能，计算它多频繁地预测正确的下一个单词组。这样的模型需要达到极高的准确率，以帮助提高产品的点击率，因为一个单词的预测错误足以使建议失效。这种方法在[图 2-1](#framing_complexity)的左侧勾画出来。
- en: Another approach would be to train a model that classifies user input into categories
    in your catalog and suggests the three most likely predicted categories. You’d
    measure the performance of your model using accuracy over all categories rather
    than accuracy over every English word. Since the number of categories in a catalog
    is much smaller than the English vocabulary, this would be a much easier modeling
    metric to optimize. In addition, the model only needs to predict one category
    correctly to generate a click. It is much easier for this model to increase the
    product’s CTR. You can see a mock-up of how this approach would work in practice
    on the right side of [Figure 2-1](#framing_complexity).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是训练一个模型，将用户输入分类到目录中的类别，并建议最有可能的三个预测类别。您将使用所有类别的准确率来衡量模型的性能，而不是每个英文单词的准确率。由于目录中的类别数量比英语词汇要小得多，这将是一个更容易优化的建模指标。此外，该模型只需要正确预测一个类别即可生成点击。这种模型更容易提高产品的点击率。您可以在[图 2-1](#framing_complexity)的右侧看到这种方法在实践中的模拟效果。
- en: '![Slightly altering a product can make modeling tasks much easier](assets/bmla_0201.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![稍微改变产品可以使建模任务更加容易](assets/bmla_0201.png)'
- en: Figure 2-1\. Slightly altering a product can make modeling tasks much easier
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-1\. 稍微改变产品可以使建模任务更加容易
- en: 'As you can see, small changes to the interaction between the model and product
    can make it possible to use a more straightforward modeling approach and deliver
    results more reliably. Here are a few other examples of updating an application
    to make a modeling task easier:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，通过对模型和产品之间的交互进行小的更改，可以使用更直接的建模方法并更可靠地交付结果。以下是更新应用程序以使建模任务更简单的几个其他示例：
- en: '*Changing an interface so that a model’s results can be omitted if they are
    below a confidence threshold.* When building a model to autocomplete a sentence
    typed by the user, for example, the model may perform well only on a subset of
    sentences. We can implement logic to only show a suggestion to users if the model’s
    confidence score exceeds 90%.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*更改接口，以便如果模型的置信度低于阈值，则可以省略模型的结果。*例如，当构建一个自动完成用户输入的模型时，该模型可能只对部分句子表现良好。我们可以实现逻辑，只有当模型的置信度得分超过90%时，才向用户显示建议。'
- en: '*Presenting a few other predictions or heuristics in addition to a model’s
    top prediction.* For example, most websites display more than one recommendation
    suggested by a model. Displaying five candidate items instead of just one makes
    it more likely that suggestions will be useful to users, even if the model is
    the same.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*除了模型的顶部预测外，还展示几个其他预测或启发法。* 例如，大多数网站会显示模型建议的不止一项推荐。显示五个候选项而不是一个，可以增加建议对用户有用的可能性，即使模型是相同的。'
- en: '*Communicating to users that a model is still in an experimental phase and
    giving them opportunities to provide feedback.* When automatically detecting a
    language that is not in the user’s native tongue and translating it for them,
    websites often add a button for a user to let them know whether the translation
    was accurate and useful.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*向用户传达模型仍处于实验阶段，并给予他们提供反馈的机会。* 当自动检测到用户非母语的语言并为其翻译时，网站通常会添加一个按钮，让用户知道翻译是否准确和有用。'
- en: Even when a modeling approach is appropriate for a problem, it can sometimes
    be worthwhile to generate additional model metrics that correlate better with
    product performance.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 即使建模方法适用于问题，有时生成与产品性能更相关的额外模型指标也是值得的。
- en: I once worked with a data scientist who built a model to generate HTML from
    hand-drawn sketches of simple websites (see [his post, “Automated Front-End Development
    Using Deep Learning”](https://oreil.ly/SdYQj)). The model’s optimization metric
    compares each predicted HTML token to the correct one using cross-entropy loss.
    The goal of the product, however, is for the generated HTML to produce a website
    that looks like the input sketch, regardless of the order of tokens.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾与一位数据科学家合作，他构建了一个模型，用于从简单网站的手绘草图生成HTML（参见[他的文章，“使用深度学习进行自动前端开发”](https://oreil.ly/SdYQj)）。该模型的优化指标使用交叉熵损失来比较每个预测的HTML标记与正确标记。然而，产品的目标是生成的HTML能够呈现与输入草图相似的网站，而不考虑标记的顺序。
- en: 'Cross-entropy does not account for alignment: if a model generates a correct
    HTML sequence except for one extra token at the start, all of the tokens will
    be shifted by one compared to the target. Such an output would lead to a very
    high loss value, despite producing an almost ideal result. This means that when
    trying to evaluate the usefulness of the model, we should look beyond its optimization
    metric. In this example, using a [BLEU Score](https://oreil.ly/8s9JE) provides
    a better measurement of the similarity between the generated HTML and the ideal
    output.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉熵不考虑对齐：如果模型生成了一个正确的HTML序列，但在开头多了一个额外的标记，那么与目标相比，所有标记都会向后偏移一个。这样的输出会导致非常高的损失值，尽管实际上产生了几乎理想的结果。这意味着在试图评估模型的实用性时，我们应该超越其优化指标。在这个例子中，使用[BLEU分数](https://oreil.ly/8s9JE)提供了更好地衡量生成的HTML与理想输出之间相似性的方法。
- en: Finally, a product should be designed with reasonable assumptions of model performance
    in mind. If a product relies on a model being perfect to be useful, it is very
    likely to produce inaccurate or even dangerous results.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，产品设计应考虑到合理的模型性能假设。如果产品依赖于模型的完美性才能有用，那么很可能会产生不准确甚至危险的结果。
- en: For example, if you are building a model that lets you take a picture of a pill
    and tells patients its type and dosage, what is the worst accuracy a model could
    have and still be useful? If this accuracy requirement is hard to attain with
    current methods, could you redesign your product to make sure users are well served
    by it and not put at risk by prediction errors it could make?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你正在构建一个模型，让你拍一张药片的照片并告诉患者其类型和剂量，那么模型能够有多少最低准确率仍然是有用的？如果当前方法很难达到这一准确性要求，您是否可以重新设计产品，以确保用户得到良好服务，而不会因其可能产生的预测错误而受到伤害？
- en: In our case, the product we want to build will provide writing advice. Most
    ML models have certain input they excel at and certain inputs they will struggle
    with. From a product standpoint, if we are not able to help—we need to make sure
    we are not going to hurt—we would like to limit the amount of time that we output
    a result that is worse than the input. How could we express this in model metrics?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们希望构建的产品将提供写作建议。大多数机器学习模型在某些输入上表现出色，在某些输入上可能遇到困难。从产品的角度来看，如果我们无法帮助——我们需要确保我们不会使情况变得更糟——我们希望限制输出比输入更差的结果的时间。我们如何在模型指标中表达这一点？
- en: Let’s say we build a classification model that attempts to predict whether a
    question is good as measured by the number of upvotes it received. The classifier’s
    precision would be defined as the proportion of questions that are truly good
    out of the ones it predicts as good. Its recall on the other side is the proportion
    of questions that it predicts as good out of all the good questions in the dataset.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们构建了一个分类模型，试图预测一个问题是否好，这是根据它所获得的点赞数量来衡量的。分类器的精确度被定义为预测为好的问题中实际上好的问题的比例。另一方面，它的召回率是预测为好的问题占数据集中所有好问题的比例。
- en: 'If we want to always have advice that is relevant, we would want to prioritize
    the model’s *precision* because when a high-precision model classifies a question
    as good (and thus makes a recommendation), there is a high chance that this question
    is actually good. High precision means that when we do make a recommendation,
    it will tend to be correct. For more about why high-precision models are more
    useful for writing recommendations, feel free to refer to [“Chris Harland: Shipping
    Experiments”](ch08.html#chris_harland).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要始终提供相关的建议，我们将优先考虑模型的*精确度*，因为高精确度的模型将一个问题分类为好（从而做出推荐）时，实际上这个问题确实很好的可能性很高。高精确度意味着当我们做出推荐时，它往往是正确的。关于为什么高精确度模型对撰写推荐更有用的更多信息，请参阅[“克里斯·哈兰德：发布实验”](ch08.html#chris_harland)。
- en: 'We measure such metrics by looking through the outputs of a model on a representative
    validation set. We will dive into what this means in [“Evaluate Your Model: Look
    Beyond Accuracy”](ch05.html#beyond_accuracy), but for now, think of a validation
    set as a set of data that is held out from training and used to estimate how your
    model performs on unseen data.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过查看模型在代表性验证集上的输出来衡量这些指标。我们将深入探讨这意味着什么，详见[“评估您的模型：超越准确度”](ch05.html#beyond_accuracy)，但现在，请将验证集视为从训练中留出并用于估计模型在未见数据上的表现。
- en: Initial model performance is important, but so is the ability of a model to
    stay useful in the face of changing user behavior. A model trained on a given
    dataset will perform well on similar data, but how do we know whether we need
    to update a dataset?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 初始模型性能很重要，但面对用户行为变化时，模型保持有用性的能力同样重要。一个在特定数据集上训练的模型将在类似数据上表现良好，但我们如何知道是否需要更新数据集呢？
- en: Freshness and Distribution Shift
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新鲜度和分布转变
- en: Supervised models draw their predictive power from learning correlations between
    input features and prediction targets. This means that most models need to have
    been exposed to training data that is similar to a given input to perform well
    on it. A model that was trained to predict the age of a user from a photo using
    only photos of men will not perform well on photos of women. But even if a model
    is trained on an adequate dataset, many problems have a distribution of data that
    changes as time goes on. When the distribution of the data *shifts*, the model
    often needs to change as well in order to maintain the same level of performance.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 监督模型从学习输入特征和预测目标之间的关联中获得其预测能力。这意味着大多数模型需要接触到与给定输入类似的训练数据才能表现良好。一个仅使用男性照片预测用户年龄的模型，在女性照片上将表现不佳。但即使模型在充足的数据集上进行了训练，许多问题的数据分布随着时间的推移会发生变化。当数据的分布*转变*时，模型通常需要相应变化以维持相同的性能水平。
- en: Let’s imagine that after noticing the impact of rain on traffic in San Francisco,
    you built a model to predict traffic conditions based on the amount of rain in
    the past week. If you built your model in October using data from the past 3 months,
    your model was likely trained on data with daily precipitation lower than an inch.
    See [Figure 2-2](#freshness) for an example of how such a distribution might look.
    As winter approaches, the average precipitation will become closer to 3 inches,
    which is higher than anything the model was exposed to during training, as you
    can see in [Figure 2-2](#freshness). If the model isn’t trained on more recent
    data, it will struggle to keep performing well.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设在注意到旧金山的雨对交通的影响后，您建立了一个模型，根据过去一周的降雨量预测交通状况。如果您在十月份使用过去三个月的数据建立模型，那么您的模型可能是在日降水量低于一英寸的数据上进行训练的。请参见[图2-2](#freshness)，展示了这种分布可能的示例。随着冬季的临近，平均降水量将接近3英寸，这高于模型在训练期间所接触到的任何数据，正如您可以在[图2-2](#freshness)中看到的。如果模型没有接受更近期数据的训练，它将难以保持良好的表现。
- en: '![Model performance decreases when input types change](assets/bmla_0202.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![当输入类型变化时，模型性能下降](assets/bmla_0202.png)'
- en: Figure 2-2\. Changing distributions
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-2\. 分布变化
- en: In general, a model can perform well on data it hasn’t seen before as long as
    it is similar enough to the data it was exposed to during training.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，只要模型在训练期间接触到的数据足够相似，它可以在之前没有见过的数据上表现良好。
- en: Not all problems have the same freshness requirements. Translation services
    for ancient languages can expect the data they operate to remain relatively constant,
    while search engines need to be built with the assumption that they will need
    to evolve as fast as users change their search habits.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 不同问题的新鲜度要求并不相同。古代语言的翻译服务可以预期其操作的数据保持相对稳定，而搜索引擎需要建立在用户搜索习惯变化快速的假设上进行构建。
- en: Depending on your business problem, you should consider how hard it will be
    to keep models *fresh*. How often will you need to retrain models, and how much
    will it cost you each time we do so?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的业务问题，您应考虑保持模型“新鲜度”的难度。您需要多频繁重新训练模型？每次重新训练会带来多少成本？
- en: For the ML editor, we imagine that the cadence at which the definition of “well-formulated
    English prose” changes is relatively low, perhaps in the order of a year. Freshness
    requirements would change if we targeted specific domains, however. For example,
    the right way to ask a question about mathematics will change much more slowly
    than the best phrasing of questions concerning music trends. Since we estimate
    that models will need to be retrained every year, we will require fresh data to
    train on yearly.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 ML 编辑器，我们设想“良好构思的英文散文”定义变化的频率相对较低，可能是每年一次。然而，如果我们针对特定领域，新鲜度的需求就会发生变化。例如，提问数学问题的正确方式变化的速度会比提问音乐趋势问题的最佳措辞慢得多。由于我们估计模型需要每年重新训练一次，因此我们需要每年获得新鲜数据来进行训练。
- en: Our baseline and simple model can both learn from unpaired data, which makes
    the data gathering process simpler (we’d simply need to find new questions from
    the last year). The complex model requires paired data, meaning we will have to
    find examples of the same sentences, said in a “good” and “bad” way, every year.
    This means satisfying the freshness requirement we’ve defined will be much harder
    for a model requiring paired data, since it is more time-consuming to acquire
    an updated dataset.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的基线模型和简单模型都可以从非配对数据中学习，这使得数据收集过程更简单（我们只需找到最近一年的新问题）。然而，复杂模型需要配对数据，这意味着我们每年都必须找到相同句子的示例，以“好”和“坏”的方式表达。这意味着满足我们定义的新鲜度要求对于需要配对数据的模型来说将更加困难，因为获取更新的数据集需要更多时间。
- en: For most applications, popularity can help alleviate data gathering requirements.
    If our question phrasing service goes viral, we could add a button for users to
    rate the quality of outputs. We could then gather past inputs from users along
    with the model’s predictions and associated user ratings and use them as a training
    set.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数应用程序来说，受欢迎程度可以帮助减轻数据收集的需求。如果我们的提问服务一夜爆红，我们可以为用户添加一个按钮来评估输出质量。然后，我们可以收集用户过去的输入以及模型的预测和相关用户评分，并将它们用作训练集。
- en: For an application to be popular, however, it should be useful. Oftentimes,
    this requires responding to user requests in a timely manner. The speed at which
    a model can deliver predictions is thus an important factor to take into account.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序要受欢迎，关键在于它是否有用。通常，这需要及时响应用户请求。因此，模型能够快速提供预测的速度成为需要考虑的重要因素。
- en: Speed
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 速度
- en: Ideally, a model should deliver a prediction quickly. This allows users to interact
    with it more easily and makes it easier to serve a model to many concurrent users.
    So how fast does a model need to be? For some use cases, such as translating a
    short sentence, users will expect an answer immediately. For others, such as a
    medical diagnosis, patients would be happy to wait 24 hours if it meant that they
    would get the most accurate results.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，模型应该能快速地提供预测。这使得用户更容易与之交互，并且更容易为多个并发用户提供模型服务。那么模型需要多快呢？对于某些用例，如翻译短句，用户会期望立即得到答案。对于其他用例，如医学诊断，患者愿意等待
    24 小时，只要能确保得到最准确的结果。
- en: 'In our case, we will consider two potential ways we could deliver suggestions:
    through a submission box where the user writes, clicks Submit, and gets a result
    or by dynamically updating each time the user enters a new letter. While we may
    want to favor the latter because we would be able to make the tool much more interactive,
    it would require models to perform much faster.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们将考虑两种潜在的方式来提供建议：通过一个提交框，用户写入内容后点击提交按钮并获取结果，或者每次用户输入新字母时动态更新。虽然我们可能更倾向于后者，因为这样可以使工具更加互动，但这需要模型运行得更快。
- en: We could conceivably imagine a user waiting a couple seconds for a result once
    they click a submission button, but for a model to run as a user is editing text,
    it would need to run significantly under a second. The most powerful models take
    longer to process data, so as we iterate through models, we will keep this requirement
    in mind. Any model we use should be able to process an example through its whole
    pipeline in under two seconds.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以设想用户点击提交按钮后等待几秒钟以获取结果，但对于一个模型在用户编辑文本时运行，它需要在一秒内显著运行。最强大的模型需要更长时间来处理数据，因此在迭代模型时，我们将牢记这一要求。我们使用的任何模型应该能够在不到两秒的时间内处理一个示例的整个流程。
- en: Model inference runtimes increase as models get more complex. The difference
    is significant even in a domain where each individual data point can be relatively
    small data such as NLP (as opposed to tasks on live videos, for example). On the
    text data used for the case study in this book, for example, an LSTM is about
    three times slower than a random forest (around 22 ms for an LSTM, while the random
    forest takes only 7 ms). On an individual datapoint, this difference are small,
    but they can quickly add up when needing to run inference on tens of thousands
    of examples at a time.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型变得越来越复杂，模型推断的运行时间也会增加。即使在每个数据点相对较小的数据（例如NLP，而不是实时视频任务）中，差异也很显著。例如，本书案例研究中使用的文本数据，LSTM大约比随机森林慢三倍（LSTM约为22毫秒，而随机森林只需7毫秒）。在单个数据点上，这些差异很小，但在需要同时对数万个示例进行推断时，它们可能会迅速累积。
- en: For complex applications where an inference call will be associated with multiple
    network calls or database queries, model execution time can become short compared
    to the rest of the application logic. In those cases, the speed of said models
    becomes less of an issue.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于复杂的应用程序，推断调用将与多个网络调用或数据库查询相关联，模型执行时间可能会比应用程序逻辑的其他部分短。在这些情况下，所述模型的速度就不再是问题的关键。
- en: Depending on your problem, there are other categories you could consider, such
    as hardware constraints, development time, and maintainability. It is important
    to develop an understanding of your needs before choosing a model so that you
    make sure to pick said model in an informed way.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的问题，还有其他类别可以考虑，例如硬件限制、开发时间和可维护性。在选择模型之前，了解您的需求非常重要，以确保以知情的方式选择所述模型。
- en: Once you identify requirements and associated metrics, it’s time to start making
    a plan. This requires estimating the challenges that lie ahead. In the next section,
    I’ll cover ways to leverage prior work and explore a dataset to decide what to
    build next.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了要求和相关指标，就是制定计划的时候了。这需要估计前方的挑战。在接下来的部分，我将介绍如何利用先前的工作和探索数据集来决定接下来要构建什么。
- en: Estimate Scope and Challenges
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估算范围和挑战
- en: As we’ve seen, ML performance is often reported in terms of model metrics. While
    these metrics are useful, they should be used to improve the product metrics we
    defined, which represent the actual task we are trying to solve. As we iterate
    on a pipeline, we should keep in mind product metrics and aim to improve them.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，机器学习的性能通常以模型指标报告。虽然这些指标很有用，但应用它们来改进我们定义的产品指标，这些产品指标代表我们试图解决的实际任务。在管道的迭代过程中，我们应该牢记产品指标，并努力改进它们。
- en: The tools we have covered so far will help us determine whether a project is
    worth tackling at all, and measure how well we are currently doing. A logical
    next step is to sketch out a plan of attack to estimate the scope and duration
    of a project and anticipate potential roadblocks.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所涵盖的工具将帮助我们确定是否值得处理某个项目，并衡量我们目前的表现如何。下一个逻辑步骤是草拟一个攻击计划，以估算项目的范围和持续时间，并预料可能遇到的障碍。
- en: In ML, success generally requires understanding the context of the task well,
    acquiring a good dataset, and building an appropriate model.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，成功通常需要充分理解任务的背景，获取一个好的数据集，并构建一个合适的模型。
- en: We will cover each of these categories in the following section.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中详细介绍每个类别。
- en: Leverage Domain Expertise
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用领域专业知识
- en: 'The simplest model we can start with is a heuristic: a good rule of thumb based
    on knowledge of the problem and the data. The best way to devise heuristics is
    to see what experts are currently doing. Most practical applications are not entirely
    novel. How do people currently solve the problem you are trying to solve?'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从最简单的启动模型开始，即启发式方法：基于问题和数据的知识得出的经验法则。制定启发式方法的最佳途径是观察专家目前的做法。
- en: The second best way to devise heuristics is to look at your data. Based on your
    dataset, how would you solve this task if you were doing it manually?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 制定启发式方法的第二最佳途径是查看您的数据。基于您的数据集，如果您手动进行此任务，您将如何解决？
- en: To identify good heuristics, I recommend either learning from experts in the
    field or getting familiar with the data. I’ll describe both in a little more detail
    next.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要找出良好的启发式方法，我建议要么向该领域的专家学习，要么熟悉数据。接下来，我将稍微详细描述这两种方法。
- en: Learning from experts
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向专家学习
- en: For many domains we might want to automate, learning from experts in the domain
    can save us dozens of hours of work. If we are attempting to build a predictive
    maintenance system for factory equipment, for example, we should start by reaching
    out to a factory manager to understand which assumptions we can reasonably make.
    This could include understanding how often maintenance is currently performed,
    which symptoms usually indicate that a machine will require maintenance soon,
    and the legal requirements concerning maintenance.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们可能想要自动化的许多领域，向该领域的专家学习可以节省我们数十小时的工作时间。例如，如果我们试图为工厂设备建立预测性维护系统，我们应该首先与工厂经理联系，了解我们可以合理假设哪些内容。这可能包括了解当前维护频率，通常表明机器即将需要维护的症状，以及与维护相关的法律要求。
- en: There are, of course, examples where finding domain experts is likely to be
    difficult—such as proprietary data for a novel use case like predicting usage
    of a unique website feature. In these cases, however, we can often find professionals
    who have had to tackle similar problems and learn from their experiences.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，也有一些例子，可能很难找到领域专家，比如用于预测独特网站功能使用情况的专有数据。然而，在这些情况下，我们通常可以找到那些曾经处理过类似问题并从中学习经验的专业人士。
- en: This will allow us to learn about useful features we can leverage, find pitfalls
    we should avoid, and most importantly prevent us from reinventing the wheel that
    many data scientists get a bad rep for.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使我们了解可以利用的有用特征，找到应该避免的陷阱，更重要的是，防止我们为许多数据科学家不好的声誉重新发明轮子。
- en: Examining the data
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检查数据
- en: 'As both Monica Rogati in [“Monica Rogati: How to Choose and Prioritize ML Projects”](ch01.html#monica_rogati)
    and Robert Munro in [“Robert Munro: How Do You Find, Label, and Leverage Data?”](ch04.html#robert_munro_how)
    mention, it’s key to look at the data before we start modeling.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '正如Monica Rogati在[“Monica Rogati: How to Choose and Prioritize ML Projects”](ch01.html#monica_rogati)
    和Robert Munro在[“Robert Munro: How Do You Find, Label, and Leverage Data?”](ch04.html#robert_munro_how)
    中提到的，开始建模之前查看数据非常关键。'
- en: Exploratory data analysis (EDA) is the process of visualizing and exploring
    a dataset, often to get an intuition to a given business problem. EDA is a crucial
    part of building any data product. In addition to EDA, it is crucial to individually
    label examples in the way you hope a model would. Doing so helps validate assumptions
    and confirms that you chose models that can appropriately leverage your dataset.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 探索性数据分析（EDA）是可视化和探索数据集的过程，通常是为了对给定的业务问题有直觉。EDA 是构建任何数据产品的关键部分。除了EDA之外，还需要以希望模型能够适当利用数据集的方式对示例进行标记。这样做有助于验证假设，并确认您选择了可以适当利用您的数据集的模型。
- en: The EDA process will allow you to get an understanding of the trends in your
    data, and labeling it yourself will force you to build a set of heuristics to
    solve your problem. After having done both previous steps, you should have a clearer
    idea of which kind of models will serve you best, as well as any additional data
    gathering and labeling strategies we may require.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: EDA 过程将帮助您了解数据的趋势，自行标记将迫使您建立一套启发式方法来解决问题。在完成了前两个步骤之后，您应该更清楚地知道哪种模型最适合您，以及我们可能需要的任何额外数据收集和标记策略。
- en: The next logical step is to see how others have tackled similar modeling problems.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个逻辑步骤是看看其他人如何解决类似的建模问题。
- en: Stand on the Shoulders of Giants
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 站在巨人的肩膀上
- en: Have people solved similar problems? If so, the best way to get started is to
    understand and reproduce existing results. Look for public implementations either
    with similar models or similar datasets, or both.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 是否有人已经解决过类似的问题？如果是这样，开始的最佳方法是理解并复制现有的结果。寻找公共实现，其模型或数据集与您相似，或两者都有关。
- en: Ideally, this would involve finding open source code and an available dataset,
    but these aren’t always easy to come by, especially for very specific products.
    Nevertheless, the fastest way to get started on an ML project is to reproduce
    existing results and then build on top of them.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，这将涉及找到开源代码和可用数据集，但这些并不总是容易获得，特别是对于非常特定的产品。尽管如此，在机器学习项目上开始的最快方式是复制现有的结果，然后在其基础上建立。
- en: In a domain with as many moving pieces as ML, it is crucial to stand on the
    shoulders of giants.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在像机器学习这样有许多不同组成部分的领域中，站在巨人的肩膀上是至关重要的。
- en: Note
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you’re planning to use open source code or datasets in your work, please
    make sure that you are allowed to do so. Most repositories and datasets will include
    a license that defines acceptable usages. In addition, credit any source you end
    up using, ideally with a reference to their original work.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您计划在您的工作中使用开源代码或数据集，请确保您有权这样做。大多数代码库和数据集都会包含定义可接受使用方式的许可证。此外，请给您最终使用的任何来源信用，最好附上对他们原始作品的引用。
- en: It can often be a good idea to build a convincing proof of concept before committing
    significant resources to a project. Before using time and money to label data,
    for example, we need to convince ourselves that we can build a model that will
    learn from said data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在投入大量资源之前，构建一个令人信服的概念证明通常是一个好主意。例如，在使用时间和金钱标记数据之前，我们需要确信我们能够构建一个能够从这些数据中学习的模型。
- en: 'So, how do we find an efficient way to start? Like most topics we will cover
    in this book, this includes two main parts: data and code.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何找到一个高效的开始方式呢？就像我们在本书中将要讨论的大多数主题一样，这包括两个主要部分：数据和代码。
- en: Open data
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开放数据
- en: You might not always be able to find a dataset that matches your desires, but
    you can often find a dataset that is similar enough in nature to be helpful. What
    does a similar dataset mean in this context? Thinking about ML models as mapping
    an input to an output is helpful here. With this in mind, a similar dataset simply
    means a dataset with similar input and output types (but not necessarily domains).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能并不总是能够找到符合您要求的数据集，但通常可以找到在性质上足够相似以帮助的数据集。在这种情况下，什么是类似的数据集？在这里将机器学习模型视为将输入映射到输出是有帮助的。基于这个想法，类似的数据集简单地意味着具有类似输入和输出类型的数据集（但不一定是相同领域的）。
- en: Frequently, models using similar inputs and outputs can be applied to entirely
    different contexts. On the left side of [Figure 2-3](#input_output_abstraction)
    are two models that both predict a text sequence from an image input. One is used
    to describe photos, while the other generates HTML code for a website from a screenshot
    of said website. Similarly, the right side of [Figure 2-3](#input_output_abstraction)
    shows a model that predicts a type of food from a text description in English,
    and another that predicts a music genre from a sheet music transcription.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 经常，使用类似输入和输出的模型可以应用于完全不同的上下文。在[图 2-3](#input_output_abstraction)的左侧是两个模型，它们都从图像输入中预测文本序列。一个用于描述照片，而另一个从该网站的截图生成网站的HTML代码。类似地，[图
    2-3](#input_output_abstraction)的右侧显示了一个模型，它从英文文本描述中预测食物类型，另一个从乐谱转录中预测音乐流派。
- en: '![Varied tasks can be tackled with the same model](assets/bmla_0203A.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![使用相同模型可以处理不同任务](assets/bmla_0203A.png)'
- en: Figure 2-3\. Different models with similar inputs and outputs
  id: totrans-98
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-3\. 具有相似输入和输出的不同模型
- en: For example, let’s say we are trying to build a model to predict viewership
    of news articles but are struggling to find a dataset of news articles and associated
    view counts. We could start with the openly accessible dataset of [Wikipedia page
    traffic statistics](https://oreil.ly/PdwgN) and train a predictive model on it.
    If we are happy with its performance, it is reasonable to believe that given a
    dataset of views for a news article, our model could perform reasonably well.
    Finding a similar dataset can help prove the validity of an approach and makes
    it more reasonable to spend resources to acquire data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们试图构建一个模型来预测新闻文章的观看次数，但却难以找到新闻文章及其关联观看次数的数据集。我们可以先使用公开访问的[Wikipedia页面流量统计数据集](https://oreil.ly/PdwgN)训练一个预测模型。如果模型表现良好，可以合理地认为，给定一个新闻文章观看次数的数据集，我们的模型也能表现得相当不错。寻找类似的数据集有助于验证方法的有效性，并使得在获取数据方面的资源投入更具合理性。
- en: This method also works when working on proprietary data. Oftentimes, the dataset
    you need for a prediction task may not be easy to access. In some cases, the data
    you would need is not being currently collected. In such cases, building a model
    that performs well on a similar dataset can often be the best way to convince
    stakeholders to build a novel data collection pipeline or facilitate access to
    an existing one.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理专有数据时，这种方法同样适用。往往情况下，用于预测任务的数据集可能并不容易获取。在某些情况下，所需的数据当前并未被收集。在这种情况下，构建一个在类似数据集上表现良好的模型通常是说服利益相关者建立新的数据收集流水线或促进现有流水线访问的最佳方式。
- en: 'When it comes to publicly accessible data, new data sources and collections
    appear regularly. The following are a few that I’ve found useful:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到公开数据时，新的数据源和集合经常出现。以下是我发现有用的一些：
- en: The [Internet archive](https://oreil.ly/tIjl9) maintains a set of datasets including
    website data, videos, and books.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[互联网档案馆](https://oreil.ly/tIjl9)维护着包括网站数据、视频和书籍在内的一组数据集。'
- en: The subreddit [r/datasets](http://reddit.com/r/datasets) is dedicated to sharing
    datasets.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: subreddit [r/datasets](http://reddit.com/r/datasets) 致力于分享数据集。
- en: '[Kaggle’s Datasets page](https://www.kaggle.com/datasets) offers a large selection
    in a variety of domains.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaggle 的[数据集页面](https://www.kaggle.com/datasets)提供多个领域的大量选择。
- en: The [UCI Machine Learning Repository](https://oreil.ly/BXLA5) is a vast resource
    of ML datasets.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UCI机器学习库](https://oreil.ly/BXLA5)是一个庞大的ML数据集资源。'
- en: Google’s [dataset search](https://oreil.ly/Gpv8S) covers a large searchable
    index of accessible datasets.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google 的[数据集搜索](https://oreil.ly/Gpv8S)涵盖了一个大型可搜索的数据集索引。
- en: '[Common Crawl](https://commoncrawl.org) crawls and archives data from across
    the web and makes results publicly available.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Common Crawl](https://commoncrawl.org)从全网抓取和存档数据，并公开发布结果。'
- en: Wikipedia also has a great evolving [list of ML research datasets](https://oreil.ly/kXGiz).
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wikipedia 也有一个不断更新的[ML研究数据集列表](https://oreil.ly/kXGiz)。
- en: For most use cases, one of these sources will provide you with a dataset sufficiently
    similar to the one you would need.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数用例来说，这些来源中的一个将为你提供足够接近你所需的数据集。
- en: Training a model on this *tangential dataset* will allow you to prototype and
    validate your results rapidly. In some cases, you can even train a model on a
    tangential dataset and transfer some of its performance to your final dataset
    (more on this in [Chapter 4](ch04.html#initial_dataset)).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个*相关数据集*上训练一个模型将能够快速原型化和验证你的结果。在某些情况下，你甚至可以在相关数据集上训练一个模型，并将其性能部分转移到最终数据集上（更多内容请参见[第 4
    章](ch04.html#initial_dataset)）。
- en: Once you have an idea of which dataset you’ll start with, it is time to turn
    your attention to models. While it can be tempting to simply start building your
    own pipeline from scratch, it can often be worthwhile to at least observe what
    others have done.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了要从哪个数据集开始，就是时候把注意力转向模型了。虽然简单地从头开始构建自己的流程可能很诱人，但至少观察其他人的做法通常也是值得的。
- en: Open source code
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开源代码
- en: Searching for existing code can achieve two high-level goals. It lets us see
    which challenges others have faced when doing similar modeling and surfaces potential
    issues with the given dataset. For this reason, I recommend looking for both pipelines
    tackling your product goal and code working with the dataset you have chosen.
    If you find an example, the first step would be to reproduce its results yourself.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索现有代码可以实现两个高级目标。它让我们看到其他人在进行类似建模时面临的挑战，并揭示了给定数据集可能存在的问题。因此，我建议寻找既处理您产品目标的管道，又处理您选择的数据集的代码。如果找到一个例子，第一步将是自己复现其结果。
- en: I have seen many data scientists attempt to leverage ML code they found online
    only to find that they are unable to train the given models to a similar level
    of accuracy claimed by the authors. Because new approaches are not always accompanied
    with well-documented and functioning code, ML results are often hard to reproduce
    and thus should always be verified.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我见过许多数据科学家尝试利用他们在网上找到的机器学习代码，却发现他们无法将给定的模型训练到作者声称的类似精度水平。因为新方法并不总是伴随着良好文档和功能良好的代码，机器学习的结果往往难以复现，因此应始终进行验证。
- en: Similar to your search for data, a good way to find similar codebases is to
    abstract your problem to its input and output types and find codebases tackling
    problems with similar types.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于您搜索数据的方式，找到类似代码库的一个好方法是将问题抽象为其输入和输出类型，并找到处理具有类似类型问题的代码库。
- en: 'For example, when attempting to generate HTML code from screenshots of a website,
    Tony Beltramelli, the author of the paper, [“pix2code: Generating Code from a
    Graphical User Interface Screenshot”](https://oreil.ly/rTQyD), realized that his
    problem boiled down to translating an image into a sequence. He leveraged existing
    architectures and best practices from a field that was more mature and also generated
    sequences from images, meaning image captioning! This allowed him to get excellent
    results on an entirely new task and leverage years of work in an adjacent application.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当试图从网站截图生成HTML代码时，论文作者Tony Beltramelli意识到他的问题归结为将图像转换为序列。他利用了现有的体系结构和最佳实践，这些实践来自一个更成熟的领域，并且还能从图像生成序列，这意味着图像字幕！这使他在一个全新的任务上获得了出色的结果，并利用了相邻应用多年的工作成果。
- en: Once you’ve looked at data and at code, you’re ready to move forward. Ideally,
    this process has given you a few pointers to start your work and acquire a more
    nuanced perspective on your problem. Let’s sum up the situations you can find
    yourself in after looking for prior work.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您查看了数据和代码，您就可以继续前进了。理想情况下，这个过程已经给了您一些指导，让您开始工作并获得对问题更加细致的理解。让我们总结一下，在寻找先前工作后您可能会遇到的情况。
- en: Bring both together
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将两者结合起来
- en: As we just discussed, leveraging existing open code and datasets can help make
    implementation faster. In the worst case, if none of the existing models performs
    well on an open dataset, you now at least know that this project will require
    significant modeling and/or data collection work.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们刚刚讨论的，利用现有的开源代码和数据集可以帮助加快实施过程。在最坏的情况下，如果没有现有模型在一个开放数据集上表现良好，那么您现在至少知道这个项目将需要大量的建模和/或数据收集工作。
- en: 'If you have found an existing model that solves a similar task and managed
    to train it on the dataset it was originally trained on, all that is left is to
    adapt it to your domain. To do so, I recommend going through the following successive
    steps:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您找到了一个解决类似任务的现有模型，并成功在其原始训练数据集上训练它，那么剩下的就是将其调整到您的领域。为此，我建议按照以下连续步骤进行：
- en: Find a similar open source model, ideally paired with a dataset it was trained
    on, and attempt to reproduce the training results yourself.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到一个类似的开源模型，最好是与其训练的数据集配对，并尝试自己复现训练结果。
- en: Once you have reproduced the results, find a dataset that is closer to your
    use case, and attempt to train the previous model on that dataset.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您复现了结果，请找一个与您使用情况更接近的数据集，并尝试在该数据集上训练之前的模型。
- en: Once you have integrated the dataset to the training code, it is time to judge
    how your model is doing using the metrics you defined and start iterating.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您将数据集集成到训练代码中，就是时候使用您定义的指标来评估您的模型表现，并开始迭代。
- en: We’ll explore the pitfalls of each of these steps and how to overcome them starting
    in [Part II](part02.html#section_2). For now, let’s go back to the case study
    and review the process we just described.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨每一个步骤的缺陷及其如何克服，从[第二部分](part02.html#section_2)开始。现在，让我们回到案例研究，回顾刚刚描述的过程。
- en: ML Editor Planning
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML编辑计划
- en: Let’s examine common writing advice and search for candidate datasets and models
    for the ML editor.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查常见的写作建议，并搜索ML编辑的候选数据集和模型。
- en: Initial Plan for an Editor
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编辑的初始计划
- en: 'We should start by implementing heuristics based on common writing guidelines.
    We’ll gather these rules by searching existing guides for writing and editing,
    like those described in [“The Simplest Approach: Being the Algorithm”](ch01.html#start_heuristic).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该从基于常见写作指南的启发式方法开始实施。我们将通过搜索现有的写作和编辑指南来收集这些规则，比如在[“最简单的方法：成为算法”](ch01.html#start_heuristic)中描述的那些。
- en: Our perfect dataset would consist of questions and their associated quality.
    First, we should quickly find a similar dataset that is easier to acquire. Based
    on observed performance on this dataset, we will then expand and deepen our search
    if needed.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们理想的数据集应该包括问题及其相关的质量。首先，我们应该快速找到一个更容易获取的类似数据集。根据这个数据集的表现，如果需要的话，我们将扩展和深化我们的搜索。
- en: Social media posts and online forums are good examples of text associated with
    a quality metric. Since most of these metrics exist to favor useful content, they
    often include quality metrics such as “likes” or “upvotes.”
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 社交媒体帖子和在线论坛是与质量指标相关的文本的好例子。由于大多数这些指标存在以支持有用内容为目的，它们通常包括“赞”或“点赞”等质量指标。
- en: '[Stack Exchange](https://stackexchange.com/), a network of Q&A communities,
    is a popular site for questions and answers. There’s also an entire anonymized
    data dump of Stack Exchange on [the Internet Archive](https://oreil.ly/NR6iQ),
    one of the data sources we mentioned earlier. This is a great dataset to start
    with.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[Stack Exchange](https://stackexchange.com/)，一个问答社区网络，是一个流行的问答网站。同时，在[互联网档案馆](https://oreil.ly/NR6iQ)上有整个匿名化的Stack
    Exchange数据备份，这是我们之前提到的数据来源之一。这是一个很好的数据集来开始研究。'
- en: We can build an initial model by using Stack Exchange questions and trying to
    predict a question’s upvotes score from its content. We will also use this opportunity
    to look through the dataset and label it, trying to find patterns.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用Stack Exchange的问题来构建一个初始模型，并尝试根据其内容预测问题的点赞分数。我们还将利用这个机会浏览数据集并标记它，试图找出模式。
- en: The model we want to build attempts to classify text quality accurately, to
    then provide writing recommendations. Many open source models exist for text classification;
    check out [this popular Python ML library scikit-learn tutorial](https://oreil.ly/y6Qdp)
    on the topic.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要构建的模型试图准确分类文本质量，然后提供写作建议。有许多开源模型用于文本分类；请查看关于这个主题的[这个流行的Python ML库scikit-learn教程](https://oreil.ly/y6Qdp)。
- en: Once we have a working classifier, we will cover how to leverage it to make
    recommendations in [Chapter 7](ch07.html#using_clas_recom).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了一个工作的分类器，我们将讨论如何利用它来做推荐，在[第7章](ch07.html#using_clas_recom)中。
- en: Now that we have a potential initial dataset, let’s transition to models and
    decide what we should start with.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个潜在的初始数据集，让我们过渡到模型，并决定从哪里开始。
- en: Always Start with a Simple Model
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 始终从一个简单的模型开始
- en: An important takeaway of this chapter is that the purpose of building an initial
    model and dataset is to produce informative results that will guide further modeling
    and data gathering work toward a more useful product.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的一个重要收获是，建立初始模型和数据集的目的是产生信息丰富的结果，以指导进一步的建模和数据收集工作，以实现更有用的产品。
- en: By starting with a simple model and extracting trends of what makes a Stack
    Overflow question successful, we can quickly measure performance and iterate on
    it.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从一个简单的模型开始并提取Stack Overflow问题成功的趋势，我们可以快速测量性能并进行迭代。
- en: The opposite approach of trying to build a perfect model from scratch does not
    work in practice. This is because ML is an iterative process where the fastest
    way to make progress is to see how a model fails. The faster your model fails,
    the more progress you will make. We will dive into this iterative process in much
    more detail in [Part III](part03.html#section_3).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 试图从头开始建立一个完美模型的相反方法在实践中是行不通的。这是因为ML是一个迭代过程，其中取得进展的最快方式是看模型如何失败。我们将在[第三部分](part03.html#section_3)中更详细地探讨这个迭代过程。
- en: We should keep caveats of each approach in mind, however. For example, the engagement
    that a question receives depends on many more factors than just the quality of
    its formulation. The context of the post, the community it was posted in, the
    popularity of the poster, the time at which it was posted, and many other details
    that the initial model will ignore also matter very much. To take such factors
    into account, we will restrict our dataset to a subset of communities. Our first
    model will ignore all metadata related to a post, but we will consider incorporating
    it if it seems necessary.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们应该记住每种方法的注意事项。例如，问题收到的关注度取决于远比问题质量更多的因素。帖子的上下文、发布社区、发布者的知名度、发布时间以及其他许多细节都非常重要，而这些初始模型可能会忽略。为了考虑这些因素，我们将限制数据集的范围到一部分社区。我们的第一个模型将忽略与帖子相关的所有元数据，但如果有必要的话，我们将考虑将其纳入。
- en: As such, our model uses what is often referred to as a *weak label*, one that
    is only slightly correlated with the desired output. As we analyze how the model
    performs, we will determine whether this label contains enough information for
    it to be useful.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的模型使用了通常被称为*弱标签*的标签，这种标签只与所需输出略有关联。随着我们分析模型的表现，我们将确定这个标签是否包含足够的信息以便于实用。
- en: We have a starting point, and we can now decide how we will progress. Making
    regular progress in ML can often seem hard due to the unpredictable aspect of
    modeling. It is hard to know ahead of time to which extent a given modeling approach
    will succeed. Because of this, I’d like to share a few tips to make steady progress.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有了一个起点，现在可以决定如何进展。在机器学习中，要实现稳定的进展通常似乎很困难，因为建模具有不可预测的方面。很难事先知道特定建模方法将成功到何种程度。因此，我想分享一些小贴士，帮助您实现稳定的进展。
- en: 'To Make Regular Progress: Start Simple'
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要实现稳定的进展：从简开始
- en: It is worth repeating that much of the challenge in ML is similar to one of
    the biggest challenges in software—resisting the urge to build pieces that are
    not needed yet. Many ML projects fail because they rely on an initial data acquisition
    and model building plan and do not regularly evaluate and update this plan. Because
    of the stochastic nature of ML, it is extremely hard to predict how far a given
    dataset or model will get us.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 值得重申的是，机器学习中的许多挑战与软件中最大的挑战之一相似——抵制构建尚不需要的部分的冲动。许多机器学习项目失败是因为它们依赖于初始数据获取和模型构建计划，并且不定期评估和更新此计划。由于机器学习的随机性质，极其难以预测特定数据集或模型能走多远。
- en: For that reason, it is *vital* to start with the simplest model that could address
    your requirements, build an end-to-end prototype including this model, and judge
    its performance not simply in terms of optimization metrics but in terms of your
    product goal.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从能够满足您需求的最简单模型开始，构建一个包含此模型的端到端原型，并根据产品目标评估其性能，这是*至关重要*的。
- en: Start with a Simple Pipeline
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从简单的流水线开始
- en: In the vast majority of cases, looking at the performance of a simple model
    on an initial dataset is the best way to decide what task should be tackled next.
    The goal is then to repeat this approach for each of the following steps, making
    small incremental improvements that are easy to track, rather than attempting
    to build the perfect model in one go.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在绝大多数情况下，查看初始数据集上简单模型的表现是决定下一步应该解决哪个任务的最佳方法。然后，目标是为每个后续步骤重复这种方法，进行小幅增量改进，这样易于跟踪，而不是试图一次性构建完美模型。
- en: To do this, we will need to build a pipeline that can take data in and return
    results. For most ML problems, there are actually two separate pipelines to consider.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要构建一个可以接收数据并返回结果的流水线。对于大多数机器学习问题，实际上有两个独立的流水线需要考虑。
- en: Training
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练
- en: For your model to be able to make accurate predictions, you first need to train
    it.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 要使您的模型能够进行准确的预测，首先需要对其进行训练。
- en: A training pipeline ingests all of the labeled data you would like to train
    on (for some tasks, datasets can be so large that they cannot fit on a single
    machine) and passes it to a model. It then trains said model on the dataset until
    it reaches satisfactory performance. Most often, a training pipeline is used to
    train multiple models and compare their performance on a held-out validation set.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 训练流水线将摄入所有您想要训练的标记数据（对于某些任务，数据集可能非常庞大，无法放在单台机器上），并将其传递给模型。然后，它在数据集上训练该模型，直到达到令人满意的性能。最常见的情况是，训练流水线用于训练多个模型，并在保留验证集上比较它们的性能。
- en: Inference
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推断
- en: This is your pipeline in production. It serves the results of a trained model
    to your user.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您生产中的管道。它将训练好的模型结果提供给用户。
- en: At a high level, an inference pipeline starts by accepting input data and preprocessing
    it. The preprocessing phase usually consists of multiple steps. Most commonly,
    these steps will include cleaning and validating the input, generating features
    a model needs, and formatting the data to a numerical representation appropriate
    for an ML model. Pipelines in more complex systems also often need to fetch additional
    information the model needs such as user features stored in a database, for example.
    The pipeline then runs the example through the model, applies any postprocessing
    logic, and returns a result.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，推理管道从接受输入数据并对其进行预处理开始。预处理阶段通常包括多个步骤。最常见的步骤包括清理和验证输入数据，生成模型所需的特征，并将数据格式化为适合机器学习模型的数值表示。在更复杂的系统中，管道通常还需要获取模型需要的其他信息，例如存储在数据库中的用户特征。然后，管道将示例输入到模型中，应用任何后处理逻辑，并返回结果。
- en: '[Figure 2-4](#training_inference) shows a flowchart of a typical inference
    and training pipeline. Ideally, the cleaning and preprocessing steps should be
    the same for both training and inference pipelines to ensure that a trained model
    receives data with the same format and characteristics at inference time.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-4](#training_inference)显示了典型推理和训练管道的流程图。理想情况下，清洁和预处理步骤对训练和推理管道应该是相同的，以确保训练好的模型在推理时接收到具有相同格式和特征的数据。'
- en: '![Training and inference pipelines are complementary](assets/bmla_0203.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![训练和推理管道是互补的](assets/bmla_0203.png)'
- en: Figure 2-4\. Training and inference pipelines are complementary
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-4\. 训练和推理管道是互补的
- en: 'Pipelines for different models will be built with different concerns in mind,
    but generally, the high-level infrastructure remains relatively stable. This is
    why it is valuable to start by building both your training and inference pipeline
    end-to-end to quickly evaluate the impact bottleneck Monica Rogati mentioned in
    [“Monica Rogati: How to Choose and Prioritize ML Projects”](ch01.html#monica_rogati).'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 不同模型的管道将考虑到不同的问题，但总体基础设施保持相对稳定。这就是为什么从构建端到端的训练和推理管道开始，快速评估莫妮卡·罗加蒂提到的瓶颈影响的价值所在[“莫妮卡·罗加蒂：如何选择和优先处理机器学习项目”](ch01.html#monica_rogati)。
- en: Most pipelines have a similar high-level structure, but because of differences
    in the structure of datasets, the functions themselves often have nothing in common.
    Let’s illustrate this by looking at the pipeline for the editor.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数管道具有类似的高级结构，但由于数据集结构的差异，这些功能本身通常没有共同点。我们来看一下编辑器的管道来加以说明。
- en: Pipeline for the ML Editor
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习编辑器的管道
- en: For the editor, we will be building both training and inference pipelines using
    Python, which is a common language of choice in ML. The goal in this first prototype
    is to build an end-to-end pipeline without being too concerned with its perfection.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 对于编辑器，我们将使用Python构建端到端的训练和推理管道，Python是机器学习中常用的语言选择。在这个第一个原型中，我们的目标是构建一个端到端的管道，而不是过于关注其完美性。
- en: 'As it should be done in any work that takes time, we can, and *will*, revisit
    parts of it to improve them. For training, we will write a pretty standard pipeline,
    one broadly applicable to many ML problems and which has a few functions, mainly
    ones that:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在任何需要时间的工作中应该做的那样，我们可以并*会*重新审视其中的部分以改进它们。对于训练，我们将编写一个相当标准的管道，适用于许多机器学习问题，并且有一些主要的功能，主要包括：
- en: Load records of data.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载数据记录。
- en: Clean data by removing incomplete records and input missing values when necessary.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过删除不完整的记录和在必要时输入缺失值来清洁数据。
- en: Preprocess and format data in a way that can be understood by a model.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以一种可以被模型理解的方式预处理和格式化数据。
- en: Remove a set of data that will not be trained on but used to validate model
    results (a validation set).
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除一组数据，这些数据不会被用来训练，而是用来验证模型的结果（验证集）。
- en: Train a model on a given subset of data and return a trained model and summary
    statistics.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对给定数据子集进行模型训练，并返回训练好的模型和总结统计信息。
- en: 'For inference, we will leverage some functions from the training pipeline,
    as well as writing a few custom ones. Ideally, we would need functions that:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 对于推理，我们将利用一些来自训练管道的功能，并编写一些自定义的功能。理想情况下，我们需要的功能包括：
- en: Load a trained model and keep it in memory (to provide faster results)
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载训练好的模型并将其保存在内存中（以提供更快的结果）
- en: Will preprocess (same as training)
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将预处理（与训练相同）
- en: Gather any relevant outside information
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集任何相关的外部信息
- en: Will pass one example through a model (an inference function)
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一个例子通过模型传递（推断函数）
- en: Will postprocess, to clean up results before serving them to users
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将进行后处理，以在提供给用户之前清理结果
- en: It is often easiest to visualize a pipeline as a flowchart, such as the one
    depicted for [Figure 2-5](#ml_editor_pipeline).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 通常最容易将一个流水线可视化为流程图，例如 [图 2-5](#ml_editor_pipeline) 所示的流程图。
- en: '![Pipelines for the editor](assets/bmla_0205.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![编辑器的流水线](assets/bmla_0205.png)'
- en: Figure 2-5\. Pipelines for the editor
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-5\. 编辑器的流水线
- en: 'In addition, we will write various analysis and exploration functions to help
    us diagnose problems, such as:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将编写各种分析和探索函数，以帮助我们诊断问题，例如：
- en: A function that visualizes examples the model performs the best and worst on
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化模型表现最佳和最差的示例的函数
- en: Functions to explore data
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索数据的函数
- en: A function to explore model results
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索模型结果的函数
- en: Many pipelines contain steps that validate inputs to the model and check its
    final outputs. Such checks help with debugging, as you’ll see in [Chapter 10](ch10.html#model_engineering),
    and help guarantee a standard of quality for an application by catching any poor
    results before displaying them to a user.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 许多流水线包含验证模型输入和检查其最终输出的步骤。这些检查有助于调试，正如您将在 [第 10 章](ch10.html#model_engineering)
    中看到的，并通过捕捉任何不良结果在显示给用户之前帮助保证应用程序的质量标准。
- en: Remember that when using ML, the outputs of models on unseen data can often
    be unpredictable and will not always be satisfactory. For this reason, it is important
    to acknowledge that models will not always work and to architect systems around
    this potential for mistakes.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在使用机器学习时，模型在未见数据上的输出通常是不可预测的，并且不总是令人满意。因此，重要的是要认识到模型不总是有效，并在此基础上设计系统以应对可能的错误。
- en: Conclusion
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We have now seen how to define core metrics that allow us to compare entirely
    different models and understand the trade-offs between each of them. We covered
    resources and methods to use to speed up the building process of your first few
    pipelines. We then outlined an overview of what we’ll need to build for each pipeline
    to get a first set of results.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经了解了如何定义核心指标，使我们能够比较完全不同的模型，并理解它们之间的权衡。我们涵盖了加快建立您的前几个流水线过程的资源和方法。然后，我们概述了构建每个流水线所需的概述，以获取一组初始结果。
- en: We now have an idea framed as an ML problem, a way to measure progress, and
    an initial plan. It is time to dive into the implementation.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将一个问题构建成了一个机器学习问题，有了衡量进展的方法和一个初始计划。现在是深入实施的时候了。
- en: In [Part II](part02.html#section_2), we will dive into how to build a first
    pipeline and explore and visualize an initial dataset.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 II 部分](part02.html#section_2) 中，我们将深入探讨如何构建第一个流水线，并探索和可视化初始数据集。
