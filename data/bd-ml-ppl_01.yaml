- en: Chapter 1\. Introduction
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第1章。引言
- en: In this first chapter, we will introduce machine learning pipelines and outline
    all the steps that go into building them. We’ll explain what needs to happen to
    move your machine learning model from an experiment to a robust production system.
    We’ll also introduce our example project that we will use throughout the rest
    of the book to demonstrate the principles we describe.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第一章中，我们将介绍机器学习流水线，并概述构建流水线所需的所有步骤。我们将解释如何将您的机器学习模型从实验推进到稳健的生产系统。我们还将介绍我们将在本书余下部分使用的示例项目，以演示我们所描述原则的应用。
- en: Why Machine Learning Pipelines?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要使用机器学习流水线？
- en: 'The key benefit of machine learning pipelines lies in the automation of the
    model life cycle steps. When new training data becomes available, a workflow which
    includes data validation, preprocessing, model training, analysis, and deployment
    should be triggered. We have observed too many data science teams manually going
    through these steps, which is costly and also a source of errors. Let’s cover
    some details of the benefits of machine learning pipelines:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习流水线的关键优势在于自动化模型生命周期的步骤。当新的训练数据变得可用时，应该触发包括数据验证、预处理、模型训练、分析和部署的工作流程。我们观察到许多数据科学团队手动完成这些步骤，这既昂贵又容易出错。让我们详细讨论一下机器学习流水线的好处：
- en: Ability to focus on new models, not maintaining existing models
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 能够专注于新模型，而不是维护现有模型
- en: Automated machine learning pipelines will free up data scientists from maintaining
    existing models. We have observed too many data scientists spending their days
    on keeping previously developed models up to date. They run scripts manually to
    preprocess their training data, they write one-off deployment scripts, or they
    manually tune their models. Automated pipelines allow data scientists to develop
    new models, the fun part of their job. Ultimately, this will lead to higher job
    satisfaction and retention in a competitive job market.
  id: totrans-5
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动化机器学习流水线将使数据科学家摆脱维护现有模型的工作。我们观察到许多数据科学家整天都在维护先前开发的模型。他们手动运行脚本预处理训练数据，编写一次性部署脚本，或手动调整模型。自动化流水线允许数据科学家开发新模型，这是他们工作中有趣的部分。最终，这将提高工作满意度，并在竞争激烈的就业市场中提高留任率。
- en: Prevention of bugs
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 防止错误
- en: Automated pipelines can prevent bugs. As we will see in later chapters, newly
    created models will be tied to a set of versioned data and preprocessing steps
    will be tied to the developed model. This means that if new data is collected,
    a new model will be generated. If the preprocessing steps are updated, the training
    data will become invalid and a new model will be generated. In manual machine
    learning workflows, a common source of bugs is a change in the preprocessing step
    after a model was trained. In this case, we would deploy a model with different
    processing instructions than what we trained the model with. These bugs might
    be really difficult to debug since an inference of the model is still possible,
    but simply incorrect. With automated workflows, these errors can be prevented.
  id: totrans-7
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动化流水线可以防止错误。正如我们将在后面的章节中看到的那样，新创建的模型将与一组版本化的数据和预处理步骤相关联。这意味着如果收集到新数据，将生成一个新模型。如果更新了预处理步骤，训练数据将变得无效，并生成一个新模型。在手动机器学习工作流程中，错误的常见来源是模型训练后预处理步骤的更改。在这种情况下，我们可能会部署带有不同处理说明的模型，这与我们训练模型时的处理方式不同。由于模型推断仍然可能存在，这些错误可能非常难以调试，但却是明显的不正确。通过自动化工作流程，可以预防这些错误。
- en: Useful paper trail
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的文件记录
- en: The experiment tracking and the model release management generate a paper trail
    of the model changes. The experiment will record changes to the model’s hyperparameters,
    the used datasets, and the resulting model metrics (e.g., loss or accuracy). The
    model release management will keep track of which model was ultimately selected
    and deployed. This paper trail is especially valuable if the data science team
    needs to re-create a model or track the model’s performance.
  id: totrans-9
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 实验跟踪和模型发布管理生成模型变更的文件记录。实验将记录模型超参数的变化、使用的数据集以及生成的模型指标（例如损失或准确度）。模型发布管理将跟踪最终选择和部署的模型。如果数据科学团队需要重新创建模型或跟踪模型的性能，这些文件记录尤为宝贵。
- en: Standardization
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化
- en: Standardized machine learning pipelines improve the experience of a data science
    team. Due to the standardized setups, data scientists can be onboarded quickly
    or move across teams and find the same development environments. This improves
    efficiency and reduces the time spent getting set up on a new project. The time
    investment of setting up machine learning pipelines can also lead to an improved
    retention rate.
  id: totrans-11
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 标准化的机器学习管道提高了数据科学团队的体验。由于标准化的设置，数据科学家可以快速上手或者在团队间流动，并找到相同的开发环境。这提高了效率并减少了在新项目上设置的时间。设置机器学习管道的时间投资也可能导致提高的保留率。
- en: The business case for pipelines
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的商业案例
- en: 'The implementation of automated machine learning pipelines will lead to three
    key impacts for a data science team:'
  id: totrans-13
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动化机器学习管道的实施将对数据科学团队产生三个关键影响：
- en: More development time for novel models
  id: totrans-14
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为新模型提供更多的开发时间
- en: Simpler processes to update existing models
  id: totrans-15
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 更新现有模型的简化流程
- en: Less time spent to reproduce models
  id: totrans-16
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 减少重复模型的时间
- en: 'All these aspects will reduce the costs of data science projects. But furthermore,
    automated machine learning pipelines will:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方面将减少数据科学项目的成本。而且，自动化的机器学习管道将：
- en: Help detect potential biases in the datasets or in the trained models. Spotting
    biases can prevent harm to people who interact with the model. For example, [Amazon’s
    machine learning–powered resume screener](https://oreil.ly/39rEg) was found to
    be biased against women.
  id: totrans-18
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 帮助检测数据集或训练模型中的潜在偏见。发现偏见可以防止对与模型交互的人造成伤害。例如，[亚马逊的机器学习驱动简历筛选器](https://oreil.ly/39rEg)发现存在性别偏见。
- en: Create a paper trail (via experiment tracking and model release management)
    that will assist if questions arise around data protection laws, such as Europe’s
    General Data Protection Regulation (GDPR).
  id: totrans-19
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 创建纸质记录（通过实验跟踪和模型发布管理），以帮助解决关于数据保护法律的问题，如欧洲的通用数据保护条例（GDPR）。
- en: Free up development time for data scientists and increase their job satisfaction.
  id: totrans-20
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 释放数据科学家的开发时间，提高他们的工作满意度。
- en: When to Think About Machine Learning Pipelines
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 何时考虑机器学习管道
- en: Machine learning pipelines provide a variety of advantages, but not every data
    science project needs a pipeline. Sometimes data scientists simply want to experiment
    with a new model, investigate a new model architecture, or reproduce a recent
    publication. Pipelines wouldn’t be useful in these cases. However, as soon as
    a model has users (e.g., it is being used in an app), it will require continuous
    updates and fine-tuning. In these situations, we are back in the scenarios we
    discussed earlier about continuously updating models and reducing the burden of
    these tasks for data scientists.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道提供了各种优势，但并非每个数据科学项目都需要管道。有时候数据科学家只是想尝试一个新模型，调查一个新的模型架构，或者重现最近的出版物。在这些情况下，管道并不实用。然而，一旦模型有了用户（例如，它被用于应用程序中），它将需要持续更新和微调。在这些情况下，我们回到了我们早些时候讨论的持续更新模型和减少数据科学家任务负担的情景。
- en: Pipelines also become more important as a machine learning project grows. If
    the dataset or resource requirements are large, the approaches we discuss allow
    for easy infrastructure scaling. If repeatability is important, this is provided
    through the automation and the audit trail of machine learning pipelines.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习项目的规模扩大后，管道变得更加重要。如果数据集或资源需求较大，我们讨论的方法可以实现基础设施的轻松扩展。如果重复性很重要，这是通过机器学习管道的自动化和审计跟踪来提供的。
- en: Overview of the Steps in a Machine Learning Pipeline
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道步骤的概述
- en: A machine learning pipeline starts with the ingestion of new training data and
    ends with receiving some kind of feedback on how your newly trained model is performing.
    This feedback can be a production performance metric or feedback from users of
    your product. The pipeline includes a variety of steps, including data preprocessing,
    model training, and model analysis, as well as the deployment of the model. You
    can imagine that going through these steps manually is cumbersome and very error-prone.
    In the course of this book, we will introduce tools and solutions to automate
    your machine learning pipeline.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道从新训练数据的摄取开始，以接收新训练模型的表现反馈结束。这个反馈可以是生产性能指标或产品用户的反馈。管道包括各种步骤，包括数据预处理、模型训练和模型分析，以及模型的部署。你可以想象手动完成这些步骤是繁琐且容易出错的。在本书的过程中，我们将介绍自动化机器学习管道的工具和解决方案。
- en: As you can see in [Figure 1-1](#filepos55701), the pipeline is actually a recurring
    cycle. Data can be continuously collected and, therefore, machine learning models
    can be updated. More data generally means improved models. And because of this
    constant influx of data, automation is key. In real-world applications, you want
    to retrain your models frequently. If you don’t, in many cases accuracy will decrease
    because the training data is different from the new data that the model is making
    predictions on. If retraining is a manual process, where it is necessary to manually
    validate the new training data or analyze the updated models, a data scientist
    or machine learning engineer would have no time to develop new models for entirely
    different business problems.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在[图1-1](#filepos55701)中看到的那样，管道实际上是一个循环周期。数据可以持续收集，因此可以更新机器学习模型。更多的数据通常意味着改进的模型。由于数据不断涌入，自动化变得至关重要。在实际应用中，您希望经常重新训练您的模型。如果不这样做，在许多情况下，准确性会降低，因为训练数据与模型正在预测的新数据不同。如果重新训练是一个手动过程，需要手动验证新的训练数据或分析更新的模型，那么数据科学家或机器学习工程师将没有时间为完全不同的业务问题开发新模型。
- en: '![](images/00054.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00054.jpg)'
- en: Figure 1-1\. Model life cycle
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图1-1\. 模型生命周期
- en: A machine learning pipeline commonly includes the steps in the following sections.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道通常包括以下部分中的步骤。
- en: Data Ingestion and Data Versioning
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据摄入和数据版本控制
- en: Data ingestion, as we describe in [Chapter 3](index_split_008.html#filepos156116),
    is the beginning of every machine learning pipeline. In this pipeline step, we
    process the data into a format that the following components can digest. The data
    ingestion step does not perform any feature engineering (this happens after the
    data validation step). It is also a good moment to version the incoming data to
    connect a data snapshot with the trained model at the end of the pipeline.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 数据摄入，正如我们在[第三章](index_split_008.html#filepos156116)中描述的那样，是每个机器学习管道的开始。在这个管道步骤中，我们将数据处理成后续组件可以消化的格式。数据摄入步骤不执行任何特征工程（这发生在数据验证步骤之后）。这也是将传入数据版本化的良好时机，以将数据快照与管道末端的训练模型连接起来。
- en: Data Validation
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据验证
- en: Before training a new model version, we need to validate the new data. Data
    validation ([Chapter 4](index_split_009.html#filepos295199)) focuses on checking
    that the statistics of the new data are as expected (e.g., the range, number of
    categories, and distribution of categories). It also alerts the data scientist
    if any anomalies are detected. For example, if you are training a binary classification
    model, your training data could contain 50% of Class X samples and 50% of Class
    Y samples. Data validation tools provide alerts if the split between these classes
    changes, where perhaps the newly collected data is split 70/30 between the two
    classes. If a model is being trained with such an imbalanced training set and
    the data scientist hasn’t adjusted the model’s loss function, or over/under sampled
    category X or Y, the model predictions could be biased toward the dominant category.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练新模型版本之前，我们需要验证新数据。数据验证（[第四章](index_split_009.html#filepos295199)）的重点是检查新数据的统计数据是否符合预期（例如范围、类别数量和类别分布）。如果检测到任何异常，它还会提醒数据科学家。例如，如果您正在训练一个二分类模型，您的训练数据可能包含50%的X类样本和50%的Y类样本。数据验证工具将在这些类别之间的分割发生变化时提供警报，例如新收集的数据在这两个类别之间的分割变为70/30。如果模型在这样一个不平衡的训练集上进行训练，并且数据科学家没有调整模型的损失函数，或者过度/欠采样类别X或Y，那么模型的预测可能会偏向于主导类别。
- en: Common data validation tools will also allow you to compare different datasets.
    If you have a dataset with a dominant label and you split the dataset into a training
    and validation set, you need to make sure that the label split is roughly the
    same between the two datasets. Data validation tools will allow you to compare
    datasets and highlight anomalies.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的数据验证工具还允许您比较不同的数据集。如果您有一个带有主导标签的数据集，并且将数据集分割为训练集和验证集，您需要确保标签在这两个数据集之间的分割大致相同。数据验证工具将允许您比较数据集并突出显示异常。
- en: If the validation highlights anything out of the ordinary, the pipeline can
    be stopped here and the data scientist can be alerted. If a shift in the data
    is detected, the data scientist or the machine learning engineer can either change
    the sampling of the individual classes (e.g., only pick the same number of examples
    from each class), or change the model’s loss function, kick off a new model build
    pipeline, and restart the life cycle.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果验证发现任何异常情况，可以在此停止流水线并通知数据科学家。如果检测到数据的变化，数据科学家或机器学习工程师可以改变各个类别的抽样（例如，只从每个类别中选择相同数量的示例），或者改变模型的损失函数，启动新的模型构建流水线，并重新启动生命周期。
- en: Data Preprocessing
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理
- en: It is highly likely that you cannot use your freshly collected data and train
    your machine learning model directly. In almost all cases, you will need to preprocess
    the data to use it for your training runs. Labels often need to be converted to
    one or multi-hot vectors.[1](#filepos81806) The same applies to the model inputs.
    If you train a model from text data, you want to convert the characters of the
    text to indices or the text tokens to word vectors. Since preprocessing is only
    required prior to model training and not with every training epoch, it makes the
    most sense to run the preprocessing in its own life cycle step before training
    the model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你几乎无法直接使用新收集的数据直接训练机器学习模型。在几乎所有情况下，您需要预处理数据以用于训练运行。标签通常需要转换为单热或多热向量。[1](#filepos81806)对模型输入也适用相同的情况。如果从文本数据训练模型，您希望将文本的字符转换为索引或文本标记转换为单词向量。由于预处理仅在模型训练之前需要，而不是每个训练时期都需要，因此在训练模型之前单独运行预处理是最合理的生命周期步骤。
- en: Data preprocessing tools can range from a simple Python script to elaborate
    graph models. While most data scientists focus on the processing capabilities
    of their preferred tools, it is also important that modifications of preprocessing
    steps can be linked to the processed data and vice versa. This means if someone
    modifies a processing step (e.g., allowing an additional label in a one-hot vector
    conversion), the previous training data should become invalid and force an update
    of the entire pipeline. We describe this pipeline step in [Chapter 5](index_split_010.html#filepos397186).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理工具可以从简单的 Python 脚本到复杂的图形模型。虽然大多数数据科学家专注于他们偏爱的工具的处理能力，但同样重要的是，预处理步骤的修改能够与处理后的数据相链接。这意味着如果有人修改了一个处理步骤（例如，在一个独热向量转换中允许额外的标签），那么先前的训练数据应该无效，强制更新整个流水线。我们在[第5章](index_split_010.html#filepos397186)中描述了这个流水线步骤。
- en: Model Training and Tuning
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练和调整
- en: The model training step ([Chapter 6](index_split_011.html#filepos491525)) is
    the core of the machine learning pipeline. In this step, we train a model to take
    inputs and predict an output with the lowest error possible. With larger models,
    and especially with large training sets, this step can quickly become difficult
    to manage. Since memory is generally a finite resource for our computations, the
    efficient distribution of the model training is crucial.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练步骤（[第6章](index_split_011.html#filepos491525)）是机器学习流水线的核心。在这一步骤中，我们训练一个模型以尽可能低的误差来预测输出。对于较大的模型，特别是大训练集，这一步骤很快就会变得难以管理。由于内存通常是我们计算的有限资源，模型训练的有效分布至关重要。
- en: Model tuning has seen a great deal of attention lately because it can yield
    significant performance improvements and provide a competitive edge. Depending
    on your machine learning project, you may choose to tune your model before starting
    to think about machine learning pipelines or you may want to tune it as part of
    your pipeline. Because our pipelines are scalable, thanks to their underlying
    architecture, we can spin up a large number of models in parallel or in sequence.
    This lets us pick out the optimal model hyperparameters for our final production
    model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 模型调整近来受到了极大关注，因为它可以显著提升性能并提供竞争优势。根据您的机器学习项目，您可以选择在开始考虑机器学习流水线之前调整模型，或者作为流水线的一部分调整它。由于我们的管道具有可伸缩性，得益于其底层架构，我们可以并行或顺序地启动大量模型。这使我们能够挑选出最终生产模型的最佳模型超参数。
- en: Model Analysis
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 模型分析
- en: Generally, we would use accuracy or loss to determine the optimal set of model
    parameters. But once we have settled on the final version of the model, it’s extremely
    useful to carry out a more in-depth analysis of the model’s performance (described
    in [Chapter 7](index_split_012.html#filepos624151)). This may include calculating
    other metrics such as precision, recall, and AUC (area under the curve), or calculating
    performance on a larger dataset than the validation set used in training.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们会使用准确率或损失来确定模型参数的最佳设定。但一旦我们确认了模型的最终版本，深入分析模型性能会非常有用（见[第7章](index_split_012.html#filepos624151)描述）。这可能包括计算其他指标，如精度、召回率和AUC（曲线下面积），或在比训练时使用的验证集更大的数据集上计算性能。
- en: Another reason for an in-depth model analysis is to check that the model’s predictions
    are fair. It’s impossible to tell how the model will perform for different groups
    of users unless the dataset is sliced and the performance is calculated for each
    slice. We can also investigate the model’s dependence on features used in training
    and explore how the model’s predictions would change if we altered the features
    of a single training example.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 进行深入模型分析的另一个原因是检查模型的预测是否公平。除非对数据集进行切片并计算每个切片的性能，否则无法确定模型在不同用户组中的表现。我们还可以调查模型对训练中使用的特征的依赖性，并探索如果更改单个训练示例的特征，模型预测会如何改变。
- en: Similar to the model-tuning step and the final selection of the best performing
    model, this workflow step requires a review by a data scientist. However, we will
    demonstrate how the entire analysis can be automated with only the final review
    done by a human. The automation will keep the analysis of the models consistent
    and comparable against other analyses.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于模型调整步骤和最佳执行模型的最终选择，此工作流步骤需要由数据科学家审查。但我们将展示如何仅通过人工进行最终审查，即可实现整个分析的自动化。自动化将确保模型分析的一致性，并与其他分析进行比较。
- en: Model Versioning
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 模型版本控制
- en: The purpose of the model versioning and validation step is to keep track of
    which model, set of hyperparameters, and datasets have been selected as the next
    version to be deployed.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 模型版本控制和验证步骤的目的是跟踪已被选择为下一个部署版本的模型、超参数集和数据集。
- en: 'Semantic versioning in software engineering requires you to increase the major
    version number when you make an incompatible change in your API or when you add
    major features. Otherwise, you increase the minor version number. Model release
    management has another degree of freedom: the dataset. There are situations in
    which you can achieve a significant difference of model performance without changing
    a single model parameter or architecture description by providing significantly
    more and/or better data for the training process. Does that performance increase
    warrant a major version upgrade?'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件工程中的语义化版本控制要求在API发生不兼容更改或添加重大功能时增加主版本号。否则，应增加次版本号。模型发布管理还有另一自由度：数据集。有些情况下，通过为训练过程提供显著更多和/或更好的数据，可以实现模型性能的显著差异，而无需更改单个模型参数或架构描述。这种性能提升是否值得进行主版本升级？
- en: While the answer to this question might be different for every data science
    team, it is essential to document all inputs into a new model version (hyperparameters,
    datasets, architecture) and track them as part of this release step.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管每个数据科学团队对这个问题的答案可能不同，但记录所有输入到新模型版本（超参数、数据集、架构）并跟踪它们作为此发布步骤的一部分是至关重要的。
- en: Model Deployment
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署
- en: Once you have trained, tuned, and analyzed your model, it is ready for prime
    time. Unfortunately, too many models are deployed with one-off implementations,
    which makes updating models a brittle process.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您已经训练、调优和分析了您的模型，它就准备好了。不幸的是，许多模型是以一次性实现方式部署的，这使得更新模型变得脆弱的过程。
- en: Modern model servers allow you to deploy your models without writing web app
    code. Often, they provide multiple API interfaces like representational state
    transfer (REST) or remote procedure call (RPC) protocols and allow you to host
    multiple versions of the same model simultaneously. Hosting multiple versions
    at the same time will allow you to run A/B tests on your models and provide valuable
    feedback about your model improvements.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现代模型服务器允许您在不编写Web应用程序代码的情况下部署模型。通常，它们提供多种API接口，如表现状态转移（REST）或远程过程调用（RPC）协议，并允许同时托管同一模型的多个版本。同时托管多个版本将使您能够对模型运行A/B测试，并提供有关模型改进的宝贵反馈。
- en: Model servers also allow you to update a model version without redeploying your
    application, which will reduce your application’s downtime and reduce the communication
    between the application development and the machine learning teams. We describe
    model deployment in Chapters [8](index_split_013.html#filepos764992) and [9](index_split_016.html#filepos996706).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 模型服务器还允许您更新模型版本，而无需重新部署应用程序，这将减少应用程序的停机时间并减少应用程序开发与机器学习团队之间的通信。我们在[第8章](index_split_013.html#filepos764992)和[第9章](index_split_016.html#filepos996706)描述了模型部署。
- en: Feedback Loops
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈回路
- en: The last step of the machine learning pipeline is often forgotten, but it is
    crucial to the success of data science projects. We need to close the loop. We
    can then measure the effectiveness and performance of the newly deployed model.
    During this step, we can capture valuable information about the performance of
    the model. In some situations, we can also capture new training data to increase
    our datasets and update our model. This may involve a human in the loop, or it
    may be automatic. We discuss feedback loops in [Chapter 13](index_split_020.html#filepos1489635).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习流水线的最后一步经常被遗忘，但对数据科学项目的成功至关重要。我们需要闭环。然后，我们可以衡量新部署模型的有效性和性能。在此步骤中，我们可以获取有关模型性能的宝贵信息。在某些情况下，我们还可以捕获新的训练数据以增加我们的数据集并更新我们的模型。这可能涉及人在回路中，也可能是自动的。我们在[第13章](index_split_020.html#filepos1489635)讨论了反馈回路。
- en: Except for the two manual review steps (the model analysis step and the feedback
    step), we can automate the entire pipeline. Data scientists should be able to
    focus on the development of new models, not on updating and maintaining existing
    models.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 除了两个手动审查步骤（模型分析步骤和反馈步骤），我们可以自动化整个流水线。数据科学家应专注于开发新模型，而不是更新和维护现有模型。
- en: Data Privacy
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据隐私
- en: At the time of writing, data privacy considerations sit outside the standard
    machine learning pipeline. We expect this to change in the future as consumer
    concerns grow over the use of their data and new laws are brought in to restrict
    the usage of personal data. This will lead to privacy-preserving methods being
    integrated into tools for building machine learning pipelines.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，数据隐私考虑超出了标准的机器学习流水线范围。随着消费者对其数据使用的关注增加以及新法律的实施限制个人数据的使用，我们预计这种情况将发生变化。这将导致隐私保护方法被整合到构建机器学习流水线工具中。
- en: 'We discuss several current options for increasing privacy in machine learning
    models in [Chapter 14](index_split_021.html#filepos1522914):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了增强机器学习模型隐私的几种当前选项，详情请参阅[第14章](index_split_021.html#filepos1522914)：
- en: Differential privacy, where math guarantees that model predictions do not expose
    a user’s data
  id: totrans-60
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 差分隐私，数学上保证模型预测不会暴露用户数据
- en: Federated learning, where the raw data does not leave a user’s device
  id: totrans-61
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 联合学习，其中原始数据不会离开用户设备
- en: Encrypted machine learning, where either the entire training process can run
    in the encrypted space or a model trained on raw data can be encrypted
  id: totrans-62
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 加密机器学习，其中整个训练过程可以在加密空间中运行，或者对原始数据进行训练的模型可以进行加密
- en: Pipeline Orchestration
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线编排
- en: All the components of a machine learning pipeline described in the previous
    section need to be executed or, as we say, orchestrated, so that the components
    are being executed in the correct order. Inputs to a component must be computed
    before a component is executed. The orchestration of these steps is performed
    by tools such as Apache Beam, Apache Airflow (discussed in [Chapter 11](index_split_018.html#filepos1264016)),
    or Kubeflow Pipelines for Kubernetes infrastructure (discussed in [Chapter 12](index_split_019.html#filepos1378763)).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中描述的机器学习流水线的所有组件都需要被执行，或者说，被编排，以确保组件按正确顺序执行。在执行组件之前必须计算组件的输入。这些步骤的编排由诸如Apache
    Beam、Apache Airflow（详见[第11章](index_split_018.html#filepos1264016)）或用于Kubernetes基础设施的Kubeflow
    Pipelines（详见[第12章](index_split_019.html#filepos1378763)）等工具执行。
- en: While data pipeline tools coordinate the machine learning pipeline steps, pipeline
    artifact stores like the TensorFlow ML MetadataStore capture the outputs of the
    individual processes. In [Chapter 2](index_split_007.html#filepos83150), we will
    provide an overview of TFX’s MetadataStore and look behind the scenes of TFX and
    its pipeline components.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数据流水线工具协调机器学习流水线步骤，但像TensorFlow ML MetadataStore这样的流水线工件存储捕获了各个过程的输出。在[第2章](index_split_007.html#filepos83150)，我们将概述TFX的MetadataStore并深入探讨TFX及其流水线组件的内部工作。
- en: Why Pipeline Orchestration?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么需要流水线编排？
- en: In 2015, a group of machine learning engineers at Google concluded that one
    of the reasons machine learning projects often fail is that most projects come
    with custom code to bridge the gap between machine learning pipeline steps.[2](#filepos82238)
    However, this custom code doesn’t transfer easily from one project to the next.
    The researchers summarized their findings in the paper “Hidden Technical Debt
    in Machine Learning Systems.”[3](#filepos82819) The authors argue in this paper
    that the glue code between the pipeline steps is often brittle and that custom
    scripts don’t scale beyond specific cases. Over time, tools like Apache Beam,
    Apache Airflow, or Kubeflow Pipelines have been developed. These tools can be
    used to manage the machine learning pipeline tasks; they allow a standardized
    orchestration and an abstraction of the glue code between tasks.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在2015年，谷歌的一群机器学习工程师总结出，机器学习项目经常失败的一个原因是大多数项目都使用定制代码来弥合机器学习流水线步骤之间的差距[2](#filepos82238)。然而，这些定制代码并不容易从一个项目转移到下一个。研究人员在论文《机器学习系统中隐藏的技术债务》[3](#filepos82819)
    中总结了他们的发现。作者在论文中认为，流水线步骤之间的粘合代码通常很脆弱，并且定制脚本在特定案例之外不具备扩展性。随着时间的推移，诸如Apache Beam、Apache
    Airflow或Kubeflow Pipelines等工具得以开发。这些工具可用于管理机器学习流水线任务，它们允许标准化的编排以及在任务之间的粘合代码的抽象化。
- en: While it might seem cumbersome at first to learn a new tool (e.g., Beam or Airflow)
    or a new framework (e.g., Kubeflow) and set up an additional machine learning
    infrastructure (e.g., Kubernetes), the time investment will pay off very soon.
    By not adopting standardized machine learning pipelines, data science teams will
    face unique project setups, arbitrary log file locations, unique debugging steps,
    etc. The list of complications can be endless.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一开始学习新工具（如Beam或Airflow）或新框架（如Kubeflow）并设置额外的机器学习基础设施（如Kubernetes）可能显得繁琐，但这种时间投资很快就会得到回报。如果不采用标准化的机器学习流水线，数据科学团队将面临独特的项目设置、任意的日志文件位置、独特的调试步骤等问题。这些复杂性问题可能无穷无尽。
- en: Directed Acyclic Graphs
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有向无环图
- en: Pipeline tools like Apache Beam, Apache Airflow, and Kubeflow Pipelines manage
    the flow of tasks through a graph representation of the task dependencies.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 像Apache Beam、Apache Airflow和Kubeflow Pipelines这样的流水线工具通过任务依赖关系的图形表示来管理任务的流动。
- en: As the example graph in [Figure 1-2](#filepos71984) shows, the pipeline steps
    are directed. This means that a pipeline starts with Task A and ends with Task
    E, which guarantees that the path of execution is clearly defined by the tasks’
    dependencies. Directed graphs avoid situations where some tasks start without
    all dependencies fully computed. Since we know that we must preprocess our training
    data before training a model, the representation as a directed graph prevents
    the training task from being executed before the preprocessing step is completed.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图1-2](#filepos71984)中的示例图所示，流水线步骤是有向的。这意味着一个流水线从任务A开始，以任务E结束，保证了执行路径由任务依赖明确定义。有向图避免了某些任务在所有依赖项完全计算之前就开始执行的情况。由于我们知道在训练模型之前必须预处理训练数据，有向图的表示防止了在完成预处理步骤之前执行训练任务。
- en: '![](images/00049.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00049.jpg)'
- en: Figure 1-2\. Example directed acyclic graph
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图1-2\. 示例有向无环图
- en: Pipeline graphs must also be acyclic, meaning that a graph isn’t linking to
    a previously completed task. This would mean that the pipeline could run endlessly
    and therefore wouldn’t finish the workflow.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线图还必须是无环的，这意味着图形不链接到先前完成的任务。这将意味着流水线可能无休止地运行，因此无法完成工作流程。
- en: Because of the two conditions (being directed and acyclic), pipeline graphs
    are called directed acyclic graphs (DAGs). You will discover DAGs are a central
    concept behind most workflow tools. We will discuss more details about how these
    graphs are executed in Chapters [11](index_split_018.html#filepos1264016) and
    [12](index_split_019.html#filepos1378763).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这两个条件（有向和无环），流水线图被称为有向无环图（DAGs）。您会发现DAG是大多数工作流工具背后的核心概念。我们将在第[11](index_split_018.html#filepos1264016)章和第[12](index_split_019.html#filepos1378763)章讨论这些图是如何执行的更多细节。
- en: Our Example Project
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例项目
- en: To follow along with this book, we have created an example project using open
    source data. The dataset is a collection of consumer complaints about financial
    products in the United States, and it contains a mixture of structured data (categorical/numeric
    data) and unstructured data (text). The data is taken from the [Consumer Finance
    Protection Bureau](https://oreil.ly/0RVBG).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随本书的内容，我们创建了一个使用开放数据的示例项目。数据集是关于美国消费者对金融产品的投诉集合，包含结构化数据（分类/数值数据）和非结构化数据（文本）。数据来自[消费者金融保护局](https://oreil.ly/0RVBG)。
- en: '[Figure 1-3](#filepos73686) shows a sample from this dataset.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1-3](#filepos73686)显示了该数据集的一个样本。'
- en: '![](images/00092.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00092.jpg)'
- en: Figure 1-3\. Data sample
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1-3\. 数据样本
- en: The machine learning problem is, given data about the complaint, to predict
    whether the complaint was disputed by the consumer. In this dataset, 30% of complaints
    are disputed, so the dataset is not balanced.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习问题是，根据投诉的数据预测消费者是否对投诉有异议。在这个数据集中，30%的投诉有异议，所以数据集不平衡。
- en: Project Structure
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 项目结构
- en: 'We have provided our example project as a [GitHub repo](https://oreil.ly/bmlp-git),
    and you can clone it as normal using the following command:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了我们的示例项目作为[GitHub仓库](https://oreil.ly/bmlp-git)，您可以使用以下命令正常克隆它：
- en: '`$` `git clone https://github.com/Building-ML-Pipelines/``\` `building-machine-learning-pipelines.git`'
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$` `git clone https://github.com/Building-ML-Pipelines/``\` `building-machine-learning-pipelines.git`'
- en: PYTHON PACKAGE VERSIONS
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: PYTHON包版本
- en: To build our example project, we used Python 3.6–3.8\. We used TensorFlow version
    2.2.0 and TFX version 0.22.0\. We will do our best to update our GitHub repo with
    future versions, but we cannot guarantee that the project will work with other
    language or package versions.
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为了构建我们的示例项目，我们使用了Python 3.6至3.8版本。我们使用了TensorFlow版本2.2.0和TFX版本0.22.0。我们将尽力更新我们的GitHub仓库到未来的版本，但不能保证项目能够与其他语言或包的版本兼容。
- en: 'Our example project contains the following:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例项目包含以下内容：
- en: A chapters folder containing notebooks for standalone examples from Chapters
    [3](index_split_008.html#filepos156116), [4](index_split_009.html#filepos295199),
    [7](index_split_012.html#filepos624151), and [14](index_split_021.html#filepos1522914)
  id: totrans-88
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 包含独立章节示例笔记本的chapters文件夹，包括第[3](index_split_008.html#filepos156116)、[4](index_split_009.html#filepos295199)、[7](index_split_012.html#filepos624151)和[14](index_split_021.html#filepos1522914)章
- en: A components folder with the code for common components such as the model definition
  id: totrans-89
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 包含常见组件代码（如模型定义）的components文件夹
- en: A complete interactive pipeline
  id: totrans-90
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 完整的交互式流水线
- en: An example of a machine learning experiment, which is the starting point for
    the pipeline
  id: totrans-91
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个机器学习实验示例，这是流水线的起点
- en: Complete example pipelines orchestrated by Apache Beam, Apache Airflow, and
    Kubeflow Pipelines
  id: totrans-92
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由Apache Beam、Apache Airflow和Kubeflow Pipelines协同管理的完整示例流水线
- en: A utility folder with a script to download the data
  id: totrans-93
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 包含下载数据脚本的utility文件夹
- en: In the following chapters. we will guide you through the necessary steps to
    turn the example machine learning experiment, in our case a Jupyter Notebook with
    a Keras model architecture, into a complete end-to-end machine learning pipeline.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将指导您完成将示例机器学习实验（在我们的案例中是一个带有Keras模型架构的Jupyter笔记本）转变为完整端到端机器学习流水线的必要步骤。
- en: Our Machine Learning Model
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的机器学习模型
- en: 'The core of our example deep learning project is the model generated by the
    function `get_model` in the `components/module.py` script of our example project.
    The model predicts whether a consumer disputed a complaint using the following
    features:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们示例深度学习项目的核心是由示例项目的`components/module.py`脚本中的`get_model`函数生成的模型。该模型预测消费者是否对投诉有异议，使用以下特征：
- en: The financial product
  id: totrans-97
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 金融产品
- en: The subproduct
  id: totrans-98
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 子产品
- en: The company’s response to the complaint
  id: totrans-99
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 公司对投诉的回应
- en: The issue that the consumer complained about
  id: totrans-100
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 消费者投诉的问题
- en: The US state
  id: totrans-101
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 美国的州
- en: The zip code
  id: totrans-102
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 邮政编码
- en: The text of the complaint (the narrative)
  id: totrans-103
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 投诉的文本（叙述）
- en: For the purpose of building the machine learning pipeline, we assume that the
    model architecture design is done and we won’t modify the model. We discuss the
    model architecture in more detail in [Chapter 6](index_split_011.html#filepos491525).
    But for this book, the model architecture is a very minor point. This book is
    all about what you can do with your model once you have it.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建机器学习流水线，我们假设模型架构设计已完成，我们不会修改模型。我们将在[第6章](index_split_011.html#filepos491525)更详细地讨论模型架构。但对于本书而言，模型架构是一个非常小的点。本书关注的是一旦您拥有模型，您可以用它做什么。
- en: Goal of the Example Project
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 示例项目的目标
- en: Over the course of this book, we will demonstrate the necessary frameworks,
    components, and infrastructure elements to continuously train our example machine
    learning model. We will use the stack in the architecture diagram shown in [Figure 1-4](#filepos80551).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的过程中，我们将展示连续训练示例机器学习模型所需的框架、组件和基础设施元素。我们将使用架构图中显示的堆栈，见[图 1-4](#filepos80551)。
- en: '![](images/00074.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00074.jpg)'
- en: Figure 1-4\. Machine learning pipeline architecture for our example project
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1-4\. 我们示例项目的机器学习管道架构
- en: We have tried to implement a generic machine learning problem that can easily
    be replaced with your specific machine learning problem. The structure and the
    basic setup of the machine learning pipeline remains the same and can be transferred
    to your use case. Each component will require some customization (e.g., where
    to ingest the data from), but as we will discuss, the customization needs will
    be limited.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试实现一个通用的机器学习问题，可以轻松替换为您特定的机器学习问题。机器学习管道的结构和基本设置保持不变，可以转移到您的用例中。每个组件都需要一些定制（例如，从何处摄取数据），但正如我们将讨论的那样，定制需求将是有限的。
- en: Summary
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have introduced the concept of machine learning pipelines
    and explained the individual steps. We have also shown the benefits of automating
    this process. In addition, we have set the stage for the following chapters and
    included a brief outline of every chapter along with an introduction of our example
    project. In the next chapter, we will start building our pipeline!
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了机器学习管道的概念，并解释了各个步骤。我们还展示了自动化此过程的好处。此外，我们为接下来的章节做了铺垫，并简要概述了每一章以及我们示例项目的介绍。在下一章中，我们将开始构建我们的管道！
- en: '[1  ](#filepos59045) In supervised classification problems with multiple classes
    as outputs, it’s often necessary to convert from a category to a vector such as
    (0,1,0), which is a one-hot vector, or from a list of categories to a vector such
    as (1,1,0), which is a multi-hot vector.'
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[1  ](#filepos59045) 在带有多个类输出的监督分类问题中，通常需要将从类别转换为向量，例如（0,1,0），这是一个独热向量，或者从类别列表转换为向量，例如（1,1,0），这是一个多热向量。'
- en: '[2  ](#filepos69713) Google started an internal project called Sibyl in 2007
    to manage an internal machine learning production pipeline. However, in 2015,
    the topic gained wider attention when D. Sculley et al. published their learnings
    of machine learning pipelines, [“Hidden Technical Debt in Machine Learning Systems”](https://oreil.ly/qVlYb).'
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[2  ](#filepos69713) Google于2007年启动了一个名为Sibyl的内部项目，用于管理内部的机器学习生产管道。然而，2015年，D.
    Sculley 等人发表了关于机器学习管道的学习成果，“机器学习系统中的隐藏技术债务”，[“Hidden Technical Debt in Machine
    Learning Systems”](https://oreil.ly/qVlYb)，这个主题引起了广泛关注。'
- en: '[3  ](#filepos69992) D. Sculley et al., “Hidden Technical Debt in Machine Learning
    Systems,” Google, Inc. (2015).'
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[3  ](#filepos69992) D. Sculley 等人，“机器学习系统中的隐藏技术债务”，Google，Inc.（2015年）。'
