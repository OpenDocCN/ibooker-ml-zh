- en: Chapter 7\. From Theory to Practice
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬ä¸ƒç« ã€‚ä»ç†è®ºåˆ°å®è·µ
- en: Real-world ML projects are rarely straightforward. You donâ€™t always know what
    exact fairness metric to implement or how robust you need the model inference
    to be. Creating trustworthy ML systems almost always involves trading off between
    technical considerations and *human decisions* like budget considerations, finding
    a balance between trust and utility, and aligning stakeholders toward a common
    goal. As an ML expert and practitioner, you are capable of handling the technical
    aspects. But when it comes to human-in-the-loop decisions, you may not be required
    to make all of those (and perhaps you shouldnâ€™t). However, itâ€™s important to have
    at least a high-level understanding of the concepts involved in both human and
    technical decisions in order to effectively align trustworthy ML development with
    the broader organizational picture.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: çœŸå®ä¸–ç•Œçš„æœºå™¨å­¦ä¹ é¡¹ç›®å¾ˆå°‘æ˜¯ç›´æˆªäº†å½“çš„ã€‚ä½ å¹¶ä¸æ€»æ˜¯çŸ¥é“è¦å®æ–½ä»€ä¹ˆç¡®åˆ‡çš„å…¬å¹³åº¦é‡æ ‡å‡†ï¼Œæˆ–è€…æ¨¡å‹æ¨æ–­éœ€è¦å¤šä¹ˆç¨³å¥ã€‚åˆ›å»ºå¯ä¿¡ä»»çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿå‡ ä¹æ€»æ˜¯æ¶‰åŠåœ¨æŠ€æœ¯è€ƒè™‘å’Œ*äººç±»å†³ç­–*ï¼ˆå¦‚é¢„ç®—è€ƒè™‘ã€åœ¨ä¿¡ä»»å’Œæ•ˆç”¨ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ï¼Œå¹¶ä½¿åˆ©ç›Šç›¸å…³è€…æœç€å…±åŒç›®æ ‡åŠªåŠ›ï¼‰ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚ä½œä¸ºä¸€ä¸ªæœºå™¨å­¦ä¹ ä¸“å®¶å’Œå®è·µè€…ï¼Œä½ æœ‰èƒ½åŠ›å¤„ç†æŠ€æœ¯æ–¹é¢çš„é—®é¢˜ã€‚ä½†æ˜¯å½“æ¶‰åŠåˆ°äººä¸ºå†³ç­–æ—¶ï¼Œä½ å¯èƒ½å¹¶ä¸éœ€è¦åšæ‰€æœ‰è¿™äº›å†³å®šï¼ˆä¹Ÿè®¸ä½ ä¸åº”è¯¥ï¼‰ã€‚ç„¶è€Œï¼Œç†è§£æ¶‰åŠäººç±»å’ŒæŠ€æœ¯å†³ç­–çš„æ¦‚å¿µè‡³å°‘å…·æœ‰é«˜å±‚æ¬¡çš„ç†è§£æ˜¯éå¸¸é‡è¦çš„ï¼Œä»¥ä¾¿æœ‰æ•ˆåœ°å°†å¯ä¿¡ä»»çš„æœºå™¨å­¦ä¹ å¼€å‘ä¸æ›´å¹¿æ³›çš„ç»„ç»‡æ ¼å±€å¯¹é½ã€‚
- en: In this chapter, weâ€™ll share with you tools for actually implementing the trustworthy
    ML methods weâ€™ve discussed in earlier chapters in messy, production-grade systems.
    Weâ€™ll start by reviewing some additional technical factors you might need to address
    before pushing a model to productionâ€”â€‹such as causality, sparsity, and uncertaintyâ€”â€‹in
    Part I. From there, weâ€™ll move on to Part II to discuss how to effectively collaborate
    with stakeholders beyond the development team.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä¸æ‚¨åˆ†äº«ä¸€äº›å·¥å…·ï¼Œç”¨äºåœ¨æ··ä¹±çš„ç”Ÿäº§çº§ç³»ç»Ÿä¸­å®é™…å®æ–½æˆ‘ä»¬åœ¨å‰å‡ ç« ä¸­è®¨è®ºè¿‡çš„å¯ä¿¡æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚æˆ‘ä»¬å°†é¦–å…ˆå›é¡¾ä¸€äº›å¯èƒ½éœ€è¦åœ¨æ¨é€æ¨¡å‹åˆ°ç”Ÿäº§ä¹‹å‰è§£å†³çš„é¢å¤–æŠ€æœ¯å› ç´ ï¼Œä¾‹å¦‚å› æœæ€§ã€ç¨€ç–æ€§å’Œä¸ç¡®å®šæ€§â€”â€‹åœ¨ç¬¬ä¸€éƒ¨åˆ†ã€‚ä»é‚£é‡Œå¼€å§‹ï¼Œæˆ‘ä»¬å°†è½¬å‘ç¬¬äºŒéƒ¨åˆ†ï¼Œè®¨è®ºå¦‚ä½•æœ‰æ•ˆåœ°ä¸å¼€å‘å›¢é˜Ÿä¹‹å¤–çš„åˆ©ç›Šç›¸å…³è€…åˆä½œã€‚
- en: 'Part I: Additional Technical Factors'
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€éƒ¨åˆ†ï¼šé¢å¤–çš„æŠ€æœ¯å› ç´ 
- en: There are some additional technical considerations you might need to think about
    while incorporating one or more trust elements in your ML project. These are somewhat
    different than the concepts discussed in [ChapterÂ 5](ch05.html#chapter5). Specifically,
    they are already established scientific concepts and tools that are becoming more
    and more relevant to MLâ€”â€‹and trusted MLâ€”â€‹applications.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å°†ä¸€ä¸ªæˆ–å¤šä¸ªä¿¡ä»»å…ƒç´ çº³å…¥æ‚¨çš„æœºå™¨å­¦ä¹ é¡¹ç›®æ—¶ï¼Œæ‚¨å¯èƒ½éœ€è¦è€ƒè™‘ä¸€äº›é¢å¤–çš„æŠ€æœ¯å› ç´ ã€‚è¿™äº›å› ç´ ä¸[ç¬¬äº”ç« ](ch05.html#chapter5)ä¸­è®¨è®ºçš„æ¦‚å¿µæœ‰æ‰€ä¸åŒã€‚å…·ä½“è€Œè¨€ï¼Œå®ƒä»¬å·²ç»æ˜¯å·²ç¡®ç«‹çš„ç§‘å­¦æ¦‚å¿µå’Œå·¥å…·ï¼Œè¿™äº›æ¦‚å¿µå’Œå·¥å…·åœ¨æœºå™¨å­¦ä¹ åº”ç”¨ä¸­å˜å¾—è¶Šæ¥è¶Šé‡è¦â€”â€‹ä»¥åŠå¯ä¿¡çš„æœºå™¨å­¦ä¹ åº”ç”¨ã€‚
- en: Causal Machine Learning
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å› æœæœºå™¨å­¦ä¹ 
- en: Suppose you want to model whether a user clicks an online ad they receive as
    a function of who is clicking the ad, what their recent activity history is, the
    subject of the ad, and the time of the day. How do you make sure that a specific
    user segment is more or less likely to click on ads? Just throwing everything
    as input features into a click prediction model and looking at variable importance
    isnâ€™t the best idea. Maybe certain user segments just spend more time on the internet
    during a certain time of the day and hence click on more ads during those times.
    How do you go beyond such interactionsâ€”which affect data collection itselfâ€”to
    extract true cause-effect relationships from your data? Causal inference is the
    answer here. Conventional ML depends on observational data. Data collection generally
    doesnâ€™t concern itself with cause-effect relationships between a few features
    while controlling for the effect of other features. The connections between features
    a typical ML model infers by analyzing observational datasets are simply *associations*,
    not *causations*. Concepts and tools from the field of causal inference are helpful
    in navigating these deficiencies.^([1](ch07.html#idm45621832115168))
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾ä½ æƒ³è¦å»ºæ¨¡ç”¨æˆ·æ˜¯å¦ç‚¹å‡»ä»–ä»¬æ”¶åˆ°çš„åœ¨çº¿å¹¿å‘Šï¼Œä½œä¸ºç‚¹å‡»å¹¿å‘Šçš„åŠŸèƒ½ï¼Œç‚¹å‡»è€…æ˜¯è°ï¼Œä»–ä»¬æœ€è¿‘çš„æ´»åŠ¨å†å²æ˜¯ä»€ä¹ˆï¼Œå¹¿å‘Šçš„ä¸»é¢˜ï¼Œä»¥åŠæ—¶é—´æ˜¯ä»€ä¹ˆã€‚å¦‚ä½•ç¡®ä¿ç‰¹å®šçš„ç”¨æˆ·æ®µæ›´æœ‰å¯èƒ½æˆ–ä¸å¤ªå¯èƒ½ç‚¹å‡»å¹¿å‘Šï¼Ÿä»…å°†æ‰€æœ‰è¾“å…¥ç‰¹å¾æŠ•å…¥ç‚¹å‡»é¢„æµ‹æ¨¡å‹å¹¶æŸ¥çœ‹å˜é‡é‡è¦æ€§å¹¶ä¸æ˜¯æœ€å¥½çš„ä¸»æ„ã€‚ä¹Ÿè®¸æŸäº›ç”¨æˆ·æ®µåœ¨ä¸€å¤©çš„æŸä¸ªç‰¹å®šæ—¶é—´æ›´å¤šåœ°èŠ±è´¹æ—¶é—´ä¸Šç½‘ï¼Œå› æ­¤åœ¨è¿™äº›æ—¶é—´å†…ç‚¹å‡»æ›´å¤šçš„å¹¿å‘Šã€‚å¦‚ä½•è¶…è¶Šè¿™ç§å½±å“â€”â€”è¿™äº›å½±å“å½±å“æ•°æ®æ”¶é›†æœ¬èº«â€”â€”ä»æ•°æ®ä¸­æå–çœŸæ­£çš„å› æœå…³ç³»ï¼Ÿå› æœæ¨æ–­å°±æ˜¯ç­”æ¡ˆã€‚ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ ä¾èµ–äºè§‚æµ‹æ•°æ®ã€‚æ•°æ®æ”¶é›†é€šå¸¸ä¸æ¶‰åŠä¸€äº›ç‰¹å¾ä¹‹é—´çš„å› æœå…³ç³»ï¼ŒåŒæ—¶æ§åˆ¶å…¶ä»–ç‰¹å¾çš„æ•ˆæœã€‚å…¸å‹æœºå™¨å­¦ä¹ æ¨¡å‹é€šè¿‡åˆ†æè§‚æµ‹æ•°æ®é›†æ¨æ–­çš„ç‰¹å¾ä¹‹é—´çš„è¿æ¥ä»…ä»…æ˜¯*å…³è”*ï¼Œè€Œä¸æ˜¯*å› æœå…³ç³»*ã€‚å› æœæ¨æ–­é¢†åŸŸçš„æ¦‚å¿µå’Œå·¥å…·æœ‰åŠ©äºå¼¥è¡¥è¿™äº›ç¼ºé™·ã€‚^([1](ch07.html#idm45621832115168))
- en: Steps to causal inference
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å› æœæ¨æ–­çš„æ­¥éª¤
- en: 'Causal inference follows four general steps:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å› æœæ¨æ–­éµå¾ªå››ä¸ªä¸€èˆ¬æ­¥éª¤ï¼š
- en: '*Step 1: Create a model of a causality problem*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºå› æœé—®é¢˜æ¨¡å‹*'
- en: This is analogous to creating a hypothesis in the scientific method. This step
    might involve defining the model as a detailed causal graph. Alternatively, it
    could just be sets of names of variables that correspond to relevant categories
    like common causes or instrumental variables.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç±»ä¼¼äºç§‘å­¦æ–¹æ³•ä¸­çš„å‡è®¾ç”Ÿæˆã€‚è¿™ä¸€æ­¥éª¤å¯èƒ½æ¶‰åŠå°†æ¨¡å‹å®šä¹‰ä¸ºè¯¦ç»†çš„å› æœå›¾ã€‚æˆ–è€…ï¼Œå®ƒå¯èƒ½åªæ˜¯å˜é‡åç§°é›†åˆï¼Œè¿™äº›åç§°å¯¹åº”äºåƒå…±åŒåŸå› æˆ–å·¥å…·å˜é‡ä¹‹ç±»çš„ç›¸å…³ç±»åˆ«ã€‚
- en: '*Step 2: Identify a target estimand*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç¬¬äºŒæ­¥ï¼šç¡®å®šç›®æ ‡ä¼°è®¡é‡*'
- en: This is the process of identifying the causal effect on the variables of interest.
    There are many tools for this step, including ML-based tools.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯è¯†åˆ«æ„Ÿå…´è¶£å˜é‡çš„å› æœæ•ˆåº”çš„è¿‡ç¨‹ã€‚æœ‰è®¸å¤šå·¥å…·å¯ä»¥ç”¨äºè¿™ä¸€æ­¥éª¤ï¼ŒåŒ…æ‹¬åŸºäºæœºå™¨å­¦ä¹ çš„å·¥å…·ã€‚
- en: '*Step 3: Determine the strength of the causal effect*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç¬¬ä¸‰æ­¥ï¼šç¡®å®šå› æœæ•ˆåº”çš„å¼ºåº¦*'
- en: Drawing a causal arrow from one variable to another isnâ€™t enough. Much as you
    might use correlation coefficients to determine the strength of a linear relationship,
    youâ€™ll also need to estimate the strength of a causal effect. Even if there is
    a causal relationship, it can still be weak.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸€ä¸ªå˜é‡å‘å¦ä¸€ä¸ªå˜é‡ç»˜åˆ¶å› æœç®­å¤´å¹¶ä¸è¶³å¤Ÿã€‚å°±åƒä½ å¯èƒ½ä½¿ç”¨ç›¸å…³ç³»æ•°æ¥ç¡®å®šçº¿æ€§å…³ç³»çš„å¼ºåº¦ä¸€æ ·ï¼Œä½ è¿˜éœ€è¦ä¼°è®¡å› æœæ•ˆåº”çš„å¼ºåº¦ã€‚å³ä½¿å­˜åœ¨å› æœå…³ç³»ï¼Œå®ƒå¯èƒ½ä»ç„¶å¾ˆå¼±ã€‚
- en: '*Step 4: Subjecting the causal model to refutation*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç¬¬å››æ­¥ï¼šä½¿å› æœæ¨¡å‹ç»å—åé©³*'
- en: Typically, in ML, you want to create a model thatâ€™s the best fit for the data.
    In causal inference, you want to create a *causal* model that represents the best
    hypothesis for how causality works in the data. Even if you have identified the
    causal effects and estimated their strengths, you should still test a few plausible
    alternative hypotheses. [TableÂ 7-1](#table-perturb) lists a few things to try,
    with notes about what ideal behavior should look like.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œä½ å¸Œæœ›åˆ›å»ºæœ€é€‚åˆæ•°æ®çš„æ¨¡å‹ã€‚åœ¨å› æœæ¨æ–­ä¸­ï¼Œä½ å¸Œæœ›åˆ›å»ºä¸€ä¸ª*å› æœ*æ¨¡å‹ï¼Œå®ƒä»£è¡¨äº†å¦‚ä½•åœ¨æ•°æ®ä¸­å·¥ä½œçš„æœ€ä½³å‡è®¾ã€‚å³ä½¿ä½ å·²ç»ç¡®å®šäº†å› æœæ•ˆåº”å¹¶ä¼°è®¡äº†å®ƒä»¬çš„å¼ºåº¦ï¼Œä½ ä»ç„¶åº”è¯¥æµ‹è¯•å‡ ä¸ªå¯èƒ½çš„æ›¿ä»£å‡è®¾ã€‚[è¡¨7-1](#table-perturb)åˆ—å‡ºäº†ä¸€äº›å°è¯•çš„å†…å®¹ï¼Œå¹¶æ³¨æ˜ç†æƒ³è¡Œä¸ºåº”è¯¥æ˜¯ä»€ä¹ˆæ ·çš„ã€‚
- en: Table 7-1\. Example considerations for potentially perturbing
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨7-1ã€‚æ½œåœ¨æ‰°åŠ¨çš„ç¤ºä¾‹è€ƒè™‘å› ç´ 
- en: '| Action | Description | Ideal |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| åŠ¨ä½œ | æè¿° | ç†æƒ³ |'
- en: '| --- | --- | --- |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Random common cause | Does the estimation method change its estimate after
    you add an independent random variable as a common cause to the dataset? | It
    shouldnâ€™t |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| éšæœºå…±åŒåŸå›  | åœ¨ä½ å‘æ•°æ®é›†æ·»åŠ ç‹¬ç«‹éšæœºå˜é‡ä½œä¸ºå…±åŒåŸå› åï¼Œä¼°è®¡æ–¹æ³•æ˜¯å¦æ”¹å˜äº†å…¶ä¼°è®¡å€¼ï¼Ÿ | ä¸åº”è¯¥æ”¹å˜ |'
- en: '| Placebo treatment | What happens to the estimated causal effect when you
    replace the true treatment variable with an independent random variable? | The
    effect should go to zero |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| å®‰æ…°å‰‚æ²»ç–— | å½“ä½ ç”¨ä¸€ä¸ªç‹¬ç«‹éšæœºå˜é‡æ›¿æ¢çœŸå®çš„æ²»ç–—å˜é‡æ—¶ï¼Œä¼°è®¡çš„å› æœæ•ˆåº”ä¼šå‘ç”Ÿä»€ä¹ˆå˜åŒ–ï¼Ÿ | æ•ˆåº”åº”è¯¥è¶‹è¿‘äºé›¶ |'
- en: '| Simulated outcome | What happens to the estimated causal effect when you
    replace the dataset with a simulated dataset based on a known data-generating
    process closest to the given dataset? | It should match the effect parameter from
    the data-generating process |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| æ¨¡æ‹Ÿç»“æœ | å½“ä½ ç”¨åŸºäºå·²çŸ¥æ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„æ¨¡æ‹Ÿæ•°æ®é›†æ›¿æ¢åŸå§‹æ•°æ®é›†æ—¶ï¼Œä¼°è®¡çš„å› æœæ•ˆåº”ä¼šå‘ç”Ÿä»€ä¹ˆå˜åŒ–ï¼Ÿ | å®ƒåº”è¯¥ä¸æ•°æ®ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ•ˆåº”å‚æ•°åŒ¹é… |'
- en: '| Unobserved common causes | How sensitive is the effect estimate when you
    add an additional common cause (often called a *confounder*) to the dataset that
    is correlated with the treatment and the outcome? | It should not be too sensitive
    |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| æœªè§‚å¯Ÿåˆ°çš„å…±åŒåŸå›  | å½“ä½ å‘æ•°æ®é›†ä¸­æ·»åŠ ä¸€ä¸ªé¢å¤–çš„ä¸æ²»ç–—å’Œç»“æœç›¸å…³çš„å…±åŒåŸå› ï¼ˆé€šå¸¸ç§°ä¸º*æ··æ‚å˜é‡*ï¼‰æ—¶ï¼Œä¼°è®¡çš„æ•ˆåº”æœ‰å¤šæ•æ„Ÿï¼Ÿ | ä¸åº”è¯¥å¤ªæ•æ„Ÿ
    |'
- en: '| Data subsets validation | Does the estimated effect change significantly
    when you replace the given dataset with a randomly selected subset? | It should
    not |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| æ•°æ®å­é›†éªŒè¯ | å½“ä½ ç”¨éšæœºé€‰å–çš„å­é›†æ›¿æ¢åŸå§‹æ•°æ®é›†æ—¶ï¼Œä¼°è®¡çš„æ•ˆåº”ä¼šå‘ç”Ÿæ˜¾è‘—å˜åŒ–å—ï¼Ÿ | ä¸åº”è¯¥å‘ç”Ÿ |'
- en: '| Bootstrap validation | Does the estimated effect change significantly when
    you replace the given dataset with bootstrap resamples from the same dataset?
    | It should not |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| è‡ªä¸¾éªŒè¯ | å½“ä½ ç”¨æ¥è‡ªç›¸åŒæ•°æ®é›†çš„è‡ªä¸¾é‡é‡‡æ ·æ›¿æ¢åŸå§‹æ•°æ®é›†æ—¶ï¼Œä¼°è®¡çš„æ•ˆåº”ä¼šå‘ç”Ÿæ˜¾è‘—å˜åŒ–å—ï¼Ÿ | ä¸åº”è¯¥å‘ç”Ÿ |'
- en: Tools for causal inference
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å› æœæ¨æ–­å·¥å…·
- en: '*Structural causal models* (SCM) are a mainstay of causal inference. ML methods
    in causal inference are based on representations of ML models as SCMs, with the
    help of cause-effect reasoning and domain knowledge.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç»“æ„å› æœæ¨¡å‹*ï¼ˆSCMï¼‰æ˜¯å› æœæ¨æ–­çš„ä¸€ä¸ªé‡è¦å·¥å…·ã€‚æœºå™¨å­¦ä¹ ä¸­çš„å› æœæ¨æ–­æ–¹æ³•åŸºäºå°†æœºå™¨å­¦ä¹ æ¨¡å‹è¡¨ç¤ºä¸ºSCMï¼Œå€ŸåŠ©å› æœæ¨ç†å’Œé¢†åŸŸçŸ¥è¯†ã€‚'
- en: 'A *structural causal model* is defined as the 4-tuple *(D, E, f, P[e])*, where:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç»“æ„å› æœæ¨¡å‹*è¢«å®šä¹‰ä¸º4å…ƒç»„*(D, E, f, P[e])*ï¼Œå…¶ä¸­ï¼š'
- en: '*D* is a set of endogenous variables, variables that can be influenced by changing
    the values of one or more of the other variables.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*D* æ˜¯ä¸€ç»„å†…ç”Ÿå˜é‡ï¼Œå¯ä»¥é€šè¿‡æ”¹å˜å…¶ä»–å˜é‡çš„å€¼æ¥å½±å“å®ƒä»¬ã€‚'
- en: '*E* is a set of exogenous variables, the values of which are not possible to
    manipulate by changing other variables.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*E* æ˜¯ä¸€ç»„å¤–ç”Ÿå˜é‡ï¼Œå…¶å€¼ä¸å¯èƒ½é€šè¿‡æ”¹å˜å…¶ä»–å˜é‡æ¥æ“æ§ã€‚'
- en: '*f = { f[1], f[2], â€¦â€‹, f[n]}* is a set of functions that represent causal mechanisms
    involving members of *D* and *E*: <math alttext="d Subscript i Baseline equals
    f Subscript i Baseline left-parenthesis upper P a left-parenthesis d Subscript
    i Baseline right-parenthesis comma upper E Subscript i Baseline right-parenthesis"><mrow><msub><mi>d</mi>
    <mi>i</mi></msub> <mo>=</mo> <msub><mi>f</mi> <mi>i</mi></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mi>a</mi> <mrow><mo>(</mo> <msub><mi>d</mi> <mi>i</mi></msub> <mo>)</mo></mrow>
    <mo>,</mo> <msub><mi>E</mi> <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>
    . Here the endogenous variable *d[i]* is modeled as a function *f[i]* of other
    endogenous variables *Pa(d[i])* and one or more exogenous variables <math alttext="upper
    E Subscript i Baseline subset-of-or-equal-to upper E"><mrow><msub><mi>E</mi> <mi>i</mi></msub>
    <mo>âŠ†</mo> <mi>E</mi></mrow></math> .'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f = { f[1], f[2], â€¦â€‹, f[n]}* æ˜¯ä¸€ç»„å‡½æ•°ï¼Œä»£è¡¨æ¶‰åŠ*D*å’Œ*E*æˆå‘˜çš„å› æœæœºåˆ¶ï¼š<math alttext="d Subscript
    i Baseline equals f Subscript i Baseline left-parenthesis upper P a left-parenthesis
    d Subscript i Baseline right-parenthesis comma upper E Subscript i Baseline right-parenthesis"><mrow><msub><mi>d</mi>
    <mi>i</mi></msub> <mo>=</mo> <msub><mi>f</mi> <mi>i</mi></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mi>a</mi> <mrow><mo>(</mo> <msub><mi>d</mi> <mi>i</mi></msub> <mo>)</mo></mrow>
    <mo>,</mo> <msub><mi>E</mi> <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>
    ã€‚è¿™é‡Œçš„å†…ç”Ÿå˜é‡*d[i]*è¢«å»ºæ¨¡ä¸ºå…¶ä»–å†…ç”Ÿå˜é‡*Pa(d[i])*å’Œä¸€ä¸ªæˆ–å¤šä¸ªå¤–ç”Ÿå˜é‡<math alttext="upper E Subscript i
    Baseline subset-of-or-equal-to upper E"><mrow><msub><mi>E</mi> <mi>i</mi></msub>
    <mo>âŠ†</mo> <mi>E</mi></mrow></math> çš„å‡½æ•°*f[i]*ã€‚'
- en: '*P[e]* is a probability distribution over the elements of *E*.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P[e]* æ˜¯*E*å…ƒç´ çš„æ¦‚ç‡åˆ†å¸ƒã€‚'
- en: Think of an SCM as a formal way of approaching the steps of causal inference.
    For the first step of creating a causal model, you can take the SCM with mathematical
    specifications for the functions in *f* as a formal model of the causality problem
    you are dealing with. The second step of identifying a target estimand corresponds
    to *estimating* a causal mechanism *f[i]* within a family of functions. Step 3â€”â€‹determining
    the strength of causal effectâ€”â€‹is analogous to testing for the effect size of
    an *f[i]* or its parameters. Finally, you can encode the fourth step of subjecting
    the causal model to refutations as testing out an alternate formulations of the
    mechanisms *f* within an SCM.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å°†SCMè§†ä¸ºæ­£å¼è§£å†³å› æœæ¨æ–­æ­¥éª¤çš„ä¸€ç§æ–¹å¼ã€‚å¯¹äºåˆ›å»ºå› æœæ¨¡å‹çš„ç¬¬ä¸€æ­¥ï¼Œä½ å¯ä»¥å°†å¸¦æœ‰*f*å‡½æ•°æ•°å­¦è§„èŒƒçš„SCMä½œä¸ºä½ æ­£åœ¨å¤„ç†çš„å› æœé—®é¢˜çš„æ­£å¼æ¨¡å‹ã€‚è¯†åˆ«ç›®æ ‡ä¼°è®¡é‡çš„ç¬¬äºŒæ­¥å¯¹åº”äºåœ¨ä¸€ç»„å‡½æ•°ä¸­ä¼°è®¡å› æœæœºåˆ¶*f[i]*ã€‚ç¬¬ä¸‰æ­¥â€”â€”ç¡®å®šå› æœæ•ˆåº”çš„å¼ºåº¦â€”â€”ç±»ä¼¼äºæµ‹è¯•*f[i]*æˆ–å…¶å‚æ•°çš„æ•ˆåº”å¤§å°ã€‚æœ€åï¼Œä½ å¯ä»¥å°†å› æœæ¨¡å‹è¿›è¡Œåé©³çš„ç¬¬å››æ­¥è§†ä¸ºæµ‹è¯•SCMä¸­*f*æœºåˆ¶çš„æ›¿ä»£å½¢å¼ã€‚
- en: 'Grounding these steps in the earlier example, an SCM based on the variables
    involved would look like this:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è¿™äº›æ­¥éª¤ä¸ä¹‹å‰çš„ä¾‹å­è”ç³»èµ·æ¥ï¼ŒåŸºäºæ¶‰åŠçš„å˜é‡ï¼Œä¸€ä¸ªåŸºäºSCMçš„æ¨¡å‹å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '*D* consists of the following features: clicked or not (*C*), user segment
    (*S*), and user history (*H*).'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*D* åŒ…å«ä»¥ä¸‹ç‰¹å¾ï¼šç‚¹å‡»æˆ–æœªç‚¹å‡»ï¼ˆ*C*ï¼‰ï¼Œç”¨æˆ·ç»†åˆ†ï¼ˆ*S*ï¼‰ï¼Œä»¥åŠç”¨æˆ·å†å²ï¼ˆ*H*ï¼‰ã€‚'
- en: '*E* consists of the following features: ad topic (*A*), and time of day (*T*).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*E* åŒ…å«ä»¥ä¸‹ç‰¹å¾ï¼šå¹¿å‘Šä¸»é¢˜ï¼ˆ*A*ï¼‰ï¼Œä»¥åŠä¸€å¤©ä¸­çš„æ—¶é—´ï¼ˆ*T*ï¼‰ã€‚'
- en: '*f* consists of these functions:'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f* åŒ…æ‹¬è¿™äº›å‡½æ•°ï¼š'
- en: <math alttext="upper C equals f 1 left-parenthesis upper S comma upper H comma
    upper A comma upper T right-parenthesis" display="block"><mrow><mi>C</mi> <mo>=</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>S</mi> <mo>,</mo> <mi>H</mi>
    <mo>,</mo> <mi>A</mi> <mo>,</mo> <mi>T</mi> <mo>)</mo></mrow></mrow></math><math
    alttext="upper S equals f 2 left-parenthesis upper H comma upper A comma upper
    T right-parenthesis" display="block"><mrow><mi>S</mi> <mo>=</mo> <msub><mi>f</mi>
    <mn>2</mn></msub> <mrow><mo>(</mo> <mi>H</mi> <mo>,</mo> <mi>A</mi> <mo>,</mo>
    <mi>T</mi> <mo>)</mo></mrow></mrow></math><math alttext="upper H equals f 3 left-parenthesis
    upper S comma upper A comma upper T right-parenthesis" display="block"><mrow><mi>H</mi>
    <mo>=</mo> <msub><mi>f</mi> <mn>3</mn></msub> <mrow><mo>(</mo> <mi>S</mi> <mo>,</mo>
    <mi>A</mi> <mo>,</mo> <mi>T</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <math alttext="upper C equals f 1 left-parenthesis upper S comma upper H comma
    upper A comma upper T right-parenthesis" display="block"><mrow><mi>C</mi> <mo>=</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>S</mi> <mo>,</mo> <mi>H</mi>
    <mo>,</mo> <mi>A</mi> <mo>,</mo> <mi>T</mi> <mo>)</mo></mrow></mrow></math><math
    alttext="upper S equals f 2 left-parenthesis upper H comma upper A comma upper
    T right-parenthesis" display="block"><mrow><mi>S</mi> <mo>=</mo> <msub><mi>f</mi>
    <mn>2</mn></msub> <mrow><mo>(</mo> <mi>H</mi> <mo>,</mo> <mi>A</mi> <mo>,</mo>
    <mi>T</mi> <mo>)</mo></mrow></mrow></math><math alttext="upper H equals f 3 left-parenthesis
    upper S comma upper A comma upper T right-parenthesis" display="block"><mrow><mi>H</mi>
    <mo>=</mo> <msub><mi>f</mi> <mn>3</mn></msub> <mrow><mo>(</mo> <mi>S</mi> <mo>,</mo>
    <mi>A</mi> <mo>,</mo> <mi>T</mi> <mo>)</mo></mrow></mrow></math>
- en: Finally, for *P[e]* assume that the distributions of ad topics is inferred from
    historical data and time can be uniformly distributed across the day.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå¯¹äº*P[e]*ï¼Œå‡è®¾å¹¿å‘Šä¸»é¢˜çš„åˆ†å¸ƒæ˜¯æ ¹æ®å†å²æ•°æ®æ¨æ–­å‡ºæ¥çš„ï¼Œè€Œæ—¶é—´å¯ä»¥åœ¨ä¸€å¤©ä¸­å‡åŒ€åˆ†å¸ƒã€‚
- en: A causal model would estimate the function *f[1]* and determine the strength
    of the causal effects while accounting for the confounding effects codified by
    *f[2]* and *f[3]*. Finally, to know whether this causal model actually works in
    practice, you can run an A/B test by randomly selecting two groups of users and
    picking users from each group to serve the same ads on the same time of the day.
    For the first group, the users predicted by the causal model as highly likely
    to click on the ad are picked, while for the second group, random users are picked.
    If the average percentage of clicks generated is significantly higher for the
    first group, you know that the causal model makes sense (i.e., is better than
    a random guess).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå› æœæ¨¡å‹å°†ä¼°è®¡å‡½æ•°*f[1]*å¹¶ç¡®å®šå› æœæ•ˆåº”çš„å¼ºåº¦ï¼ŒåŒæ—¶è€ƒè™‘åˆ°*f[2]*å’Œ*f[3]*ç¼–ç çš„æ··æ‚æ•ˆåº”ã€‚æœ€åï¼Œè¦çŸ¥é“è¿™ä¸ªå› æœæ¨¡å‹åœ¨å®è·µä¸­æ˜¯å¦æœ‰æ•ˆï¼Œä½ å¯ä»¥é€šè¿‡éšæœºé€‰æ‹©ä¸¤ç»„ç”¨æˆ·å¹¶ä»æ¯ç»„ç”¨æˆ·ä¸­é€‰æ‹©åŒä¸€å¹¿å‘Šåœ¨åŒä¸€æ—¶é—´å†…æœåŠ¡çš„ç”¨æˆ·æ¥è¿è¡ŒA/Bæµ‹è¯•ã€‚å¯¹äºç¬¬ä¸€ç»„ï¼Œé€‰å–å› æœæ¨¡å‹é¢„æµ‹é«˜ç‚¹å‡»å¹¿å‘Šçš„ç”¨æˆ·ï¼Œè€Œå¯¹äºç¬¬äºŒç»„ï¼Œåˆ™éšæœºé€‰å–ç”¨æˆ·ã€‚å¦‚æœç¬¬ä¸€ç»„ç”Ÿæˆçš„å¹³å‡ç‚¹å‡»ç™¾åˆ†æ¯”æ˜¾è‘—é«˜äºç¬¬äºŒç»„ï¼Œä½ å°±çŸ¥é“å› æœæ¨¡å‹æ˜¯åˆç†çš„ï¼ˆå³æ¯”éšæœºçŒœæµ‹æ›´å¥½ï¼‰ã€‚
- en: Tip
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å°è´´å£«
- en: Can you think of a statistical test to use for testing if the difference between
    the click percentages in the two user groups is significant?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ èƒ½æƒ³åˆ°ä¸€ä¸ªç»Ÿè®¡æµ‹è¯•ç”¨æ¥æ£€éªŒä¸¤ä¸ªç”¨æˆ·ç»„ä¹‹é—´ç‚¹å‡»ç™¾åˆ†æ¯”çš„å·®å¼‚æ˜¯å¦æ˜¾è‘—å—ï¼Ÿ
- en: Causal inference spans a broad range of techniques, from ML-based to non-ML
    statistical inference. Thereâ€™s been an explosion of new tools and techniques in
    the space, far more than what we can cover in this chapter. Many of the large
    ML conferences have designated [special tracks and workshops](https://oreil.ly/Jeokv)
    on the subject.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å› æœæ¨æ–­æ¶µç›–äº†ä»åŸºäºæœºå™¨å­¦ä¹ åˆ°éæœºå™¨å­¦ä¹ ç»Ÿè®¡æ¨æ–­çš„å¹¿æ³›æŠ€æœ¯èŒƒå›´ã€‚åœ¨è¿™ä¸ªé¢†åŸŸå‡ºç°äº†å¤§é‡æ–°å·¥å…·å’ŒæŠ€æœ¯ï¼Œè¿œè¿œè¶…å‡ºäº†æˆ‘ä»¬å¯ä»¥åœ¨æœ¬ç« èŠ‚ä¸­è¦†ç›–çš„èŒƒå›´ã€‚è®¸å¤šå¤§å‹æœºå™¨å­¦ä¹ ä¼šè®®éƒ½ä¸“é—¨è®¾æœ‰[ç‰¹åˆ«çš„èµ›é“å’Œç ”è®¨ä¼š](https://oreil.ly/Jeokv)ã€‚
- en: 'When considering causal inference tools, look for well-maintained tools with
    wide coverage of techniques. The four best options we recommend are:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è€ƒè™‘å› æœæ¨æ–­å·¥å…·æ—¶ï¼Œè¯·å¯»æ‰¾è¦†ç›–æŠ€æœ¯èŒƒå›´å¹¿æ³›çš„ç»´æŠ¤è‰¯å¥½çš„å·¥å…·ã€‚æˆ‘ä»¬æ¨èçš„å››ä¸ªæœ€ä½³é€‰é¡¹æ˜¯ï¼š
- en: '*[CMUâ€™s Causal-learn](https://oreil.ly/bTIV7)*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*[CMUçš„Causal-learn](https://oreil.ly/bTIV7)*'
- en: For ML-based techniques, this is perhaps the best package to make sure your
    bases are covered when it comes to time-tested statistical causal inference. Causal-learn
    is a Python translation and extension of the Java-based [Tetrad](https://oreil.ly/avaIx)
    and offers [causal search methods](https://oreil.ly/FdVlA) (searching through
    a causal graph and nominating causal variables), [conditional independence tests](https://oreil.ly/OnNFS)
    (testing whether two variables are independent given a set of conditioning variables),
    and [scoring functions](https://oreil.ly/vRLWc), which are useful in building
    Bayesian models.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåŸºäºæœºå™¨å­¦ä¹ çš„æŠ€æœ¯æ¥è¯´ï¼Œè¿™å¯èƒ½æ˜¯ç¡®ä¿æ‚¨åœ¨ç»å—æ—¶é—´è€ƒéªŒçš„ç»Ÿè®¡å› æœæ¨æ–­æ–¹é¢çš„æœ€ä½³é€‰æ‹©ã€‚Causal-learnæ˜¯Java-based [Tetrad](https://oreil.ly/avaIx)çš„Pythonç¿»è¯‘å’Œæ‰©å±•ï¼Œæä¾›äº†[å› æœæœç´¢æ–¹æ³•](https://oreil.ly/FdVlA)ï¼ˆé€šè¿‡å› æœå›¾æœç´¢å’Œæåå› æœå˜é‡ï¼‰ï¼Œ[æ¡ä»¶ç‹¬ç«‹æ€§æµ‹è¯•](https://oreil.ly/OnNFS)ï¼ˆæµ‹è¯•ç»™å®šä¸€ç»„æ¡ä»¶å˜é‡æ—¶ä¸¤ä¸ªå˜é‡æ˜¯å¦ç‹¬ç«‹ï¼‰ï¼Œä»¥åŠ[è¯„åˆ†å‡½æ•°](https://oreil.ly/vRLWc)ï¼Œè¿™äº›åœ¨æ„å»ºè´å¶æ–¯æ¨¡å‹ä¸­éå¸¸æœ‰ç”¨ã€‚
- en: '*[QuantumBlackâ€™s CausalNex](https://oreil.ly/wCTBd)*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*[QuantumBlackçš„CausalNex](https://oreil.ly/wCTBd)*'
- en: CausalNex dives deeper into neural networks than does Causal-learn. Specifically,
    CausalNex heavily leverages Bayesian networks, and it aims to encode domain knowledge
    in graph models.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: CausalNexæ¯”Causal-learnæ›´æ·±å…¥åœ°æ¢è®¨äº†ç¥ç»ç½‘ç»œã€‚å…·ä½“æ¥è¯´ï¼ŒCausalNexå¤§é‡åˆ©ç”¨è´å¶æ–¯ç½‘ç»œï¼Œå¹¶æ—¨åœ¨åœ¨å›¾æ¨¡å‹ä¸­ç¼–ç é¢†åŸŸçŸ¥è¯†ã€‚
- en: '*[Uberâ€™s CausalML](https://oreil.ly/LzSf6)*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*[Uberçš„CausalML](https://oreil.ly/LzSf6)*'
- en: Like CausalNex, Uberâ€™s CausalML emphasizes the ML algorithms for causal inference.
    However, it offers a wider variety of algorithms, including tree-based algorithms
    (such as [Uplift trees based on KL divergence](https://oreil.ly/GMXzR)), meta-learner
    algorithms (including [S-learner and T-learner](https://oreil.ly/bUxG0), doubly
    robust learners), instrumental variables algorithms (such as two-stage least squares),
    and TensorFlow-based neural network algorithms (including [CEVAE](https://arxiv.org/abs/1705.08821)
    and [DragonNet](https://arxiv.org/abs/1906.02120)).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼äºCausalNexï¼ŒUberçš„CausalMLä¸“æ³¨äºå› æœæ¨æ–­çš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚ç„¶è€Œï¼Œå®ƒæä¾›äº†æ›´å¹¿æ³›çš„ç®—æ³•é€‰æ‹©ï¼ŒåŒ…æ‹¬åŸºäºæ ‘çš„ç®—æ³•ï¼ˆä¾‹å¦‚åŸºäºKLæ•£åº¦çš„æå‡æ ‘ç®—æ³•[Uplift
    trees based on KL divergence](https://oreil.ly/GMXzR)ï¼‰ï¼Œå…ƒå­¦ä¹ ç®—æ³•ï¼ˆåŒ…æ‹¬[S-learnerå’ŒT-learner](https://oreil.ly/bUxG0)ï¼ŒåŒé‡ç¨³å¥å­¦ä¹ è€…ï¼‰ï¼Œå·¥å…·å˜é‡ç®—æ³•ï¼ˆä¾‹å¦‚ä¸¤é˜¶æ®µæœ€å°äºŒä¹˜æ³•ï¼‰ï¼Œä»¥åŠåŸºäºTensorFlowçš„ç¥ç»ç½‘ç»œç®—æ³•ï¼ˆåŒ…æ‹¬[CEVAE](https://arxiv.org/abs/1705.08821)å’Œ[DragonNet](https://arxiv.org/abs/1906.02120)ï¼‰ã€‚
- en: '*[doWhy](https://oreil.ly/Jm9s1)*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*[DoWhy](https://oreil.ly/Jm9s1)*'
- en: Similar to CausalML, DoWhy (named for Judea Pearlâ€™s [â€œdo-calculusâ€](https://arxiv.org/abs/1305.5506))
    is an open source library (originally maintained by Microsoft) that covers multiple
    algorithms for causal inference, based on both statistical and ML methods. DoWhy
    has a few features that make it particularly useful. First, it is extensible with
    some of Microsoftâ€™s other causal ML libraries such as EconML and CausalML (not
    to be confused with the Uber CausalML library discussed previously). It also has
    a built-in high-level Pandas API. This is helpful, since most causal inference
    methods are geared toward tabular and time series data. The Pandas API also allows
    you to easily create mock datasets for testing. DoWhy is also much stronger than
    CausalML in providing automatic refutation tools.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼äºCausalMLï¼ŒDoWhyï¼ˆä»¥Judea Pearlçš„[â€œdo-calculusâ€](https://arxiv.org/abs/1305.5506)å‘½åï¼‰æ˜¯ä¸€ä¸ªå¼€æºåº“ï¼ˆæœ€åˆç”±å¾®è½¯ç»´æŠ¤ï¼‰ï¼Œæ¶µç›–äº†åŸºäºç»Ÿè®¡å’Œæœºå™¨å­¦ä¹ æ–¹æ³•çš„å¤šç§å› æœæ¨æ–­ç®—æ³•ã€‚DoWhyå…·æœ‰ä¸€äº›ç‰¹æ€§ä½¿å…¶ç‰¹åˆ«æœ‰ç”¨ã€‚é¦–å…ˆï¼Œå®ƒå¯ä»¥ä¸å¾®è½¯çš„å…¶ä»–å› æœæœºå™¨å­¦ä¹ åº“ï¼ˆå¦‚EconMLå’ŒCausalMLï¼Œä¸è¦ä¸ä¹‹å‰è®¨è®ºçš„Uber
    CausalMLåº“æ··æ·†ï¼‰ç›¸æ‰©å±•ã€‚å®ƒè¿˜å…·æœ‰å†…ç½®çš„é«˜çº§Pandas APIã€‚è¿™éå¸¸æœ‰å¸®åŠ©ï¼Œå› ä¸ºå¤§å¤šæ•°å› æœæ¨æ–­æ–¹æ³•éƒ½é’ˆå¯¹è¡¨æ ¼å’Œæ—¶é—´åºåˆ—æ•°æ®ã€‚Pandas APIè¿˜å…è®¸æ‚¨è½»æ¾åˆ›å»ºç”¨äºæµ‹è¯•çš„æ¨¡æ‹Ÿæ•°æ®é›†ã€‚DoWhyåœ¨æä¾›è‡ªåŠ¨åé©³å·¥å…·æ–¹é¢ä¹Ÿæ¯”CausalMLå¼ºå¤§å¾—å¤šã€‚
- en: Letâ€™s look at a small piece of code to understand how DoWhy helps encode a causal
    structure into ML workflows.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹ä¸€æ®µå°ä»£ç ç‰‡æ®µï¼Œäº†è§£DoWhyå¦‚ä½•å¸®åŠ©å°†å› æœç»“æ„ç¼–ç åˆ°æœºå™¨å­¦ä¹ å·¥ä½œæµä¸­ã€‚
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: While these packages are useful, causal ML still follows the [garbage in, garbage
    out](https://oreil.ly/2ItFq) principle. Your ability to draw conclusions about
    causality will depend on the quality of your dataset and on how well you follow
    the process of creating the hypothesis graph, testing it, and trying to refute
    it.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶è¿™äº›åŒ…å¾ˆæœ‰ç”¨ï¼Œå› æœæœºå™¨å­¦ä¹ ä»ç„¶éµå¾ªâ€œ[åƒåœ¾è¿›ï¼Œåƒåœ¾å‡º](https://oreil.ly/2ItFq)â€çš„åŸåˆ™ã€‚ä½ å¯¹å› æœæ€§çš„ç»“è®ºèƒ½åŠ›å°†å–å†³äºæ•°æ®é›†çš„è´¨é‡ä»¥åŠä½ å¦‚ä½•è·Ÿéšåˆ›å»ºå‡è®¾å›¾ã€æµ‹è¯•å’Œè¯•å›¾åé©³çš„è¿‡ç¨‹ã€‚
- en: Causality and trust
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å› æœæ€§ä¸ä¿¡ä»»
- en: Using an SCM, it is possible to embed domain knowledge into causal models that
    are inherently explainable (that is global explanations, see [ChapterÂ 3](ch03.html#chapter3))
    using regularization and to produce post hoc explanations. For local explanations,
    counterfactuals are useful in evaluating model outputs under alternate *what-if*
    scenarios, for instance, by supplying the model input examples with the values
    of some input features changed, then observing the outputs.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨SCMï¼Œå¯ä»¥å°†é¢†åŸŸçŸ¥è¯†åµŒå…¥åˆ°å› æœæ¨¡å‹ä¸­ï¼Œè¿™äº›æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯å¯è§£é‡Šçš„ï¼ˆå³å…¨å±€è§£é‡Šï¼Œå‚è§[ç¬¬3ç« ](ch03.html#chapter3)ï¼‰ï¼Œä½¿ç”¨æ­£åˆ™åŒ–å¹¶ç”Ÿæˆäº‹åè§£é‡Šã€‚å¯¹äºå±€éƒ¨è§£é‡Šï¼Œåäº‹å®åœ¨è¯„ä¼°æ¨¡å‹è¾“å‡ºåœ¨æ›¿ä»£*å‡è®¾*åœºæ™¯ä¸‹éå¸¸æœ‰ç”¨ï¼Œä¾‹å¦‚é€šè¿‡æä¾›æ¨¡å‹è¾“å…¥ç¤ºä¾‹å¹¶æ›´æ”¹æŸäº›è¾“å…¥ç‰¹å¾çš„å€¼ï¼Œç„¶åè§‚å¯Ÿè¾“å‡ºã€‚
- en: '*Counterfactual* explanations differ from non-causal feature attribution methods.
    Non-causal methods are based on changing *only* the values of the input features
    being evaluated. By contrast, counterfactual methods observe the model outputs
    at input points with changed values for the evaluated features *and* for other
    input features affected by the evaluated features, based on the underlying causal
    model.^([2](ch07.html#idm45621831819760)) The concept of counterfactuals may be
    applied to fairness and robustness too.^([3](ch07.html#idm45621831818272)) In
    general, evaluating synthetic counterfactual samples free from the confounding
    effects of real observational data allows for a more precise evaluation of trust
    metrics.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*åäº‹å®* è§£é‡Šä¸éå› æœç‰¹å¾å½’å› æ–¹æ³•ä¸åŒã€‚éå› æœæ–¹æ³•åŸºäºä»…æ”¹å˜è¢«è¯„ä¼°è¾“å…¥ç‰¹å¾çš„å€¼ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œåäº‹å®æ–¹æ³•è§‚å¯Ÿæ¨¡å‹è¾“å‡ºï¼Œè¾“å…¥ç‚¹çš„å€¼æ”¹å˜ä¸ºè¯„ä¼°ç‰¹å¾ä»¥åŠå—è¯„ä¼°ç‰¹å¾å½±å“çš„å…¶ä»–è¾“å…¥ç‰¹å¾ï¼ŒåŸºäºæ½œåœ¨çš„å› æœæ¨¡å‹ã€‚^([2](ch07.html#idm45621831819760))
    åäº‹å®çš„æ¦‚å¿µä¹Ÿå¯åº”ç”¨äºå…¬å¹³æ€§å’Œé²æ£’æ€§ã€‚^([3](ch07.html#idm45621831818272)) æ€»çš„æ¥è¯´ï¼Œè¯„ä¼°ä¸å—çœŸå®è§‚æµ‹æ•°æ®æ··æ·†æ•ˆåº”çš„åˆæˆåäº‹å®æ ·æœ¬ï¼Œå…è®¸æ›´ç²¾ç¡®åœ°è¯„ä¼°ä¿¡ä»»åº¦æŒ‡æ ‡ã€‚'
- en: Sparsity and Model Compression
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¨€ç–æ€§ä¸æ¨¡å‹å‹ç¼©
- en: Deploying large-scale ML models in industry applications is costly, since training
    them requires a lot of computing power and memory. Resource constraints become
    even more acute when it is time to deploy models into environments such as mobile
    phones. Generally, trained deep-learning model objectsâ€”and even random forest,
    or [XGBoost](https://oreil.ly/sbhXW)â€”contain numerous parameters to aid in the
    highly granular decision process. To train objects for on-the-edge ML, you need
    to compress the model.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å·¥ä¸šåº”ç”¨ä¸­éƒ¨ç½²å¤§è§„æ¨¡æœºå™¨å­¦ä¹ æ¨¡å‹æˆæœ¬é«˜æ˜‚ï¼Œå› ä¸ºè®­ç»ƒå®ƒä»¬éœ€è¦å¤§é‡çš„è®¡ç®—èƒ½åŠ›å’Œå†…å­˜ã€‚å½“éƒ¨ç½²æ¨¡å‹åˆ°ç§»åŠ¨ç”µè¯ç­‰ç¯å¢ƒæ—¶ï¼Œèµ„æºçº¦æŸå˜å¾—æ›´åŠ ä¸¥å³»ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œè®­ç»ƒå¥½çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹è±¡ï¼Œç”šè‡³éšæœºæ£®æ—æˆ–[XGBoost](https://oreil.ly/sbhXW)ï¼ŒåŒ…å«å¤§é‡å‚æ•°ï¼Œä»¥å¸®åŠ©é«˜åº¦ç»†ç²’åº¦çš„å†³ç­–è¿‡ç¨‹ã€‚ä¸ºäº†åœ¨è¾¹ç¼˜æœºå™¨å­¦ä¹ ä¸­è®­ç»ƒå¯¹è±¡ï¼Œä½ éœ€è¦å‹ç¼©æ¨¡å‹ã€‚
- en: 'By default, the training process of conventional neural networks (NN) and deep-learning
    models is *dense*: it sets the weights and biases of all nodes to non-zero values.
    You can probably guess that not all nodes contribute equally to model performance.
    Nodes with weights very close to zero contribute very little, so if you set those
    weights to exactly zero, there will be little to no impact on performance. This
    is what *sparse neural networks* do: a number of their weights are hard-coded
    to zero. Sparse neural networks not only help in model compression but also go
    a long way to improve generalization by preventing overfitting.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æƒ…å†µä¸‹ï¼Œä¼ ç»Ÿç¥ç»ç½‘ç»œï¼ˆNNï¼‰å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹æ˜¯*å¯†é›†*çš„ï¼šå®ƒè®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„æƒé‡å’Œåå·®ä¸ºéé›¶å€¼ã€‚ä½ å¯ä»¥çŒœæµ‹ï¼Œä¸æ˜¯æ‰€æœ‰èŠ‚ç‚¹å¯¹æ¨¡å‹æ€§èƒ½è´¡çŒ®ç›¸åŒã€‚æƒé‡æ¥è¿‘é›¶çš„èŠ‚ç‚¹è´¡çŒ®éå¸¸å°‘ï¼Œå› æ­¤å¦‚æœå°†è¿™äº›æƒé‡è®¾ç½®ä¸ºé›¶ï¼Œå¯¹æ€§èƒ½å‡ ä¹æ²¡æœ‰å½±å“ã€‚è¿™å°±æ˜¯*ç¨€ç–ç¥ç»ç½‘ç»œ*æ‰€åšçš„äº‹æƒ…ï¼šå®ƒä»¬çš„ä¸€äº›æƒé‡ç¡¬ç¼–ç ä¸ºé›¶ã€‚ç¨€ç–ç¥ç»ç½‘ç»œä¸ä»…æœ‰åŠ©äºæ¨¡å‹å‹ç¼©ï¼Œè¿˜é€šè¿‡é˜²æ­¢è¿‡æ‹Ÿåˆå¤§å¤§æ”¹å–„äº†æ³›åŒ–èƒ½åŠ›ã€‚
- en: Pruning
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç²¾ç®€
- en: A simple way to sparsify trained neural networks is to just drop low-magnitude
    weights. [Frankle and Carbin](https://oreil.ly/EikoA) popularized this approach.
    They compared finding just the right set of parameters to fit a neural network
    to the data involved with playing the lottery. Training a dense NN is like buying
    a lot of tickets to increase your odds of winning. But what if there was a way
    to figure out which lottery tickets are more likely to win? Then, you could spend
    less money while still guaranteeing a high amount of winnings. Similarly, if you
    could isolate the most important weights and biases behind the performance of
    a trained dense NN, youâ€™d be able to set the rest of them to zero while still
    maintaining good performance.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç¥ç»ç½‘ç»œè®­ç»ƒç»“æœå˜å¾—ç¨€ç–çš„ä¸€ä¸ªç®€å•æ–¹æ³•æ˜¯ä»…ä¸¢å¼ƒä½å¹…åº¦æƒé‡ã€‚[Frankle and Carbin](https://oreil.ly/EikoA) æå€¡äº†è¿™ç§æ–¹æ³•ã€‚ä»–ä»¬å°†æ‰¾åˆ°é€‚åˆç¥ç»ç½‘ç»œæ•°æ®çš„å‚æ•°é›†ä¸å‚ä¸å½©ç¥¨æ¸¸æˆçš„æƒ…å†µåšäº†æ¯”è¾ƒã€‚è®­ç»ƒå¯†é›†ç¥ç»ç½‘ç»œå°±åƒè´­ä¹°å¤§é‡å½©ç¥¨ä»¥å¢åŠ ä¸­å¥–æ¦‚ç‡ã€‚ä½†å¦‚æœæœ‰åŠæ³•æ‰¾å‡ºå“ªäº›å½©ç¥¨æ›´æœ‰å¯èƒ½ä¸­å¥–ï¼Œä½ å¯ä»¥èŠ±æ›´å°‘çš„é’±ï¼ŒåŒæ—¶ä¿è¯é«˜é¢å¥–é‡‘ã€‚ç±»ä¼¼åœ°ï¼Œå¦‚æœä½ èƒ½å¤Ÿåˆ†ç¦»å‡ºè®­ç»ƒåå¯†é›†ç¥ç»ç½‘ç»œæ€§èƒ½èƒŒåæœ€é‡è¦çš„æƒé‡å’Œåå·®ï¼Œä½ å°±èƒ½å°†å…¶ä½™çš„è®¾ä¸ºé›¶ï¼ŒåŒæ—¶ä»ç„¶ä¿æŒè‰¯å¥½çš„æ€§èƒ½ã€‚
- en: The systematic process of setting some parameters to zero in a dense NN is called
    *pruning*. As you prune, consider some trade-offs. For instance, you might need
    to balance the amount of pruning you do with performance metrics such as accuracy,
    optimal strategies for specific datasets or data types, and high-level design
    choices such as hardware and software architecture.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¯†é›†ç¥ç»ç½‘ç»œä¸­å°†ä¸€äº›å‚æ•°è®¾ä¸ºé›¶çš„ç³»ç»ŸåŒ–è¿‡ç¨‹ç§°ä¸º *ä¿®å‰ªï¼ˆpruningï¼‰*ã€‚åœ¨ä¿®å‰ªæ—¶ï¼Œéœ€è¦è€ƒè™‘ä¸€äº›æƒè¡¡ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½éœ€è¦åœ¨ä¿®å‰ªé‡å’Œæ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚å‡†ç¡®æ€§ï¼‰ã€ç‰¹å®šæ•°æ®é›†æˆ–æ•°æ®ç±»å‹çš„æœ€ä½³ç­–ç•¥ï¼Œä»¥åŠç¡¬ä»¶å’Œè½¯ä»¶æ¶æ„ç­‰é«˜çº§è®¾è®¡é€‰æ‹©ä¹‹é—´è¿›è¡Œå¹³è¡¡ã€‚
- en: 'There are three steps to obtaining sparse NNs: training, pruning, and fine-tuning.
    When the training process has converged for a NN model, its empirical riskâ€”that
    is, the average loss over training dataâ€”is minimal. If you prune the set of weights
    *W* for this NN by setting some weights to zero, this *will* degrade your modelâ€™s
    performance on the training data. As a result, youâ€™ll need to retrain your model.
    This is called *fine-tuning*. Generally, fine-tuning is performed for a predefined
    number of iterations.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è·å¾—ç¨€ç–ç¥ç»ç½‘ç»œçš„ä¸‰ä¸ªæ­¥éª¤åŒ…æ‹¬ï¼šè®­ç»ƒã€ä¿®å‰ªå’Œå¾®è°ƒã€‚å½“ç¥ç»ç½‘ç»œæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹æ”¶æ•›æ—¶ï¼Œå…¶ç»éªŒé£é™©â€”â€”å³å¯¹è®­ç»ƒæ•°æ®çš„å¹³å‡æŸå¤±â€”â€”æ˜¯æœ€å°çš„ã€‚å¦‚æœä½ é€šè¿‡å°†ä¸€äº›æƒé‡è®¾ä¸ºé›¶æ¥ä¿®å‰ªè¿™ä¸ªNNçš„æƒé‡é›†åˆ
    *W*ï¼Œè¿™å°†ä¼šé™ä½æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„æ€§èƒ½ã€‚å› æ­¤ï¼Œä½ éœ€è¦é‡æ–°è®­ç»ƒä½ çš„æ¨¡å‹ã€‚è¿™å°±æ˜¯æ‰€è°“çš„ *å¾®è°ƒ*ã€‚é€šå¸¸ï¼Œå¾®è°ƒæ˜¯åœ¨é¢„å®šä¹‰çš„è¿­ä»£æ¬¡æ•°å†…è¿›è¡Œçš„ã€‚
- en: 'Given training data *X* and a family of NNs defined as <math alttext="f left-parenthesis
    x comma dot right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo>
    <mo>Â·</mo> <mo>)</mo></mrow></math> , with the function *f* parametrized by a
    weight matrix *W*, the generic process of obtaining a sparse NN through pruning
    looks like the following algorithm:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å®šè®­ç»ƒæ•°æ® *X* å’Œä½œä¸º <math alttext="f left-parenthesis x comma dot right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>,</mo> <mo>Â·</mo> <mo>)</mo></mrow></math> å®šä¹‰çš„ä¸€ç»„ç¥ç»ç½‘ç»œï¼Œå…¶ä¸­å‡½æ•°
    *f* çš„å‚æ•°æ˜¯æƒé‡çŸ©é˜µ *W*ï¼Œé€šè¿‡ä¿®å‰ªè·å–ç¨€ç–ç¥ç»ç½‘ç»œçš„ä¸€èˆ¬è¿‡ç¨‹çœ‹èµ·æ¥åƒä»¥ä¸‹ç®—æ³•ï¼š
- en: Inputs
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å…¥
- en: 'Feature matrix: <math alttext="upper X element-of double-struck upper R Superscript
    n times p"><mrow><mi>X</mi> <mo>âˆˆ</mo> <msup><mi>â„</mi> <mrow><mi>n</mi><mo>Ã—</mo><mi>p</mi></mrow></msup></mrow></math>'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾çŸ©é˜µï¼š<math alttext="upper X element-of double-struck upper R Superscript n times
    p"><mrow><mi>X</mi> <mo>âˆˆ</mo> <msup><mi>â„</mi> <mrow><mi>n</mi><mo>Ã—</mo><mi>p</mi></mrow></msup></mrow></math>
- en: 'Number of iterations: *N*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿­ä»£æ¬¡æ•°ï¼š*N*
- en: Steps
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤
- en: <math alttext="upper W left-arrow i n i t i a l i z e left-parenthesis right-parenthesis"><mrow><mi>W</mi>
    <mo>â†</mo> <mi>i</mi> <mi>n</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi> <mi>a</mi> <mi>l</mi>
    <mi>i</mi> <mi>z</mi> <mi>e</mi> <mo>(</mo> <mo>)</mo></mrow></math>
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <math alttext="upper W left-arrow i n i t i a l i z e left-parenthesis right-parenthesis"><mrow><mi>W</mi>
    <mo>â†</mo> <mi>i</mi> <mi>n</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi> <mi>a</mi> <mi>l</mi>
    <mi>i</mi> <mi>z</mi> <mi>e</mi> <mo>(</mo> <mo>)</mo></mrow></math>
- en: <math alttext="upper W left-arrow t r a i n upper T o upper C o n v e r g e
    n c e left-parenthesis f left-parenthesis upper X semicolon upper W right-parenthesis
    right-parenthesis"><mrow><mi>W</mi> <mo>â†</mo> <mi>t</mi> <mi>r</mi> <mi>a</mi>
    <mi>i</mi> <mi>n</mi> <mi>T</mi> <mi>o</mi> <mi>C</mi> <mi>o</mi> <mi>n</mi> <mi>v</mi>
    <mi>e</mi> <mi>r</mi> <mi>g</mi> <mi>e</mi> <mi>n</mi> <mi>c</mi> <mi>e</mi> <mo>(</mo>
    <mi>f</mi> <mo>(</mo> <mi>X</mi> <mo>;</mo> <mi>W</mi> <mo>)</mo> <mo>)</mo></mrow></math>
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <math alttext="upper W left-arrow t r a i n upper T o upper C o n v e r g e
    n c e left-parenthesis f left-parenthesis upper X semicolon upper W right-parenthesis
    right-parenthesis"><mrow><mi>W</mi> <mo>â†</mo> <mi>t</mi> <mi>r</mi> <mi>a</mi>
    <mi>i</mi> <mi>n</mi> <mi>T</mi> <mi>o</mi> <mi>C</mi> <mi>o</mi> <mi>n</mi> <mi>v</mi>
    <mi>e</mi> <mi>r</mi> <mi>g</mi> <mi>e</mi> <mi>n</mi> <mi>c</mi> <mi>e</mi> <mo>(</mo>
    <mi>f</mi> <mo>(</mo> <mi>X</mi> <mo>;</mo> <mi>W</mi> <mo>)</mo> <mo>)</mo></mrow></math>
- en: <math alttext="upper M left-arrow o n e s left-parenthesis n comma p right-parenthesis"><mrow><mi>M</mi>
    <mo>â†</mo> <mi>o</mi> <mi>n</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo> <mi>n</mi> <mo>,</mo>
    <mi>p</mi> <mo>)</mo></mrow></math>
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <math alttext="upper M left-arrow o n e s left-parenthesis n comma p right-parenthesis"><mrow><mi>M</mi>
    <mo>â†</mo> <mi>o</mi> <mi>n</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo> <mi>n</mi> <mo>,</mo>
    <mi>p</mi> <mo>)</mo></mrow></math>
- en: 'for *i* in 1 : *N* do'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹äº *i* åœ¨ 1 åˆ° *N* ä¹‹é—´æ‰§è¡Œ
- en: <math alttext="upper M left-arrow p r u n e left-parenthesis upper M comma s
    c o r e left-parenthesis upper W right-parenthesis right-parenthesis"><mrow><mi>M</mi>
    <mo>â†</mo> <mi>p</mi> <mi>r</mi> <mi>u</mi> <mi>n</mi> <mi>e</mi> <mo>(</mo> <mi>M</mi>
    <mo>,</mo> <mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi> <mo>(</mo> <mi>W</mi>
    <mo>)</mo> <mo>)</mo></mrow></math>
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <math alttext="upper M left-arrow p r u n e left-parenthesis upper M comma s
    c o r e left-parenthesis upper W right-parenthesis right-parenthesis"><mrow><mi>M</mi>
    <mo>â†</mo> <mi>p</mi> <mi>r</mi> <mi>u</mi> <mi>n</mi> <mi>e</mi> <mo>(</mo> <mi>M</mi>
    <mo>,</mo> <mi>s</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi> <mo>(</mo> <mi>W</mi>
    <mo>)</mo> <mo>)</mo></mrow></math>
- en: <math alttext="upper W left-arrow f i n e upper T u n e left-parenthesis f left-parenthesis
    upper X semicolon upper M circled-dot upper W right-parenthesis right-parenthesis"><mrow><mi>W</mi>
    <mo>â†</mo> <mi>f</mi> <mi>i</mi> <mi>n</mi> <mi>e</mi> <mi>T</mi> <mi>u</mi> <mi>n</mi>
    <mi>e</mi> <mo>(</mo> <mi>f</mi> <mo>(</mo> <mi>X</mi> <mo>;</mo> <mi>M</mi> <mo>âŠ™</mo>
    <mi>W</mi> <mo>)</mo> <mo>)</mo></mrow></math>
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <math alttext="upper W left-arrow f i n e upper T u n e left-parenthesis f left-parenthesis
    upper X semicolon upper M circled-dot upper W right-parenthesis right-parenthesis"><mrow><mi>W</mi>
    <mo>â†</mo> <mi>f</mi> <mi>i</mi> <mi>n</mi> <mi>e</mi> <mi>T</mi> <mi>u</mi> <mi>n</mi>
    <mi>e</mi> <mo>(</mo> <mi>f</mi> <mo>(</mo> <mi>X</mi> <mo>;</mo> <mi>M</mi> <mo>âŠ™</mo>
    <mi>W</mi> <mo>)</mo> <mo>)</mo></mrow></math>
- en: return *M, W*
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿”å› *M, W*
- en: The pruning in step 5 applies a *score function* to each element of *W*, based
    on which it sets some elements of the mask *M* to zero. Think of the score function
    as a threshold. It could be as simple as absolute value, or as complex as how
    much an element of *W* contributes to the activation function of a layer. You
    can find pruning methods in the literature that deal with the details in the preceding
    algorithm. This includes designing novel score functions, fine-tuning methods,
    scheduling the pruning iterations, or structuring the pruning process to prune
    weights individually, by group, or other logics.^([4](ch07.html#idm45621831716192))
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬5æ­¥ä¸­çš„ä¿®å‰ªå¯¹ *W* çš„æ¯ä¸ªå…ƒç´ åº”ç”¨ä¸€ä¸ª *å¾—åˆ†å‡½æ•°ï¼ˆscore functionï¼‰*ï¼ŒåŸºäºè¿™ä¸ªå‡½æ•°å°† *M* çš„ä¸€äº›å…ƒç´ è®¾ä¸ºé›¶ã€‚å¯ä»¥å°†å¾—åˆ†å‡½æ•°çœ‹ä½œä¸€ä¸ªé˜ˆå€¼ã€‚å®ƒå¯ä»¥ç®€å•åˆ°ç»å¯¹å€¼ï¼Œä¹Ÿå¯ä»¥å¤æ‚åˆ°è€ƒè™‘åˆ°
    *W* çš„å…ƒç´ å¯¹å±‚æ¿€æ´»å‡½æ•°çš„è´¡çŒ®ç¨‹åº¦ã€‚æ–‡çŒ®ä¸­å¯ä»¥æ‰¾åˆ°å¤„ç†ä¸Šè¿°ç®—æ³•ç»†èŠ‚çš„ä¿®å‰ªæ–¹æ³•ã€‚è¿™åŒ…æ‹¬è®¾è®¡æ–°é¢–çš„å¾—åˆ†å‡½æ•°ã€å¾®è°ƒæ–¹æ³•ã€è°ƒåº¦ä¿®å‰ªè¿­ä»£æˆ–ç»“æ„åŒ–ä¿®å‰ªè¿‡ç¨‹ï¼Œä»¥ä¾¿é€šè¿‡ä¸ªåˆ«æƒé‡ã€æŒ‰ç»„æˆ–å…¶ä»–é€»è¾‘ä¿®å‰ªæƒé‡ã€‚^([4](ch07.html#idm45621831716192))
- en: Sparse training
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¨€ç–è®­ç»ƒ
- en: Pruning-based methods are somewhat ad hoc in nature. There are many techniques
    available for scoring, fine-tuning, and pruning. What combination of these techniques
    gives the best results will depend on your task and dataset. Compared to post-processing
    an already trained NN, sparse *training* methods provide more general performance
    guarantees on what algorithm works for which class of tasksâ€”â€‹in theory, at least.
    Robert Tibshirani proposed the first ever method for sparse training, called *least
    absolute shrinkage and selection operator* (LASSO),^([5](ch07.html#idm45621831705184))
    designed to work for linear regression. Since then the theory of sparse penalized
    models has become quite well-established.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºä¿®å‰ªçš„æ–¹æ³•åœ¨æŸç§ç¨‹åº¦ä¸Šæ˜¯ä¸´æ—¶æ€§çš„ã€‚æœ‰è®¸å¤šæŠ€æœ¯å¯ç”¨äºè¯„åˆ†ã€å¾®è°ƒå’Œä¿®å‰ªã€‚è¿™äº›æŠ€æœ¯çš„ç»„åˆå°†å–å†³äºæ‚¨çš„ä»»åŠ¡å’Œæ•°æ®é›†ï¼Œå“ªç§ç®—æ³•å¯¹å“ªç±»ä»»åŠ¡çš„æ•ˆæœæœ€ä½³ã€‚ä¸åå¤„ç†å·²è®­ç»ƒçš„ç¥ç»ç½‘ç»œç›¸æ¯”ï¼Œç¨€ç–*è®­ç»ƒ*æ–¹æ³•åœ¨ç†è®ºä¸Šä¸ºå“ªç§ç®—æ³•é€‚ç”¨äºå“ªç±»ä»»åŠ¡æä¾›äº†æ›´å¹¿æ³›çš„æ€§èƒ½ä¿è¯ã€‚ç½—ä¼¯ç‰¹Â·æå¸ƒä»€æ‹‰å°¼æœ€æ—©æå‡ºäº†ç”¨äºç¨€ç–è®­ç»ƒçš„æ–¹æ³•ï¼Œç§°ä¸º*æœ€å°ç»å¯¹å€¼æ”¶ç¼©å’Œé€‰æ‹©ç®—å­*ï¼ˆLASSOï¼‰^([5](ch07.html#idm45621831705184))ï¼Œè®¾è®¡ç”¨äºçº¿æ€§å›å½’ã€‚è‡ªé‚£æ—¶èµ·ï¼Œç¨€ç–æƒ©ç½šæ¨¡å‹çš„ç†è®ºå·²ç»ç›¸å½“æˆç†Ÿã€‚
- en: 'Sparse training involves optimization of a penalized risk function. With the
    notation in this section, the set of weights produced by a sparse training process
    can be written as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨€ç–è®­ç»ƒæ¶‰åŠä¼˜åŒ–ä¸€ä¸ªæƒ©ç½šé£é™©å‡½æ•°ã€‚åœ¨æœ¬èŠ‚çš„ç¬¦å·è¡¨ç¤ºä¸­ï¼Œç”±ç¨€ç–è®­ç»ƒè¿‡ç¨‹äº§ç”Ÿçš„æƒé‡é›†å¯ä»¥å†™æˆå¦‚ä¸‹å½¢å¼ï¼š
- en: <math><mrow><mover accent="true"><mi>W</mi> <mo>^</mo></mover> <mo>=</mo> <msub><mtext>argmax</mtext>
    <mrow><mi>W</mi><mo>âˆˆ</mo><mi>ğ’²</mi></mrow></msub> <mfenced close="}" open="{"
    separators=""><mi>L</mi> <mo>(</mo> <mi>Y</mi> <mo>,</mo> <mi>f</mi> <mo>(</mo>
    <mi>X</mi> <mo>;</mo> <mi>W</mi> <mo>)</mo> <mo>)</mo> <mo>+</mo> <mi>Î»</mi> <mi>P</mi>
    <mo>(</mo> <mi>W</mi> <mo>)</mo></mfenced></mrow></math>
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mover accent="true"><mi>W</mi> <mo>^</mo></mover> <mo>=</mo> <msub><mtext>argmax</mtext>
    <mrow><mi>W</mi><mo>âˆˆ</mo><mi>ğ’²</mi></mrow></msub> <mfenced close="}" open="{"
    separators=""><mi>L</mi> <mo>(</mo> <mi>Y</mi> <mo>,</mo> <mi>f</mi> <mo>(</mo>
    <mi>X</mi> <mo>;</mo> <mi>W</mi> <mo>)</mo> <mo>)</mo> <mo>+</mo> <mi>Î»</mi> <mi>P</mi>
    <mo>(</mo> <mi>W</mi> <mo>)</mo></mfenced></mrow></math>
- en: Here *Y* is the set of output features, <math alttext="script upper W"><mi>ğ’²</mi></math>
    is the set of all possible *W* matrices over which the optimization is run, <math
    alttext="upper L left-parenthesis dot comma dot right-parenthesis"><mrow><mi>L</mi>
    <mo>(</mo> <mo>Â·</mo> <mo>,</mo> <mo>Â·</mo> <mo>)</mo></mrow></math> is the loss
    function, and <math alttext="upper P left-parenthesis dot right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <mo>Â·</mo> <mo>)</mo></mrow></math> is a *penalty function*. Taking
    the penalty function as the *L[1]* norm, that is <math alttext="upper P left-parenthesis
    upper W right-parenthesis equals parallel-to upper W parallel-to"><mrow><mi>P</mi>
    <mrow><mo>(</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <msub><mrow><mo>âˆ¥</mo><mi>W</mi><mo>âˆ¥</mo></mrow>
    <mn>1</mn></msub></mrow></math> , imposes sparsity on the the values of calculated
    weights in the solution <math alttext="ModifyingAbove upper W With caret"><mover
    accent="true"><mi>W</mi> <mo>^</mo></mover></math> . The tuning parameter <math
    alttext="lamda"><mi>Î»</mi></math> controls the upper bound above which a value
    of <math alttext="ModifyingAbove upper W With caret"><mover accent="true"><mi>W</mi>
    <mo>^</mo></mover></math> will be set to 0. There are many ways of selecting the
    optimal <math alttext="lamda"><mi>Î»</mi></math> , such as cross-validation and
    [information criteria](https://oreil.ly/X2uCX).^([6](ch07.html#idm45621831663760))
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Here *Y* æ˜¯è¾“å‡ºç‰¹å¾çš„é›†åˆï¼Œ<math alttext="script upper W"><mi>ğ’²</mi></math> æ˜¯æ‰€æœ‰å¯èƒ½çš„ *W*
    çŸ©é˜µçš„é›†åˆï¼Œä¼˜åŒ–è¿è¡Œåœ¨è¿™äº›çŸ©é˜µä¸Šï¼Œ<math alttext="upper L left-parenthesis dot comma dot right-parenthesis"><mrow><mi>L</mi>
    <mo>(</mo> <mo>Â·</mo> <mo>,</mo> <mo>Â·</mo> <mo>)</mo></mrow></math> æ˜¯æŸå¤±å‡½æ•°ï¼Œè€Œ <math
    alttext="upper P left-parenthesis dot right-parenthesis"><mrow><mi>P</mi> <mo>(</mo>
    <mo>Â·</mo> <mo>)</mo></mrow></math> æ˜¯ä¸€ä¸ª*æƒ©ç½šå‡½æ•°*ã€‚å°†æƒ©ç½šå‡½æ•°å®šä¹‰ä¸º *L[1]* èŒƒæ•°ï¼Œå³ <math alttext="upper
    P left-parenthesis upper W right-parenthesis equals parallel-to upper W parallel-to"><mrow><mi>P</mi>
    <mrow><mo>(</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <msub><mrow><mo>âˆ¥</mo><mi>W</mi><mo>âˆ¥</mo></mrow>
    <mn>1</mn></msub></mrow></math> ï¼Œå¯¹äºè§£ <math alttext="ModifyingAbove upper W With
    caret"><mover accent="true"><mi>W</mi> <mo>^</mo></mover></math> çš„æƒé‡å€¼æ–½åŠ ç¨€ç–æ€§ã€‚è°ƒèŠ‚å‚æ•°
    <math alttext="lamda"><mi>Î»</mi></math> æ§åˆ¶äº† <math alttext="ModifyingAbove upper
    W With caret"><mover accent="true"><mi>W</mi> <mo>^</mo></mover></math> å€¼è¶…è¿‡è¯¥ä¸Šé™æ—¶è¢«è®¾ä¸º0çš„ä¸Šç•Œã€‚é€‰æ‹©æœ€ä¼˜
    <math alttext="lamda"><mi>Î»</mi></math> çš„æ–¹æ³•æœ‰å¾ˆå¤šï¼Œæ¯”å¦‚äº¤å‰éªŒè¯å’Œ[ä¿¡æ¯å‡†åˆ™](https://oreil.ly/X2uCX)^([6](ch07.html#idm45621831663760))ã€‚
- en: Although promising, sparse training methods are very computationally intensive
    when applied to models more complex than logistic regression. Further, modern
    deep learning software and hardware are optimized for *dense* matrix computations,
    so pruning is much easier to implement. A few recent papers are starting to propose
    realistic and scalable sparse NN training procedures.^([7](ch07.html#idm45621831656864))
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æœ‰å¸Œæœ›ï¼Œä½†å°†ç¨€ç–è®­ç»ƒæ–¹æ³•åº”ç”¨äºæ¯”é€»è¾‘å›å½’æ›´å¤æ‚çš„æ¨¡å‹æ—¶ï¼Œè®¡ç®—å¯†é›†åº¦éå¸¸é«˜ã€‚æ­¤å¤–ï¼Œç°ä»£æ·±åº¦å­¦ä¹ è½¯ä»¶å’Œç¡¬ä»¶éƒ½é’ˆå¯¹*å¯†é›†*çŸ©é˜µè®¡ç®—è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå› æ­¤ä¿®å‰ªï¼ˆpruningï¼‰è¦å®¹æ˜“å¾—å¤šã€‚æœ€è¿‘çš„å‡ ç¯‡è®ºæ–‡å¼€å§‹æå‡ºç°å®å’Œå¯æ‰©å±•çš„ç¨€ç–ç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ã€‚^([7](ch07.html#idm45621831656864))
- en: Note
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æ³¨æ„
- en: The discussion in this section applies mainly to neural networkâ€“based models.
    Other techniques, like those based on SVMs or decision trees, can also be subject
    to their own sparsity-inducing training methods.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬èŠ‚è®¨è®ºä¸»è¦é€‚ç”¨äºåŸºäºç¥ç»ç½‘ç»œçš„æ¨¡å‹ã€‚å…¶ä»–æŠ€æœ¯ï¼Œå¦‚åŸºäºæ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰æˆ–å†³ç­–æ ‘çš„æŠ€æœ¯ï¼Œä¹Ÿå¯ä»¥é‡‡ç”¨å®ƒä»¬è‡ªå·±çš„ç¨€ç–è¯±å¯¼è®­ç»ƒæ–¹æ³•ã€‚
- en: Trust elements in sparse models
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¨€ç–æ¨¡å‹ä¸­çš„ä¿¡ä»»å…ƒç´ 
- en: One advantage of sparse models is that theyâ€™re somewhat easier to interpret.
    A sparse NN has far fewer latent variables to keep track of than a dense NN. You
    can simply ignore some weights when interpreting many of the internals in a pruned
    model (about 90% sparsity or more), since they lead to dead ends. This can greatly
    reduce the amount of information youâ€™d need to process to interpret the prediction
    from a sparse NN model. Still, for very large models, like those for image segmentation
    or natural language processing, working with fewer weights might not be enough
    to lighten the burden.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨€ç–æ¨¡å‹çš„ä¸€ä¸ªä¼˜åŠ¿æ˜¯å®ƒä»¬æ›´å®¹æ˜“è§£é‡Šã€‚ç¨€ç–ç¥ç»ç½‘ç»œæ¯”å¯†é›†ç¥ç»ç½‘ç»œå°‘å¾—å¤šçš„æ½œå˜é‡éœ€è¦è·Ÿè¸ªã€‚åœ¨è§£é‡Šä¿®å‰ªæ¨¡å‹ï¼ˆçº¦90%æˆ–æ›´å¤šçš„ç¨€ç–åº¦ï¼‰ä¸­çš„è®¸å¤šå†…éƒ¨æ—¶ï¼Œæ‚¨å¯ä»¥ç®€å•åœ°å¿½ç•¥ä¸€äº›æƒé‡ï¼Œå› ä¸ºå®ƒä»¬ä¼šå¯¼è‡´æ­»èƒ¡åŒã€‚è¿™å¯ä»¥å¤§å¤§å‡å°‘æ‚¨éœ€è¦å¤„ç†çš„ä¿¡æ¯é‡ï¼Œä»¥è§£é‡Šç¨€ç–ç¥ç»ç½‘ç»œæ¨¡å‹çš„é¢„æµ‹ã€‚ç„¶è€Œï¼Œå¯¹äºåƒå›¾åƒåˆ†å‰²æˆ–è‡ªç„¶è¯­è¨€å¤„ç†çš„éå¸¸å¤§çš„æ¨¡å‹æ¥è¯´ï¼Œä½¿ç”¨æ›´å°‘çš„æƒé‡å¯èƒ½ä¸è¶³ä»¥å‡è½»è´Ÿæ‹…ã€‚
- en: Even though sparse models seem to improve generalization, they also tend to
    *forget* some information. For example, Hooker et al. showed that even though
    NNs can be pruned to high sparsity with little impact to *top-line metrics* such
    as top 1% or 5% accuracy, this comes at the cost of performance degradation in
    a small subset of samples, which they call *compression identified exemplars*
    (CIE).^([8](ch07.html#idm45621831645600)) In a later paper,^([9](ch07.html#idm45621831643664))
    the same team showed that CIEs are, in fact, more likely to contain underrepresented
    attribute values than non-CIEs, so they can exacerbate the fairness concerns in
    the original model. In general, CIEs are more likely to have a high influence
    on the training process. Pruned models are also highly sensitive to noise and
    corruption. Thus, itâ€™s possible that pruning has robustness and privacy implications.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ç¨€ç–æ¨¡å‹ä¼¼ä¹æé«˜äº†æ³›åŒ–èƒ½åŠ›ï¼Œä½†å®ƒä»¬ä¹Ÿå€¾å‘äº*å¿˜è®°*æŸäº›ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼ŒHookerç­‰äººè¡¨æ˜ï¼Œå°½ç®¡ç¥ç»ç½‘ç»œå¯ä»¥è¢«ä¿®å‰ªåˆ°é«˜ç¨€ç–åº¦è€Œå¯¹*é¡¶çº¿æŒ‡æ ‡*ï¼ˆå¦‚1%æˆ–5%çš„å‡†ç¡®ç‡ï¼‰å‡ ä¹æ²¡æœ‰å½±å“ï¼Œä½†è¿™æ˜¯ä»¥åœ¨å°‘æ•°æ ·æœ¬ä¸­æ€§èƒ½ä¸‹é™ä¸ºä»£ä»·çš„ï¼Œä»–ä»¬ç§°ä¹‹ä¸º*å‹ç¼©è¯†åˆ«ç¤ºä¾‹*ï¼ˆCIEï¼‰ã€‚^([8](ch07.html#idm45621831645600))
    åœ¨åç»­çš„ä¸€ç¯‡è®ºæ–‡ä¸­ï¼Œ^([9](ch07.html#idm45621831643664)) åŒä¸€å›¢é˜Ÿè¡¨æ˜ï¼ŒCIEå®é™…ä¸Šæ›´å¯èƒ½åŒ…å«æ¯”éCIEæ›´å°‘ä»£è¡¨çš„å±æ€§å€¼ï¼Œå› æ­¤å®ƒä»¬å¯èƒ½åŠ å‰§åŸå§‹æ¨¡å‹ä¸­çš„å…¬å¹³æ€§é—®é¢˜ã€‚æ€»çš„æ¥è¯´ï¼ŒCIEæ›´å¯èƒ½å¯¹è®­ç»ƒè¿‡ç¨‹äº§ç”Ÿè¾ƒé«˜çš„å½±å“ã€‚ä¿®å‰ªæ¨¡å‹è¿˜å¯¹å™ªå£°å’ŒæŸåéå¸¸æ•æ„Ÿã€‚å› æ­¤ï¼Œä¿®å‰ªå¯èƒ½å…·æœ‰é²æ£’æ€§å’Œéšç§æ–¹é¢çš„å½±å“ã€‚
- en: Uncertainty Quantification
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§é‡åŒ–
- en: In the previous section, you saw that for use cases where storing the weights
    for a large trained neural network is a concern, a concise internal representation
    of the network that preserves (most of) its predictive performance is desirable.
    In other situations, you may also want to know how certain the modelâ€™s decision
    is. A common example is when you are comparing the performance between two models
    and want to know if their performance is significantly different. There are multiple
    ways to quantify uncertainty depending on where in the decision process you focus.
    Model uncertainty measures can also be part of a fail-safe mechanism that sends
    an alert to the ML development team if a certain uncertainty measure drops below
    a critical threshold, triggering human-in-the-loop incident responses. In [â€œSparsity
    and Model Compressionâ€](#sec-sparsity), you reduced the numbers of latent variables
    that can contribute to a model. In a sense, you reduced the *functional uncertainty*,
    or the uncertainty that lies in the function that takes in the output. Beyond
    functional uncertainty, [*aleatoric* and *epistemic* uncertainty](https://oreil.ly/CQYqj)
    are two concepts that arise a lot in this space. Respectively, they refer to uncertainty
    around the inputs and around the outputs, though they can be easily confused.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‰ä¸€èŠ‚ä¸­ï¼Œä½ çœ‹åˆ°å¯¹äºå­˜å‚¨å¤§å‹è®­ç»ƒè¿‡çš„ç¥ç»ç½‘ç»œæƒé‡æ˜¯ä¸€ä¸ªé—®é¢˜çš„ç”¨ä¾‹ï¼Œä¿ç•™ï¼ˆå¤§éƒ¨åˆ†ï¼‰é¢„æµ‹æ€§èƒ½çš„ç®€æ´çš„ç½‘ç»œå†…éƒ¨è¡¨ç¤ºæ˜¯å¯å–çš„ã€‚åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½è¿˜æƒ³çŸ¥é“æ¨¡å‹å†³ç­–çš„ç¡®å®šç¨‹åº¦ã€‚ä¸€ä¸ªå¸¸è§çš„ä¾‹å­æ˜¯ï¼Œå½“ä½ æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„æ€§èƒ½å¹¶æƒ³çŸ¥é“å®ƒä»¬çš„æ€§èƒ½æ˜¯å¦æœ‰æ˜¾è‘—å·®å¼‚æ—¶ã€‚æ ¹æ®å†³ç­–è¿‡ç¨‹ä¸­ä½ å…³æ³¨çš„ä½ç½®ï¼Œæœ‰å¤šç§æ–¹å¼æ¥é‡åŒ–ä¸ç¡®å®šæ€§ã€‚æ¨¡å‹ä¸ç¡®å®šæ€§åº¦é‡ä¹Ÿå¯ä»¥ä½œä¸ºæ•…éšœå®‰å…¨æœºåˆ¶çš„ä¸€éƒ¨åˆ†ï¼Œå¦‚æœæŸä¸ªä¸ç¡®å®šæ€§åº¦é‡ä½äºä¸´ç•Œé˜ˆå€¼ï¼Œåˆ™è§¦å‘äººåœ¨ç¯è·¯çš„äº‹ä»¶å“åº”ï¼Œå‘MLå¼€å‘å›¢é˜Ÿå‘é€è­¦æŠ¥ã€‚åœ¨
    [â€œç¨€ç–æ€§å’Œæ¨¡å‹å‹ç¼©â€](#sec-sparsity) ä¸­ï¼Œä½ å‡å°‘äº†å¯ä»¥å¯¹æ¨¡å‹åšå‡ºè´¡çŒ®çš„æ½œåœ¨å˜é‡çš„æ•°é‡ã€‚åœ¨æŸç§æ„ä¹‰ä¸Šï¼Œä½ å‡å°‘äº† *åŠŸèƒ½æ€§ä¸ç¡®å®šæ€§*ï¼Œæˆ–è€…è¯´æ˜¯æ¶‰åŠåˆ°è¾“å‡ºçš„å‡½æ•°ä¸­çš„ä¸ç¡®å®šæ€§ã€‚è¶…è¶ŠåŠŸèƒ½æ€§ä¸ç¡®å®šæ€§ï¼Œ[*éšæœºæ€§*
    å’Œ *è®¤çŸ¥* ä¸ç¡®å®šæ€§](https://oreil.ly/CQYqj) æ˜¯åœ¨è¿™ä¸€é¢†åŸŸç»å¸¸å‡ºç°çš„ä¸¤ä¸ªæ¦‚å¿µã€‚å®ƒä»¬åˆ†åˆ«æŒ‡çš„æ˜¯å›´ç»•è¾“å…¥å’Œè¾“å‡ºçš„ä¸ç¡®å®šæ€§ï¼Œå°½ç®¡å®ƒä»¬å¾ˆå®¹æ˜“æ··æ·†ã€‚
- en: Aleatoric uncertainty
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: éšæœºæ€§ä¸ç¡®å®šæ€§
- en: Even if the true output label for a model input is within the distribution of
    accepted outputs, the inputs themselves may fall outside the training distribution
    of input data. In other words, even if an input is legitimate and should create
    an acceptable output, the training algorithm may not be able to compute it properly.
    This uncertainty, referring to input data (within the appropriate problem space)
    failing to be matched with other data with the same ground truth, is also referred
    to as *aleatoric uncertainty*. For example, suppose you have an MNIST classifier
    that was trained to distinguish the digits 0â€“9. You could input an image that
    belongs to one of those classes but has a shape between that of two very similar
    classes (e.g., 1 and 7 or 6 and 0). This is an example of aleatoric uncertainty.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿æ¨¡å‹è¾“å…¥çš„çœŸå®è¾“å‡ºæ ‡ç­¾åœ¨æ¥å—çš„è¾“å‡ºåˆ†å¸ƒä¹‹å†…ï¼Œè¾“å…¥æœ¬èº«å¯èƒ½ä»ç„¶è½åœ¨è®­ç»ƒæ•°æ®è¾“å…¥åˆ†å¸ƒä¹‹å¤–ã€‚æ¢å¥è¯è¯´ï¼Œå³ä½¿ä¸€ä¸ªè¾“å…¥æ˜¯åˆæ³•çš„å¹¶ä¸”åº”è¯¥äº§ç”Ÿä¸€ä¸ªå¯æ¥å—çš„è¾“å‡ºï¼Œè®­ç»ƒç®—æ³•å¯èƒ½æ— æ³•æ­£ç¡®è®¡ç®—å®ƒã€‚è¿™ç§ä¸ç¡®å®šæ€§ï¼ŒæŒ‡çš„æ˜¯è¾“å…¥æ•°æ®ï¼ˆåœ¨é€‚å½“çš„é—®é¢˜ç©ºé—´å†…ï¼‰æœªèƒ½ä¸å…¶ä»–å…·æœ‰ç›¸åŒåœ°é¢çœŸå®çš„æ•°æ®åŒ¹é…ï¼Œä¹Ÿè¢«ç§°ä¸º
    *éšæœºæ€§ä¸ç¡®å®šæ€§*ã€‚ä¾‹å¦‚ï¼Œå‡è®¾ä½ æœ‰ä¸€ä¸ªMNISTåˆ†ç±»å™¨ï¼Œè®­ç»ƒå®ƒå¯ä»¥åŒºåˆ†æ•°å­—0åˆ°9ã€‚ä½ å¯ä»¥è¾“å…¥ä¸€ä¸ªå±äºè¿™äº›ç±»ä¹‹ä¸€ä½†å½¢çŠ¶ä»‹äºä¸¤ä¸ªéå¸¸ç›¸ä¼¼ç±»åˆ«ä¹‹é—´çš„å›¾åƒï¼ˆä¾‹å¦‚1å’Œ7æˆ–6å’Œ0ï¼‰ã€‚è¿™å°±æ˜¯éšæœºæ€§ä¸ç¡®å®šæ€§çš„ä¸€ä¸ªä¾‹å­ã€‚
- en: Cases of high aleatoric uncertainty are harder to solve with alternative problem
    formulations than cases of high epistemic uncertainty (see the following section).
    This is part of why aleatoric uncertainty is still a large problem in medical
    diagnosis, despite the amount of time and resources applied to solving it.^([10](ch07.html#idm45621831625888))
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: é«˜éšæœºæ€§ä¸ç¡®å®šæ€§æ¡ˆä¾‹æ¯”é«˜è®¤çŸ¥ä¸ç¡®å®šæ€§æ¡ˆä¾‹çš„æ›¿ä»£é—®é¢˜è¡¨è¿°æ›´éš¾è§£å†³ï¼ˆè§ä¸‹ä¸€èŠ‚ï¼‰ã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå°½ç®¡èŠ±è´¹äº†å¤§é‡æ—¶é—´å’Œèµ„æºæ¥è§£å†³å®ƒï¼Œä½†éšæœºæ€§ä¸ç¡®å®šæ€§åœ¨åŒ»å­¦è¯Šæ–­ä¸­ä»ç„¶æ˜¯ä¸€ä¸ªå¤§é—®é¢˜çš„ä¸€éƒ¨åˆ†ã€‚^([10](ch07.html#idm45621831625888))
- en: Epistemic uncertainty
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è®¤çŸ¥ä¸ç¡®å®šæ€§
- en: '*Epistemic uncertainty* refers to ground truth output decisions that fall outside
    the distributions of previously known outputs. As an example, imagine that instead
    of feeding in an image of a handwritten digit, you feed in something completely
    alien to the previously mentioned MNIST classifier. You might feed in a handwritten
    letter, or a typeset letter, or something thatâ€™s not even a letter or digit but
    say a picture of a dog.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*è®¤çŸ¥ä¸ç¡®å®šæ€§* æŒ‡çš„æ˜¯åœ°é¢çœŸå®è¾“å‡ºå†³ç­–è½åœ¨å…ˆå‰å·²çŸ¥è¾“å‡ºåˆ†å¸ƒä¹‹å¤–çš„æƒ…å†µã€‚ä¾‹å¦‚ï¼Œæƒ³è±¡ä¸€ä¸‹ï¼Œä½ ä¸æ˜¯è¾“å…¥ä¸€ä¸ªæ‰‹å†™æ•°å­—çš„å›¾åƒï¼Œè€Œæ˜¯è¾“å…¥ä¸€äº›å®Œå…¨ä¸åŒäºå…ˆå‰æåˆ°çš„MNISTåˆ†ç±»å™¨çš„ä¸œè¥¿ã€‚ä½ å¯èƒ½è¾“å…¥ä¸€å°æ‰‹å†™çš„å­—æ¯ï¼Œæˆ–è€…ä¸€å°æ’ç‰ˆçš„å­—æ¯ï¼Œæˆ–è€…ç”šè‡³ä¸æ˜¯å­—æ¯æˆ–æ•°å­—è€Œæ˜¯ä¸€å¹…ç‹—çš„å›¾ç‰‡ã€‚'
- en: For most classifiers with hard-coded outputs, there is usually no option for
    â€œdoes not belong to any recognized classes.â€ This is unless youâ€™re specifically
    creating a one-versus-all classifier with a designated [*garbage class*](https://oreil.ly/h6uqr).
    Even then, itâ€™s difficult to account for all possible (and theoretically infinite)
    ways the input could be outside the training distribution. A few types of ML model
    architectures take this into account. For example, image segmentation models in
    general have a *background class* that represents everything thatâ€™s not within
    the boundary for the object of interest.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¤§å¤šæ•°ç¡¬ç¼–ç è¾“å‡ºçš„åˆ†ç±»å™¨æ¥è¯´ï¼Œé€šå¸¸æ²¡æœ‰â€œä¸å±äºä»»ä½•å·²è¯†åˆ«ç±»åˆ«â€çš„é€‰é¡¹ã€‚è¿™æ˜¯é™¤éä½ ä¸“é—¨åˆ›å»ºä¸€ä¸ªå…·æœ‰æŒ‡å®š[*åƒåœ¾ç±»*](https://oreil.ly/h6uqr)çš„ä¸€å¯¹æ‰€æœ‰åˆ†ç±»å™¨ã€‚å³ä½¿å¦‚æ­¤ï¼Œå¾ˆéš¾è€ƒè™‘åˆ°è¾“å…¥å¯èƒ½åœ¨è®­ç»ƒåˆ†å¸ƒä¹‹å¤–çš„æ‰€æœ‰å¯èƒ½æ–¹å¼ï¼ˆç†è®ºä¸Šæ˜¯æ— é™çš„ï¼‰ã€‚ä¸€äº›MLæ¨¡å‹æ¶æ„è€ƒè™‘åˆ°äº†è¿™ä¸€ç‚¹ã€‚ä¾‹å¦‚ï¼Œä¸€èˆ¬çš„å›¾åƒåˆ†å‰²æ¨¡å‹å…·æœ‰ä¸€ä¸ª*èƒŒæ™¯ç±»*ï¼Œä»£è¡¨æ‰€æœ‰ä¸åœ¨æ„Ÿå…´è¶£å¯¹è±¡è¾¹ç•Œå†…çš„å†…å®¹ã€‚
- en: For general quantification of epistemic uncertainty there are many formulaic
    approaches, depending on exactly how the output structure is defined. Letâ€™s explore
    three such approaches in the context of one-hot encoded or binary classifiers.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ™®éé‡åŒ–è®¤çŸ¥ä¸ç¡®å®šæ€§ï¼Œæœ‰è®¸å¤šå…¬å¼åŒ–çš„æ–¹æ³•ï¼Œå…·ä½“å–å†³äºè¾“å‡ºç»“æ„çš„å®šä¹‰æ–¹å¼ã€‚è®©æˆ‘ä»¬åœ¨ä¸€ä¸ªç‹¬çƒ­ç¼–ç æˆ–äºŒå…ƒåˆ†ç±»å™¨çš„ä¸Šä¸‹æ–‡ä¸­æ¢è®¨è¿™ä¸‰ç§æ–¹æ³•ã€‚
- en: 'There are three common ways to calculate epistemic uncertainty for ML decision
    making. The most straightforward way to measure uncertainty from a classifier
    model is *classification uncertainty*: <math alttext="upper U left-parenthesis
    x right-parenthesis equals 1 minus upper P left-parenthesis ModifyingAbove x With
    caret vertical-bar x right-parenthesis"><mrow><mi>U</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn> <mo>-</mo> <mi>P</mi> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>^</mo></mover> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    , where *x* is the instance to be predicted and <math alttext="upper P left-parenthesis
    ModifyingAbove x With caret vertical-bar x right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>^</mo></mover> <mo>|</mo> <mi>x</mi>
    <mo>)</mo></mrow></math> is the most likely prediction. For example, if you have
    classes `[0,1,2]` and classification probabilities `[0.1,0.2,0.7]`, the most likely
    class according to the classifier is 2 with uncertainty 0.3. Say you have three
    instances with class probabilities.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸‰ç§å¸¸è§æ–¹æ³•å¯ä»¥è®¡ç®—MLå†³ç­–åˆ¶å®šçš„è®¤çŸ¥ä¸ç¡®å®šæ€§ã€‚ä»åˆ†ç±»å™¨æ¨¡å‹ä¸­æµ‹é‡ä¸ç¡®å®šæ€§çš„æœ€ç›´æ¥æ–¹æ³•æ˜¯*åˆ†ç±»ä¸ç¡®å®šæ€§*ï¼š<math alttext="upper U
    left-parenthesis x right-parenthesis equals 1 minus upper P left-parenthesis ModifyingAbove
    x With caret vertical-bar x right-parenthesis"><mrow><mi>U</mi> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn> <mo>-</mo> <mi>P</mi> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>^</mo></mover> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>ï¼Œå…¶ä¸­*x*æ˜¯è¦é¢„æµ‹çš„å®ä¾‹ï¼Œ<math
    alttext="upper P left-parenthesis ModifyingAbove x With caret vertical-bar x right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>^</mo></mover> <mo>|</mo> <mi>x</mi>
    <mo>)</mo></mrow></math>æ˜¯æœ€æœ‰å¯èƒ½çš„é¢„æµ‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰ç±»åˆ« `[0,1,2]` å’Œåˆ†ç±»æ¦‚ç‡ `[0.1,0.2,0.7]`ï¼Œåˆ™æ ¹æ®åˆ†ç±»å™¨ï¼Œæœ€å¯èƒ½çš„ç±»åˆ«æ˜¯2ï¼Œä¸ç¡®å®šæ€§ä¸º0.3ã€‚å‡è®¾ä½ æœ‰ä¸‰ä¸ªå¸¦æœ‰ç±»åˆ«æ¦‚ç‡çš„å®ä¾‹ã€‚
- en: '[PRE1]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The corresponding uncertainties are `1 - proba.max(axis=1)`, or `array([0.15,
    0.4, 0.39])` (in short, the second class is the most uncertain). This is useful
    for class-specific uncertainty, that is, if you are uncertain whether the predictions
    for a class are accurate or not. But you also want to take into account differences
    *between* classifications, that is how much uncertainty does a class prediction
    containâ€”â€‹whether it is correct or not.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸åº”çš„ä¸ç¡®å®šæ€§ä¸º `1 - proba.max(axis=1)`ï¼Œæˆ–è€… `array([0.15, 0.4, 0.39])`ï¼ˆç®€è¨€ä¹‹ï¼Œç¬¬äºŒç±»æœ€ä¸ç¡®å®šï¼‰ã€‚è¿™å¯¹äºç‰¹å®šç±»åˆ«çš„ä¸ç¡®å®šæ€§å¾ˆæœ‰ç”¨ï¼Œå³å¦‚æœä½ ä¸ç¡®å®šæŸä¸ªç±»åˆ«çš„é¢„æµ‹æ˜¯å¦å‡†ç¡®ã€‚ä½†ä½ ä¹Ÿå¸Œæœ›è€ƒè™‘åˆ°åˆ†ç±»ä¹‹é—´çš„å·®å¼‚ï¼Œå³ä¸€ä¸ªç±»åˆ«é¢„æµ‹åŒ…å«å¤šå°‘ä¸ç¡®å®šæ€§â€”â€”å®ƒæ˜¯å¦æ­£ç¡®æˆ–ä¸æ­£ç¡®ã€‚
- en: '*Classification margin* is the difference in probability between the first
    most likely prediction and the second most likely. Mathematically, it is defined
    as <math alttext="upper M left-parenthesis x right-parenthesis equals upper P
    left-parenthesis ModifyingAbove x 1 With caret vertical-bar x right-parenthesis
    minus upper P left-parenthesis ModifyingAbove x 2 With caret vertical-bar x right-parenthesis"><mrow><mi>M</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo>
    <mover accent="true"><msub><mi>x</mi> <mn>1</mn></msub> <mo>^</mo></mover> <mo>|</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>-</mo> <mi>P</mi> <mrow><mo>(</mo> <mover accent="true"><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>^</mo></mover> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    . Here, <math alttext="ModifyingAbove x 1 With caret"><mover accent="true"><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>^</mo></mover></math> is the most likely class, and <math
    alttext="ModifyingAbove x 2 With caret"><mover accent="true"><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>^</mo></mover></math> is the second most likely. Using the
    same example as for classification uncertainty, for the class probabilities given
    in the matrix `proba`, the corresponding margins are'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*åˆ†ç±»é—´éš”* æ˜¯æŒ‡ç¬¬ä¸€æœ€å¯èƒ½é¢„æµ‹ä¸ç¬¬äºŒæœ€å¯èƒ½é¢„æµ‹ä¹‹é—´çš„æ¦‚ç‡å·®å¼‚ã€‚æ•°å­¦ä¸Šå®šä¹‰ä¸º <math alttext="upper M left-parenthesis
    x right-parenthesis equals upper P left-parenthesis ModifyingAbove x 1 With caret
    vertical-bar x right-parenthesis minus upper P left-parenthesis ModifyingAbove
    x 2 With caret vertical-bar x right-parenthesis"><mrow><mi>M</mi> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo> <mover accent="true"><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>^</mo></mover> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>-</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mover accent="true"><msub><mi>x</mi> <mn>2</mn></msub>
    <mo>^</mo></mover> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math> ã€‚è¿™é‡Œï¼Œ<math
    alttext="ModifyingAbove x 1 With caret"><mover accent="true"><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>^</mo></mover></math> æ˜¯æœ€å¯èƒ½çš„ç±»åˆ«ï¼Œè€Œ<math alttext="ModifyingAbove
    x 2 With caret"><mover accent="true"><msub><mi>x</mi> <mn>2</mn></msub> <mo>^</mo></mover></math>
    æ˜¯ç¬¬äºŒå¯èƒ½çš„ç±»åˆ«ã€‚ä½¿ç”¨ä¸åˆ†ç±»ä¸ç¡®å®šæ€§ç›¸åŒçš„ç¤ºä¾‹ï¼Œå¯¹äºçŸ©é˜µ`proba`ä¸­ç»™å®šçš„ç±»æ¦‚ç‡ï¼Œç›¸åº”çš„é—´éš”ä¸º'
- en: '[PRE2]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: When you are querying for labels, this strategy selects the sample with the
    smallest margin, since the smaller the decision margin is, the less sure the decision.
    In this case, the sample with the smallest margin would be the third sample.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ‚¨æŸ¥è¯¢æ ‡ç­¾æ—¶ï¼Œè¿™ç§ç­–ç•¥é€‰æ‹©å…·æœ‰æœ€å°é—´éš”çš„æ ·æœ¬ï¼Œå› ä¸ºå†³ç­–é—´éš”è¶Šå°ï¼Œå†³ç­–è¶Šä¸ç¡®å®šã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå…·æœ‰æœ€å°é—´éš”çš„æ ·æœ¬å°†æ˜¯ç¬¬ä¸‰ä¸ªæ ·æœ¬ã€‚
- en: '*Classification entropy* gives an approach to uncertainty thatâ€™s more grounded
    in information theory. In information theory, we have the concept of entropy of
    a random variable, or the average level of â€œinformation,â€ â€œsurprise,â€ or â€œuncertaintyâ€
    inherent to the variableâ€™s possible outcomes. If we have a random variable like
    a dice roll, weâ€™d expect the probabilities of the possible outcomes to be equal.
    However, since a good classifier will favor one outcome over the others in response
    to the input, the output logits become far more predictable than a random variable
    (and thus less â€œsurprisingâ€ or â€œuncertain.â€ Mathematically, itâ€™s simply the [Shannon
    entropy](https://oreil.ly/0niIu) defined over the distribution of predicted class
    probabilities for a sample: <math alttext="upper H left-parenthesis x right-parenthesis
    equals minus sigma-summation Underscript k Endscripts p Subscript k Baseline log
    left-parenthesis p Subscript k Baseline right-parenthesis"><mrow><mi>H</mi> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <msub><mo>âˆ‘</mo> <mi>k</mi></msub>
    <msub><mi>p</mi> <mi>k</mi></msub> <mo form="prefix">log</mo> <mrow><mo>(</mo>
    <msub><mi>p</mi> <mi>k</mi></msub> <mo>)</mo></mrow></mrow></math> , where *p[k]*
    is the probability of the sample belonging to the *k*-th class.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*åˆ†ç±»ç†µ* æä¾›äº†ä¸€ç§æ›´åŸºäºä¿¡æ¯è®ºçš„ä¸ç¡®å®šæ€§æ–¹æ³•ã€‚åœ¨ä¿¡æ¯è®ºä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªéšæœºå˜é‡çš„ç†µï¼Œæˆ–è€…è¯´æ˜¯å˜é‡å¯èƒ½ç»“æœçš„â€œä¿¡æ¯â€ã€â€œæƒŠè®¶â€æˆ–â€œä¸ç¡®å®šæ€§â€çš„å¹³å‡æ°´å¹³ã€‚å¦‚æœæˆ‘ä»¬æœ‰åƒæ·éª°å­è¿™æ ·çš„éšæœºå˜é‡ï¼Œæˆ‘ä»¬æœŸæœ›å¯èƒ½ç»“æœçš„æ¦‚ç‡æ˜¯ç›¸ç­‰çš„ã€‚ç„¶è€Œï¼Œç”±äºä¸€ä¸ªå¥½çš„åˆ†ç±»å™¨ä¼šåå‘æŸä¸ªè¾“å‡ºè€Œä¸æ˜¯å…¶ä»–è¾“å‡ºï¼Œè¾“å‡ºçš„logitsæ¯”éšæœºå˜é‡æ›´å¯é¢„æµ‹ï¼ˆå› æ­¤æ›´å°‘â€œæƒŠè®¶â€æˆ–â€œä¸ç¡®å®šâ€ï¼‰ã€‚æ•°å­¦ä¸Šï¼Œå®ƒç®€å•åœ°æ˜¯[Shannonç†µ](https://oreil.ly/0niIu)åœ¨æ ·æœ¬çš„é¢„æµ‹ç±»æ¦‚ç‡åˆ†å¸ƒä¸Šå®šä¹‰ï¼š<math
    alttext="upper H left-parenthesis x right-parenthesis equals minus sigma-summation
    Underscript k Endscripts p Subscript k Baseline log left-parenthesis p Subscript
    k Baseline right-parenthesis"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mo>-</mo> <msub><mo>âˆ‘</mo> <mi>k</mi></msub> <msub><mi>p</mi> <mi>k</mi></msub>
    <mo form="prefix">log</mo> <mrow><mo>(</mo> <msub><mi>p</mi> <mi>k</mi></msub>
    <mo>)</mo></mrow></mrow></math> ï¼Œå…¶ä¸­*p[k]* æ˜¯æ ·æœ¬å±äºç¬¬*k*ç±»çš„æ¦‚ç‡ã€‚'
- en: Heuristically, the entropy is proportional to the average number of guesses
    youâ€™d have to make to find the true class. Letâ€™s come back to our example from
    before. Here, the corresponding entropies are
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å°±ç›´è§‰è€Œè¨€ï¼Œç†µä¸ä½ æ‰¾åˆ°çœŸå®ç±»åˆ«æ‰€éœ€çš„å¹³å‡çŒœæµ‹æ¬¡æ•°æˆæ­£æ¯”ã€‚è®©æˆ‘ä»¬å›åˆ°ä¹‹å‰çš„ä¾‹å­ã€‚åœ¨è¿™é‡Œï¼Œç›¸åº”çš„ç†µæ˜¯
- en: '[PRE3]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you repeat this process for many random samples, you would get a *distribution*
    of the uncertainty values. [FigureÂ 7-1](#img-uncertainty) gives the distributions
    of the three types of uncertainties. The closer a distribution is to uniform,
    the larger that specific type of uncertainty is. Proximity to a corner of the
    triangle indicates high predicted probability for the outcome to have that specific
    label.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¯¹è®¸å¤šéšæœºæ ·æœ¬é‡å¤æ­¤è¿‡ç¨‹ï¼Œä½ ä¼šå¾—åˆ°ä¸€ä¸ª*åˆ†å¸ƒ*ï¼Œæ˜¾ç¤ºä¸ç¡®å®šæ€§å€¼ã€‚[å›¾7-1](#img-uncertainty)å±•ç¤ºäº†ä¸‰ç§ä¸ç¡®å®šæ€§çš„åˆ†å¸ƒã€‚åˆ†å¸ƒè¶Šæ¥è¿‘å‡åŒ€ï¼Œç‰¹å®šç±»å‹çš„ä¸ç¡®å®šæ€§è¶Šå¤§ã€‚ä¸‰è§’å½¢çš„è§’è½è¶Šæ¥è¿‘ï¼Œè¯´æ˜ç‰¹å®šæ ‡ç­¾çš„é¢„æµ‹æ¦‚ç‡è¶Šé«˜ã€‚
- en: '![ptml 0701](assets/ptml_0701.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0701](assets/ptml_0701.png)'
- en: Figure 7-1\. Representations of uncertainty distributions
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾7-1\. ä¸ç¡®å®šæ€§åˆ†å¸ƒçš„è¡¨ç°å½¢å¼
- en: For a code walkthrough of the preceding example of implementing classification
    uncertainty, margin uncertainty, and classification entropy in a three-class classification
    problem, see [this notebook](https://oreil.ly/oydWO).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è¦äº†è§£å¦‚ä½•åœ¨ä¸€ä¸ªä¸‰ç±»åˆ†ç±»é—®é¢˜ä¸­å®ç°åˆ†ç±»ä¸ç¡®å®šæ€§ã€è¾¹é™…ä¸ç¡®å®šæ€§å’Œåˆ†ç±»ç†µçš„ä»£ç æ¼”ç¤ºï¼Œè¯·å‚è§[è¿™ä¸ªç¬”è®°æœ¬](https://oreil.ly/oydWO)ã€‚
- en: Tip
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æç¤º
- en: 'Letâ€™s look back for a moment at [â€œDeep Dive: Adversarial Attacks in Computer
    Visionâ€](ch04.html#deepdive-cv). Among the uncertainty metrics you learned here,
    which do you think is suitable for quantifying the ambiguity in predicted probabilities
    for the different images?'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç¨å¾®å›é¡¾ä¸€ä¸‹[â€œæ·±å…¥äº†è§£ï¼šè®¡ç®—æœºè§†è§‰ä¸­çš„å¯¹æŠ—æ€§æ”»å‡»â€](ch04.html#deepdive-cv)ã€‚åœ¨è¿™é‡Œå­¦åˆ°çš„ä¸ç¡®å®šæ€§åº¦é‡ä¸­ï¼Œä½ è®¤ä¸ºå“ªä¸€ä¸ªé€‚åˆç”¨æ¥é‡åŒ–ä¸åŒå›¾åƒé¢„æµ‹æ¦‚ç‡ä¸­çš„æ¨¡ç³Šæ€§ï¼Ÿ
- en: Confidence intervals
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç½®ä¿¡åŒºé—´
- en: As you saw in the previous section, aleatoric and epistemic uncertainty can
    be quantified by simple dimensionless numbers. However, when presenting uncertainty
    to stakeholders, youâ€™ll usually want to choose a more intuitive visual representation.
    For regression-based models, you can present the outputs in the form of [confidence
    intervals (CI)](https://oreil.ly/WZfBO). Most data scientists and ML practitioners
    should be familiar with placing bars that indicate the upper and lower estimates.
    Typically, you can do this by calculating the [standard error](https://oreil.ly/oSt6U)
    of the mean response, then using that to build a CI of that mean response.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚åœ¨å‰ä¸€èŠ‚ä¸­æ‰€çœ‹åˆ°çš„ï¼Œé€šè¿‡ç®€å•çš„æ— é‡çº²æ•°å­—å¯ä»¥é‡åŒ–è¯¯å·®ä¸ç¡®å®šæ€§å’Œè®¤çŸ¥ä¸ç¡®å®šæ€§ã€‚ç„¶è€Œï¼Œå½“å‘åˆ©ç›Šç›¸å…³è€…å‘ˆç°ä¸ç¡®å®šæ€§æ—¶ï¼Œé€šå¸¸ä¼šé€‰æ‹©æ›´ç›´è§‚çš„è§†è§‰è¡¨ç¤ºã€‚å¯¹äºåŸºäºå›å½’çš„æ¨¡å‹ï¼Œä½ å¯ä»¥ä»¥[ç½®ä¿¡åŒºé—´ï¼ˆCIï¼‰](https://oreil.ly/WZfBO)çš„å½¢å¼å‘ˆç°è¾“å‡ºã€‚å¤§å¤šæ•°æ•°æ®ç§‘å­¦å®¶å’Œæœºå™¨å­¦ä¹ ä»ä¸šè€…åº”è¯¥ç†Ÿæ‚‰æ”¾ç½®æŒ‡ç¤ºä¸Šä¸‹é™ä¼°è®¡çš„æŸ±çŠ¶å›¾ã€‚é€šå¸¸ï¼Œä½ å¯ä»¥é€šè¿‡è®¡ç®—å‡å€¼å“åº”çš„[æ ‡å‡†è¯¯å·®](https://oreil.ly/oSt6U)ï¼Œç„¶åç”¨å®ƒæ¥æ„å»ºè¿™ä¸ªå‡å€¼å“åº”çš„
    CIã€‚
- en: Bootstrap resampling
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Bootstrap é‡æŠ½æ ·
- en: One way you can estimate the standard error and produce CIs is through bootstrap
    resampling. Broadly speaking, bootstrapping approximates the difference between
    the true and sample data distributions using the difference between the data and
    *resampled* data distributions. It generates variants of the dataset at hand (or
    parameters estimated from it), hoping that these variants can give intuition about
    the uncertainty in the data-generating process and the parameters of that process.
    For a code walkthrough of implementing bootstrap in scikit-learn, see [this notebook](https://oreil.ly/n0wi7).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥é€šè¿‡è‡ªåŠ©é‡æŠ½æ ·ï¼ˆbootstrap resamplingï¼‰æ¥ä¼°è®¡æ ‡å‡†è¯¯å·®å¹¶ç”Ÿæˆç½®ä¿¡åŒºé—´ã€‚å¹¿ä¹‰æ¥è¯´ï¼Œbootstrapping ä½¿ç”¨æ•°æ®ä¸*é‡æŠ½æ ·*æ•°æ®åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚æ¥è¿‘ä¼¼çœŸå®æ•°æ®ä¸æ ·æœ¬æ•°æ®åˆ†å¸ƒçš„å·®å¼‚ã€‚å®ƒç”Ÿæˆæ‰‹å¤´æ•°æ®é›†ï¼ˆæˆ–ä»ä¸­ä¼°è®¡çš„å‚æ•°ï¼‰çš„å˜ä½“ï¼Œå¸Œæœ›è¿™äº›å˜ä½“èƒ½è®©æˆ‘ä»¬å¯¹æ•°æ®ç”Ÿæˆè¿‡ç¨‹åŠå…¶å‚æ•°çš„ä¸ç¡®å®šæ€§æœ‰ç›´è§‚çš„äº†è§£ã€‚è¦åœ¨
    scikit-learn ä¸­å®ç° bootstrap çš„ä»£ç æ¼”ç¤ºï¼Œè¯·å‚è§[è¿™ä¸ªç¬”è®°æœ¬](https://oreil.ly/n0wi7)ã€‚
- en: 'Bootstrap resampling has three main variants. Letâ€™s look at them in a supervised
    model setting, where the observed dataset *D* is composed of an input feature
    matrix *X* and an output feature vector *y*:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Bootstrap é‡æŠ½æ ·æœ‰ä¸‰ä¸ªä¸»è¦å˜ä½“ã€‚è®©æˆ‘ä»¬åœ¨ç›‘ç£æ¨¡å‹è®¾ç½®ä¸­çœ‹çœ‹å®ƒä»¬ï¼Œè§‚å¯Ÿè§‚å¯Ÿåˆ°çš„æ•°æ®é›†*D*ç”±è¾“å…¥ç‰¹å¾çŸ©é˜µ*X*å’Œè¾“å‡ºç‰¹å¾å‘é‡*y*ç»„æˆï¼š
- en: Nonparametric bootstrap
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: éå‚æ•° bootstrap
- en: You directly sample from the observed dataset *D*, perhaps thousands of times,
    to build your variant datasets. Sampling is generally done *with replacement*,
    i.e., one data point can be picked multiple times.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ç›´æ¥ä»è§‚å¯Ÿåˆ°çš„æ•°æ®é›†*D*ä¸­è¿›è¡Œæ ·æœ¬é‡‡æ ·ï¼Œå¯èƒ½è¦é‡å¤æˆåƒä¸Šä¸‡æ¬¡ï¼Œä»¥æ„å»ºä½ çš„å˜ä½“æ•°æ®é›†ã€‚é‡‡æ ·é€šå¸¸æ˜¯*æœ‰æ”¾å›*çš„ï¼Œå³å¯ä»¥å¤šæ¬¡é€‰å–åŒä¸€ä¸ªæ•°æ®ç‚¹ã€‚
- en: Parametric bootstrap
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•° bootstrap
- en: 'You start with a parametric model to fit the data: <math alttext="y equals
    f left-parenthesis upper X semicolon theta right-parenthesis plus epsilon"><mrow><mi>y</mi>
    <mo>=</mo> <mi>f</mi> <mo>(</mo> <mi>X</mi> <mo>;</mo> <mi>Î¸</mi> <mo>)</mo> <mo>+</mo>
    <mi>Ïµ</mi></mrow></math> , with <math alttext="epsilon"><mi>Ïµ</mi></math> being
    a vector of random errors. Then you use parameter estimates <math alttext="ModifyingAbove
    theta With caret"><mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover></math> (which
    are a function of data *D*) as proxies of the true parameters <math alttext="theta
    Superscript asterisk"><msup><mi>Î¸</mi> <mo>*</mo></msup></math> to generate a
    large number of datasets from the parametric model <math alttext="y Subscript
    r Baseline equals f left-parenthesis upper X semicolon ModifyingAbove theta With
    caret right-parenthesis plus upper P left-parenthesis ModifyingAbove epsilon With
    caret right-parenthesis"><mrow><msub><mi>y</mi> <mi>r</mi></msub> <mo>=</mo> <mi>f</mi>
    <mrow><mo>(</mo> <mi>X</mi> <mo>;</mo> <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover>
    <mo>)</mo></mrow> <mo>+</mo> <mi>P</mi> <mrow><mo>(</mo> <mover accent="true"><mi>Ïµ</mi>
    <mo>^</mo></mover> <mo>)</mo></mrow></mrow></math> , where <math alttext="ModifyingAbove
    epsilon With caret equals y minus f left-parenthesis upper X semicolon ModifyingAbove
    theta With caret right-parenthesis"><mrow><mover accent="true"><mi>Ïµ</mi> <mo>^</mo></mover>
    <mo>=</mo> <mi>y</mi> <mo>-</mo> <mi>f</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>;</mo>
    <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mo>)</mo></mrow></mrow></math>
    is the fitted residual vector, and *P* denotes a permutation. You then estimate
    <math alttext="ModifyingAbove theta With caret"><mover accent="true"><mi>Î¸</mi>
    <mo>^</mo></mover></math> for each of these new datasets.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨ä»å‚æ•°æ¨¡å‹å¼€å§‹æ‹Ÿåˆæ•°æ®ï¼š<math alttext="y equals f left-parenthesis upper X semicolon theta
    right-parenthesis plus epsilon"><mrow><mi>y</mi> <mo>=</mo> <mi>f</mi> <mo>(</mo>
    <mi>X</mi> <mo>;</mo> <mi>Î¸</mi> <mo>)</mo> <mo>+</mo> <mi>Ïµ</mi></mrow></math>
    ï¼Œå…¶ä¸­ <math alttext="epsilon"><mi>Ïµ</mi></math> æ˜¯ä¸€ä¸ªéšæœºè¯¯å·®å‘é‡ã€‚ç„¶åï¼Œæ‚¨ä½¿ç”¨å‚æ•°ä¼°è®¡ <math alttext="ModifyingAbove
    theta With caret"><mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover></math>ï¼ˆè¿™äº›æ˜¯æ•°æ®*D*çš„å‡½æ•°ï¼‰ä½œä¸ºçœŸå®å‚æ•°
    <math alttext="theta Superscript asterisk"><msup><mi>Î¸</mi> <mo>*</mo></msup></math>
    çš„ä»£ç†ï¼Œä»å‚æ•°æ¨¡å‹ <math alttext="y Subscript r Baseline equals f left-parenthesis upper
    X semicolon ModifyingAbove theta With caret right-parenthesis plus upper P left-parenthesis
    ModifyingAbove epsilon With caret right-parenthesis"><mrow><msub><mi>y</mi> <mi>r</mi></msub>
    <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>;</mo> <mover accent="true"><mi>Î¸</mi>
    <mo>^</mo></mover> <mo>)</mo></mrow> <mo>+</mo> <mi>P</mi> <mrow><mo>(</mo> <mover
    accent="true"><mi>Ïµ</mi> <mo>^</mo></mover> <mo>)</mo></mrow></mrow></math> ç”Ÿæˆå¤§é‡æ•°æ®é›†ï¼Œå…¶ä¸­
    <math alttext="ModifyingAbove epsilon With caret equals y minus f left-parenthesis
    upper X semicolon ModifyingAbove theta With caret right-parenthesis"><mrow><mover
    accent="true"><mi>Ïµ</mi> <mo>^</mo></mover> <mo>=</mo> <mi>y</mi> <mo>-</mo> <mi>f</mi>
    <mrow><mo>(</mo> <mi>X</mi> <mo>;</mo> <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover>
    <mo>)</mo></mrow></mrow></math> æ˜¯æ‹Ÿåˆæ®‹å·®å‘é‡ï¼Œ*P*è¡¨ç¤ºç½®æ¢ã€‚ç„¶åï¼Œæ‚¨ä¸ºæ¯ä¸ªæ–°æ•°æ®é›†ä¼°è®¡ <math alttext="ModifyingAbove
    theta With caret"><mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover></math>ã€‚
- en: Wild bootstrap
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: é‡ç”Ÿè‡ªä¸¾
- en: 'What if the amount of random variance in the data is not constant throughout?
    This is a general version of the parametric bootstrap where you still use <math
    alttext="ModifyingAbove theta With caret"><mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover></math>
    to generate new datasets, but instead of permuting the residuals, you *perturb*
    them: <math alttext="y Subscript r Baseline equals left-parenthesis f left-parenthesis
    upper X semicolon ModifyingAbove theta With caret right-parenthesis plus ModifyingAbove
    epsilon With caret v"><mrow><msub><mi>y</mi> <mi>r</mi></msub> <mrow><mo>=</mo>
    <mo>(</mo> <mi>f</mi></mrow> <mrow><mo>(</mo> <mi>X</mi> <mo>;</mo> <mover accent="true"><mi>Î¸</mi>
    <mo>^</mo></mover> <mo>)</mo></mrow> <mo>+</mo> <mover accent="true"><mi>Ïµ</mi>
    <mo>^</mo></mover> <mi>v</mi></mrow></math> , where *v* is a vector of independent
    draws from a random variable with mean 0 and variance 1.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ•°æ®ä¸­çš„éšæœºå˜å¼‚é‡å¹¶éå§‹ç»ˆä¿æŒæ’å®šï¼Œé‚£ä¹ˆè¿™æ˜¯å‚æ•°è‡ªä¸¾çš„ä¸€èˆ¬ç‰ˆæœ¬ï¼Œå…¶ä¸­æ‚¨ä»ç„¶ä½¿ç”¨ <math alttext="ModifyingAbove theta
    With caret"><mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover></math> ç”Ÿæˆæ–°æ•°æ®é›†ï¼Œä½†ä¸æ˜¯ç½®æ¢æ®‹å·®ï¼Œè€Œæ˜¯*æ‰°åŠ¨*å®ƒä»¬ï¼š<math
    alttext="y Subscript r Baseline equals left-parenthesis f left-parenthesis upper
    X semicolon ModifyingAbove theta With caret right-parenthesis plus ModifyingAbove
    epsilon With caret v"><mrow><msub><mi>y</mi> <mi>r</mi></msub> <mrow><mo>=</mo>
    <mo>(</mo> <mi>f</mi></mrow> <mrow><mo>(</mo> <mi>X</mi> <mo>;</mo> <mover accent="true"><mi>Î¸</mi>
    <mo>^</mo></mover> <mo>)</mo></mrow> <mo>+</mo> <mover accent="true"><mi>Ïµ</mi>
    <mo>^</mo></mover> <mi>v</mi></mrow></math> ï¼Œå…¶ä¸­*v*æ˜¯ä¸€ä¸ªå‡å€¼ä¸º0ã€æ–¹å·®ä¸º1çš„éšæœºå˜é‡çš„ç‹¬ç«‹æŠ½æ ·å‘é‡ã€‚
- en: Letâ€™s look at an example of using bootstrap confidence intervals in regression
    models. For simplicity, weâ€™ll take a nonparametric (i.e., sampling directly from
    the dataset) approach. Letâ€™s sample one thousand subsets of the data of a given
    size, fit a linear regression model to each sample, then record intercepts and
    coefficients of each regression model. From these you can get the 95% CIs by obtaining
    the 97.5% and 2.5% percentiles of the intercepts and coefficients. Using intervals
    based on percentiles also means not making assumptions about the underlying data
    distribution. Now you can estimate the uncertainty of these model predictions.
    Based on the [standard assumptions for linear regression](https://oreil.ly/mx0yT),
    you can approximate the variance of a value of the outcome given input feature
    values using the prediction residuals. From this variance, you can calculate the
    standard error, a measure of how well youâ€™re estimating *y*.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªä½¿ç”¨è‡ªåŠ©æ³•ç½®ä¿¡åŒºé—´åœ¨å›å½’æ¨¡å‹ä¸­çš„ä¾‹å­ã€‚ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨éå‚æ•°æ–¹æ³•ï¼ˆå³ç›´æ¥ä»æ•°æ®é›†ä¸­æŠ½æ ·ï¼‰ã€‚è®©æˆ‘ä»¬ä»ç»™å®šå¤§å°çš„æ•°æ®ä¸­æŠ½æ ·ä¸€åƒä¸ªå­é›†ï¼Œå¯¹æ¯ä¸ªæ ·æœ¬æ‹Ÿåˆçº¿æ€§å›å½’æ¨¡å‹ï¼Œç„¶åè®°å½•æ¯ä¸ªå›å½’æ¨¡å‹çš„æˆªè·å’Œç³»æ•°ã€‚ä»è¿™äº›æ•°æ®ä¸­ï¼Œæ‚¨å¯ä»¥é€šè¿‡è·å–æˆªè·å’Œç³»æ•°çš„97.5%å’Œ2.5%åˆ†ä½æ•°æ¥è·å¾—95%çš„ç½®ä¿¡åŒºé—´ã€‚ä½¿ç”¨åŸºäºåˆ†ä½æ•°çš„åŒºé—´è¿˜æ„å‘³ç€ä¸å¯¹åº•å±‚æ•°æ®åˆ†å¸ƒåšå‡ºå‡è®¾ã€‚ç°åœ¨ï¼Œæ‚¨å¯ä»¥ä¼°è®¡è¿™äº›æ¨¡å‹é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚æ ¹æ®[çº¿æ€§å›å½’çš„æ ‡å‡†å‡è®¾](https://oreil.ly/mx0yT)ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨é¢„æµ‹æ®‹å·®æ¥è¿‘ä¼¼ç»™å®šè¾“å…¥ç‰¹å¾å€¼çš„ç»“æœå€¼çš„æ–¹å·®ã€‚ä»è¿™ä¸ªæ–¹å·®ä¸­ï¼Œæ‚¨å¯ä»¥è®¡ç®—æ ‡å‡†è¯¯å·®ï¼Œè¿™æ˜¯è¡¡é‡æ‚¨å¯¹*y*ä¼°è®¡ç²¾åº¦çš„ä¸€ç§æŒ‡æ ‡ã€‚
- en: <math><mrow><msup><mi>Ïƒ</mi> <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><msubsup><mo>âˆ‘</mo>
    <mi>i</mi> <mi>N</mi></msubsup> <msup><mrow><mo>(</mo><msub><mi>y</mi> <mi>d</mi></msub>
    <mo>-</mo><msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover> <mi>d</mi></msub>
    <mo>)</mo></mrow> <mn>2</mn></msup></mrow> <mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow></mfrac>
    <mo>,</mo></mrow></math><math><mrow><mtext>Var</mtext> <mrow><mo>(</mo> <mover
    accent="true"><mi>Î±</mi> <mo>^</mo></mover> <mo>+</mo> <mover accent="true"><mi>Î²</mi>
    <mo>^</mo></mover> <msub><mi>x</mi> <mi>d</mi></msub> <mo>)</mo></mrow> <mo>=</mo>
    <mtext>Var</mtext> <mrow><mo>(</mo> <mover accent="true"><mi>Î±</mi> <mo>^</mo></mover>
    <mo>)</mo></mrow> <mo>+</mo> <mtext>Var</mtext> <mrow><mo>(</mo> <mover accent="true"><mi>Î²</mi>
    <mo>^</mo></mover> <mo>)</mo></mrow> <msubsup><mi>x</mi> <mi>d</mi> <mn>2</mn></msubsup>
    <mo>+</mo> <mn>2</mn> <msub><mi>x</mi> <mi>d</mi></msub> <mtext>Cov</mtext> <mrow><mo>(</mo>
    <mover accent="true"><mi>Î±</mi> <mo>^</mo></mover> <mo>,</mo> <mover accent="true"><mi>Î²</mi>
    <mo>^</mo></mover> <mo>)</mo></mrow> <mo>,</mo></mrow></math><math><mrow><mtext>Var</mtext>
    <mrow><mo>(</mo> <mover accent="true"><mi>Î±</mi> <mo>^</mo></mover> <mo>+</mo>
    <mover accent="true"><mi>Î²</mi> <mo>^</mo></mover> <msub><mi>x</mi> <mi>d</mi></msub>
    <mo>)</mo></mrow> <mo>=</mo> <msup><mi>Ïƒ</mi> <mn>2</mn></msup> <mfenced close=")"
    open="(" separators=""><mfrac><mn>1</mn> <mi>m</mi></mfrac> <mo>+</mo> <mfrac><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>d</mi></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>Â¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mrow><mo>âˆ‘</mo><msup><mrow><mo>(</mo><msub><mi>x</mi> <mi>i</mi></msub>
    <mo>-</mo><mover accent="true"><mi>x</mi> <mo>Â¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></mfrac></mfenced> <mo>,</mo></mrow></math><math><mrow><msub><mi>s</mi>
    <msub><mi>Î¼</mi> <mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></msub></msub> <mo>=</mo>
    <msqrt><mrow><mtext>Var</mtext> <mo>(</mo> <mover accent="true"><mi>Î±</mi> <mo>^</mo></mover>
    <mo>+</mo> <mover accent="true"><mi>Î²</mi> <mo>^</mo></mover> <msub><mi>x</mi>
    <mi>d</mi></msub> <mo>)</mo></mrow></msqrt> <mo>,</mo></mrow></math><math><mrow><mi>C</mi>
    <mi>I</mi> <mo>=</mo> <mo>[</mo> <msub><mi>Î¼</mi> <mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></msub>
    <mo>-</mo> <msub><mi>t</mi> <mrow><mn>1</mn><mo>-</mo><mi>Î±</mi><mo>/</mo><mn>2</mn><mo>,</mo><mi>n</mi><mo>-</mo><mn>2</mn></mrow></msub>
    <msub><mi>s</mi> <msub><mi>Î¼</mi> <mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></msub></msub>
    <mo>,</mo> <msub><mi>Î¼</mi> <mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></msub>
    <mo>+</mo> <msub><mi>t</mi> <mrow><mn>1</mn><mo>-</mo><mi>Î±</mi><mo>/</mo><mn>2</mn><mo>,</mo><mi>n</mi><mo>-</mo><mn>2</mn></mrow></msub>
    <msub><mi>s</mi> <msub><mi>Î¼</mi> <mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></msub></msub>
    <mo>]</mo> <mo>.</mo></mrow></math>
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><msup><mi>Ïƒ</mi> <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><msubsup><mo>âˆ‘</mo>
    <mi>i</mi> <mi>N</mi></msubsup> <msup><mrow><mo>(</mo><msub><mi>y</mi> <mi>d</mi></msub>
    <mo>-</mo><msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover> <mi>d</mi></msub>
    <mo>)</mo></mrow> <mn>2</mn></msup></mrow> <mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow></mfrac>
    <mo>,</mo></mrow></math><math><mrow><mtext>Var</mtext> <mrow><mo>(</mo> <mover
    accent="true"><mi>Î±</mi> <mo>^</mo></mover> <mo>+</mo> <mover accent="true"><mi>Î²</mi>
    <mo>^</mo></mover> <msub><mi>x</mi> <mi>d</mi></msub> <mo>)</mo></mrow> <mo>=</mo>
    <mtext>Var</mtext> <mrow><mo>(</mo> <mover accent="true"><mi>Î±</mi> <mo>^</mo></mover>
    <mo>)</mo></mrow> <mo>+</mo> <mtext>Var</mtext> <mrow><mo>(</mo> <mover accent="true"><mi>Î²</mi>
    <mo>^</mo></mover> <mo>)</mo></mrow> <msubsup><mi>x</mi> <mi>d</mi> <mn>2</mn></msubsup>
    <mo>+</mo> <mn>2</mn> <msub><mi>x</mi> <mi>d</mi></msub> <mtext>Cov</mtext> <mrow><mo>(</mo>
    <mover accent="true"><mi>Î±</mi> <mo>^</mo></mover> <mo>,</mo> <mover accent="true"><mi>Î²</mi>
    <mo>^</mo></mover> <mo>)</mo></mrow> <mo>,</mo></mrow></math><math><mrow><mtext>Var</mtext>
    <mrow><mo>(</mo> <mover accent="true"><mi>Î±</mi> <mo>^</mo></mover> <mo>+</mo>
    <mover accent="true"><mi>Î²</mi> <mo>^</mo></mover> <msub><mi>x</mi> <mi>d</mi></msub>
    <mo>)</mo></mrow> <mo>=</mo> <msup><mi>Ïƒ</mi> <mn>2</mn></msup> <mfenced close=")"
    open="(" separators=""><mfrac><mn>1</mn> <mi>m</mi></mfrac> <mo>+</mo> <mfrac><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>d</mi></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>Â¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mrow><mo>âˆ‘</mo><msup><mrow><mo>(</mo><msub><mi>x</mi> <mi>i</mi></msub>
    <mo>-</mo><mover accent="true"><mi>x</mi> <mo>Â¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></mfrac></mfenced> <mo>,</mo></mrow></math><math><mrow><msub><mi>s</mi>
    <msub><mi>Î¼</mi> <mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></msub></msub> <mo>=</mo>
    <msqrt><mrow><mtext>Var</mtext> <mo>(</mo> <mover accent="true"><mi>Î±</mi> <mo>^</mo></mover>
    <mo>+</mo> <mover accent="true"><mi>Î²</mi> <mo>^</mo></mover> <msub><mi>x</mi>
    <mi>d</mi></msub> <mo>)</mo></mrow></msqrt> <mo>,</mo></mrow></math><math><mrow><mi>C</mi>
    <mi>I</mi> <mo>=</mo> <mo>[</mo> <msub><mi>Î¼</mi> <mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></msub>
    <mo>-</mo> <msub><mi>t</mi> <mrow><mn>1</mn><mo>-</mo><mi>Î±</mi><mo>/</mo><mn>2</mn><mo>,</mo><mi>n</mi><mo>-</mo><mn>2</mn></mrow></msub>
    <msub><mi>s</mi> <msub><mi>Î¼</mi> <mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></msub></msub>
    <mo>,</mo> <msub><mi>Î¼</mi> <mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></msub>
    <mo>+</mo> <msub><mi>t</mi> <mrow><mn>1</mn><mo>-</mo><mi>Î±</mi><mo>/</mo><mn>2</mn><mo>,</mo><mi>n</mi><mo>-</mo><mn>2</mn></mrow></msub>
    <msub><mi>s</mi> <msub><mi>Î¼</mi> <mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></msub></msub>
    <mo>]</mo> <mo>.</mo></mrow></math>
- en: The resulting CI is great, but this only accounts for drift in the *mean* response
    of *Y*. If you want to get intervals for all possible values of *Y* for a given
    *X* value, you need to calculate the *prediction interval*. The derivation of
    the prediction interval is similar to that of the CI, except you include the variance
    of our dependent variable *Y* when calculating the standard error, leading to
    wider intervals.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„CIå¾ˆå¥½ï¼Œä½†è¿™åªæ¶µç›–äº†*Y*çš„*å¹³å‡*å“åº”çš„æ¼‚ç§»ã€‚å¦‚æœæ‚¨æƒ³è¦ä¸ºç»™å®š*X*å€¼çš„æ‰€æœ‰å¯èƒ½*Y*å€¼è®¡ç®—åŒºé—´ï¼Œæ‚¨éœ€è¦è®¡ç®—*é¢„æµ‹åŒºé—´*ã€‚é¢„æµ‹åŒºé—´çš„æ¨å¯¼ä¸CIçš„ç±»ä¼¼ï¼Œåªæ˜¯åœ¨è®¡ç®—æ ‡å‡†è¯¯å·®æ—¶åŒ…æ‹¬äº†æˆ‘ä»¬çš„å› å˜é‡*Y*çš„æ–¹å·®ï¼Œå¯¼è‡´åŒºé—´æ›´å®½ã€‚
- en: Are you certain I can trust you?
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ‚¨ç¡®å®šæˆ‘èƒ½ç›¸ä¿¡æ‚¨å—ï¼Ÿ
- en: Calculating uncertainty estimates such as CIs for trust metrics is an obvious
    way to incorporate uncertainty quantification into trustworthy ML pipelines. This
    is useful extra information. For example, suppose the disparate impact of binary
    outcomes from an ML model for a hiring use case is 1.1. While at face value the
    model seems unbiased, different widths of the 95% CI may lead to different conclusions.
    A CI of [1.08, 1.12] would reaffirm the conclusion of unbiasedness by the point
    estimate of 1.1. On the other hand, a much wider CI, say [0.9, 1.3], would diminish
    the trust in the conclusion. Based on feedback from the domain experts with whom
    you are collaborating, this may prompt you to revisit the data collection process
    to find out whether or not the 1.1 value is simply an artifact of the specific
    dataset analyzed.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—è¯¸å¦‚ä¿¡ä»»åº¦åº¦é‡çš„CIç­‰ä¸ç¡®å®šæ€§ä¼°è®¡æ˜¯å°†ä¸ç¡®å®šæ€§é‡åŒ–çº³å…¥å¯ä¿¡MLç®¡é“çš„ä¸€ç§æ˜æ˜¾æ–¹å¼ã€‚è¿™æ˜¯æœ‰ç”¨çš„é¢å¤–ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå‡è®¾ç”¨äºæ‹›è˜ç”¨ä¾‹çš„MLæ¨¡å‹çš„äºŒå…ƒç»“æœçš„ä¸å¹³ç­‰å½±å“ä¸º1.1ã€‚å°½ç®¡è¡¨é¢ä¸Šçœ‹æ¥ï¼Œæ¨¡å‹ä¼¼ä¹æ²¡æœ‰åå·®ï¼Œä½†95%çš„CIçš„ä¸åŒå®½åº¦å¯èƒ½å¯¼è‡´ä¸åŒçš„ç»“è®ºã€‚CIä¸º[1.08,
    1.12]å°†é€šè¿‡1.1çš„ç‚¹ä¼°è®¡é‡æ–°ç¡®è®¤æ— åçš„ç»“è®ºã€‚å¦ä¸€æ–¹é¢ï¼Œæ›´å®½çš„CIï¼Œæ¯”å¦‚[0.9, 1.3]ï¼Œå¯èƒ½ä¼šå‡å¼±å¯¹ç»“è®ºçš„ä¿¡ä»»ã€‚æ ¹æ®ä¸æ‚¨åˆä½œçš„é¢†åŸŸä¸“å®¶çš„åé¦ˆï¼Œè¿™å¯èƒ½ä¿ƒä½¿æ‚¨é‡æ–°å®¡è§†æ•°æ®æ”¶é›†è¿‡ç¨‹ï¼Œä»¥ç¡®å®š1.1å€¼æ˜¯å¦ä»…ä»…æ˜¯ç‰¹å®šæ•°æ®é›†åˆ†æçš„ç»“æœã€‚
- en: 'Part II: Implementation Challenges'
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬äºŒéƒ¨åˆ†ï¼šå®æ–½æŒ‘æˆ˜
- en: Now that you know about the technical factors beyond aspects of trust that may
    be relevant for your efforts to build a trustworthy ML pipeline, itâ€™s time to
    shift gears. Letâ€™s talk about the systemic considerations that go into designing
    trustworthy ML systems. Outside strict methodological research settings, ML work
    does not happen in a vacuum. This cannot be truer than in the typical modern tech
    company setting. As a part of well-defined product initiatives, the ML development
    team *needs* to interact with people outside the team. Depending on these stakeholdersâ€™
    familiarity with ML and trustworthy ML concepts, you might face one or more challenges
    you need to navigate to make progress on a product development journey that effectively
    incorporates aspects of trust.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å·²äº†è§£è¶…è¶Šä¿¡ä»»æ–¹é¢çš„æŠ€æœ¯å› ç´ å¯èƒ½å¯¹å»ºç«‹å¯ä¿¡MLç®¡é“çš„åŠªåŠ›æœ‰æ‰€å¸®åŠ©ï¼Œç°åœ¨æ˜¯è½¬å˜æ€è·¯çš„æ—¶å€™äº†ã€‚è®©æˆ‘ä»¬è®¨è®ºè®¾è®¡å¯ä¿¡MLç³»ç»Ÿæ‰€éœ€çš„ç³»ç»Ÿè€ƒè™‘å› ç´ ã€‚åœ¨ä¸¥æ ¼çš„æ–¹æ³•è®ºç ”ç©¶è®¾ç½®ä¹‹å¤–ï¼ŒMLå·¥ä½œå¹¶éåœ¨çœŸç©ºä¸­è¿›è¡Œã€‚è¿™åœ¨å…¸å‹çš„ç°ä»£ç§‘æŠ€å…¬å¸è®¾ç½®ä¸­æ›´æ˜¯å¦‚æ­¤ã€‚ä½œä¸ºæ˜ç¡®å®šä¹‰çš„äº§å“å€¡è®®çš„ä¸€éƒ¨åˆ†ï¼ŒMLå¼€å‘å›¢é˜Ÿ*éœ€è¦*ä¸å›¢é˜Ÿå¤–çš„äººå‘˜è¿›è¡Œäº’åŠ¨ã€‚æ ¹æ®è¿™äº›åˆ©ç›Šç›¸å…³è€…å¯¹MLå’Œå¯ä¿¡MLæ¦‚å¿µçš„ç†Ÿæ‚‰ç¨‹åº¦ï¼Œæ‚¨å¯èƒ½ä¼šé¢å¯¹ä¸€ä¸ªæˆ–å¤šä¸ªæŒ‘æˆ˜ï¼Œæ‚¨éœ€è¦è§£å†³è¿™äº›æŒ‘æˆ˜ä»¥åœ¨æœ‰æ•ˆæ•´åˆä¿¡ä»»æ–¹é¢çš„äº§å“å¼€å‘æ—…ç¨‹ä¸­å–å¾—è¿›å±•ã€‚
- en: Motivating Stakeholders to Develop Trustworthy ML Systems
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¿€åŠ±åˆ©ç›Šç›¸å…³è€…å¼€å‘å¯ä¿¡MLç³»ç»Ÿ
- en: 'As you progress along the journey of applying trustworthy ML principles in
    business settings, chances are that you will face questions and comments from
    stakeholders beyond your team that fall along these lines:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åº”ç”¨å¯ä¿¡MLåŸåˆ™äºå•†ä¸šç¯å¢ƒä¸­çš„æ—…ç¨‹ä¸­ï¼Œéšç€æ‚¨çš„è¿›å±•ï¼Œå¾ˆå¯èƒ½ä¼šé¢å¯¹æ¥è‡ªå›¢é˜Ÿä»¥å¤–çš„åˆ©ç›Šç›¸å…³è€…çš„é—®é¢˜å’Œè¯„è®ºï¼Œå†…å®¹å¤§è‡´å¦‚ä¸‹ï¼š
- en: Why do we need trustworthy methods in the first place?
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆéœ€è¦å¯ä¿¡çš„æ–¹æ³•ï¼Ÿ
- en: Your model is already optimized for best performance.Wonâ€™t placing these extra
    conditions on the model degrade its accuracy, area under the curve (AUC), or other
    performance metrics?
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨çš„æ¨¡å‹å·²ç»ä¼˜åŒ–ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚å°†è¿™äº›é¢å¤–æ¡ä»¶æ”¾åœ¨æ¨¡å‹ä¸Šæ˜¯å¦ä¼šé™ä½å…¶å‡†ç¡®æ€§ã€æ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰æˆ–å…¶ä»–æ€§èƒ½æŒ‡æ ‡ï¼Ÿ
- en: If you want a fair ML model, just donâ€™t use data on sensitive features!
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨å¸Œæœ›å¾—åˆ°ä¸€ä¸ªå…¬å¹³çš„MLæ¨¡å‹ï¼Œå°±ä¸è¦ä½¿ç”¨æ¶‰åŠæ•æ„Ÿç‰¹å¾çš„æ•°æ®ï¼
- en: I donâ€™t know if you have the budget for all this extra work.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä¸çŸ¥é“æ‚¨æ˜¯å¦æœ‰é¢„ç®—æ¥å®Œæˆæ‰€æœ‰è¿™äº›é¢å¤–å·¥ä½œã€‚
- en: 'There are two lines of reasoning for adding one or more trust elements into
    an applied ML workflow: (a) debt management and (b) risk management. When these
    two things are done properly, the benefits of trustworthy ML development far outweigh
    the perceived cost of â€œextraâ€ work.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: æ·»åŠ ä¸€ä¸ªæˆ–å¤šä¸ªä¿¡ä»»å…ƒç´ åˆ°åº”ç”¨çš„æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æœ‰ä¸¤ç§æ¨ç†çº¿ç´¢ï¼š(a) å€ºåŠ¡ç®¡ç†å’Œ (b) é£é™©ç®¡ç†ã€‚å½“è¿™ä¸¤ä»¶äº‹åšå¾—æ°å½“æ—¶ï¼Œå¯ä¿¡ä»»çš„æœºå™¨å­¦ä¹ å¼€å‘å¸¦æ¥çš„å¥½å¤„è¿œè¿œè¶…è¿‡â€œé¢å¤–â€å·¥ä½œçš„æ„ŸçŸ¥æˆæœ¬ã€‚
- en: Debt management
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å€ºåŠ¡ç®¡ç†
- en: Ward Cunningham proposed the term *technical debt* in 1992 to represent the
    hidden long-term costs to software systems incurred by perpetual fast development
    cycles.^([11](ch07.html#idm45621831208160)) As the creator of [Agile](https://oreil.ly/j2VFi),
    Cunningham knew a thing or two about good software development. He realized that
    perpetually building things and adding new functionalities does not come cheap.
    If not channeled properly, a fast-paced development culture creates redundancies
    and dependencies that make the underlying product difficult to troubleshoot and
    maintain even as it matures in its capabilities. Debt management work such as
    refactoring code to minimize dependencies, cleaning up duplicate code, and writing
    proper documentation does cost some developer cycles. However, it protects the
    product against the potentially higher long-term costs of running a brittle, patched-together
    system.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 1992å¹´ï¼Œæ²ƒå¾·Â·åå®å®‰æå‡ºäº†æœ¯è¯­*æŠ€æœ¯å€ºåŠ¡*ï¼Œç”¨äºè¡¨ç¤ºç”±äºæ°¸ä¹…å¿«é€Ÿå¼€å‘å‘¨æœŸè€Œç»™è½¯ä»¶ç³»ç»Ÿå¸¦æ¥çš„éšè—é•¿æœŸæˆæœ¬^([11](ch07.html#idm45621831208160))ã€‚ä½œä¸º[æ•æ·å¼€å‘](https://oreil.ly/j2VFi)çš„åˆ›å§‹äººï¼Œåå®å®‰å¯¹è‰¯å¥½çš„è½¯ä»¶å¼€å‘æœ‰ä¸€äº›äº†è§£ã€‚ä»–æ„è¯†åˆ°ï¼Œæ°¸è¿œåœ°æ„å»ºå’Œæ·»åŠ æ–°åŠŸèƒ½å¹¶ä¸ä¾¿å®œã€‚å¦‚æœä¸é€‚å½“åœ°å¼•å¯¼ï¼Œå¿«èŠ‚å¥çš„å¼€å‘æ–‡åŒ–ä¼šé€ æˆå†—ä½™å’Œä¾èµ–ï¼Œä½¿åŸºç¡€äº§å“åœ¨å…¶èƒ½åŠ›ä¸æ–­å¢å¼ºçš„åŒæ—¶éš¾ä»¥æ’é™¤æ•…éšœå’Œç»´æŠ¤ã€‚åƒé‡æ„ä»£ç ä»¥æœ€å°åŒ–ä¾èµ–ã€æ¸…ç†é‡å¤ä»£ç å’Œæ’°å†™é€‚å½“æ–‡æ¡£ç­‰å€ºåŠ¡ç®¡ç†å·¥ä½œç¡®å®éœ€è¦ä¸€äº›å¼€å‘è€…å‘¨æœŸã€‚ç„¶è€Œï¼Œè¿™äº›å·¥ä½œä¿æŠ¤äº§å“å…å—è¿è¡Œè„†å¼±ã€æ‹¼å‡‘åœ¨ä¸€èµ·çš„ç³»ç»Ÿå¯èƒ½å¯¼è‡´çš„æ›´é«˜é•¿æœŸæˆæœ¬çš„å½±å“ã€‚
- en: In addition to technical debt, ML systems may need to contend with some unique
    and more systematic maintenance problems. Examples of ML-specific technical debt
    include dependencies on external data with poor documentation and/or of dubious
    quality, data dependencies on black box ML models, and reproducibility concerns
    due to randomness during model training and inference (especially when the outputs
    of one model are the inputs of another). Real ML systems have a relatively small
    amount of code dedicated to just model training and inference. These code components
    need a complex infrastructure to properly do their job, incurring additional trust
    debt. Adding trust elements to this system means creating even more dependencies
    and interactions that go beyond the ML infrastructure (see [FigureÂ 7-2](#img-system)).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†æŠ€æœ¯å€ºåŠ¡ï¼Œæœºå™¨å­¦ä¹ ç³»ç»Ÿå¯èƒ½è¿˜éœ€è¦å¤„ç†ä¸€äº›ç‹¬ç‰¹ä¸”æ›´ç³»ç»ŸåŒ–çš„ç»´æŠ¤é—®é¢˜ã€‚æœºå™¨å­¦ä¹ ç‰¹å®šæŠ€æœ¯å€ºåŠ¡çš„ä¾‹å­åŒ…æ‹¬ä¾èµ–äºæ–‡æ¡£è´¨é‡å·®å’Œ/æˆ–è´¨é‡å¯ç–‘çš„å¤–éƒ¨æ•°æ®ã€å¯¹é»‘ç›’æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ•°æ®ä¾èµ–ä»¥åŠç”±äºæ¨¡å‹è®­ç»ƒå’Œæ¨ç†æœŸé—´çš„éšæœºæ€§è€Œå¯¼è‡´çš„å¯é‡ç°æ€§é—®é¢˜ï¼ˆå°¤å…¶æ˜¯å½“ä¸€ä¸ªæ¨¡å‹çš„è¾“å‡ºæ˜¯å¦ä¸€ä¸ªæ¨¡å‹çš„è¾“å…¥æ—¶ï¼‰ã€‚çœŸå®çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿä»…æœ‰ç›¸å¯¹è¾ƒå°‘çš„ä»£ç ä¸“é—¨ç”¨äºæ¨¡å‹è®­ç»ƒå’Œæ¨ç†ã€‚è¿™äº›ä»£ç ç»„ä»¶éœ€è¦ä¸€ä¸ªå¤æ‚çš„åŸºç¡€è®¾æ–½æ¥æ­£ç¡®æ‰§è¡Œå…¶å·¥ä½œï¼Œä»è€Œäº§ç”Ÿé¢å¤–çš„ä¿¡ä»»å€ºåŠ¡ã€‚åœ¨è¿™ä¸ªç³»ç»Ÿä¸­æ·»åŠ ä¿¡ä»»å…ƒç´ æ„å‘³ç€åˆ›å»ºæ›´å¤šè¶…å‡ºæœºå™¨å­¦ä¹ åŸºç¡€è®¾æ–½èŒƒå›´çš„ä¾èµ–å’Œäº’åŠ¨ï¼ˆå‚è§[å›¾Â 7-2](#img-system)ï¼‰ã€‚
- en: Real ML systems are composed of many components above and beyond just data and
    code. The ML system itself is a part of a broader company-wide ecosystem of initiatives.
    Trust considerations (circles) are applicable to many components of the business,
    both inside and outside the ML system. Thus, to make ML systems trustworthy, these
    additional debts need the attention of the ML teamâ€”â€‹and the product team in general.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: çœŸå®çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿç”±è®¸å¤šè¶…å‡ºæ•°æ®å’Œä»£ç ä¹‹å¤–çš„ç»„ä»¶ç»„æˆã€‚æœºå™¨å­¦ä¹ ç³»ç»Ÿæœ¬èº«æ˜¯å…¬å¸èŒƒå›´å†…å„ç§å€¡è®®çš„ä¸€éƒ¨åˆ†ã€‚ä¿¡ä»»è€ƒè™‘ï¼ˆåœ†åœˆï¼‰é€‚ç”¨äºä¸šåŠ¡çš„è®¸å¤šç»„ä»¶ï¼Œæ— è®ºæ˜¯åœ¨æœºå™¨å­¦ä¹ ç³»ç»Ÿå†…éƒ¨è¿˜æ˜¯å¤–éƒ¨ã€‚å› æ­¤ï¼Œä¸ºäº†ä½¿æœºå™¨å­¦ä¹ ç³»ç»Ÿå¯ä¿¡ä»»ï¼Œè¿™äº›é¢å¤–çš„å€ºåŠ¡éœ€è¦æœºå™¨å­¦ä¹ å›¢é˜Ÿä»¥åŠæ•´ä½“äº§å“å›¢é˜Ÿçš„å…³æ³¨ã€‚
- en: '![ptml 0702](assets/ptml_0702.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0702](assets/ptml_0702.png)'
- en: Figure 7-2\. Technical and nontechnical components of a ML system, with those
    with potential trust considerations marked by circles
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 7-2\. æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„æŠ€æœ¯å’ŒéæŠ€æœ¯ç»„ä»¶ï¼Œå…¶ä¸­æœ‰æ½œåœ¨ä¿¡ä»»è€ƒè™‘çš„ç»„ä»¶æ ‡è®°ä¸ºåœ†åœˆ
- en: Risk management
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é£é™©ç®¡ç†
- en: 'The model risk management (MRM) framework has gained popularity in the financial
    sector as a best-practice rubric to ensure that data analytics projects meet regulatory
    goals and align with core institutional values *while* maintaining reproducible
    performance guarantees. Think of trustworthy ML practices as an enhanced form
    of MRM. Itâ€™s helpful to think about the evolution of an organizationâ€™s trustworthy
    ML capabilities in three stages:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é‡‘èé¢†åŸŸï¼Œæ¨¡å‹é£é™©ç®¡ç†ï¼ˆMRMï¼‰æ¡†æ¶å·²ç»å› å…¶ä½œä¸ºæœ€ä½³å®è·µè§„èŒƒï¼Œä»¥ç¡®ä¿æ•°æ®åˆ†æé¡¹ç›®è¾¾åˆ°ç›‘ç®¡ç›®æ ‡å¹¶ä¸æ ¸å¿ƒæœºæ„ä»·å€¼è§‚ä¿æŒä¸€è‡´çš„èƒ½åŠ›è€Œå—åˆ°æ¬¢è¿ã€‚å°†å€¼å¾—ä¿¡èµ–çš„æœºå™¨å­¦ä¹ å®è·µè§†ä¸ºMRMçš„å¢å¼ºå½¢å¼æ˜¯å¾ˆæœ‰å¸®åŠ©çš„ã€‚æœ‰åŠ©äºæ€è€ƒç»„ç»‡ä¿¡ä»»çš„æœºå™¨å­¦ä¹ èƒ½åŠ›çš„ä¸‰ä¸ªé˜¶æ®µçš„æ¼”å˜ï¼š
- en: '*Setting standards*'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '*è®¾å®šæ ‡å‡†*'
- en: The first stage includes setting formal processes and best practices for incorporating
    trust elements into ML workflows and product design.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªé˜¶æ®µåŒ…æ‹¬ä¸ºå°†ä¿¡ä»»å…ƒç´ çº³å…¥æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹å’Œäº§å“è®¾è®¡ä¸­åˆ¶å®šæ­£å¼æµç¨‹å’Œæœ€ä½³å®è·µã€‚
- en: '*Implementation*'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '*å®æ–½*'
- en: The second stage includes implementing the guidelines into actual projects,
    as well as training practitioners.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒé˜¶æ®µåŒ…æ‹¬å°†æŒ‡å—å®æ–½åˆ°å®é™…é¡¹ç›®ä¸­ï¼Œä»¥åŠåŸ¹è®­ä»ä¸šäººå‘˜ã€‚
- en: '*Efficiency*'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ•ˆç‡*'
- en: Third, ensuring efficiency includes actually extracting value from trusted ML
    practices through gathering feedback to improve future implementations, optimizing
    resource management, and validating methods in the field.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œç¡®ä¿æ•ˆç‡åŒ…æ‹¬é€šè¿‡æ”¶é›†åé¦ˆä»¥æ”¹è¿›æœªæ¥çš„å®æ–½ã€ä¼˜åŒ–èµ„æºç®¡ç†å’ŒéªŒè¯é¢†åŸŸæ–¹æ³•ï¼Œä»è€Œå®é™…æå–å¯ä¿¡æœºå™¨å­¦ä¹ å®è·µçš„ä»·å€¼ã€‚
- en: This three-stage process helps offset trust debt and protects against significant
    operational risks. Such risks include falling out of compliance with current or
    future regulations for ML-powered applications and negative PR if anything goes
    wrong.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªä¸‰é˜¶æ®µè¿‡ç¨‹æœ‰åŠ©äºæŠµæ¶ˆä¿¡ä»»å€ºåŠ¡ï¼Œå¹¶é˜²æ­¢é¢ä¸´é‡å¤§è¿è¥é£é™©ã€‚è¿™äº›é£é™©åŒ…æ‹¬ä¸ç¬¦åˆå½“å‰æˆ–æœªæ¥MLåº”ç”¨ç¨‹åºçš„æ³•è§„è¦æ±‚ï¼Œä»¥åŠå¦‚æœå‡ºç°é—®é¢˜å¯èƒ½å¼•èµ·çš„è´Ÿé¢å…¬å…³ã€‚
- en: While there are costs for getting the *trust* risk management process startedâ€”in
    stages 1 and 2â€”it is important to focus on stage 3, which is mostly about offsetting
    such costs and even turning profits over time. Research has shown that the *trust-utility
    tradeoff* is often a red herring. For example, [Rodolfa et al.](https://oreil.ly/Ii11e)
    shows that it is indeed possible to use ML to allocate benefits fairly and equitably
    in resource-constrained practical situations, with little to no decline in model
    performance.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶åœ¨é˜¶æ®µ1å’Œ2å¯åŠ¨*ä¿¡ä»»*é£é™©ç®¡ç†è¿‡ç¨‹ä¼šæœ‰æˆæœ¬ï¼Œä½†ä¸“æ³¨äºç¬¬3é˜¶æ®µéå¸¸é‡è¦ï¼Œè¿™ä¸»è¦æ˜¯ä¸ºäº†æŠµæ¶ˆè¿™äº›æˆæœ¬ï¼Œç”šè‡³éšç€æ—¶é—´çš„æ¨ç§»å®ç°ç›ˆåˆ©ã€‚ç ”ç©¶è¡¨æ˜*ä¿¡ä»»-æ•ˆç”¨æƒè¡¡*é€šå¸¸æ˜¯ä¸€ä¸ªä¸åˆ‡å®é™…çš„é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œ[Rodolfaç­‰äºº](https://oreil.ly/Ii11e)è¡¨æ˜ï¼Œåœ¨èµ„æºå—é™çš„å®é™…æƒ…å†µä¸‹ï¼Œç¡®å®å¯ä»¥ä½¿ç”¨æœºå™¨å­¦ä¹ å…¬å¹³å’Œå…¬æ­£åœ°åˆ†é…åˆ©ç›Šï¼Œå‡ ä¹ä¸ä¼šå½±å“æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚
- en: Trust Debts
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¿¡ä»»å€ºåŠ¡
- en: Letâ€™s now dive deeper into a few aspects of both technical and non-technical
    (ethical) trust debts.^([12](ch07.html#idm45621831185904)) Both types of debts
    are categorized in terms of the system components in [FigureÂ 7-2](#img-system).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬æ·±å…¥æ¢è®¨æŠ€æœ¯å’ŒéæŠ€æœ¯ï¼ˆä¼¦ç†ï¼‰ä¿¡ä»»å€ºåŠ¡çš„å‡ ä¸ªæ–¹é¢ã€‚^([12](ch07.html#idm45621831185904)) è¿™ä¸¤ç§ç±»å‹çš„å€ºåŠ¡æ ¹æ®ç³»ç»Ÿç»„ä»¶åœ¨[å›¾Â 7-2](#img-system)ä¸­è¿›è¡Œåˆ†ç±»ã€‚
- en: Technical trust debt
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æŠ€æœ¯ä¿¡ä»»å€ºåŠ¡
- en: 'Components of technical trust debt roughly map to the lifecycle stages of a
    typical ML project. The broad idea is to form and adhere to technical best practices
    for ML system development that make sense under the constraints of our company
    and ML organization:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ€æœ¯ä¿¡ä»»å€ºåŠ¡çš„ç»„æˆéƒ¨åˆ†å¤§è‡´æ˜ å°„åˆ°å…¸å‹æœºå™¨å­¦ä¹ é¡¹ç›®çš„ç”Ÿå‘½å‘¨æœŸé˜¶æ®µã€‚æ€»ä½“æ€è·¯æ˜¯åˆ¶å®šå¹¶åšæŒç¬¦åˆæˆ‘ä»¬å…¬å¸å’Œæœºå™¨å­¦ä¹ ç»„ç»‡çº¦æŸæ¡ä»¶çš„æŠ€æœ¯æœ€ä½³å®è·µï¼š
- en: Data collection
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æ”¶é›†
- en: Specific datasets are often siloed into groups with concentrated domain expertise.
    It can be hard to get proper guidance on the access policies of specific sensitive
    datasets. For these logistical reasons, an ML team may be discouraged in collating
    data sources that could aid them in building trusted applications. Even when they
    do manage to collate them, the owners of data sources sometimes update them without
    properly tracking the changes. This can lead to models that worked one day mysteriously
    not working the next.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å®šæ•°æ®é›†é€šå¸¸è¢«åˆ†ç»„åˆ°å…·æœ‰é›†ä¸­é¢†åŸŸä¸“ä¸šçŸ¥è¯†çš„ç¾¤ä½“ä¸­ã€‚å¾ˆéš¾è·å¾—å…³äºç‰¹å®šæ•æ„Ÿæ•°æ®é›†è®¿é—®æ”¿ç­–çš„é€‚å½“æŒ‡å¯¼ã€‚å‡ºäºè¿™äº›åå‹¤åŸå› ï¼Œä¸€ä¸ªæœºå™¨å­¦ä¹ å›¢é˜Ÿå¯èƒ½ä¸æ„¿æ„æ•´åˆèƒ½å¤Ÿå¸®åŠ©ä»–ä»¬æ„å»ºå—ä¿¡ä»»åº”ç”¨ç¨‹åºçš„æ•°æ®æºã€‚å³ä½¿ä»–ä»¬è®¾æ³•æ•´åˆäº†è¿™äº›æ•°æ®æºï¼Œæ•°æ®æºçš„æ‰€æœ‰è€…æœ‰æ—¶ä¼šåœ¨æ²¡æœ‰é€‚å½“è·Ÿè¸ªæ›´æ”¹çš„æƒ…å†µä¸‹æ›´æ–°å®ƒä»¬ã€‚è¿™å¯èƒ½å¯¼è‡´ä¸€å¤©å·¥ä½œæ­£å¸¸çš„æ¨¡å‹åœ¨ç¬¬äºŒå¤©å°±ç¥ç§˜åœ°å¤±æ•ˆã€‚
- en: Tools like Data Version Control ([DVC](https://dvc.org)) can help you track
    which versions of a dataset your team is using, and it can help you fix versions
    for specific experiments. You might think of DVC as Git for datasets. Adding DVC
    to a project is straightforward.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼æ•°æ®ç‰ˆæœ¬æ§åˆ¶ï¼ˆ[DVC](https://dvc.org)ï¼‰è¿™æ ·çš„å·¥å…·å¯ä»¥å¸®åŠ©æ‚¨è·Ÿè¸ªå›¢é˜Ÿä½¿ç”¨çš„æ•°æ®é›†ç‰ˆæœ¬ï¼Œå¹¶ä¸ºç‰¹å®šå®éªŒå›ºå®šç‰ˆæœ¬ã€‚æ‚¨å¯ä»¥å°†DVCè§†ä¸ºæ•°æ®é›†çš„Gitã€‚å°†DVCæ·»åŠ åˆ°é¡¹ç›®ä¸­éå¸¸ç®€å•ã€‚
- en: '[PRE4]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Just make sure you add a few internal files to Git.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: åªéœ€ç¡®ä¿å‘Gitæ·»åŠ å‡ ä¸ªå†…éƒ¨æ–‡ä»¶ã€‚
- en: '[PRE5]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Versioning with DVC is simple.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨DVCè¿›è¡Œç‰ˆæœ¬æ§åˆ¶å¾ˆç®€å•ã€‚
- en: '[PRE6]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If youâ€™ve already initialized your project, you can use DVC to directly download
    datasets as well.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨å·²ç»åˆå§‹åŒ–äº†é¡¹ç›®ï¼Œå¯ä»¥ä½¿ç”¨DVCç›´æ¥ä¸‹è½½æ•°æ®é›†ã€‚
- en: '[PRE7]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In addition, `dvc get` can download any file or directory tracked in a DVC repository.
    It works like `wget`, but for DVC or Git repos. In this case, we are downloading
    the latest version of the *data.xml* file from the dataset registry repo (the
    data source).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œ`dvc get`å¯ä»¥ä¸‹è½½DVCä»“åº“ä¸­è·Ÿè¸ªçš„ä»»ä½•æ–‡ä»¶æˆ–ç›®å½•ã€‚å®ƒç±»ä¼¼äº`wget`ï¼Œä½†ç”¨äºDVCæˆ–Gitä»“åº“ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä»æ•°æ®é›†æ³¨å†Œä»“åº“ï¼ˆæ•°æ®æºï¼‰ä¸‹è½½*data.xml*æ–‡ä»¶çš„æœ€æ–°ç‰ˆæœ¬ã€‚
- en: Data verification
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®éªŒè¯
- en: Even when the required data is available and accessible, deficiencies in data
    collection processes may hinder trustworthy ML deployment. For example, procuring
    quality third-party demographic data has been an ongoing issue in applied algorithmic
    fairness.^([13](ch07.html#idm45621831158800))
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿æ‰€éœ€æ•°æ®å·²ç»å¯ç”¨ä¸”æ˜“äºè®¿é—®ï¼Œæ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­çš„ç¼ºé™·å¯èƒ½ä¼šé˜»ç¢å¯ä¿¡çš„æœºå™¨å­¦ä¹ éƒ¨ç½²ã€‚ä¾‹å¦‚ï¼Œåœ¨åº”ç”¨ç®—æ³•å…¬å¹³æ€§ä¸­ï¼Œè·å–ä¼˜è´¨ç¬¬ä¸‰æ–¹äººå£ç»Ÿè®¡æ•°æ®ä¸€ç›´æ˜¯ä¸€ä¸ªæŒç»­å­˜åœ¨çš„é—®é¢˜ã€‚^([13](ch07.html#idm45621831158800))
- en: Monitoring the health of critical data dependencies is an ongoing process. Even
    when a source supplies you with high-quality data in the first iteration of your
    model, you need to put checks in place to make sure that this quality level remains
    for future iterations as well.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ç›‘æ§å…³é”®æ•°æ®ä¾èµ–é¡¹çš„å¥åº·çŠ¶æ€æ˜¯ä¸€ä¸ªæŒç»­è¿›è¡Œçš„è¿‡ç¨‹ã€‚å³ä½¿æºæ•°æ®åœ¨æ¨¡å‹çš„ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­æä¾›äº†é«˜è´¨é‡çš„æ•°æ®ï¼Œæ‚¨ä¹Ÿéœ€è¦ç¡®ä¿å°†æ¥çš„è¿­ä»£ä¸­ä»ç„¶ä¿æŒè¿™ç§è´¨é‡æ°´å¹³ã€‚
- en: Feature extraction
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾æå–
- en: One major hurdle in implementing ML fairness methods is the risk that information
    about sensitive features will seep into the data through correlated non-sensitive
    proxy features. This is why creating fair algorithms isnâ€™t as simple as just not
    including sensitive features in your datasets.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: å®æ–½æœºå™¨å­¦ä¹ å…¬å¹³æ–¹æ³•çš„ä¸€ä¸ªä¸»è¦éšœç¢æ˜¯ï¼Œå…³äºæ•æ„Ÿç‰¹å¾çš„ä¿¡æ¯å¯èƒ½é€šè¿‡ç›¸å…³çš„éæ•æ„Ÿä»£ç†ç‰¹å¾æ¸—å…¥æ•°æ®ä¸­ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåˆ›å»ºå…¬å¹³ç®—æ³•å¹¶ä¸åƒç®€å•åœ°åœ¨æ•°æ®é›†ä¸­ä¸åŒ…å«æ•æ„Ÿç‰¹å¾é‚£æ ·ç®€å•ã€‚
- en: For other aspects of trust, youâ€™ll need to use domain knowledge extensively
    when you craft features in standard data science workflows. Without well-reasoned
    extract-transform-load (ETL) pipelines, ML systems are difficult to interpret
    and troubleshootâ€”hence, trust. Even if the features *arenâ€™t* sensitive, unseen
    correlated features can make ML training both more brittle and more expensive.
    Tools like analysis of covariance ([ANCOVA](https://oreil.ly/Zm4Sg)) are commonly
    used to identify correlated features. However, ANCOVA has been used in many scenarios
    where some of its assumptions definitely do not apply.^([14](ch07.html#idm45621831148064))
    This is a practical application for the causal inference techniques we mentioned
    in [â€œCausal Machine Learningâ€](#causalinf).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¿¡ä»»çš„å…¶ä»–æ–¹é¢ï¼Œå½“æ‚¨åœ¨æ ‡å‡†æ•°æ®ç§‘å­¦å·¥ä½œæµç¨‹ä¸­è®¾è®¡ç‰¹å¾æ—¶ï¼Œéœ€è¦å¹¿æ³›è¿ç”¨é¢†åŸŸçŸ¥è¯†ã€‚æ²¡æœ‰åˆç†æ¨ç†çš„æå–-è½¬æ¢-åŠ è½½ï¼ˆETLï¼‰ç®¡é“ï¼Œæœºå™¨å­¦ä¹ ç³»ç»Ÿéš¾ä»¥è§£é‡Šå’Œæ’é”™ï¼Œå› æ­¤éš¾ä»¥å»ºç«‹ä¿¡ä»»ã€‚å³ä½¿ç‰¹å¾*ä¸*æ•æ„Ÿï¼Œæœªè§è¿‡çš„ç›¸å…³ç‰¹å¾ä¹Ÿå¯èƒ½ä½¿æœºå™¨å­¦ä¹ è®­ç»ƒæ›´åŠ è„†å¼±å’Œæ›´åŠ æ˜‚è´µã€‚è¯¸å¦‚åæ–¹å·®åˆ†æï¼ˆ[ANCOVA](https://oreil.ly/Zm4Sg)ï¼‰ä¹‹ç±»çš„å·¥å…·é€šå¸¸ç”¨äºè¯†åˆ«ç›¸å…³ç‰¹å¾ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šåœºæ™¯ä¸­ï¼ŒANCOVAè¢«ä½¿ç”¨æ—¶ï¼Œå…¶æŸäº›å‡è®¾æ˜¾ç„¶ä¸é€‚ç”¨ã€‚^([14](ch07.html#idm45621831148064))è¿™æ˜¯æˆ‘ä»¬åœ¨[â€œå› æœæœºå™¨å­¦ä¹ â€](#causalinf)ä¸­æåˆ°çš„å› æœæ¨æ–­æŠ€æœ¯çš„å®é™…åº”ç”¨ã€‚
- en: Process management
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: è¿‡ç¨‹ç®¡ç†
- en: ML projects inside an organization rarely happen in a linear and isolated manner.
    Rather, they tend to focus on a handful of application domains, leverage similar
    ETL components, and interact with each other through reuse and output chaining.
    Given this interconnectedness, trust debt incurred in one project can cascade
    down to other projects affected by the current project, or the same source of
    debt can affect multiple projects in tandem. If you are retraining a model at
    any step in this pipeline, itâ€™s important to also retrain any downstream models
    that would be affected by a change of outputs. They should be retrained in the
    order in which information passes through the pipeline.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ç»„ç»‡å†…çš„MLé¡¹ç›®å¾ˆå°‘æ˜¯çº¿æ€§å’Œå­¤ç«‹çš„ã€‚ç›¸åï¼Œå®ƒä»¬å¾€å¾€é›†ä¸­åœ¨å°‘æ•°åº”ç”¨é¢†åŸŸï¼Œåˆ©ç”¨ç±»ä¼¼çš„ETLç»„ä»¶ï¼Œå¹¶é€šè¿‡é‡ç”¨å’Œè¾“å‡ºé“¾æ¥ç›¸äº’äº¤äº’ã€‚é‰´äºè¿™ç§ç›¸äº’è¿æ¥æ€§ï¼Œä¸€ä¸ªé¡¹ç›®ä¸­äº§ç”Ÿçš„ä¿¡ä»»å€ºåŠ¡å¯èƒ½ä¼šå‘å—å½“å‰é¡¹ç›®å½±å“çš„å…¶ä»–é¡¹ç›®çº§è”ä¼ é€’ï¼Œæˆ–è€…åŒä¸€å€ºåŠ¡æºå¯èƒ½ä¼šå½±å“å¤šä¸ªé¡¹ç›®ã€‚å¦‚æœåœ¨ç®¡é“çš„ä»»ä½•æ­¥éª¤ä¸­é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œåˆ™é‡è¦çš„æ˜¯ä¹Ÿé‡æ–°è®­ç»ƒå—è¾“å‡ºå˜åŒ–å½±å“çš„ä»»ä½•ä¸‹æ¸¸æ¨¡å‹ã€‚å®ƒä»¬åº”æŒ‰ç…§ä¿¡æ¯é€šè¿‡ç®¡é“çš„é¡ºåºè¿›è¡Œé‡æ–°è®­ç»ƒã€‚
- en: Feedback
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: åé¦ˆ
- en: Feedback loops can result in technical trust debt directly or indirectly. *Direct
    feedback loops* arise when the data collected for a model comes from the population
    where the inferences from previous iterations of the model are being served ([FigureÂ 7-3](#img-feedback)).
    With *indirect* or *hidden* feedback loops, two or more models influence each
    other through intermediate real-world steps. In both situations, trust debts can
    cascade by amplifying problems in one or more aspects of trust.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: åé¦ˆå¾ªç¯å¯èƒ½ç›´æ¥æˆ–é—´æ¥å¯¼è‡´æŠ€æœ¯ä¿¡ä»»å€ºåŠ¡ã€‚*ç›´æ¥åé¦ˆå¾ªç¯*å‘ç”Ÿåœ¨æ¨¡å‹æ‰€é‡‡é›†æ•°æ®çš„äººç¾¤ä¸­ï¼Œè¿™äº›æ•°æ®ç”¨äºä¸ºæ¨¡å‹çš„å…ˆå‰è¿­ä»£æä¾›æ¨æ–­æœåŠ¡([å›¾7-3](#img-feedback))ã€‚è€Œ*é—´æ¥*æˆ–*éšè—*çš„åé¦ˆå¾ªç¯åˆ™æ˜¯æŒ‡ä¸¤ä¸ªæˆ–æ›´å¤šæ¨¡å‹é€šè¿‡ä¸­é—´çš„ç°å®ä¸–ç•Œæ­¥éª¤ç›¸äº’å½±å“ã€‚åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œä¿¡ä»»å€ºåŠ¡å¯ä»¥é€šè¿‡æ”¾å¤§ä¸€ä¸ªæˆ–å¤šä¸ªä¿¡ä»»æ–¹é¢çš„é—®é¢˜è€Œçº§è”æ‰©å±•ã€‚
- en: '![ptml 0703](assets/ptml_0703.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0703](assets/ptml_0703.png)'
- en: Figure 7-3\. Examples of direct feedback loops that can be present in a ML pipeline
  id: totrans-181
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾7-3\. MLç®¡é“ä¸­å¯èƒ½å­˜åœ¨çš„ç›´æ¥åé¦ˆå¾ªç¯ç¤ºä¾‹
- en: Monitoring
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ç›‘æ§
- en: Technical trust debts can arise in any or all of the preceding categories during
    any part of an organizationâ€™s ML journey. As you deploy, update, and iterate upon
    more and more ML models, new needs may arise, while old ones go away. Thus, it
    is important not only to put a process in place to perform code and infrastructure
    due diligence but also to reevaluate that process periodically.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ€æœ¯ä¿¡ä»»å€ºåŠ¡å¯ä»¥åœ¨ç»„ç»‡çš„MLæ—…ç¨‹çš„ä»»ä½•éƒ¨åˆ†æˆ–æ‰€æœ‰éƒ¨åˆ†ä¸­äº§ç”Ÿã€‚éšç€æ‚¨éƒ¨ç½²ã€æ›´æ–°å’Œè¿­ä»£è¶Šæ¥è¶Šå¤šçš„MLæ¨¡å‹ï¼Œå¯èƒ½ä¼šå‡ºç°æ–°çš„éœ€æ±‚ï¼Œè€Œæ—§çš„éœ€æ±‚åˆ™å¯èƒ½æ¶ˆå¤±ã€‚å› æ­¤ï¼Œä¸ä»…éœ€è¦å»ºç«‹ä¸€ä¸ªè¿›è¡Œä»£ç å’ŒåŸºç¡€è®¾æ–½å°½èŒè°ƒæŸ¥çš„æµç¨‹ï¼Œè¿˜éœ€è¦å®šæœŸé‡æ–°è¯„ä¼°è¯¥æµç¨‹çš„æœ‰æ•ˆæ€§ã€‚
- en: Ethical debt
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é“å¾·å€ºåŠ¡
- en: Nontechnical trust debt, often called *ethical debt*, arises when ML workflows
    and/or the business decisions guiding ML workflows are misaligned with ethical
    principles. Ethical debt is more dangerous than technical trust debt, in that
    its consequences can reach far beyond the organization and affect real people
    in serious, sometimes life-and-death ways. As cybersecurity engineer Catherine
    Petrozzino notes, â€œUnlike technical debt which is an a priori organizational decision,
    ethical debt is exacerbated by the reality that some ethical problems with AI
    solutions can only be detected after they are deployed.â€^([15](ch07.html#idm45621831122656))
    Cases in point are the [death of Elaine Herzberg](https://oreil.ly/D5cLv) involving
    an Uber self-driving test vehicle and ML-based hiring algorithms continuing to
    exhibit demographic bias even when designed to combat the same problem.^([16](ch07.html#idm45621831120016))
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: éæŠ€æœ¯ä¿¡ä»»å€ºåŠ¡ï¼Œé€šå¸¸ç§°ä¸º*é“å¾·å€ºåŠ¡*ï¼Œæ˜¯åœ¨æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹å’Œ/æˆ–æŒ‡å¯¼æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹çš„ä¸šåŠ¡å†³ç­–ä¸ä¼¦ç†åŸåˆ™ä¸ä¸€è‡´æ—¶äº§ç”Ÿçš„ã€‚é“å¾·å€ºåŠ¡æ¯”æŠ€æœ¯ä¿¡ä»»å€ºåŠ¡æ›´ä¸ºå±é™©ï¼Œå› ä¸ºå…¶åæœå¯èƒ½è¿œè¿œè¶…å‡ºç»„ç»‡èŒƒå›´ï¼Œå½±å“åˆ°çœŸå®äººå‘˜ï¼Œæœ‰æ—¶ç”šè‡³æ¶‰åŠç”Ÿæ­»ã€‚æ­£å¦‚ç½‘ç»œå®‰å…¨å·¥ç¨‹å¸ˆå‡¯ç‘Ÿç³Â·ä½©ç‰¹ç½—é½è¯ºæŒ‡å‡ºï¼Œâ€œä¸æŠ€æœ¯å€ºåŠ¡ä¸åŒï¼Œé“å¾·å€ºåŠ¡åŠ å‰§çš„åŸå› åœ¨äºï¼ŒæŸäº›äººå·¥æ™ºèƒ½è§£å†³æ–¹æ¡ˆçš„ä¼¦ç†é—®é¢˜åªèƒ½åœ¨éƒ¨ç½²åæ‰èƒ½æ£€æµ‹åˆ°ã€‚â€^([15](ch07.html#idm45621831122656))
    æ¯”å¦‚ï¼Œ[Elaine Herzbergçš„æ­»äº¡](https://oreil.ly/D5cLv)ä¸Uberè‡ªåŠ¨é©¾é©¶æµ‹è¯•è½¦æœ‰å…³ï¼Œä»¥åŠåŸºäºMLçš„æ‹›è˜ç®—æ³•ç»§ç»­å±•ç°å‡ºäººå£ç»Ÿè®¡åè§ï¼Œå³ä½¿è®¾è®¡ç”¨äºè§£å†³ç›¸åŒé—®é¢˜ä¹Ÿæ˜¯å¦‚æ­¤ã€‚^([16](ch07.html#idm45621831120016))
- en: The study of ethical debt in ML is fairly new. Letâ€™s look at the current treatment
    of this topic distilled down into a few categories:^([17](ch07.html#idm45621831117744))
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ç ”ç©¶MLä¸­çš„é“å¾·å€ºåŠ¡ç›¸å¯¹è¾ƒæ–°ã€‚è®©æˆ‘ä»¬å°†å½“å‰å¯¹è¿™ä¸€ä¸»é¢˜çš„å¤„ç†æ€»ç»“ä¸ºå‡ ä¸ªç±»åˆ«:^([17](ch07.html#idm45621831117744))
- en: Assumption
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾
- en: Even well-intentioned, trustworthy ML implementations sometimes fall short of
    their goals due to faulty or out-of-context assumptions. For example, the disparate
    impact (DI) thresholds of 0.8 and 1.2 are informed by the [EEOCâ€™s 80-20 rule](https://oreil.ly/IG3QC).
    This rule was originally proposed in the context of combating hiring discrimination,
    but today it is taken for granted in probably all applications of the DI metric
    in algorithmic fairness literature.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿æ˜¯å‡ºäºè‰¯å¥½æ„å›¾çš„ã€å€¼å¾—ä¿¡èµ–çš„æœºå™¨å­¦ä¹ å®ç°æœ‰æ—¶ä¹Ÿä¼šç”±äºé”™è¯¯çš„æˆ–ä¸Šä¸‹æ–‡æ— å…³çš„å‡è®¾è€Œæœªèƒ½è¾¾åˆ°å…¶ç›®æ ‡ã€‚ä¾‹å¦‚ï¼Œä¸åŒå½±å“ï¼ˆDIï¼‰é˜ˆå€¼ä¸º0.8å’Œ1.2æ˜¯åŸºäº[å¹³ç­‰å°±ä¸šæœºä¼šå§”å‘˜ä¼šçš„80-20è§„åˆ™](https://oreil.ly/IG3QC)ã€‚è¯¥è§„åˆ™æœ€åˆæ˜¯åœ¨æ‰“å‡»æ‹›è˜æ­§è§†çš„èƒŒæ™¯ä¸‹æå‡ºçš„ï¼Œä½†å¦‚ä»Šåœ¨ç®—æ³•å…¬å¹³æ€§æ–‡çŒ®ä¸­DIæŒ‡æ ‡çš„æ‰€æœ‰åº”ç”¨ä¸­éƒ½è¢«è§†ä¸ºç†æ‰€å½“ç„¶ã€‚
- en: Post facto determination
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: åäº‹å®ç¡®å®š
- en: In the recent past, a number of ethical harms caused by ML applications have
    come to light as the people harmed have spoken up about their experiences. Adding
    elements of trust to ML-based solutions does make them less likely to occur. However,
    doing so reactively to plug known deficiencies, without proactively expanding
    or characterizing the applicationâ€™s deficiencies still to be fixed, only leaves
    room for future mishaps.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ€è¿‘çš„è¿‡å»ï¼Œç”±äºå—å®³è€…è®²è¿°ä»–ä»¬çš„ç»å†ï¼ŒMLåº”ç”¨é€ æˆçš„ä¸€äº›ä¼¦ç†ä¼¤å®³å·²ç»æ˜¾éœ²å‡ºæ¥ã€‚å°†ä¿¡ä»»å…ƒç´ æ·»åŠ åˆ°åŸºäºMLçš„è§£å†³æ–¹æ¡ˆä¸­ç¡®å®ä¼šå‡å°‘è¿™äº›äº‹ä»¶çš„å‘ç”Ÿã€‚ç„¶è€Œï¼Œä»…ä»…å¯¹å·²çŸ¥ç¼ºé™·è¿›è¡Œååº”æ€§è¡¥æ•‘è€Œä¸ç§¯ææ‰©å±•æˆ–æè¿°åº”ç”¨ç¨‹åºå°šå¾…ä¿®å¤çš„ç¼ºé™·ï¼Œåªä¼šä¸ºæœªæ¥çš„ä¸å¹¸ç•™ä¸‹ç©ºé—´ã€‚
- en: Human limitations
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: äººç±»é™åˆ¶
- en: Organizational decision making is a collective and iterative process. The implementation
    details of an ML project are no exception. The collective judgment of human teams
    is often constrained by gaps in perception, lack of cultural diversity, and shortfalls
    in resources and education.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ç»„ç»‡å†³ç­–æ˜¯ä¸€ä¸ªé›†ä½“å’Œè¿­ä»£çš„è¿‡ç¨‹ã€‚MLé¡¹ç›®çš„å®æ–½ç»†èŠ‚ä¹Ÿä¸ä¾‹å¤–ã€‚äººç±»å›¢é˜Ÿçš„é›†ä½“åˆ¤æ–­å¾€å¾€å—åˆ°æ„ŸçŸ¥å·®è·ã€æ–‡åŒ–å¤šæ ·æ€§ä¸è¶³ä»¥åŠèµ„æºå’Œæ•™è‚²çš„çŸ­ç¼ºçš„é™åˆ¶ã€‚
- en: Automation bias
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨åŒ–åè§
- en: Humans in the loop of automated decision-making systems are prone to *automation
    bias*, or overreliance on machine-generated outputs. This is specifically a problem
    in ML explainability, where the main goal is to ensure that explanations of an
    MLâ€™s decisions â€œmake senseâ€ to the end user. Some studies published in 2020 and
    2021 have found that humans *do* tend to overly trust outputs from post hoc explanation
    methods and that it is possible to mislead users with rogue explanations.^([18](ch07.html#idm45621831095712))^,^([19](ch07.html#idm45621831093472))
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨å†³ç­–ç³»ç»Ÿä¸­çš„äººç±»å¾€å¾€å®¹æ˜“å‡ºç°*è‡ªåŠ¨åŒ–åè§*ï¼Œæˆ–è€…å¯¹æœºå™¨ç”Ÿæˆçš„è¾“å‡ºè¿‡åº¦ä¾èµ–ã€‚è¿™åœ¨MLè§£é‡Šæ€§æ–¹é¢ç‰¹åˆ«æ˜¯ä¸ªé—®é¢˜ï¼Œä¸»è¦ç›®æ ‡æ˜¯ç¡®ä¿MLå†³ç­–çš„è§£é‡Šå¯¹æœ€ç»ˆç”¨æˆ·â€œè®²å¾—é€šâ€ã€‚ä¸€äº›2020å¹´å’Œ2021å¹´å‘è¡¨çš„ç ”ç©¶å‘ç°ï¼Œäººä»¬ç¡®å®å€¾å‘äºè¿‡åº¦ä¿¡ä»»äº‹åè§£é‡Šæ–¹æ³•çš„è¾“å‡ºï¼Œè€Œä¸”å¯èƒ½é€šè¿‡ä¸è‰¯è§£é‡Šè¯¯å¯¼ç”¨æˆ·ã€‚^([18](ch07.html#idm45621831095712))^,^([19](ch07.html#idm45621831093472))
- en: Paying off trust debt
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: æ¸…å¿ä¿¡ä»»è´Ÿå€º
- en: Formally measuring technical debt in ML is challenging. For ethical debt, what
    further complicates matters is the fact that those who are guilty of lackluster
    practices are not always the ones paying back the debt. End users are the people
    most affected by the negative consequences of less-than-trustworthy algorithms,
    and such consequences most often affect disadvantaged segments of the user base.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨MLä¸­æ­£å¼è¡¡é‡æŠ€æœ¯å€ºåŠ¡å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å¯¹äºä¼¦ç†å€ºåŠ¡ï¼Œæ›´å¤æ‚çš„æ˜¯ï¼Œé‚£äº›çŠ¯ä¸‹ä¸è‰¯å®è·µçš„äººå¹¶ä¸æ€»æ˜¯åœ¨å¿è¿˜å€ºåŠ¡ã€‚æœ€ç»ˆç”¨æˆ·æ˜¯å—ä¸å¯ä¿¡èµ–ç®—æ³•è´Ÿé¢å½±å“æœ€å¤šçš„äººç¾¤ï¼Œè¿™äº›å½±å“å¾€å¾€æœ€å¸¸å½±å“åˆ°å¤„äºåŠ£åŠ¿çš„ç”¨æˆ·ç¾¤ä½“ã€‚
- en: To some extent, general engineering best practices can help keep technical trust
    debt in check. This includes writing proper documentation, sharing knowledge,
    minimizing dependencies, and implementing tests to measure and adjust for the
    effects of adding new functionality to an ML-based solution. In particular, itâ€™s
    helpful to create documentation focused on recording trust-specific considerations
    and learning from documented information about similar past projects. Letâ€™s briefly
    discuss two such approaches here, but defer a detailed treatment to [ChapterÂ 8](ch08.html#chapter8).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸€å®šç¨‹åº¦ä¸Šï¼Œä¸€èˆ¬çš„å·¥ç¨‹æœ€ä½³å®è·µå¯ä»¥å¸®åŠ©æ§åˆ¶æŠ€æœ¯ä¿¡ä»»è´Ÿå€ºã€‚è¿™åŒ…æ‹¬æ’°å†™é€‚å½“çš„æ–‡æ¡£ã€åˆ†äº«çŸ¥è¯†ã€æœ€å°åŒ–ä¾èµ–å…³ç³»ï¼Œå¹¶å®æ–½æµ‹è¯•æ¥è¡¡é‡å’Œè°ƒæ•´ä¸ºåŸºäºMLçš„è§£å†³æ–¹æ¡ˆæ·»åŠ æ–°åŠŸèƒ½çš„å½±å“ã€‚ç‰¹åˆ«æ˜¯ï¼Œæœ‰åŠ©äºåˆ›å»ºä¸“æ³¨äºè®°å½•ä¿¡ä»»ç‰¹å®šè€ƒè™‘å› ç´ å¹¶ä»ç±»ä¼¼è¿‡å»é¡¹ç›®çš„æ–‡æ¡£ä¿¡æ¯ä¸­å­¦ä¹ çš„æ–‡æ¡£ã€‚è®©æˆ‘ä»¬åœ¨è¿™é‡Œç®€è¦è®¨è®ºä¸¤ç§æ–¹æ³•ï¼Œä½†è¯¦ç»†å¤„ç†æ¨è¿Ÿåˆ°[ç¬¬8ç« ](ch08.html#chapter8)ã€‚
- en: Model cards
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹å¡ç‰‡
- en: '*Model cards* are structured documents that provide context for and transparency
    into the development and performance of an ML model.^([20](ch07.html#idm45621831080464))
    There are a variety of model card implementations out there, for example, the
    TensorFlow ecosystemâ€™s [Model Card Toolkit](https://oreil.ly/XtBuH).'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ¨¡å‹å¡*æ˜¯ç»“æ„åŒ–æ–‡æ¡£ï¼Œæä¾›MLæ¨¡å‹å¼€å‘å’Œæ€§èƒ½çš„èƒŒæ™¯å’Œé€æ˜åº¦ã€‚^([20](ch07.html#idm45621831080464)) ç›®å‰æœ‰å¤šç§æ¨¡å‹å¡å®ç°ï¼Œä¾‹å¦‚TensorFlowç”Ÿæ€ç³»ç»Ÿçš„[æ¨¡å‹å¡å·¥å…·åŒ…](https://oreil.ly/XtBuH)ã€‚'
- en: Model cards are useful for B2C use cases, but they may not be sufficient for
    internal development teams. A growing company will be more concerned with how
    easily new details about the ML pipeline can be added without hassle. Model cards
    also focus mainly on the ML model, while ignoring the much larger ML pipeline
    surrounding the model.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹å¡å¯¹B2Cç”¨ä¾‹å¾ˆæœ‰ç”¨ï¼Œä½†å¯¹å†…éƒ¨å¼€å‘å›¢é˜Ÿå¯èƒ½ä¸å¤Ÿã€‚ä¸æ–­å‘å±•çš„å…¬å¸æ›´å…³æ³¨å¦‚ä½•è½»æ¾æ·»åŠ å…³äºMLç®¡é“çš„æ–°ç»†èŠ‚ã€‚æ¨¡å‹å¡ä¸»è¦å…³æ³¨MLæ¨¡å‹ï¼Œè€Œå¿½è§†å›´ç»•æ¨¡å‹çš„æ›´å¤§çš„MLç®¡é“ã€‚
- en: What you as a developer want is not only ML model cards, but also ML directed
    acyclic graphs (DAGs). This would be a much more detailed way of describing the
    network of dependencies as information flows through the pipeline and reaches
    the various decision points. For an implementation of DAGs in model documentation
    and maintenance, check out [DAG cards](https://oreil.ly/iaj8O), which build upon
    model cards with dependency graphs built using [Metaflow](https://metaflow.org)
    and [Weights and Biases](https://wandb.ai/site).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºå¼€å‘è€…ï¼Œæ‚¨ä¸ä»…éœ€è¦MLæ¨¡å‹å¡ï¼Œè¿˜éœ€è¦MLæœ‰å‘æ— ç¯å›¾ï¼ˆDAGsï¼‰ã€‚è¿™å°†æ›´è¯¦ç»†åœ°æè¿°ä¿¡æ¯é€šè¿‡ç®¡é“æµåŠ¨å¹¶åˆ°è¾¾å„ç§å†³ç­–ç‚¹çš„ä¾èµ–ç½‘ç»œã€‚å…³äºæ¨¡å‹æ–‡æ¡£å’Œç»´æŠ¤ä¸­çš„DAGsçš„å®ç°ï¼Œè¯·æŸ¥çœ‹ä½¿ç”¨[Metaflow](https://metaflow.org)å’Œ[Weights
    and Biases](https://wandb.ai/site)æ„å»ºçš„[DAGå¡](https://oreil.ly/iaj8O)ã€‚
- en: Important Aspects of Trust
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¿¡ä»»çš„é‡è¦æ–¹é¢
- en: So, your team has managed to convince stakeholders that not only does their
    productâ€™s ML algorithm need to be accurate, but it is also important to do due
    diligence regarding trust. Congratulations! Now, how will you decide which aspects
    to prioritize in your specific project? Do you need your algorithm to be fair?
    Explainable? Private? Robust? Secure? All of these? Some of them? How much fairness,
    explainability, etc. do you need? Letâ€™s talk a bit about how to move forward in
    this situation.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ‚¨çš„å›¢é˜Ÿå·²ç»æˆåŠŸè¯´æœåˆ©ç›Šç›¸å…³è€…ï¼Œä»–ä»¬çš„äº§å“MLç®—æ³•ä¸ä»…éœ€è¦å‡†ç¡®ï¼Œè¿˜éœ€è¦è¿›è¡Œä¿¡ä»»çš„å°½èŒè°ƒæŸ¥ã€‚æ­å–œï¼ç°åœ¨ï¼Œæ‚¨å¦‚ä½•å†³å®šåœ¨ç‰¹å®šé¡¹ç›®ä¸­ä¼˜å…ˆè€ƒè™‘å“ªäº›æ–¹é¢ï¼Ÿæ‚¨çš„ç®—æ³•éœ€è¦å…¬å¹³å—ï¼Ÿå¯è§£é‡Šå—ï¼Ÿç§å¯†å—ï¼Ÿå¥å£®å—ï¼Ÿå®‰å…¨å—ï¼Ÿå…¨éƒ¨ï¼Ÿéƒ¨åˆ†ï¼Ÿæ‚¨éœ€è¦å¤šå°‘å…¬å¹³æ€§ã€å¯è§£é‡Šæ€§ç­‰ï¼Ÿè®©æˆ‘ä»¬è°ˆä¸€è°ˆåœ¨è¿™ç§æƒ…å†µä¸‹å¦‚ä½•å‰è¿›ã€‚
- en: 'This decision-making process has three steps: assessing your needs to decide
    which aspects of trust to prioritize, deciding on metrics for each aspect, and
    deciding on thresholds for those metrics.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå†³ç­–è¿‡ç¨‹æœ‰ä¸‰ä¸ªæ­¥éª¤ï¼šè¯„ä¼°æ‚¨çš„éœ€æ±‚ä»¥å†³å®šä¼˜å…ˆè€ƒè™‘ä¿¡ä»»çš„å“ªäº›æ–¹é¢ï¼Œä¸ºæ¯ä¸ªæ–¹é¢ç¡®å®šæŒ‡æ ‡ï¼Œä»¥åŠç¡®å®šè¿™äº›æŒ‡æ ‡çš„é˜ˆå€¼ã€‚
- en: 'The first step, assessing needs, means weighing your projectâ€™s need for each
    aspect of trust and categorizing the needs by priority. Letâ€™s consider three categories
    of needs:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥ï¼Œè¯„ä¼°éœ€æ±‚ï¼Œæ„å‘³ç€æƒè¡¡é¡¹ç›®å¯¹æ¯ä¸ªä¿¡ä»»æ–¹é¢çš„éœ€æ±‚ï¼Œå¹¶æŒ‰ä¼˜å…ˆçº§åˆ†ç±»è¿™äº›éœ€æ±‚ã€‚è®©æˆ‘ä»¬è€ƒè™‘ä¸‰ç±»éœ€æ±‚ï¼š
- en: '*High need*'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '*é«˜éœ€æ±‚*'
- en: It is absolutely essential for the algorithm to be fair, explainable, private,
    robust, and safe.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ç®—æ³•å…¬å¹³ã€å¯è§£é‡Šã€ç§å¯†ã€å¥å£®å’Œå®‰å…¨ç»å¯¹è‡³å…³é‡è¦ã€‚
- en: '*Medium need*'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä¸­ç­‰éœ€æ±‚*'
- en: It would be nice for the algorithm to be fair, explainable, private, robust,
    and safe.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ç®—æ³•å…¬å¹³ã€å¯è§£é‡Šã€ç§å¯†ã€å¥å£®å’Œå®‰å…¨ä¼šå¾ˆå¥½ã€‚
- en: '*Low need*'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä½éœ€æ±‚*'
- en: It is not too important for the algorithm to be fair, explainable, private,
    robust, and safe.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ç®—æ³•å…¬å¹³ã€å¯è§£é‡Šã€ç§å¯†ã€å¥å£®å’Œå®‰å…¨å¹¶ä¸æ˜¯å¤ªé‡è¦ã€‚
- en: The best way to figure this out is to ask a number of questions. Some of these
    questions are general; others are specific to one or more trust elements. See
    [TableÂ 7-2](#table-trust-questions) for an example list of questions. Not every
    company or product has the same priorities, so feel free to take, modify, and
    expand parts of this table to suit your own context.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: å¼„æ¸…æ¥šè¿™ä¸€ç‚¹çš„æœ€ä½³æ–¹æ³•æ˜¯æå‡ºä¸€äº›é—®é¢˜ã€‚å…¶ä¸­ä¸€äº›é—®é¢˜æ˜¯é€šç”¨çš„ï¼Œå…¶ä»–åˆ™æ˜¯ç‰¹å®šäºä¸€ä¸ªæˆ–å¤šä¸ªä¿¡ä»»å…ƒç´ ã€‚æœ‰å…³ç¤ºä¾‹é—®é¢˜åˆ—è¡¨ï¼Œè¯·å‚è§[è¡¨æ ¼ 7-2](#table-trust-questions)ã€‚å¹¶éæ¯å®¶å…¬å¸æˆ–äº§å“çš„ä¼˜å…ˆçº§éƒ½ç›¸åŒï¼Œå› æ­¤è¯·éšæ—¶æ ¹æ®æ‚¨è‡ªå·±çš„æƒ…å†µé‡‡å–ã€ä¿®æ”¹å’Œæ‰©å±•è¿™ä¸ªè¡¨æ ¼çš„éƒ¨åˆ†ã€‚
- en: Table 7-2\. Sample questions for needs assessment of trust elements with relevant
    trust elements tick-marked if the answer is *yes*
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨æ ¼ 7-2\. ç”¨äºä¿¡ä»»å…ƒç´ éœ€æ±‚è¯„ä¼°çš„ç¤ºä¾‹é—®é¢˜åˆ—è¡¨ï¼Œå¦‚æœç­”æ¡ˆæ˜¯*æ˜¯*ï¼Œåˆ™ç›¸å…³çš„ä¿¡ä»»å…ƒç´ ä¼šæ‰“å‹¾ã€‚
- en: '| Question | Fairness | Explainability | Privacy | Robustness | Safety |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| é—®é¢˜ | å…¬å¹³æ€§ | å¯è§£é‡Šæ€§ | éšç§æ€§ | å¥å£®æ€§ | å®‰å…¨æ€§ |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Is there a regulation or law that applies to this use case? | ![16](assets/tick.png)
    | ![16](assets/tick.png) | ![16](assets/tick.png) | ![16](assets/tick.png) | ![16](assets/tick.png)
    |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| æ˜¯å¦æœ‰é€‚ç”¨äºæ­¤ä½¿ç”¨æ¡ˆä¾‹çš„æ³•è§„æˆ–æ³•å¾‹ï¼Ÿ | ![16](assets/tick.png) | ![16](assets/tick.png) | ![16](assets/tick.png)
    | ![16](assets/tick.png) | ![16](assets/tick.png) |'
- en: '| Will we use data on individuals? | ![16](assets/tick.png) | ![16](assets/tick.png)
    | ![16](assets/tick.png) |  | ![16](assets/tick.png) |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| æˆ‘ä»¬ä¼šä½¿ç”¨ä¸ªäººæ•°æ®å—ï¼Ÿ | ![16](assets/tick.png) | ![16](assets/tick.png) | ![16](assets/tick.png)
    |  | ![16](assets/tick.png) |'
- en: '| Are there disadvantaged segments of the population who may be disparately
    impacted by the biased outputs of this model? | ![16](assets/tick.png) |  |  |  |  |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| æ˜¯å¦æœ‰å—å½±å“çš„äººç¾¤åˆ†éƒ¨ä¼šå› ä¸ºæ¨¡å‹çš„åè§è¾“å‡ºè€Œå—åˆ°ä¸å…¬å¹³çš„å½±å“ï¼Ÿ | ![16](assets/tick.png) |  |  |  |  |'
- en: '| Are there humans who need to understand how this model functions? |  | ![16](assets/tick.png)
    |  |  |  |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| æ˜¯å¦æœ‰éœ€è¦äº†è§£è¿™ä¸ªæ¨¡å‹åŠŸèƒ½çš„äººç±»ï¼Ÿ |  | ![16](assets/tick.png) |  |  |  |'
- en: '| Are there any potential data quality issues? | ![16](assets/tick.png) | ![16](assets/tick.png)
    |  | ![16](assets/tick.png) |  |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| æ˜¯å¦å­˜åœ¨ä»»ä½•æ½œåœ¨çš„æ•°æ®è´¨é‡é—®é¢˜ï¼Ÿ | ![16](assets/tick.png) | ![16](assets/tick.png) |  | ![16](assets/tick.png)
    |  |'
- en: '| Do we know of attacks where data or model components could be exposed in
    an unintended manner? |  |  | ![16](assets/tick.png) | ![16](assets/tick.png)
    | ![16](assets/tick.png) |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| æˆ‘ä»¬æ˜¯å¦çŸ¥é“æœ‰æ”»å‡»å¯èƒ½ä¼šä½¿æ•°æ®æˆ–æ¨¡å‹ç»„ä»¶ä»¥æ„å¤–æ–¹å¼æš´éœ²ï¼Ÿ |  |  | ![16](assets/tick.png) | ![16](assets/tick.png)
    | ![16](assets/tick.png) |'
- en: Letâ€™s consider an example. Suppose you are working for an educational technology
    (EdTech) company in the US, building a product that automatically grades individualsâ€™
    writing samples. The US governmentâ€™s [Office of Civil Rights prohibits discrimination](https://oreil.ly/jY6Iw)
    on the basis of race, color, national origin, sex, disability, and age. While
    your company does not directly use individualsâ€™ demographic data to grade their
    writing, there is still potential for discrimination. Studies have shown that
    automated grading systems can be fooled by text that uses sophisticated words
    but poor writing quality.^([21](ch07.html#idm45621831020192)) In such situations,
    people whose educational background may not have exposed them to such words may
    be at a disadvantage.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªä¾‹å­ã€‚å‡è®¾ä½ åœ¨ç¾å›½ä¸€å®¶æ•™è‚²æŠ€æœ¯ï¼ˆEdTechï¼‰å…¬å¸å·¥ä½œï¼Œæ­£åœ¨å¼€å‘ä¸€æ¬¾èƒ½å¤Ÿè‡ªåŠ¨è¯„åˆ†ä¸ªäººå†™ä½œæ ·æœ¬çš„äº§å“ã€‚ç¾å›½æ”¿åºœçš„[æ°‘æƒåŠå…¬å®¤ç¦æ­¢åŸºäºç§æ—ã€è‚¤è‰²ã€å›½ç±ã€æ€§åˆ«ã€æ®‹ç–¾å’Œå¹´é¾„çš„æ­§è§†](https://oreil.ly/jY6Iw)ã€‚è™½ç„¶ä½ çš„å…¬å¸å¹¶ä¸ç›´æ¥ä½¿ç”¨ä¸ªäººçš„äººå£ç»Ÿè®¡æ•°æ®æ¥è¯„åˆ†ä»–ä»¬çš„å†™ä½œï¼Œä½†ä»å­˜åœ¨æ­§è§†çš„æ½œåŠ›ã€‚ç ”ç©¶è¡¨æ˜ï¼Œè‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿå¯èƒ½ä¼šå—åˆ°ä½¿ç”¨å¤æ‚è¯æ±‡ä½†å†™ä½œè´¨é‡ä¸ä½³çš„æ–‡æœ¬æ‰€æ¬ºéª—ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé‚£äº›æ•™è‚²èƒŒæ™¯æœªæ›¾æ¥è§¦åˆ°è¿™äº›è¯æ±‡çš„äººå¯èƒ½å¤„äºä¸åˆ©åœ°ä½ã€‚
- en: It is important to ensure that models are being trained on examples where quality
    of writing is not so heavily correlated with the number of syllables in each word
    or, better yet, on examples in which large words are misused as [malapropisms](https://oreil.ly/cO5Kw).
    It would be helpful to have a human in the loop to spot places where the writerâ€™s
    use of large words not only does not contribute to the essayâ€™s quality but actively
    detracts from it.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®ä¿æ¨¡å‹åœ¨ä¾‹å­ä¸Šè®­ç»ƒæ—¶é‡è¦çš„ä¸€ç‚¹æ˜¯ï¼Œå†™ä½œè´¨é‡ä¸åº”è¿‡åˆ†ä¸æ¯ä¸ªè¯çš„éŸ³èŠ‚æ•°ç›¸å…³ï¼Œæˆ–è€…æ›´å¥½çš„æƒ…å†µæ˜¯ï¼Œè®­ç»ƒåœ¨å¤§è¯è¢«è¯¯ç”¨ä¸º[æ»‘ç¨½é”™è¯¯](https://oreil.ly/cO5Kw)çš„ä¾‹å­ä¸Šã€‚æœ€å¥½èƒ½å¤Ÿæœ‰äººå‚ä¸ä»¥å‘ç°ä½œå®¶ä½¿ç”¨å¤§è¯ä¸ä»…ä¸æå‡æ–‡ç« è´¨é‡ï¼Œåè€Œé™ä½å…¶è´¨é‡çš„åœ°æ–¹ã€‚
- en: 'In this example, the trust elements with the highest need are:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæœ€éœ€è¦çš„ä¿¡ä»»è¦ç´ åŒ…æ‹¬ï¼š
- en: '*Fairness* across writing samples collected across relevant demographic categories'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å…¬æ­£æ€§*ï¼Œè·¨ç›¸å…³äººå£ç»Ÿè®¡ç±»åˆ«æ”¶é›†çš„å†™ä½œæ ·æœ¬'
- en: '*Robustness* to changes in vernacular and level of vocabulary sophistication'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¯¹äºæ–¹è¨€å’Œè¯æ±‡å¤æ‚ç¨‹åº¦çš„å˜åŒ–å…·æœ‰é²æ£’æ€§*'
- en: '*Explainability*, so that teachers and students are able to understand how
    to improve their writing'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¯è§£é‡Šæ€§*ï¼Œä»¥ä¾¿æ•™å¸ˆå’Œå­¦ç”Ÿèƒ½å¤Ÿç†è§£å¦‚ä½•æ”¹å–„ä»–ä»¬çš„å†™ä½œ'
- en: After youâ€™ve assessed needs, the next phase is to decide on metrics and their
    thresholds. This is very specific to your domain of application and use case.
    Generally, your stakeholders should have the requisite domain knowledge to ascertain
    which metrics would be most useful.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¯„ä¼°éœ€æ±‚åï¼Œä¸‹ä¸€æ­¥æ˜¯å†³å®šæŒ‡æ ‡åŠå…¶é˜ˆå€¼ã€‚è¿™å¯¹äºæ‚¨çš„åº”ç”¨é¢†åŸŸå’Œä½¿ç”¨æ¡ˆä¾‹éå¸¸å…·ä½“ã€‚é€šå¸¸æ¥è¯´ï¼Œæ‚¨çš„åˆ©ç›Šç›¸å…³è€…åº”è¯¥å…·å¤‡é¢†åŸŸçŸ¥è¯†ï¼Œä»¥ç¡®å®šå“ªäº›æŒ‡æ ‡æœ€ä¸ºæœ‰ç”¨ã€‚
- en: A good general rule of thumb is to first check to see if any default rules of
    the domain apply. If not, use statistical significance tests. In our disparate
    impact (DI) example, for an ML project in the hiring domain, the EEOC 80-20 rule
    applies. However, for other applications of DI, you could check if it is extreme
    enough to warrant fairness concerns. You might use bootstrap sampling or permutation
    to generate a null distribution for DI, then obtain the *p*-value for the computed
    metric with respect to that null distribution.^([22](ch07.html#idm45621831006480))
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¾ˆå¥½çš„ä¸€èˆ¬è§„åˆ™æ˜¯é¦–å…ˆæ£€æŸ¥é¢†åŸŸä¸­æ˜¯å¦é€‚ç”¨ä»»ä½•é»˜è®¤è§„åˆ™ã€‚å¦‚æœæ²¡æœ‰ï¼Œè¯·ä½¿ç”¨ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒã€‚åœ¨æˆ‘ä»¬çš„ä¸å¹³ç­‰å½±å“ï¼ˆDIï¼‰ç¤ºä¾‹ä¸­ï¼Œå¯¹äºæ‹›è˜é¢†åŸŸçš„ ML é¡¹ç›®ï¼Œé€‚ç”¨
    EEOC 80-20 è§„åˆ™ã€‚ç„¶è€Œï¼Œå¯¹äº DI çš„å…¶ä»–åº”ç”¨ï¼Œå¯ä»¥æ£€æŸ¥å…¶æ˜¯å¦è¶³å¤Ÿæç«¯ï¼Œä»è€Œå¼•èµ·å…¬å¹³æ€§å…³åˆ‡ã€‚æ‚¨å¯ä»¥ä½¿ç”¨è‡ªä¸¾æŠ½æ ·æˆ–ç½®æ¢æ¥ç”Ÿæˆ DI çš„é›¶å‡è®¾åˆ†å¸ƒï¼Œç„¶åé’ˆå¯¹è¯¥é›¶å‡è®¾åˆ†å¸ƒè·å–è®¡ç®—åº¦é‡çš„
    *p* å€¼ã€‚^([22](ch07.html#idm45621831006480))
- en: Evaluation and Feedback
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯„ä¼°å’Œåé¦ˆ
- en: 'After everything is said and done, you need to evaluate if, and how successfully,
    you incorporated the trust elements into your analysis. This is a bit more involved
    than just checking that acceptable ranges or thresholds for all relevant metrics
    are satisfied. Some element-specific considerations that you may need to tackle
    are as follows:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰€æœ‰äº‹æƒ…éƒ½è§£å†³ä¹‹åï¼Œæ‚¨éœ€è¦è¯„ä¼°æ‚¨å¦‚ä½•æˆåŠŸåœ°å°†ä¿¡ä»»å…ƒç´ çº³å…¥æ‚¨çš„åˆ†æä¸­ã€‚è¿™æ¯”ä»…ä»…æ£€æŸ¥æ‰€æœ‰ç›¸å…³æŒ‡æ ‡çš„å¯æ¥å—èŒƒå›´æˆ–é˜ˆå€¼æ˜¯å¦æ»¡è¶³è¦å¤æ‚ä¸€äº›ã€‚æ‚¨å¯èƒ½éœ€è¦è§£å†³ä¸€äº›ç‰¹å®šäºå…ƒç´ çš„è€ƒè™‘ï¼Œå¦‚ä¸‹ï¼š
- en: Fairness
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: å…¬å¹³æ€§
- en: Choose a pre-processing, in-processing, or post-processing mitigation technique
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€‰æ‹©é¢„å¤„ç†ã€å¤„ç†ä¸­æˆ–åå¤„ç†çš„ç¼“è§£æŠ€æœ¯
- en: Perform risk assessment of proceeding with or without mitigation of demographic
    bias at the data, model, or prediction level
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹æ˜¯å¦è¿›è¡Œäººå£ç»Ÿè®¡åè§çš„æ•°æ®ã€æ¨¡å‹æˆ–é¢„æµ‹çº§åˆ«çš„ç¼“è§£è¿›è¡Œé£é™©è¯„ä¼°
- en: Ensure that unbiasing the algorithm for specific user segments does not introduce
    additional bias
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡®ä¿ä¸ºç‰¹å®šç”¨æˆ·æ®µè°ƒæ•´ç®—æ³•ä¸ä¼šå¼•å…¥é¢å¤–çš„åè§
- en: Explainability
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: å¯è§£é‡Šæ€§
- en: Stakeholder feedback regarding effectiveness of the explainability techniques
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ©ç›Šç›¸å…³è€…å¯¹å¯è§£é‡Šæ€§æŠ€æœ¯æ•ˆæœçš„åé¦ˆ
- en: Ensuring that the explanations are actually augmenting the expertise of human
    SMEs, i.e., they are not suffering automation bias by being overreliant on the
    explanations
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡®ä¿è§£é‡Šå®é™…ä¸Šå¢å¼ºäº†äººç±»ä¸“å®¶çš„ä¸“ä¸šçŸ¥è¯†ï¼Œå³å®ƒä»¬ä¸ä¼šå› è¿‡åº¦ä¾èµ–è§£é‡Šè€Œé­å—è‡ªåŠ¨åŒ–åè§
- en: Privacy
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: éšç§ä¿æŠ¤
- en: Choice of modeling step to introduce differential privacy (DP) noise and the
    optimal amount of DP noise for privacy-utility trade-off
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: é€‰æ‹©å¼•å…¥å·®åˆ†éšç§ï¼ˆDPï¼‰å™ªéŸ³çš„å»ºæ¨¡æ­¥éª¤ä»¥åŠéšç§æ•ˆç”¨æƒè¡¡çš„æœ€ä½³ DP å™ªéŸ³é‡
- en: Robustness and safety
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: é²æ£’æ€§å’Œå®‰å…¨æ€§
- en: Making sure that robust methods that protect against certain adversarial attacks
    do not make the ML system more vulnerable against other relevant attacks
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡®ä¿ä¿æŠ¤å…å—ç‰¹å®šå¯¹æŠ—æ€§æ”»å‡»çš„é²æ£’æ–¹æ³•ä¸ä¼šä½¿ ML ç³»ç»Ÿæ›´å®¹æ˜“å—åˆ°å…¶ä»–ç›¸å…³æ”»å‡»
- en: Prioritizing robustness/safety specifications and ensuring high-priority specifications
    are given higher weights or always satisfied
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼˜å…ˆè€ƒè™‘é²æ£’æ€§/å®‰å…¨æ€§è§„èŒƒï¼Œå¹¶ç¡®ä¿é«˜ä¼˜å…ˆçº§è§„èŒƒè·å¾—æ›´é«˜æƒé‡æˆ–å§‹ç»ˆè¢«æ»¡è¶³
- en: Trustworthiness and MLOps
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯ä¿¡åº¦å’Œ MLOps
- en: Itâ€™s important to incorporate trust elements into your ML pipelines, but itâ€™s
    also important to ensure that your pipelines stay functional over time, even under
    changing configurations. Thus, in this section, we discuss a number of engineering
    aspects of trust that can complicate things, including challenges around scaling,
    data drift, and model monitoring and observability.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ä¿¡ä»»å…ƒç´ çº³å…¥ ML æµæ°´çº¿æ˜¯å¾ˆé‡è¦çš„ï¼Œä½†åŒæ—¶ä¹Ÿè¦ç¡®ä¿æ‚¨çš„æµæ°´çº¿åœ¨éšæ—¶é—´å˜åŒ–çš„é…ç½®ä¸‹ä¿æŒåŠŸèƒ½æ­£å¸¸ã€‚å› æ­¤ï¼Œåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä¸€äº›ä¼šå¤æ‚åŒ–äº‹æƒ…çš„ä¿¡ä»»å·¥ç¨‹æ–¹é¢ï¼ŒåŒ…æ‹¬æ‰©å±•ã€æ•°æ®æ¼‚ç§»ä»¥åŠæ¨¡å‹ç›‘æ§å’Œå¯è§‚å¯Ÿæ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚
- en: Scaling challenges
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ‰©å±•æŒ‘æˆ˜
- en: Beyond logistical limitations, your ability to incorporate trust elements into
    ML pipelines may be constrained by how much computing power your company can realistically
    afford. For example, both the in-processing techniques discussed in [ChapterÂ 1](ch01.html#chapter1)
    are quite computationally involved. For adversarial debiasing, this is a result
    of the iterative optimization of two neural networks. For HGR, the culprit is
    the computation-intensive kernel density calculation, to calculate the joint density
    of the output and sensitive feature(s). Among explainability methods, exact calculation
    of SHAP values is notoriously computation-intensive.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†åå‹¤é™åˆ¶ä¹‹å¤–ï¼Œæ‚¨å°†ä¿¡ä»»å…ƒç´ çº³å…¥MLç®¡é“çš„èƒ½åŠ›å¯èƒ½å—åˆ°å…¬å¸å®é™…å¯ä»¥æ‰¿å—çš„è®¡ç®—èƒ½åŠ›çš„é™åˆ¶ã€‚ä¾‹å¦‚ï¼Œè®¨è®ºçš„ä¸¤ç§å¤„ç†æŠ€æœ¯åœ¨è®¡ç®—ä¸Šéƒ½éå¸¸å¤æ‚ã€‚å¯¹äºå¯¹æŠ—æ€§å»åå·®ï¼Œè¿™æ˜¯ä¸¤ä¸ªç¥ç»ç½‘ç»œçš„è¿­ä»£ä¼˜åŒ–ç»“æœã€‚å¯¹äºHGRï¼Œç½ªé­ç¥¸é¦–æ˜¯è®¡ç®—å¯†é›†çš„æ ¸å¯†åº¦è®¡ç®—ï¼Œç”¨äºè®¡ç®—è¾“å‡ºå’Œæ•æ„Ÿç‰¹å¾çš„è”åˆå¯†åº¦ã€‚åœ¨å¯è§£é‡Šæ€§æ–¹æ³•ä¸­ï¼Œè®¡ç®—SHAPå€¼çš„ç²¾ç¡®è®¡ç®—å› è®¡ç®—å¯†é›†è€Œè‡­åæ˜­è‘—ã€‚
- en: When faced with scaling challenges, look around and get creative! Oftentimes
    youâ€™ll find a solution in the literature or open source community that can solve
    your problem. For example, FastSHAP provides fast, but approximate, computation
    of Shapley values.^([23](ch07.html#idm45621830978528)) Instead of using a non-scalable
    Python library, try writing your own code in Scalaâ€”or use a package like [LiFT](https://oreil.ly/n5Ll3)â€”to
    perform fairness evaluation for large volumes of data.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: é¢å¯¹æ‰©å±•æŒ‘æˆ˜æ—¶ï¼Œç¯é¡¾å››å‘¨ï¼Œå‘æŒ¥åˆ›é€ åŠ›ï¼å¾€å¾€ä½ ä¼šåœ¨æ–‡çŒ®æˆ–å¼€æºç¤¾åŒºä¸­æ‰¾åˆ°è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥è§£å†³ä½ çš„é—®é¢˜ã€‚ä¾‹å¦‚ï¼ŒFastSHAPæä¾›äº†å¿«é€Ÿä½†è¿‘ä¼¼çš„Shapleyå€¼è®¡ç®—ã€‚^([23](ch07.html#idm45621830978528))
    ä¸å…¶ä½¿ç”¨ä¸å¯æ‰©å±•çš„Pythonåº“ï¼Œä¸å¦‚å°è¯•ç”¨Scalaç¼–å†™è‡ªå·±çš„ä»£ç ï¼Œæˆ–è€…ä½¿ç”¨ç±»ä¼¼[LiFT](https://oreil.ly/n5Ll3)çš„åŒ…ï¼Œåœ¨å¤§é‡æ•°æ®çš„æƒ…å†µä¸‹æ‰§è¡Œå…¬å¹³æ€§è¯„ä¼°ã€‚
- en: Data drift
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•°æ®æ¼‚ç§»
- en: Aspects of incoming data used for building an ML model may change over time.
    For example, features may be deleted or added, new categories may be added to
    a categorical feature, data quality might improve or deteriorate, and distributions
    of one or more key features may shift. You need to have a process in place for
    continuously integrating such changes into the model-training and evaluation cycleâ€”and
    that extends to trust elements as well. Shifted or otherwise modified features
    affect a trust metricâ€™s estimated value *and* estimation uncertainty.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºæ„å»ºMLæ¨¡å‹çš„å…¥ç«™æ•°æ®çš„å„ä¸ªæ–¹é¢å¯èƒ½éšæ—¶é—´å˜åŒ–ã€‚ä¾‹å¦‚ï¼Œç‰¹å¾å¯èƒ½ä¼šè¢«åˆ é™¤æˆ–æ·»åŠ ï¼Œåˆ†ç±»ç‰¹å¾å¯èƒ½ä¼šæ·»åŠ æ–°çš„ç±»åˆ«ï¼Œæ•°æ®è´¨é‡å¯èƒ½ä¼šæ”¹å–„æˆ–æ¶åŒ–ï¼Œä¸€ä¸ªæˆ–å¤šä¸ªå…³é”®ç‰¹å¾çš„åˆ†å¸ƒå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚æ‚¨éœ€è¦å»ºç«‹ä¸€ä¸ªæµç¨‹ï¼ŒæŒç»­å°†è¿™äº›å˜åŒ–æ•´åˆåˆ°æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å‘¨æœŸä¸­ï¼Œå¹¶ä¸”è¿™ä¹Ÿæ¶‰åŠåˆ°ä¿¡ä»»å…ƒç´ ã€‚å˜åŒ–æˆ–ä¿®æ”¹åçš„ç‰¹å¾ä¼šå½±å“ä¿¡ä»»åº¦é‡çš„ä¼°è®¡å€¼
    *ä»¥åŠ* ä¼°è®¡ä¸ç¡®å®šæ€§ã€‚
- en: Model monitoring and observability
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¨¡å‹ç›‘æ§ä¸å¯è§‚å¯Ÿæ€§
- en: These two well-known concepts in DevOps are equally relevant for MLOps.^([24](ch07.html#idm45621830966240))
    Broadly speaking, *monitoring* refers to collectingâ€”often through samplingâ€”metrics,
    logs, or other artifacts from software systems to enable post hoc analysis and
    learning. In comparison, *observability* is a property of the software system
    itself. It allows the system to make key structured artifacts available to the
    development team so they can take meaningful action quickly to troubleshoot the
    system.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸¤ä¸ªåœ¨DevOpsä¸­å¹¿ä¸ºäººçŸ¥çš„æ¦‚å¿µå¯¹MLOpsåŒæ ·é€‚ç”¨ã€‚^([24](ch07.html#idm45621830966240)) ä¸€èˆ¬æ¥è¯´ï¼Œ*ç›‘æ§*
    æŒ‡çš„æ˜¯é€šè¿‡æŠ½æ ·æ”¶é›†è½¯ä»¶ç³»ç»Ÿä¸­çš„æŒ‡æ ‡ã€æ—¥å¿—æˆ–å…¶ä»–æ–‡ç‰©ï¼Œä»¥æ”¯æŒäº‹ååˆ†æå’Œå­¦ä¹ ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ*å¯è§‚å¯Ÿæ€§* æ˜¯è½¯ä»¶ç³»ç»Ÿæœ¬èº«çš„å±æ€§ã€‚å®ƒä½¿å¾—ç³»ç»Ÿå¯ä»¥å‘å¼€å‘å›¢é˜Ÿæä¾›å…³é”®çš„ç»“æ„åŒ–æ–‡ç‰©ï¼Œä»¥ä¾¿ä»–ä»¬èƒ½å¤Ÿå¿«é€Ÿé‡‡å–æœ‰æ„ä¹‰çš„è¡ŒåŠ¨æ¥æ’æŸ¥ç³»ç»Ÿé—®é¢˜ã€‚
- en: Method-agnostic monitoring of trust elements in ML models broadly corresponds
    to computing and recording metrics for every training and/or inference cycle (feature
    importance, bias metrics, and explanations of certain representative data points),
    and further analysis of the timelines of one or more such metrics, to troubleshoot
    pipeline issues in future iterations of training and inference.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸MLæ¨¡å‹ä¸­ä¿¡ä»»å…ƒç´ çš„æ–¹æ³•æ— å…³çš„ç›‘æ§å¹¿æ³›å¯¹åº”äºè®¡ç®—å¹¶è®°å½•æ¯ä¸ªè®­ç»ƒå’Œ/æˆ–æ¨ç†å‘¨æœŸçš„æŒ‡æ ‡ï¼ˆç‰¹å¾é‡è¦æ€§ã€åè§æŒ‡æ ‡å’ŒæŸäº›ä»£è¡¨æ€§æ•°æ®ç‚¹çš„è§£é‡Šï¼‰ï¼Œå¹¶è¿›ä¸€æ­¥åˆ†æä¸€ä¸ªæˆ–å¤šä¸ªæ­¤ç±»æŒ‡æ ‡çš„æ—¶é—´çº¿ï¼Œä»¥æ’é™¤å°†æ¥è®­ç»ƒå’Œæ¨ç†è¿­ä»£ä¸­çš„ç®¡é“é—®é¢˜ã€‚
- en: By contrast, observability in trust metrics is more proactive. Specific combinations
    of trust elements can be combined with one or more technical factorsâ€”such as causality,
    sparsity, and uncertainty quantificationâ€”to design focused resources. In the context
    of the EdTech example earlier, say you want to measure the fairness of predictions
    toward a demographic group of interest, because there is a known insufficient
    sample issue for that demographic group. When you calculate the bias metric, you
    would do well to monitor uncertainty. This is an example of trust element observability.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸æ¯”ä¹‹ä¸‹ï¼Œåœ¨ä¿¡ä»»åº¦é‡ä¸­çš„å¯è§‚å¯Ÿæ€§æ›´å…·å‰ç»æ€§ã€‚ç‰¹å®šçš„ä¿¡ä»»å…ƒç´ ç»„åˆå¯ä»¥ä¸ä¸€ä¸ªæˆ–å¤šä¸ªæŠ€æœ¯å› ç´ ç»“åˆä½¿ç”¨â€”â€”æ¯”å¦‚å› æœå…³ç³»ã€ç¨€ç–æ€§å’Œä¸ç¡®å®šæ€§é‡åŒ–â€”â€”æ¥è®¾è®¡ä¸“æ³¨çš„èµ„æºã€‚åœ¨ä¹‹å‰çš„EdTechç¤ºä¾‹ä¸­ï¼Œå‡è®¾ä½ æƒ³è¦è¡¡é‡å¯¹ä¸€ä¸ªäººç¾¤åˆ©ç›Šçš„é¢„æµ‹å…¬å¹³æ€§ï¼Œå› ä¸ºå·²çŸ¥è¯¥äººç¾¤çš„æ ·æœ¬ä¸è¶³é—®é¢˜ã€‚å½“ä½ è®¡ç®—åå·®åº¦é‡æ—¶ï¼Œæœ€å¥½ç›‘æ§ä¸ç¡®å®šæ€§ã€‚è¿™æ˜¯ä¿¡ä»»å…ƒç´ å¯è§‚å¯Ÿæ€§çš„ä¸€ä¸ªä¾‹å­ã€‚
- en: Techniques
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æŠ€æœ¯
- en: Weâ€™ll wrap this chapter up by introducing the basics of a few methods that are
    helpful in tackling drift and other quality issues in data or model metrics, enabling
    monitoring and observability.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é€šè¿‡ä»‹ç»å‡ ç§æ–¹æ³•çš„åŸºç¡€æ¥ç»“æŸè¿™ä¸€ç« ï¼Œè¿™äº›æ–¹æ³•æœ‰åŠ©äºè§£å†³æ•°æ®æˆ–æ¨¡å‹æŒ‡æ ‡ä¸­çš„æ¼‚ç§»å’Œå…¶ä»–è´¨é‡é—®é¢˜ï¼Œä»è€Œå®ç°ç›‘æ§å’Œå¯è§‚å¯Ÿæ€§ã€‚
- en: Anomaly detection
  id: totrans-257
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å¼‚å¸¸æ£€æµ‹
- en: Think of *anomalies* as outliers with context. They are not only rare events
    in a stream of otherwise normal data points but often represent problems of an
    underlying feature. For example, if the five most recent test datasets show a
    sudden drop in grading accuracy among a sensitive demographic group, this most
    likely points to a broader issue about the quality of the writing samples in newer
    datasets. If you have only one outlier, however, it may or may not be just a rare
    observation as part of a *normal* data stream.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: å°†*å¼‚å¸¸*è§†ä¸ºå¸¦æœ‰èƒŒæ™¯ä¿¡æ¯çš„å¼‚å¸¸å€¼ã€‚å®ƒä»¬ä¸ä»…æ˜¯åœ¨é€šå¸¸æ•°æ®ç‚¹æµä¸­çš„ç½•è§äº‹ä»¶ï¼Œè€Œä¸”ç»å¸¸ä»£è¡¨æ½œåœ¨ç‰¹å¾é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæœ€è¿‘çš„äº”ä¸ªæµ‹è¯•æ•°æ®é›†æ˜¾ç¤ºæŸä¸€æ•æ„Ÿäººç¾¤çš„è¯„åˆ†å‡†ç¡®æ€§çªç„¶ä¸‹é™ï¼Œè¿™å¾ˆå¯èƒ½æŒ‡å‘æ–°æ•°æ®é›†ä¸­å†™ä½œæ ·æœ¬è´¨é‡çš„æ›´å¹¿æ³›é—®é¢˜ã€‚ç„¶è€Œï¼Œå¦‚æœåªæœ‰ä¸€ä¸ªå¼‚å¸¸å€¼ï¼Œå®ƒå¯èƒ½åªæ˜¯æ­£å¸¸æ•°æ®æµä¸­çš„ä¸€ä¸ªç½•è§è§‚å¯Ÿç»“æœï¼Œä¹Ÿå¯èƒ½ä¸æ˜¯ã€‚
- en: 'Here are two popular methods of anomaly detection:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸¤ç§æµè¡Œçš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼š
- en: '*STL* (seasonal-trend decomposition using Loess) fits a Loess smoother to time
    series data to remove temporal components such as seasonality and trend, then
    examines the residuals to designate points above or below certain thresholds as
    anomalies. The thresholds are set at a certain multiple of the interquartile range
    (or IQR, defined as the difference between the 75th and 25th percentiles).'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*STL*ï¼ˆLoesså­£èŠ‚è¶‹åŠ¿åˆ†è§£ï¼‰å°†Loesså¹³æ»‘å™¨æ‹Ÿåˆåˆ°æ—¶é—´åºåˆ—æ•°æ®ä¸­ï¼Œä»¥ç§»é™¤å­£èŠ‚æ€§å’Œè¶‹åŠ¿ç­‰æ—¶é—´ç»„æˆéƒ¨åˆ†ï¼Œç„¶åæ£€æŸ¥æ®‹å·®ä»¥ç¡®å®šé«˜äºæˆ–ä½äºæŸäº›é˜ˆå€¼çš„ç‚¹æ˜¯å¦ä¸ºå¼‚å¸¸å€¼ã€‚é˜ˆå€¼è®¾ç½®ä¸ºå››åˆ†ä½è·ï¼ˆIQRï¼‰çš„æŸä¸ªå€æ•°ï¼ˆIQRå®šä¹‰ä¸ºç¬¬75ç™¾åˆ†ä½æ•°ä¸ç¬¬25ç™¾åˆ†ä½æ•°ä¹‹å·®ï¼‰ã€‚'
- en: The *generalized extreme studentized deviate* (GESD) test iteratively adjusts
    detection thresholds by removing higher-percentile sample points from the data
    considered for threshold computation. GESD is more computation-intensive than
    STL, but less prone to false positives.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¹¿ä¹‰æç«¯å­¦ç”ŸåŒ–åå·®*ï¼ˆGESDï¼‰æµ‹è¯•é€šè¿‡ä»è€ƒè™‘ç”¨äºé˜ˆå€¼è®¡ç®—çš„æ•°æ®ä¸­ç§»é™¤æ›´é«˜ç™¾åˆ†ä½æ•°çš„æ ·æœ¬ç‚¹æ¥è¿­ä»£è°ƒæ•´æ£€æµ‹é˜ˆå€¼ã€‚GESDæ¯”STLæ›´æ¶ˆè€—è®¡ç®—èµ„æºï¼Œä½†è¯¯æŠ¥ç‡è¾ƒä½ã€‚'
- en: Change point detection
  id: totrans-262
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å˜ç‚¹æ£€æµ‹
- en: 'Change point detection methods aim to detect the points within a time-series
    dataset where the data-generating process itself changes. This is a more permanent
    change than anomaly detection. There are two types of change point detection methods:
    offline and online. Offline methods do post hoc analysis of the time series, while
    online methods detect change points in a data *stream*. As you can guess, online
    change point detection in data/model metrics is very relevant to the MLOps problems
    we have discussed, in particular when observability is coupled with knowledge
    of the parameters that can cause such changes.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: å˜ç‚¹æ£€æµ‹æ–¹æ³•æ—¨åœ¨æ£€æµ‹æ—¶é—´åºåˆ—æ•°æ®é›†ä¸­æ•°æ®ç”Ÿæˆè¿‡ç¨‹æœ¬èº«å‘ç”Ÿå˜åŒ–çš„ç‚¹ã€‚è¿™ç§å˜åŒ–æ¯”å¼‚å¸¸æ£€æµ‹æ›´ä¸ºæ°¸ä¹…ã€‚æœ‰ä¸¤ç§å˜ç‚¹æ£€æµ‹æ–¹æ³•ï¼šç¦»çº¿å’Œåœ¨çº¿ã€‚ç¦»çº¿æ–¹æ³•å¯¹æ—¶é—´åºåˆ—è¿›è¡Œäº‹ååˆ†æï¼Œè€Œåœ¨çº¿æ–¹æ³•æ£€æµ‹æ•°æ®æµä¸­çš„å˜ç‚¹ã€‚æ­£å¦‚ä½ å¯ä»¥çŒœåˆ°çš„é‚£æ ·ï¼Œæ•°æ®/æ¨¡å‹æŒ‡æ ‡ä¸­çš„åœ¨çº¿å˜ç‚¹æ£€æµ‹ä¸æˆ‘ä»¬è®¨è®ºè¿‡çš„MLOpsé—®é¢˜éå¸¸ç›¸å…³ï¼Œç‰¹åˆ«æ˜¯å½“å¯è§‚å¯Ÿæ€§ä¸å¯èƒ½å¯¼è‡´è¿™äº›å˜åŒ–çš„å‚æ•°çš„çŸ¥è¯†ç»“åˆåœ¨ä¸€èµ·æ—¶ã€‚
- en: Control charts
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ§åˆ¶å›¾
- en: 'Statistical process control charts have been a mainstay of industrial quality
    control methods for decades. Control charts incorporate even more causal knowledge
    into the timeline being analyzed than do anomaly or change point detection.^([25](ch07.html#idm45621830937216))
    To put it simply, a number of well-defined metrics are calculated for subgroups
    of interest and tracked over time. These could include:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°åå¹´æ¥ï¼Œç»Ÿè®¡è¿‡ç¨‹æ§åˆ¶å›¾è¡¨ä¸€ç›´æ˜¯å·¥ä¸šè´¨é‡æ§åˆ¶æ–¹æ³•çš„æ”¯æŸ±ã€‚æ§åˆ¶å›¾è¡¨åœ¨åˆ†ææ—¶é—´çº¿æ—¶æ¯”å¼‚å¸¸æˆ–å˜æ›´ç‚¹æ£€æµ‹åŒ…å«æ›´å¤šå› æœçŸ¥è¯†ã€‚^([25](ch07.html#idm45621830937216))
    ç®€è€Œè¨€ä¹‹ï¼Œä¸ºæ„Ÿå…´è¶£çš„å­ç¾¤ä½“è®¡ç®—å¤šä¸ªæ˜ç¡®å®šä¹‰çš„æŒ‡æ ‡ï¼Œå¹¶éšæ—¶é—´è·Ÿè¸ªè¿™äº›æŒ‡æ ‡ã€‚è¿™äº›æŒ‡æ ‡å¯ä»¥åŒ…æ‹¬ï¼š
- en: Mean and standard deviation ( <math alttext="x overbar"><mover accent="true"><mi>x</mi>
    <mo>Â¯</mo></mover></math> and *s* chart)
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆ <math alttext="x overbar"><mover accent="true"><mi>x</mi> <mo>Â¯</mo></mover></math>
    å’Œ *s* å›¾è¡¨ï¼‰
- en: Fraction of positive/negative predictions (*p* and *np* chart)
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­£è´Ÿé¢„æµ‹çš„æ¯”ä¾‹ï¼ˆ*p* å’Œ *np* å›¾è¡¨ï¼‰
- en: The combination of multiple time points through a moving average (EWMA chart)
    or cumulative sums (CUSUM chart)
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ç§»åŠ¨å¹³å‡çº¿ï¼ˆEWMAå›¾è¡¨ï¼‰æˆ–ç´¯ç§¯å’Œï¼ˆCUSUMå›¾è¡¨ï¼‰ç»“åˆå¤šä¸ªæ—¶é—´ç‚¹
- en: Custom aggregate metrics (see example in [TableÂ 7-3](#table-control))
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è‡ªå®šä¹‰èšåˆæŒ‡æ ‡ï¼ˆè§[è¡¨Â 7-3](#table-control)ä¸­çš„ç¤ºä¾‹ï¼‰
- en: In the trusted MLOps context of the EdTech example, control charts can be used
    to ensure quality of *trustworthiness* of ML model outcomes. See [TableÂ 7-3](#table-control)
    for sample metrics that can be tracked across time for this purpose.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•™è‚²ç§‘æŠ€ç¤ºä¾‹çš„å¯ä¿¡MLOpsèƒŒæ™¯ä¸­ï¼Œæ§åˆ¶å›¾è¡¨å¯ç”¨äºç¡®ä¿MLæ¨¡å‹ç»“æœçš„*å¯ä¿¡åº¦*è´¨é‡ã€‚è¯¦è§[è¡¨Â 7-3](#table-control)ä¸­ï¼Œä¸ºæ­¤ç›®çš„è·¨æ—¶é—´è·Ÿè¸ªçš„ç¤ºä¾‹æŒ‡æ ‡ã€‚
- en: Table 7-3\. Example metrics to be tracked to ensure quality control of trust
    elements
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨7-3\. ç¤ºä¾‹æŒ‡æ ‡ï¼Œç”¨äºè·Ÿè¸ªä¿¡ä»»å…ƒç´ çš„è´¨é‡æ§åˆ¶
- en: '| Trust element | Additional factor | Metric | Aggregation |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| ä¿¡ä»»å…ƒç´  | é™„åŠ å› ç´  | æŒ‡æ ‡ | èšåˆ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Fairness |  | Disparate impact | Custom: ratio of proportions over sensitive
    versus non-sensitive subgroups |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| å…¬å¹³æ€§ |  | ä¸å¹³ç­‰å½±å“ | è‡ªå®šä¹‰ï¼šæ•æ„Ÿä¸éæ•æ„Ÿå­ç¾¤ä½“æ¯”ä¾‹çš„æ¯”ç‡ |'
- en: '| Fairness |  | Statistical parity | Mean over all samples |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| å…¬å¹³æ€§ |  | ç»Ÿè®¡å¹³ç­‰æ€§ | æ‰€æœ‰æ ·æœ¬çš„å¹³å‡å€¼ |'
- en: '| Robustness |  | Prediction difference in presence and absence of one or more
    sophisticated words | Mean over all samples |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| é²æ£’æ€§ |  | å­˜åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªå¤æ‚è¯è¯­æ—¶é¢„æµ‹å·®å¼‚ | æ‰€æœ‰æ ·æœ¬çš„å¹³å‡å€¼ |'
- en: '| Robustness | Uncertainty | Prediction difference in presence and absence
    of one or more sophisticated words | SD over all samples |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| é²æ£’æ€§ | ä¸ç¡®å®šæ€§ | å­˜åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªå¤æ‚è¯è¯­æ—¶é¢„æµ‹å·®å¼‚ | æ‰€æœ‰æ ·æœ¬çš„æ ‡å‡†å·® |'
- en: '| Explainability |  | LIME feature importance difference in presence and absence
    of a feature value | Mean over all samples |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| å¯è§£é‡Šæ€§ |  | LIMEç‰¹å¾é‡è¦æ€§åœ¨å­˜åœ¨å’Œä¸å­˜åœ¨ç‰¹å¾å€¼æ—¶çš„å·®å¼‚ | æ‰€æœ‰æ ·æœ¬çš„å¹³å‡å€¼ |'
- en: '| Explainability | Uncertainty | LIME feature importance difference in presence
    and absence of a feature value | SD over all samples |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| å¯è§£é‡Šæ€§ | ä¸ç¡®å®šæ€§ | LIMEç‰¹å¾é‡è¦æ€§åœ¨å­˜åœ¨å’Œä¸å­˜åœ¨ç‰¹å¾å€¼æ—¶çš„å·®å¼‚ | æ‰€æœ‰æ ·æœ¬çš„æ ‡å‡†å·® |'
- en: '| Explainability | Causality | Difference in counterfactual explanations |
    Mean over all samples |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| å¯è§£é‡Šæ€§ | å› æœæ€§ | åäº‹å®è§£é‡Šçš„å·®å¼‚ | æ‰€æœ‰æ ·æœ¬çš„å¹³å‡å€¼ |'
- en: '| Explainability and fairness |  | LIME feature importance difference in presence
    and absence of a feature value | Difference of means over sensitive and non-sensitive
    samples |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| å¯è§£é‡Šæ€§å’Œå…¬å¹³æ€§ |  | LIMEç‰¹å¾é‡è¦æ€§åœ¨å­˜åœ¨å’Œä¸å­˜åœ¨ç‰¹å¾å€¼æ—¶çš„å·®å¼‚ | å¯¹æ•æ„Ÿå’Œéæ•æ„Ÿæ ·æœ¬çš„å¹³å‡å·®å¼‚ |'
- en: Tip
  id: totrans-282
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æç¤º
- en: As an exercise, try to design metrics for quality control of more than one trust
    element, just like the last row in [TableÂ 7-3](#table-control). Give it a try!
    After you come up with some examples, try to augment additional factors, too.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºç»ƒä¹ ï¼Œå°è¯•è®¾è®¡ç”¨äºå¤šä¸ªä¿¡ä»»å…ƒç´ è´¨é‡æ§åˆ¶çš„æŒ‡æ ‡ï¼Œå°±åƒ[è¡¨Â 7-3](#table-control)ä¸­çš„æœ€åä¸€è¡Œã€‚è¯•è¯•å§ï¼åœ¨æå‡ºä¸€äº›ç¤ºä¾‹åï¼Œå°è¯•å¢åŠ é™„åŠ å› ç´ ã€‚
- en: Conclusion
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: When implementing real-world ML projects, thereâ€™s more to consider than deciding,
    coding up, and evaluating trust metrics. This chapter has covered several essential
    technical and nontechnical considerations.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®æ–½çœŸå®ä¸–ç•Œçš„MLé¡¹ç›®æ—¶ï¼Œé™¤äº†å†³ç­–ã€ç¼–ç å’Œè¯„ä¼°ä¿¡ä»»åº¦æŒ‡æ ‡å¤–ï¼Œè¿˜éœ€è¦è€ƒè™‘æ›´å¤šå› ç´ ã€‚æœ¬ç« æ¶µç›–äº†å‡ ä¸ªé‡è¦çš„æŠ€æœ¯å’ŒéæŠ€æœ¯è€ƒè™‘äº‹é¡¹ã€‚
- en: The technical considerations include evaluating cause and effect relationships,
    compressing your model, and estimating uncertainty when necessary. Also, donâ€™t
    forget to check for how these considerations interact with trust elements!
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ€æœ¯è€ƒè™‘äº‹é¡¹åŒ…æ‹¬è¯„ä¼°å› æœå…³ç³»ã€å‹ç¼©æ¨¡å‹ä»¥åŠå¿…è¦æ—¶ä¼°ç®—ä¸ç¡®å®šæ€§ã€‚è¿˜è¦è®°å¾—æ£€æŸ¥è¿™äº›è€ƒè™‘äº‹é¡¹å¦‚ä½•ä¸ä¿¡ä»»å…ƒç´ äº’åŠ¨ï¼
- en: You should always, always get buy-in from stakeholders beyond the ML team. As
    you work toward this, remember that technical and ethical debt management and
    risk management are two key reasons trustworthy ML methods are important to the
    broader organization.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '-   æ€»æ˜¯ç¡®ä¿ä»MLå›¢é˜Ÿä»¥å¤–çš„åˆ©ç›Šç›¸å…³è€…é‚£é‡Œè·å¾—æ”¯æŒã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œè¯·è®°ä½ï¼ŒæŠ€æœ¯å’Œä¼¦ç†å€ºåŠ¡ç®¡ç†ä»¥åŠé£é™©ç®¡ç†æ˜¯ä¿ƒä½¿å€¼å¾—ä¿¡èµ–çš„MLæ–¹æ³•å¯¹æ›´å¹¿æ³›ç»„ç»‡é‡è¦çš„ä¸¤ä¸ªå…³é”®åŸå› ã€‚'
- en: Finally, be mindful of scaling issues in large-scale trustworthy ML implementations.
    Even after you deploy the system in production, itâ€™s a good idea to continue monitoring
    and troubleshooting.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '-   æœ€åï¼Œè¦æ³¨æ„å¤§è§„æ¨¡å€¼å¾—ä¿¡èµ–çš„MLå®æ–½ä¸­çš„è§„æ¨¡é—®é¢˜ã€‚å³ä½¿åœ¨å°†ç³»ç»ŸæŠ•å…¥ç”Ÿäº§åï¼Œç»§ç»­ç›‘æ§å’Œè§£å†³é—®é¢˜ä¹Ÿæ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚'
- en: ^([1](ch07.html#idm45621832115168-marker)) Check out Judea Pearlâ€™s books for
    deeper dives into causal inference, such as [*The Book of Why*](https://oreil.ly/LUcZh)
    (Basic Books, 2018).
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch07.html#idm45621832115168-marker)) æ·±å…¥ç ”ç©¶å› æœæ¨æ–­çš„ä¹¦ç±ï¼Œä¾‹å¦‚Judea Pearlçš„è‘—ä½œ [*â€œä¸ºä»€ä¹ˆçš„ä¹¦â€*](https://oreil.ly/LUcZh)
    (Basic Books, 2018)ã€‚
- en: ^([2](ch07.html#idm45621831819760-marker)) Christoph Molnar gives a great explanation
    and examples of counterfactual explanations in his [book on interpretable ML](https://oreil.ly/JvCHc).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch07.html#idm45621831819760-marker)) Christoph Molnar åœ¨ä»–çš„ [â€œå¯è§£é‡Šæœºå™¨å­¦ä¹ â€](https://oreil.ly/JvCHc)
    ä¸€ä¹¦ä¸­å¯¹åäº‹å®è§£é‡Šè¿›è¡Œäº†æ·±å…¥è§£é‡Šå’Œä¸¾ä¾‹ã€‚
- en: ^([3](ch07.html#idm45621831818272-marker)) Matt Kusner et al., [â€œCounterfactual
    Fairnessâ€](https://oreil.ly/I2r9t), *NeurIPS-2017* (2017); Timothy Christensen
    and Benjamin Connault, [â€œCounterfactual Sensitivity and Robustnessâ€](https://arxiv.org/abs/1904.00989),
    *arXiv preprint* (2019).
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch07.html#idm45621831818272-marker)) Matt Kusner ç­‰äººçš„ç ”ç©¶ï¼Œ[â€œåäº‹å®å…¬å¹³æ€§â€](https://oreil.ly/I2r9t)ï¼Œ*NeurIPS-2017*
    (2017)ï¼›Timothy Christensen å’Œ Benjamin Connault çš„ç ”ç©¶ï¼Œ[â€œåäº‹å®æ•æ„Ÿæ€§å’Œé²æ£’æ€§â€](https://arxiv.org/abs/1904.00989)ï¼Œ*arXiv
    é¢„å°æœ¬* (2019)ã€‚
- en: ^([4](ch07.html#idm45621831716192-marker)) For more technical details on specific
    methods, we recommend the review papers by [R. Reed](https://oreil.ly/TcUjt) and
    [Davis Blalock et al.](https://oreil.ly/0VS7R), as well as the papers in their
    references.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch07.html#idm45621831716192-marker)) å¦‚éœ€æ›´å¤šå…³äºç‰¹å®šæ–¹æ³•çš„æŠ€æœ¯ç»†èŠ‚ï¼Œè¯·å‚é˜…[R. Reed](https://oreil.ly/TcUjt)åŠå…¶åˆè‘—è€…çš„ç»¼è¿°è®ºæ–‡ï¼Œä»¥åŠå‚è€ƒæ–‡çŒ®ä¸­çš„è®ºæ–‡ã€‚
- en: '^([5](ch07.html#idm45621831705184-marker)) Robert Tibshirani, [â€œRegression
    Shrinkage and Selection via the Lassoâ€](https://oreil.ly/noLVr), *Journal of the
    Royal Statistical Society* Series B 58, no. 1 (1996): 267â€“88.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '^([5](ch07.html#idm45621831705184-marker)) Robert Tibshirani çš„ç ”ç©¶ï¼Œ[â€œLassoå›å½’æ”¶ç¼©å’Œé€‰æ‹©â€](https://oreil.ly/noLVr)ï¼Œ*Royal
    Statistical Society Bç³»åˆ—æœŸåˆŠ* 58å·1æœŸ (1996): 267â€“88ã€‚'
- en: '^([6](ch07.html#idm45621831663760-marker)) You can see an intuitive visualization
    of some of these concepts in Uber AIâ€™s ICML 2019 poster [â€œDeconstructing Lottery
    Tickets: Zeros, Signs, and the Supermaskâ€](https://oreil.ly/iLQ9e).'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch07.html#idm45621831663760-marker)) æ‚¨å¯ä»¥åœ¨Uber AIçš„ICML 2019æµ·æŠ¥ [â€œè§£æ„å½©ç¥¨ï¼šé›¶ã€ç¬¦å·å’Œè¶…è’™ç‰ˆâ€](https://oreil.ly/iLQ9e)
    ä¸­ç›´è§‚åœ°çœ‹åˆ°è¿™äº›æ¦‚å¿µçš„å¯è§†åŒ–ã€‚
- en: ^([7](ch07.html#idm45621831656864-marker)) For example, check out the recent
    papers by [Selima Curci et al.](https://arxiv.org/abs/2102.01732) and [Shiwei
    Liu et al.](https://doi.org/10.1007/s00521-021-05727-y) that have code available
    in GitHub.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch07.html#idm45621831656864-marker)) ä¾‹å¦‚ï¼ŒæŸ¥çœ‹Selima Curciç­‰äººä»¥åŠShiwei Liuç­‰äººçš„æœ€æ–°è®ºæ–‡ï¼Œè¿™äº›è®ºæ–‡åœ¨GitHubä¸Šæœ‰å¯ç”¨çš„ä»£ç ã€‚
- en: ^([8](ch07.html#idm45621831645600-marker)) Sara Hooker et al., [â€œWhat Do Compressed
    Deep Neural Networks Forget?â€](https://arxiv.org/abs/1911.05248), *arXiv preprint*
    (2019).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch07.html#idm45621831645600-marker)) Sara Hooker ç­‰äººçš„ç ”ç©¶ï¼Œ[â€œå‹ç¼©æ·±åº¦ç¥ç»ç½‘ç»œå¿˜å´äº†ä»€ä¹ˆï¼Ÿâ€](https://arxiv.org/abs/1911.05248)ï¼Œ*arXiv
    é¢„å°æœ¬* (2019)ã€‚
- en: ^([9](ch07.html#idm45621831643664-marker)) Sara Hooker et al., [â€œCharacterising
    Bias in Compressed Modelsâ€](https://arxiv.org/abs/2010.03058), *arXiv preprint*
    (2020).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch07.html#idm45621831643664-marker)) Sara Hooker ç­‰äººçš„ç ”ç©¶ï¼Œ[â€œå‹ç¼©æ¨¡å‹ä¸­çš„åå·®è¡¨å¾â€](https://arxiv.org/abs/2010.03058)ï¼Œ*arXiv
    é¢„å°æœ¬* (2020)ã€‚
- en: '^([10](ch07.html#idm45621831625888-marker)) Abhaya Indrayan, *Medical Biostatistics*
    (Boca Raton, FL: CRC Press, 2008).'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '^([10](ch07.html#idm45621831625888-marker)) Abhaya Indrayan çš„è‘—ä½œï¼Œ*åŒ»å­¦ç”Ÿç‰©ç»Ÿè®¡å­¦* (Boca
    Raton, FL: CRC Press, 2008)ã€‚'
- en: ^([11](ch07.html#idm45621831208160-marker)) Ward Cunningham, [â€œThe WyCash Portfolio
    Management Systemâ€](https://oreil.ly/E5k5J), *OOPSLA â€™92 Experience Report*, March
    26, 1992.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch07.html#idm45621831208160-marker)) Ward Cunningham çš„æŠ¥å‘Šï¼Œ[â€œWyCash æŠ•èµ„ç»„åˆç®¡ç†ç³»ç»Ÿâ€](https://oreil.ly/E5k5J)ï¼Œ*OOPSLA
    â€™92 ç»éªŒæŠ¥å‘Š*ï¼Œ1992å¹´3æœˆ26æ—¥ã€‚
- en: ^([12](ch07.html#idm45621831185904-marker)) For a detailed treatment of technical
    debt in ML, see D. Sculley et al., [â€œHidden Technical Debt in Machine Learning
    Systemsâ€](https://oreil.ly/GtJ3E), *NeurIPS Proceedings* (2015). For a technical
    perspective on this paper and debt management best practices for a modern ML workflow,
    see author Matthew McAteerâ€™s [blog post, â€œNitpicking Machine Learning Technical
    Debtâ€](https://oreil.ly/M6Yix) from 2020.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch07.html#idm45621831185904-marker)) å…³äºæœºå™¨å­¦ä¹ ä¸­æŠ€æœ¯å€ºåŠ¡çš„è¯¦ç»†è®¨è®ºï¼Œè¯·å‚é˜… D. Sculley
    ç­‰äººçš„[â€œHidden Technical Debt in Machine Learning Systemsâ€](https://oreil.ly/GtJ3E)ï¼Œ*NeurIPS
    Proceedings* (2015)ã€‚å…³äºæœ¬æ–‡å’Œç°ä»£æœºå™¨å­¦ä¹ å·¥ä½œæµä¸­å€ºåŠ¡ç®¡ç†çš„æŠ€æœ¯è§†è§’ï¼Œè¯·å‚é˜…ä½œè€… Matthew McAteer åœ¨2020å¹´çš„[åšå®¢æ–‡ç« ï¼Œâ€œNitpicking
    Machine Learning Technical Debtâ€](https://oreil.ly/M6Yix)ã€‚
- en: '^([13](ch07.html#idm45621831158800-marker)) McKane Andrus et al., [â€œWhat We
    Canâ€™t Measure, We Canâ€™t Understand: Challenges to Demographic Data Procurement
    in the Pursuit of Fairnessâ€](https://dl.acm.org/doi/10.1145/3442188.3445888),
    *FaccT-2021* (March 2021): 249â€“60.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '^([13](ch07.html#idm45621831158800-marker)) McKane Andrus ç­‰äººï¼Œåœ¨[â€œWhat We Canâ€™t
    Measure, We Canâ€™t Understand: Challenges to Demographic Data Procurement in the
    Pursuit of Fairnessâ€](https://dl.acm.org/doi/10.1145/3442188.3445888)ï¼Œ*FaccT-2021*
    (2021å¹´3æœˆ): 249â€“60ã€‚'
- en: ^([14](ch07.html#idm45621831148064-marker)) Matthieu Renard, [â€œOne of The Most
    Common Mistakes When Running an ANOVA in Râ€](https://oreil.ly/0UyT7), *Towards
    Data Science* (blog), January 2, 2020.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch07.html#idm45621831148064-marker)) Matthieu Renardï¼Œåœ¨[â€œOne of The Most
    Common Mistakes When Running an ANOVA in Râ€](https://oreil.ly/0UyT7)ï¼Œ*Towards
    Data Science* (åšå®¢)ï¼Œ2020å¹´1æœˆ2æ—¥ã€‚
- en: '^([15](ch07.html#idm45621831122656-marker)) Catherine Petrozzino, [â€œWho Pays
    for Ethical Debt in AI?â€](https://oreil.ly/E31jV), *AI and Ethics* 1 (January
    2021): 205â€“8.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '^([15](ch07.html#idm45621831122656-marker)) Catherine Petrozzinoï¼Œåœ¨[â€œWho Pays
    for Ethical Debt in AI?â€](https://oreil.ly/E31jV)ï¼Œ*AI and Ethics* 1 (2021å¹´1æœˆ):
    205â€“8ã€‚'
- en: ^([16](ch07.html#idm45621831120016-marker)) Miranda Bogen, [â€œAll the Ways Hiring
    Algorithms Can Introduce Biasâ€](https://oreil.ly/BTR1X), *Harvard Business Review*,
    May 6, 2019.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch07.html#idm45621831120016-marker)) Miranda Bogenï¼Œåœ¨[â€œAll the Ways Hiring
    Algorithms Can Introduce Biasâ€](https://oreil.ly/BTR1X)ï¼Œ*Harvard Business Review*ï¼Œ2019å¹´5æœˆ6æ—¥ã€‚
- en: ^([17](ch07.html#idm45621831117744-marker)) For a detailed treatment of the
    motivations, see Casey Fiesler and Natalie Garrett, [â€œEthical Tech Starts With
    Addressing Ethical Debtâ€](https://oreil.ly/ihDM6), *Wired*, September 16, 2020
    and Petrozzino, â€œWho Pays for Ethical Debt in AI?â€ 205â€“8.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch07.html#idm45621831117744-marker)) å…³äºåŠ¨æœºçš„è¯¦ç»†è®¨è®ºï¼Œè¯·å‚é˜… Casey Fiesler å’Œ Natalie
    Garrett çš„[â€œEthical Tech Starts With Addressing Ethical Debtâ€](https://oreil.ly/ihDM6)ï¼Œ*Wired*ï¼Œ2020å¹´9æœˆ16æ—¥
    å’Œ Petrozzino çš„â€œWho Pays for Ethical Debt in AI?â€ 205â€“8ã€‚
- en: '^([18](ch07.html#idm45621831095712-marker)) In [â€œâ€˜How Do I Fool You?â€™: Manipulating
    User Trust via Misleading Black Box Explanationsâ€](https://dl.acm.org/doi/10.1145/3375627.3375833),
    *Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society* (February
    2020): 79â€“85, Himabindu Lakkaraju and Osbert Bastani show that, just like any
    other ML method, explanation methods can be fooled by adversaries.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '^([18](ch07.html#idm45621831095712-marker)) åœ¨[â€œâ€˜How Do I Fool You?â€™: Manipulating
    User Trust via Misleading Black Box Explanationsâ€](https://dl.acm.org/doi/10.1145/3375627.3375833)ï¼ŒHimabindu
    Lakkaraju å’Œ Osbert Bastani åœ¨ *Proceedings of the AAAI/ACM Conference on AI, Ethics,
    and Society* (2020å¹´2æœˆ): 79â€“85 ä¸­è¡¨æ˜ï¼Œåƒå…¶ä»–ä»»ä½•æœºå™¨å­¦ä¹ æ–¹æ³•ä¸€æ ·ï¼Œè§£é‡Šæ–¹æ³•ä¹Ÿå®¹æ˜“å—åˆ°å¯¹æ‰‹çš„æ¬ºéª—ã€‚'
- en: '^([19](ch07.html#idm45621831093472-marker)) To learn about how humans perceive
    the outcomes from an explanation method, see Harmanpreet Kaur et al., [â€œInterpreting
    Interpretability: Understanding Data Scientistsâ€™ Use of Interpretability Tools
    for Machine Learningâ€](https://dl.acm.org/doi/abs/10.1145/3313831.3376219), *Proceedings
    of the 2020 CHI Conference on Human Factors in Computing Systems* (April 2020):
    1â€“14 and Forough Poursabzi-Sangdeh et al., [â€œManipulating and Measuring Model
    Interpretabilityâ€](https://dl.acm.org/doi/10.1145/3411764.3445315), *Proceedings
    of the 2021 CHI Conference on Human Factors in Computing Systems*, no. 237 (May
    2021): 1â€“52.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '^([19](ch07.html#idm45621831093472-marker)) å…³äºäººç±»å¦‚ä½•ç†è§£è§£é‡Šæ–¹æ³•çš„ç»“æœï¼Œè¯·å‚é˜… Harmanpreet
    Kaur ç­‰äººçš„[â€œInterpreting Interpretability: Understanding Data Scientistsâ€™ Use of
    Interpretability Tools for Machine Learningâ€](https://dl.acm.org/doi/abs/10.1145/3313831.3376219)ï¼Œ*Proceedings
    of the 2020 CHI Conference on Human Factors in Computing Systems* (2020å¹´4æœˆ): 1â€“14
    å’Œ Forough Poursabzi-Sangdeh ç­‰äººçš„[â€œManipulating and Measuring Model Interpretabilityâ€](https://dl.acm.org/doi/10.1145/3411764.3445315)ï¼Œ*Proceedings
    of the 2021 CHI Conference on Human Factors in Computing Systems*ï¼Œno. 237 (2021å¹´5æœˆ):
    1â€“52ã€‚'
- en: '^([20](ch07.html#idm45621831080464-marker)) Margaret Mitchell et al., [â€œModel
    Cards for Model Reportingâ€](https://dl.acm.org/doi/10.1145/3287560.3287596), *Proceedings
    of the Conference on Fairness, Accountability, and Transparency* (January 2019):
    220â€“9.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '^([20](ch07.html#idm45621831080464-marker)) Margaret Mitchell ç­‰äººï¼Œåœ¨[â€œModel Cards
    for Model Reportingâ€](https://dl.acm.org/doi/10.1145/3287560.3287596)ï¼Œ*Proceedings
    of the Conference on Fairness, Accountability, and Transparency* (2019å¹´1æœˆ): 220â€“9ã€‚'
- en: '^([21](ch07.html#idm45621831020192-marker)) Evelin Amorim et al., [â€œAutomated
    Essay Scoring in the Presence of Biased Ratingsâ€](https://oreil.ly/sxS65), *ACL
    Anthology* 1 (2018): 229â€“37.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch07.html#idm45621831020192-marker)) Evelin Amorim ç­‰äººï¼Œ[â€œåœ¨åè§è¯„åˆ†å­˜åœ¨æ—¶çš„è‡ªåŠ¨åŒ–ä½œæ–‡è¯„åˆ†â€](https://oreil.ly/sxS65)ï¼Œ*ACL
    Anthology* 1ï¼ˆ2018å¹´ï¼‰ï¼š229â€“37ã€‚
- en: '^([22](ch07.html#idm45621831006480-marker)) Cyrus DiCiccio et al., [â€œEvaluating
    Fairness Using Permutation Testsâ€](https://dl.acm.org/doi/10.1145/3394486.3403199),
    *KDD-2020* (August 2020): 1467â€“77.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch07.html#idm45621831006480-marker)) Cyrus DiCiccio ç­‰äººï¼Œ[â€œä½¿ç”¨æ’åˆ—æµ‹è¯•è¯„ä¼°å…¬å¹³æ€§â€](https://dl.acm.org/doi/10.1145/3394486.3403199)ï¼Œ*KDD-2020*ï¼ˆ2020å¹´8æœˆï¼‰ï¼š1467â€“77ã€‚
- en: '^([23](ch07.html#idm45621830978528-marker)) Neil Jethani et al., [â€œFastSHAP:
    Real-Time Shapley Value Estimationâ€](https://arxiv.org/abs/2107.07436), *International
    Conference on Learning Representations* (2021).'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](ch07.html#idm45621830978528-marker)) Neil Jethani ç­‰äººï¼Œ[â€œFastSHAPï¼šå®æ—¶Shapleyå€¼ä¼°è®¡â€](https://arxiv.org/abs/2107.07436)ï¼Œ*International
    Conference on Learning Representations*ï¼ˆ2021å¹´ï¼‰ã€‚
- en: '^([24](ch07.html#idm45621830966240-marker)) Jayne Groll, [â€œMonitoring vs. Observability:
    Whatâ€™s the Difference in DevOps?â€](https://oreil.ly/Rq7YC), *The Enterprisers
    Project*, September 17, 2021.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](ch07.html#idm45621830966240-marker)) Jayne Grollï¼Œ[â€œç›‘æ§ä¸å¯è§‚å¯Ÿæ€§ï¼šåœ¨DevOpsä¸­æœ‰ä½•åŒºåˆ«ï¼Ÿâ€](https://oreil.ly/Rq7YC)ï¼Œ*The
    Enterprisers Project*ï¼Œ2021å¹´9æœˆ17æ—¥ã€‚
- en: ^([25](ch07.html#idm45621830937216-marker)) *Control Charts* by John Murdoch
    (Palgrave) is a great resource on the theory and applications of control charts.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: ^([25](ch07.html#idm45621830937216-marker)) *æ§åˆ¶å›¾* ç”± John Murdochï¼ˆPalgraveï¼‰æ’°å†™ï¼Œæ˜¯å…³äºæ§åˆ¶å›¾ç†è®ºå’Œåº”ç”¨çš„é‡è¦èµ„æºã€‚
