- en: Chapter 1\. The Need for Machine Learning Design Patterns
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 机器学习设计模式的需求
- en: In engineering disciplines, design patterns capture best practices and solutions
    to commonly occurring problems. They codify the knowledge and experience of experts
    into advice that all practitioners can follow. This book is a catalog of machine
    learning design patterns that we have observed in the course of working with hundreds
    of machine learning teams.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在工程学科中，设计模式捕捉到常见问题的最佳实践和解决方案。它们将专家的知识和经验编码为所有从业者都可以遵循的建议。本书是我们在与数百个机器学习团队合作中观察到的机器学习设计模式的目录。
- en: What Are Design Patterns?
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是设计模式？
- en: 'The idea of patterns, and a catalog of proven patterns, was introduced in the
    field of architecture by Christopher Alexander and five coauthors in a hugely
    influential book titled *A Pattern Language* (Oxford University Press, 1977).
    In their book, they catalog 253 patterns, introducing them this way:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 模式的概念和已证实的模式目录是由克里斯托弗·亚历山大和五位共同作者在一本极具影响力的书籍*一种模式语言*（牛津大学出版社，1977）中引入建筑领域的。在他们的书中，他们列出了253种模式，并以这种方式介绍它们：
- en: Each pattern describes a problem which occurs over and over again in our environment,
    and then describes the core of the solution to that problem, in such a way that
    you can use this solution a million times over, without ever doing it the same
    way twice.
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 每个模式描述了在我们的环境中反复出现的问题，然后以这样的方式描述了解决这个问题的核心，这样你可以一百万次地使用这个解决方案，而不必两次做同样的事情。
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: …
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: …
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Each solution is stated in such a way that it gives the essential field of relationships
    needed to solve the problem, but in a very general and abstract way—so that you
    can solve the problem for yourself, in your own way, by adapting it to your preferences,
    and the local conditions at the place where you are making it.
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 每个解决方案都以一种方式陈述，即给出解决问题所需的关系领域的核心，但以非常一般和抽象的方式—这样你就可以根据自己的偏好和所处地点的局部条件自己解决问题。
- en: 'For example, a couple of the patterns that incorporate human details when building
    a home are *Light on Two Sides of Every Room* and *Six-Foot Balcony*. Think of
    your favorite room in your home, and your least-favorite room. Does your favorite
    room have windows on two walls? What about your least-favorite room? According
    to Alexander:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在建造家庭时，包含人类细节的几种模式是*每个房间两面有光*和*六英尺阳台*。想象一下你家中最喜欢的房间和最不喜欢的房间。你最喜欢的房间是否有两面墙的窗户？而你最不喜欢的房间呢？根据亚历山大：
- en: Rooms lit on two sides, with natural light, create less glare around people
    and objects; this lets us see things more intricately; and most important, it
    allows us to read in detail the minute expressions that flash across people’s
    faces….
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 两侧自然采光的房间在人和物体周围产生较少的眩光；这使我们能更加细致地看到事物；最重要的是，它使我们能够详细阅读人们脸上瞬间的微表情……。
- en: Having a name for this pattern saves architects from having to continually rediscover
    this principle. Yet where and how you get two light sources in any specific local
    condition is up to the architect’s skill. Similarly, when designing a balcony,
    how big should it be? Alexander recommends 6 feet by 6 feet as being enough for
    2 (mismatched!) chairs and a side table, and 12 feet by 12 feet if you want both
    a covered sitting space and a sitting space in the sun.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个这种模式的名字可以让建筑师们免于不断重新发现这个原则。然而，在任何特定的地方条件下，你如何获取两个光源取决于建筑师的技能。同样地，在设计阳台时，它应该有多大？亚历山大建议尺寸为6英尺×6英尺足够放置两把（不匹配的！）椅子和一个边桌，如果你想要既有遮阳的休息空间又有阳光的休息空间，建议尺寸为12英尺×12英尺。
- en: 'Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides brought the idea
    to software by cataloging 23 object-oriented design patterns in a 1994 book entitled
    *Design Patterns: Elements of Reusable Object-Oriented Software* (Addison-Wesley,
    1995). Their catalog includes patterns such as Proxy, Singleton, and Decorator
    and led to lasting impact on the field of object-oriented programming. In 2005
    the Association of Computing Machinery (ACM) awarded their annual Programming
    Languages Achievement Award to the authors, recognizing the impact of their work
    “on programming practice and programming language design.”'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides 在1994年的书籍*设计模式：可重用面向对象软件的元素*（Addison-Wesley，1995）中列出了23种面向对象设计模式，将这一想法引入了软件领域。他们的目录包括代理、单例和装饰者等模式，并对面向对象编程领域产生了深远影响。2005年，计算机协会（ACM）将年度编程语言成就奖颁发给了这些作者，以表彰他们的工作“对编程实践和编程语言设计的影响”。
- en: Building production machine learning models is increasingly becoming an engineering
    discipline, taking advantage of ML methods that have been proven in research settings
    and applying them to business problems. As machine learning becomes more mainstream,
    it is important that practitioners take advantage of tried-and-proven methods
    to address recurring problems.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 构建生产机器学习模型越来越成为一门工程学科，利用在研究环境中已被证明有效的机器学习方法，并将其应用于业务问题。随着机器学习变得更加普及，重要的是从业者利用经过验证的方法来解决反复出现的问题。
- en: One benefit of our jobs in the customer-facing part of Google Cloud is that
    it brings us in contact with a wide variety of machine learning and data science
    teams and individual developers from around the world. At the same time, we each
    work closely with internal Google teams solving cutting-edge machine learning
    problems. Finally, we have been fortunate to work with the TensorFlow, Keras,
    BigQuery ML, TPU, and Cloud AI Platform teams that are driving the democratization
    of machine learning research and infrastructure. All this gives us a rather unique
    perspective from which to catalog the best practices we have observed these teams
    carrying out.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在Google Cloud面向客户的部分工作的一个好处是，它让我们接触到来自世界各地的各种机器学习和数据科学团队以及个人开发人员。同时，我们与内部Google团队密切合作，解决前沿的机器学习问题。最后，我们有幸与推动机器学习研究和基础设施民主化的TensorFlow、Keras、BigQuery
    ML、TPU和Cloud AI平台团队合作。所有这些使我们能够从独特的视角来整理我们观察到的这些团队正在实施的最佳实践。
- en: This book is a catalog of design patterns or repeatable solutions to commonly
    occurring problems in ML engineering. For example, the Transform pattern ([Chapter 6](ch06_split_000.xhtml#reproducibility_design_patterns))
    enforces the separation of inputs, features, and transforms and makes the transformations
    persistent in order to simplify moving an ML model to production. Similarly, Keyed
    Predictions, in [Chapter 5](ch05.xhtml#design_patterns_for_resilient_serving),
    is a pattern that enables the large-scale distribution of batch predictions, such
    as for recommendation models.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是机器学习工程中常见问题的设计模式或可重复解决方案的目录。例如，转换模式（[第6章](ch06_split_000.xhtml#reproducibility_design_patterns)）强制分离输入、特征和转换，并使转换持久化，以简化将机器学习模型移至生产环境。类似地，有钥匙预测，在[第5章](ch05.xhtml#design_patterns_for_resilient_serving)，这是一种模式，可以实现批量预测的大规模分发，例如推荐模型。
- en: For each pattern, we describe the commonly occurring problem that is being addressed
    and then walk through a variety of potential solutions to the problem, the trade-offs
    of these solutions, and recommendations for choosing between these solutions.
    Implementation code for these solutions is provided in SQL (useful if you are
    carrying out preprocessing and other ETL in Spark SQL, BigQuery, and so on), scikit-learn,
    and/or Keras with a TensorFlow backend.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每种模式，我们描述正在解决的常见问题，然后逐步介绍问题的各种潜在解决方案，这些解决方案的权衡以及选择这些解决方案的建议。这些解决方案的实现代码提供在SQL中（如果您在Spark
    SQL、BigQuery等中进行预处理和其他ETL操作时有用）、scikit-learn和/或带有TensorFlow后端的Keras中。
- en: How to Use This Book
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用本书
- en: This is a catalog of patterns that we have observed in practice, among multiple
    teams. In some cases, the underlying concepts have been known for many years.
    We don’t claim to have invented or discovered these patterns. Instead, we hope
    to provide a common frame of reference and set of tools for ML practitioners.
    We will have succeeded if this book gives you and your team a vocabulary when
    talking about concepts that you already incorporate intuitively into your ML projects.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个实践中观察到的模式目录，涉及多个团队。在某些情况下，这些模式的概念已经为人所知多年。我们并不声称发明或发现这些模式。相反，我们希望为机器学习从业者提供一个共同的参考框架和工具集。如果这本书能够为您和您的团队在讨论您已经在机器学习项目中直觉地整合的概念时提供词汇，那么我们就算达到了目标。
- en: We don’t expect you to read this book sequentially (although you can!). Instead,
    we anticipate that you will skim through the book, read a few sections more deeply
    than others, reference the ideas in conversations with colleagues, and refer back
    to the book when faced with problems you remember reading about. If you plan to
    skip around, we recommend that you start with [Chapter 1](#the_need_for_machine_learning_design_pa)
    and [Chapter 8](ch08.xhtml#connected_patterns) before dipping into individual
    patterns.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不期望您按顺序阅读本书（尽管您可以！）。相反，我们预计您会快速浏览本书，深入阅读某些部分，与同事讨论想法，并在面对您记得读过的问题时参考本书。如果您计划跳跃阅读，我们建议您从[第一章](#the_need_for_machine_learning_design_pa)和[第八章](ch08.xhtml#connected_patterns)开始，然后再深入到各个模式中。
- en: Each pattern has a brief problem statement, a canonical solution, an explanation
    of why the solution works, and a many-part discussion on tradeoffs and alternatives.
    We recommend that you read the discussion section with the canonical solution
    firmly in mind, so as to compare and contrast. The pattern description will include
    code snippets taken from the implementation of the canonical solution. The full
    code can be found in [our GitHub repository](https://github.com/GoogleCloudPlatform/ml-design-patterns).
    We strongly encourage you to peruse the code as you read the pattern description.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模式都有简短的问题陈述、一个经典解决方案、解决方案有效性的解释，以及对权衡和替代方案的多部分讨论。建议您在心中牢记经典解决方案的前提下阅读讨论部分，以便进行比较和对比。模式描述将包括从经典解决方案的实现中提取的代码片段。完整的代码可以在[我们的
    GitHub 代码库](https://github.com/GoogleCloudPlatform/ml-design-patterns)中找到。强烈建议您在阅读模式描述时浏览代码。
- en: Machine Learning Terminology
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习术语
- en: Because machine learning practitioners today may have different areas of primary
    expertise—software engineering, data analysis, DevOps, or statistics—there can
    be subtle differences in the way that different practitioners use certain terms.
    In this section, we define terminology that we use throughout the book.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因为今天的机器学习实践者可能拥有不同的主要专业领域 —— 软件工程、数据分析、DevOps 或统计学 —— 所以不同实践者对某些术语的使用方式可能会有微妙的差异。在本节中，我们定义了本书中使用的术语。
- en: Models and Frameworks
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型和框架
- en: 'At its core, *machine learning* is a process of building models that learn
    from data. This is in contrast to traditional programming where we write explicit
    rules that tell programs how to behave. Machine learning *models* are algorithms
    that learn patterns from data. To illustrate this point, imagine we are a moving
    company and need to estimate moving costs for potential customers. In traditional
    programming, we might solve this with an if statement:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，*机器学习* 是一个从数据中学习的模型构建过程。这与传统编程不同，传统编程中我们编写明确的规则来告诉程序如何行为。机器学习的*模型* 是从数据中学习模式的算法。为了说明这一点，想象我们是一个搬家公司，需要为潜在客户估算搬家成本。在传统编程中，我们可能会用
    if 语句来解决这个问题：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You can imagine how this will quickly get complicated as we add more variables
    (number of large furniture items, amount of clothing, fragile items, and so on)
    and try to handle edge cases. More to the point, asking for all this information
    ahead of time from customers can cause them to abandon the estimation process.
    Instead, we can train a machine learning model to estimate moving costs based
    on past data on previous households our company has moved.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以想象，随着我们添加更多变量（大型家具件数、衣物量、易碎物品等等）并尝试处理边缘情况，这将很快变得复杂起来。更重要的是，要求客户提前提供所有这些信息可能会导致他们放弃估算过程。相反，我们可以训练一个机器学习模型，根据我们公司已经搬迁过的以往家庭的数据来估算搬家成本。
- en: Throughout the book, we primarily use feed-forward neural network models in
    our examples, but we’ll also reference linear regression models, decision trees,
    clustering models, and others. *Feed-forward neural networks,* which we will commonly
    shorten as *neural networks*, are a type of machine learning algorithm whereby
    multiple layers, each with many neurons, analyze and process information and then
    send that information to the next layer, resulting in a final layer that produces
    a prediction as output. Though they are in no way identical, neural networks are
    often compared to the neurons in our brain because of the connectivity between
    nodes and the way they are able to generalize and form new predictions from the
    data they process. Neural networks with more than one *hidden layer* (layers other
    than the input and output layer) are classified as *deep learning* (see [Figure 1-1](#a_breakdown_of_different_types_of_machi)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中，我们主要在示例中使用前馈神经网络模型，但我们也会提到线性回归模型、决策树、聚类模型等其他模型。*前馈神经网络*，通常我们简称为*神经网络*，是一种机器学习算法，多层次、每层具有多个神经元，分析和处理信息，然后将该信息传递到下一层，最终产生预测作为输出。尽管它们并非完全相同，神经网络常被比作大脑中的神经元，因为节点之间的连接方式和它们处理数据后生成新预测的能力。具有超过一个*隐藏层*（除了输入和输出层以外的层）的神经网络被归类为*深度学习*（见[图 1-1](#a_breakdown_of_different_types_of_machi)）。
- en: Machine learning models, regardless of how they are depicted visually, are mathematical
    functions and can therefore be implemented from scratch using a numerical software
    package. However, ML engineers in industry tend to employ one of several open
    source frameworks designed to provide intuitive APIs for building models. The
    majority of our examples will use *TensorFlow*, an open source machine learning
    framework created by Google with a focus on deep learning models. Within the TensorFlow
    library, we’ll be using the *Keras* API in our examples, which can be imported
    through `tensorflow.keras. Keras is a higher-level API for building neural networks`.
    While Keras supports many backends, we’ll be using its TensorFlow backend. In
    other examples, we’ll be using *scikit-learn, XGBoost,* and *PyTorch*, which are
    other popular open source frameworks that provide utilities for preparing your
    data, along with APIs for building linear and deep models. Machine learning continues
    to become more accessible, and one exciting development is the availability of
    machine learning models that can be expressed in SQL. We’ll use *BigQuery ML*
    as an example of this, especially in situations where we want to combine data
    preprocessing and model creation.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型，无论它们在视觉上如何表现，都是数学函数，因此可以使用数值软件包从头开始实现。然而，在工业界，机器学习工程师倾向于使用几种设计用于构建模型的开源框架之一。我们的大多数示例将使用*TensorFlow*，这是由Google创建的专注于深度学习模型的开源机器学习框架。在TensorFlow库中，我们将在示例中使用*Keras*
    API，可以通过`tensorflow.keras`导入。Keras是一个构建神经网络的高级API。虽然Keras支持多种后端，我们将使用其TensorFlow后端。在其他示例中，我们将使用*scikit-learn,
    XGBoost*和*PyTorch*，这些都是其他流行的开源框架，提供了用于准备数据的实用工具，以及构建线性和深度模型的API。机器学习变得越来越易于接触，一个令人兴奋的发展是可以在SQL中表达机器学习模型的可用性。我们将使用*BigQuery
    ML*作为这种情况的示例，特别是在我们希望结合数据预处理和模型创建的情况下。
- en: '![A breakdown of different types of machine learning, with a few examples of
    each. Note that although it is not included in this diagram, neural networks like
    autoencoders can also be used for unsupervised learning.](Images/mldp_0101.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![不同类型的机器学习分解，以及每种类型的几个示例。请注意，尽管此图中未包含，像自编码器这样的神经网络也可用于无监督学习。](Images/mldp_0101.png)'
- en: Figure 1-1\. A breakdown of different types of machine learning, with a few
    examples of each. Note that although it is not included in this diagram, neural
    networks like autoencoders can also be used for unsupervised learning.
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-1\. 不同类型的机器学习分解，以及每种类型的几个示例。请注意，尽管此图中未包含，像自编码器这样的神经网络也可用于无监督学习。
- en: Conversely, neural networks with only an input and output layer are another
    subset of machine learning known as *linear models*. Linear models represent the
    patterns they’ve learned from data using a linear function. *Decision trees* are
    machine learning models that use your data to create a subset of paths with various
    branches. These branches approximate the results of different outcomes from your
    data. Finally, *clustering* models look for similarities between different subsets
    of your data and use these identified patterns to group data into clusters.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，只有输入和输出层的神经网络是机器学习的另一种子集，被称为*线性模型*。线性模型使用线性函数表示它们从数据中学到的模式。*决策树*是一种机器学习模型，它使用你的数据创建带有各种分支的路径子集。这些分支近似于你的数据中不同结果的结果。最后，*聚类*模型寻找数据不同子集之间的相似性，并使用这些识别的模式将数据分组成簇。
- en: 'Machine learning problems (see [Figure 1-1](#a_breakdown_of_different_types_of_machi))
    can be broken into two types: supervised and unsupervised learning. *Supervised
    learning* defines problems where you know the ground truth label for your data
    in advance. For example, this could include labeling an image as “cat” or labeling
    a baby as being 2.3 kg at birth. You feed this labeled data to your model in hopes
    that it can learn enough to label new examples. With *unsupervised learning*,
    you do not know the labels for your data in advance, and the goal is to build
    a model that can find natural groupings of your data (called *clustering*), compress
    the information content (*dimensionality reduction*), or find association rules.
    The majority of this book will focus on supervised learning because the vast majority
    of machine learning models used in production are supervised.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习问题（见[图 1-1](#a_breakdown_of_different_types_of_machi)）可以分为两种类型：监督学习和无监督学习。*监督学习*定义了你提前知道数据的地面真实标签的问题。例如，这可以包括将图像标记为“猫”或将婴儿标记为出生时体重为2.3公斤。你将这些标记数据提供给你的模型，希望它能够学习足够多的内容来标记新的例子。*无监督学习*则不知道数据的标签，目标是构建一个能够找到数据的自然分组（称为*聚类*）、压缩信息内容（*降维*）或找到关联规则的模型。本书的大部分内容将集中在监督学习上，因为在生产中使用的大多数机器学习模型都是监督学习模型。
- en: With supervised learning, problems can typically be defined as either classification
    or regression. *Classification* models assign your input data a label (or labels)
    from a discrete, predefined set of categories. Examples of classification problems
    include determining the type of pet breed in an image, tagging a document, or
    predicting whether or not a transaction is fraudulent. *Regression* models assign
    continuous, numerical values to your inputs. Examples of regression models include
    predicting the duration of a bike trip, a company’s future revenue, or the price
    of a product.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，问题通常可以定义为分类或回归。*分类*模型为你的输入数据分配来自离散预定义类别集的标签（或标签）。分类问题的例子包括确定图像中宠物品种的类型、标记文档或预测交易是否欺诈。*回归*模型为你的输入分配连续的数值。回归模型的例子包括预测自行车行程的持续时间、公司未来的收入或产品的价格。
- en: Data and Feature Engineering
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据与特征工程
- en: 'Data is at the heart of any machine learning problem. When we talk about *datasets*,
    we’re referring to the data used for training, validating, and testing a machine
    learning model. The bulk of your data will be *training data*: the data fed to
    your model during the training process. *Validation data* is data that is held
    out from your training set and used to evaluate how the model is performing after
    each training *epoch* (or pass through the training data). The performance of
    the model on the validation data is used to decide when to stop the training run,
    and to choose *hyperparameters*, such as the number of trees in a random forest
    model. *Test data* is data that is not used in the training process at all and
    is used to evaluate how the trained model performs. Performance reports of the
    machine learning model must be computed on the independent test data, rather than
    the training or validation tests. It’s also important that the data be split in
    such a way that all three datasets (training, test, validation) have similar statistical
    properties.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是任何机器学习问题的核心。当我们谈论 *数据集* 时，我们指的是用于训练、验证和测试机器学习模型的数据。大部分数据将是 *训练数据*：在训练过程中输入模型的数据。*验证数据*
    是从训练集中留出来用于评估模型在每个训练 *轮次*（或通过训练数据的次数）后表现的数据。模型在验证数据上的表现用于决定何时停止训练过程，并选择 *超参数*，例如随机森林模型中的树的数量。*测试数据*
    是完全不参与训练过程的数据，用于评估训练好的模型的表现。机器学习模型的性能报告必须基于独立的测试数据集计算，而不是基于训练或验证数据。同样重要的是，数据必须以这样一种方式分割，使得所有三个数据集（训练、测试、验证）具有类似的统计特性。
- en: The data you use to train your model can take many forms depending on the model
    type. We define *structured data* as numerical and categorical data. Numerical
    data includes integer and float values, and categorical data includes data that
    can be divided into a finite set of groups, like type of car or education level.
    You can also think of structured data as data you would commonly find in a spreadsheet.
    Throughout the book, we’ll use the term *tabular data* interchangeably with structured
    data. *Unstructured data*, on the other hand, includes data that cannot be represented
    as neatly. This typically includes free-form text, images, video, and audio.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型所使用的数据可以采用多种形式，这取决于模型类型。我们将 *结构化数据* 定义为数值和分类数据。数值数据包括整数和浮点数值，而分类数据则包括可以划分为有限组的数据，例如汽车类型或教育水平。你也可以将结构化数据看作是常见的电子表格中的数据。在本书中，我们将
    *表格数据* 与结构化数据互换使用。另一方面，*非结构化数据* 则包括不能整齐表示的数据。这通常包括自由文本、图像、视频和音频。
- en: Numeric data can often be fed directly to a machine learning model, where other
    data requires various *data preprocessing* before it’s ready to be sent to a model.
    This preprocessing step typically includes scaling numerical values, or converting
    nonnumerical data into a numerical format that can be understood by your model.
    Another term for preprocessing is *feature engineering*. We’ll use these two terms
    interchangeably throughout the book.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数值数据通常可以直接输入到机器学习模型中，而其他数据则需要进行各种 *数据预处理* 才能准备好送入模型。这个预处理步骤通常包括对数值进行缩放，或将非数值数据转换为模型可理解的数值格式。预处理的另一个术语是
    *特征工程*。在本书中，我们将这两个术语交替使用。
- en: There are various terms used to describe data as it goes through the feature
    engineering process. *Input* describes a single column in your dataset before
    it has been processed, and *feature* describes a single column *after* it has
    been processed. For example, a timestamp could be your input, and the feature
    would be day of the week. To convert the data from timestamp to day of the week,
    you’ll need to do some data preprocessing. This preprocessing step can also be
    referred to as *data transformation*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征工程过程中，有各种术语用来描述数据。*输入* 指的是在处理前数据集中的单个列，而 *特征* 则指处理后的单个列。例如，时间戳可以是你的输入，而特征则是一周中的某一天。要将数据从时间戳转换为一周中的某一天，你需要进行一些数据预处理。这个预处理步骤也可以称为
    *数据转换*。
- en: 'An *instance* is an item you’d like to send to your model for prediction. An
    instance could be a row in your test dataset (without the label column), an image
    you want to classify, or a text document to send to a sentiment analysis model.
    Given a set of features about the instance, the model will calculate a predicted
    value. In order to do that, the model is trained on *training examples*, which
    associate an instance with a *label*. A *training example* refers to a single
    instance (row) of data from your dataset that will be fed to your model. Building
    on the timestamp use case, a full training example might include: “day of week,”
    “city,” and “type of car.” A *label* is the output column in your dataset—the
    item your model is predicting. *Label* can refer both to the target column in
    your dataset (also called a *ground truth label*) and the output given by your
    model (also called a *prediction*). A sample label for the training example outlined
    above could be “trip duration”—in this case, a float value denoting minutes.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*实例*是您想要发送到模型进行预测的项目。 实例可以是测试数据集中的一行（不包括标签列），要分类的图像，或者要发送给情感分析模型的文本文档。 给定实例的特征集，模型将计算预测值。
    为了做到这一点，模型是在*训练示例*上进行训练的，这些示例将实例与*标签*关联起来。 *训练示例*指的是从数据集中提取的单个实例（行），将其馈送到模型中。
    基于时间戳用例，完整的训练示例可能包括：“星期几”，“城市”和“汽车类型”。 *标签*是数据集中的输出列-模型正在预测的项目。 *标签*可以同时指数据集中的目标列（也称为*地面实况标签*）和模型提供的输出（也称为*预测*）。
    例如，上述训练示例的一个样本标签可能是“行程持续时间”-在这种情况下，是表示分钟的浮点值。'
- en: Once you’ve assembled your dataset and determined the features for your model,
    *data validation* is the process of computing statistics on your data, understanding
    your schema, and evaluating the dataset to identify problems like drift and training-serving
    skew. Evaluating various statistics on your data can help you ensure the dataset
    contains a balanced representation of each feature. In cases where it’s not possible
    to collect more data, understanding data balance will help you design your model
    to account for this. Understanding your schema involves defining the data type
    for each feature and identifying training examples where certain values may be
    incorrect or missing. Finally, data validation can identify inconsistencies that
    may affect the quality of your training and test sets. For example, maybe the
    majority of your training dataset contains *weekday* examples while your test
    set contains primarily *weekend* examples.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您组装好数据集并确定了模型的特征，*数据验证*就是计算数据统计信息，理解架构并评估数据集以识别漂移和训练-服务偏差等问题的过程。 对数据进行各种统计信息的评估可以帮助您确保数据集包含每个特征的平衡表示。
    在无法收集更多数据的情况下，理解数据平衡将帮助您设计模型以解决这个问题。 理解您的架构涉及为每个特征定义数据类型，并识别其中某些值可能不正确或缺失的训练示例。
    最后，数据验证可以识别可能影响训练和测试集质量的不一致之处。 例如，也许您的大部分训练数据集包含*工作日*示例，而您的测试集主要包含*周末*示例。
- en: The Machine Learning Process
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习流程
- en: The first step in a typical machine learning workflow is *training*—the process
    of passing training data to a model so that it can learn to identify patterns.
    After training, the next step in the process is testing how your model performs
    on data outside of your training set. This is known as model *evaluation*. You
    might run training and evaluation multiple times, performing additional feature
    engineering and tweaking your model architecture. Once you are happy with your
    model’s performance during evaluation, you’ll likely want to serve your model
    so that others can access it to make predictions. We use the term *serving* to
    refer to accepting incoming requests and sending back predictions by deploying
    the model as a microservice. The serving infrastructure could be in the cloud,
    on-premises, or on-device.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的机器学习工作流程中的第一步是*训练*——将训练数据传递给模型，使其能够学习识别模式。 训练后，流程的下一步是测试模型在训练集之外的数据上的表现。
    这称为模型*评估*。 您可能会多次运行训练和评估，进行额外的特征工程并调整模型架构。 一旦您对模型在评估过程中的性能感到满意，您可能会希望提供您的模型，以便其他人可以访问它来进行预测。
    我们使用术语*服务*来接受传入请求，并通过将模型部署为微服务来发送预测。 服务基础设施可以在云端、本地或设备上。
- en: The process of sending new data to your model and making use of its output is
    called *prediction*. This can refer both to generating predictions from local
    models that have not yet been deployed as well as getting predictions from deployed
    models. For deployed models, we’ll refer both to online and batch prediction.
    *Online prediction* is used when you want to get predictions on a few examples
    in near real time. With online prediction, the emphasis is on low latency. *Batch
    prediction*, on the other hand, refers to generating predictions on a large set
    of data offline. Batch prediction jobs take longer than online prediction and
    are useful for precomputing predictions (such as in recommendation systems) and
    in analyzing your model’s predictions across a large sample of new data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 向模型发送新数据并利用其输出的过程称为*预测*。这既可以指尚未部署的本地模型生成预测，也可以指获取已部署模型的预测结果。对于已部署的模型，我们将同时提到在线预测和批处理预测。*在线预测*用于在几个示例上近实时获取预测结果。在线预测强调低延迟。另一方面，*批处理预测*是指在大量数据上离线生成预测。批处理预测作业比在线预测时间长，适用于预先计算预测结果（例如在推荐系统中），以及分析模型在大量新数据样本上的预测表现。
- en: The word *prediction* is apt when it comes to forecasting future values, such
    as in predicting the duration of a bicycle ride or predicting whether a shopping
    cart will be abandoned. It is less intuitive in the case of image and text classification
    models. If an ML model looks at a text review and outputs that the sentiment is
    positive, it’s not really a “prediction” (there is no future outcome). Hence,
    you will also see word *inference* being used to refer to predictions. The statistical
    term inference is being repurposed here, but it’s not really about reasoning.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测未来值时，如预测自行车骑行时间或预测购物车是否会被放弃，使用词语*预测*非常恰当。但在图像和文本分类模型的情况下，这种用法就不那么直观了。如果一个机器学习模型分析文本评论并输出情感是积极的，这并不算是一个真正的“预测”（因为没有未来结果）。因此，你也会看到词语*推断*用于指代预测。这里推断这一统计术语被重新定义，但实际上并不涉及推理过程。
- en: Often, the processes of collecting training data, feature engineering, training,
    and evaluating your model are handled separately from the production pipeline.
    When this is the case, you’ll reevaluate your solution whenever you decide you
    have enough additional data to train a new version of your model. In other situations,
    you may have new data being ingested continuously and need to process this data
    immediately before sending it to your model for training or prediction. This is
    known as *streaming*. To handle streaming data, you’ll need a multistep solution
    for performing feature engineering, training, evaluation, and predictions. Such
    multistep solutions are called *ML pipelines*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，收集训练数据、特征工程、训练和评估模型的过程是与生产管道分开处理的。在这种情况下，当您认为有足够的额外数据可以训练新版本的模型时，将重新评估您的解决方案。在其他情况下，可能会持续不断地摄入新数据，并需要在将其送入模型进行训练或预测之前立即处理这些数据。这被称为*流式处理*。为了处理流式数据，您将需要一个多步骤解决方案来执行特征工程、训练、评估和预测。这样的多步骤解决方案被称为*ML流水线*。
- en: Data and Model Tooling
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据与模型工具
- en: There are various Google Cloud products we’ll be referencing that provide tooling
    for solving data and machine learning problems. These products are merely one
    option for implementing the design patterns referenced in this book and are not
    meant to be an exhaustive list. All of the products included here are serverless,
    allowing us to focus more on implementing machine learning design patterns instead
    of the infrastructure behind them.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将引用多种谷歌云产品，提供解决数据和机器学习问题的工具。这些产品只是在本书中实现设计模式的一种选择，而非详尽的列表。所有这些产品都是无服务器的，使我们能够更专注于实现机器学习设计模式，而不是它们背后的基础设施。
- en: '[*BigQuery*](https://oreil.ly/7PnVj) is an enterprise data warehouse designed
    for analyzing large datasets quickly with SQL. We’ll use BigQuery in our examples
    for data collection and feature engineering. Data in BigQuery is organized by
    Datasets, and a Dataset can have multiple Tables. Many of our examples will use
    data from [*Google Cloud Public Datasets*](https://oreil.ly/AbTaJ), a set of free,
    publicly available data hosted in BigQuery. Google Cloud Public Datasets consists
    of hundreds of different datasets, including NOAA weather data since 1929, Stack
    Overflow questions and answers, open source code from GitHub, natality data, and
    more. To build some of the models in our examples, we’ll use [*BigQuery Machine
    Learning*](https://oreil.ly/_VjVz) (or BigQuery ML). BigQuery ML is a tool for
    building models from data stored in BigQuery. With BigQuery ML, we can train,
    evaluate, and generate predictions on our models using SQL. It supports classification
    and regression models, along with unsupervised clustering models. It’s also possible
    to import previously trained TensorFlow models to BigQuery ML for prediction.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[*BigQuery*](https://oreil.ly/7PnVj) 是一种专为通过SQL快速分析大型数据集而设计的企业数据仓库。我们将在示例中使用BigQuery进行数据收集和特征工程。BigQuery中的数据通过数据集（Datasets）进行组织，一个数据集可以包含多个表（Tables）。我们的许多示例将使用来自[*Google
    Cloud Public Datasets*](https://oreil.ly/AbTaJ)的数据，这是一组在BigQuery中免费提供的公共数据。Google
    Cloud Public Datasets包括数百个不同的数据集，包括从1929年起的NOAA天气数据，Stack Overflow的问题与回答，GitHub的开源代码，出生率数据等等。为了构建一些示例中的模型，我们将使用[*BigQuery
    Machine Learning*](https://oreil.ly/_VjVz)（或简称BigQuery ML）。BigQuery ML是一个用于从BigQuery存储的数据构建模型的工具。使用BigQuery
    ML，我们可以使用SQL训练、评估和生成模型的预测。它支持分类和回归模型以及无监督的聚类模型。还可以将之前训练好的TensorFlow模型导入BigQuery
    ML进行预测。'
- en: '[*Cloud AI Platform*](https://oreil.ly/90KLs) includes a variety of products
    for training and serving custom machine learning models on Google Cloud. In our
    examples, we’ll be using AI Platform Training and AI Platform Prediction. AI Platform
    Training provides infrastructure for training machine learning models on Google
    Cloud. With AI Platform Prediction, you can deploy your trained models and generate
    predictions on them using an API. Both services support TensorFlow, scikit-Learn,
    and XGBoost models, along with custom containers for models built with other frameworks.
    We’ll also reference [*Explainable AI*](https://oreil.ly/lDocn), a tool for interpreting
    the results of your model’s predictions, available for models deployed to AI Platform.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[*Cloud AI Platform*](https://oreil.ly/90KLs) 包括多种产品，用于在Google Cloud上训练和提供自定义机器学习模型。在我们的示例中，我们将使用AI
    Platform Training和AI Platform Prediction。AI Platform Training提供Google Cloud上的机器学习模型训练基础设施。通过AI
    Platform Prediction，您可以部署已训练的模型并使用API生成预测。这两项服务支持TensorFlow、scikit-Learn和XGBoost模型，以及使用其他框架构建的自定义容器模型。我们还将提到[*Explainable
    AI*](https://oreil.ly/lDocn)，这是一个用于解释模型预测结果的工具，适用于部署到AI Platform的模型。'
- en: Roles
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 角色
- en: Within an organization, there are many different job roles relating to data
    and machine learning. Below we’ll define a few common ones referenced frequently
    throughout the book. This book is targeted primarily at data scientists, data
    engineers, and ML engineers, so let’s start with those.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个组织中，涉及数据和机器学习的许多不同职务角色。以下是书中经常提到的一些常见角色定义。本书主要针对数据科学家、数据工程师和ML工程师，我们先从这些角色开始。
- en: A *data scientist* is someone focused on collecting, interpreting, and processing
    datasets. They run statistical and exploratory analysis on data. As it relates
    to machine learning, a data scientist may work on data collection, feature engineering,
    model building, and more. Data scientists often work in Python or R in a notebook
    environment, and are usually the first to build out an organization’s machine
    learning models.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据科学家* 是专注于收集、解释和处理数据集的人员。他们对数据进行统计和探索性分析。在涉及机器学习时，数据科学家可能参与数据收集、特征工程、模型构建等工作。数据科学家通常在Python或R的笔记本环境中工作，并且通常是组织内第一个构建机器学习模型的人员。'
- en: A *data engineer* is focused on the infrastructure and workflows powering an
    organization’s data. They might help manage how a company ingests data, data pipelines,
    and how data is stored and transferred. Data engineers implement infrastructure
    and pipelines around data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据工程师* 专注于支持组织数据的基础架构和工作流程。他们可能帮助管理公司如何摄取数据、数据管道以及数据的存储和传输方式。数据工程师实施围绕数据的基础设施和管道。'
- en: '*Machine learning engineers* do similar tasks to data engineers, but for ML
    models. They take models developed by data scientists, and manage the infrastructure
    and operations around training and deploying those models. ML engineers help build
    production systems to handle updating models, model versioning, and serving predictions
    to end users.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*机器学习工程师*执行与数据工程师类似的任务，但针对的是机器学习模型。他们接手数据科学家开发的模型，并管理围绕训练和部署这些模型的基础设施和运营。机器学习工程师帮助构建生产系统，处理模型更新、模型版本管理，并向最终用户提供预测服务。'
- en: The smaller the data science team at a company and the more agile the team is,
    the more likely it is that the same person plays multiple roles. If you are in
    such a situation, it is very likely that you read the above three descriptions
    and saw yourself partially in all three categories. You might commonly start out
    a machine learning project as a data engineer and build data pipelines to operationalize
    the ingest of data. Then, you transition to the data scientist role and build
    the ML model(s). Finally, you put on the ML engineer hat and move the model to
    production. In larger organizations, machine learning projects may move through
    the same phases, but different teams might be involved in each phase.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在一家公司，数据科学团队越小且团队越敏捷，同一个人承担多个角色的可能性就越大。如果你处于这种情况下，很可能你读到上述三种描述时，在所有三类中都能找到自己的一部分影子。你可能通常会以数据工程师的身份开始一个机器学习项目，构建数据管道以实现数据的摄取。然后，你会转向数据科学家的角色，建立机器学习模型。最后，你会换上机器学习工程师的帽子，将模型移植到生产环境中。在规模较大的组织中，机器学习项目可能会经历相同的阶段，但每个阶段可能会涉及不同的团队。
- en: Research scientists, data analysts, and developers may also build and use AI
    models, but these job roles are not a focus audience for this book.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 研究科学家、数据分析师和开发人员也可能构建和使用AI模型，但这些工作角色并不是本书的焦点读者群。
- en: '*Research scientists* focus primarily on finding and developing new algorithms
    to advance the discipline of ML. This could include a variety of subfields within
    machine learning, like model architectures, natural language processing, computer
    vision, hyperparameter tuning, model interpretability, and more. Unlike the other
    roles discussed here, research scientists spend most of their time prototyping
    and evaluating new approaches to ML, rather than building out production ML systems.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*研究科学家*主要专注于找到和开发新的算法来推动机器学习学科的发展。这可能涉及机器学习的多个子领域，如模型架构、自然语言处理、计算机视觉、超参数调整、模型可解释性等等。与本文中讨论的其他角色不同，研究科学家大部分时间用于原型设计和评估新的机器学习方法，而不是构建生产环境中的机器学习系统。'
- en: '*Data analysts* evaluate and gather insights from data, then summarize these
    insights for other teams within their organization. They tend to work in SQL and
    spreadsheets, and use business intelligence tools to create data visualizations
    to share their findings. Data analysts work closely with product teams to understand
    how their insights can help address business problems and create value. While
    data analysts focus on identifying trends in existing data and deriving insights
    from it, data scientists are concerned with using that data to generate future
    predictions and in automating or scaling out the generation of insights. With
    the increasing democratization of machine learning, data analysts can upskill
    themselves to become data scientists.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据分析师*评估和从数据中获取洞见，然后为组织内的其他团队总结这些洞见。他们倾向于在SQL和电子表格中工作，并使用商业智能工具创建数据可视化来分享他们的发现。数据分析师与产品团队密切合作，了解他们的洞见如何帮助解决业务问题并创造价值。虽然数据分析师专注于识别现有数据中的趋势并从中获得洞见，数据科学家则关注如何利用这些数据生成未来的预测，并自动化或扩展洞见的生成。随着机器学习的民主化趋势，数据分析师可以通过提升自己的技能成为数据科学家。'
- en: '*Developers* are in charge of building production systems that enable end users
    to access ML models. They are often involved in designing the APIs that query
    models and return predictions in a user-friendly format via a web or mobile application.
    This could involve models hosted in the cloud, or models served on-device. Developers
    utilize the model serving infrastructure implemented by ML Engineers to build
    applications and user interfaces for surfacing predictions to model users.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*开发人员*负责构建能让最终用户访问机器学习模型的生产系统。他们通常参与设计API，用于查询模型并以用户友好的方式通过Web或移动应用返回预测结果。这可能涉及在云中托管模型或在设备上提供模型。开发人员利用由机器学习工程师实施的模型服务基础设施来构建应用程序和用户界面，以向模型用户呈现预测结果。'
- en: '[Figure 1-2](#there_are_many_different_job_roles_rela) illustrates how these
    different roles work together throughout an organization’s machine learning model
    development process.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-2](#there_are_many_different_job_roles_rela)展示了这些不同角色如何在一个组织的机器学习模型开发过程中共同合作。'
- en: '![There are many different job roles relating to data and machine learning,
    and these roles collaborate on the ML workflow, from data ingestion to model serving
    and the end user interface. For example, the data engineer works on data ingestion
    and data validation and collaborates closely with data scientists.](Images/mldp_0102.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![与数据和机器学习相关的许多不同工作角色，在机器学习工作流中进行协作，从数据摄取到模型服务和最终用户界面。例如，数据工程师负责数据摄取和数据验证，并与数据科学家密切合作。](Images/mldp_0102.png)'
- en: Figure 1-2\. There are many different job roles related to data and machine
    learning, and these roles collaborate on the ML workflow, from data ingestion
    to model serving and the end user interface. For example, the data engineer works
    on data ingestion and data validation and collaborates closely with data scientists.
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2。与数据和机器学习相关的许多不同工作角色，这些角色在机器学习工作流中进行协作，从数据摄取到模型服务和最终用户界面。例如，数据工程师负责数据摄取和数据验证，并与数据科学家密切合作。
- en: Common Challenges in Machine Learning
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的常见挑战
- en: Why do we need a book about machine learning design patterns? The process of
    building out ML systems presents a variety of unique challenges that influence
    ML design. Understanding these challenges will help you, an ML practitioner, develop
    a frame of reference for the solutions introduced throughout the book.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们需要一本关于机器学习设计模式的书？构建机器学习系统的过程中存在多种独特的挑战，这些挑战影响着机器学习的设计。理解这些挑战将有助于您作为机器学习从业者，在整本书中介绍的解决方案中建立一个参考框架。
- en: Data Quality
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据质量
- en: 'Machine learning models are only as reliable as the data used to train them.
    If you train a machine learning model on an incomplete dataset, on data with poorly
    selected features, or on data that doesn’t accurately represent the population
    using the model, your model’s predictions will be a direct reflection of that
    data. As a result, machine learning models are often referred to as “garbage in,
    garbage out.” Here we’ll highlight four important components of data quality:
    accuracy, completeness, consistency, and timeliness.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的可靠性取决于用于训练它们的数据。如果您在不完整的数据集、选择不当的特征或不能准确代表使用该模型的人群的数据上训练机器学习模型，那么您的模型的预测将直接反映出这些数据的情况。因此，机器学习模型通常被称为“垃圾进垃圾出”。在这里，我们将重点介绍数据质量的四个重要组成部分：准确性、完整性、一致性和及时性。
- en: Data *accuracy* refers to both your training data’s features and the ground
    truth labels corresponding with those features. Understanding where your data
    came from and any potential errors in the data collection process can help ensure
    feature accuracy. After your data has been collected, it’s important to do a thorough
    analysis to screen for typos, duplicate entries, measurement inconsistencies in
    tabular data, missing features, and any other errors that may affect data quality.
    Duplicates in your training dataset, for example, can cause your model to incorrectly
    assign more weight to these data points.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 数据*准确性*既涉及您的训练数据的特征，也涉及与这些特征对应的地面真相标签。了解数据的来源以及数据收集过程中可能存在的任何错误可以帮助确保特征的准确性。在数据收集完成后，进行彻底分析以筛查拼写错误、重复条目、表格数据中的测量不一致性、缺失特征以及可能影响数据质量的任何其他错误非常重要。例如，训练数据集中的重复条目可能导致模型错误地为这些数据点分配更多的权重。
- en: Accurate data labels are just as important as feature accuracy. Your model relies
    solely on the ground truth labels in your training data to update its weights
    and minimize loss. As a result, incorrectly labeled training examples can cause
    misleading model accuracy. For example, let’s say you’re building a sentiment
    analysis model and 25% of your “positive” training examples have been incorrectly
    labeled as “negative.” Your model will have an inaccurate picture of what should
    be considered negative sentiment, and this will be directly reflected in its predictions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 准确的数据标签与特征准确性同样重要。您的模型仅依赖于训练数据中的地面真相标签来更新其权重并最小化损失。因此，错误标记的训练样本可能导致误导性的模型准确性。例如，假设您正在构建一个情感分析模型，其中25%的“正面”训练示例被错误标记为“负面”。您的模型将对什么应该被视为负面情感有一个不准确的理解，并且这将直接反映在其预测中。
- en: To understand data *completeness*, let’s say you’re training a model to identify
    cat breeds. You train the model on an extensive dataset of cat images, and the
    resulting model is able to classify images into 1 of 10 possible categories (“Bengal,”
    “Siamese,” and so forth) with 99% accuracy. When you deploy your model to production,
    however, you find that in addition to uploading cat photos for classification,
    many of your users are uploading photos of dogs and are disappointed with the
    model’s results. Because the model was trained only to identify 10 different cat
    breeds, this is all it knows how to do. These 10 breed categories are, essentially,
    the model’s entire “world view.” No matter what you send the model, you can expect
    it to slot it into one of these 10 categories. It may even do so with high confidence
    for an image that looks nothing like a cat. Additionally, there’s no way your
    model will be able to return “not a cat” if this data and label weren’t included
    in the training dataset.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解数据*完整性*，假设你正在训练一个模型来识别猫的品种。你在一个广泛的猫图像数据集上训练模型，结果模型能够将图像分类为10个可能的类别之一（“孟加拉猫”，“暹罗猫”等），准确率达到99%。然而，当你将模型部署到生产环境时，你发现除了上传猫照片进行分类外，许多用户还上传了狗的照片，并对模型的结果感到失望。因为模型只被训练来识别10种不同的猫品种，这就是它知道如何做的全部。这10种品种类别，本质上就是模型的整个“世界观”。无论你发送什么样的图像给模型，它都会将其分类为这10个类别之一。即使是看起来一点也不像猫的图像，它也可能以很高的置信度进行分类。此外，如果在训练数据集中没有包括这些数据和标签，“不是猫”的返回结果也无法由模型实现。
- en: Another aspect of data completeness is ensuring your training data contains
    a varied representation of each label. In the cat breed detection example, if
    all of your images are close-ups of a cat’s face, your model won’t be able to
    correctly identify an image of a cat from the side, or a full-body cat image.
    To look at a tabular data example, if you are building a model to predict the
    price of real estate in a specific city but only include training examples of
    houses larger than 2,000 square feet, your resulting model will perform poorly
    on smaller houses.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 数据完整性的另一个方面是确保你的训练数据包含每个标签的多样化代表。以猫品种检测为例，如果你所有的图像都是猫脸的特写，那么你的模型将无法正确识别侧面或全身的猫图像。再看一个表格数据的例子，如果你正在建立一个模型来预测特定城市房地产的价格，但只包括大于2000平方英尺的房屋的训练样本，那么你得到的模型将在较小的房屋上表现不佳。
- en: The third aspect of data quality is data *consistency*. For large datasets,
    it’s common to divide the work of data collection and labeling among a group of
    people. Developing a set of standards for this process can help ensure consistency
    across your dataset, since each person involved in this will inevitably bring
    their own biases to the process. Like data completeness, data inconsistencies
    can be found in both data features and labels. For an example of inconsistent
    features, let’s say you’re collecting atmospheric data from temperature sensors.
    If each sensor has been calibrated to different standards, this will result in
    inaccurate and unreliable model predictions. Inconsistencies can also refer to
    data format. If you’re capturing location data, some people may write out a full
    street address as “Main Street” and others may abbreviate it as “Main St.” Measurement
    units, like miles and kilometers, can also differ around the world.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量的第三个方面是数据*一致性*。对于大型数据集，将数据收集和标记工作分配给一组人是很常见的。制定这一过程的一套标准可以帮助确保数据集的一致性，因为参与其中的每个人都会不可避免地带入他们自己的偏见。像数据完整性一样，数据不一致性可以在数据特征和标签中找到。例如，在不一致的特征方面，假设你正在从温度传感器收集大气数据。如果每个传感器都校准到不同的标准，那么将导致不准确和不可靠的模型预测。不一致性还可以指数据格式。如果你正在捕捉位置数据，有些人可能会将完整街道地址写成“Main
    Street”，而其他人可能会缩写为“Main St.”，而测量单位，如英里和公里，在世界各地也可能不同。
- en: 'In regards to labeling inconsistencies, let’s return to the text sentiment
    example. In this case, it’s likely people will not always agree on what is considered
    positive and negative when labeling training data. To solve this, you can have
    multiple people labeling each example in your dataset, then take the most commonly
    applied label for each item. Being aware of potential labeler bias, and implementing
    systems to account for it, will ensure label consistency throughout your dataset.
    We’ll explore the concept of bias in the [“Design Pattern 30: Fairness Lens”](ch07.xhtml#design_pattern_threezero_fairness_lens)
    in [Chapter 7](ch07.xhtml#responsible_ai).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 关于标签一致性问题，让我们回到文本情感分类的例子。在这种情况下，当标记训练数据时，人们可能不会总是同意什么是正面和负面。为了解决这个问题，你可以让多人为数据集中的每个示例进行标记，然后采用每个项上应用最常见的标签。意识到可能存在的标签者偏见，并实施系统来解决这个问题，将确保数据集中的标签一致性。我们将在[第七章](ch07.xhtml#responsible_ai)中探讨“设计模式30：公平性视角”中的偏见概念。
- en: '*Timeliness* in data refers to the latency between when an event occurred and
    when it was added to your database. If you’re collecting data on application logs,
    for example, an error log might take a few hours to show up in your log database.
    For a dataset recording credit card transactions, it might take one day from when
    the transaction occurred before it is reported in your system. To deal with timeliness,
    it’s useful to record as much information as possible about a particular data
    point, and make sure that information is reflected when you transform your data
    into features for a machine learning model. More specifically, you can keep track
    of the timestamp of when an event occurred and when it was added to your dataset.
    Then, when performing feature engineering, you can account for these differences
    accordingly.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据的及时性* 指的是事件发生与其被添加到数据库之间的延迟。例如，如果你收集应用程序日志数据，错误日志可能需要几个小时才会出现在日志数据库中。对于记录信用卡交易的数据集，从交易发生到报告到系统中可能需要一天时间。为了处理数据的及时性，记录关于特定数据点的尽可能多的信息是有用的，并确保这些信息在将数据转换为机器学习模型特征时得到反映。更具体地说，你可以跟踪事件发生的时间戳以及将其添加到数据集中的时间。然后，在进行特征工程时，可以相应地考虑这些差异。'
- en: Reproducibility
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可复现性
- en: In traditional programming, the output of a program is reproducible and guaranteed.
    For example, if you write a Python program that reverses a string, you know that
    an input of the word “banana” will always return an output of “ananab.” Similarly,
    if there’s a bug in your program causing it to incorrectly reverse strings containing
    numbers, you could send the program to a colleague and expect them to be able
    to reproduce the error with the same inputs you used (unless the bug has something
    to do with the program maintaining some incorrect internal state, differences
    in architecture such as floating point precision, or differences in execution
    such as threading).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统编程中，程序的输出是可复现且有保证的。例如，如果你编写一个反转字符串的 Python 程序，你知道输入单词“banana”将始终返回“ananab”的输出。同样地，如果你的程序有一个
    bug 导致它错误地反转包含数字的字符串，你可以将程序发送给同事，并期望他们能够使用相同的输入复现错误（除非 bug 与程序保持一些错误的内部状态、架构差异如浮点精度或执行差异如线程有关）。
- en: Machine learning models, on the other hand, have an inherent element of randomness.
    When training, ML model weights are initialized with random values. These weights
    then converge during training as the model iterates and learns from the data.
    Because of this, the same model code given the same training data will produce
    slightly different results across training runs. This introduces a challenge of
    reproducibility. If you train a model to 98.1% accuracy, a repeated training run
    is not guaranteed to reach the same result. This can make it difficult to run
    comparisons across experiments.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，机器学习模型具有一定的随机性元素。在训练时，ML 模型权重使用随机值进行初始化。随着模型迭代并从数据中学习，这些权重逐渐收敛。因此，给定相同的训练数据，相同的模型代码将在训练运行中产生略有不同的结果。这引入了可复现性的挑战。如果你训练一个模型达到了98.1%的准确率，重复的训练运行不保证会达到相同的结果。这可能使得跨实验进行比较变得困难。
- en: In order to address this problem of repeatability, it’s common to set the random
    seed value used by your model to ensure that the same randomness will be applied
    each time you run training. In TensorFlow, you can do this by running `tf.random.set_seed(value)`
    at the beginning of your program.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这种重复性问题，通常会将模型使用的随机种子值设置为固定值，以确保每次运行训练时应用相同的随机性。在 TensorFlow 中，您可以通过在程序开头运行
    `tf.random.set_seed(value)` 来实现这一点。
- en: 'Additionally, in scikit-learn, many utility functions for shuffling your data
    also allow you to set a random seed value:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，在 scikit-learn 中，许多用于洗牌数据的实用函数还允许您设置随机种子值：
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Keep in mind that you’ll need to use the same data *and* the same random seed
    when training your model to ensure repeatable, reproducible results across different
    experiments.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在训练模型时需要使用相同的数据 *和* 相同的随机种子，以确保在不同实验中获得可重复的结果。
- en: 'Training an ML model involves several artifacts that need to be fixed in order
    to ensure reproducibility: the data used, the splitting mechanism used to generate
    datasets for training and validation, data preparation and model hyperparameters,
    and variables like the batch size and learning rate schedule.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 ML 模型涉及多个需要固定的工件，以确保可重复性：使用的数据、用于生成训练和验证数据集的分割机制、数据准备和模型超参数，以及诸如批量大小和学习率调度等变量。
- en: Reproducibility also applies to machine learning framework dependencies. In
    addition to manually setting a random seed, frameworks also implement elements
    of randomness internally that are executed when you call a function to train your
    model. If this underlying implementation changes between different framework versions,
    repeatability is not guaranteed. As a concrete example, if one version of a framework’s
    `train()` method makes 13 calls to `rand()`, and a newer version of the same framework
    makes 14 calls, using different versions between experiments will cause slightly
    different results, even with the same data and model code. Running ML workloads
    in containers and standardizing library versions can help ensure repeatability.
    [Chapter 6](ch06_split_000.xhtml#reproducibility_design_patterns) introduces a
    series of patterns for making ML processes reproducible.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 可重复性还适用于机器学习框架依赖项。除了手动设置随机种子外，框架还在调用训练模型函数时内部实现了随机性元素。如果这些底层实现在不同框架版本之间发生更改，重复性就无法保证。具体而言，如果一个框架版本的
    `train()` 方法调用 `rand()` 13 次，而同一框架的新版本调用 14 次，则在不同实验之间使用不同版本会导致稍有不同的结果，即使使用相同的数据和模型代码。在容器中运行
    ML 工作负载并标准化库版本可以帮助确保重复性。[第 6 章](ch06_split_000.xhtml#reproducibility_design_patterns)介绍了一系列用于实现
    ML 过程可重复性的模式。
- en: Finally, reproducibility can refer to a model’s training environment. Often,
    due to large datasets and complexity, many models take a significant amount of
    time to train. This can be accelerated by employing distribution strategies like
    data or model parallelism (see [Chapter 5](ch05.xhtml#design_patterns_for_resilient_serving)).
    With this acceleration, however, comes an added challenge of repeatability when
    you rerun code that makes use of distributed training.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，可重复性还可能指模型的训练环境。通常由于大型数据集和复杂性，许多模型需要大量时间来训练。通过采用数据或模型并行等分布策略可以加速此过程（参见[第
    5 章](ch05.xhtml#design_patterns_for_resilient_serving)）。然而，当重新运行利用分布式训练的代码时，重复性也带来了额外的挑战。
- en: Data Drift
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据漂移
- en: While machine learning models typically represent a static relationship between
    inputs and outputs, data can change significantly over time. Data drift refers
    to the challenge of ensuring your machine learning models stay relevant, and that
    model predictions are an accurate reflection of the environment in which they’re
    being used.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然机器学习模型通常代表输入和输出之间的静态关系，但数据随时间可能会发生显著变化。数据漂移指的是确保机器学习模型保持相关性，并且模型预测能够准确反映其使用环境的挑战。
- en: For example, let’s say you’re training a model to classify news article headlines
    into categories like “politics,” “business,” and “technology.” If you train and
    evaluate your model on historical news articles from the 20th century, it likely
    won’t perform as well on current data. Today, we know that an article with the
    word “smartphone” in the headline is probably about technology. However, a model
    trained on historical data would have no knowledge of this word. To solve for
    drift, it’s important to continually update your training dataset, retrain your
    model, and modify the weight your model assigns to particular groups of input
    data.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您正在训练一个模型来将新闻文章标题分类为“政治”、“商业”和“技术”等类别。如果您在20世纪的历史新闻文章上训练和评估您的模型，它可能不会在当前数据上表现出色。今天，我们知道标题中含有“智能手机”一词的文章可能是关于技术的。然而，一个在历史数据上训练的模型将不会知道这个词。为了解决漂移问题，持续更新您的训练数据集，重新训练您的模型，并修改模型分配给特定输入数据组的权重是非常重要的。
- en: To see a less-obvious example of drift, look at the [NOAA dataset](https://oreil.ly/obzvn)
    of severe storms in BigQuery. If we were training a model to predict the likelihood
    of a storm in a given area, we would need to take into account the way weather
    reporting has [changed over time](https://github.com/GoogleCloudPlatform/ml-design-patterns/blob/master/01_need_for_design_patterns/ml_challenges.ipynb).
    We can see in [Figure 1-3](#number_of_severe_storms_reported_in_a_y) that the
    total number of severe storms recorded has been steadily increasing since 1950.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要看一个不太明显的漂移示例，请查看NOAA在BigQuery中的严重风暴数据集。如果我们正在训练一个模型来预测特定区域的风暴可能性，我们需要考虑天气报告随时间变化的方式。我们可以从《图1-3：年度记录的严重风暴数量》中看到，自1950年以来记录的严重风暴总数一直在稳步增加。
- en: '![Number of severe storms reported in a year, as recorded by NOAA from 1950
    to 2011.](Images/mldp_0103.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![1950年至2011年由NOAA记录的每年记录的严重风暴数量。](Images/mldp_0103.png)'
- en: Figure 1-3\. Number of severe storms reported in a year, as recorded by NOAA
    from 1950 to 2011.
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3. 1950年至2011年由NOAA记录的每年记录的严重风暴数量。
- en: 'From this trend, we can see that training a model on data before 2000 to generate
    predictions on storms today would lead to inaccurate predictions. In addition
    to the total number of reported storms increasing, it’s also important to consider
    other factors that may have influenced the data in [Figure 1-3](#number_of_severe_storms_reported_in_a_y).
    For example, the technology for observing storms has improved over time, most
    dramatically with the introduction of weather radars in the 1990s. In the context
    of features, this may mean that newer data contains more information about each
    storm, and that a feature available in today’s data may not have been observed
    in 1950\. Exploratory data analysis can help identify this type of drift and can
    inform the correct window of data to use for training. [Section , “Design Pattern
    23: Bridged Schema”](ch06_split_000.xhtml#design_pattern_twothree_bridged_schema)
    provides a way to handle datasets in which the availability of features improves
    over time.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一趋势中，我们可以看出，使用2000年以前的数据来训练模型，以预测今天的风暴，将导致不准确的预测。除了报告风暴总数增加外，还应考虑可能影响数据的其他因素，例如时间。例如，随着天气雷达在1990年代的引入，观测风暴的技术得到了显著改进。在特征的背景下，这可能意味着较新的数据包含了更多关于每场风暴的信息，并且今天的数据中可能存在的特征在1950年可能没有被观察到。探索性数据分析有助于识别这种漂移，并能够确定用于训练的正确数据时间窗口。《设计模式23：桥接架构》提供了处理随着时间推移特征可用性改善的数据集的方法。
- en: Scale
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规模
- en: The challenge of scaling is present throughout many stages of a typical machine
    learning workflow. You’ll likely encounter scaling challenges in data collection
    and preprocessing, training, and serving. When ingesting and preparing data for
    a machine learning model, the size of the dataset will dictate the tooling required
    for your solution. It is often the job of data engineers to build out data pipelines
    that can scale to handle datasets with millions of rows.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放问题贯穿了典型的机器学习工作流的许多阶段。在数据收集和预处理、训练以及服务过程中，您可能会遇到缩放挑战。当摄取和准备数据以供机器学习模型使用时，数据集的大小将决定所需解决方案的工具。通常情况下，数据工程师的工作是构建能够扩展处理包含数百万行数据集的数据管道。
- en: For model training, ML engineers are responsible for determining the necessary
    infrastructure for a specific training job. Depending on the type and size of
    the dataset, model training can be time consuming and computationally expensive,
    requiring infrastructure (like GPUs) designed specifically for ML workloads. Image
    models, for instance, typically require much more training infrastructure than
    models trained entirely on tabular data.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模型训练，机器学习工程师负责确定特定训练任务所需的基础设施。根据数据集的类型和大小，模型训练可能会耗时且计算成本高昂，需要专为机器学习工作负载设计的基础设施（如GPU）。例如，图像模型通常需要比完全基于表格数据训练的模型更多的训练基础设施。
- en: In the context of model serving, the infrastructure required to support a team
    of data scientists getting predictions from a model prototype is entirely different
    from the infrastructure necessary to support a production model getting millions
    of prediction requests every hour. Developers and ML engineers are typically responsible
    for handling the scaling challenges associated with model deployment and serving
    prediction requests.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型服务的背景下，支持数据科学家团队从模型原型获取预测所需的基础设施与支持生产模型每小时获得数百万预测请求所需的基础设施完全不同。开发人员和机器学习工程师通常负责处理与模型部署和服务预测请求相关的扩展挑战。
- en: Most of the ML patterns in this book are useful without regard to organizational
    maturity. However, several of the patterns in Chapters [6](ch06_split_000.xhtml#reproducibility_design_patterns)
    and [7](ch07.xhtml#responsible_ai) address resilience and reproducibility challenges
    in different ways, and the choice between them will often come down to the use
    case and the ability of your organization to absorb complexity.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的大多数机器学习模式无论组织成熟度如何都很有用。然而，第[6](ch06_split_000.xhtml#reproducibility_design_patterns)章和第[7](ch07.xhtml#responsible_ai)章中的几种模式以不同的方式解决了韧性和可再现性挑战，选择哪种模式通常取决于使用案例以及组织吸收复杂性的能力。
- en: Multiple Objectives
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多个目标
- en: Though there is often a single team responsible for building a machine learning
    model, many teams across an organization will make use of the model in some way.
    Inevitably, these teams may have different ideas of what defines a successful
    model.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管通常有一个团队负责构建机器学习模型，但组织中的许多团队都会以某种方式使用该模型。不可避免地，这些团队可能对定义成功模型有不同的看法。
- en: To understand how this may play out in practice, let’s say you’re building a
    model to identify defective products from images. As a data scientist, your goal
    may be to minimize your model’s cross-entropy loss. The product manager, on the
    other hand, may want to reduce the number of defective products that are misclassified
    and sent to customers. Finally, the executive team’s goal might be to increase
    revenue by 30%. Each of these goals vary in what they are optimizing for, and
    balancing these differing needs within an organization can present a challenge.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解这在实践中如何发挥作用，假设你正在构建一个模型来识别图像中的缺陷产品。作为数据科学家，你的目标可能是最小化模型的交叉熵损失。另一方面，产品经理可能希望减少被误分类并发送给客户的缺陷产品数量。最后，高管团队的目标可能是增加30%的收入。每个目标在其优化的方面存在差异，在组织内平衡这些不同需求可能是一项挑战。
- en: As a data scientist, you could translate the product team’s needs into the context
    of your model by saying false negatives are five times more costly than false
    positives. Therefore, you should optimize for recall over precision to satisfy
    this when designing your model. You can then find a balance between the product
    team’s goal of optimizing for precision and your goal of minimizing the model’s
    loss.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名数据科学家，你可以通过说假阴性的成本是假阳性的五倍来将产品团队的需求转化为你模型的上下文。因此，在设计模型时，你应该优化召回率而不是精确度来满足这一点。然后，你可以在产品团队优化精确度的目标和你最小化模型损失的目标之间找到平衡。
- en: When defining the goals for your model, it’s important to consider the needs
    of different teams across an organization, and how each team’s needs relate back
    to the model. By analyzing what each team is optimizing for before building out
    your solution, you can find areas of compromise in order to optimally balance
    these multiple objectives.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义模型的目标时，考虑到组织中不同团队的需求以及每个团队的需求如何与模型相关是很重要的。通过在构建解决方案之前分析每个团队的优化目标，你可以找到折中的领域，以最优地平衡这些多重目标。
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Design patterns are a way to codify the knowledge and experience of experts
    into advice that all practitioners can follow. The design patterns in this book
    capture best practices and solutions to commonly occurring problems in designing,
    building, and deploying machine learning systems. The common challenges in machine
    learning tend to revolve around data quality, reproducibility, data drift, scale,
    and having to satisfy multiple objectives.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 设计模式是将专家的知识和经验编码为所有从业者可以遵循的建议的一种方式。本书中的设计模式捕捉了在设计、构建和部署机器学习系统中常见问题的最佳实践和解决方案。机器学习中的常见挑战通常围绕数据质量、可重现性、数据漂移、规模以及满足多个目标展开。
- en: We tend to use different ML design patterns at different stages of the ML life
    cycle. There are patterns that are useful in problem framing and assessing feasibility.
    The majority of patterns address either development or deployment, and quite a
    few patterns address the interplay between these stages.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习生命周期的不同阶段，我们倾向于使用不同的ML设计模式。有些模式对问题框架和可行性评估非常有用。大多数模式涉及开发或部署，还有一些模式涉及这些阶段之间的相互作用。
