- en: Chapter 6\. Model Training
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第6章\. 模型训练
- en: Now that the data preprocessing step is complete and the data has been transformed
    into the format that our model requires, the next step in our pipeline is to train
    the model with the freshly transformed data.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据预处理步骤已经完成，并且数据已被转换为我们的模型所需的格式，我们管道中的下一步是使用新转换的数据训练模型。
- en: As we discussed in [Chapter 1](index_split_006.html#filepos46283), we won’t
    cover the process of choosing your model architecture. We assume that you have
    a separate experimentation process that took place before you even picked up this
    book and that you already know the type of model you wish to train. We discuss
    how to track this experimentation process in [Chapter 15](index_split_022.html#filepos1590301)
    because it helps with creating a full audit trail for the model. However, we don’t
    cover any of the theoretical background you’ll need to understand the model training
    process. If you would like to learn more about this, we strongly recommend the
    O’Reilly publication Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow,
    2nd edition.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 [第1章](index_split_006.html#filepos46283) 中讨论的，我们不会涵盖选择模型架构的过程。我们假设您在拿起本书之前已经进行了独立的实验过程，并且您已经知道要训练的模型类型。我们在
    [第15章](index_split_022.html#filepos1590301) 中讨论如何跟踪这个实验过程，因为它有助于为模型创建完整的审计跟踪。但我们不涵盖您需要了解模型训练过程的任何理论背景。如果您想进一步了解，请强烈推荐
    O'Reilly 出版的《Scikit-Learn、Keras 和 TensorFlow 实战：机器学习实用指南》第2版。
- en: In this chapter, we cover the model training process as part of a machine learning
    pipeline, including how it is automated in a TFX pipeline. We also include some
    details of distribution strategies available in TensorFlow and how to tune hyperparameters
    in a pipeline. This chapter is more specific to TFX pipelines than most of the
    others because we don’t cover training as a standalone process.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖作为机器学习管道一部分的模型训练过程，包括在 TFX 管道中如何自动化这一过程。我们还包括 TensorFlow 中可用的分布策略的一些细节，以及如何在管道中调整超参数。这一章比大多数其他章节更专注于
    TFX 管道，因为我们不单独涵盖训练作为一个独立的过程。
- en: As shown in [Figure 6-1](#filepos493820), by this point data has been ingested,
    validated, and preprocessed. This ensures that all the data needed by the model
    is present and that it has been reproducibly transformed into the features that
    the model requires. All of this is necessary because we don’t want the pipeline
    to fail at our next step. We want to ensure that the training proceeds smoothly
    because it is often the most time-consuming part of the entire pipeline.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 正如 [图6-1](#filepos493820) 所示，到这个时候数据已被摄取、验证和预处理。这确保了模型所需的所有数据都存在，并且已被可复制地转换为模型需要的特征。所有这些都是必要的，因为我们不希望管道在下一步失败。我们希望确保培训顺利进行，因为这通常是整个管道中耗时最长的部分。
- en: '![](images/00084.jpg)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00084.jpg)'
- en: Figure 6-1\. Model training as part of ML pipelines
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图6-1\. ML 管道中的模型训练
- en: One very important feature of training a model in a TFX pipeline is that the
    data preprocessing steps that we discussed in [Chapter 5](index_split_010.html#filepos397186)
    are saved along with the trained model weights. This is incredibly useful once
    our model is deployed to production because it means that the preprocessing steps
    will always produce the features the model is expecting. Without this feature,
    it would be possible to update the data preprocessing steps without updating the
    model, and then the model would fail in production or the predictions would be
    based on the wrong data. Because we export the preprocessing steps and the model
    as one graph, we eliminate this potential source of error.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TFX 管道中训练模型的一个非常重要的特性是，我们在 [第5章](index_split_010.html#filepos397186) 中讨论的数据预处理步骤会与训练好的模型权重一起保存。一旦我们的模型部署到生产环境中，这将非常有用，因为这意味着预处理步骤将始终生成模型期望的特征。如果没有这个特性，就有可能更新数据预处理步骤而不更新模型，那么模型在生产中可能会失败，或者预测将基于错误的数据。因为我们将预处理步骤和模型导出为一个图，所以我们消除了这种潜在的错误来源。
- en: In the next two sections, we’ll take a detailed look at the steps required to
    train a `tf.Keras` model as part of a TFX pipeline.[1](#filepos621373)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的两节中，我们将详细介绍作为 TFX 管道的一部分训练 `tf.Keras` 模型所需的步骤。[1](#filepos621373)
- en: Defining the Model for Our Example Project
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为我们的示例项目定义模型
- en: Even though the model architecture is already defined, some extra code is necessary
    here. We need to make it possible to automate the model training part of the pipeline.
    In this section, we will briefly describe the model we use throughout this chapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 即使模型架构已经定义，这里仍然需要一些额外的代码。我们需要使得能够自动化管道中的模型训练部分成为可能。在本节中，我们将简要描述我们在整个本章中使用的模型。
- en: 'The model for our example project is a hypothetical implementation, and we
    could probably optimize the model architecture. However, it showcases some common
    ingredients of many deep learning models:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们示例项目的模型是一个假设实现，我们可能需要优化模型架构。但是，它展示了许多深度学习模型的一些常见组成部分：
- en: Transfer learning from a pretrained model
  id: totrans-12
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从预训练模型进行迁移学习
- en: Dense layers
  id: totrans-13
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 密集层
- en: Concatenation layers
  id: totrans-14
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 连接层
- en: As we discussed in [Chapter 1](index_split_006.html#filepos46283), the model
    in our example project uses data from the US Consumer Finance Protection Bureau
    to predict whether a consumer disputed a complaint about a financial product.
    The features in our model include the financial product, the company’s response,
    the US state, and the consumer complaint narrative. Our model is inspired by the
    [Wide and Deep model architecture](https://oreil.ly/9sXHU), with the addition
    of the [Universal Sentence Encoder](https://oreil.ly/7BFZP) from [TensorFlow Hub](https://oreil.ly/0OJZ_)
    to encode the free-text feature (the consumer complaint narrative).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第一章](index_split_006.html#filepos46283)讨论的那样，我们示例项目中的模型使用来自美国消费者金融保护局的数据，以预测消费者是否对有关金融产品的投诉提出异议。我们模型的特征包括金融产品、公司的响应、美国州份和消费者投诉叙述。我们的模型受到[宽与深模型架构](https://oreil.ly/9sXHU)的启发，并添加了来自[TensorFlow
    Hub](https://oreil.ly/0OJZ_)的[Universal Sentence Encoder](https://oreil.ly/7BFZP)来编码自由文本特征（消费者投诉叙述）。
- en: You can see a visual representation of our model architecture in [Figure 6-2](#filepos497689),
    with the text feature (`narrative_xf`) taking the “deep” route and the other features
    taking the “wide” route.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[图 6-2](#filepos497689)中看到我们模型架构的视觉表示，其中文本特征（`narrative_xf`）采用“深层”路线，而其他特征采用“宽层”路线。
- en: '![](images/00093.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00093.jpg)'
- en: Figure 6-2\. Model architecture for our example project
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6-2\. 我们示例项目的模型架构
- en: '[Example 6-1](#filepos498554) shows the full model architecture definition.
    Because we want to export the model with our preprocessing steps, we need to guarantee
    that the model input names match the transformed feature names from `preprocessing_fn()`,
    which we discussed in [Chapter 5](index_split_010.html#filepos397186). In our
    example model, we reuse the `transformed_name()` function described in [Chapter 5](index_split_010.html#filepos397186)
    to add the suffix `_xf` to our features.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 6-1](#filepos498554)展示了完整的模型架构定义。因为我们希望导出带有我们预处理步骤的模型，我们需要确保模型输入名称与`preprocessing_fn()`转换的特征名称匹配，我们在[第五章](index_split_010.html#filepos397186)中讨论过。在我们的示例模型中，我们重用了在[第五章](index_split_010.html#filepos397186)中描述的`transformed_name()`函数，以添加后缀`_xf`到我们的特征中。'
- en: Example 6-1\. Defining our model architecture
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 6-1\. 定义我们的模型架构
- en: '`import``tensorflow``as``tf``import``tensorflow_hub``as``hub``def``transformed_name``(``key``):``return``key``+``''_xf''``def``get_model``():``#
    One-hot categorical features``input_features``=``[]``for``key``,``dim``in``ONE_HOT_FEATURES``.``items``():`![](images/00002.jpg)`input_features``.``append``(``tf``.``keras``.``Input``(``shape``=``(``dim``+``1``,),``name``=``transformed_name``(``key``)))``#
    Adding bucketized features``for``key``,``dim``in``BUCKET_FEATURES``.``items``():``input_features``.``append``(``tf``.``keras``.``Input``(``shape``=``(``dim``+``1``,),``name``=``transformed_name``(``key``)))``#
    Adding text input features``input_texts``=``[]``for``key``in``TEXT_FEATURES``.``keys``():``input_texts``.``append``(``tf``.``keras``.``Input``(``shape``=``(``1``,),``name``=``transformed_name``(``key``),``dtype``=``tf``.``string``))``inputs``=``input_features``+``input_texts``#
    Embed text features``MODULE_URL``=``"https://tfhub.dev/google/universal-sentence-encoder/4"``embed``=``hub``.``KerasLayer``(``MODULE_URL``)`![](images/00075.jpg)`reshaped_narrative``=``tf``.``reshape``(``input_texts``[``0``],``[``-``1``])`![](images/00064.jpg)`embed_narrative``=``embed``(``reshaped_narrative``)``deep_ff``=``tf``.``keras``.``layers``.``Reshape``((``512``,``),``input_shape``=``(``1``,``512``))(``embed_narrative``)``deep``=``tf``.``keras``.``layers``.``Dense``(``256``,``activation``=``''relu''``)(``deep_ff``)``deep``=``tf``.``keras``.``layers``.``Dense``(``64``,``activation``=``''relu''``)(``deep``)``deep``=``tf``.``keras``.``layers``.``Dense``(``16``,``activation``=``''relu''``)(``deep``)``wide_ff``=``tf``.``keras``.``layers``.``concatenate``(``input_features``)``wide``=``tf``.``keras``.``layers``.``Dense``(``16``,``activation``=``''relu''``)(``wide_ff``)``both``=``tf``.``keras``.``layers``.``concatenate``([``deep``,``wide``])``output``=``tf``.``keras``.``layers``.``Dense``(``1``,``activation``=``''sigmoid''``)(``both``)``keras_model``=``tf``.``keras``.``models``.``Model``(``inputs``,``output``)`![](images/00055.jpg)`keras_model``.``compile``(``optimizer``=``tf``.``keras``.``optimizers``.``Adam``(``learning_rate``=``0.001``),``loss``=``''binary_crossentropy''``,``metrics``=``[``tf``.``keras``.``metrics``.``BinaryAccuracy``(),``tf``.``keras``.``metrics``.``TruePositives``()``])``return``keras_model`'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '```import``tensorflow``as``tf``import``tensorflow_hub``as``hub``def``transformed_name``(``key``):``return``key``+``''_xf''``def``get_model``():``#
    One-hot分类特征``input_features``=``[]``for``key``,``dim``in``ONE_HOT_FEATURES``.``items``():`![](images/00002.jpg)`input_features``.``append``(``tf``.``keras``.``Input``(``shape``=``(``dim``+``1``,),``name``=``transformed_name``(``key``)))``#
    添加分桶特征``for``key``,``dim``in``BUCKET_FEATURES``.``items``():``input_features``.``append``(``tf``.``keras``.``Input``(``shape``=``(``dim``+``1``,),``name``=``transformed_name``(``key``)))``#
    添加文本输入特征``input_texts``=``[]``for``key``in``TEXT_FEATURES``.``keys``():``input_texts``.``append``(``tf``.``keras``.``Input``(``shape``=``(``1``,),``name``=``transformed_name``(``key``),``dtype``=``tf``.``string``))``inputs``=``input_features``+``input_texts``#
    嵌入文本特征``MODULE_URL``=``"https://tfhub.dev/google/universal-sentence-encoder/4"``embed``=``hub``.``KerasLayer``(``MODULE_URL``)`![](images/00075.jpg)`reshaped_narrative``=``tf``.``reshape``(``input_texts``[``0``],``[``-``1``])`![](images/00064.jpg)`embed_narrative``=``embed``(``reshaped_narrative``)``deep_ff``=``tf``.``keras``.``layers``.``Reshape``((``512``,``),``input_shape``=``(``1``,``512``))(``embed_narrative``)``deep``=``tf``.``keras``.``layers``.``Dense``(``256``,``activation``=``''relu''``)(``deep_ff``)``deep``=``tf``.``keras``.``layers``.``Dense``(``64``,``activation``=``''relu''``)(``deep``)``deep``=``tf``.``keras``.``layers``.``Dense``(``16``,``activation``=``''relu''``)(``deep``)``wide_ff``=``tf``.``keras``.``layers``.``concatenate``(``input_features``)``wide``=``tf``.``keras``.``layers``.``Dense``(``16``,``activation``=``''relu''``)(``wide_ff``)``both``=``tf``.``keras``.``layers``.``concatenate``([``deep``,``wide``])``output``=``tf``.``keras``.``layers``.``Dense``(``1``,``activation``=``''sigmoid''``)(``both``)``keras_model``=``tf``.``keras``.``models``.``Model``(``inputs``,``output``)`![](images/00055.jpg)`keras_model``.``compile``(``optimizer``=``tf``.``keras``.``optimizers``.``Adam``(``learning_rate``=``0.001``),``loss``=``''binary_crossentropy''``,``metrics``=``[``tf``.``keras``.``metrics``.``BinaryAccuracy``(),``tf``.``keras``.``metrics``.``TruePositives``()``])``return``keras_model`'
- en: '![](images/00002.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00002.jpg)'
- en: Loop over the features and create an input for each feature.
  id: totrans-23
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 循环遍历特征，并为每个特征创建一个输入。
- en: '![](images/00075.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00075.jpg)'
- en: Load the `tf.hub` module of the Universal Sentence Encoder model.
  id: totrans-25
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 加载`tf.hub`模块的通用句子编码器模型。
- en: '![](images/00064.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00064.jpg)'
- en: Keras inputs are two-dimensional, but the encoder expects one-dimensional inputs.
  id: totrans-27
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Keras输入是二维的，但编码器期望一维的输入。
- en: '![](images/00055.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00055.jpg)'
- en: Assemble the model graph with the functional API.
  id: totrans-29
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用功能API组装模型图。
- en: Now that we have defined our model, let’s move on to describe the process to
    integrate it into a TFX pipeline.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了我们的模型，让我们继续描述将其集成到TFX管道中的过程。
- en: The TFX Trainer Component
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: TFX训练组件
- en: The TFX `Trainer` component handles the training step in our pipeline. In this
    section, we will first describe how to train the Keras model from the example
    project in a one-off training run. At the end of the section, we will add some
    considerations for other training situations and for `Estimator` models.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: TFX `Trainer` 组件处理我们流水线中的训练步骤。在本节中，我们将首先描述如何从示例项目中进行一次性训练运行 Keras 模型。在本节末尾，我们将添加一些考虑其他训练情况和
    `Estimator` 模型的内容。
- en: All the steps we will describe may seem lengthy and unnecessary compared to
    the normal Keras training code. But the key point here is that the `Trainer` component
    will produce a model that will be put into production, where it will transform
    new data and use the model to make predictions. Because the `Transform` steps
    are included in this model, the data preprocessing steps will always match what
    the model is expecting. This removes a huge potential source of errors when our
    model is deployed.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将描述的所有步骤可能看起来比普通的 Keras 训练代码冗长和不必要。但关键在于 `Trainer` 组件将生成一个模型，该模型将投入生产中，用于转换新数据并使用模型进行预测。由于这个模型包含了
    `Transform` 步骤，数据预处理步骤将始终与模型期望的匹配。这消除了我们部署模型时可能产生的巨大错误源。
- en: 'In our example project, the `Trainer` component requires the following inputs:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例项目中，`Trainer` 组件需要以下输入：
- en: The previously generated data schema, generated by the data validation step
    discussed in [Chapter 4](index_split_009.html#filepos295199)
  id: totrans-35
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由数据验证步骤生成的先前生成的数据模式，在 [第 4 章](index_split_009.html#filepos295199) 中讨论
- en: The transformed data and its preprocessing graph, as discussed in [Chapter 5](index_split_010.html#filepos397186)
  id: totrans-36
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 转换后的数据及其预处理图，在 [第 5 章](index_split_010.html#filepos397186) 中讨论
- en: Training parameters (e.g., the number of training steps)
  id: totrans-37
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 训练参数（例如，训练步数）
- en: A module file containing a `run_fn()` function, which defines the training process
  id: totrans-38
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 包含 `run_fn()` 函数的模块文件，该函数定义了训练过程
- en: In the next section, we will discuss the setup of the `run_fn` function. We
    also will cover how to train a machine learning model in our pipeline and export
    it to the next pipeline step that we will discuss in [Chapter 7](index_split_012.html#filepos624151).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论 `run_fn` 函数的设置。我们还将介绍如何在我们的流水线中训练机器学习模型并将其导出到我们将在 [第 7 章](index_split_012.html#filepos624151)
    中讨论的下一个流水线步骤中。
- en: run_fn() Function
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`run_fn()` 函数'
- en: The `Trainer` component will look for a `run_fn()` function in our module file
    and use the function as an entry point to execute the training process. The module
    file needs to be accessible to the `Trainer` component. If you run the component
    in an interactive context, you can simply define the absolute path to the module
    file and pass it to the component. If you run your pipelines in production, please
    check [Chapter 11](index_split_018.html#filepos1264016) or [Chapter 12](index_split_019.html#filepos1378763)
    for details on how to provide the module file.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`Trainer` 组件将在我们的模块文件中查找 `run_fn()` 函数，并使用该函数作为执行训练过程的入口点。模块文件需要对 `Trainer`
    组件可访问。如果您在交互式环境中运行组件，只需定义模块文件的绝对路径并将其传递给组件即可。如果您在生产中运行流水线，请参阅 [第 11 章](index_split_018.html#filepos1264016)
    或 [第 12 章](index_split_019.html#filepos1378763) 获取有关如何提供模块文件的详细信息。'
- en: 'The `run_fn()` function is a generic entry point to the training steps and
    not `tf.Keras` specific. It carries out the following steps:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`run_fn()` 函数是训练步骤的通用入口点，而不是 `tf.Keras` 特定的。它执行以下步骤：'
- en: Loading the training and validation data (or the data generator)
  id: totrans-43
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 加载训练和验证数据（或数据生成器）
- en: Defining the model architecture and compiling the model
  id: totrans-44
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 定义模型架构并编译模型
- en: Training the model
  id: totrans-45
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 训练模型
- en: Exporting the model to be evaluated in the next pipeline step
  id: totrans-46
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 导出模型以便在下一个流水线步骤中进行评估
- en: The `run_fn` for our example project performs these four steps as shown in [Example 6-2](#filepos533510).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们示例项目的 `run_fn` 在 [示例 6-2](#filepos533510) 中执行这四个步骤。
- en: Example 6-2\. `run_fn()` function of our example pipeline
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 6-2\. 我们示例流水线的 `run_fn()` 函数
- en: '`def``run_fn``(``fn_args``):``tf_transform_output``=``tft``.``TFTransformOutput``(``fn_args``.``transform_output``)``train_dataset``=``input_fn``(``fn_args``.``train_files``,``tf_transform_output``)`![](images/00002.jpg)`eval_dataset``=``input_fn``(``fn_args``.``eval_files``,``tf_transform_output``)``model``=``get_model``()`![](images/00075.jpg)`model``.``fit``(``train_dataset``,``steps_per_epoch``=``fn_args``.``train_steps``,``validation_data``=``eval_dataset``,``validation_steps``=``fn_args``.``eval_steps``)`![](images/00064.jpg)`signatures``=``{``''serving_default''``:``_get_serve_tf_examples_fn``(``model``,``tf_transform_output``)``.``get_concrete_function``(``tf``.``TensorSpec``(``shape``=``[``None``],``dtype``=``tf``.``string``,``name``=``''examples''``)``)``}`![](images/00055.jpg)`model``.``save``(``fn_args``.``serving_model_dir``,``save_format``=``''tf''``,``signatures``=``signatures``)`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`def``run_fn``(``fn_args``):``tf_transform_output``=``tft``.``TFTransformOutput``(``fn_args``.``transform_output``)``train_dataset``=``input_fn``(``fn_args``.``train_files``,``tf_transform_output``)`![](images/00002.jpg)`eval_dataset``=``input_fn``(``fn_args``.``eval_files``,``tf_transform_output``)``model``=``get_model``()`![](images/00075.jpg)`model``.``fit``(``train_dataset``,``steps_per_epoch``=``fn_args``.``train_steps``,``validation_data``=``eval_dataset``,``validation_steps``=``fn_args``.``eval_steps``)`![](images/00064.jpg)`signatures``=``{``''serving_default''``:``_get_serve_tf_examples_fn``(``model``,``tf_transform_output``)``.``get_concrete_function``(``tf``.``TensorSpec``(``shape``=``[``None``],``dtype``=``tf``.``string``,``name``=``''examples''``)``)``}`![](images/00055.jpg)`model``.``save``(``fn_args``.``serving_model_dir``,``save_format``=``''tf''``,``signatures``=``signatures``)`'
- en: '![](images/00002.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00002.jpg)'
- en: Call the `input_fn` to get data generators.
  id: totrans-51
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 调用`input_fn`函数以获取数据生成器。
- en: '![](images/00075.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00075.jpg)'
- en: Call the `get_model` function to get the compiled Keras model.
  id: totrans-53
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 调用`get_model`函数以获取已编译的Keras模型。
- en: '![](images/00064.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00064.jpg)'
- en: Train the model using the number of training and evaluation steps passed by
    the `Trainer` component.
  id: totrans-55
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用由`Trainer`组件传递的训练步数和评估步数来训练模型。
- en: '![](images/00055.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00055.jpg)'
- en: Define the model signature, which includes the serving function we will describe
    later.
  id: totrans-57
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 定义模型签名，包括稍后将描述的服务函数。
- en: This function is fairly generic and could be reused with any other `tf.Keras`
    model. The project-specific details are defined in helper functions like `get_model()`
    or `input_fn()`.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数相当通用，可以与任何其他`tf.Keras`模型重用。项目特定的细节由诸如`get_model()`或`input_fn()`之类的辅助函数定义。
- en: In the following sections, we want to take a closer look into how we load the
    data, train, and export our machine learning model inside the `run_fn()` function.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入了解如何在`run_fn()`函数中加载数据、训练和导出我们的机器学习模型。
- en: Load the data
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'The following lines in the `run_fn` load our training and evaluation data:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`run_fn`中的以下行加载我们的训练和评估数据：'
- en: '`def``run_fn``(``fn_args``):``tf_transform_output``=``tft``.``TFTransformOutput``(``fn_args``.``transform_output``)``train_dataset``=``input_fn``(``fn_args``.``train_files``,``tf_transform_output``)``eval_dataset``=``input_fn``(``fn_args``.``eval_files``,``tf_transform_output``)`'
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`def``run_fn``(``fn_args``):``tf_transform_output``=``tft``.``TFTransformOutput``(``fn_args``.``transform_output``)``train_dataset``=``input_fn``(``fn_args``.``train_files``,``tf_transform_output``)``eval_dataset``=``input_fn``(``fn_args``.``eval_files``,``tf_transform_output``)`'
- en: In the first line, the `run_fn` function receives a set of arguments, including
    the transform graph, example datasets, and training parameters through the `fn_args`
    object.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一行中，`run_fn`函数通过`fn_args`对象接收一组参数，包括变换图、示例数据集和训练参数。
- en: Data loading for model training and validation is performed in batches, and
    the loading is handled by the `input_fn()` function as shown in [Example 6-3](#filepos548328).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加载用于模型训练和验证，以批处理方式处理，加载由`input_fn()`函数处理，如[示例 6-3](#filepos548328)所示。
- en: Example 6-3\. `Input_fn` function of our example pipeline
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 6-3\. 我们示例管道的`Input_fn`函数
- en: '`LABEL_KEY``=``''labels''``def``_gzip_reader_fn``(``filenames``):``return``tf``.``data``.``TFRecordDataset``(``filenames``,``compression_type``=``''GZIP''``)``def``input_fn``(``file_pattern``,``tf_transform_output``,``batch_size``=``32``):``transformed_feature_spec``=``(``tf_transform_output``.``transformed_feature_spec``()``.``copy``())``dataset``=``tf``.``data``.``experimental``.``make_batched_features_dataset``(``file_pattern``=``file_pattern``,``batch_size``=``batch_size``,``features``=``transformed_feature_spec``,``reader``=``_gzip_reader_fn``,``label_key``=``transformed_name``(``LABEL_KEY``))`![](images/00002.jpg)`return``dataset`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`LABEL_KEY``=``''labels''``def``_gzip_reader_fn``(``filenames``):``return``tf``.``data``.``TFRecordDataset``(``filenames``,``compression_type``=``''GZIP''``)``def``input_fn``(``file_pattern``,``tf_transform_output``,``batch_size``=``32``):``transformed_feature_spec``=``(``tf_transform_output``.``transformed_feature_spec``()``.``copy``())``dataset``=``tf``.``data``.``experimental``.``make_batched_features_dataset``(``file_pattern``=``file_pattern``,``batch_size``=``batch_size``,``features``=``transformed_feature_spec``,``reader``=``_gzip_reader_fn``,``label_key``=``transformed_name``(``LABEL_KEY``))`![](images/00002.jpg)`return``dataset`'
- en: '![](images/00002.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00002.jpg)'
- en: The dataset will be batched into the correct batch size.
  id: totrans-68
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 数据集将被分批为正确的批次大小。
- en: The `input_fn` function lets us load the compressed, preprocessed datasets that
    were generated by the previous Transform step.[2](#filepos621850) To do this,
    we need to pass the `tf_transform_output` to the function. This gives us the data
    schema to load the dataset from the TFRecord data structures generated by the
    Transform component. By using the preprocessed datasets, we can avoid data preprocessing
    during training and speed up the training process.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`input_fn`函数允许我们加载由上一个Transform步骤生成的压缩预处理数据集。[2](#filepos621850)为此，我们需要将`tf_transform_output`传递给函数。这为我们提供了从Transform组件生成的TFRecord数据结构加载数据集的数据模式。通过使用预处理数据集，我们可以避免在训练期间进行数据预处理，从而加快训练过程。'
- en: The `input_fn` returns a generator (a `batched_features_dataset`) that will
    supply data to the model one batch at a time.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`input_fn`返回一个生成器（一个`batched_features_dataset`），它将以一批一次的方式向模型提供数据。'
- en: Compile and train the model
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 编译并训练模型
- en: 'Now that we have defined our data-loading steps, the next step is defining
    our model architecture and compiling our model. In our `run_fn`, this will require
    a call to `get_model()`, which we have described, so it just needs a single line
    of code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经定义了数据加载步骤，下一步是定义我们的模型架构并编译我们的模型。在我们的`run_fn`中，这将需要调用`get_model()`，我们已经描述了这一点，所以只需要一行代码：
- en: '`model``=``get_model``()`'
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`model``=``get_model``()`'
- en: 'Next, we train our compiled `tf.Keras` model with the Keras method fit():'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用Keras的`fit()`方法训练我们已编译的`tf.Keras`模型：
- en: '`model``.``fit``(``train_dataset``,``steps_per_epoch``=``fn_args``.``train_steps``,``validation_data``=``eval_dataset``,``validation_steps``=``fn_args``.``eval_steps``)`'
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`model``.``fit``(``train_dataset``,``steps_per_epoch``=``fn_args``.``train_steps``,``validation_data``=``eval_dataset``,``validation_steps``=``fn_args``.``eval_steps``)`'
- en: TRAINING STEPS VERSUS EPOCHS
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 训练步骤与轮数的比较
- en: The TFX `Trainer` component defines the training process by the number of training
    steps rather than by epochs. A training step is when the model is trained on a
    single batch of data. The benefit of using steps rather than epochs is that we
    can train or validate models with large datasets and only use a fraction of the
    data. At the same time, if you want to loop over the training dataset multiple
    times during training, you can increase the step size to a multiple of the available
    samples.
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: TFX `Trainer`组件通过训练步数而不是轮数定义训练过程。训练步骤是指模型在单个数据批次上训练的次数。使用步数而不是轮数的好处在于，我们可以用大型数据集训练或验证模型，并且只使用数据的一小部分。同时，如果您希望在训练过程中多次遍历训练数据集，可以增加步长以达到可用样本的倍数。
- en: Once the model training is complete, the next step is to export the trained
    model. We will have a detailed discussion about exporting models for deployment
    in [Chapter 8](index_split_013.html#filepos764992). In the following section,
    we want to highlight how the preprocessing steps can be exported with the model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练完成后，下一步是导出训练好的模型。我们将在[第8章](index_split_013.html#filepos764992)详细讨论导出模型以用于部署。在接下来的部分中，我们希望强调如何将预处理步骤与模型一起导出。
- en: Model export
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 模型导出
- en: Finally, we export the model. We combine the preprocessing steps from the previous
    pipeline component with the trained model and save the model in TensorFlow’s SavedModel
    format. We define a model signature based on the graph generated by the [Example 6-4](#filepos565460)
    function. We will describe model signatures in much more detail in [“Model Signatures”](index_split_013.html#filepos800641)
    in [Chapter 8](index_split_013.html#filepos764992).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们导出模型。我们将前一个管道组件的预处理步骤与训练模型结合起来，并将模型保存为TensorFlow的SavedModel格式。我们根据由[Example 6-4](#filepos565460)函数生成的图定义模型签名。我们将在[“模型签名”](index_split_013.html#filepos800641)中更详细地描述模型签名在[第8章](index_split_013.html#filepos764992)中。
- en: 'In the `run_fn` function, we define the model signature and save the model
    with the following code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在`run_fn`函数中，我们定义了模型签名，并使用以下代码保存模型：
- en: '`signatures``=``{``''serving_default''``:``_get_serve_tf_examples_fn``(``model``,``tf_transform_output``)``.``get_concrete_function``(``tf``.``TensorSpec``(``shape``=``[``None``],``dtype``=``tf``.``string``,``name``=``''examples''``)``)``}``model``.``save``(``fn_args``.``serving_model_dir``,``save_format``=``''tf''``,``signatures``=``signatures``)`'
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`signatures``=``{``''serving_default''``:``_get_serve_tf_examples_fn``(``model``,``tf_transform_output``)``.``get_concrete_function``(``tf``.``TensorSpec``(``shape``=``[``None``],``dtype``=``tf``.``string``,``name``=``''examples''``)``)``}``model``.``save``(``fn_args``.``serving_model_dir``,``save_format``=``''tf''``,``signatures``=``signatures``)`'
- en: The `run_fn` exports the `get_serve_tf_examples_fn` as part of the model signature.
    When a model has been exported and deployed, every prediction request will pass
    through the `serve_tf_examples_fn()` shown in [Example 6-4](#filepos565460). With
    every request, we parse the serialized `tf.Example` records and apply the preprocessing
    steps to the raw request data. The model then makes a prediction on the preprocessed
    data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`run_fn`将`get_serve_tf_examples_fn`导出为模型签名的一部分。当模型被导出并部署时，每个预测请求都会通过[Example 6-4](#filepos565460)中显示的`serve_tf_examples_fn()`。每个请求，我们解析序列化的`tf.Example`记录，并将预处理步骤应用于原始请求数据。然后，模型对预处理数据进行预测。'
- en: Example 6-4\. Applying the preprocessing graph to model inputs
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Example 6-4\. 将预处理图应用于模型输入
- en: '`def``get_serve_tf_examples_fn``(``model``,``tf_transform_output``):``model``.``tft_layer``=``tf_transform_output``.``transform_features_layer``()`![](images/00002.jpg)`@tf.function``def``serve_tf_examples_fn``(``serialized_tf_examples``):``feature_spec``=``tf_transform_output``.``raw_feature_spec``()``feature_spec``.``pop``(``LABEL_KEY``)``parsed_features``=``tf``.``io``.``parse_example``(``serialized_tf_examples``,``feature_spec``)`![](images/00075.jpg)`transformed_features``=``model``.``tft_layer``(``parsed_features``)`![](images/00064.jpg)`outputs``=``model``(``transformed_features``)`![](images/00055.jpg)`return``{``''outputs''``:``outputs``}``return``serve_tf_examples_fn`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`def``get_serve_tf_examples_fn``(``model``,``tf_transform_output``):``model``.``tft_layer``=``tf_transform_output``.``transform_features_layer``()`![](images/00002.jpg)`@tf.function``def``serve_tf_examples_fn``(``serialized_tf_examples``):``feature_spec``=``tf_transform_output``.``raw_feature_spec``()``feature_spec``.``pop``(``LABEL_KEY``)``parsed_features``=``tf``.``io``.``parse_example``(``serialized_tf_examples``,``feature_spec``)`![](images/00075.jpg)`transformed_features``=``model``.``tft_layer``(``parsed_features``)`![](images/00064.jpg)`outputs``=``model``(``transformed_features``)`![](images/00055.jpg)`return``{``''outputs''``:``outputs``}``return``serve_tf_examples_fn`'
- en: '![](images/00002.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00002.jpg)'
- en: Load the preprocessing graph.
  id: totrans-87
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 加载预处理图。
- en: '![](images/00075.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00075.jpg)'
- en: Parse the raw `tf.Example` records from the request.
  id: totrans-89
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 解析来自请求的原始`tf.Example`记录。
- en: '![](images/00064.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00064.jpg)'
- en: Apply the preprocessing transformation to raw data.
  id: totrans-91
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将预处理转换应用于原始数据。
- en: '![](images/00055.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00055.jpg)'
- en: Perform prediction with preprocessed data.
  id: totrans-93
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用预处理数据进行预测。
- en: With the definition of our `run_fn()` function in place, let’s discuss how we
    can run the `Trainer` component.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 完成
- en: Running the Trainer Component
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 运行训练组件
- en: 'As shown in [Example 6-5](#filepos574604), the `Trainer` component takes the
    following as input:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如[Example 6-5](#filepos574604)所示，`Trainer`组件将以下内容作为输入：
- en: The Python module file, here saved as module.py, containing the `run_fn()`,
    `input_fn()`, `get_serve_tf_examples_fn()`, and other associated functions we
    discussed earlier
  id: totrans-97
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Python模块文件，保存为module.py，包含我们之前讨论过的`run_fn()`、`input_fn()`、`get_serve_tf_examples_fn()`等相关函数
- en: The transformed examples generated by the Transform component
  id: totrans-98
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 转换组件生成的转换示例
- en: The transform graph generated by the Transform component
  id: totrans-99
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 转换组件生成的转换图
- en: The schema generated by the data validation component
  id: totrans-100
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 数据验证组件生成的模式
- en: The number of training and evaluation steps
  id: totrans-101
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 训练和评估步骤的数量
- en: Example 6-5\. `Trainer` component
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Example 6-5\. `Trainer`组件
- en: '`from``tfx.components``import``Trainer``from``tfx.components.base``import``executor_spec``from``tfx.components.trainer.executor``import``GenericExecutor`![](images/00002.jpg)`from``tfx.proto``import``trainer_pb2``TRAINING_STEPS``=``1000``EVALUATION_STEPS``=``100``trainer``=``Trainer``(``module_file``=``os``.``path``.``abspath``(``"module.py"``),``custom_executor_spec``=``executor_spec``.``ExecutorClassSpec``(``GenericExecutor``),`![](images/00075.jpg)`transformed_examples``=``transform``.``outputs``[``''transformed_examples''``],``transform_graph``=``transform``.``outputs``[``''transform_graph''``],``schema``=``schema_gen``.``outputs``[``''schema''``],``train_args``=``trainer_pb2``.``TrainArgs``(``num_steps``=``TRAINING_STEPS``),``eval_args``=``trainer_pb2``.``EvalArgs``(``num_steps``=``EVALUATION_STEPS``))`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`from``tfx.components``import``Trainer``from``tfx.components.base``import``executor_spec``from``tfx.components.trainer.executor``import``GenericExecutor`![](images/00002.jpg)`from``tfx.proto``import``trainer_pb2``TRAINING_STEPS``=``1000``EVALUATION_STEPS``=``100``trainer``=``Trainer``(``module_file``=``os``.``path``.``abspath``(``"module.py"``),``custom_executor_spec``=``executor_spec``.``ExecutorClassSpec``(``GenericExecutor``),`![](images/00075.jpg)`transformed_examples``=``transform``.``outputs``[``''transformed_examples''``],``transform_graph``=``transform``.``outputs``[``''transform_graph''``],``schema``=``schema_gen``.``outputs``[``''schema''``],``train_args``=``trainer_pb2``.``TrainArgs``(``num_steps``=``TRAINING_STEPS``),``eval_args``=``trainer_pb2``.``EvalArgs``(``num_steps``=``EVALUATION_STEPS``))`'
- en: '![](images/00002.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00002.jpg)'
- en: Load the `GenericExecutor` to override the training executor.
  id: totrans-105
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 加载 `GenericExecutor` 来覆盖训练执行器。
- en: '![](images/00075.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00075.jpg)'
- en: Override the executor to load the `run_fn()` function.
  id: totrans-107
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 覆盖执行器以加载 `run_fn()` 函数。
- en: 'In a notebook environment (an interactive context), we can run the `Trainer`
    component, like any previous component, with the following command:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本环境（交互式环境）中，我们可以像以前的组件一样运行 `Trainer` 组件，使用以下命令：
- en: '`context``.``run``(``trainer``)`'
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`context``.``run``(``trainer``)`'
- en: After the model training and exporting is completed, the component will register
    the path of the exported model with the metadata store. Downstream components
    can pick up the model for the model validation.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成模型训练和导出后，该组件将注册导出模型的路径到元数据存储中。下游组件可以提取模型进行模型验证。
- en: The `Trainer` component is generic and not limited to running TensorFlow models.
    However, the components later in the pipeline expect that the model is saved in
    the TensorFlow [SavedModel format](https://oreil.ly/fe6rp). The SavedModel graph
    includes the Transform graph, so the data preprocessing steps are part of the
    model.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`Trainer` 组件是通用的，并不限于运行 TensorFlow 模型。然而，管道中稍后的组件期望模型以 TensorFlow [SavedModel
    格式](https://oreil.ly/fe6rp)保存。SavedModel 图包括 Transform 图，因此数据预处理步骤是模型的一部分。'
- en: OVERRIDING THE TRAINER COMPONENT’S EXECUTOR
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 覆盖 `Trainer` 组件的执行器
- en: In our example project, we override the `Trainer` component’s executor to enable
    the generic training entry point `run_fn()` function instead of the default `trainer_fn()`
    function, which only supports `tf.Estimator` models. In [Chapter 12](index_split_019.html#filepos1378763),
    we will introduce another Trainer executor, the `ai_platform_trainer_executor.GenericExecutor`.
    This executor allows you to train models on Google Cloud’s AI Platform instead
    of inside your pipeline. This is an alternative if your model requires specific
    training hardware (e.g., GPUs or tensor processing units [TPUs]), which aren’t
    available in your pipeline environment.
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在我们的示例项目中，我们覆盖了 `Trainer` 组件的执行器，以启用通用的训练入口函数 `run_fn()`，而不是仅支持 `tf.Estimator`
    模型的默认 `trainer_fn()` 函数。在 [第 12 章](index_split_019.html#filepos1378763)，我们将介绍另一个
    `Trainer` 执行器，即 `ai_platform_trainer_executor.GenericExecutor`。此执行器允许您在谷歌云的 AI
    平台上训练模型，而不是在管道环境内部。如果您的模型需要特定的训练硬件（例如 GPU 或张量处理单元 [TPU]），这是一种替代方法。
- en: Other Trainer Component Considerations
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 其他 `Trainer` 组件注意事项
- en: In our examples so far in this chapter, we have only considered a single training
    run of a Keras model. But we can also use the `Trainer` component to fine-tune
    a model from a previous run or to train multiple models simultaneously, and we
    will describe these in [“Advanced Pipeline Concepts”](index_split_017.html#filepos1074974).
    We can also use it to optimize a model through hyperparameter search, and we will
    discuss this more in [“Model Tuning”](#filepos614919).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章的示例中，我们只考虑了对 Keras 模型的单次训练运行。但我们也可以使用 `Trainer` 组件对先前运行的模型进行微调，或者同时训练多个模型，并且我们将在
    [“高级管道概念”](index_split_017.html#filepos1074974) 中描述这些内容。我们还可以使用它通过超参数搜索来优化模型，我们将在
    [“模型调优”](#filepos614919) 中更详细地讨论这一点。
- en: In this section, we will also discuss how to use the `Trainer` component with
    an `Estimator` model and how to load your SavedModel exported by the `Trainer`
    component outside a TFX pipeline.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们还将讨论如何与`Estimator`模型一起使用`Trainer`组件，以及如何在TFX管道之外加载由`Trainer`组件导出的SavedModel。
- en: Using the Trainer component with an Estimator model
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Trainer组件与Estimator模型
- en: Until recently, TFX supported only `tf.Estimator` models and the `Trainer` component
    was solely designed for `Estimators`. The default implementation of the `Trainer`
    component used the `trainer_fn()` function as an entry point to the training process,
    but this entry point is very `tf.Estimator` specific. The `Trainer` component
    expects the Estimator inputs to be defined by functions like `train_input_fn()`,
    `eval_input_fn()`, and `serving_receiver_fn`().[3](#filepos622393)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 直到最近，TFX仅支持`tf.Estimator`模型，而`Trainer`组件仅设计用于`Estimator`。`Trainer`组件的默认实现使用`trainer_fn()`函数作为训练过程的入口点，但该入口点非常依赖于`tf.Estimator`。`Trainer`组件期望Estimator输入由函数如`train_input_fn()`、`eval_input_fn()`和`serving_receiver_fn`()定义。[3](#filepos622393)
- en: As we discussed in [“Running the Trainer Component”](#filepos572856), the core
    functionality of the component can be swapped out with the generic training executor
    `GenericExecutor`, which uses the `run_fn()` function as its entry point to the
    training process.[4](#filepos622913) As the name of the executor implies, the
    training process becomes generic and not tied to `tf.Estimator` or `tf.Keras`
    models.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[“运行训练器组件”](#filepos572856)中讨论的，该组件的核心功能可以通过通用训练执行器`GenericExecutor`进行替换，该执行器使用`run_fn()`函数作为训练过程的入口点。[4](#filepos622913)正如执行器的名称所示，训练过程变得通用化，不再局限于`tf.Estimator`或`tf.Keras`模型。
- en: Using the SavedModel outside a pipeline
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在管道之外使用SavedModel
- en: 'If we would like to inspect the exported SavedModel outside a TFX pipeline,
    we can load the model as a concrete function,[5](#filepos623447) which represents
    the graph of a single signature:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要在TFX管道之外检查导出的SavedModel，我们可以将该模型加载为具体函数，[5](#filepos623447)代表单个签名的图形：
- en: '`model_path``=``trainer``.``outputs``.``model``.``get``()[``0``]``.``uri``model``=``tf``.``saved_model``.``load``(``export_dir``=``model_path``)``predict_fn``=``model``.``signatures``[``"serving_default"``]`'
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`model_path``=``trainer``.``outputs``.``model``.``get``()[``0``]``.``uri``model``=``tf``.``saved_model``.``load``(``export_dir``=``model_path``)``predict_fn``=``model``.``signatures``[``"serving_default"``]`'
- en: 'With the model loaded as a concrete function, we can now perform predictions.
    The exported model expects the input data to be provided in the `tf.Example` data
    structure as shown in the following example. More details around the `tf.Example`
    data structure, and how other features (like integers and floats) can be converted
    can be found in [Example 3-1](index_split_008.html#filepos191596). The following
    code shows how to create the serialized data structure and perform a model prediction
    by calling the `prediction_fn()` function:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型加载为具体函数后，我们现在可以进行预测。导出的模型期望以`tf.Example`数据结构提供输入数据，如下面的示例所示。有关`tf.Example`数据结构的更多细节，以及如何转换其他特征（如整数和浮点数），请参见[Example 3-1](index_split_008.html#filepos191596)。以下代码显示如何创建序列化数据结构，并通过调用`prediction_fn()`函数执行模型预测：
- en: '`example``=``tf``.``train``.``Example``(``features``=``tf``.``train``.``Features``(``feature``=``{``''feature_A''``:``_bytes_feature``(``feature_A_value``),``...``}))`![](images/00002.jpg)`serialized_example``=``example``.``SerializeToString``()``print``(``predict_fn``(``tf``.``constant``([``serialized_example``])))`'
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`example``=``tf``.``train``.``Example``(``features``=``tf``.``train``.``Features``(``feature``=``{``''feature_A''``:``_bytes_feature``(``feature_A_value``),``...``}))`![](images/00002.jpg)`serialized_example``=``example``.``SerializeToString``()``print``(``predict_fn``(``tf``.``constant``([``serialized_example``])))`'
- en: '![](images/00002.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00002.jpg)'
- en: The `_bytes_feature` helper function is defined in [Example 3-1](index_split_008.html#filepos191596).
  id: totrans-126
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`_bytes_feature`辅助函数在[Example 3-1](index_split_008.html#filepos191596)中定义。'
- en: If you would like to inspect the progress of the model in detail during training,
    you can do this using TensorBoard. We will describe how to use TensorBoard in
    our pipeline in the next section.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望在训练过程中详细检查模型的进展，可以使用TensorBoard。我们将在下一节中描述如何在我们的管道中使用TensorBoard。
- en: Using TensorBoard in an Interactive Pipeline
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在交互式管道中使用TensorBoard
- en: TensorBoard is another wonderful tool that is part of the TensorFlow ecosystem.
    It has many helpful functions that we can use in our pipelines, for example, monitoring
    metrics while training, visualizing word embeddings in NLP problems, or viewing
    activations for layers in the model. A new [Profiler feature](https://oreil.ly/Tiw9Y)
    lets us profile the model to understand performance bottlenecks.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 是 TensorFlow 生态系统中的另一个精彩工具。它具有许多有用的功能，我们可以在我们的流水线中使用，例如在训练过程中监控指标、可视化自然语言处理问题中的词嵌入，或查看模型中层的激活情况。一个新的[Profiler
    feature](https://oreil.ly/Tiw9Y)让我们能够分析模型以理解性能瓶颈。
- en: An example of TensorBoard’s basic visualization is shown in [Figure 6-3](#filepos595843).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 的基本可视化示例如图[Figure 6-3](#filepos595843)所示。
- en: '![](images/00102.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00102.jpg)'
- en: Figure 6-3\. Viewing metrics while training in TensorBoard
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6-3\. 在 TensorBoard 中查看训练过程中的指标
- en: 'To be able to use TensorBoard in our pipeline, we need to add callbacks in
    the `run_fn` function and log the training to a folder we specify:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要在我们的流水线中使用 TensorBoard，我们需要在 `run_fn` 函数中添加回调并将训练日志记录到指定的文件夹中：
- en: '`log_dir``=``os``.``path``.``join``(``os``.``path``.``dirname``(``fn_args``.``serving_model_dir``),``''logs''``)``tensorboard_callback``=``tf``.``keras``.``callbacks``.``TensorBoard``(``log_dir``=``log_dir``,``update_freq``=``''batch''``)`'
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`log_dir``=``os``.``path``.``join``(``os``.``path``.``dirname``(``fn_args``.``serving_model_dir``),``''logs''``)``tensorboard_callback``=``tf``.``keras``.``callbacks``.``TensorBoard``(``log_dir``=``log_dir``,``update_freq``=``''batch''``)`'
- en: 'We also need to add the callback to our model training:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要将回调添加到我们的模型训练中：
- en: '`model``.``fit``(``train_dataset``,``steps_per_epoch``=``fn_args``.``train_steps``,``validation_data``=``eval_dataset``,``validation_steps``=``fn_args``.``eval_steps``,``callbacks``=``[``tensorboard_callback``])`'
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`model``.``fit``(``train_dataset``,``steps_per_epoch``=``fn_args``.``train_steps``,``validation_data``=``eval_dataset``,``validation_steps``=``fn_args``.``eval_steps``,``callbacks``=``[``tensorboard_callback``])`'
- en: 'Then, to view TensorBoard in a notebook, we get the location of the model training
    logs and pass it to TensorBoard:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，要在笔记本中查看 TensorBoard，我们获取模型训练日志的位置，并将其传递给 TensorBoard：
- en: '`model_dir``=``trainer``.``outputs``[``''output''``]``.``get``()[``0``]``.``uri``%``load_ext``tensorboard``%``tensorboard``--``logdir``{``model_dir``}`'
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`model_dir``=``trainer``.``outputs``[``''output''``]``.``get``()[``0``]``.``uri``%``load_ext``tensorboard``%``tensorboard``--``logdir``{``model_dir``}`'
- en: 'We can also use TensorBoard outside a notebook by running:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在笔记本之外运行 TensorBoard：
- en: '`tensorboard --logdir path/to/logs`'
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`tensorboard --logdir path/to/logs`'
- en: Then connect to [http://localhost:6006/](http://localhost:6006/) to view TensorBoard.
    This gives us a larger window to view the details.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 然后连接到 [http://localhost:6006/](http://localhost:6006/) 查看 TensorBoard。这将为我们提供一个更大的视窗来查看细节。
- en: Next, we will introduce some useful strategies for training large models on
    multiple GPUs.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍一些在多个 GPU 上训练大型模型时有用的策略。
- en: Distribution Strategies
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 分布策略
- en: TensorFlow provides distribution strategies for machine learning models that
    can’t be adequately trained on a single GPU. You might want to consider distribution
    strategies when you want to accelerate your training or you can’t fit the entire
    model into a single GPU.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 提供了分布策略，用于无法在单个 GPU 上充分训练的机器学习模型。当您希望加速训练或无法将整个模型放入单个 GPU 时，您可能需要考虑分布策略。
- en: 'The strategies we describe here are abstractions to distribute the model parameters
    across multiple GPUs or even multiple servers. In general, there are two groups
    of strategies: synchronous and asynchronous training. Under the synchronous strategies,
    all training workers train with different slices of the training data synchronously
    and then aggregate the gradients from all workers before updating the model. The
    asynchronous strategies train models independently with the entire dataset on
    different workers. Each worker updates the gradients of the model asynchronously,
    without waiting for the other workers to finish. Typically, synchronous strategies
    are coordinated via all-reduce operations[6](#filepos623804) and asynchronous
    strategies through a parameter server architecture.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这里描述的策略是将模型参数抽象化以分布到多个 GPU 或多个服务器上。一般来说，有两组策略：同步训练和异步训练。在同步策略下，所有训练工作节点都同步使用不同切片的训练数据进行训练，然后在更新模型之前聚合所有工作节点的梯度。异步策略则是独立训练模型，并行处理整个数据集。每个工作节点异步更新模型的梯度，无需等待其他工作节点完成。通常，同步策略通过全局归约操作[6](#filepos623804)协调，而异步策略通过参数服务器架构实现。
- en: 'A few synchronous and asynchronous strategies exist, and they have their benefits
    and drawbacks. At the time of writing this section, Keras supports the following
    strategies:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一些同步和异步策略，它们各自有其优缺点。在撰写本节时，Keras支持以下策略：
- en: MirroredStrategy
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: MirroredStrategy
- en: This strategy is relevant for multiple GPUs on a single instance, and it follows
    the synchronous training pattern. The strategy mirrors the model and the parameters
    across the workers, but each worker receives a different batch of data. The MirroredStrategy
    is a good default strategy if you train a machine learning model on a single node
    with multiple GPUs and your machine learning model fits in the GPU memory.
  id: totrans-148
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 该策略适用于单个实例上的多个GPU，并遵循同步训练模式。该策略会在各个工作器之间镜像模型和参数，但每个工作器会接收不同的数据批次。如果你在单节点多GPU环境下训练机器学习模型，并且你的模型适合GPU内存，MirroredStrategy是一个很好的默认策略。
- en: CentralStorageStrategy
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: CentralStorageStrategy
- en: In contrast to the MirroredStrategy, the variables in this strategy aren’t mirrored
    across all GPUs. Instead, they are stored in the CPU’s memory and then copied
    into the assigned GPU to execute the relevant operations. In case of a single
    GPU operation, the CentralStorageStrategy will store the variables on the GPU,
    not in the CPU. CentralStorageStrategy is a good strategy for distributing your
    training when you train on a single node with multiple GPUs and your complete
    model doesn’t fit in the memory of single GPU, or when the communication bandwidth
    between the GPUs is too limited.
  id: totrans-150
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 与MirroredStrategy相比，这种策略不会将变量镜像到所有GPU上。相反，它们存储在CPU内存中，然后复制到分配的GPU上执行相关操作。在单GPU操作的情况下，CentralStorageStrategy会将变量存储在GPU上，而不是CPU上。当你在单节点多GPU环境下进行训练，且整个模型不适合单个GPU内存，或者GPU之间的通信带宽过于有限时，CentralStorageStrategy是一个很好的策略。
- en: MultiWorkerMirroredStrategy
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: MultiWorkerMirroredStrategy
- en: This follows the design patterns of the MirroredStrategy, but it copies the
    variables across multiple workers (e.g., compute instances). The MultiWorkerMirroredStrategy
    is an option if one node isn’t enough for your model training.
  id: totrans-152
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这种策略遵循MirroredStrategy的设计模式，但是它将变量复制到多个工作器（例如计算实例）之间。如果单个节点不足以支持你的模型训练，MultiWorkerMirroredStrategy是一个选择。
- en: TPUStrategy
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: TPUStrategy
- en: This strategy lets you use Google Cloud’s TPUs. It follows the synchronous training
    pattern and basically works like MirroredStrategy except it uses TPUs instead
    of GPUs. It requires its own strategy since the MirroredStrategy uses GPU-specific
    all-reduce functions. TPUs have a huge amount of RAM available, and the cross-TPU
    communication is highly optimized, which is why the TPU strategy uses the mirrored
    approach.
  id: totrans-154
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 此策略允许您使用Google Cloud的TPU。它遵循同步训练模式，基本上与MirroredStrategy类似，但使用TPU而不是GPU。由于MirroredStrategy使用GPU特定的全局减函数，因此TPU策略需要自己的策略。TPU具有大量可用的RAM，并且跨TPU通信高度优化，这就是为什么TPU策略使用了镜像方法。
- en: ParameterServerStrategy
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ParameterServerStrategy
- en: The ParameterServerStrategy uses multiple nodes as the central variable repository.
    This strategy is useful for models exceeding the available resources (e.g., RAM
    or I/O bandwidth) of a single node. The ParameterServerStrategy is your only option
    if you can’t train on a single node and the model is exceeding the RAM or I/O
    limitations of a node.
  id: totrans-156
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ParameterServerStrategy使用多个节点作为中央变量存储库。对于超出单节点可用资源（例如RAM或I/O带宽）的模型，此策略非常有用。如果无法在单节点上进行训练且模型超出了节点的RAM或I/O限制，则ParameterServerStrategy是唯一的选择。
- en: OneDeviceStrategy
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: OneDeviceStrategy
- en: The whole point of the OneDeviceStrategy is to test the entire model setup before
    engaging in real distributed training. This strategy forces the model training
    to only use one device (e.g., one GPU). Once it is confirmed that the training
    setup is working, the strategy can be swapped.
  id: totrans-158
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OneDeviceStrategy的整体目的是在进行真正的分布式训练之前测试整个模型设置。该策略强制模型训练仅使用一个设备（例如一个GPU）。一旦确认训练设置有效，可以切换策略。
- en: NOT ALL STRATEGIES ARE AVAILABLE VIA THE TFX TRAINER COMPONENT
  id: totrans-159
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 并非所有策略都可以通过TFX Trainer组件使用
- en: At the time of writing this section, the TFX `Trainer` component only supports
    the MirroredStrategy. While the different strategies can currently be used with
    `tf.keras`, they will be made accessible via the `Trainer` component in the second
    half of 2020, according to the [TFX roadmap](https://oreil.ly/I-OPN).
  id: totrans-160
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在撰写本节时，TFX的`Trainer`组件仅支持MirroredStrategy。虽然不同的策略目前可以在`tf.keras`中使用，但根据[TFX路线图](https://oreil.ly/I-OPN)，它们将在2020年下半年通过`Trainer`组件变得可访问。
- en: 'Because the MirroredStrategy is supported by the TFX Trainer, we’ll show an
    example of it here. We can apply the MirroredStrategy easily by adding a few lines
    before invoking our model creation and the subsequent `model.compile()` call:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 因为**MirroredStrategy**由TFX Trainer支持，我们将在此展示一个示例。在调用我们的模型创建及后续的`model.compile()`之前，我们可以轻松地应用**MirroredStrategy**，只需添加几行代码：
- en: '`mirrored_strategy``=``tf``.``distribute``.``MirroredStrategy``()`![](images/00002.jpg)`with``mirrored_strategy``.``scope``():`![](images/00075.jpg)`model``=``get_model``()`'
  id: totrans-162
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`mirrored_strategy``=``tf``.``distribute``.``MirroredStrategy``()`![](images/00002.jpg)`with``mirrored_strategy``.``scope``():`![](images/00075.jpg)`model``=``get_model``()`'
- en: '![](images/00002.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00002.jpg)'
- en: Instance of distribution strategy.
  id: totrans-164
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 分布策略的实例。
- en: '![](images/00075.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00075.jpg)'
- en: Wrap model creation and compilation with Python manager.
  id: totrans-166
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用Python管理器包装模型创建和编译。
- en: 'In this example setup, we create an instance of the MirroredStrategy. In order
    to apply the distribution strategy to our model, we wrap the model creation and
    compilation with the Python manager (in our case, it all happens inside of the
    `get_model()` function). This will create and compile our model under the distribution
    scope of our choice. The MirroredStrategy will use all available GPUs of the instance.
    If you want to reduce the number of GPU instances being used (e.g., in case you
    share instances), you can specify the GPUs to be used with the MirroredStrategy
    by changing the creation of the distribution strategy:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例设置中，我们创建了一个**MirroredStrategy**的实例。为了将分布策略应用到我们的模型中，我们将模型创建和编译包装在Python管理器中（在我们的情况下，这一切发生在`get_model()`函数内部）。这将在我们选择的分布范围下创建和编译我们的模型。**MirroredStrategy**将使用实例中所有可用的GPU。如果您希望减少使用的GPU实例数（例如在共享实例的情况下），可以通过更改分布策略的创建来指定要使用的GPU：
- en: '`mirrored_strategy``=``tf``.``distribute``.``MirroredStrategy``(``devices``=``[``"/gpu:0"``,``"/gpu:1"``])`'
  id: totrans-168
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`mirrored_strategy``=``tf``.``distribute``.``MirroredStrategy``(``devices``=``[``"/gpu:0"``,``"/gpu:1"``])`'
- en: In this example, we specify two GPUs to be used for our training runs.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们指定了两个GPU用于训练运行。
- en: BATCH SIZE REQUIREMENT WHEN USING THE MIRROREDSTRATEGY
  id: totrans-170
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用MirroredStrategy时的批量大小要求
- en: The MirroredStrategy expects that the batch size is proportional to the number
    of devices. For example, if you train with five GPUs, the batch size needs to
    be a multiple of the number of GPUs. Please keep this in mind when you set up
    your `input_fn()` function as described in [Example 6-3](#filepos548328).
  id: totrans-171
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**MirroredStrategy**期望批量大小与设备数量成比例。例如，如果您使用五个GPU进行训练，则批量大小需要是GPU数量的倍数。在设置您的`input_fn()`函数时，请牢记这一点，如[示例
    6-3](#filepos548328)所述。'
- en: These distribution strategies are useful for large training jobs that won’t
    fit on the memory of a single GPU. Model tuning, which we will discuss in the
    next section, is a common reason for us to need these strategies.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这些分布策略对于那些单个GPU内存无法容纳的大型训练作业非常有用。模型调优是我们需要这些策略的常见原因，在下一节中将对此进行讨论。
- en: Model Tuning
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 模型调优
- en: Hyperparameter tuning is an important part of achieving an accurate machine
    learning model. Depending on the use case, it may be something that we do during
    our initial experiments or it may be something we want to include in our pipeline.
    This is not a comprehensive introduction to model tuning, but we will give a brief
    overview of it here and describe how it may be included in a pipeline.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调优是实现准确机器学习模型的重要部分。根据用例，它可能是我们在初始实验中执行的事项，也可能是我们想要包含在管道中的内容。这不是模型调优的全面介绍，但我们将在此简要概述并描述其如何包含在管道中。
- en: Strategies for Hyperparameter Tuning
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调优策略
- en: Depending on the type of model in your pipeline, the choice of hyperparameters
    will be different. If your model is a deep neural network, hyperparameter tuning
    is especially critical to achieving good performance with neural networks. Two
    of the most important sets of hyperparameters to tune are those controlling the
    optimization and the network architecture.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 根据管道中模型的类型，选择的超参数会有所不同。如果您的模型是深度神经网络，则超参数调优对于实现良好性能尤为重要。控制优化和网络架构的两组最重要的超参数之一。
- en: For optimization, we recommend using [Adam](https://oreil.ly/dsdHb) or [NAdam](https://oreil.ly/TjatF)
    by default. The learning rate is a very important parameter to experiment with,
    and there are [many possible options](https://oreil.ly/MopUS) for learning rate
    schedulers. We recommend using the largest batch size that fits in your GPU memory.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 对于优化，我们建议默认使用[Adam](https://oreil.ly/dsdHb)或[NAdam](https://oreil.ly/TjatF)。学习率是一个非常重要的参数，可以进行实验，有[许多可能的选择](https://oreil.ly/MopUS)用于学习率调度器。我们建议使用适合GPU内存的最大批量大小。
- en: 'For very large models, we suggest the following steps:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非常大的模型，我们建议以下步骤：
- en: Tune the initial learning rate, starting with 0.1.
  id: totrans-179
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 调节初始学习率，从0.1开始。
- en: Pick a number of steps to train for (as many as patience allows).
  id: totrans-180
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 选择一个训练步数（尽可能多，只要耐心允许）。
- en: Linearly decay the learning rate to 0 over the specified number of steps.
  id: totrans-181
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在指定的步数内线性衰减学习率至0。
- en: For smaller models, we recommend using [early stopping](https://oreil.ly/ACUIn)
    to avoid overfitting. With this technique, model training is stopped when the
    validation loss does not improve after a user-defined number of epochs.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较小的模型，我们建议使用[提前停止](https://oreil.ly/ACUIn)以避免过拟合。使用此技术时，模型训练会在经过用户定义的一定数量的epochs后，验证损失不再改善时停止。
- en: For the network architecture, two of the most important parameters to tune are
    the size and number of layers. Increasing these will improve training performance,
    but it may cause overfitting and will mean the model takes longer to train. You
    can also consider adding residual connections between the layers, particularly
    for deep architectures.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于网络架构，调节的两个最重要的参数是大小和层数。增加这些参数将改善训练性能，但可能导致过拟合，并意味着模型训练时间更长。您还可以考虑在层之间添加残差连接，特别是对于深层架构。
- en: The most popular hyperparameter search approaches are grid search and random
    search. In grid search, every combination of parameters is tried exhaustively,
    whereas in random search, parameters are sampled from the available options and
    may not try every combination. Grid search can get extremely time consuming if
    the number of possible hyperparameters is large. After trying a range of values,
    you can fine-tune by taking the best-performing hyperparameters and starting a
    new search centered on them.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 最流行的超参数搜索方法是网格搜索和随机搜索。在网格搜索中，会穷举尝试每个参数的所有组合；而在随机搜索中，参数从可用选项中抽样，可能不会尝试每个组合。如果可能的超参数数量很大，网格搜索可能会非常耗时。尝试了一系列值之后，可以通过选择表现最佳的超参数，并围绕它们开始新的搜索来进行微调。
- en: In the TensorFlow ecosystem, hyperparameter tuning is implemented using the
    [Keras Tuner](https://oreil.ly/N3DqZ) and also [Katib](https://oreil.ly/rVwCk),
    which provides hyperparameter tuning in Kubeflow. In addition to grid and random
    search, both of these packages support Bayesian search and the [Hyperband algorithm](https://oreil.ly/KzqJY).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow生态系统中，使用[Keras Tuner](https://oreil.ly/N3DqZ)和[Katib](https://oreil.ly/rVwCk)来实现超参数调优，Katib在Kubeflow中提供超参数调优。除了网格搜索和随机搜索外，这两个包还支持贝叶斯搜索和[Hyperband算法](https://oreil.ly/KzqJY)。
- en: Hyperparameter Tuning in TFX Pipelines
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: TFX管道中的超参数调优
- en: In a TFX pipeline, hyperparameter tuning takes in the data from the Transform
    component and trains a variety of models to establish the best hyperparameters.
    The hyperparameters are then passed to the `Trainer` component, which then trains
    a final model using them.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在TFX管道中，超参数调优使用Transform组件中的数据进行，训练多种模型以确定最佳超参数。然后将这些超参数传递给`Trainer`组件，使用它们训练最终模型。
- en: In this case, the model definition function (the `get_model` function in our
    example) needs to accept the hyperparameters as an input and build the model according
    to the specified hyperparameters. So, for example, the number of layers needs
    to be defined as an input argument.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，模型定义函数（例如我们示例中的`get_model`函数）需要接受超参数作为输入，并根据指定的超参数构建模型。例如，层数需要作为输入参数定义。
- en: THE TFX TUNER COMPONENT
  id: totrans-189
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: TFX调节器组件
- en: The TFX Tuner component was released as we were finalizing this book. You can
    view the source code in the project’s [GitHub repo](https://oreil.ly/uK7Z9).
  id: totrans-190
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在我们完成本书的过程中发布了TFX调节器组件。您可以在项目的[GitHub仓库](https://oreil.ly/uK7Z9)中查看源代码。
- en: Summary
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 概要
- en: In this chapter, we described how to move our model training from a standalone
    script to an integrated part of our pipeline. This means that the process can
    be automated and triggered whenever we would like—as soon as new data arrives
    in the pipeline or when the previous model accuracy dips beneath a predefined
    level. We also described how the model and the data preprocessing steps are saved
    together to avoid any errors from a mismatch between the preprocessing and the
    training. We additionally covered strategies for distributing the model training
    and for tuning the hyperparameters.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们描述了如何将我们的模型训练从独立脚本转移到我们流水线的集成部分。这意味着该过程可以自动化，并在需要时触发——例如在新数据到达流水线或者之前的模型准确度低于预定水平时。我们还描述了如何将模型和数据预处理步骤一起保存，以避免预处理与训练之间的不匹配导致的任何错误。此外，我们还介绍了分发模型训练和调整超参数的策略。
- en: Now that we have a saved model, the next step is to dive into the details of
    what it can do.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个保存的模型，下一步是深入了解它能做什么。
- en: '[1  ](#filepos495010) We use a Keras model in our example project, but TFX
    also works perfectly with an `Estimator` model. Examples can be found in the [TFX
    documentation](https://oreil.ly/KIDko).'
  id: totrans-194
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[1  ](#filepos495010) 在我们的示例项目中使用了 Keras 模型，但 TFX 与 `Estimator` 模型也能完美配合。示例可以在[《TFX
    文档》](https://oreil.ly/KIDko)中找到。'
- en: '[2  ](#filepos555205) The `Trainer` component could be used without the previous
    `Transform` component, and we could load the raw datasets. However, in this case,
    we would miss out on an excellent feature of TFX, which is exporting the preprocessing
    and the model graphs as one SavedModel graph.'
  id: totrans-195
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[2  ](#filepos555205) `Trainer` 组件可以在没有前置的 `Transform` 组件的情况下使用，并且可以加载原始数据集。然而，在这种情况下，我们将错过
    TFX 的一个很好的特性，即将预处理和模型图导出为一个 SavedModel 图。'
- en: '[3  ](#filepos586801)  `tf.Keras` models can be converted to `tf.Estimator`
    models through the `tf.model_to_estimator()` conversion. However, with the recent
    updates to TFX, this is no longer the recommended best practice.'
  id: totrans-196
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[3  ](#filepos586801)  `tf.Keras` 模型可以通过 `tf.model_to_estimator()` 转换成 `tf.Estimator`
    模型。然而，由于 TFX 的最新更新，这不再是推荐的最佳实践。'
- en: '[4  ](#filepos587247) If you are interested in the steps of how component executors
    can be developed and exchanged, we recommend the section [“Reusing Existing Components”](index_split_017.html#filepos1225563)
    in [Chapter 10](index_split_017.html#filepos1073133).'
  id: totrans-197
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[4  ](#filepos587247) 如果您对组件执行者如何开发和交换的步骤感兴趣，我们建议查看[《重复使用现有组件》](index_split_017.html#filepos1225563)
    章节中的 [第 10 章](index_split_017.html#filepos1073133)。'
- en: '[5  ](#filepos587773) For more details on concrete functions, check out the
    [TensorFlow documentation](https://oreil.ly/Y8Hup).'
  id: totrans-198
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[5  ](#filepos587773) 想要了解具体函数的更多细节，请查看[《TensorFlow 文档》](https://oreil.ly/Y8Hup)。'
- en: '[6  ](#filepos605116) The all-reduce operation reduces information from all
    the workers to a single information; in other words, it enables synchronization
    between all training workers.'
  id: totrans-199
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[6  ](#filepos605116) 全局归约操作将所有工作节点的信息归约为单一信息；换句话说，它实现了所有训练工作节点之间的同步。'
