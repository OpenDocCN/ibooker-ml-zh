- en: Chapter 1\. Introduction to MLOps
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 介绍MLOps
- en: By Noah Gift
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: By Noah Gift
- en: Since 1986, I have had a few more deaths, several from insufficient attention
    but mainly from deliberately pushing the limits in various directions—taking a
    chance in bonsai is a bit like taking a chance with love; the best outcome requires
    risky exposure to being hurt and no guarantee of success.
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自1986年以来，我经历了更多的死亡，其中一些是由于注意力不足，但主要是因为故意在各个方向上推限度，冒险盆景有点像冒险恋爱；最好的结果需要冒险接触受伤并且没有成功的保证。
- en: ''
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Dr. Joseph Bogen
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Dr. Joseph Bogen
- en: One of the powerful aspects of science fiction is its ability to imagine a future
    without constraints. One of the most influential science fiction shows of all
    time is the TV show *Star Trek*, which first aired in the mid-1960s, approximately
    60 years ago. The cultural impact inspired designers of technology like the Palm
    Pilot and hand-held cellular phones. In addition, *Star Trek* influenced the cofounder
    of Apple computer, Steve Wozniak, to create Apple computers.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 科幻小说的一个强大之处在于它能够想象一个没有约束的未来。有史以来最具影响力的科幻节目之一是60年前左右首次播出的电视剧*星际迷航*。这种文化影响激发了像Palm
    Pilot和手持式手机的技术设计者。此外，*星际迷航*还影响了苹果计算机的联合创始人史蒂夫·沃兹尼亚克，促使他创建了苹果计算机。
- en: In this age of innovation in machine learning, there are many essential ideas
    from the original series relevant to the coming MLOps (or Machine Learning Operations)
    industrial revolution. For example, *Star Trek* hand-held tricorders can instantly
    classify objects using pretrained multiclass classification models. But, ultimately,
    in this futuristic science-fiction world, domain experts like the science officers,
    medical officers, or captain of the ship, don’t spend months training machine
    learning models. Likewise, the crew of their science vessel, the *Enterprise*,
    are not called data scientists. Instead, they have jobs where they often use data
    science.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个机器学习创新时代，原始系列中的许多重要思想与即将到来的MLOps（或机器学习运营）工业革命相关。例如，*星际迷航*手持三角仪可以使用预训练的多类别分类模型即时对物体进行分类。但最终，在这个未来的科幻世界中，像科学官员、医疗官员或者飞船船长这样的领域专家们，并不花几个月时间来训练机器学习模型。同样，他们的科学船员，*企业号*的船员，也不被称为数据科学家。相反，他们的工作经常涉及使用数据科学。
- en: Many of the machine learning aspects of this *Star Trek* science fiction future
    are no longer science fiction in the 2020s. This chapter guides the reader into
    the foundational theory of how to make this possible. Let’s get started.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在2020年代，*星际迷航*科幻未来的许多机器学习方面已不再是科幻。本章引导读者进入使这一切成为可能的基础理论。让我们开始吧。
- en: Rise of the Machine Learning Engineer and MLOps
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习工程师和MLOps的兴起
- en: Machine learning (ML), with its widespread adoption globally, has created a
    need for a systematic and efficient approach toward building ML systems, leading
    to a sudden rise in demand for ML engineers. These ML engineers, in turn, are
    applying established DevOps best practices to the emerging machine learning technologies.
    The major cloud vendors all have certifications targeting these practitioners.
    I have experience working directly with AWS, Azure, and GCP as a subject matter
    expert on machine learning. In some cases, this includes helping create machine
    learning certifications themselves and official training material. In addition,
    I teach machine learning engineering and cloud computing at some of the top data
    science programs with Duke and Northwestern. Firsthand, I have seen the rise in
    machine learning engineering as many former students have become machine learning
    engineers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）以其在全球范围内的广泛应用，引发了对构建ML系统的系统化和高效方法的需求，从而导致对ML工程师的需求迅速增长。这些ML工程师又将已建立的DevOps最佳实践应用于新兴的机器学习技术。主要的云供应商都有针对这些从业者的认证。我在AWS、Azure和GCP作为机器学习的专家与之直接合作的经验。在某些情况下，这包括帮助创建机器学习认证和官方培训材料。此外，我在杜克大学和西北大学的一些顶尖数据科学项目中教授机器学习工程和云计算。亲身经历中，我看到了机器学习工程师的兴起，许多以前的学生成为了机器学习工程师。
- en: 'Google has a [Professional Machine Learning Engineer certification](https://oreil.ly/83skz).
    It describes an ML engineer as someone who “designs, builds, and productionizes
    ML models to solve business challenges…” Azure has a [Microsoft Certified: Azure
    Data Scientist Associate](https://oreil.ly/mtczl). It describes this type of practitioner
    as someone who “applies their knowledge of data science and machine learning to
    implement and run machine learning workloads…” Finally, AWS describes an [AWS
    Certified Machine Learning specialist](https://oreil.ly/O0cLK) as someone with
    “the ability to design, implement, deploy, and maintain machine learning solutions
    for given business problems.”'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 'Google 有一个 [专业机器学习工程师认证](https://oreil.ly/83skz)。它描述ML工程师是“设计、构建和将ML模型投入生产以解决业务挑战的人…”
    Azure 有一个 [Microsoft Certified: Azure 数据科学家关联](https://oreil.ly/mtczl)。它描述这种从业者是“应用他们在数据科学和机器学习方面的知识来实现和运行机器学习工作负载的人…”
    最后，AWS描述了一个 [AWS Certified 机器学习专家](https://oreil.ly/O0cLK)。他们具备“设计、实施、部署和维护解决特定业务问题的机器学习解决方案的能力。”'
- en: One way to look at data science versus machine learning engineering is to consider
    science versus engineering itself. Science gears toward research, and engineering
    gears toward production. As machine learning moves beyond just the research side,
    companies are eager for a return on investment in hiring around AI and ML. According
    to payscale.com and glassdoor.com, the results show that at the end of 2020, the
    median salary for a data scientist, data engineer, and machine learning engineer
    was similar. According to LinkedIn in Q4 of 2020, 191K jobs mentioned cloud, there
    were 70K data engineering job listings, 55k machine learning engineering job listings,
    and 20k data science job listings, as shown in [Figure 1-1](#Figure-1-1).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一种看待数据科学与机器学习工程的方式是考虑科学与工程本身的区别。科学倾向于研究，而工程则倾向于生产。随着机器学习超越仅仅是研究的一面，公司迫切希望在围绕AI和ML的雇佣中获得投资回报。根据
    payscale.com 和 glassdoor.com 的数据，2020年底，数据科学家、数据工程师和机器学习工程师的中位薪资相似。根据 LinkedIn
    在2020年第四季度的数据显示，191K 个工作提及云计算，有 70K 个数据工程工作列表，55K 个机器学习工程工作列表和 20K 个数据科学工作列表，如图
    [Figure 1-1](#Figure-1-1) 所示。
- en: 'Another way to look at these job trends is that they are a natural part of
    the hype cycle of technology. Organizations realize that to generate a return
    on investment (ROI), they need employees with hard skills: cloud computing, data
    engineering, and machine learning. They also need them in a much larger quantity
    than data scientists. As a result, the decade of the 2020s may show an acceleration
    in treating data science as a behavior, rather than a job title. DevOps is behavior,
    just like data science. Think about the principles of both DevOps and data science.
    In both cases, DevOps and data science are methodologies for evaluating the world,
    not necessarily unique job titles.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种看待这些工作趋势的方式是它们是技术炒作周期的自然组成部分。组织意识到，要产生投资回报（ROI），他们需要具备硬技能的员工：云计算、数据工程和机器学习。他们还需要比数据科学家更多。因此，2020年代可能会显示出将数据科学视为一种行为而非职称的加速趋势。DevOps
    是一种行为，就像数据科学一样。考虑到DevOps和数据科学的原则。在这两种情况下，DevOps 和数据科学都是评估世界的方法论，不一定是唯一的职称。
- en: '![Machine learning jobs](Images/pmlo_0101.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习工作](Images/pmlo_0101.png)'
- en: Figure 1-1\. Machine learning jobs
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-1\. 机器学习工作
- en: Let’s look at the options for measuring the success of a machine learning engineering
    initiative at an organization. First, you could count the machine learning models
    that go into production. Second, you could measure the impact of the ML models
    on business ROI. These metrics culminate in a model’s operational efficiency.
    The cost, uptime, and staff needed to maintain it are signals that predict a machine
    learning engineering project’s success or failure.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下组织中机器学习工程倡议的成功衡量选项。首先，您可以统计进入生产的机器学习模型数量。其次，您可以衡量ML模型对业务ROI的影响。这些指标汇总为模型的运行效率。维护它所需的成本、正常运行时间和人员是预测机器学习工程项目成功或失败的信号。
- en: 'Advanced technology organizations know they need to leverage methodologies
    and tools that decrease the risk of machine learning projects failing. So what
    are these tools and processes used in machine learning engineering? Here is a
    partial list:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 先进技术组织知道他们需要利用能降低机器学习项目失败风险的方法和工具。那么，机器学习工程中使用的这些工具和流程是什么呢？以下是部分列表：
- en: Cloud native ML platforms
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生ML平台
- en: AWS SageMaker, Azure ML Studio, and GCP AI Platform
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: AWS SageMaker，Azure ML Studio 和 GCP AI Platform
- en: Containerized workflows
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 容器化工作流
- en: Docker format containers, Kubernetes, and private and public container registries
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Docker格式容器、Kubernetes和私有以及公共容器注册表
- en: Serverless technology
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器技术
- en: AWS Lambda, AWS Athena, Google Cloud Functions, Azure Functions
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda, AWS Athena, Google Cloud Functions, Azure Functions
- en: Specialized hardware for machine learning
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 用于机器学习的专用硬件
- en: GPUs, Google TPU (TensorFlow Processing Unit), Apple A14, AWS Inferentia Elastic
    inference
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: GPU、Google TPU（TensorFlow处理单元）、Apple A14、AWS Inferentia弹性推断
- en: Big data platforms and tools
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据平台和工具
- en: Databricks, Hadoop/Spark, Snowflake, Amazon EMR (Elastic Map Reduce), Google
    Big Query
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks、Hadoop/Spark、Snowflake、Amazon EMR（弹性Map Reduce）、Google Big Query
- en: One clear pattern about machine learning is how deeply tied it is to cloud computing.
    This is because the raw ingredients of machine learning happen to require massive
    compute, extensive data, and specialized hardware. Thus, there is a natural synergy
    with deep integration with cloud platforms and machine learning engineering. Further
    supporting this is that the cloud platforms are building specialized platforms
    to enhance ML’s operationalization. So, if you are doing ML engineering, you are
    probably doing it in the cloud. Next, let’s discuss how DevOps plays a role in
    doing this.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有关机器学习的一个明显模式是它与云计算的紧密联系。这是因为机器学习的原始成分需要大量计算、广泛的数据和专门的硬件。因此，与云平台的深度集成具有自然的协同效应，与机器学习工程相结合。进一步支持这一点的是，云平台正在构建专门的平台来增强机器学习的操作能力。因此，如果您从事机器学习工程，您很可能是在云中进行。接下来，让我们讨论DevOps在其中的作用。
- en: What Is MLOps?
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是MLOps？
- en: 'Why isn’t machine learning 10X faster? Most of the problem-building machine
    learning systems involve everything surrounding machine learning modeling: data
    engineering, data processing, problem feasibility, and business alignment. One
    issue with this is a focus on the “code” and technical details versus solving
    the business problem with machine learning. There is also a lack of automation
    and the issue of HiPPO (Highest Paid Person’s Opinions) culture. Finally, much
    of machine learning is not cloud native and uses academic datasets and academic
    software packages that don’t scale for large-scale problems.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么机器学习不是快10倍？大多数构建机器学习系统的问题涉及机器学习建模周围的一切：数据工程、数据处理、问题可行性和业务对齐。其中一个问题是过于关注“代码”和技术细节，而不是用机器学习解决业务问题。还存在自动化不足和最高薪水者的观点（HiPPO）文化问题。最后，许多机器学习并非云原生，使用学术数据集和学术软件包，无法解决大规模问题。
- en: The quicker the feedback loop (see Kaizen), the more time to focus on business
    problems like the recent issues of rapid detection of Covid, detecting mask versus
    nonmask computer vision solutions deployed in the real world, and faster drug
    discovery. The technology exists to solve these problems, yet these solutions
    aren’t available in the real world? Why is this?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈循环越快（见Kaizen），就越有时间专注于像快速检测Covid最新问题，检测现实世界中的口罩与非口罩计算机视觉解决方案以及更快的药物发现等业务问题。这些问题存在解决技术，但这些解决方案为何在现实世界中无法使用？为什么呢？
- en: Note
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'What is Kaizen? In Japanese, it means improvement. Using Kaizen as a software
    management philosophy originated in the Japanese automobile industry after World
    War II. It underlies many other techniques: Kanban, root cause analysis & five
    why’s, and Six Sigma. To practice Kaizen, an accurate and realistic assessment
    of the world’s state is necessary and pursues daily, incremental improvements
    in the pursuit of excellence.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是Kaizen？在日语中，它意味着改善。Kaizen作为一种软件管理哲学起源于二战后的日本汽车工业。它支撑许多其他技术：看板、根本原因分析和五个为什么、以及六西格玛。要实践Kaizen，需要对世界状态进行准确而现实的评估，并追求卓越的日常、渐进改进。
- en: The reason models are not moving into production is the impetus for the emergence
    of MLOps as a critical industry standard. MLOps shares a lineage with DevOps in
    that DevOps philosophically demands automation. A common expression is *if it
    is not automated, it’s broken.* Similarly, with MLOps, there must not be components
    of the system that have humans as the levers of the machine. The history of automation
    shows that humans are the least valuable doing repetitive tasks but are the most
    valuable using technology as the architects and practitioners. Likewise, coordination
    between developers, models, and operations must coordinate through transparent
    teamwork and healthy collaboration. Think of MLOps as the process of automating
    machine learning using DevOps methodologies.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 模型没有进入生产的原因促使MLOps作为关键的行业标准出现。MLOps与DevOps有着相同的历史渊源，因为DevOps在哲学上要求自动化。一个常见的说法是*如果不自动化，就是有问题的*。同样，在MLOps中，系统中不应该有人为杠杆的组件。自动化的历史表明，人类在重复任务中的价值最低，但在利用技术作为架构师和实践者时最有价值。同样地，开发者、模型和运维之间的协调必须通过透明的团队合作和健康的协作来实现。把MLOps看作是使用DevOps方法自动化机器学习的过程。
- en: Note
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: What is DevOps? It combines best practices, including microservices, continuous
    integration, and continuous delivery, removing the barriers between Operations
    and Development and Teamwork. You can read more about DevOps in our book [*Python
    for DevOps*](https://learning.oreilly.com/library/view/python-for-devops/9781492057680/)
    (O’Reilly). Python is the predominant language of scripting, DevOps, and machine
    learning. As a result of this, this MLOps book focuses on Python, just as the
    DevOps book focused on Python.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是DevOps？它结合了包括微服务、持续集成和持续交付在内的最佳实践，消除了运维与开发之间以及团队之间的障碍。你可以在我们的书籍 [*Python
    for DevOps*](https://learning.oreilly.com/library/view/python-for-devops/9781492057680/)（O’Reilly）中详细了解DevOps。Python是脚本、DevOps和机器学习的主要语言。因此，这本MLOps书籍着重于Python，就像DevOps书籍着重于Python一样。
- en: With MLOps, not only do the software engineering processes need full automation,
    but so do the data and modeling. The model training and deployment is a new wrinkle
    added to the traditional DevOps lifecycle. Finally, additional monitoring and
    instrumentation must account for new things that can break, like data drift—the
    delta between changes in the data from the last time the model training occurred.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于MLOps来说，不仅需要对软件工程过程进行全面自动化，还需要对数据和建模进行自动化。模型训练和部署是传统DevOps生命周期中新增的问题。最后，额外的监控和仪表必须考虑到可能出现故障的新因素，例如数据漂移——即数据自上次模型训练以来的变化量。
- en: A fundamental problem in getting machine learning models into production is
    the immaturity of the data science industry. The software industry has embraced
    DevOps to solve similar issues; now, the machine learning community embraces MLOps.
    Let’s dive into how to do this.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 将机器学习模型投入生产的一个基本问题是数据科学行业的不成熟。软件行业已经采用DevOps来解决类似的问题；现在，机器学习社区也在推广MLOps。让我们深入了解如何做到这一点。
- en: DevOps and MLOps
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DevOps和MLOps
- en: 'DevOps is a set of technical and management practices that aim to increase
    an organization’s velocity in releasing high-quality software. Some of the benefits
    of DevOps include speed, reliability, scale, and security. These benefits occur
    through adherence to the following best practices:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps是一组旨在提高组织发布高质量软件速度的技术和管理实践。DevOps的一些好处包括速度、可靠性、规模和安全性。这些好处通过遵循以下最佳实践实现：
- en: Continuous integration (CI)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 持续集成（CI）
- en: CI is the process of continuously testing a software project and improving the
    quality based on these tests’ results. It is automated testing using open source
    and SaaS build servers such as GitHub Actions, Jenkins, Gitlab, CircleCI, or cloud
    native build systems like AWS Code Build.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: CI是持续测试软件项目并基于这些测试结果改进质量的过程。它是使用开源和SaaS构建服务器（如GitHub Actions、Jenkins、GitLab、CircleCI或云原生构建系统如AWS
    Code Build）进行自动化测试。
- en: Continuous delivery (CD)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付（CD）
- en: This method delivers code to a new environment without human intervention. CD
    is the process of deploying code automatically, often through the use of IaC.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法在没有人为干预的情况下将代码交付到新环境。CD是通过基础设施即代码自动部署代码的过程。
- en: Microservices
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务
- en: A microservice is a software service with a distinct function that had little
    to no dependencies. One of the most popular Python-based microservice frameworks
    is Flask. For example, a machine learning prediction endpoint is an excellent
    fit for a microservice. These microservices can use a wide variety of technologies,
    including FaaS (function as a service). A perfect example of a cloud function
    is AWS Lambda. A microservice could be container-ready and use CaaS (container
    as a service) to deploy a Flask application with a Dockerfile to a service like
    AWS Fargate, Google Cloud Run, or Azure App Services.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务是具有独特功能且几乎没有依赖性的软件服务。最流行的基于 Python 的微服务框架之一是 Flask。例如，机器学习预测端点非常适合作为微服务。这些微服务可以使用各种技术，包括
    FaaS（函数即服务）。云函数的一个完美示例是 AWS Lambda。微服务可以准备好容器，并使用 CaaS（容器即服务）将具有 Dockerfile 的
    Flask 应用程序部署到 AWS Fargate、Google Cloud Run 或 Azure 应用服务。
- en: Infrastructure as Code
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施即代码
- en: Infrastructure as Code (IaC) is the process of checking the infrastructure into
    a source code repository and “deploying” it to push changes to that repository.
    IaC allows for idempotent behavior and ensures the infrastructure doesn’t require
    humans to build it out. A cloud environment defined purely in code and checked
    into a source control repository is a good example use case. Popular technologies
    include cloud-specific IaC like AWS Cloud Formation or [AWS SAM (Serverless Application
    Model)](https://oreil.ly/4Q3XE). Multicloud options include [Pulumi](https://pulumi.com)
    and [Terraform](https://terraform.io).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施即代码（IaC）是将基础设施检入源代码存储库并“部署”到该存储库以推送更改的过程。IaC 允许幂等行为，并确保基础设施不需要人类来构建它。在代码中定义的云环境并检入源代码存储库是一个很好的示例用例。流行的技术包括云特定的
    IaC，如 AWS Cloud Formation 或 [AWS SAM（无服务器应用程序模型）](https://oreil.ly/4Q3XE)。多云选项包括
    [Pulumi](https://pulumi.com) 和 [Terraform](https://terraform.io)。
- en: Monitoring and instrumentation
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 监控与仪表
- en: Monitoring and instrumentation are the processes and techniques used that allow
    an organization to make decisions about a software system’s performance and reliability.
    Through logging and other tools like application performance monitoring tools
    such as New Relic, Data Dog, or Stackdriver, monitoring and instrumentation are
    essentially collecting data about the behavior of an application in production
    or data science for deployed software systems. This process is where Kaizen comes
    into play; the data-driven organization uses this instrumentation to make things
    better daily or weekly.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 监控与仪表是用于允许组织对软件系统的性能和可靠性做出决策的过程和技术。通过记录和其他工具，如 New Relic、Data Dog 或 Stackdriver
    等应用程序性能监控工具，监控和仪表本质上是收集有关生产或数据科学中部署的软件系统的应用行为的数据。这个过程是 Kaizen 起作用的地方；数据驱动的组织使用这些仪表来每天或每周使事情变得更好。
- en: Effective technical communication
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的技术沟通
- en: This skill involves the ability to create effective, repeatable, and efficient
    communication methods. An excellent example of effective technical communication
    could be adopting AutoML for the initial prototyping of a system. Of course, ultimately,
    the AutoML model may be kept or discarded. Nevertheless, automation can serve
    as an informational tool to prevent work on an intractable problem.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技能涉及创建有效、可重复和高效的沟通方法的能力。一个很好的有效技术沟通的例子可以是采用自动机器学习（AutoML）来进行系统的初步原型设计。当然，最终，AutoML
    模型可能会被保留或丢弃。然而，自动化可以作为一个信息工具，以防止在一个棘手的问题上工作。
- en: Effective technical project management
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的技术项目管理
- en: This process can efficiently use human and technology solutions, like ticket
    systems and spreadsheets, to manage projects. Also, appropriate technical project
    management requires breaking down problems into small, discreet chunks of work,
    so incremental progress occurs. An antipattern in machine learning is often when
    a team works on one production machine model that solves a problem “perfectly.”
    Instead, smaller wins delivered daily or weekly is a more scalable and prudent
    approach to model building.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可以有效地利用人类和技术解决方案，如票务系统和电子表格，来管理项目。此外，适当的技术项目管理需要将问题分解为小的、离散的工作块，以便进行增量进展。在机器学习中的反模式通常是团队致力于解决问题“完美”的一个生产机器模型。相反，每天或每周交付较小的成功案例是建立模型的更可扩展和谨慎的方法。
- en: Continuous integration and continuous delivery are two of the most critical
    pillars of DevOps. Continuous integration involves merging code into a source
    control repository that automatically checks the code’s quality through testing.
    Continuous delivery is when code changes are automatically tested and deployed,
    either to a staging environment or production. Both of these techniques are a
    form of automation in the spirit of Kaizen or continuous improvement.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 持续集成和持续交付是DevOps的两个最关键支柱之一。持续集成涉及将代码合并到源代码控制库中，并通过测试自动检查代码质量。持续交付是指代码更改在自动测试后自动部署到预备环境或生产环境。这两种技术都是持续改进精神下的自动化形式。
- en: A good question to ask is who on the team should implement CI/CD? This question
    would be similar to asking who contributes to taxes in a democracy. In a democracy,
    taxes pay for roads, bridges, law enforcement, emergency services, schools, and
    other infrastructure, so all must contribute to building a better society. Likewise,
    all MLOps team members should help develop and maintain the CI/CD system. A well-maintained
    CI/CD system is a form of investment in the future of the team and company.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好问题是，团队中谁应该实施CI/CD？这个问题类似于在民主国家中谁负责纳税。在民主国家，税款用于修建道路、桥梁、执法、紧急服务、学校及其他基础设施，所以所有人都必须为建设更好的社会贡献力量。同样，所有MLOps团队成员都应该帮助开发和维护CI/CD系统。一个良好维护的CI/CD系统是对团队和公司未来的一种投资。
- en: 'An ML system is also a software system, but it contains a unique component:
    a machine learning model. The same benefits of DevOps can and do apply to ML systems.
    The embrace of automation is why new approaches like Data Versioning and AutoML
    hold many promises in capturing the DevOps mindset.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ML系统同样也是一个软件系统，但它包含一个独特的组件：机器学习模型。DevOps的同样好处可以适用于ML系统。自动化的采纳是为什么新的方法如数据版本控制和自动机器学习在捕捉DevOps思维方式方面充满了许多希望。
- en: An MLOps Hierarchy of Needs
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps需求层次
- en: One way to think about machine learning systems is to consider Maslow’s hierarchy
    of needs, as shown in [Figure 1-2](#Figure-1-2). Lower levels of a pyramid reflect
    “survival,” and true human potential occurs after basic survival and emotional
    needs are met.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一种思考机器学习系统的方法是考虑马斯洛的需求层次理论，如[图1-2](#Figure-1-2)所示。金字塔的底层反映了“生存”，而真正的人类潜力在满足基本生存和情感需求后才会显现。
- en: '![Maslow''s hierarchy of needs theory](Images/pmlo_0102.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![马斯洛需求层次理论](Images/pmlo_0102.png)'
- en: Figure 1-2\. Maslow’s hierarchy of needs theory
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. 马斯洛需求层次理论
- en: The same concept applies to machine learning. An ML system is a software system,
    and software systems work efficiently and reliably when DevOps and data engineering
    best practices are in place. So how could it be possible to deliver the true potential
    of machine learning to an organization if DevOps’ basic foundational rules don’t
    exist or data engineering is not fully automated? The ML hierarchy of needs shown
    in [Figure 1-3](#Figure-1-3) is not a definitive guide but is an excellent place
    to start a discussion.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念同样适用于机器学习。一个ML系统是一个软件系统，而当DevOps和数据工程的最佳实践到位时，软件系统才能高效可靠地运行。因此，如果没有DevOps的基本基础规则或者数据工程没有完全自动化，那么如何将机器学习的真正潜力带给一个组织呢？[图1-3](#Figure-1-3)中展示的ML需求层次不是一个确定的指南，但却是开始讨论的绝佳起点。
- en: '![ML Engineering hierarchy of needs](Images/pmlo_0103.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![ML工程需求层次](Images/pmlo_0103.png)'
- en: Figure 1-3\. ML engineering hierarchy of needs
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3\. ML工程需求层次
- en: One of the major things holding back machine learning projects is this necessary
    foundation of DevOps. After this foundation is complete, next is data automation,
    then platform automation, and then finally true ML automation, or MLOps, occurs.
    The culmination of MLOps is a machine learning system that works. The people that
    work on operationalizing and building machine learning applications are machine
    learning engineers and/or data engineers. Let’s dive into each step of the ML
    hierarchy and make sure you have a firm grasp of implementing them, starting with
    DevOps.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 阻碍机器学习项目的主要因素之一是DevOps的这种必要基础。在这个基础建立完成后，接下来是数据自动化，然后是平台自动化，最后才是真正的ML自动化或者MLOps。MLOps的顶峰是一个能够运行的机器学习系统。负责运营和构建机器学习应用的人是机器学习工程师和/或数据工程师。让我们深入探讨ML需求层次的每一步，并确保您能够牢固地实施它们，从DevOps开始。
- en: Implementing DevOps
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施DevOps
- en: The foundation of DevOps is continuous integration. Without automated testing,
    there is no way to move forward with DevOps. Continuous integration is relatively
    painless for a Python project with the modern tools available. The first step
    is to build a “scaffolding” for a Python project, as shown in [Figure 1-4](#Figure-1-4).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps 的基础是持续集成。没有自动化测试，DevOps 无法前进。对于现代工具可用的 Python 项目来说，持续集成相对来说不太痛苦。第一步是为
    Python 项目建立一个“脚手架”，如 [图1-4](#Figure-1-4) 所示。
- en: '![Python Project Scaffold](Images/pmlo_0104.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![Python 项目脚手架](Images/pmlo_0104.png)'
- en: Figure 1-4\. Python project scaffold
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. Python 项目脚手架
- en: 'The runtime for a Python machine learning project is almost guaranteed to be
    on a Linux operating system. As a result, the following Python project structure
    is straightforward to implement for ML projects. You can access the source code
    for this example [on GitHub](https://oreil.ly/4dei0) for reference as you read
    this section. The components are as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Python 机器学习项目的运行时几乎可以保证在 Linux 操作系统上。因此，以下是为 ML 项目实现简单的 Python 项目结构。你可以访问 GitHub
    上的这个例子的源代码 [链接](https://oreil.ly/4dei0) 作为阅读本节内容的参考。这些组件如下：
- en: Makefile
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Makefile
- en: A *Makefile* runs “recipes” via the `make` system, which comes with Unix-based
    operating systems. Therefore, a Makefile is an ideal choice to simplify the steps
    involved in continuous integration, such as the following. Note that a Makefile
    is a good starting point for a project and will often evolve as new pieces need
    automation.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*Makefile* 通过 `make` 系统运行“recipes”，这是 Unix 操作系统自带的。因此，Makefile 是简化连续集成步骤的理想选择，例如以下内容。请注意，Makefile
    是项目的良好起点，通常会随着需要自动化的新组件而发展。'
- en: Note
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If your project uses a Python virtual environment, you source it before you
    work with a Makefile, since all a Makefile does is run commands. It is a common
    mistake for a newcomer to Python to confuse Makefile with a virtual environment.
    Similarly, suppose you use an editor like Microsoft Visual Studio Code. In that
    case, you will need to tell the editor about your Python virtual environment so
    it can accurately give you syntax highlighting, linting, and other available libraries.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的项目使用 Python 虚拟环境，在使用 Makefile 之前需要激活它，因为 Makefile 只是运行命令。对于 Python 的新手来说，将
    Makefile 与虚拟环境混淆是一个常见的错误。同样，如果你使用像 Microsoft Visual Studio Code 这样的编辑器，你需要告诉编辑器你的
    Python 虚拟环境，以便它可以准确地提供语法高亮、linting 和其他可用库。
- en: Make install
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 执行安装
- en: This step installs software via the `make install` command
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步通过 `make install` 命令安装软件
- en: Make lint
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 执行 lint
- en: This step checks for syntax errors via the `make lint` command
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步通过 `make lint` 命令检查语法错误
- en: Make test
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 执行测试
- en: 'This step runs tests via the `make test` command:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步通过 `make test` 命令运行测试：
- en: '[PRE0]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*requirements.txt*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*requirements.txt*'
- en: A *requirements.txt* file is a convention used by the `pip` installation tool,
    the default installation tool for Python. A project can contain one or more of
    these files if different packages need installation for different environments.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*requirements.txt* 文件是 `pip` 安装工具的一种约定，这是 Python 的默认安装工具。如果需要在不同的环境中安装不同的包，一个项目可以包含一个或多个这样的文件。'
- en: Source code and tests
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码和测试
- en: 'The Python scaffolding’s final portion is to add a source code file and a test
    file, as shown here. This script exists in a file called *hello.py*:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Python 脚手架的最后一部分是添加一个源代码文件和一个测试文件，如下所示。这个脚本存在于一个名为 *hello.py* 的文件中：
- en: '[PRE1]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, the test file is very trivial to create by using the `pytest` framework.
    This script would be in a file *test_hello.py* contained in the same folder as
    *hello.py* so that the `from hello import add` works:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，通过 `pytest` 框架创建测试文件非常简单。这个脚本会在一个名为 *test_hello.py* 的文件中，与 *hello.py* 放在同一个文件夹中，这样
    `from hello import add` 就可以工作：
- en: '[PRE2]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'These four files: *Makefile*, *requirements.txt*, *hello.py*, and *test_hello.py*
    are all that is needed to start the continuous integration journey except for
    creating a local Python virtual environment. To do that, first, create it:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个文件：*Makefile*、*requirements.txt*、*hello.py* 和 *test_hello.py* 就足以启动连续集成之旅，除了创建本地
    Python 虚拟环境外。要做到这一点，首先创建它：
- en: '[PRE3]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Also, be aware that there are generally two ways to create a virtual environment.
    First, many Linux distributions will include the command-line tool `virtualenv`,
    which does the same thing as `python3 -m venv`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，需要注意一般有两种方法创建虚拟环境。首先，许多 Linux 发行版将包含命令行工具 `virtualenv`，它与 `python3 -m venv`
    的功能相同。
- en: 'Next, you source it to “activate” it:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，需要激活它来“激活”它：
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Why create and use a Python virtual environment? This question is ubiquitous
    for newcomers to Python, and there is a straightforward answer. Because Python
    is an interpreted language, it can “grab” libraries from anywhere on the operating
    system. A Python virtual environment isolates third-party packages to a specific
    directory. There are other solutions to this problem and many developing tools.
    They effectively solve the same problem: the Python library and interpreter are
    isolated to a particular project.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要创建和使用 Python 虚拟环境？对于 Python 新手来说，这个问题无处不在，但答案很简单。因为 Python 是一种解释型语言，它可以从操作系统的任何地方“获取”库。Python
    虚拟环境将第三方包隔离到一个特定的目录中。还有其他解决此问题的方案和许多开发工具。它们有效地解决了同样的问题：Python 库和解释器被隔离到特定的项目中。
- en: 'Once you have this scaffolding set up, you can do the following local continuous
    integration steps:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设置了这个框架，你可以在本地执行以下持续集成步骤：
- en: Use `make install` to install the libraries for your project.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `make install` 安装你项目所需的库。
- en: 'The output will look similar to [Figure 1-5](#Figure-1-5) (this example shows
    a run in [GitHub Codespaces](https://oreil.ly/xmqlm)):'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将类似于 [图 1-5](#Figure-1-5)（此示例显示在 [GitHub Codespaces](https://oreil.ly/xmqlm)
    中运行）。
- en: '[PRE5]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![GitHub Code Spaces](Images/pmlo_0105.png)'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![GitHub Code Spaces](Images/pmlo_0105.png)'
- en: Figure 1-5\. GitHub Codespaces
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-5\. GitHub Codespaces
- en: 'Run `make lint` to lint your project:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 `make lint` 来对你的项目进行代码风格检查：
- en: '[PRE6]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Run `make test` to test your project:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 `make test` 来测试你的项目：
- en: '[PRE7]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Once this is working locally, it is straightforward to integrate this same process
    with a remote SaaS build server. Options include GitHub Actions, a Cloud native
    build server like AWS Code Build, GCP CloudBuild, Azure DevOps Pipelines, or an
    open source, self-hosted build server like Jenkins.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在本地工作正常，将这个相同的过程集成到远程 SaaS 构建服务器中就很简单了。选项包括 GitHub Actions、像 AWS Code Build
    这样的云原生构建服务器、GCP CloudBuild、Azure DevOps Pipelines，或者像 Jenkins 这样的开源、自托管构建服务器。
- en: Configuring Continuous Integration with GitHub Actions
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 GitHub Actions 配置持续集成
- en: 'One of the most straightforward ways to implement continuous integration for
    this Python scaffolding project is with GitHub Actions. To do this, you can either
    select “Actions” in the GitHub UI and create a new one or create a file inside
    of these directories you make as shown here:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个 Python 框架项目实施持续集成最简单的方法之一是使用 GitHub Actions。要做到这一点，你可以在 GitHub UI 中选择“Actions”并创建一个新的操作，或者在你创建的这些目录中创建一个文件，如下所示：
- en: '[PRE8]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The GitHub Actions file itself is straightforward to create, and the following
    is an example of one. Note that the exact version of Python sets to whatever interpretation
    the project requires. In this example, I want to check a specific version of Python
    that runs on Azure. The continuous integration steps are trivial to implement
    due to the hard work earlier in creating a Makefile:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub Actions 文件本身很容易创建，以下是一个示例。注意，Python 的确切版本设置为项目所需的任何解释。在此示例中，我想检查在 Azure
    上运行的特定版本的 Python。由于之前创建 Makefile 的辛勤工作，持续集成步骤实施起来非常简单：
- en: '[PRE9]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: An overview of what GitHub Actions looks like when run on “push” events from
    a GitHub repository is shown in [Figure 1-6](#Figure-1-6).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从 GitHub 仓库的“push”事件运行时，GitHub Actions 的概览如 [图 1-6](#Figure-1-6) 所示。
- en: '![GitHub Actions](Images/pmlo_0106.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![GitHub Actions](Images/pmlo_0106.png)'
- en: Figure 1-6\. GitHub Actions
  id: totrans-113
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-6\. GitHub Actions
- en: This step completes the final portion of setting up continuous integration.
    A continuous deployment—i.e., automatically pushing the machine learning project
    into production—would be the next logical step. This step would involve deploying
    the code to a specific location using a continuous delivery process and IaC (Infrastructure
    as Code). This process is shown in [Figure 1-7](#Figure-1-7).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步完成了设置持续集成的最后部分。接下来的逻辑步骤是持续部署，即将机器学习项目自动推送到生产环境。这一步涉及使用持续交付流程和 IaC（基础设施即代码）将代码部署到特定位置。此过程如
    [图 1-7](#Figure-1-7) 所示。
- en: '![Continuous Delivery](Images/pmlo_0107.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![持续交付](Images/pmlo_0107.png)'
- en: Figure 1-7\. Continuous delivery
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-7\. 持续交付
- en: DataOps and Data Engineering
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DataOps 和数据工程
- en: Next up on the ML hierarchy of needs is a way to automate the flow of data.
    For example, imagine a town with a well as the only water source. Daily life is
    complicated because of the need to arrange trips for water, and things we take
    for granted may not work, like on-demand hot showers, on-demand dishwashing, or
    automated irrigation. Similarly, an organization without an automated flow of
    data cannot reliably do MLOps.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在ML需求层次结构中的下一步是自动化数据流。例如，想象一个只有井作为唯一水源的城镇。由于需要为水安排旅行，日常生活变得复杂，而我们认为理所当然的事情可能无法正常工作，比如按需热水淋浴、按需洗碗或自动灌溉。类似地，一个没有数据自动流的组织无法可靠地进行MLOps。
- en: Many commercial tools are evolving to do DataOps. One example includes [Apache
    Airflow](https://oreil.ly/p55kD), designed by Airbnb, then later open sourced,
    to schedule and monitor its data processing jobs. AWS tools include AWS Data Pipeline
    and AWS Glue. AWS Glue is a serverless ETL (Extract, Load, Transform) tool that
    detects a data source’s schema and then stores the data source’s metadata. Other
    tools like AWS Athena and AWS QuickSight can query and visualize the data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 许多商业工具正在演变成DataOps。一个例子包括由Airbnb设计，后来开源的[Apache Airflow](https://oreil.ly/p55kD)，用于调度和监控其数据处理作业。AWS工具包括AWS数据管道和AWS
    Glue。AWS Glue是一个无服务器的ETL（抽取、加载、转换）工具，它检测数据源的架构，然后存储数据源的元数据。其他工具如AWS Athena和AWS
    QuickSight可以查询和可视化数据。
- en: Some items to consider here are the data’s size, the frequency at which the
    information is changed, and how clean the data is. Many organizations use a centralized
    data lake as the hub of all activity around data engineering. The reason a data
    lake is helpful to build automation around, including machine learning, is the
    “near infinite” scale it provides in terms of I/O coupled with its high durability
    and availability.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里需要考虑的一些问题是数据的大小，信息更改的频率以及数据的清洁程度。许多组织使用集中式数据湖作为围绕数据工程的所有活动的中心枢纽。数据湖之所以有助于建立围绕其周围的自动化，包括机器学习，是因为它在I/O方面提供了“接近无限”的规模，并具有高耐用性和可用性。
- en: Note
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: A data lake is often synonymous with a cloud-based object storage system such
    as Amazon S3\. A data lake allows data processing “in place” without needing to
    move it around. A data lake accomplishes this through near-infinite capacity and
    computing characteristics.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖通常与云对象存储系统（例如Amazon S3）等同。数据湖允许在原地进行数据处理，无需移动数据。数据湖通过接近无限的容量和计算特性实现此目标。
- en: When I worked in the film industry on movies like [*Avatar*](https://oreil.ly/MSh29),
    the data was immense; it did need to be moved by an excessively complicated system.
    Now with the cloud, this problem goes away.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在电影行业工作时，比如[*Avatar*](https://oreil.ly/MSh29)，数据是巨大的；确实需要通过一个非常复杂的系统进行移动。现在有了云，这个问题解决了。
- en: '[Figure 1-8](#Figure-1-8) shows a cloud data lake–based workflow. Note the
    ability to do many tasks, all in the exact location, without moving the data.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-8](#Figure-1-8)展示了基于云数据湖的工作流程。请注意，在同一位置执行许多任务的能力，无需移动数据。'
- en: 'Dedicated job titles, like data engineer, can spend all of their time building
    systems that handle these diverse use cases:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 专门的职称，比如数据工程师，可以全天候建造处理这些多样化用例的系统：
- en: Periodic collection of data and running of jobs
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期收集数据和运行作业
- en: Processing streaming data
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理流数据
- en: Serverless and event-driven data
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器和事件驱动数据
- en: Big data jobs
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据作业
- en: Data and model versioning for ML engineering tasks
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于ML工程任务的数据和模型版本控制
- en: '![Data Engineering with a Cloud Data Lake](Images/pmlo_0108.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![使用云数据湖进行数据工程](Images/pmlo_0108.png)'
- en: Figure 1-8\. Data engineering with a cloud data lake
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8。云数据湖的数据工程
- en: Much like a village without running water cannot use an automated dishwashing
    machine, an organization without data automation cannot use advanced methods for
    machine learning. Therefore, data processing needs automation and operationalization.
    This step enables ML tasks further down the chain to operationalize and automate.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 就像一个没有自来水的村庄不能使用自动洗碗机一样，一个没有数据自动化的组织也不能使用先进的机器学习方法。因此，数据处理需要自动化和运营化。这一步骤使得更下游的ML任务能够实现运营化和自动化。
- en: Platform Automation
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平台自动化
- en: Once there is an automated flow of data, the next item on the list to evaluate
    is how an organization can use high-level platforms to build machine learning
    solutions. For example, if an organization is already collecting data into a cloud
    platform’s data lake, such as Amazon S3, it is natural to tie machine learning
    workflows into Amazon Sagemaker. Likewise, if an organization uses Google, it
    could use Google AI Platform or Azure to use Azure Machine Learning Studio. Similarly,
    [Kubeflow](https://kubeflow.org) would be appropriate for an organization using
    Kubernetes versus a public cloud.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据自动流动起来，评估组织如何利用高级平台构建机器学习解决方案就成为清单上的下一个项目。例如，如果组织已将数据收集到云平台的数据湖中，如Amazon
    S3，将机器学习工作流程与Amazon Sagemaker结合是很自然的选择。同样，如果组织使用Google，它可以使用Google AI平台或Azure来使用Azure
    Machine Learning Studio。类似地，对于使用Kubernetes而不是公共云的组织，[Kubeflow](https://kubeflow.org)将是合适的选择。
- en: An excellent example of a platform that solves these problems appears in [Figure 1-9](#Figure-1-9).
    Notice that AWS SageMaker orchestrates a complex MLOps sequence for a real-world
    machine learning problem, including spinning up virtual machines, reading and
    writing to S3, and provisioning production endpoints. Performing these infrastructure
    steps without automation would be foolhardy at best in a production scenario.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些问题的一个优秀平台示例见[图 1-9](#Figure-1-9)。请注意，AWS SageMaker为真实的机器学习问题编排了复杂的MLOps序列，包括启动虚拟机、读写S3以及配置生产终端点。在生产场景中，执行这些基础设施步骤而不进行自动化至少是愚蠢的。
- en: '![Sagemaker MLOps Pipeline](Images/pmlo_0109.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![Sagemaker MLOps管道](Images/pmlo_0109.png)'
- en: Figure 1-9\. Sagemaker MLOps pipeline
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-9\. Sagemaker MLOps管道
- en: An ML platform solves real-world repeatability, scale, and operationalization
    problems.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 一个ML平台解决了真实世界中可重复性、规模化和操作化问题。
- en: MLOps
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps
- en: Assuming all of these other layers are complete (DevOps, Data Automation, and
    Platform Automation) MLOps is possible. Remember from earlier that the process
    of automating machine learning using DevOps methodologies is MLOps. The method
    of building machine learning is machine learning engineering.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 假设所有其他层次（DevOps、数据自动化和平台自动化）都已完成，MLOps就可能实现。请记住，使用DevOps方法自动化机器学习的过程称为MLOps。构建机器学习的方法是机器学习工程。
- en: As a result, MLOps is a behavior, just as DevOps is a behavior. While some people
    work as DevOps engineers, a software engineer will more frequently perform tasks
    using DevOps best practices. Similarly, a machine learning engineer should use
    MLOps best practices to create machine learning systems.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，MLOps是一种行为，就像DevOps是一种行为一样。虽然有些人作为DevOps工程师工作，但软件工程师更频繁地使用DevOps最佳实践执行任务。同样，机器学习工程师应使用MLOps最佳实践创建机器学习系统。
- en: DevOps and MLOps combined best practices?
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DevOps和MLOps结合的最佳实践？
- en: Remember the DevOps practices described earlier in the chapter? MLOps builds
    on those practices and extends specific items to target machine learning systems
    directly.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得本章前面描述的DevOps实践吗？MLOps基于这些实践，并将特定项目扩展到直接针对机器学习系统。
- en: One way to articulate these best practices is to consider that they create reproducible
    models with robust model packaging, validation, and deployment. In addition, these
    enhance the ability to explain and observe model performance. [Figure 1-10](#Figure-1-10)
    shows this in more detail.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 表达这些最佳实践的一种方式是考虑它们通过创建可复制的模型，具有强大的模型打包、验证和部署来增强解释和观察模型性能的能力。[图 1-10](#Figure-1-10)更详细展示了这一点。
- en: '![MLOps Feedback Loop](Images/pmlo_0110.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![MLOps反馈循环](Images/pmlo_0110.png)'
- en: Figure 1-10\. MLOps Feedback Loop
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-10\. MLOps反馈循环
- en: 'The feedback loop includes the following:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈循环包括以下内容：
- en: Create and retrain models with reusable ML Pipelines
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 使用可重用的ML管道创建和重新训练模型
- en: Creating a model just once isn’t enough. The data can change, the customers
    can change, and the people making the models can change. The solution is to have
    reusable ML pipelines that are versioned.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅创建一次模型是不够的。数据可能会发生变化，客户可能会发生变化，制定模型的人可能会发生变化。解决方案是使用版本化的可重用ML管道。
- en: Continuous Delivery of ML Models
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型的持续交付
- en: Continuous delivery of ML Models is similar to continuous delivery of software.
    When all of the steps are automated, including the infrastructure, using IaC,
    the model is deployable at any time to a new environment, including production.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型的持续交付类似于软件的持续交付。当所有步骤都包括基础设施在内自动化，使用IaC时，模型可以随时部署到新环境，包括生产环境。
- en: Audit trail for MLOps pipeline
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps管道的审计跟踪
- en: It is critical to have auditing for machine learning models. There is no shortage
    of problems in machine learning, including security, bias, and accuracy. Therefore,
    having a helpful audit trail is invaluable, just as having adequate logging is
    critical in production software engineering projects. In addition, the audit trail
    is part of the feedback loop where you continuously improve your approach to the
    problem and the actual problem.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习模型进行审计至关重要。机器学习中存在许多问题，包括安全性、偏见和准确性。因此，拥有一个有用的审计追踪系统是无价的，就像在生产软件工程项目中拥有足够的日志记录一样关键。此外，审计追踪系统是反馈循环的一部分，您可以不断改进解决问题和实际问题的方法。
- en: Observe model data drift use to improve future models
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 观察模型数据漂移的使用以改进未来的模型
- en: One of the unique aspects of machine learning is that the data can literally
    “shift” beneath the model. Thus, the model that worked for customers two years
    ago most likely won’t work the same today. By monitoring data drift, i.e., the
    delta of changes from the last time a model training occurred, it is possible
    to prevent accuracy problems before causing production issues.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的一个独特方面是数据可以在模型下方实际“转移”。因此，两年前适用于客户的模型今天很可能不会起同样的作用。通过监控数据漂移，即从上次进行模型训练以来的变化量，可以在引起生产问题之前防止准确性问题。
- en: Conclusion
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This chapter discussed the importance of using DevOps principles in the context
    of machine learning. Beyond just software, machine learning adds the new complexities
    of managing both the data and the model. The solution to this complexity is to
    embrace automation the way the software engineering community has done with DevOps.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了在机器学习背景下使用DevOps原则的重要性。除了软件本身外，机器学习还增加了管理数据和模型的新复杂性。解决这种复杂性的方法是像软件工程社区在DevOps中所做的那样接受自动化。
- en: Building a bookshelf is different from growing a tree. A bookshelf requires
    an initial design then a one-time build. Complex software systems involving machine
    learning are more like growing a tree. A tree that grows successfully requires
    multiple dynamic inputs, including soil, water, wind, and sun.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 建造书架与种植树木不同。书架需要初步设计，然后一次性建造。涉及机器学习的复杂软件系统更像是种植树木。一个成功生长的树木需要多个动态输入，包括土壤、水、风和阳光。
- en: Likewise, one way to think about MLOps is the rule of 25%. In [Figure 1-13](#Figure-1-13),
    software engineering, data engineering, modeling, and the business problem are
    equally important. The multidisciplinary aspect of MLOps is what makes it tough
    to do. However, there are many good examples of companies doing MLOps following
    this rule of 25%.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，理解MLOps的一种方法是25%法则。在[图1-13](#Figure-1-13)中，软件工程、数据工程、建模和业务问题同样重要。MLOps的跨学科特性使其难以处理。然而，有许多公司在遵循这个25%法则的MLOps方面有很好的例子。
- en: '![Rule of 25%](Images/pmlo_0113.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![25%法则](Images/pmlo_0113.png)'
- en: Figure 1-13\. Rule of 25%
  id: totrans-162
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-13。25%法则
- en: Tesla cars are one good example; they provide customers with what they want
    in the form of semi-autonomous vehicles. They also have excellent software engineering
    practices in that they do constant updates. Simultaneously, the car’s system continuously
    trains the model to improve based on new data it receives. Another example of
    a product following the rule of 25% is the Amazon Alexa device.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 特斯拉汽车是一个很好的例子；它们通过半自动驾驶汽车形式提供客户所需的功能。它们还在软件工程实践中做了很好的更新。同时，汽车系统还不断训练模型，以根据接收到的新数据进行改进。符合25%法则的产品的另一个例子是亚马逊的Alexa设备。
- en: Foundational skills necessary for MLOps are discussed in the next chapter. These
    include math for programmers, examples of data science projects, and a complete
    end-to-end MLOps process. By doing the recommended exercises at the end of this
    chapter, you put yourself in a great position to absorb the following content.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将讨论MLOps所需的基础技能。这些包括程序员的数学、数据科学项目示例以及完整的端到端MLOps流程。通过在本章末推荐的练习，您将使自己处于吸收后续内容的绝佳位置。
- en: Exercises
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Create a new GitHub repository with necessary Python scaffolding using a `Makefile`,
    linting, and testing. Then, perform additional steps such as code formatting in
    your Makefile.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`Makefile`创建一个新的GitHub存储库，并生成必要的Python支架结构，包括linting和测试。然后，在您的Makefile中执行额外的步骤，如代码格式化。
- en: Using [GitHub Actions](https://oreil.ly/csmNI), test a GitHub project with two
    or more Python versions.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[GitHub Actions](https://oreil.ly/csmNI)来测试一个GitHub项目，使用两个或更多Python版本。
- en: Using a cloud native build server (AWS Code Build, GCP CloudBuild, or Azure
    DevOps Pipelines), perform continuous integration for your project.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用云原生构建服务器（如AWS Code Build、GCP CloudBuild或Azure DevOps Pipelines），为您的项目执行持续集成。
- en: Containerize a GitHub project by integrating a Dockerfile and automatically
    registering new containers to a Container Registry.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过集成Dockerfile将GitHub项目容器化，并自动将新容器注册到容器注册表。
- en: Create a simple load test for your application using a load test framework such
    as [locust](https://locust.io) or [loader io](https://loader.io) and automatically
    run this test when you push changes to a staging branch.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用负载测试框架如[locust](https://locust.io)或[loader io](https://loader.io)为您的应用程序创建一个简单的负载测试，并在将更改推送到预备分支时自动运行此测试。
- en: Critical Thinking Discussion Questions
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批判性思维讨论问题
- en: What problems does a continuous integration (CI) system solve?
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续集成（CI）系统解决了哪些问题？
- en: Why is a CI system an essential part of both a SaaS software product and an
    ML system?
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么CI系统是SaaS软件产品和ML系统的重要组成部分？
- en: Why are cloud platforms the ideal target for analytics applications? How do
    data engineering and DataOps assist in building cloud-based analytics applications?
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么云平台是分析应用程序的理想目标？数据工程和DataOps如何帮助构建基于云的分析应用程序？
- en: How does deep learning benefit from the cloud? Is deep learning feasible without
    cloud computing?
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习如何从云计算中受益？深度学习在没有云计算的情况下可行吗？
- en: Explain what MLOps is and how it can enhance a machine learning engineering
    project.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释MLOps是什么以及它如何增强机器学习工程项目。
