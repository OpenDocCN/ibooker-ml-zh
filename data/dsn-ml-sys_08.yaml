- en: Chapter 8\. Data Distribution Shifts and Monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章 数据分布转移和监控
- en: Let’s start the chapter with a story I was told by an executive that many readers
    might be able to relate to. About two years ago, his company hired a consulting
    firm to develop an ML model to help them predict how many of each grocery item
    they’d need next week, so they could restock the items accordingly. The consulting
    firm took six months to develop the model. When the consulting firm handed the
    model over, his company deployed it and was very happy with its performance. They
    could finally boast to their investors that they were an AI-powered company.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一位高管告诉我的一个故事开始，许多读者可能会有共鸣。大约两年前，他的公司聘请了一家咨询公司开发一个 ML 模型，帮助他们预测下周他们需要多少杂货商品，以便他们可以相应地补货。咨询公司花了六个月时间开发这个模型。当咨询公司交付模型时，他的公司部署并且对其表现非常满意。他们最终可以向他们的投资者夸耀他们是一家
    AI 驱动的公司。
- en: 'However, a year later, their numbers went down. The demand for some items was
    consistently being overestimated, which caused the extra items to expire. At the
    same time, the demand for some items was consistently being underestimated, leading
    to lost sales.^([1](ch08.xhtml#ch01fn250)) Initially, his inventory team manually
    changed the model’s predictions to correct the patterns they noticed, but eventually,
    the model’s predictions had become so bad that they could no longer use it. They
    had three options: pay the same consulting firm an obscene amount of money to
    update the model, pay another consulting firm even more money because this firm
    would need time to get up to speed, or hire an in-house team to maintain the model
    onward.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一年后，他们的数据降低了。一些商品的需求被持续高估，导致额外的商品过期。同时，一些商品的需求一直被低估，导致销售额损失^([1](ch08.xhtml#ch01fn250))。最初，他的库存团队手动更改了模型的预测，以纠正他们注意到的模式，但最终，模型的预测变得如此糟糕，以至于他们无法再使用它。他们有三种选择：支付同一家咨询公司天价来更新模型，支付另一家咨询公司更多的钱，因为这家公司需要时间来适应，或者雇佣内部团队来维护模型。
- en: 'His company learned the hard way an important lesson that the rest of the industry
    is also discovering: deploying a model isn’t the end of the process. A model’s
    performance degrades over time in production. Once a model has been deployed,
    we still have to continually monitor its performance to detect issues as well
    as deploy updates to fix these issues.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 他的公司通过艰难的经历学到了一条重要的教训，这也是这个行业其他公司正在发现的：部署模型并不是流程的终点。模型在生产环境中的性能会随时间降低。一旦模型被部署，我们仍然需要不断地监控其性能，以便检测问题并部署更新来解决这些问题。
- en: 'In this chapter and the next, we’ll cover the necessary topics to help you
    keep a model in production. We’ll start by covering reasons why ML models that
    perform great during development fail in production. Then, we’ll take a deep dive
    into one especially prevalent and thorny issue that affects almost all ML models
    in production: data distribution shifts. This occurs when the data distribution
    in production differs and diverges from the data distribution the model was exposed
    to during training. We’ll continue with how to monitor for distribution shifts.
    In the next chapter, we’ll cover how to continually update your models in production
    to adapt to shifts in data distributions.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章和下一章中，我们将涵盖必要的主题，以帮助您保持模型在生产中。我们将首先介绍在开发阶段表现出色的 ML 模型在生产中失败的原因。然后，我们将深入了解一个特别普遍和棘手的问题，影响几乎所有生产中的
    ML 模型：数据分布转移。当生产环境中的数据分布与模型在训练期间暴露的数据分布不同时出现数据分布转变。我们将继续介绍如何监控分布转移。在下一章中，我们将介绍如何不断更新你的生产模型以适应数据分布的变化。
- en: Causes of ML System Failures
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML 系统失败的原因
- en: 'Before we identify the cause of ML system failures, let’s briefly discuss what
    an ML system failure is. A failure happens when one or more expectations of the
    system is violated. In traditional software, we mostly care about a system’s operational
    expectations: whether the system executes its logic within the expected operational
    metrics, e.g., latency and throughput.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定 ML 系统失败的原因之前，让我们简要讨论一下什么是 ML 系统失败。当系统的一个或多个预期被违反时，就会发生失败。在传统软件中，我们主要关心系统的操作预期：系统是否在预期的操作指标范围内执行其逻辑，例如延迟和吞吐量。
- en: For an ML system, we care about both its operational metrics and its ML performance
    metrics. For example, consider an English-French machine translation system. Its
    operational expectation might be that, given an English sentence, the system returns
    a French translation within a one-second latency. Its ML performance expectation
    is that the returned translation is an accurate translation of the original English
    sentence 99% of the time.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个机器学习系统，我们关注其操作指标和ML性能指标。例如，考虑一个英法机器翻译系统。其操作预期可能是，在给定的英文句子后，系统在一秒内返回一个法语翻译。其ML性能预期是，返回的翻译在99%的情况下准确翻译原始的英文句子。
- en: If you enter an English sentence into the system and don’t get back a translation,
    the first expectation is violated, so this is a system failure.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你输入一句英文句子到系统中，却没有得到翻译，第一个预期被违反，这就是系统故障。
- en: If you get back a translation that isn’t correct, it’s not necessarily a system
    failure because the accuracy expectation allows some margin of error. However,
    if you keep entering different English sentences into the system and keep getting
    back wrong translations, the second expectation is violated, which makes it a
    system failure.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你得到的翻译不正确，并不一定是系统故障，因为准确性预期允许一定的误差。但是，如果你不断输入不同的英文句子到系统中，却一直得到错误的翻译，那么第二个预期被违反，这就成为了系统故障。
- en: Operational expectation violations are easier to detect, as they’re usually
    accompanied by an operational breakage such as a timeout, a 404 error on a webpage,
    an out-of-memory error, or a segmentation fault. However, ML performance expectation
    violations are harder to detect as doing so requires measuring and monitoring
    the performance of ML models in production. In the preceding example of the English-French
    machine translation system, detecting whether the returned translations are correct
    99% of the time is difficult if we don’t know what the correct translations are
    supposed to be. There are countless examples of Google Translate’s painfully wrong
    translations being used by users because they aren’t aware that these are wrong
    translations. For this reason, we say that ML systems often fail silently.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 操作预期违规较易检测，通常会伴随操作故障，如超时、网页的404错误、内存溢出或段错误。然而，机器学习性能预期的违规检测则较难，因为这需要在生产环境中测量和监控机器学习模型的性能。在先前的英法机器翻译系统示例中，如果我们不知道正确的翻译结果，要检测返回翻译是否正确99%的难度很大。有很多例子表明，谷歌翻译的严重错误翻译被用户使用，是因为用户不知道这些是错误的翻译。因此，我们说机器学习系统经常会默默地失败。
- en: 'To effectively detect and fix ML system failures in production, it’s useful
    to understand why a model, after proving to work well during development, would
    fail in production. We’ll examine two types of failures: software system failures
    and ML-specific failures.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要有效地检测和修复生产中的机器学习系统故障，了解为何一个在开发过程中表现良好的模型在生产环境中会失败是很有用的。我们将分析两种类型的故障：软件系统故障和ML特定故障。
- en: Software System Failures
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 软件系统故障
- en: 'Software system failures are failures that would have happened to non-ML systems.
    Here are some examples of software system failures:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 软件系统故障是非机器学习系统可能发生的故障。以下是一些软件系统故障的示例：
- en: Dependency failure
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖项故障
- en: A software package or a codebase that your system depends on breaks, which leads
    your system to break. This failure mode is common when the dependency is maintained
    by a third party, and especially common if the third party that maintains the
    dependency no longer exists.^([2](ch08.xhtml#ch01fn251))
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你的系统依赖的软件包或代码库出现问题，导致你的系统崩溃。当依赖项由第三方维护时，这种故障模式很常见，特别是如果维护该依赖项的第三方不再存在。^([2](ch08.xhtml#ch01fn251))
- en: Deployment failure
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 部署失败
- en: Failures caused by deployment errors, such as when you accidentally deploy the
    binaries of an older version of your model instead of the current version, or
    when your systems don’t have the right permissions to read or write certain files.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于部署错误引起的故障，比如你意外地部署了旧版本的模型二进制文件，而不是当前版本，或者你的系统没有正确的权限来读取或写入某些文件。
- en: Hardware failures
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件故障
- en: When the hardware that you use to deploy your model, such as CPUs or GPUs, doesn’t
    behave the way it should. For example, the CPUs you use might overheat and break
    down.^([3](ch08.xhtml#ch01fn252))
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当你用来部署模型的硬件，如CPU或GPU，表现不如预期时，比如你使用的CPU可能会过热并且出现故障。^([3](ch08.xhtml#ch01fn252))
- en: Downtime or crashing
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 停机或崩溃
- en: If a component of your system runs from a server somewhere, such as AWS or a
    hosted service, and that server is down, your system will also be down.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果系统的某个组件在某个服务器上运行，例如AWS或托管服务，而该服务器宕机，您的系统也将宕机。
- en: Just because some failures are not specific to ML doesn’t mean they’re not important
    for ML engineers to understand. In 2020, Daniel Papasian and Todd Underwood, two
    ML engineers at Google, looked at 96 cases where a large ML pipeline at Google
    broke. They reviewed data from over the previous 15 years to determine the causes
    and found out that 60 out of these 96 failures happened due to causes not directly
    related to ML.^([4](ch08.xhtml#ch01fn253)) Most of the issues are related to distributed
    systems, e.g., where the workflow scheduler or orchestrator makes a mistake, or
    related to the data pipeline, e.g., where data from multiple sources is joined
    incorrectly or the wrong data structures are being used.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 有些失败并非特定于机器学习，这并不意味着对机器学习工程师来说它们不重要。在2020年，谷歌的两位机器学习工程师Daniel Papasian和Todd
    Underwood分析了96个谷歌大型机器学习管道出现故障的案例。他们回顾了过去15年的数据，以确定造成这些故障的原因，发现其中60个故障并非直接与机器学习相关。^([4](ch08.xhtml#ch01fn253))
    大多数问题与分布式系统有关，例如工作流调度器或编排器出错，或者与数据管道有关，例如多个来源的数据连接错误或使用了错误的数据结构。
- en: Addressing software system failures requires not ML skills, but traditional
    software engineering skills, and addressing them is beyond the scope of this book.
    Because of the importance of traditional software engineering skills in deploying
    ML systems, ML engineering is mostly engineering, not ML.^([5](ch08.xhtml#ch01fn254))
    For readers interested in learning how to make ML systems reliable from the software
    engineering perspective, I highly recommend the book [*Reliable Machine Learning*](https://oreil.ly/5UOds),
    published by O’Reilly with Todd Underwood as one of the authors.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 处理软件系统故障不需要机器学习技能，而是传统的软件工程技能，并且处理它们超出了本书的范围。由于传统软件工程技能在部署机器学习系统中的重要性，机器学习工程大多是工程，而不是机器学习。^([5](ch08.xhtml#ch01fn254))
    对于有兴趣从软件工程角度学习如何使机器学习系统可靠的读者，我强烈推荐由Todd Underwood等人撰写的书籍 [*可靠的机器学习*](https://oreil.ly/5UOds)，由O'Reilly出版。
- en: A reason for the prevalence of software system failures is that because ML adoption
    in the industry is still nascent, tooling around ML production is limited and
    best practices are not yet well developed or standardized. However, as toolings
    and best practices for ML production mature, there are reasons to believe that
    the proportion of software system failures will decrease and the proportion of
    ML-specific failures will increase.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 软件系统故障普遍的原因是，由于工业中对机器学习的采用仍处于起步阶段，围绕机器学习生产的工具和最佳实践尚不完善或未标准化。然而，随着机器学习生产工具和最佳实践的成熟，有理由相信软件系统故障的比例将减少，而机器学习特定故障的比例将增加。
- en: ML-Specific Failures
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习特定的故障
- en: ML-specific failures are failures specific to ML systems. Examples include data
    collection and processing problems, poor hyperparameters, changes in the training
    pipeline not correctly replicated in the inference pipeline and vice versa, data
    distribution shifts that cause a model’s performance to deteriorate over time,
    edge cases, and degenerate feedback loops.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习特定的故障是指仅限于机器学习系统的故障。例如包括数据收集和处理问题，超参数不佳，训练管道中的更改未能正确复制到推断管道中，反之亦然，导致模型性能随时间下降的数据分布变化，边缘情况以及退化反馈循环等。
- en: 'In this chapter, we’ll focus on addressing ML-specific failures. Even though
    they account for a small portion of failures, they can be more dangerous than
    non-ML failures as they’re hard to detect and fix, and they can prevent ML systems
    from being used altogether. We’ve covered data problems in great detail in [Chapter 4](ch04.xhtml#training_data),
    hyperparameter tuning in [Chapter 6](ch06.xhtml#model_development_and_offline_evaluatio),
    and the danger of having two separate pipelines for training and inference in
    [Chapter 7](ch07.xhtml#model_deployment_and_prediction_service). In this chapter,
    we’ll discuss three new but very common problems that arise after a model has
    been deployed: production data differing from training data, edge cases, and degenerate
    feedback loops.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将重点讨论处理特定于机器学习的故障。尽管这些故障占比很小，但它们可能比非机器学习故障更危险，因为它们很难检测和修复，并且可能导致机器学习系统根本无法使用。在[第四章](ch04.xhtml#training_data)中，我们详细讨论了数据问题，[第六章](ch06.xhtml#model_development_and_offline_evaluatio)讨论了超参数调整，以及[第七章](ch07.xhtml#model_deployment_and_prediction_service)讨论了训练和推断使用两个独立管道的危险。在本章中，我们将讨论模型部署后出现的三个新但非常常见的问题：生产数据与训练数据不同，边缘案例和退化反馈循环。
- en: Production data differing from training data
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生产数据与训练数据不同
- en: When we say that an ML model learns from the training data, it means that the
    model learns the underlying distribution of the training data with the goal of
    leveraging this learned distribution to generate accurate predictions for unseen
    data—data that it didn’t see during training. We’ll go into what this means mathematically
    in the section [“Data Distribution Shifts”](#data_distribution_shifts). When the
    model is able to generate accurate predictions for unseen data, we say that this
    model “generalizes to unseen data.”^([6](ch08.xhtml#ch01fn255)) The test data
    that we use to evaluate a model during development is supposed to represent unseen
    data, and the model’s performance on the test data is supposed to give us an idea
    of how well the model will generalize.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们说一个机器学习模型从训练数据中学习时，意味着模型学习训练数据的基础分布，目标是利用这种学习到的分布为未见过的数据生成准确的预测——也就是在训练过程中没有见过的数据。我们将在“数据分布变化”章节中数学上详细说明这意味着什么。当模型能够为未见数据生成准确的预测时，我们称这个模型“对未见数据泛化良好”^([6](ch08.xhtml#ch01fn255))。我们用来评估模型在开发过程中的测试数据，应该代表未见过的数据，而模型在测试数据上的表现应该给我们一个模型泛化能力的概念。
- en: One of the first things I learned in ML courses is that it’s essential for the
    training data and the unseen data to come from a similar distribution. The assumption
    is that the unseen data comes from a *stationary* distribution that is *the same*
    as the training data distribution. If the unseen data comes from a different distribution,
    the model might not generalize well.^([7](ch08.xhtml#ch01fn256))
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我在机器学习课程中学到的第一件事就是训练数据和未见数据来自相似的分布是至关重要的。假设未见数据来自与训练数据分布“稳态”的相同分布。如果未见数据来自不同的分布，那么模型可能无法很好地泛化。^([7](ch08.xhtml#ch01fn256))
- en: 'This assumption is incorrect in most cases for two reasons. First, the underlying
    distribution of the real-world data is unlikely to be *the same* as the underlying
    distribution of the training data. Curating a training dataset that can accurately
    represent the data that a model will encounter in production turns out to be very
    difficult.^([8](ch08.xhtml#ch01fn257)) Real-world data is multifaceted and, in
    many cases, virtually infinite, whereas training data is finite and constrained
    by the time, compute, and human resources available during the dataset creation
    and processing. There are many different selection and sampling biases, as discussed
    in [Chapter 4](ch04.xhtml#training_data), that can happen and make real-world
    data diverge from training data. The divergence can be something as minor as real-world
    data using a different type of encoding of emojis. This type of divergence leads
    to a common failure mode known as *the train-serving skew*: a model that does
    great in development but performs poorly when deployed.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种假设在大多数情况下都是不正确的，原因有两个。首先，真实世界数据的基础分布不太可能与训练数据的基础分布*相同*。精心策划一个能够准确代表模型在生产中遇到的数据的训练数据集，结果证明非常困难。^([8](ch08.xhtml#ch01fn257))
    真实世界的数据是多面的，在许多情况下几乎是无限的，而训练数据是有限的，并且受到创建和处理数据集期间可用的时间、计算和人力资源的限制。存在许多不同的选择和抽样偏差，正如[第4章](ch04.xhtml#training_data)中讨论的那样，这些偏差可能发生并使真实世界数据与训练数据偏离。这种偏差可能仅仅是真实世界数据使用了一种不同的表情符号编码类型。这种类型的偏差导致了一种常见的失败模式，即*训练-服务偏差*：一个在开发中表现良好但在部署时表现不佳的模型。
- en: Second, the real world isn’t *stationary*. Things change. Data distributions
    shift. In 2019, when people searched for Wuhan, they likely wanted to get travel
    information, but since COVID-19, when people search for Wuhan, they likely want
    to know about the place where COVID-19 originated. Another common failure mode
    is that a model does great when first deployed, but its performance degrades over
    time as the data distribution changes. This failure mode needs to be continually
    monitored and detected for as long as a model remains in production.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，现实世界并非*静止*不变的。事物变化，数据分布变化。2019年，人们搜索武汉时，可能想获取旅行信息，但自从COVID-19以来，当人们搜索武汉时，他们可能想了解COVID-19起源的地方。另一种常见的失败模式是，一个模型在首次部署时表现良好，但随着时间推移，随着数据分布的变化，其性能会下降。这种失败模式需要在模型继续投入使用期间进行持续监测和检测。
- en: When I use COVID-19 as an example that causes data shifts, some people have
    the impression that data shifts only happen because of unusual events, which implies
    they don’t happen often. Data shifts happen all the time, suddenly, gradually,
    or seasonally. They can happen suddenly because of a specific event, such as when
    your existing competitors change their pricing policies and you have to update
    your price predictions in response, or when you launch your product in a new region,
    or when a celebrity mentions your product, which causes a surge in new users,
    and so on. They can happen gradually because social norms, cultures, languages,
    trends, industries, etc. just change over time. They can also happen due to seasonal
    variations, such as people might be more likely to request rideshares in the winter
    when it’s cold and snowy than in the spring.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当我以COVID-19作为导致数据转移的例子时，一些人有这样的印象，即数据转移只发生在不寻常的事件中，这意味着它们并不经常发生。数据转移随时随地发生，突然、逐渐或季节性地。它们可能会突然发生，因为特定事件，例如你的现有竞争对手改变了他们的定价策略，你必须对价格预测进行更新，或者当你在新区域推出产品时，或者当一位名人提到你的产品时，引起新用户的激增，等等。它们可能会逐渐发生，因为社会规范、文化、语言、趋势、行业等随时间的推移而变化。它们也可能由于季节变化而发生，例如在冬季寒冷多雪时，人们更有可能要求共乘服务，而在春季则不太可能。
- en: Due to the complexity of ML systems and the poor practices in deploying them,
    a large percentage of what might look like data shifts on monitoring dashboards
    are caused by internal errors,^([9](ch08.xhtml#ch01fn258)) such as bugs in the
    data pipeline, missing values incorrectly inputted, inconsistencies between the
    features extracted during training and inference, features standardized using
    statistics from the wrong subset of data, wrong model version, or bugs in the
    app interface that force users to change their behaviors.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器学习系统的复杂性及其在部署过程中的糟糕实践，监控仪表板上可能看起来像是数据转移的大部分情况都是由内部错误引起的，^([9](ch08.xhtml#ch01fn258))
    例如数据管道中的错误、错误输入的缺失值、训练和推理期间提取的特征不一致、使用错误数据子集统计标准化的特征、错误的模型版本，或者应用界面中的错误导致用户改变其行为。
- en: Since this is an error mode that affects almost all ML models, we’ll cover this
    in detail in the section [“Data Distribution Shifts”](#data_distribution_shifts).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是几乎所有机器学习模型都会受到影响的错误模式，我们将在章节 [“数据分布变化”](#data_distribution_shifts) 中详细讨论这个问题。
- en: Edge cases
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 边缘情况
- en: Imagine there existed a self-driving car that can drive you safely 99.99% of
    the time, but the other 0.01% of the time, it might get into a catastrophic accident
    that can leave you permanently injured or even dead.^([10](ch08.xhtml#ch01fn259))
    Would you use that car?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下存在一辆自动驾驶汽车，99.99% 的时间能够安全驾驶，但剩下的0.01% 的时间可能会发生灾难性事故，导致您永久受伤甚至死亡^([10](ch08.xhtml#ch01fn259))。您会使用这样的车吗？
- en: If you’re tempted to say no, you’re not alone. An ML model that performs well
    on most cases but fails on a small number of cases might not be usable if these
    failures cause catastrophic consequences. For this reason, major self-driving
    car companies are focusing on making their systems work on edge cases.^([11](ch08.xhtml#ch01fn260))
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你倾向于选择不使用，那么你并不孤单。一个在大多数情况下表现良好但在少数情况下失败的机器学习模型，如果这些失败造成灾难性后果，可能就无法使用。因此，主要的自动驾驶汽车公司正在专注于使其系统在边缘情况下工作^([11](ch08.xhtml#ch01fn260))。
- en: Edge cases are the data samples so extreme that they cause the model to make
    catastrophic mistakes. Even though edge cases generally refer to data samples
    drawn from the same distribution, if there is a sudden increase in the number
    of data samples in which your model doesn’t perform well, it could be an indication
    that the underlying data distribution has shifted.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘情况是那些极端的数据样本，它们会导致模型做出灾难性的错误。尽管边缘情况通常指的是从相同分布抽取的数据样本，如果在您的模型表现不佳的数据样本数量突然增加，这可能表明基础数据分布发生了变化。
- en: Autonomous vehicles are often used to illustrate how edge cases can prevent
    an ML system from being deployed. But this is also true for any safety-critical
    application such as medical diagnosis, traffic control, e-discovery,^([12](ch08.xhtml#ch01fn261))
    etc. It can also be true for non-safety-critical applications. Imagine a customer
    service chatbot that gives reasonable responses to most of the requests, but sometimes,
    it spits out outrageously racist or sexist content. This chatbot will be a brand
    risk for any company that wants to use it, thus rendering it unusable.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 自动驾驶车辆经常被用来说明边缘情况如何阻止机器学习系统的部署。但这也适用于任何安全关键应用，例如医疗诊断、交通控制、电子发现^([12](ch08.xhtml#ch01fn261))
    等等。对于非安全关键应用也可能如此。想象一下，一个客服聊天机器人能够对大部分请求给出合理的回应，但有时却会输出极端种族主义或性别歧视内容。这种机器人将成为任何希望使用它的公司的品牌风险，因此无法使用。
- en: Degenerate feedback loops
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 退化反馈循环
- en: In the section [“Natural Labels”](ch04.xhtml#natural_labels), we discussed a
    feedback loop as the time it takes from when a prediction is shown until the time
    feedback on the prediction is provided. The feedback can be used to extract natural
    labels to evaluate the model’s performance and train the next iteration of the
    model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在章节 [“自然标签”](ch04.xhtml#natural_labels) 中，我们讨论了反馈循环，即从显示预测到提供预测反馈的时间。该反馈可以用来提取自然标签以评估模型的性能并训练模型的下一个迭代。
- en: A *degenerate feedback loop* can happen when the predictions themselves influence
    the feedback, which, in turn, influences the next iteration of the model. More
    formally, a degenerate feedback loop is created when a system’s outputs are used
    to generate the system’s future inputs, which, in turn, influence the system’s
    future outputs. In ML, a system’s predictions can influence how users interact
    with the system, and because users’ interactions with the system are sometimes
    used as training data to the same system, degenerate feedback loops can occur
    and cause unintended consequences. Degenerate feedback loops are especially common
    in tasks with natural labels from users, such as recommender systems and ads click-through-rate
    prediction.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*退化反馈循环* 可能会发生在预测本身影响反馈的情况下，进而影响模型的下一个迭代。更正式地说，当系统的输出用于生成系统未来的输入时，就会产生退化反馈循环，这反过来又会影响系统未来的输出。在机器学习中，系统的预测可以影响用户如何与系统交互，而用户与系统的互动有时被用作相同系统的训练数据，这样就可能发生退化反馈循环，导致意想不到的后果。退化反馈循环在涉及用户自然标签的任务中特别常见，如推荐系统和广告点击率预测。'
- en: To make this concrete, imagine you build a system to recommend to users songs
    that they might like. The songs that are ranked high by the system are shown first
    to users. Because they are shown first, users click on them more, which makes
    the system more confident that these recommendations are good. In the beginning,
    the rankings of two songs, A and B, might be only marginally different, but because
    A was originally ranked a bit higher, it showed up higher in the recommendation
    list, making users click on A more, which made the system rank A even higher.
    After a while, A’s ranking became much higher than B’s.^([13](ch08.xhtml#ch01fn262))
    Degenerate feedback loops are one reason why popular movies, books, or songs keep
    getting more popular, which makes it hard for new items to break into popular
    lists. This type of scenario is incredibly common in production, and it’s heavily
    researched. It goes by many different names, including “exposure bias,” “popularity
    bias,” “filter bubbles,” and sometimes “echo chambers.”
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要让这个更具体，想象你建立了一个系统，推荐用户可能喜欢的歌曲。系统排名较高的歌曲会首先展示给用户。因为它们首先展示，用户点击率更高，这使得系统更加确信这些推荐是好的。刚开始时，两首歌曲
    A 和 B 的排名可能只有微小差异，但因为 A 的初始排名稍高，所以它在推荐列表中排名较高，使得用户更多地点击 A，这进一步提高了系统对 A 的排名。过一段时间后，A
    的排名比 B 的高得多。^([13](ch08.xhtml#ch01fn262)) 退化反馈循环是为什么流行电影、书籍或歌曲保持流行的原因之一，这使得新物品难以打入流行列表。这种场景在生产中非常常见，并且得到了大量研究。它有许多不同的名称，包括“曝光偏差”、“流行偏差”、“过滤泡沫”以及有时称为“回声室”。
- en: Here’s another example to drive the danger of degenerative feedback loops home.
    Imagine building a resume-screening model to predict whether someone with a certain
    resume is qualified for the job. The model finds that feature X accurately predicts
    whether someone is qualified, so it recommends resumes with feature X. You can
    replace X with features like “went to Stanford,” “worked at Google,” or “identifies
    as male.” Recruiters only interview people whose resumes are recommended by the
    model, which means they only interview candidates with feature X, which means
    the company only hires candidates with feature X. This, in turn, makes the model
    put even more weight on feature X.^([14](ch08.xhtml#ch01fn263)) Having visibility
    into how your model makes predictions—such as measuring the importance of each
    feature for the model, as discussed in [Chapter 5](ch05.xhtml#feature_engineering)—can
    help detect the bias toward feature X in this case.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 下面再举一个例子来说明退化反馈循环的危险性。想象构建一个简历筛选模型，预测某个简历的人是否合格。模型发现特征 X 能够准确预测某人是否合格，因此推荐具有特征
    X 的简历。你可以用“毕业于斯坦福大学”、“在谷歌工作过”或“男性身份认同”等特征替换 X。招聘人员只会面试模型推荐的简历，这意味着他们只会面试具有特征 X
    的候选人，公司也只会雇佣具有特征 X 的候选人。这反过来又使模型对特征 X 给予更多权重。^([14](ch08.xhtml#ch01fn263)) 了解模型如何进行预测，例如通过测量模型每个特征的重要性来检测这种情况下对特征
    X 的偏见，可以帮助识别这种偏见。
- en: Left unattended, degenerate feedback loops can cause your model to perform suboptimally
    at best. At worst, they can perpetuate and magnify biases embedded in data, such
    as biasing against candidates without feature X.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果放任不管，退化反馈循环最多会导致您的模型表现不佳。在最坏的情况下，它们可能会持续放大数据中嵌入的偏见，比如偏向没有特征 X 的候选人。
- en: Detecting degenerate feedback loops
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 检测退化反馈循环
- en: If degenerate feedback loops are so bad, how do we know if a feedback loop in
    a system is degenerate? When a system is offline, degenerate feedback loops are
    difficult to detect. Degenerate loops result from user feedback, and a system
    won’t have users until it’s online (i.e., deployed to users).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果退化反馈循环如此糟糕，那么我们如何知道系统中的反馈循环是否是退化的呢？当系统离线时，很难检测到退化反馈循环。退化循环是由用户反馈导致的，而在系统上线之前（即部署给用户之前），系统不会有用户。
- en: 'For the task of recommender systems, it’s possible to detect degenerate feedback
    loops by measuring the popularity diversity of a system’s outputs even when the
    system is offline. An item’s popularity can be measured based on how many times
    it has been interacted with (e.g., seen, liked, bought, etc.) in the past. The
    popularity of all the items will likely follow a long-tail distribution: a small
    number of items are interacted with a lot, while most items are rarely interacted
    with at all. Various metrics such as *aggregate diversity* and *average coverage
    of long-tail items* proposed by [Brynjolfsson et al.](https://oreil.ly/8EKPf)
    (2011), [Fleder and Hosanagar](https://oreil.ly/PmNQm) (2009), and [Abdollahpouri
    et al.](https://oreil.ly/EkiFw) (2019) can help you measure the diversity of the
    outputs of a recommender system.^([15](ch08.xhtml#ch01fn264)) Low scores mean
    that the outputs of your system are homogeneous, which might be caused by popularity
    bias.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于推荐系统的任务，可以通过在系统离线时测量其输出的流行度多样性来检测退化反馈环。一个物品的流行度可以根据过去与其互动的次数（如查看、点赞、购买等）来衡量。所有物品的流行度可能会遵循长尾分布：少数物品会被大量互动，而大多数物品几乎不被互动。[Brynjolfsson
    et al.](https://oreil.ly/8EKPf)（2011）、[Fleder and Hosanagar](https://oreil.ly/PmNQm)（2009）和[Abdollahpouri
    et al.](https://oreil.ly/EkiFw)（2019）提出的诸如*聚合多样性*和*长尾物品平均覆盖率*等各种度量标准可以帮助你衡量推荐系统输出的多样性。^([15](ch08.xhtml#ch01fn264))
    低分数意味着你的系统输出是同质化的，这可能是由流行度偏见引起的。
- en: In 2021, Chia et al. went a step further and proposed the measurement of hit
    rate against popularity. They first divided items into buckets based on their
    popularity—e.g., bucket 1 consists of items that have been interacted with less
    than 100 times, bucket 2 consists of items that have been interacted with more
    than 100 times but less than 1,000 times, etc. Then they measured the prediction
    accuracy of a recommender system for each of these buckets. If a recommender system
    is much better at recommending popular items than recommending less popular items,
    it likely suffers from popularity bias.^([16](ch08.xhtml#ch01fn265)) Once your
    system is in production and you notice that its predictions become more homogeneous
    over time, it likely suffers from degenerate feedback loops.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2021 年，Chia 等人更进一步，提出了根据流行度来衡量点击率的方法。他们首先根据物品的流行度将其分成不同的桶 —— 比如，桶 1 包括那些与用户互动少于
    100 次的物品，桶 2 包括那些与用户互动超过 100 次但少于 1,000 次的物品等等。然后，他们针对每个桶测量了推荐系统的预测准确度。如果一个推荐系统在推荐流行物品方面要比推荐不那么流行的物品要好得多，那么它很可能存在流行度偏见。^([16](ch08.xhtml#ch01fn265))
    一旦你的系统投入生产，并且你注意到它的预测随时间变得更加同质化，那么它很可能存在退化反馈环。
- en: Correcting degenerate feedback loops
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 纠正退化反馈环
- en: Because degenerate feedback loops are a common problem, there are many proposed
    methods on how to correct them. In this chapter, we’ll discuss two methods. The
    first one is to use randomization, and the second one is to use positional features.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 因为退化反馈环是一个常见问题，所以有许多提出的方法来纠正它们。在本章中，我们将讨论两种方法。第一种方法是使用随机化，第二种方法是使用位置特征。
- en: We’ve discussed that degenerate feedback loops can cause a system’s outputs
    to be more homogeneous over time. Introducing randomization in the predictions
    can reduce their homogeneity. In the case of recommender systems, instead of showing
    the users only the items that the system ranks highly for them, we show users
    random items and use their feedback to determine the true quality of these items.
    This is the approach that TikTok follows. Each new video is randomly assigned
    an initial pool of traffic (which can be up to hundreds of impressions). This
    pool of traffic is used to evaluate each video’s unbiased quality to determine
    whether it should be moved to a bigger pool of traffic or be marked as irrelevant.^([17](ch08.xhtml#ch01fn266))
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过，退化反馈环可以导致系统的输出随时间变得更加同质化。在预测中引入随机化可以减少它们的同质性。在推荐系统的情况下，我们不再只向用户展示系统为其排名较高的物品，而是展示随机物品，并利用用户的反馈来确定这些物品的真实质量。这是
    TikTok 采用的方法。每个新视频都会随机分配一个初始的流量池（最多可以达到数百次展示）。这个流量池用于评估每个视频的无偏质量，以确定它是否应该转移到更大的流量池或被标记为无关紧要。^([17](ch08.xhtml#ch01fn266))
- en: Randomization has been shown to improve diversity, but at the cost of user experience.^([18](ch08.xhtml#ch01fn267))
    Showing our users completely random items might cause users to lose interest in
    our product. An intelligent exploration strategy, such as those discussed in the
    section [“Contextual bandits as an exploration strategy”](ch09.xhtml#contextual_bandits_as_an_exploration_st),
    can help increase item diversity with acceptable prediction accuracy loss. Schnabel
    et al. use a small amount of randomization and causal inference techniques to
    estimate the unbiased value of each song.^([19](ch08.xhtml#ch01fn268)) They were
    able to show that this algorithm was able to correct a recommender system to make
    recommendations fair to creators.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 随机化已经显示可以提高多样性，但以用户体验为代价。^([18](ch08.xhtml#ch01fn267)) 展示给用户完全随机的项目可能会导致用户对我们的产品失去兴趣。智能的探索策略，例如本节讨论的[“作为探索策略的情境臂展”](ch09.xhtml#contextual_bandits_as_an_exploration_st)，可以帮助增加项目的多样性，同时可以接受的预测准确性损失。Schnabel等人使用少量随机化和因果推断技术来估计每首歌的无偏值。^([19](ch08.xhtml#ch01fn268))
    他们能够展示该算法能够纠正推荐系统，使得推荐对创作者更公平。
- en: We’ve also discussed that degenerate feedback loops are caused by users’ feedback
    on predictions, and users’ feedback on a prediction is biased based on where it
    is shown. Consider the preceding recommender system example, where each time you
    recommend five songs to users. You realize that the top recommended song is much
    more likely to be clicked on compared to the other four songs. You are unsure
    whether your model is exceptionally good at picking the top song, or whether users
    click on any song as long as it’s recommended on top.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了退化反馈循环是由用户对预测的反馈引起的，而用户对预测的反馈则基于它们所展示的位置而偏倚。考虑前述推荐系统的例子，每次向用户推荐五首歌曲。你会发现，排名靠前的推荐歌曲比其他四首更有可能被点击。你不确定你的模型是在选择顶部歌曲方面异常出色，还是只要推荐在顶部，用户就会点击任何一首歌。
- en: If the position in which a prediction is shown affects its feedback in any way,
    you might want to encode the position information using *positional features*.
    Positional features can be numerical (e.g., positions are 1, 2, 3,...) or Boolean
    (e.g., whether a prediction is shown in the first position or not). Note that
    “positional features” are different from “positional embeddings” mentioned in
    [Chapter 5](ch05.xhtml#feature_engineering).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果预测所显示的位置以任何方式影响其反馈，你可能希望使用*位置特征*来编码位置信息。位置特征可以是数值型的（例如，位置为 1、2、3...）或布尔型的（例如，是否预测显示在第一位置）。请注意，“位置特征”与第五章提到的“位置嵌入”是不同的。
- en: Here is a naive example to show how to use positional features. During training,
    you add “whether a song is recommended first” as a feature to your training data,
    as shown in [Table 8-1](#adding_positional_features_to_your_trai). This feature
    allows your model to learn how much being a top recommendation influences how
    likely a song is clicked on.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的示例，展示如何使用位置特征。在训练过程中，你将“是否推荐为首位”的特征添加到你的训练数据中，如[表 8-1](#adding_positional_features_to_your_trai)所示。这个特征允许你的模型学习，成为顶部推荐对歌曲被点击的可能性有多大。
- en: Table 8-1\. Adding positional features to your training data to mitigate degenerate
    feedback loops
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-1\. 将位置特征添加到你的训练数据中以减少退化反馈循环
- en: '| ID | Song | Genre | Year | Artist | User | 1st Position | Click |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| ID | 歌曲 | 风格 | 年份 | 艺术家 | 用户 | 首位位置 | 点击 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | Shallow | Pop | 2020 | Lady Gaga | listenr32 | **False** | No |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 肤浅 | 流行 | 2020 | Lady Gaga | listenr32 | **假** | 否 |'
- en: '| 2 | Good Vibe | Funk | 2019 | Funk Overlord | listenr32 | **False** | No
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 好的氛围 | 放克 | 2019 | 放克霸主 | listenr32 | **假** | 否 |'
- en: '| 3 | Beat It | Rock | 1989 | Michael Jackson | fancypants | **False** | No
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 击败它 | 摇滚 | 1989 | 迈克尔·杰克逊 | fancypants | **假** | 否 |'
- en: '| 4 | In Bloom | Rock | 1991 | Nirvana | fancypants | **True** | Yes |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 在绽放中 | 摇滚 | 1991 | 尼尔瓦纳 | fancypants | **真** | 是 |'
- en: '| 5 | Shallow | Pop | 2020 | Lady Gaga | listenr32 | **True** | Yes |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 肤浅 | 流行 | 2020 | Lady Gaga | listenr32 | **真** | 是 |'
- en: During inference, you want to predict whether a user will click on a song regardless
    of where the song is recommended, so you might want to set the 1st Position feature
    to be False. Then you look at the model’s predictions for various songs for each
    user and can choose the order in which to show each song.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在推断过程中，你想预测用户是否会点击一首歌，无论歌曲推荐在何处，因此你可能希望将首位位置特征设置为假。然后你查看模型对每位用户各种歌曲的预测，并可以选择展示每首歌曲的顺序。
- en: This is a naive example because doing this alone might not be enough to combat
    degenerate feedback loops. A more sophisticated approach would be to use two different
    models. The first model predicts the probability that the user will see and consider
    a recommendation taking into account the position at which that recommendation
    will be shown. The second model then predicts the probability that the user will
    click on the item given that they saw and considered it. The second model doesn’t
    concern positions at all.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个简单的例子，因为仅凭这样做可能不足以对抗退化的反馈循环。更复杂的方法是使用两个不同的模型。第一个模型预测用户会看到并考虑推荐的概率，考虑推荐显示的位置。第二个模型则预测用户在看到并考虑了推荐后点击该项的概率。第二个模型完全不考虑位置。
- en: Data Distribution Shifts
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分布偏移
- en: 'In the previous section, we discussed common causes for ML system failures.
    In this section, we’ll zero in onto one especially sticky cause of failures: data
    distribution shifts, or data shifts for short. Data distribution shift refers
    to the phenomenon in supervised learning when the data a model works with changes
    over time, which causes this model’s predictions to become less accurate as time
    passes. The distribution of the data the model is trained on is called the *source
    distribution*. The distribution of the data the model runs inference on is called
    the *target distribution*.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分，我们讨论了机器学习系统失败的常见原因。在本节中，我们将重点关注一种特别棘手的失败原因：数据分布偏移，或简称数据偏移。数据分布偏移指的是在监督学习中，模型所处理的数据随时间变化，导致模型的预测随着时间推移变得不太准确的现象。模型训练所使用的数据分布称为*源分布*。模型推断时所使用的数据分布称为*目标分布*。
- en: Even though discussions around data distribution shift have only become common
    in recent years with the growing adoption of ML in the industry, data distribution
    shift in systems that learned from data has been studied as early as in 1986.^([20](ch08.xhtml#ch01fn269))
    There’s also a book on dataset distribution shifts, *Dataset Shift in Machine
    Learning* by Quiñonero-Candela et al., published by MIT Press in 2008.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管关于数据分布偏移的讨论在近年来随着机器学习在工业界的广泛应用而变得常见，但从数据中学习的系统中数据分布偏移的研究早在1986年就已经开始了。^([20](ch08.xhtml#ch01fn269))
    还有一本关于数据集分布偏移的书籍，《数据集偏移在机器学习中的应用》由Quiñonero-Candela等人撰写，2008年由MIT出版社出版。
- en: Types of Data Distribution Shifts
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据分布偏移类型
- en: 'While data distribution shift is often used interchangeably with concept drift
    and covariate shift and occasionally label shift, these are three distinct subtypes
    of data shift. Note that this discussion on different types of data shifts is
    math-heavy and mostly useful from a research perspective: to develop efficient
    algorithms to detect and address data shifts requires understanding the causes
    of those shifts. In production, when encountering a distribution shift, data scientists
    don’t usually stop to wonder what type of shift it is. They mostly care about
    what they can do to handle this shift. If you find this discussion dense, feel
    free to skip to the section [“General Data Distribution Shifts”](#general_data_distribution_shifts).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数据分布偏移通常与概念漂移、协变量偏移以及偶尔的标签偏移可以互换使用，但这些是数据偏移的三种不同子类型。请注意，关于不同类型的数据偏移的讨论充满数学内容，并且大多数情况下从研究的角度来看才有用：开发有效的算法来检测和处理数据偏移需要理解这些偏移的原因。在生产环境中，当遇到分布偏移时，数据科学家通常不会停下来思考是哪种类型的偏移。他们更关心如何处理这种偏移。如果你觉得这部分内容过于密集，可以直接跳到[“一般数据分布偏移”](#general_data_distribution_shifts)一节。
- en: 'To understand what concept drift, covariate shift, and label shift mean, we
    first need to define a couple of mathematical notations. Let’s call the inputs
    to a model *X* and its outputs *Y*. We know that in supervised learning, the training
    data can be viewed as a set of samples from the joint distribution *P*(*X*, *Y*),
    and then ML usually models *P*(*Y*|*X*). This joint distribution *P*(*X*, *Y*)
    can be decomposed in two ways:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解概念漂移、协变量偏移和标签偏移的含义，我们首先需要定义一些数学符号。让我们将模型的输入称为*X*，输出称为*Y*。我们知道在监督学习中，训练数据可以看作是从联合分布*P*(*X*,
    *Y*)中抽取的样本集，而机器学习通常模拟的是*P*(*Y*|*X*)。这个联合分布*P*(*X*, *Y*)可以通过两种方式分解：
- en: '*P*(*X*, *Y*) = *P*(*Y*|*X*)*P*(*X*)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*X*, *Y*) = *P*(*Y*|*X*)*P*(*X*)'
- en: '*P*(*X*, *Y*) = *P*(*X*|*Y*)*P*(*Y*)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*X*, *Y*) = *P*(*X*|*Y*)*P*(*Y*)'
- en: '*P*(*Y*|*X*) denotes the conditional probability of an output given an input—for
    example, the probability of an email being spam given the content of the email.
    *P*(*X*) denotes the probability density of the input. *P*(*Y*) denotes the probability
    density of the output. Label shift, covariate shift, and concept drift are defined
    as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*P*(*Y*|*X*) 表示给定输入的输出的条件概率，例如给定电子邮件内容的垃圾邮件的概率。*P*(*X*) 表示输入的概率密度。*P*(*Y*)
    表示输出的概率密度。标签偏移、协变量偏移和概念漂移的定义如下：'
- en: Covariate shift
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 协变量偏移
- en: When *P*(*X*) changes but *P*(*Y*|*X*) remains the same. This refers to the
    first decomposition of the joint distribution.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *P*(*X*) 变化时，但 *P*(*Y*|*X*) 保持不变。这指的是联合分布的第一个分解。
- en: Label shift
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 标签偏移
- en: When *P*(*Y*) changes but *P*(*X*|*Y*) remains the same. This refers to the
    second decomposition of the joint distribution.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *P*(*Y*) 变化时，但 *P*(*X*|*Y*) 保持不变。这指的是联合分布的第二个分解。
- en: Concept drift
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 概念漂移
- en: When *P*(*Y*|*X*) changes but *P*(*X*) remains the same. This refers to the
    first decomposition of the joint distribution.^([21](ch08.xhtml#ch01fn270))
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *P*(*Y*|*X*) 变化时，但 *P*(*X*) 保持不变。这指的是联合分布的第一个分解。^([21](ch08.xhtml#ch01fn270))
- en: If you find this confusing, don’t panic. We’ll go over examples in the following
    section to illustrate their differences.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您觉得这很混乱，不要惊慌。我们将在以下部分中讨论示例，以说明它们之间的区别。
- en: Covariate shift
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 协变量偏移
- en: '*Covariate shift* is one of the most widely studied forms of data distribution
    shift.^([22](ch08.xhtml#ch01fn271)) In statistics, a covariate is an independent
    variable that can influence the outcome of a given statistical trial but which
    is not of direct interest. Consider that you are running an experiment to determine
    how locations affect the housing prices. The housing price variable is your direct
    interest, but you know the square footage affects the price, so the square footage
    is a covariate. In supervised ML, the label is the variable of direct interest,
    and the input features are covariate variables.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*协变量偏移* 是研究最广泛的数据分布转移形式之一。^([22](ch08.xhtml#ch01fn271)) 在统计学中，协变量是可以影响给定统计试验结果的独立变量，但不是直接感兴趣的。考虑您正在进行一个实验，以确定位置如何影响房价。房价变量是您的直接兴趣，但您知道房屋面积会影响价格，因此房屋面积是一个协变量。在监督学习中，标签是直接感兴趣的变量，而输入特征是协变量变量。'
- en: Mathematically, covariate shift is when *P*(*X*) changes, but *P*(*Y*|*X*) remains
    the same, which means that the distribution of the input changes, but the conditional
    probability of an output given an input remains the same.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学上，协变量偏移是指 *P*(*X*) 变化，但 *P*(*Y*|*X*) 保持不变，这意味着输入的分布发生变化，但给定输入时输出的条件概率保持不变。
- en: To make this concrete, consider the task of detecting breast cancer. You know
    that the risk of breast cancer is higher for women over the age of 40,^([23](ch08.xhtml#ch01fn272))
    so you have a variable “age” as your input. You might have more women over the
    age of 40 in your training data than in your inference data, so the input distributions
    differ for your training and inference data. However, for an example with a given
    age, such as above 40, the probability that this example has breast cancer is
    constant. So *P*(*Y*|*X*), the probability of having breast cancer given age over
    40, is the same.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了具体化这一点，考虑检测乳腺癌的任务。您知道乳腺癌的风险在40岁以上的女性中更高，^([23](ch08.xhtml#ch01fn272)) 因此您有一个名为“年龄”的输入变量。您的训练数据中可能有更多40岁以上的女性，而推断数据中可能没有这么多，因此您的训练和推断数据的输入分布不同。然而，对于给定年龄的示例，例如超过40岁，该示例具有乳腺癌的概率是恒定的。因此
    *P*(*Y*|*X*)，即给定年龄超过40岁的情况下有乳腺癌的概率是相同的。
- en: During model development, covariate shifts can happen due to biases during the
    data selection process, which could result from difficulty in collecting examples
    for certain classes. For example, suppose that to study breast cancer, you get
    data from a clinic where women go to test for breast cancer. Because people over
    40 are encouraged by their doctors to get checkups, your data is dominated by
    women over 40\. For this reason, covariate shift is closely related to the sample
    selection bias problem.^([24](ch08.xhtml#ch01fn273))
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型开发过程中，由于数据选择过程中的偏见，可能会发生协变量偏移，这可能是由于难以收集某些类别的示例造成的。例如，假设为了研究乳腺癌，您从妇女去检查乳腺癌的诊所中获得数据。由于医生鼓励40岁以上的人进行检查，您的数据被40岁以上的女性所主导。因此，协变量偏移与样本选择偏差问题密切相关。^([24](ch08.xhtml#ch01fn273))
- en: Covariate shifts can also happen because the training data is artificially altered
    to make it easier for your model to learn. As discussed in [Chapter 4](ch04.xhtml#training_data),
    it’s hard for ML models to learn from imbalanced datasets, so you might want to
    collect more samples of the rare classes or oversample your data on the rare classes
    to make it easier for your model to learn the rare classes.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 协变量转移还可能由于训练数据人为修改而发生，以使您的模型更容易学习。如[第4章](ch04.xhtml#training_data)讨论的那样，ML模型很难从不平衡的数据集中学习，因此您可能希望收集更多罕见类别的样本，或者过采样罕见类别的数据，以使模型更容易学习这些罕见类别。
- en: 'Covariate shift can also be caused by the model’s learning process, especially
    through active learning. In [Chapter 4](ch04.xhtml#training_data), we defined
    active learning as follows: instead of randomly selecting samples to train a model
    on, we use the samples most helpful to that model according to some heuristics.
    This means that the training input distribution is altered by the learning process
    to differ from the real-world input distribution, and covariate shifts are a by-product.^([25](ch08.xhtml#ch01fn274))'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 协变量转移还可能是由模型的学习过程引起的，尤其是通过主动学习。在[第4章](ch04.xhtml#training_data)中，我们将主动学习定义为：不是随机选择样本来训练模型，而是根据某些启发式方法选择对该模型最有帮助的样本。这意味着训练输入分布被学习过程改变，使其与现实世界输入分布不同，协变量转移是其副产品^([25](ch08.xhtml#ch01fn274))。
- en: In production, covariate shift usually happens because of major changes in the
    environment or in the way your application is used. Imagine you have a model to
    predict how likely a free user will be to convert to a paid user. The income level
    of the user is a feature. Your company’s marketing department recently launched
    a campaign that attracts users from a demographic more affluent than your current
    demographic. The input distribution into your model has changed, but the probability
    that a user with a given income level will convert remains the same.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，协变量转移通常发生在环境或应用程序使用方式发生重大变化时。假设您有一个模型，用于预测免费用户转化为付费用户的可能性。用户的收入水平是一个特征。您公司的市场部最近推出了一项吸引更富裕人群的广告活动，这导致用户的输入分布发生了变化，但对于给定收入水平用户的转化概率仍然保持不变。
- en: 'If you know in advance how the real-world input distribution will differ from
    your training input distribution, you can leverage techniques such as *importance
    weighting* to train your model to work for the real-world data. Importance weighting
    consists of two steps: estimate the density ratio between the real-world input
    distribution and the training input distribution, then weight the training data
    according to this ratio and train an ML model on this weighted data.^([26](ch08.xhtml#ch01fn275))'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您预先知道实际输入分布与训练输入分布的差异，您可以利用诸如*重要性加权*之类的技术来训练模型以适应实际数据。重要性加权包括两个步骤：估计实际输入分布与训练输入分布之间的密度比率，然后根据此比率对训练数据进行加权，并在加权数据上训练ML模型^([26](ch08.xhtml#ch01fn275))。
- en: However, because we don’t know in advance how the distribution will change in
    the real world, it’s very difficult to preemptively train your models to make
    them robust to new, unknown distributions. There has been research that attempts
    to help models learn representations of latent variables that are invariant across
    data distributions,^([27](ch08.xhtml#idm46868207601952)) but I’m not aware of
    their adoption in the industry.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于我们无法预先知道现实世界中分布如何变化，因此很难提前训练模型，使其对新的、未知的分布具有鲁棒性。已经有研究试图帮助模型学习潜在变量的表示，这些变量在数据分布上是不变的^([27](ch08.xhtml#idm46868207601952))，但我不清楚它们在工业界的采纳情况。
- en: Label shift
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标签转移
- en: Label shift, also known as prior shift, prior probability shift, or target shift,
    is when *P*(*Y*) changes but *P*(*X*|*Y*) remains the same. You can think of this
    as the case when the output distribution changes but, *for a given output*, the
    input distribution stays the same.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 标签转移，也称为先验转移、先验概率转移或目标转移，是指*P*(*Y*)变化，但*P*(*X*|*Y*)保持不变的情况。您可以将其视为输出分布发生变化但对于给定输出，输入分布保持不变的情况。
- en: Remember that covariate shift is when the input distribution changes. When the
    input distribution changes, the output distribution also changes, resulting in
    both covariate shift and label shift happening at the same time. Consider the
    preceding breast cancer example for covariate shift. Because there are more women
    over 40 in our training data than in our inference data, the percentage of POSITIVE
    labels is higher during training. However, if you randomly select person A with
    breast cancer from your training data and person B with breast cancer from your
    test data, A and B have the same probability of being over 40\. This means that
    *P*(*X*|*Y*), or probability of age over 40 given having breast cancer, is the
    same. So this is also a case of label shift.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，协变量漂移是指输入分布发生变化时。当输入分布改变时，输出分布也会改变，从而导致同时发生协变量漂移和标签漂移。考虑前面的乳腺癌例子中的协变量漂移。由于我们的训练数据中40岁以上的女性比推断数据中的要多，所以在训练期间，POSITIVE标签的百分比更高。然而，如果你从训练数据中随机选择一个患有乳腺癌的A人和从测试数据中选择一个患有乳腺癌的B人，那么A和B患有乳腺癌的概率相同。这意味着*P*(*X*|*Y*)，即患有乳腺癌的情况下年龄超过40岁的概率，是相同的。因此，这也是标签漂移的情况。
- en: However, not all covariate shifts result in label shifts. It’s a subtle point,
    so we’ll consider another example. Imagine that there is now a preventive drug
    that every woman takes that helps reduce their chance of getting breast cancer.
    The probability *P*(*Y*|*X*) reduces for women of all ages, so it’s no longer
    a case of covariate shift. However, given a person with breast cancer, the age
    distribution remains the same, so this is still a case of label shift.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非所有的协变量漂移都会导致标签漂移。这是一个微妙的问题，所以我们将考虑另一个例子。想象一下，现在有一种预防性药物，每个女性都服用，可以帮助减少她们罹患乳腺癌的几率。对所有年龄段的女性来说，概率*P*(*Y*|*X*)都会降低，因此不再是协变量漂移的情况。然而，对于已经得了乳腺癌的人来说，年龄分布仍然保持不变，因此这仍然是标签漂移的情况。
- en: Because label shift is closely related to covariate shift, methods for detecting
    and adapting models to label shifts are similar to covariate shift adaptation
    methods. We’ll discuss them more later in this chapter.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 由于标签漂移与协变量漂移密切相关，用于检测和适应标签漂移的方法与适应协变量漂移的方法类似。我们将在本章稍后讨论这些方法。
- en: Concept drift
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 概念漂移
- en: Concept drift, also known as posterior shift, is when the input distribution
    remains the same but the conditional distribution of the output given an input
    changes. You can think of this as “same input, different output.” Consider you’re
    in charge of a model that predicts the price of a house based on its features.
    Before COVID-19, a three-bedroom apartment in San Francisco could cost $2,000,000\.
    However, at the beginning of COVID-19, many people left San Francisco, so the
    same apartment would cost only $1,500,000\. So even though the distribution of
    house features remains the same, the conditional distribution of the price of
    a house given its features has changed.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 概念漂移，也被称为后验转移，是指输入分布保持不变，但是给定输入时输出的条件分布发生变化。你可以把它想象成“同样的输入，不同的输出”。想象一下，你负责一个根据房屋特征预测房价的模型。在COVID-19之前，旧金山的一个三居室公寓可能售价为$2,000,000。然而，在COVID-19爆发初期，许多人离开了旧金山，因此同样的公寓现在只需$1,500,000。因此，即使房屋特征的分布保持不变，给定其特征的房价的条件分布也发生了变化。
- en: In many cases, concept drifts are cyclic or seasonal. For example, rideshare
    prices will fluctuate on weekdays versus weekends, and flight ticket prices rise
    during holiday seasons. Companies might have different models to deal with cyclic
    and seasonal drifts. For example, they might have one model to predict rideshare
    prices on weekdays and another model for weekends.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，概念漂移是周期性的或季节性的。例如，共享出行的价格在工作日和周末会有波动，航班票价在假期季节会上涨。公司可能会有不同的模型来处理周期性和季节性的漂移。例如，他们可能有一个模型来预测工作日的共享出行价格，另一个模型用于周末。
- en: General Data Distribution Shifts
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一般数据分布转移
- en: There are other types of changes in the real world that, even though not well
    studied in research, can still degrade your models’ performance.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管研究中并没有详细研究，但现实世界中存在其他类型的变化，这些变化仍然可能降低模型的性能。
- en: One is *feature change*, such as when new features are added, older features
    are removed, or the set of all possible values of a feature changes.^([28](ch08.xhtml#ch01fn276))
    For example, your model was using years for the “age” feature, but now it uses
    months, so the range of this feature’s values has drifted. One time, our team
    realized that our model’s performance plummeted because a bug in our pipeline
    caused a feature to become NaNs (short for “not a number”).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一种是*特征变化*，例如添加新特征、删除旧特征或更改特征可能值的集合。^([28](ch08.xhtml#ch01fn276)) 例如，您的模型曾使用“年龄”特征的年份，但现在使用月份，因此该特征值的范围已发生漂移。有一次，我们的团队意识到，由于管道中的错误导致特征变成了
    NaNs（“非数字”）而导致模型性能急剧下降。
- en: '*Label schema change* is when the set of possible values for *Y* change. With
    label shift, *P*(*Y*) changes but *P*(*X*|*Y*) remains the same. With label schema
    change, both *P*(*Y*) and *P*(*X*|*Y*) change. A schema describes the structure
    of the data, so the label schema of a task describes the structure of the labels
    of that task. For example, a dictionary that maps from a class to an integer value,
    such as `{“POSITIVE”: 0, “NEGATIVE”: 1}`, is a schema.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*标签架构变化* 是指 *Y* 的可能值集合发生变化。与标签偏移不同，*P*(*Y*) 变化但 *P*(*X*|*Y*) 保持不变。标签架构变化则是
    *P*(*Y*) 和 *P*(*X*|*Y*) 都发生变化。架构描述数据的结构，因此任务的标签架构描述该任务标签的结构。例如，将类映射到整数值的字典，如 `{“正面”:
    0, “负面”: 1}`，就是一个架构。'
- en: With regression tasks, label schema change could happen because of changes in
    the possible range of label values. Imagine you’re building a model to predict
    someone’s credit score. Originally, you used a credit score system that ranged
    from 300 to 850, but you switched to a new system that ranges from 250 to 900.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归任务，标签架构变化可能是因为标签值的可能范围发生了变化。想象一下，您正在建立一个预测某人信用评分的模型。最初，您使用的信用评分系统范围从300到850，但后来切换到一个范围从250到900的新系统。
- en: 'With classification tasks, label schema change could happen because you have
    new classes. For example, suppose you are building a model to diagnose diseases
    and there’s a new disease to diagnose. Classes can also become outdated or more
    fine-grained. Imagine that you’re in charge of a sentiment analysis model for
    tweets that mention your brand. Originally, your model predicted only three classes:
    POSITIVE, NEGATIVE, and NEUTRAL. However, your marketing department realized the
    most damaging tweets are the angry ones, so they wanted to break the NEGATIVE
    class into two classes: SAD and ANGRY. Instead of having three classes, your task
    now has four classes. When the number of classes changes, your model’s structure
    might change,^([29](ch08.xhtml#ch01fn277)) and you might need to both relabel
    your data and retrain your model from scratch. Label schema change is especially
    common with high-cardinality tasks—tasks with a high number of classes—such as
    product or documentation categorization.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类任务中，标签架构的变化可能是因为出现了新的类别。例如，假设您正在建立一个诊断疾病的模型，出现了一种新的需要诊断的疾病。类别还可以变得过时或更加精细。想象一下，您负责的情感分析模型用于分析提及您品牌的推文。最初，您的模型仅预测三种类别：正面、负面和中性。然而，您的市场部门意识到最有害的推文是愤怒的推文，因此他们希望将负面类别细分为两个类别：悲伤和愤怒。现在，您的任务不再有三个类别，而是四个类别。当类别数量发生变化时，您的模型结构可能会发生变化，^([29](ch08.xhtml#ch01fn277))
    您可能需要重新标记数据并从头开始训练模型。标签架构的变化在高基数任务中特别常见——即类别数量较多的任务，例如产品或文档分类。
- en: There’s no rule that says that only one type of shift should happen at one time.
    A model might suffer from multiple types of drift, which makes handling them a
    lot more difficult.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 没有规定只能同时发生一种类型的偏移。一个模型可能受到多种类型漂移的影响，这使得处理它们变得更加困难。
- en: Detecting Data Distribution Shifts
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测数据分布偏移
- en: Data distribution shifts are only a problem if they cause your model’s performance
    to degrade. So the first idea might be to monitor your model’s accuracy-related
    metrics—accuracy, F1 score, recall, AUC-ROC, etc.—in production to see whether
    they have changed. “Change” here usually means “decrease,” but if my model’s accuracy
    suddenly goes up or fluctuates significantly for no reason that I’m aware of,
    I’d want to investigate.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分布偏移只有在导致模型性能下降时才是问题。因此，第一个想法可能是在生产环境中监控模型的准确度相关指标——准确率、F1 分数、召回率、AUC-ROC
    等——以查看它们是否发生了变化。“变化” 这里通常意味着“减少”，但如果我的模型准确率突然提高或者因我不知道的原因而显著波动，我会想要进行调查。
- en: Accuracy-related metrics work by comparing the model’s predictions to ground
    truth labels.^([30](ch08.xhtml#ch01fn278)) During model development, you have
    access to labels, but in production, you don’t always have access to labels, and
    even if you do, labels will be delayed, as discussed in the section [“Natural
    Labels”](ch04.xhtml#natural_labels). Having access to labels within a reasonable
    time window will vastly help with giving you visibility into your model’s performance.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 与准确性相关的指标通过将模型的预测与地面真实标签进行比较来工作。^([30](ch08.xhtml#ch01fn278)) 在模型开发过程中，您可以访问标签，但在生产中，您并不总是可以访问标签，即使可以，标签也会延迟，正如在“自然标签”部分中讨论的那样。在合理的时间窗口内获取标签将极大地帮助您了解模型的性能。
- en: When ground truth labels are unavailable or too delayed to be useful, we can
    monitor other distributions of interest instead. The distributions of interest
    are the input distribution *P*(*X*), the label distribution *P*(*Y*), and the
    conditional distributions *P*(*X*|*Y*) and *P*(*Y*|*X*).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当无法获得或者地面真相标签延迟过长以至于无法使用时，我们可以监控其他感兴趣的分布。感兴趣的分布包括输入分布*P*(*X*)、标签分布*P*(*Y*)以及条件分布*P*(*X*|*Y*)和*P*(*Y*|*X*)。
- en: While we don’t need to know the ground truth labels *Y* to monitor the input
    distribution, monitoring the label distribution and both of the conditional distributions
    require knowing *Y*. In research, there have been efforts to understand and detect
    label shifts without labels from the target distribution. One such effort is [Black
    Box Shift Estimation](https://oreil.ly/4rKh7) by Lipton et al. (2018). However,
    in the industry, most drift detection methods focus on detecting changes in the
    input distribution, especially the distributions of features, as we discuss in
    detail in this chapter.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们不需要知道地面真实标签*Y*来监控输入分布，但是监控标签分布以及两个条件分布都需要知道*Y*。在研究中，已经有努力理解和检测没有目标分布标签的标签偏移。Lipton等人（2018年）的一项努力是[黑盒偏移估计](https://oreil.ly/4rKh7)。然而，在工业界，大多数漂移检测方法集中于检测输入分布的变化，特别是特征的分布，正如我们在本章中详细讨论的那样。
- en: Statistical methods
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 统计方法
- en: In industry, a simple method many companies use to detect whether the two distributions
    are the same is to compare their statistics like min, max, mean, median, variance,
    various quantiles (such as 5th, 25th, 75th, or 95th quantile), skewness, kurtosis,
    etc. For example, you can compute the median and variance of the values of a feature
    during inference and compare them to the metrics computed during training. As
    of October 2021, even [TensorFlow Extended’s built-in data validation tools](https://oreil.ly/knwm0)
    use only summary statistics to detect the skew between the training and serving
    data and shifts between different days of training data. This is a good start,
    but these metrics are far from sufficient.^([31](ch08.xhtml#ch01fn279)) Mean,
    median, and variance are only useful with the distributions for which the mean/median/variance
    are useful summaries. If those metrics differ significantly, the inference distribution
    might have shifted from the training distribution. However, if those metrics are
    similar, there’s no guarantee that there’s no shift.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在工业界，许多公司用于检测两个分布是否相同的简单方法是比较它们的统计数据，如最小值、最大值、均值、中位数、方差、各种分位数（如5th、25th、75th或95th分位数）、偏度、峰度等。例如，您可以计算推断过程中某个特征的中位数和方差，并将其与训练过程中计算的指标进行比较。截至2021年10月，即使[TensorFlow
    Extended内置的数据验证工具](https://oreil.ly/knwm0)也仅使用汇总统计数据来检测训练和服务数据之间的偏差，以及不同训练数据日期之间的变化。这是一个很好的起点，但是这些指标远远不足以满足需求。^([31](ch08.xhtml#ch01fn279))
    均值、中位数和方差只对均值/中位数/方差为有效总结的分布有用。如果这些指标存在显著差异，则推断分布可能已从训练分布中偏移。然而，如果这些指标相似，则不能保证没有偏移。
- en: A more sophisticated solution is to use a two-sample hypothesis test, shortened
    as two-sample test. It’s a test to determine whether the difference between two
    populations (two sets of data) is statistically significant. If the difference
    is statistically significant, then the probability that the difference is a random
    fluctuation due to sampling variability is very low, and, therefore, the difference
    is caused by the fact that these two populations come from two distinct distributions.
    If you consider the data from yesterday to be the source population and the data
    from today to be the target population and they are statistically different, it’s
    likely that the underlying data distribution has shifted between yesterday and
    today.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的解决方案是使用双样本假设检验，简称双样本检验。它是一种测试方法，用于确定两个总体（两组数据）之间的差异是否在统计上显著。如果差异在统计上显著，则说明这两个总体来自于两个不同的分布，而不是因为采样变异性导致的随机波动。如果你将昨天的数据视为源总体，今天的数据视为目标总体，并且它们在统计上是不同的，那么显然昨天和今天之间的数据分布已经发生了变化。
- en: A caveat is that just because the difference is statistically significant doesn’t
    mean that it is practically important. However, a good heuristic is that if you
    are able to detect the difference from a relatively small sample, then it is probably
    a serious difference. If it takes a huge number of samples to detect, then the
    difference is probably not worth worrying about.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一个警告是，仅仅因为差异在统计上是显著的，并不意味着它在实际中很重要。然而，一个很好的经验法则是，如果你能从一个相对小的样本中检测到差异，那么这个差异可能是严重的。如果需要大量样本才能检测到差异，那么这个差异可能不值得担忧。
- en: A basic two-sample test is the Kolmogorov–Smirnov test, also known as the K-S
    or KS test.^([32](ch08.xhtml#ch01fn280)) It’s a nonparametric statistical test,
    which means it doesn’t require any parameters of the underlying distribution to
    work. It doesn’t make any assumption about the underlying distribution, which
    means it can work for any distribution. However, one major drawback of the KS
    test is that it can only be used for one-dimensional data. If your model’s predictions
    and labels are one-dimensional (scalar numbers), then the KS test is useful to
    detect label or prediction shifts. However, it won’t work for high-dimensional
    data, and features are usually high-dimensional.^([33](ch08.xhtml#ch01fn281))
    KS tests can also be expensive and produce too many false positive alerts.^([34](ch08.xhtml#ch01fn282))
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的双样本测试是科尔莫哥洛夫-斯米尔诺夫（Kolmogorov–Smirnov）检验，也被称为K-S或KS检验。[^32] 它是一种非参数统计检验，这意味着它不需要任何基础分布的参数即可工作。它不对基础分布做任何假设，这意味着它可以适用于任何分布。然而，KS检验的一个主要缺点是它只能用于一维数据。如果你的模型预测和标签是一维的（标量数字），那么KS检验对于检测标签或预测的变化是有用的。然而，对于高维数据，它将不起作用，而特征通常是高维的。[^33]
    KS检验可能也会很昂贵，并产生过多的假阳性警报。[^34]
- en: Another test is Least-Squares Density Difference, an algorithm that is based
    on the least squares density-difference estimation method.^([35](ch08.xhtml#ch01fn283))
    There is also MMD, [Maximum Mean Discrepancy](https://oreil.ly/KzUuw) (Gretton
    et al. 2012), a kernel-based technique for multivariate two-sample testing and
    its variant [Learned Kernel MMD](https://oreil.ly/C5dXI) (Liu et al. 2020). MMD
    is popular in research, but as of writing this book, I’m not aware of any company
    that is using it in the industry. [Alibi Detect](https://oreil.ly/162tf) is a
    great open source package with the implementations of many drift detection algorithms,
    as shown in [Figure 8-2](#some_drift_detection_algorithms_impleme).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个测试是最小二乘密度差异（Least-Squares Density Difference），这是一种基于最小二乘密度差异估计方法的算法。[^35]
    还有MMD（Maximum Mean Discrepancy，最大均值差异），是一种基于核的多变量双样本测试技术及其变体“学习核MMD”（Liu等人，2020）。MMD在研究中很受欢迎，但截至撰写本书时，我不知道有任何公司在工业中使用它。[Alibi
    Detect](https://oreil.ly/162tf)是一个优秀的开源软件包，其中包含许多漂移检测算法的实现，如图8-2所示。[^35]
- en: Because two-sample tests often work better on low-dimensional data than on high-dimensional
    data, it’s highly recommended that you reduce the dimensionality of your data
    before performing a two-sample test on it.^([36](ch08.xhtml#ch01fn284))
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因为双样本测试在低维数据上的表现往往比在高维数据上好得多，强烈建议在对数据进行双样本测试之前，先降低数据的维度。[^36]
- en: '![](Images/dmls_0802.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0802.png)'
- en: 'Figure 8-2\. Some drift detection algorithms implemented by [Alibi Detect](https://oreil.ly/162tf).
    Source: Screenshot of the project’s GitHub repository'
  id: totrans-122
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 8-2\. [Alibi Detect](https://oreil.ly/162tf) 实现的一些漂移检测算法。来源：项目的 GitHub
    仓库的截图
- en: Time scale windows for detecting shifts
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用于检测转变的时间尺度窗口
- en: 'Not all types of shifts are equal—some are harder to detect than others. For
    example, shifts happen at different rates, and abrupt changes are easier to detect
    than slow, gradual changes.^([37](ch08.xhtml#ch01fn285)) Shifts can also happen
    across two dimensions: spatial or temporal. Spatial shifts are shifts that happen
    across access points, such as your application gets a new group of users or your
    application is now served on a different type of device. Temporal shifts are shifts
    that happen over time. To detect temporal shifts, a common approach is to treat
    input data to ML applications as time-series data.^([38](ch08.xhtml#ch01fn286))'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 不是所有类型的转变都相同 —— 有些比其他的更难检测。例如，转变发生的速率不同，突然变化比缓慢、逐渐的变化更容易检测到。^([37](ch08.xhtml#ch01fn285))
    转变也可以发生在两个维度上：空间或时间。空间转变是指跨越访问点发生的转变，比如你的应用程序获得了一群新用户或你的应用程序现在在不同类型的设备上提供服务。时间转变是随时间发生的转变。要检测时间转变，一种常见的方法是将输入数据处理为时间序列数据。^([38](ch08.xhtml#ch01fn286))
- en: When dealing with temporal shifts, the time scale window of the data we look
    at affects the shifts we can detect. If your data has a weekly cycle, then a time
    scale of less than a week won’t detect the cycle. Consider the data in [Figure 8-3](#whether_a_distribution_has_drifted_over).
    If we use data from day 9 to day 14 as the source distribution, then day 15 looks
    like a shift. However, if we use data from day 1 to day 14 as the source distribution,
    then all data points from day 15 are likely being generated by that same distribution.
    As illustrated by this example, detecting temporal shifts is hard when shifts
    are confounded by seasonal variation.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 处理时间转变时，我们查看的数据的时间尺度窗口影响我们能够检测到的转变。如果您的数据具有每周循环，那么小于一周的时间尺度将无法检测到该周期。考虑[Figure 8-3](#whether_a_distribution_has_drifted_over)
    中的数据。如果我们使用从第9天到第14天的数据作为源分布，则第15天看起来像是一个转变。然而，如果我们使用从第1天到第14天的数据作为源分布，则第15天的所有数据点可能都是由同一分布生成的。正如这个例子所说明的那样，当转变被季节性变化所混淆时，检测时间转变是困难的。
- en: '![](Images/dmls_0803.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0803.png)'
- en: Figure 8-3\. Whether a distribution has drifted over time depends on the time
    scale window specified
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 8-3\. 随时间分布是否漂移取决于指定的时间尺度窗口
- en: When computing running statistics over time, it’s important to differentiate
    between *cumulative and sliding statistics*. Sliding statistics are computed within
    a single time scale window, e.g., an hour. Cumulative statistics are continually
    updated with more data. This means, for the beginning of each time scale window,
    the sliding accuracy is reset, whereas the cumulative sliding accuracy is not.
    Because cumulative statistics contain information from previous time windows,
    they might obscure what happens in a specific time window. [Figure 8-4](#cumulative_accuracy_hides_the_sudden_di)
    shows an example of how cumulative accuracy can hide the sudden dip in accuracy
    between hours 16 and 18.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算时间上的运行统计数据时，区分*累积和滑动统计*是很重要的。滑动统计是在单个时间尺度窗口内计算的，例如一个小时。累积统计则随着更多数据不断更新。这意味着，每个时间尺度窗口的开始，滑动准确性会被重置，而累积滑动准确性则不会。因为累积统计包含了前几个时间窗口的信息，它可能会掩盖特定时间窗口内发生的情况。[Figure 8-4](#cumulative_accuracy_hides_the_sudden_di)
    展示了累积准确性如何掩盖在第16小时到第18小时之间的突然准确性下降的例子。
- en: '![](Images/dmls_0804.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0804.png)'
- en: 'Figure 8-4\. Cumulative accuracy hides the sudden dip in accuracy between hours
    16 and 18\. Source: Adapted from an image by [MadeWithML](https://oreil.ly/viegx)'
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 8-4\. 累积准确性掩盖了在第16小时到第18小时之间的突然准确性下降。来源：根据[MadeWithML](https://oreil.ly/viegx)的一幅图片修改而成
- en: Working with data in the temporal space makes things so much more complicated,
    requiring knowledge of time-series analysis techniques such as time-series decompositions
    that are beyond the scope of this book. For readers interested in time-series
    decomposition, Lyft engineering has [a great case study](https://oreil.ly/zi1kk)
    on how they decompose their time-series data to deal with the seasonality of the
    market.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间空间中处理数据使得事情变得更加复杂，需要了解时间序列分析技术，如超出本书范围的时间序列分解。对于对时间序列分解感兴趣的读者，Lyft 工程团队有一个[很好的案例研究](https://oreil.ly/zi1kk)，展示了他们如何分解时间序列数据以应对市场的季节性。
- en: As of today, many companies use the distribution of the training data as the
    base distribution and monitor the production data distribution at a certain granularity
    level, such as hourly and daily.^([39](ch08.xhtml#ch01fn287)) The shorter your
    time scale window, the faster you’ll be able to detect changes in your data distribution.
    However, too short a time scale window can lead to false alarms of shifts, like
    the example in [Figure 8-3](#whether_a_distribution_has_drifted_over).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，许多公司使用训练数据的分布作为基础分布，并以每小时和每日等特定粒度监控生产数据的分布。^([39](ch08.xhtml#ch01fn287))
    时间窗口越短，就能越快地检测到数据分布的变化。然而，时间窗口过短可能导致像[图 8-3](#whether_a_distribution_has_drifted_over)中的例子那样，误报偏移。
- en: Some platforms, especially those dealing with real-time data analytics such
    as monitoring, provide a merge operation that allows merging statistics from shorter
    time scale windows to create statistics for larger time scale windows. For example,
    you can compute the data statistics you care about hourly, then merge these hourly
    statistics chunks into daily views.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一些平台，特别是那些处理实时数据分析的平台，提供了合并操作，允许合并来自较短时间窗口的统计数据，以创建较大时间窗口的统计数据。例如，您可以按小时计算您关心的数据统计，然后将这些小时统计数据块合并为每日视图。
- en: More advanced monitoring platforms even attempt a root cause analysis (RCA)
    feature that automatically analyzes statistics across various time window sizes
    to detect exactly the time window where a change in data happened.^([40](ch08.xhtml#ch01fn288))
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 更先进的监控平台甚至尝试实现根本原因分析（RCA）功能，该功能自动分析各种时间窗口大小的统计数据，以便精确定位数据发生变化的时间窗口。^([40](ch08.xhtml#ch01fn288))
- en: Addressing Data Distribution Shifts
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理数据分布变化
- en: How companies address data shifts depends on how sophisticated their ML infrastructure
    setups are. At one end of the spectrum, we have companies that have just started
    with ML and are still working on getting ML models into production, so they might
    not have gotten to the point where data shifts are catastrophic to them. However,
    at some point in the future—maybe three months, maybe six months—they might realize
    that their initial deployed models have degraded to the point that they do more
    harm than good. They will then need to adapt their models to the shifted distributions
    or to replace them with other solutions.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 公司如何处理数据偏移取决于其机器学习基础设施设置的复杂程度。在光谱的一端，我们有一些刚刚开始使用机器学习的公司，仍在努力将机器学习模型投入生产，因此他们可能尚未遇到数据偏移对他们造成灾难性影响的程度。然而，在未来的某个时刻——也许是三个月，也许是六个月——他们可能会意识到，他们最初部署的模型已经降级到比有益更为有害的地步。然后，他们将需要调整他们的模型以适应变化的分布，或者用其他解决方案替换它们。
- en: At the same time, many companies assume that data shifts are inevitable, so
    they periodically retrain their models—once a month, once a week, or once a day—regardless
    of the extent of the shift. How to determine the optimal frequency to retrain
    your models is an important decision that many companies still determine based
    on gut feelings instead of experimental data.^([41](ch08.xhtml#ch01fn289)) We’ll
    discuss more about the retraining frequency in [Chapter 9](ch09.xhtml#continual_learning_and_test_in_producti).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，许多公司认为数据偏移是不可避免的，因此他们定期重新训练他们的模型——每月一次，每周一次或每天一次——无论偏移程度如何。如何确定重新训练模型的最佳频率是一项重要决策，许多公司仍然基于直觉而不是实验数据来确定。^([41](ch08.xhtml#ch01fn289))
    我们将在[第9章](ch09.xhtml#continual_learning_and_test_in_producti)中更详细地讨论重新训练频率。
- en: 'To make a model work with a new distribution in production, there are three
    main approaches. The first is the approach that currently dominates research:
    train models using massive datasets. The hope here is that if the training dataset
    is large enough, the model will be able to learn such a comprehensive distribution
    that whatever data points the model will encounter in production will likely come
    from this distribution.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要使模型能够在生产环境中适应新的分布，有三种主要方法。第一种方法是目前主导研究的方法：使用大规模数据集训练模型。希望在这里的是，如果训练数据集足够大，模型将能够学习到如此全面的分布，以至于模型在生产中遇到的任何数据点可能都来自这个分布。
- en: 'The second approach, less popular in research, is to adapt a trained model
    to a target distribution *without requiring new labels*. Zhang et al. (2013) used
    causal interpretations together with kernel embedding of conditional and marginal
    distributions to correct models’ predictions for both covariate shifts and label
    shifts without using labels from the target distribution.^([42](ch08.xhtml#ch01fn290))
    Similarly, Zhao et al. (2020) proposed domain-invariant representation learning:
    an unsupervised domain adaptation technique that can learn data representations
    invariant to changing distributions.^([43](ch08.xhtml#ch01fn291)) However, this
    area of research is heavily underexplored and hasn’t found wide adoption in industry.^([44](ch08.xhtml#ch01fn292))'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法，在研究中不太流行，是将训练好的模型调整到目标分布*而无需新的标签*。张等人（2013年）使用因果解释以及条件和边缘分布的核嵌入，来纠正模型对协变量转移和标签转移的预测，而不使用目标分布的标签。类似地，赵等人（2020年）提出了领域不变表示学习：一种无监督领域适应技术，可以学习对变化分布不变的数据表示。然而，这一研究领域深度未被探索，并未在工业界广泛应用。^([44](ch08.xhtml#ch01fn292))
- en: 'The third approach is what is usually done in the industry today: retrain your
    model using the labeled data from the target distribution. However, retraining
    your model is not so straightforward. Retraining can mean retraining your model
    from scratch on both the old and new data or continuing training the existing
    model on new data. The latter approach is also called fine-tuning.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种方法是当今工业界通常采用的方法：使用目标分布的标记数据重新训练您的模型。然而，重新训练模型并不那么简单。重新训练可能意味着从头开始重新训练模型，使用旧数据和新数据，或者在新数据上继续训练现有模型。后一种方法也称为微调。
- en: 'If you want to retrain your model, there are two questions. First, whether
    to train your model from scratch (stateless retraining) or continue training it
    from the last checkpoint (stateful training). Second, what data to use: data from
    the last 24 hours, last week, last 6 months, or from the point when data has started
    to drift. You might need to run experiments to figure out which retraining strategy
    works best for you.^([45](ch08.xhtml#ch01fn293))'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望重新训练您的模型，有两个问题需要考虑。首先，是否从头开始训练模型（无状态重新训练）还是继续从上一个检查点训练模型（有状态训练）。其次，使用哪些数据：最近24小时的数据，最近一周的数据，最近6个月的数据，或者从数据开始漂移的时间点开始的数据。您可能需要进行实验以找出哪种重新训练策略对您最有效。^([45](ch08.xhtml#ch01fn293))
- en: In this book, we use “retraining” to refer to both training from scratch and
    fine-tuning. We’ll discuss more about retraining strategy in the next chapter.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们使用“重新训练”来指代从头开始训练和微调两者。我们将在下一章节详细讨论重新训练策略。
- en: Readers familiar with data shift literature might often see data shifts mentioned
    along with domain adaptation and transfer learning. If you consider a distribution
    to be a domain, then the question of how to adapt your model to new distributions
    is similar to the question of how to adapt your model to different domains.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉数据转移文献的读者经常会看到数据转移与领域适应和迁移学习一同提及。如果您将分布视为一个领域，那么如何将您的模型调整到新的分布的问题类似于如何将您的模型适应不同领域的问题。
- en: Similarly, if you consider learning a joint distribution *P*(*X*, *Y*) as a
    task, then adapting a model trained on one joint distribution for another joint
    distribution can be framed as a form of transfer learning. As discussed in [Chapter 4](ch04.xhtml#training_data),
    transfer learning refers to the family of methods where a model developed for
    a task is reused as the starting point for a model on a second task. The difference
    is that with transfer learning, you don’t retrain the base model from scratch
    for the second task. However, to adapt your model to a new distribution, you might
    need to retrain your model from scratch.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，如果您考虑学习联合分布*P*(*X*, *Y*)作为一项任务，那么将一个在一个联合分布上训练的模型调整到另一个联合分布上可以被视为一种迁移学习形式。正如在[第四章](ch04.xhtml#training_data)中讨论的那样，迁移学习是指一系列方法，其中为一个任务开发的模型被重复使用作为第二个任务模型的起点。不同之处在于，使用迁移学习时，您不会从头开始为第二个任务重新训练基础模型。然而，要使您的模型适应新的分布，可能需要从头开始重新训练您的模型。
- en: 'Addressing data distribution shifts doesn’t have to start after the shifts
    have happened. It’s possible to design your system to make it more robust to shifts.
    A system uses multiple features, and different features shift at different rates.
    Consider that you’re building a model to predict whether a user will download
    an app. You might be tempted to use that app’s ranking in the app store as a feature
    since higher-ranking apps tend to be downloaded more. However, app ranking changes
    very quickly. You might want to instead bucket each app’s ranking into general
    categories such as top 10, between 11 and 100, between 101 and 1,000, between
    1,001 and 10,000, and so on. At the same time, an app’s categories might change
    a lot less frequently, but they might have less power to predict whether a user
    will download that app. When choosing features for your models, you might want
    to consider the trade-off between the performance and the stability of a feature:
    a feature might be really good for accuracy but deteriorate quickly, forcing you
    to train your model more often.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 处理数据分布的变化并不一定要在变化发生后才开始。可以设计系统使其更能抵抗变化。系统使用多个特征，不同的特征变化速度不同。考虑你正在构建一个模型来预测用户是否会下载一个应用程序。你可能会想要使用该应用在应用商店中的排名作为一个特征，因为排名较高的应用程序往往会被下载更多。然而，应用程序的排名变化非常快。你可能希望将每个应用程序的排名分为通用类别，例如前10名，11至100名，101至1,000名，1,001至10,000名等。同时，应用程序的类别可能变化的频率要低得多，但它们可能没有那么强的预测用户是否下载该应用的能力。在选择模型特征时，你可能需要考虑特征性能和稳定性之间的权衡：某个特征可能在准确性方面非常好，但却很快恶化，迫使你更频繁地训练模型。
- en: You might also want to design your system to make it easier for it to adapt
    to shifts. For example, housing prices might change a lot faster in major cities
    like San Francisco than in rural Arizona, so a housing price prediction model
    serving rural Arizona might need to be updated less frequently than a model serving
    San Francisco. If you use the same model to serve both markets, you’ll have to
    use data from both markets to update your model at the rate demanded by San Francisco.
    However, if you use a separate model for each market, you can update each of them
    only when necessary.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还想设计你的系统，使其更容易适应变化。例如，像旧金山这样的大城市的房价可能会比亚利桑那州的农村地区变化得更快，因此为亚利桑那州农村地区提供服务的房价预测模型可能需要更新频率较低，而为旧金山提供服务的模型可能需要更频繁地更新。如果你使用同一个模型来服务这两个市场，你将不得不使用来自两个市场的数据来按照旧金山的要求更新模型。然而，如果你为每个市场使用单独的模型，你可以只在必要时更新它们。
- en: Before we move on to the next section, I want to reiterate that not all performance
    degradation of models in production requires ML solutions. Many ML failures today
    are still caused by human errors. If your model failure is caused by human errors,
    you’d first need to find those errors to fix them. Detecting a data shift is hard,
    but determining what causes a shift can be even harder.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入下一节之前，我想再次强调，不是所有在生产中模型性能下降的情况都需要机器学习的解决方案。今天许多机器学习的失败仍然是由人为错误造成的。如果你的模型失败是由人为错误造成的，你首先需要找出这些错误并修复它们。检测数据变化是困难的，但确定是什么导致了变化可能更加困难。
- en: Monitoring and Observability
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控和可观察性
- en: As the industry realized that many things can go wrong with an ML system, many
    companies started investing in monitoring and observability for their ML systems
    in production.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 随着行业意识到机器学习系统可能出现许多问题，许多公司开始投资于监控和观察他们生产中的机器学习系统。
- en: Monitoring and observability are sometimes used exchangeably, but they are different.
    Monitoring refers to the act of tracking, measuring, and logging different metrics
    that can help us determine when something goes wrong. Observability means setting
    up our system in a way that gives us visibility into our system to help us investigate
    what went wrong. The process of setting up our system in this way is also called
    “instrumentation.” Examples of instrumentation are adding timers to your functions,
    counting NaNs in your features, tracking how inputs are transformed through your
    systems, logging unusual events such as unusually long inputs, etc. Observability
    is part of monitoring. Without some level of observability, monitoring is impossible.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 监控和可观测性有时候被交换使用，但它们是不同的。监控是指追踪、测量和记录不同的指标，这些指标可以帮助我们确定何时出现问题。可观测性意味着设置系统，使我们能够看到系统内部，帮助我们调查出现了什么问题。以这种方式设置系统的过程也称为“仪表化”。例如，将计时器添加到函数中、计算特征中的
    NaN 数量、跟踪输入如何通过系统转换、记录异常事件（例如异常长的输入）等都是仪表化的示例。可观测性是监控的一部分。没有一定程度的可观测性，监控是不可能的。
- en: 'Monitoring is all about metrics. Because ML systems are software systems, the
    first class of metrics you’d need to monitor are the operational metrics. These
    metrics are designed to convey the health of your systems. They are generally
    divided into three levels: the network the system is run on, the machine the system
    is run on, and the application that the system runs. Examples of these metrics
    are latency; throughput; the number of prediction requests your model receives
    in the last minute, hour, day; the percentage of requests that return with a 2xx
    code; CPU/GPU utilization; memory utilization; etc. No matter how good your ML
    model is, if the system is down, you’re not going to benefit from it.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 监控关注的是指标。因为机器学习系统是软件系统，您需要监控的第一类指标是操作指标。这些指标旨在传达系统的健康状况。它们通常分为三个级别：运行系统的网络、运行系统的机器以及系统运行的应用程序。这些指标的例子包括延迟、吞吐量、模型在过去一分钟、一小时、一天接收到的预测请求数量，返回2xx代码的请求百分比、CPU/GPU利用率、内存利用率等。无论您的机器学习模型有多好，如果系统停机，您将无法从中受益。
- en: Let’s look at an example. One of the most important characteristics of a software
    system in production is availability—how often the system is available to offer
    reasonable performance to users. This characteristic is measured by *uptime*,
    the percentage of time a system is up. The conditions to determine whether a system
    is up are defined in the service level objectives (SLOs) or service level agreements
    (SLAs). For example, an SLA may specify that the service is considered to be up
    if it has a median latency of less than 200 ms and a 99th percentile under 2 s.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举个例子。生产中软件系统最重要的特性之一是可用性——系统能够为用户提供合理性能的时间。这个特性由*正常运行时间*来衡量，即系统正常运行的时间百分比。用于确定系统是否正常运行的条件被定义在服务水平目标（SLOs）或服务水平协议（SLAs）中。例如，SLA可以指定，如果服务的中位延迟小于200毫秒，99分位数小于2秒，则服务被认为是正常运行的。
- en: A service provider might offer an SLA that specifies their uptime guarantee,
    such as 99.99% of the time, and if this guarantee is not met, they’ll give their
    customers back money. For example, as of October 2021, AWS EC2 service offers
    a monthly uptime percentage of at least 99.99% (four nines), and if the monthly
    uptime percentage is lower than that, they’ll give you back a service credit toward
    future EC2 payments.^([46](ch08.xhtml#idm46868207424048)) A 99.99% monthly uptime
    means the service is only allowed to be down a little over 4 minutes a month,
    and 99.999% means only 26 seconds a month!
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 服务提供商可能会提供SLA，其中规定了他们的正常运行时间保证，例如99.99%的时间，如果未达到此保证，他们将向客户返还款项。例如，截至2021年10月，AWS
    EC2服务提供每月至少99.99%（四个九）的正常运行时间，如果月度正常运行时间低于此水平，他们将为您提供未来EC2付款的服务信用。99.99%的月度正常运行时间意味着服务每月只能停机超过4分钟，而99.999%意味着每月只能停机26秒！
- en: However, for ML systems, the system health extends beyond the system uptime.
    If your ML system is up but its predictions are garbage, your users aren’t going
    to be happy. Another class of metrics you’d want to monitor are ML-specific metrics
    that tell you the health of your ML models.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于机器学习系统来说，系统健康程度不仅限于系统的正常运行时间。如果您的机器学习系统运行正常但其预测结果是垃圾，用户是不会满意的。您还需要监控另一类指标，这些指标是专门用来告诉您机器学习模型健康状况的。
- en: ML-Specific Metrics
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习特定指标
- en: 'Within ML-specific metrics, there are generally four artifacts to monitor:
    a model’s accuracy-related metrics, predictions, features, and raw inputs. These
    are artifacts generated at four different stages of an ML system pipeline, as
    shown in [Figure 8-5](#the_more_transformations_an_artifact_ha). The deeper into
    the pipeline an artifact is, the more transformations it has gone through, which
    makes a change in that artifact more likely to be caused by errors in one of those
    transformations. However, the more transformations an artifact has gone through,
    the more structured it’s become and the closer it is to the metrics you actually
    care about, which makes it easier to monitor. We’ll look at each of these artifacts
    in detail in the following sections.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在特定于 ML 的指标中，通常有四种要监控的物件：模型的与准确性相关的指标、预测、特征和原始输入。这些是在 ML 系统管道的四个不同阶段生成的物件，如[图
    8-5](#the_more_transformations_an_artifact_ha)所示。物件在管道中的深度越深，经历的转换就越多，这使得物件中的变化更有可能是由其中一个转换中的错误引起的。然而，物件经历的转换越多，它变得越有结构化，越接近您实际关心的指标，这使得监控变得更容易。我们将在接下来的章节详细讨论每一个物件。
- en: '![](Images/dmls_0805.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0805.png)'
- en: Figure 8-5\. The more transformations an artifact has gone through, the more
    likely its changes are to be caused by errors in one of those transformations
  id: totrans-158
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-5\. 一个物件经历的转换越多，其变化由于这些转换中的错误引起的可能性就越大。
- en: Monitoring accuracy-related metrics
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控与准确性相关的指标
- en: If your system receives any type of user feedback for the predictions it makes—click,
    hide, purchase, upvote, downvote, favorite, bookmark, share, etc.—you should definitely
    log and track it. Some feedback can be used to infer natural labels, which can
    then be used to calculate your model’s accuracy-related metrics. Accuracy-related
    metrics are the most direct metrics to help you decide whether a model’s performance
    has degraded.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的系统接收任何类型的用户反馈来对其进行预测 - 点击、隐藏、购买、赞成、反对、收藏、标记、分享等 - 您应该记录并跟踪它。有些反馈可以用于推断自然标签，然后用于计算模型的与准确性相关的指标。与准确性相关的指标是帮助您确定模型性能是否下降的最直接指标。
- en: Even if the feedback can’t be used to infer natural labels directly, it can
    be used to detect changes in your ML model’s performance. For example, when you’re
    building a system to recommend to users what videos to watch next on YouTube,
    you want to track not only whether the users click on a recommended video (click-through
    rate), but also the duration of time users spend on that video and whether they
    complete watching it (completion rate). If, over time, the click-through rate
    remains the same but the completion rate drops, it might mean that your recommender
    system is getting worse.^([47](ch08.xhtml#ch01fn294))
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 即使反馈不能直接用于推断自然标签，它也可以用来检测您的 ML 模型性能的变化。例如，当您正在构建一个系统来推荐用户在 YouTube 上接下来观看什么视频时，您不仅希望跟踪用户是否点击推荐的视频（点击率），还希望跟踪用户观看该视频的时间以及是否观看完毕（完成率）。如果随着时间的推移，点击率保持不变，但完成率下降，这可能意味着您的推荐系统正在变得更糟。^([47](ch08.xhtml#ch01fn294))
- en: It’s also possible to engineer your system so that you can collect users’ feedback.
    For example, Google Translate has the option for users to upvote or downvote a
    translation, as shown in [Figure 8-6](#google_translate_allows_users_to_upvote).
    If the number of downvotes the system receives suddenly goes up, there might be
    issues. These downvotes can also be used to guide the labeling process, such as
    getting human experts to generate new translations for the samples with downvotes,
    to train the next iteration of their models.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以设计您的系统，以便收集用户的反馈。例如，Google 翻译允许用户对翻译进行赞成或反对，如[图 8-6](#google_translate_allows_users_to_upvote)所示。如果系统收到的反对票数突然增加，可能存在问题。这些反对票也可以用来指导标签过程，例如让人类专家为获得反对票的样本生成新的翻译，以训练他们模型的下一个迭代。
- en: '![](Images/dmls_0806.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0806.png)'
- en: Figure 8-6\. Google Translate allows users to upvote or downvote a translation.
    These votes will be used to evaluate their translation model’s quality as well
    as to guide the labeling process.
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-6\. Google 翻译允许用户对翻译进行赞成或反对。这些投票将用于评估其翻译模型的质量，并指导标签过程。
- en: Monitoring predictions
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控预测
- en: Prediction is the most common artifact to monitor. If it’s a regression task,
    each prediction is a continuous value (e.g., the predicted price of a house),
    and if it’s a classification task, each prediction is a discrete value corresponding
    to the predicted category. Because each prediction is usually just a number (low
    dimension), predictions are easy to visualize, and their summary statistics are
    straightforward to compute and interpret.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 预测是最常见的监视对象。如果是回归任务，每个预测是一个连续值（例如房屋的预测价格），如果是分类任务，每个预测是一个离散值，对应于预测的类别。因为每个预测通常只是一个数字（低维度），预测很容易可视化，并且它们的摘要统计量易于计算和解释。
- en: You can monitor predictions for distribution shifts. Because predictions are
    low dimensional, it’s also easier to compute two-sample tests to detect whether
    the prediction distribution has shifted. Prediction distribution shifts are also
    a proxy for input distribution shifts. Assuming that the function that maps from
    input to output doesn’t change—the weights and biases of your model haven’t changed—then
    a change in the prediction distribution generally indicates a change in the underlying
    input distribution.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以监控预测以检测分布变化。因为预测是低维的，所以更容易计算两样本检验，以检测预测分布是否发生了变化。预测分布的变化也是输入分布变化的代理。假设从输入到输出映射的函数没有改变——模型的权重和偏差没有改变——那么预测分布的变化通常表明底层输入分布发生了变化。
- en: You can also monitor predictions for anything odd happening, such as predicting
    an unusual number of False in a row. There could be a long delay between predictions
    and ground truth labels, as discussed in the section [“Natural Labels”](ch04.xhtml#natural_labels).
    Changes in accuracy-related metrics might not become obvious for days or weeks,
    whereas a model predicting all False for 10 minutes can be detected immediately.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以监控预测，以发现任何异常情况，例如连续预测异常数量的False。预测与地面实况标签之间可能存在长时间延迟，如第[“自然标签”](ch04.xhtml#natural_labels)节所述。准确率相关指标的变化可能需要几天甚至几周才能变得明显，而预测所有False持续10分钟的模型可以立即检测到。
- en: Monitoring features
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控特征
- en: 'ML monitoring solutions in the industry focus on tracking changes in features,
    both the features that a model uses as inputs and the intermediate transformations
    from raw inputs into final features. Feature monitoring is appealing because compared
    to raw input data, features are well structured following a predefined schema.
    The first step of feature monitoring is *feature validation*: ensuring that your
    features follow an expected schema. The expected schemas are usually generated
    from training data or from common sense. If these expectations are violated in
    production, there might be a shift in the underlying distribution. For example,
    here are some of the things you can check for a given feature:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 行业中的机器学习监控解决方案专注于跟踪特征的变化，包括模型用作输入的特征以及从原始输入到最终特征的中间转换。特征监控具有吸引力，因为与原始输入数据相比，特征遵循预定义模式结构化良好。特征监控的第一步是*特征验证*：确保您的特征符合预期的模式。预期的模式通常是从训练数据生成或从常识中获取的。如果这些期望在生产环境中被违反，可能会导致基础分布的变化。例如，对于给定特征，可以检查以下内容：
- en: If the min, max, or median values of a feature are within an acceptable range
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个特征的最小值、最大值或中位数在可接受范围内
- en: If the values of a feature satisfy a regular expression format
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个特征的值满足正则表达式格式
- en: If all the values of a feature belong to a predefined set
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个特征的所有值属于预定义集合
- en: If the values of a feature are always greater than the values of another feature
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个特征的值始终大于另一个特征的值
- en: Because features are often organized into tables—each column representing a
    feature and each row representing a data sample—feature validation is also known
    as table testing or table validation. Some call them unit tests for data. There
    are many open source libraries that help you do basic feature validation, and
    the two most common are [Great Expectations](https://oreil.ly/vBa35) and [Deequ](https://oreil.ly/OWoIB),
    which is by AWS. [Figure 8-7](#some_of_the_built_in_feature_validation) shows
    some of the built-in feature validation functions by Great Expectations and an
    example of how to use them.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 因为特征通常组织成表格——每列表示一个特征，每行表示一个数据样本——特征验证也称为表测试或表验证。有些人称其为数据的单元测试。有许多开源库可以帮助您进行基本的特征验证，其中最常见的两个是[Great
    Expectations](https://oreil.ly/vBa35)和[Deequ](https://oreil.ly/OWoIB)，后者是AWS开发的。[图 8-7](#some_of_the_built_in_feature_validation)显示了Great
    Expectations内置的一些特征验证函数及其使用示例。
- en: '![](Images/dmls_0807.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0807.png)'
- en: 'Figure 8-7\. Some of the built-in feature validation functions by Great Expectations
    and an example of how to use them. Source: Adapted from content in the Great Expectations
    GitHub repository'
  id: totrans-177
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-7\. 一些Great Expectations内置特征验证函数及其使用示例。来源：改编自Great Expectations GitHub存储库中的内容。
- en: Beyond basic feature validation, you can also use two-sample tests to detect
    whether the underlying distribution of a feature or a set of features has shifted.
    Since a feature or a set of features can be high-dimensional, you might need to
    reduce their dimension before performing the test on them, which can make the
    test less effective.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基本的特征验证之外，您还可以使用双样本检验来检测特征或一组特征的基础分布是否发生了变化。由于特征或一组特征可能是高维的，您可能需要在执行测试之前降低它们的维度，这可能会降低测试的有效性。
- en: 'There are four major concerns when doing feature monitoring:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行特征监控时有四个主要关注点：
- en: A company might have hundreds of models in production, and each model uses hundreds,
    if not thousands, of features.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 一家公司可能在生产中使用数百个模型，每个模型使用数百甚至数千个特征。
- en: Even something as simple as computing summary statistics for all these features
    every hour can be expensive, not only in terms of compute required but also memory
    used. Tracking, i.e., constantly computing, too many metrics can also slow down
    your system and increase both the latency that your users experience and the time
    it takes for you to detect anomalies in your system.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是每小时为所有这些特征计算汇总统计数据这样简单的事情也可能成本高昂，不仅计算资源要求高，而且内存使用也很大。跟踪，即不断计算太多的指标，还可能降低系统的速度，并增加用户体验的延迟以及检测系统异常所需的时间。
- en: While tracking features is useful for debugging purposes, it’s not very useful
    for detecting model performance degradation.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然跟踪特征对于调试目的很有用，但对于检测模型性能下降并不是非常有效。
- en: In theory, a small distribution shift can cause catastrophic failure, but in
    practice, an individual feature’s minor changes might not harm the model’s performance
    at all. Feature distributions shift all the time, and most of these changes are
    benign.^([48](ch08.xhtml#ch01fn295)) If you want to be alerted whenever a feature
    seems to have drifted, you might soon be overwhelmed by alerts and realize that
    most of these alerts are false positives. This can cause a phenomenon called “alert
    fatigue” where the monitoring team stops paying attention to the alerts because
    they are so frequent. The problem of feature monitoring becomes the problem of
    trying to decide which feature shifts are critical and which are not.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，小的分布变化可能导致灾难性故障，但实际上，单个特征的轻微变化可能根本不会影响模型的性能。特征分布随时都在变化，大多数这些变化都是良性的。^([48](ch08.xhtml#ch01fn295))
    如果您想在特征似乎漂移时接收警报，您可能很快就会被警报淹没，并意识到大多数这些警报都是误报。这可能导致一种称为“警报疲劳”的现象，监控团队停止关注警报，因为它们如此频繁。特征监控的问题变成了尝试确定哪些特征变化是关键的，哪些不是关键的问题。
- en: Feature extraction is often done in multiple steps (such as filling missing
    values and standardization), using multiple libraries (such as pandas, Spark),
    on multiple services (such as BigQuery or Snowflake).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提取通常是通过多个步骤进行的（例如填充缺失值和标准化），使用多个库（例如pandas、Spark），在多个服务中执行（例如BigQuery或Snowflake）。
- en: You might have a relational database as an input to the feature extraction process
    and a NumPy array as the output. Even if you detect a harmful change in a feature,
    it might be impossible to detect whether this change is caused by a change in
    the underlying input distribution or whether it’s caused by an error in one of
    the multiple processing steps.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会将关系数据库作为特征提取过程的输入，将NumPy数组作为输出。即使您检测到特征中的有害变化，也可能无法确定这种变化是由底层输入分布的变化引起的，还是由多个处理步骤中的错误引起的。
- en: The schema that your features follow can change over time.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 特征遵循的架构可能随时间改变。
- en: If you don’t have a way to version your schemas and map each of your features
    to its expected schema, the cause of the reported alert might be due to the mismatched
    schema rather than a change in the data.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有一种方法来对架构进行版本控制，并将每个特征映射到其预期的架构，那么报告的警报原因可能是由于架构不匹配而不是数据变化引起的。
- en: These concerns are not to dismiss the importance of feature monitoring; changes
    in the feature space are a useful source of signals to understand the health of
    your ML systems. Hopefully, thinking about these concerns can help you choose
    a feature monitoring solution that works for you.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这些关注点并不是为了忽视特征监控的重要性；特征空间的变化是理解ML系统健康的有用信号源。希望考虑到这些关注点可以帮助您选择适合您的特征监控解决方案。
- en: Monitoring raw inputs
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控原始输入
- en: As discussed in the previous section, a change in the features might be caused
    by problems in processing steps and not by changes in data. What if we monitor
    the raw inputs before they are processed? The raw input data might not be easier
    to monitor, as it can come from multiple sources in different formats, following
    multiple structures. The way many ML workflows are set up today also makes it
    impossible for ML engineers to get direct access to raw input data, as the raw
    input data is often managed by a data platform team who processes and moves the
    data to a location like a data warehouse, and the ML engineers can only query
    for data from that data warehouse where the data is already partially processed.
    Therefore, monitoring raw inputs is often a responsibility of the data platform
    team, not the data science or ML team. Therefore, it’s out of scope for this book.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前一节讨论的那样，特征的变化可能是由于处理步骤中的问题，而不是数据变化引起的。如果我们在数据处理之前监控原始输入会怎么样？然而，原始输入数据可能并不容易监控，因为它可以来自不同格式的多个来源，并且遵循多种结构。今天许多ML工作流的设置也使得ML工程师无法直接访问原始输入数据，因为原始输入数据通常由数据平台团队管理，他们处理并将数据移动到数据仓库等位置，而ML工程师只能从数据仓库查询数据，其中数据已经部分处理。因此，监控原始输入通常是数据平台团队的责任，而不是数据科学或ML团队的责任。因此，这本书不涵盖此范围。
- en: So far, we’ve discussed different types of metrics to monitor, from operational
    metrics generally used for software systems to ML-specific metrics that help you
    keep track of the health of your ML models. In the next section, we’ll discuss
    the toolbox you can use to help with metrics monitoring.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论了用于监控的不同类型的指标，从通常用于软件系统的运行指标到帮助您跟踪ML模型健康状况的ML特定指标。在下一节中，我们将讨论您可以使用的工具箱，以帮助进行指标监控。
- en: Monitoring Toolbox
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控工具箱
- en: 'Measuring, tracking, and interpreting metrics for complex systems is a nontrivial
    task, and engineers rely on a set of tools to help them do so. It’s common for
    the industry to herald metrics, logs, and traces as the three pillars of monitoring.
    However, I find their differentiations murky. They seem to be generated from the
    perspective of people who develop monitoring systems: traces are a form of logs
    and metrics can be computed from logs. In this section, I’d like to focus on the
    set of tools from the perspective of users of the monitoring systems: logs, dashboards,
    and alerts.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 测量、跟踪和解释复杂系统的指标是一项非常复杂的任务，工程师们依赖一套工具来帮助他们完成这些任务。行业通常将指标、日志和追踪视为监控的三大支柱。然而，我发现它们的区别并不清晰。它们似乎是从开发监控系统的人的角度生成的：追踪是日志的一种形式，指标可以从日志中计算得出。在这一节中，我想专注于从监控系统用户的角度看待的一组工具：日志、仪表板和警报。
- en: Logs
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 日志
- en: Traditional software systems rely on logs to record events produced at runtime.
    An event is anything that can be of interest to the system developers, either
    at the time the event happens or later for debugging and analysis purposes. Examples
    of events are when a container starts, the amount of memory it takes, when a function
    is called, when that function finishes running, the other functions that this
    function calls, the input and output of that function, etc. Also, don’t forget
    to log crashes, stack traces, error codes, and more. In the words of Ian Malpass
    at Etsy, “If it moves, we track it.”^([49](ch08.xhtml#ch01fn296)) They also track
    things that haven’t changed yet, in case they’ll move later.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 传统软件系统依赖于日志记录运行时产生的事件。一个事件是对系统开发者可能感兴趣的任何事情，无论是事件发生时还是以后用于调试和分析的目的。例如，容器启动时的事件，它所占用的内存量，函数调用的时间，函数运行结束的时间，该函数调用的其他函数，该函数的输入和输出等等。同时，不要忘记记录崩溃、堆栈跟踪、错误代码等等。用Ian
    Malpass在Etsy的话来说，“如果它有动静，我们都追踪。”^([49](ch08.xhtml#ch01fn296)) 他们也追踪那些尚未发生变化的东西，以防它们以后会有动静。
- en: The number of logs can grow very large very quickly. For example, back in 2019,
    the dating app Badoo was handling 20 billion events a day.^([50](ch08.xhtml#ch01fn297))
    When something goes wrong, you’ll need to query your logs for the sequence of
    events that caused it, a process that can feel like searching for a needle in
    a haystack.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 日志数量可能非常快速地增长。例如，早在2019年，约会应用Badoo每天处理200亿个事件。^([50](ch08.xhtml#ch01fn297))
    当发生问题时，您需要查询日志以查找导致问题的事件序列，这个过程就像在一堆草垛中搜索针一样。
- en: 'In the early days of software deployment, an application might be one single
    service. When something happened, you knew where that happened. But today, a system
    might consist of many different components: containers, schedulers, microservices,
    polyglot persistence, mesh routing, ephemeral auto-scaling instances, serverless
    Lambda functions. A request may do 20–30 hops from when it’s sent until when a
    response is received. The hard part might not be in detecting when something happened,
    but where the problem was.^([51](ch08.xhtml#ch01fn298))'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件部署的早期阶段，一个应用可能是一个单独的服务。发生问题时，您知道发生了什么。但是今天，一个系统可能由许多不同的组件组成：容器、调度器、微服务、多语言持久性、网格路由、短暂的自动扩展实例、无服务器
    Lambda 函数。一个请求可能需要经过 20-30 个跃点，从发送到接收响应。困难之处可能不在于检测何时发生了什么，而在于问题发生的位置。^([51](ch08.xhtml#ch01fn298))
- en: 'When we log an event, we want to make it as easy as possible for us to find
    it later. This practice with microservice architecture is called *distributed
    tracing*. We want to give each process a unique ID so that, when something goes
    wrong, the error message will (hopefully) contain that ID. This allows us to search
    for the log messages associated with it. We also want to record with each event
    all the metadata necessary: the time when it happens, the service where it happens,
    the function that is called, the user associated with the process, if any, etc.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们记录一个事件时，我们希望尽可能容易地找到它。在微服务架构中，这种实践被称为*分布式追踪*。我们希望为每个进程分配一个唯一的 ID，这样，当出现问题时，错误消息将（希望）包含该
    ID。这使我们能够搜索与之关联的日志消息。我们还希望记录每个事件所需的所有元数据：发生时间、发生的服务、调用的函数、与进程相关联的用户（如果有的话）等。
- en: Because logs have grown so large and so difficult to manage, there have been
    many tools developed to help companies manage and analyze logs. The log management
    market is estimated to be worth USD 2.3 billion in 2021, and it’s expected to
    grow to USD 4.1 billion by 2026.^([52](ch08.xhtml#ch01fn299))
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 由于日志变得如此庞大且难以管理，已经开发出许多工具来帮助公司管理和分析日志。2021 年，日志管理市场的价值估计为 23 亿美元，预计到 2026 年将增长到
    41 亿美元。^([52](ch08.xhtml#ch01fn299))
- en: 'Analyzing billions of logged events manually is futile, so many companies use
    ML to analyze logs. An example use case of ML in log analysis is anomaly detection:
    to detect abnormal events in your system. A more sophisticated model might even
    classify each event in terms of its priorities such as usual, abnormal, exception,
    error, and fatal.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 手动分析数十亿条日志事件是徒劳的，因此许多公司使用机器学习来分析日志。日志分析中机器学习的一个例子是异常检测：检测系统中的异常事件。更复杂的模型甚至可以根据其优先级（如常规、异常、异常、错误和致命）对每个事件进行分类。
- en: Another use case of ML in log analysis is that when a service fails, it might
    be helpful to know the probability of related services being affected. This could
    be especially useful when the system is under cyberattack.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 日志分析中机器学习的另一个用例是，当服务失败时，了解相关服务受到影响的可能性可能会很有帮助，尤其是在系统遭受网络攻击时。
- en: Many companies process logs in batch processes. In this scenario, you collect
    a large number of logs, then periodically query over them looking for specific
    events using SQL or process them using a batch process like in a Spark or Hadoop
    or Hive cluster. This makes the processing of logs efficient because you can leverage
    distributed and MapReduce processes to increase your processing throughput. However,
    because you process your logs periodically, you can only discover problems periodically.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 许多公司使用批处理方式处理日志。在这种场景中，您收集大量日志，然后定期使用 SQL 查询特定事件，或者使用类似于 Spark、Hadoop 或 Hive
    集群的批处理过程处理它们。这使得日志处理变得高效，因为您可以利用分布式和 MapReduce 过程来增加处理吞吐量。然而，由于您周期性地处理日志，您只能周期性地发现问题。
- en: To discover anomalies in your logs as soon as they happen, you want to process
    your events as soon as they are logged. This makes log processing a stream processing
    problem.^([53](ch08.xhtml#ch01fn300)) You can use real-time transport such as
    Kafka or Amazon Kinesis to transport events as they are logged. To search for
    events with specific characteristics in real time, you can leverage a streaming
    SQL engine like KSQL or Flink SQL.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 要在日志出现异常时尽快发现异常，您需要在日志记录时立即处理事件。这使得日志处理成为一个流处理问题。^([53](ch08.xhtml#ch01fn300))
    您可以使用实时传输，例如Kafka或Amazon Kinesis，以在日志记录时传输事件。要实时搜索具有特定特征的事件，您可以利用流式SQL引擎如KSQL或Flink
    SQL。
- en: Dashboards
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 仪表板
- en: A picture is worth a thousand words. A series of numbers might mean nothing
    to you, but visualizing them on a graph might reveal the relationships among these
    numbers. Dashboards to visualize metrics are critical for monitoring.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 一图胜过千言万语。一系列数字对您可能毫无意义，但在图表上可视化它们可能会揭示这些数字之间的关系。监控指标的仪表板对于监控至关重要。
- en: Another use of dashboards is to make monitoring accessible to nonengineers.
    Monitoring isn’t just for the developers of a system, but also for nonengineering
    stakeholders including product managers and business developers.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板的另一个用途是使监控对非工程师也可见。监控不仅仅是系统开发者的事情，还包括产品经理和业务开发者等非工程利益相关者。
- en: Even though graphs can help a lot with understanding metrics, they aren’t sufficient
    on their own. You still need experience and statistical knowledge. Consider the
    two graphs in [Figure 8-8](#graphs_are_useful_for_making_sense_of_n). The only
    thing that is obvious from these graphs is that the loss fluctuates a lot. If
    there’s a distribution shift in any of these two graphs, I can’t tell. It’s easier
    to plot a graph to draw a wiggling line than to understand what this wiggly line
    means.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管图表在理解指标方面有很大帮助，但它们本身并不足够。您仍然需要经验和统计知识。考虑图8-8中的两个图表。从这些图表中唯一显而易见的是损失波动很大。如果这两个图表中的任何一个出现分布变化，我无法判断。绘制一个图表来绘制一个波动的线比理解这条波动线意味着更容易。
- en: '![](Images/dmls_0808.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0808.png)'
- en: Figure 8-8\. Graphs are useful for making sense of numbers, but they aren’t
    sufficient
  id: totrans-209
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-8\. 图表对于理解数字很有帮助，但并不足够。
- en: Excessive metrics on a dashboard can also be counterproductive, a phenomenon
    known as *dashboard rot*. It’s important to pick the right metrics or abstract
    out lower-level metrics to compute higher-level signals that make better sense
    for your specific tasks.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板上过多的指标也可能产生反作用，这种现象被称为*仪表板腐化*。选择正确的指标或将低级指标抽象出来以计算更高级别的信号，这对于您的具体任务更有意义至关重要。
- en: Alerts
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 警报
- en: 'When our monitoring system detects something suspicious, it’s necessary to
    alert the right people about it. An alert consists of the following three components:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的监控系统检测到可疑情况时，有必要及时通知相关人员。警报由以下三个组件组成：
- en: An alert policy
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 警报策略
- en: This describes the condition for an alert. You might want to create an alert
    when a metric breaches a threshold, optionally over a certain duration. For example,
    you might want to be notified when a model’s accuracy is under 90%, or that the
    HTTP response latency is higher than a second for at least 10 minutes.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这描述了警报的条件。当度量指标超出阈值时，您可能希望创建警报，可选地在一定时间内超过某个持续时间。例如，您可能希望在模型准确率低于90%或HTTP响应延迟高于1秒至少10分钟时收到通知。
- en: Notification channels
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 通知渠道
- en: 'These describe who is to be notified when the condition is met. The alerts
    will be shown in the monitoring service you employ, such as Amazon CloudWatch
    or GCP Cloud Monitoring, but you also want to reach responsible people when they’re
    not on these monitoring services. For example, you might configure your alerts
    to be sent to an email address such as mlops-monitoring@*[your company email domain]*,
    or to post to a Slack channel such as #mlops-monitoring or to PagerDuty.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这些描述了在满足条件时应通知谁。警报将显示在您使用的监控服务中，例如Amazon CloudWatch或GCP Cloud Monitoring，但当他们不在这些监控服务上时，您还希望通知负责人员。例如，您可以配置警报发送到像mlops-monitoring@*[您的公司邮件域名]*这样的电子邮件地址，或者发布到Slack频道（如#mlops-monitoring）或PagerDuty。
- en: A description of the alert
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 警报的描述
- en: 'This helps the alerted person understand what’s going on. The description should
    be as detailed as possible, such as:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这有助于提醒相关人员了解当前情况。描述应尽可能详细，例如：
- en: '[PRE0]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Depending on the audience of the alert, it’s often necessary to make the alert
    actionable by providing mitigation instructions or a [runbook](https://oreil.ly/vgLR8),
    a compilation of routine procedures and operations that might help with handling
    the alert.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 根据警报的受众，通常需要通过提供缓解指南或一个[运行手册](https://oreil.ly/vgLR8)，这是一本编译了例行程序和操作的手册，可能有助于处理警报，来使警报具有可操作性。
- en: Alert fatigue is a real phenomenon, as discussed previously in this chapter.
    Alert fatigue can be demoralizing—nobody likes to be awakened in the middle of
    the night for something outside of their responsibilities. It’s also dangerous—being
    exposed to trivial alerts can desensitize people to critical alerts. It’s important
    to set meaningful conditions so that only critical alerts are sent out.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 警报疲劳是一个真实存在的现象，前面在本章中已经讨论过。警报疲劳可能会让人灰心丧气——没有人愿意因为责任范围之外的事情在半夜被吵醒。这也是危险的——暴露于琐碎的警报可能会使人对关键警报麻木不仁。因此，设置有意义的条件非常重要，以便只发送关键的警报。
- en: Observability
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可观察性
- en: Since the mid-2010s, the industry has started embracing the term “observability”
    instead of “monitoring.” Monitoring makes no assumption about the relationship
    between the internal state of a system and its outputs. You monitor the external
    outputs of the system to figure out *when* something goes wrong inside the system—there’s
    no guarantee that the external outputs will help you figure out *what* goes wrong.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 自2010年代中期以来，行业开始采纳“可观察性”这一术语，而不再使用“监控”。监控不对系统的内部状态与其输出之间的关系做任何假设。您监控系统的外部输出，以找出系统内部出了什么问题——外部输出并不能保证能帮助您找出问题所在。
- en: In the early days of software deployment, software systems were simple enough
    that monitoring external outputs was sufficient for software maintenance. A system
    used to consist of only a few components, and a team used to have control over
    the entire codebase. If something went wrong, it was possible to make changes
    to the system to test and figure out what went wrong.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件部署的早期阶段，软件系统足够简单，只需要监控外部输出就足以维护软件。一个系统只由几个组件组成，一个团队可以完全控制整个代码库。如果出了问题，可以对系统进行更改，进行测试并找出问题所在。
- en: However, software systems have grown significantly more complex over the last
    decade. Today, a software system consists of many components. Many of these components
    are services run by other companies—cue all cloud native services—which means
    that a team doesn’t even have control of the inside of all the components of their
    system. When something goes wrong, a team can no longer just break apart their
    system to find out. The team has to rely on external outputs of their system to
    figure out what’s going on internally.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在过去十年中，软件系统已经显著变得更加复杂。今天，软件系统由许多组件组成。其中许多组件是其他公司运行的服务——所有的云原生服务——这意味着一个团队甚至无法控制其系统中所有组件的内部情况。当出现问题时，团队不再能够仅仅拆开其系统来找出问题所在。团队必须依赖其系统的外部输出来了解内部发生了什么。
- en: Observability is a term used to address this challenge. It’s a concept drawn
    from control theory, and it refers to bringing “better visibility into understanding
    the complex behavior of software using [outputs] collected from the system at
    run time.”^([54](ch08.xhtml#ch01fn301))
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 可观察性是用来解决这一挑战的术语。这是从控制理论中引入的概念，指的是通过在运行时从系统收集的“输出”来提高对软件复杂行为理解的可见性。
- en: 'In other words, observability makes an assumption stronger than traditional
    monitoring: that the internal states of a system can be inferred from knowledge
    of its external outputs. Internal states can be current states, such as “the GPU
    utilization right now,” and historical states, such as “the average GPU utilization
    over the last day.”'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，可观察性比传统的监控做出了更强的假设：系统的内部状态可以从其外部输出的知识中推断出来。内部状态可以是当前状态，比如“当前的 GPU 利用率”，也可以是历史状态，比如“过去一天的平均
    GPU 利用率”。
- en: When something goes wrong with an observable system, we should be able to figure
    out what went wrong by looking at the system’s logs and metrics without having
    to ship new code to the system. Observability is about instrumenting your system
    in a way to ensure that sufficient information about a system’s runtime is collected
    and analyzed.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 当可观察的系统出现问题时，我们应该能够通过查看系统的日志和指标来弄清楚问题所在，而不必向系统发布新代码。可观察性是关于以一种确保收集和分析系统运行时足够信息的方式来仪器化您的系统。
- en: 'Monitoring centers around metrics, and metrics are usually aggregated. Observability
    allows more fine-grain metrics, so that you can know not only when a model’s performance
    degrades but also for what types of inputs or what subgroups of users or over
    what period of time the model degrades. For example, you should be able to query
    your logs for the answers to questions like: “show me all the users for which
    model A returned wrong predictions over the last hour, grouped by their zip codes”
    or “show me the outliers requests in the last 10 minutes” or “show me all the
    intermediate outputs of this input through the system.” To achieve this, you need
    to have logged your system’s outputs using tags and other identifying keywords
    to allow these outputs to later be sliced and diced along different dimensions
    of your data.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 监控围绕指标展开，而指标通常是聚合的。可观测性允许更精细的指标，因此您不仅可以知道模型性能何时下降，还可以了解对于哪些输入、哪些用户子组或者在多长时间内模型性能下降。例如，您应该能够查询日志以回答类似以下问题：“显示在最后一小时内，模型A为所有错误预测的用户分组，按其邮政编码排序”或者“显示最近10分钟的异常请求”或者“显示该输入通过系统的所有中间输出”。要实现这一点，您需要使用标签和其他识别关键字记录系统的输出，以便以后可以沿不同数据维度切片和分析这些输出。
- en: In ML, observability encompasses interpretability. Interpretability helps us
    understand how an ML model works, and observability helps us understand how the
    entire ML system, which includes the ML model, works. For example, when a model’s
    performance degrades over the last hour, being able to interpret which feature
    contributes the most to all the wrong predictions made over the last hour will
    help with figuring out what went wrong with the system and how to fix it.^([55](ch08.xhtml#ch01fn302))
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（ML）中，可观测性包括可解释性。可解释性帮助我们理解ML模型的工作原理，而可观测性则帮助我们理解整个ML系统的工作方式，包括ML模型在内。例如，当模型在最后一小时内的性能下降时，能够解释哪个特征对在最后一小时内所有错误预测贡献最大，将有助于弄清楚系统出了什么问题以及如何修复它。^([55](ch08.xhtml#ch01fn302))
- en: In this section, we’ve discussed multiple aspects of monitoring, from what data
    to monitor and what metrics to keep track of to different tools for monitoring
    and observability. Even though monitoring is a powerful concept, it’s inherently
    *passive*. You wait for a shift to happen to detect it. Monitoring helps unearth
    the problem without correcting it. In the next section, we’ll introduce continual
    learning, a paradigm that can *actively* help you update your models to address
    shifts.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了监控的多个方面，从监控哪些数据和跟踪哪些指标到不同的监控和可观测性工具。尽管监控是一个强大的概念，但它本质上是*被动*的。你需要等待发生变化才能检测到它。监控帮助发现问题，但并不会纠正它。在接下来的部分中，我们将介绍持续学习，这是一个能够*主动*帮助您更新模型以应对变化的范式。
- en: Summary
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This might have been the most challenging chapter for me to write in this book.
    The reason is that despite the importance of understanding how and why ML systems
    fail in production, the literature surrounding it is limited. We usually think
    of research preceding production, but this is an area of ML where research is
    still trying to catch up with production.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是我在本书中撰写的最具挑战性的章节。原因是尽管了解ML系统在生产环境中失败的重要性，但围绕它的文献却有限。我们通常认为研究在生产之前进行，但这是ML领域的一个方面，其中研究仍在努力赶上生产。
- en: 'To understand failures of ML systems, we differentiated between two types of
    failures: software systems failures (failures that also happen to non-ML systems)
    and ML-specific failures. Even though the majority of ML failures today are non-ML-specific,
    as tooling and infrastructure around MLOps matures, this might change.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解ML系统的失败，我们区分了两种类型的失败：软件系统失败（也发生在非ML系统中的失败）和ML特定失败。尽管今天大多数ML失败都是非ML特定的，随着围绕MLOps的工具和基础设施的成熟，这种情况可能会发生变化。
- en: 'We discussed three major causes of ML-specific failures: production data differing
    from training data, edge cases, and degenerate feedback loops. The first two causes
    are related to data, whereas the last cause is related to system design because
    it happens when the system’s outputs influence the same system’s input.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了ML特定失败的三个主要原因：生产数据与训练数据不同，边缘情况和退化反馈循环。前两个原因与数据有关，而最后一个原因则与系统设计有关，因为它发生在系统的输出影响同一系统的输入时。
- en: 'We zeroed into one failure that has gathered much attention in recent years:
    data distribution shifts. We looked into three types of shifts: covariate shift,
    label shift, and concept drift. Even though studying distribution shifts is a
    growing subfield of ML research, the research community hasn’t yet found a standard
    narrative. Different papers call the same phenomena by different names. Many studies
    are still based on the assumption that we know in advance how the distribution
    will shift or have the labels for the data from both the source distribution and
    the target distribution. However, in reality, we don’t know what the future data
    will be like, and obtaining labels for new data might be costly, slow, or just
    infeasible.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来引起广泛关注的一个失败案例是数据分布偏移。我们研究了三种类型的偏移：协变量偏移、标签偏移和概念漂移。尽管研究分布偏移的领域正在成长，但研究界尚未形成一个标准的叙述。不同的论文用不同的名字称呼同一现象。许多研究仍然基于一个假设，即我们预先知道分布将如何偏移，或者已经获得了来自源分布和目标分布的数据标签。然而，实际情况是，我们不知道未来的数据会是什么样子，获取新数据的标签可能成本高昂、速度缓慢，或者根本不可行。
- en: To be able to detect shifts, we need to monitor our deployed systems. Monitoring
    is an important set of practices for any software engineering system in production,
    not just ML, and it’s an area of ML where we should learn as much as we can from
    the DevOps world.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够检测到偏移，我们需要监控我们部署的系统。监控是任何软件工程系统在生产中的重要实践，不仅仅是ML，而且这是我们应该从DevOps世界中尽可能多学习的ML领域。
- en: 'Monitoring is all about metrics. We discussed different metrics we need to
    monitor: operational metrics—the metrics that should be monitored with any software
    systems such as latency, throughput, and CPU utilization—and ML-specific metrics.
    Monitoring can be applied to accuracy-related metrics, predictions, features,
    and/or raw inputs.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 监控关键在于度量标准。我们讨论了需要监控的不同度量标准：操作度量标准——任何软件系统都应该监控的度量标准，例如延迟、吞吐量和CPU利用率——以及ML特定的度量标准。监控可以应用于与准确率相关的度量标准、预测、特征和/或原始输入。
- en: Monitoring is hard because even if it’s cheap to compute metrics, understanding
    metrics isn’t straightforward. It’s easy to build dashboards to show graphs, but
    it’s much more difficult to understand what a graph means, whether it shows signs
    of drift, and, if there’s drift, whether it’s caused by an underlying data distribution
    change or by errors in the pipeline. An understanding of statistics might be required
    to make sense of the numbers and graphs.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 监控很难，因为即使计算度量标准的成本低廉，理解度量标准并不直观。建立展示图表的仪表板很容易，但理解图表的含义要困难得多，特别是确定是否显示漂移的迹象，以及如果有漂移，是由于底层数据分布的变化还是管道中的错误引起的。理解统计学可能需要解释数字和图形。
- en: Detecting model performance’s degradation in production is the first step. The
    next step is how to adapt our systems to changing environments, which we’ll discuss
    in the next chapter.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中检测模型性能的下降是第一步。下一步是如何使我们的系统适应不断变化的环境，这将在下一章中讨论。
- en: ^([1](ch08.xhtml#ch01fn250-marker)) This seems to be a fairly common pattern
    for inventory prediction. Eugene Yan wrote about a similar story to illustrate
    the problem of degenerate feedback loops in his article [“6 Little-Known Challenges
    After Deploying Machine Learning”](https://oreil.ly/p1yCd) (2021).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch08.xhtml#ch01fn250-marker)) 这似乎是库存预测的一个相当普遍模式。尤金·严在他的文章[“部署机器学习后的6个不太知名挑战”](https://oreil.ly/p1yCd)（2021年）中写到一个类似的案例来说明退化反馈循环的问题。
- en: ^([2](ch08.xhtml#ch01fn251-marker)) This is one of the reasons why many companies
    are hesitant to use products by startups, and why many companies prefer to use
    open source software. When a product you use is no longer maintained by its creators,
    if that product is open source, at least you’ll be able to access the codebase
    and maintain it yourself.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch08.xhtml#ch01fn251-marker)) 这是许多公司不愿使用初创公司产品的原因之一，也是许多公司更喜欢使用开源软件的原因之一。当你使用的产品不再由其创建者维护时，如果该产品是开源的，至少你可以访问代码库并自行维护。
- en: ^([3](ch08.xhtml#ch01fn252-marker)) Cosmic rays can cause your hardware to break
    down (Wikipedia, s.v. “Soft error,” [*https://oreil.ly/4cvNg*](https://oreil.ly/4cvNg)).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch08.xhtml#ch01fn252-marker)) 宇宙射线可能导致硬件故障（维基百科，“软错误”，[*https://oreil.ly/4cvNg*](https://oreil.ly/4cvNg)）。
- en: '^([4](ch08.xhtml#ch01fn253-marker)) Daniel Papasian and Todd Underwood, “How
    ML Breaks: A Decade of Outages for One Large ML Pipeline,” Google, July 17, 2020,
    video, 19:06, [*https://oreil.ly/WGabN*](https://oreil.ly/WGabN). A non-ML failure
    might still be indirectly due to ML. For example, a server can crash for non-ML
    systems, but because ML systems tend to require more compute power, it might cause
    this server to crash more often.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch08.xhtml#ch01fn253-marker)) Daniel Papasian 和 Todd Underwood，《ML如何崩溃：一个大型ML管道十年的停机期》，Google，2020年7月17日，视频，19:06，[*https://oreil.ly/WGabN*](https://oreil.ly/WGabN)。虽然非ML故障可能仍然间接归因于ML。例如，服务器可能因非ML系统而崩溃，但由于ML系统通常需要更多计算能力，这可能导致该服务器更频繁地崩溃。
- en: '^([5](ch08.xhtml#ch01fn254-marker)) The peak of my career: [Elon Musk agreed
    with me](https://oreil.ly/mBseG).'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch08.xhtml#ch01fn254-marker)) 我职业生涯的高峰：[埃隆·马斯克同意我的观点](https://oreil.ly/mBseG)。
- en: ^([6](ch08.xhtml#ch01fn255-marker)) Back when in-person academic conferences
    were still a thing, I often heard researchers arguing about whose models can generalize
    better. “My model generalizes better than your model” is the ultimate flex.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch08.xhtml#ch01fn255-marker)) 在线学术会议仍然存在时，我经常听到研究人员争论他们的模型谁能更好地泛化。“我的模型比你的模型泛化能力更强”是最终的炫耀。
- en: '^([7](ch08.xhtml#ch01fn256-marker)) Masashi Sugiyama and Motoaki Kawanabe,
    *Machine Learning in Non-stationary Environments: Introduction to Covariate Shift
    Adaptation* (Cambridge, MA: MIT Press, 2012).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch08.xhtml#ch01fn256-marker)) 杉山雅士和川辺基晃，《非稳态环境中的机器学习：协变量转移适应简介》（剑桥，MA：MIT
    Press，2012年）。
- en: '^([8](ch08.xhtml#ch01fn257-marker)) John Mcquaid, “Limits to Growth: Can AI’s
    Voracious Appetite for Data Be Tamed?” *Undark*, October 18, 2021, [*https://oreil.ly/LSjVD*](https://oreil.ly/LSjVD).'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch08.xhtml#ch01fn257-marker)) John Mcquaid，《增长的极限：AI对数据的贪婪能被驯服吗？》，*Undark*，2021年10月18日，[*https://oreil.ly/LSjVD*](https://oreil.ly/LSjVD)。
- en: ^([9](ch08.xhtml#ch01fn258-marker)) The chief technology officer (CTO) of a
    monitoring service company told me that, in his estimate, 80% of the drifts captured
    by his service are caused by human errors.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch08.xhtml#ch01fn258-marker)) 一家监控服务公司的首席技术官告诉我，据他估计，他们服务捕捉到的漂移中80%是由人为错误引起的。
- en: ^([10](ch08.xhtml#ch01fn259-marker)) This means the self-driving car is a bit
    safer than an average human driver. As of 2019, the ratio of traffic-related fatalities
    per 100,000 licensed drivers was 15.8, or 0.0158% (“Fatality Rate per 100,000
    Licensed Drivers in the U.S. from 1990 to 2019,” Statista, 2021, [*https://oreil.ly/w3wYh*](https://oreil.ly/w3wYh)).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch08.xhtml#ch01fn259-marker)) 这意味着自动驾驶汽车比普通人类驾驶员稍微安全一些。截至2019年，每10万名持证驾驶员的交通相关死亡率为15.8，或0.0158%（“Fatality
    Rate per 100,000 Licensed Drivers in the U.S. from 1990 to 2019”，Statista，2021年，[*https://oreil.ly/w3wYh*](https://oreil.ly/w3wYh)）。
- en: ^([11](ch08.xhtml#ch01fn260-marker)) Rodney Brooks, “Edge Cases for Self Driving
    Cars,” *Robots, AI, and Other Stuff*, June 17, 2017, [*https://oreil.ly/Nyp4F*](https://oreil.ly/Nyp4F);
    Lance Eliot, “Whether Those Endless Edge or Corner Cases Are the Long-Tail Doom
    for AI Self-Driving Cars,” *Forbes*, July 13, 2021, [*https://oreil.ly/L2Sbp*](https://oreil.ly/L2Sbp);
    Kevin McAllister, “Self-Driving Cars Will Be Shaped by Simulated, Location Data,”
    *Protocol*, March 25, 2021, [*https://oreil.ly/tu8hs*](https://oreil.ly/tu8hs).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch08.xhtml#ch01fn260-marker)) Rodney Brooks，《自动驾驶汽车的边缘案例》，*Robots, AI,
    and Other Stuff*，2017年6月17日，[*https://oreil.ly/Nyp4F*](https://oreil.ly/Nyp4F)；Lance
    Eliot，《无尽的边缘或角落案例是否是AI自动驾驶汽车的长尾厄运？》，*Forbes*，2021年7月13日，[*https://oreil.ly/L2Sbp*](https://oreil.ly/L2Sbp)；Kevin
    McAllister，《自动驾驶汽车将由模拟和位置数据塑造》，*Protocol*，2021年3月25日，[*https://oreil.ly/tu8hs*](https://oreil.ly/tu8hs)。
- en: ^([12](ch08.xhtml#ch01fn261-marker)) [e-discovery](https://oreil.ly/KCets),
    or electronic discovery, refers to discovery in legal proceedings, such as litigation,
    government investigations, or Freedom of Information Act requests, where the information
    sought is in electronic format.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch08.xhtml#ch01fn261-marker)) [电子发现](https://oreil.ly/KCets)，或电子发现，指的是在法律诉讼、政府调查或信息自由法案请求等法律程序中寻找的信息，其格式为电子格式。
- en: ^([13](ch08.xhtml#ch01fn262-marker)) Ray Jiang, Silvia Chiappa, Tor Lattimore,
    András György, and Pushmeet Kohli, “Degenerate Feedback Loops in Recommender Systems,”
    *arXiv*, February 27, 2019, [*https://oreil.ly/b9G7o*](https://oreil.ly/b9G7o).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch08.xhtml#ch01fn262-marker)) Ray Jiang, Silvia Chiappa, Tor Lattimore,
    András György, 和 Pushmeet Kohli，《推荐系统中的退化反馈环路》，*arXiv*，2019年2月27日，[*https://oreil.ly/b9G7o*](https://oreil.ly/b9G7o)。
- en: ^([14](ch08.xhtml#ch01fn263-marker)) This is related to “survivorship bias.”
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch08.xhtml#ch01fn263-marker)) 这与“存活偏差”有关。
- en: '^([15](ch08.xhtml#ch01fn264-marker)) Erik Brynjolfsson, Yu (Jeffrey) Hu, and
    Duncan Simester, “Goodbye Pareto Principle, Hello Long Tail: The Effect of Search
    Costs on the Concentration of Product Sales,” *Management Science* 57, no. 8 (2011):
    1373–86, [*https://oreil.ly/tGhHi*](https://oreil.ly/tGhHi); Daniel Fleder and
    Kartik Hosanagar, “Blockbuster Culture’s Next Rise or Fall: The Impact of Recommender
    Systems on Sales Diversity,” *Management Science* 55, no. 5 (2009), [*https://oreil.ly/Zwkh8*](https://oreil.ly/Zwkh8);
    Himan Abdollahpouri, Robin Burke, and Bamshad Mobasher, “Managing Popularity Bias
    in Recommender Systems with Personalized Re-ranking,” *arXiv*, January 22, 2019,
    [*https://oreil.ly/jgYLr*](https://oreil.ly/jgYLr).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '^([15](ch08.xhtml#ch01fn264-marker)) Erik Brynjolfsson, Yu (Jeffrey) Hu, 和
    Duncan Simester, “再见帕累托原理，你好长尾：搜索成本对产品销售集中度的影响,” *Management Science* 57, no.
    8 (2011): 1373–86, [*https://oreil.ly/tGhHi*](https://oreil.ly/tGhHi); Daniel
    Fleder 和 Kartik Hosanagar, “重大文化的兴起或衰落：推荐系统对销售多样性的影响,” *Management Science* 55,
    no. 5 (2009), [*https://oreil.ly/Zwkh8*](https://oreil.ly/Zwkh8); Himan Abdollahpouri,
    Robin Burke, 和 Bamshad Mobasher, “管理推荐系统中的流行偏见与个性化重新排名,” *arXiv*, January 22,
    2019, [*https://oreil.ly/jgYLr*](https://oreil.ly/jgYLr).'
- en: '^([16](ch08.xhtml#ch01fn265-marker)) Patrick John Chia, Jacopo Tagliabue, Federico
    Bianchi, Chloe He, and Brian Ko, “Beyond NDCG: Behavioral Testing of Recommender
    Systems with RecList,” *arXiv*, November 18, 2021, [*https://oreil.ly/7GfHk*](https://oreil.ly/7GfHk).'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch08.xhtml#ch01fn265-marker)) Patrick John Chia, Jacopo Tagliabue, Federico
    Bianchi, Chloe He, 和 Brian Ko, “超越NDCG：使用RecList测试推荐系统的行为,” *arXiv*, November
    18, 2021, [*https://oreil.ly/7GfHk*](https://oreil.ly/7GfHk).
- en: ^([17](ch08.xhtml#ch01fn266-marker)) Catherine Wang, “Why TikTok Made Its User
    So Obsessive? The AI Algorithm That Got You Hooked,” *Towards Data Science*, June
    7, 2020, [*https://oreil.ly/J7nJ9*](https://oreil.ly/J7nJ9).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch08.xhtml#ch01fn266-marker)) Catherine Wang, “为什么 TikTok 让它的用户如此着迷？AI
    算法让你上瘾的原因,” *Towards Data Science*, June 7, 2020, [*https://oreil.ly/J7nJ9*](https://oreil.ly/J7nJ9).
- en: '^([18](ch08.xhtml#ch01fn267-marker)) Gediminas Adomavicius and YoungOk Kwon,
    “Improving Aggregate Recommendation Diversity Using Ranking-Based Techniques,”
    *IEEE Transactions on Knowledge and Data Engineering* 24, no. 5 (May 2012): 896–911,
    [*https://oreil.ly/0JjUV*](https://oreil.ly/0JjUV).'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '^([18](ch08.xhtml#ch01fn267-marker)) Gediminas Adomavicius 和 YoungOk Kwon,
    “利用基于排名的技术提高聚合推荐多样性,” *IEEE Transactions on Knowledge and Data Engineering* 24,
    no. 5 (May 2012): 896–911, [*https://oreil.ly/0JjUV*](https://oreil.ly/0JjUV).'
- en: '^([19](ch08.xhtml#ch01fn268-marker)) Tobias Schnabel, Adith Swaminathan, Ashudeep
    Singh, Navin Chandak, and Thorsten Joachims, “Recommendations as Treatments: Debiasing
    Learning and Evaluation,” *arXiv*, February 17, 2016, [*https://oreil.ly/oDPSK*](https://oreil.ly/oDPSK).'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch08.xhtml#ch01fn268-marker)) Tobias Schnabel, Adith Swaminathan, Ashudeep
    Singh, Navin Chandak, and Thorsten Joachims, “推荐作为治疗：去偏见化学习与评估,” *arXiv*, February
    17, 2016, [*https://oreil.ly/oDPSK*](https://oreil.ly/oDPSK).
- en: '^([20](ch08.xhtml#ch01fn269-marker)) Jeffrey C. Schlimmer and Richard H. Granger,
    Jr., “Incremental Learning from Noisy Data,” *Machine Learning* 1 (1986): 317–54,
    [*https://oreil.ly/FxFQi*](https://oreil.ly/FxFQi).'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '^([20](ch08.xhtml#ch01fn269-marker)) Jeffrey C. Schlimmer 和 Richard H. Granger,
    Jr., “从噪声数据中的增量学习,” *Machine Learning* 1 (1986): 317–54, [*https://oreil.ly/FxFQi*](https://oreil.ly/FxFQi).'
- en: ^([21](ch08.xhtml#ch01fn270-marker)) You might wonder what about the case when
    *P*(*X*|*Y*) changes but *P*(*Y*) remains the same, as in the second decomposition.
    I’ve never encountered any research in this setting. I asked a couple of researchers
    who specialize in data shifts about it, and they also told me that setting would
    be too difficult to study.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch08.xhtml#ch01fn270-marker)) 你可能会想到，当*P*(*X*|*Y*)发生变化但*P*(*Y*)保持不变时，如第二种分解情况。我在这种情况下从未遇到过任何研究。我询问了几位专门研究数据转移的研究人员，他们也告诉我，这种情况将会非常难以研究。
- en: ^([22](ch08.xhtml#ch01fn271-marker)) Wouter M. Kouw and Marco Loog, “An Introduction
    to Domain Adaptation and Transfer Learning,” *arXiv*, December 31, 2018, [*https://oreil.ly/VKSVP*](https://oreil.ly/VKSVP).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch08.xhtml#ch01fn271-marker)) Wouter M. Kouw 和 Marco Loog, “领域适应与迁移学习简介,”
    *arXiv*, December 31, 2018, [*https://oreil.ly/VKSVP*](https://oreil.ly/VKSVP).
- en: ^([23](ch08.xhtml#ch01fn272-marker)) “Breast Cancer Risk in American Women,”
    National Cancer Institute, [*https://oreil.ly/BFP3U*](https://oreil.ly/BFP3U).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](ch08.xhtml#ch01fn272-marker)) “美国女性的乳腺癌风险,” 美国国家癌症研究所, [*https://oreil.ly/BFP3U*](https://oreil.ly/BFP3U).
- en: ^([24](ch08.xhtml#ch01fn273-marker)) Arthur Gretton, Alex Smola, Jiayuan Huang,
    Marcel Schmittfull, Karsten Borgwardt, and Bernard Schölkopf, “Covariate Shift
    by Kernel Mean Matching,” *Journal of Machine Learning Research* (2009), [*https://oreil.ly/s49MI*](https://oreil.ly/s49MI).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](ch08.xhtml#ch01fn273-marker)) Arthur Gretton, Alex Smola, Jiayuan Huang,
    Marcel Schmittfull, Karsten Borgwardt 和 Bernard Schölkopf，“核均值匹配的协变量转移”，*机器学习研究期刊*
    (2009年)，[*https://oreil.ly/s49MI*](https://oreil.ly/s49MI)。
- en: ^([25](ch08.xhtml#ch01fn274-marker)) Sugiyama and Kawanabe, *Machine Learning
    in Non-stationary Environments*.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ^([25](ch08.xhtml#ch01fn274-marker)) Sugiyama 和 Kawanabe，《非稳态环境下的机器学习》。
- en: ^([26](ch08.xhtml#ch01fn275-marker)) Tongtong Fang, Nan Lu, Gang Niu, and Masashi
    Sugiyama, “Rethinking Importance Weighting for Deep Learning under Distribution
    Shift,” *NeurIPS Proceedings* 2020, [*https://oreil.ly/GzJ1r*](https://oreil.ly/GzJ1r);
    Gretton et al., “Covariate Shift by Kernel Mean Matching.”
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ^([26](ch08.xhtml#ch01fn275-marker)) Tongtong Fang, Nan Lu, Gang Niu 和 Masashi
    Sugiyama，“重新思考深度学习中的重要性加权在分布转移下的应用”，*神经信息处理系统大会论文集* 2020，[*https://oreil.ly/GzJ1r*](https://oreil.ly/GzJ1r)；Gretton
    等人，“核均值匹配的协变量转移”。
- en: '^([27](ch08.xhtml#idm46868207601952-marker)) Han Zhao, Remi Tachet Des Combes,
    Kun Zhang, and Geoffrey Gordon, “On Learning Invariant Representations for Domain
    Adaptation,” *Proceedings of Machine Learning Research* 97 (2019): 7523–32, [*https://oreil.ly/ZxYWD*](https://oreil.ly/ZxYWD).'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '^([27](ch08.xhtml#idm46868207601952-marker)) Han Zhao, Remi Tachet Des Combes,
    Kun Zhang 和 Geoffrey Gordon，“关于学习不变表示进行领域自适应”，*机器学习研究会议论文集* 97 (2019): 7523–32，[*https://oreil.ly/ZxYWD*](https://oreil.ly/ZxYWD)。'
- en: ^([28](ch08.xhtml#ch01fn276-marker)) You can think of this as the case where
    both *P*(*X*) and *P*(*Y*|*X*) change.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ^([28](ch08.xhtml#ch01fn276-marker)) 你可以把这看作是 *P*(*X*) 和 *P*(*Y*|*X*) 都发生变化的情况。
- en: ^([29](ch08.xhtml#ch01fn277-marker)) If you use a neural network using softmax
    as your last layer for your classification tax, the dimension of this softmax
    layer is [number_of_hidden_units × number_of_classes]. When the number of classes
    changes, the number of parameters in your softmax layer changes.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ^([29](ch08.xhtml#ch01fn277-marker)) 如果你使用 softmax 作为分类税的最后一层神经网络，这个 softmax
    层的维度是 [隐藏单元数 × 类别数]。当类别数变化时，softmax 层中的参数数目也会变化。
- en: ^([30](ch08.xhtml#ch01fn278-marker)) You don’t need ground truth labels if you
    use an unsupervised learning method, but the vast majority of applications today
    are supervised.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: ^([30](ch08.xhtml#ch01fn278-marker)) 如果你使用无监督学习方法，你不需要地面真实标签，但今天绝大多数应用程序都是监督学习的。
- en: '^([31](ch08.xhtml#ch01fn279-marker)) Hamel Husain gave a great lecture on why
    TensorFlow Extended’s skew detection is so bad for [CS 329S: Machine Learning
    Systems Design](https://oreil.ly/Y9hAW) (Stanford, 2022). You can find the video
    on [YouTube](https://oreil.ly/ivxbQ).'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '^([31](ch08.xhtml#ch01fn279-marker)) Hamel Husain 在斯坦福大学2022年的 [CS 329S: 机器学习系统设计](https://oreil.ly/Y9hAW)
    课上出色地讲解了为何 TensorFlow Extended 的偏斜检测如此糟糕。你可以在 [YouTube](https://oreil.ly/ivxbQ)
    上找到视频。'
- en: '^([32](ch08.xhtml#ch01fn280-marker)) I. M. Chakravarti, R. G. Laha, and J.
    Roy, *Handbook of Methods of Applied Statistics*, vol. 1, *Techniques of Computation,
    Descriptive Methods, and Statistical Inference* (New York: Wiley, 1967).'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ^([32](ch08.xhtml#ch01fn280-marker)) I. M. Chakravarti, R. G. Laha 和 J. Roy，《应用统计方法手册》，第1卷，《计算技术、描述方法和统计推断技术》，（纽约：Wiley，1967年）。
- en: ^([33](ch08.xhtml#ch01fn281-marker)) Eric Feigelson and G. Jogesh Babu, “Beware
    the Kolmogorov-Smirnov Test!” Center for Astrostatistics, Penn State University,
    [*https://oreil.ly/7AHcT*](https://oreil.ly/7AHcT).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ^([33](ch08.xhtml#ch01fn281-marker)) Eric Feigelson 和 G. Jogesh Babu，“小心科尔莫哥罗夫-斯米尔诺夫检验！”
    宇宙统计中心，宾夕法尼亚州立大学，[*https://oreil.ly/7AHcT*](https://oreil.ly/7AHcT)。
- en: ^([34](ch08.xhtml#ch01fn282-marker)) Eric Breck, Marty Zinkevich, Neoklis Polyzotis,
    Steven Whang, and Sudip Roy, “Data Validation for Machine Learning,” *Proceedings
    of SysML*, 2019, [*https://oreil.ly/xoneh*](https://oreil.ly/xoneh).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ^([34](ch08.xhtml#ch01fn282-marker)) Eric Breck, Marty Zinkevich, Neoklis Polyzotis,
    Steven Whang 和 Sudip Roy，“机器学习的数据验证”，*SysML会议论文集*，2019年，[*https://oreil.ly/xoneh*](https://oreil.ly/xoneh)。
- en: '^([35](ch08.xhtml#ch01fn283-marker)) Li Bu, Cesare Alippi, and Dongbin Zhao,
    “A pdf-Free Change Detection Test Based on Density Difference Estimation,” *IEEE
    Transactions on Neural Networks and Learning Systems* 29, no. 2 (February 2018):
    324–34, [*https://oreil.ly/RD8Uy*](https://oreil.ly/RD8Uy). The authors claim
    that the method works on multidimensional inputs.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '^([35](ch08.xhtml#ch01fn283-marker)) Li Bu, Cesare Alippi 和 Dongbin Zhao，“基于密度差异估计的无pdf变化检测测试”，*IEEE神经网络与学习系统交易*
    29, no. 2 (2018年2月): 324–34，[*https://oreil.ly/RD8Uy*](https://oreil.ly/RD8Uy)。作者声称该方法适用于多维输入。'
- en: '^([36](ch08.xhtml#ch01fn284-marker)) Stephan Rabanser, Stephan Günnemann, and
    Zachary C. Lipton, “Failing Loudly: An Empirical Study of Methods for Detecting
    Dataset Shift,” *arXiv*, October 29, 2018, [*https://oreil.ly/HxAwV*](https://oreil.ly/HxAwV).'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ^([36](ch08.xhtml#ch01fn284-marker)) Stephan Rabanser、Stephan Günnemann和Zachary
    C. Lipton，《高声失败：检测数据集转移方法的实证研究》，*arXiv*，2018年10月29日，[*https://oreil.ly/HxAwV*](https://oreil.ly/HxAwV)。
- en: ^([37](ch08.xhtml#ch01fn285-marker)) Manuel Baena-García, José del Campo-Ávila,
    Raúl Fidalgo, Albert Bifet, Ricard Gavaldà, and Rafael Morales-Bueno, “Early Drift
    Detection Method,” 2006, [*https://oreil.ly/Dnv0s*](https://oreil.ly/Dnv0s).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: ^([37](ch08.xhtml#ch01fn285-marker)) Manuel Baena-García、José del Campo-Ávila、Raúl
    Fidalgo、Albert Bifet、Ricard Gavaldà和Rafael Morales-Bueno，《早期漂移检测方法》，2006年，[*https://oreil.ly/Dnv0s*](https://oreil.ly/Dnv0s)。
- en: ^([38](ch08.xhtml#ch01fn286-marker)) Nandini Ramanan, Rasool Tahmasbi, Marjorie
    Sayer, Deokwoo Jung, Shalini Hemachandran, and Claudionor Nunes Coelho Jr., “Real-time
    Drift Detection on Time-series Data,” *arXiv*, October 12, 2021, [*https://oreil.ly/xmdqW*](https://oreil.ly/xmdqW).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ^([38](ch08.xhtml#ch01fn286-marker)) Nandini Ramanan、Rasool Tahmasbi、Marjorie
    Sayer、Deokwoo Jung、Shalini Hemachandran和Claudionor Nunes Coelho Jr.，《时间序列数据上的实时漂移检测》，*arXiv*，2021年10月12日，[*https://oreil.ly/xmdqW*](https://oreil.ly/xmdqW)。
- en: ^([39](ch08.xhtml#ch01fn287-marker)) I’m working on a solution that can handle
    the minute granularity level.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: ^([39](ch08.xhtml#ch01fn287-marker)) 我正在研究一个可以处理分钟粒度级别的解决方案。
- en: ^([40](ch08.xhtml#ch01fn288-marker)) Thanks Goku Mohandas for sharing this tip
    on the [MLOps Discord server](https://oreil.ly/UOJ8h).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ^([40](ch08.xhtml#ch01fn288-marker)) 感谢Goku Mohandas在[MLOps Discord服务器](https://oreil.ly/UOJ8h)上分享这个提示。
- en: ^([41](ch08.xhtml#ch01fn289-marker)) As Han-chung Lee, one early reviewer, pointed
    out, this is also because smaller companies don’t have enough data on their models.
    When you don’t have a lot of data, it’s better to have a time-based regimen than
    to overfit your regime to insufficient data.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ^([41](ch08.xhtml#ch01fn289-marker)) 早期评论家李汉钟指出，这也是因为较小的公司对其模型的数据不足。当你没有足够的数据时，最好是按时间安排而不是过度拟合于不充分的数据。
- en: ^([42](ch08.xhtml#ch01fn290-marker)) Kun Zhang, Bernhard Schölkopf, Krikamol
    Muandet, and Zhikun Wang, “Domain Adaptation under Target and Conditional Shift,”
    *Proceedings of the 30th International Conference on Machine Learning* (2013),
    [*https://oreil.ly/C123l*](https://oreil.ly/C123l).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: ^([42](ch08.xhtml#ch01fn290-marker)) Kun Zhang、Bernhard Schölkopf、Krikamol Muandet和Zhikun
    Wang，《目标和条件转移下的领域适应》，*第30届国际机器学习会议论文集*（2013年），[*https://oreil.ly/C123l*](https://oreil.ly/C123l)。
- en: '^([43](ch08.xhtml#ch01fn291-marker)) Han Zhao, Remi Tachet Des Combes, Kun
    Zhang, and Geoffrey Gordon, “On Learning Invariant Representations for Domain
    Adaptation,” *Proceedings of Machine Learning Research* 97 (2019): 7523–32, [*https://oreil.ly/W78hH*](https://oreil.ly/W78hH).'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: ^([43](ch08.xhtml#ch01fn291-marker)) Han Zhao、Remi Tachet Des Combes、Kun Zhang和Geoffrey
    Gordon，《关于学习不变表示进行领域适应的研究》，*机器学习研究会议录* 第97卷（2019年）：7523–32，[*https://oreil.ly/W78hH*](https://oreil.ly/W78hH)。
- en: ^([44](ch08.xhtml#ch01fn292-marker)) Zachary C. Lipton, Yu-Xiang Wang, and Alex
    Smola, “Detecting and Correcting for Label Shift with Black Box Predictors,” *arXiv*,
    February 12, 2018, [*https://oreil.ly/zKSlj*](https://oreil.ly/zKSlj).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ^([44](ch08.xhtml#ch01fn292-marker)) Zachary C. Lipton、Yu-Xiang Wang和Alex Smola，《使用黑盒预测器检测和修正标签转移》，*arXiv*，2018年2月12日，[*https://oreil.ly/zKSlj*](https://oreil.ly/zKSlj)。
- en: ^([45](ch08.xhtml#ch01fn293-marker)) Some monitoring vendors claim that their
    solutions are able to detect not only when your model should be retrained, but
    also what data to retrain on. I haven’t been able to verify the validity of these
    claims.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ^([45](ch08.xhtml#ch01fn293-marker)) 一些监控供应商声称，他们的解决方案不仅能够检测何时应重新训练模型，还能确定重新训练的数据。我尚未能够验证这些声明的有效性。
- en: ^([46](ch08.xhtml#idm46868207424048-marker)) “Amazon Compute Service Level Agreement,”
    Amazon Web Services, last updated August 24, 2021, [*https://oreil.ly/5bjx9*](https://oreil.ly/5bjx9).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: ^([46](ch08.xhtml#idm46868207424048-marker)) “Amazon计算服务等级协议”，亚马逊网络服务，最后更新于2021年8月24日，[*https://oreil.ly/5bjx9*](https://oreil.ly/5bjx9)。
- en: ^([47](ch08.xhtml#ch01fn294-marker)) Be careful when using the completion rate
    as a metric to optimize for, as it might bias your recommender system toward short
    videos.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: ^([47](ch08.xhtml#ch01fn294-marker)) 在使用完成率作为优化度量标准时要小心，因为它可能会使你的推荐系统偏向短视频。
- en: ^([48](ch08.xhtml#ch01fn295-marker)) Rabanser, Günnemann, and Lipton, “Failing
    Loudly.”
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: ^([48](ch08.xhtml#ch01fn295-marker)) Rabanser、Günnemann和Lipton，《高声失败》。
- en: ^([49](ch08.xhtml#ch01fn296-marker)) Ian Malpass, “Measure Anything, Measure
    Everything,” *Code as Craft*, February 15, 2011, [*https://oreil.ly/3KF1K*](https://oreil.ly/3KF1K).
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: ^([49](ch08.xhtml#ch01fn296-marker)) Ian Malpass，《任何事情都可以衡量，一切都可以测量》，*Code as
    Craft*，2011年2月15日，[*https://oreil.ly/3KF1K*](https://oreil.ly/3KF1K)。
- en: '^([50](ch08.xhtml#ch01fn297-marker)) Andrew Morgan, “Data Engineering in Badoo:
    Handling 20 Billion Events Per Day,” InfoQ, August 9, 2019, [*https://oreil.ly/qnnuV*](https://oreil.ly/qnnuV).'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: ^([50](ch08.xhtml#ch01fn297-marker)) Andrew Morgan，“Badoo中的数据工程：处理每天200亿事件”，InfoQ，2019年8月9日，[*https://oreil.ly/qnnuV*](https://oreil.ly/qnnuV)。
- en: ^([51](ch08.xhtml#ch01fn298-marker)) Charity Majors, “Observability—A 3-Year
    Retrospective,” *The New Stack*, August 6, 2019, [*https://oreil.ly/Logby*](https://oreil.ly/Logby).
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: ^([51](ch08.xhtml#ch01fn298-marker)) Charity Majors，“可观测性——三年回顾”，*The New Stack*，2019年8月6日，[*https://oreil.ly/Logby*](https://oreil.ly/Logby)。
- en: ^([52](ch08.xhtml#ch01fn299-marker)) “Log Management Market Size, Share and
    Global Market Forecast to 2026,” MarketsandMarkets, 2021, [*https://oreil.ly/q0xgh*](https://oreil.ly/q0xgh).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ^([52](ch08.xhtml#ch01fn299-marker)) “日志管理市场规模、份额和全球市场预测至2026年”，MarketsandMarkets，2021年，[*https://oreil.ly/q0xgh*](https://oreil.ly/q0xgh)。
- en: ^([53](ch08.xhtml#ch01fn300-marker)) For readers unfamiliar with stream processing,
    please refer to the section [“Batch Processing Versus Stream Processing”](ch03.xhtml#batch_processing_versus_stream_processi).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: ^([53](ch08.xhtml#ch01fn300-marker)) 对于不熟悉流处理的读者，请参考章节[“批处理与流处理对比”](ch03.xhtml#batch_processing_versus_stream_processi)。
- en: '^([54](ch08.xhtml#ch01fn301-marker)) Suman Karumuri, Franco Solleza, Stan Zdonik,
    and Nesime Tatbul, “Towards Observability Data Management at Scale,” *ACM SIGMOD
    Record* 49, no. 4 (December 2020): 18–23, [*https://oreil.ly/oS5hn*](https://oreil.ly/oS5hn).'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: ^([54](ch08.xhtml#ch01fn301-marker)) Suman Karumuri、Franco Solleza、Stan Zdonik和Nesime
    Tatbul，“朝向规模化可观测数据管理”，*ACM SIGMOD Record*，第49卷第4期（2020年12月）：18–23，[*https://oreil.ly/oS5hn*](https://oreil.ly/oS5hn)。
- en: ^([55](ch08.xhtml#ch01fn302-marker)) See the section [“Feature Importance”](ch05.xhtml#feature_importance).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: ^([55](ch08.xhtml#ch01fn302-marker)) 查看章节[“特征重要性”](ch05.xhtml#feature_importance)。
