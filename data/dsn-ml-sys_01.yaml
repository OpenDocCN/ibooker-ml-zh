- en: Chapter 1\. Overview of Machine Learning Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章\. 机器学习系统概述
- en: In November 2016, Google announced that it had incorporated its multilingual
    neural machine translation system into Google Translate, marking one of the first
    success stories of deep artificial neural networks in production at scale.^([1](ch01.xhtml#ch01fn1))
    According to Google, with this update, the quality of translation improved more
    in a single leap than they had seen in the previous 10 years combined.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 2016年11月，谷歌宣布已将其多语言神经机器翻译系统整合到Google翻译中，标志着深度人工神经网络在大规模生产中的首个成功案例。^([1](ch01.xhtml#ch01fn1))
    根据谷歌的说法，通过此更新，翻译质量的改善超过了前10年的总和。
- en: 'This success of deep learning renewed the interest in machine learning (ML)
    at large. Since then, more and more companies have turned toward ML for solutions
    to their most challenging problems. In just five years, ML has found its way into
    almost every aspect of our lives: how we access information, how we communicate,
    how we work, how we find love. The spread of ML has been so rapid that it’s already
    hard to imagine life without it. Yet there are still many more use cases for ML
    waiting to be explored in fields such as health care, transportation, farming,
    and even in helping us understand the universe.^([2](ch01.xhtml#ch01fn2))'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的成功重新激发了对机器学习（ML）的广泛兴趣。此后，越来越多的公司转向ML来解决它们最具挑战性的问题。仅仅五年时间，ML已经渗透到我们生活的几乎每一个方面：我们如何获取信息，如何沟通，如何工作，如何寻找爱情。ML的传播速度如此之快，以至于很难想象没有它的生活。然而，在健康护理、交通运输、农业乃至于帮助我们理解宇宙等领域，还有许多ML等待被探索的用例。^([2](ch01.xhtml#ch01fn2))
- en: Many people, when they hear “machine learning system,” think of just the ML
    algorithms being used such as logistic regression or different types of neural
    networks. However, the algorithm is only a small part of an ML system in production.
    The system also includes the business requirements that gave birth to the ML project
    in the first place, the interface where users and developers interact with your
    system, the data stack, and the logic for developing, monitoring, and updating
    your models, as well as the infrastructure that enables the delivery of that logic.
    [Figure 1-1](#different_components_of_an_ml_systemdot) shows you the different
    components of an ML system and in which chapters of this book they will be covered.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当许多人听到“机器学习系统”时，他们只考虑使用的ML算法，如逻辑回归或不同类型的神经网络。然而，算法只是ML系统在生产中的一小部分。系统还包括首次诞生ML项目的业务需求，用户和开发人员与系统交互的界面，数据堆栈，以及开发、监控和更新模型的逻辑，以及支持交付该逻辑的基础设施。[图1-1](#different_components_of_an_ml_systemdot)展示了ML系统的不同组成部分，以及本书中将涵盖它们的章节。
- en: The Relationship Between MLOps and ML Systems Design
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps与ML系统设计之间的关系
- en: Ops in MLOps comes from DevOps, short for Developments and Operations. To operationalize
    something means to bring it into production, which includes deploying, monitoring,
    and maintaining it. MLOps is a set of tools and best practices for bringing ML
    into production.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps中的Ops源自DevOps，即开发与运维。将某物操作化意味着将其投入生产，包括部署、监控和维护。MLOps是将ML引入生产的一组工具和最佳实践。
- en: ML systems design takes a system approach to MLOps, which means that it considers
    an ML system holistically to ensure that all the components and their stakeholders
    can work together to satisfy the specified objectives and requirements.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ML系统设计采用系统方法进行MLOps，这意味着它全面考虑ML系统，以确保所有组件及其利益相关者可以共同工作，以满足指定的目标和要求。
- en: '![](Images/dmls_0101.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0101.png)'
- en: Figure 1-1\. Different components of an ML system. “ML algorithms” is usually
    what people think of when they say machine learning, but it’s only a small part
    of the entire system.
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. ML系统的不同组成部分。“ML算法”通常是人们谈论机器学习时所想到的，但它只是整个系统的一小部分。
- en: There are many excellent books about various ML algorithms. This book doesn’t
    cover any specific algorithms in detail but rather helps readers understand the
    entire ML system as a whole. In other words, this book’s goal is to provide you
    with a framework to develop a solution that best works for your problem, regardless
    of which algorithm you might end up using. Algorithms might become outdated quickly
    as new algorithms are constantly being developed, but the framework proposed in
    this book should still work with new algorithms.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多关于各种机器学习算法的优秀书籍。本书不详细涵盖任何特定算法，而是帮助读者全面理解整个机器学习系统。换句话说，本书的目标是为您提供一个框架，以开发对您的问题最有效的解决方案，无论最终使用哪种算法。随着新算法的不断开发，算法可能很快就会过时，但本书提出的框架应该仍然适用于新算法。
- en: The first chapter of the book aims to give you an overview of what it takes
    to bring an ML model to production. Before discussing how to develop an ML system,
    it’s important to ask a fundamental question of when and when not to use ML. We’ll
    cover some of the popular use cases of ML to illustrate this point.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的第一章旨在为您提供将机器学习模型投入生产所需的概述。在讨论如何开发机器学习系统之前，问清楚何时以及何时不使用机器学习是很重要的。我们将通过一些流行的机器学习用例来说明这一点。
- en: After the use cases, we’ll move on to the challenges of deploying ML systems,
    and we’ll do so by comparing ML in production to ML in research as well as to
    traditional software. If you’ve been in the trenches of developing applied ML
    systems, you might already be familiar with what’s written in this chapter. However,
    if you have only had experience with ML in an academic setting, this chapter will
    give an honest view of ML in the real world and set your first application up
    for success.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍用例之后，我们将继续讨论部署机器学习系统的挑战，并通过比较在生产环境中的机器学习与研究中的机器学习以及传统软件来进行。如果您一直在开发应用型机器学习系统的前线，您可能已经对本章中的内容很熟悉。但是，如果您只在学术环境中有过机器学习的经验，本章将为您展示机器学习在现实世界中的真实情况，并为您的首个应用程序成功的设立基础。
- en: When to Use Machine Learning
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用机器学习
- en: As its adoption in the industry quickly grows, ML has proven to be a powerful
    tool for a wide range of problems. Despite an incredible amount of excitement
    and hype generated by people both inside and outside the field, ML is not a magic
    tool that can solve all problems. Even for problems that ML can solve, ML solutions
    might not be the optimal solutions. Before starting an ML project, you might want
    to ask whether ML is necessary or cost-effective.^([3](ch01.xhtml#ch01fn3))
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着它在行业中的快速应用增长，机器学习已被证明是解决各种问题的强大工具。尽管内外部都充满了无数的兴奋和炒作，但机器学习并非解决所有问题的神奇工具。即使是机器学习可以解决的问题，机器学习解决方案也可能不是最佳解决方案。在开始机器学习项目之前，您可能想问问机器学习是否是必要的或者是否具有成本效益。^([3](ch01.xhtml#ch01fn3))
- en: 'To understand what ML can do, let’s examine what ML solutions generally do:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解机器学习能做什么，让我们先来看看机器学习解决方案通常做什么：
- en: Machine learning is an approach to (1) *learn* (2) *complex patterns* from (3)
    *existing data* and use these patterns to make (4) *predictions* on (5) *unseen
    data*.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 机器学习是一种从现有数据中*学习* *复杂模式* 并利用这些模式对*未见数据*做出*预测*的方法。
- en: 'We’ll look at each of the italicized keyphrases in the above framing to understand
    its implications to the problems ML can solve:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分析上述表述中的每一个斜体关键词组，以理解它对机器学习可以解决的问题的影响：
- en: '*1\. Learn*: the system has the capacity to learn'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*1\. 学习*：系统具有学习能力'
- en: A relational database isn’t an ML system because it doesn’t have the capacity
    to learn. You can explicitly state the relationship between two columns in a relational
    database, but it’s unlikely to have the capacity to figure out the relationship
    between these two columns by itself.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 关系数据库不是机器学习系统，因为它没有学习能力。您可以明确地说明关系数据库中两列之间的关系，但它不太可能自己找出这两列之间的关系。
- en: For an ML system to learn, there must be something for it to learn from. In
    most cases, ML systems learn from data. In supervised learning, based on example
    input and output pairs, ML systems learn how to generate outputs for arbitrary
    inputs. For example, if you want to build an ML system to learn to predict the
    rental price for Airbnb listings, you need to provide a dataset where each input
    is a listing with relevant characteristics (square footage, number of rooms, neighborhood,
    amenities, rating of that listing, etc.) and the associated output is the rental
    price of that listing. Once learned, this ML system should be able to predict
    the price of a new listing given its characteristics.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习系统来学习，必须有东西可以让它学习。在大多数情况下，机器学习系统从数据中学习。在监督学习中，基于示例输入和输出对，机器学习系统学习如何为任意输入生成输出。例如，如果你想构建一个机器学习系统来预测Airbnb房源的租金价格，你需要提供一个数据集，其中每个输入是一个带有相关特征的房源（面积、房间数、社区、设施、该房源的评级等），而相关输出是该房源的租金价格。一旦学习完成，这个机器学习系统应该能够预测新房源的价格，根据其特征。
- en: '*2\. Complex patterns*: there are patterns to learn, and they are complex'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*2\. 复杂模式*：有一些需要学习的模式，并且它们是复杂的。'
- en: ML solutions are only useful when there are patterns to learn. Sane people don’t
    invest money into building an ML system to predict the next outcome of a fair
    die because there’s no pattern in how these outcomes are generated.^([4](ch01.xhtml#ch01fn4))
    However, there are patterns in how stocks are priced, and therefore companies
    have invested billions of dollars in building ML systems to learn those patterns.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习解决方案仅在存在需要学习的模式时才有用。理智的人不会投入资金建立一个机器学习系统来预测公正骰子的下一个结果，因为这些结果的生成方式没有模式。^([4](ch01.xhtml#ch01fn4))
    然而，在股票定价方式中存在模式，因此公司已经投入数十亿美元建立机器学习系统来学习这些模式。
- en: Whether a pattern exists might not be obvious, or if patterns exist, your dataset
    or ML algorithms might not be sufficient to capture them. For example, there might
    be a pattern in how Elon Musk’s tweets affect cryptocurrency prices. However,
    you wouldn’t know until you’ve rigorously trained and evaluated your ML models
    on his tweets. Even if all your models fail to make reasonable predictions of
    cryptocurrency prices, it doesn’t mean there’s no pattern.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 是否存在模式可能并不明显，或者如果存在模式，你的数据集或机器学习算法可能不足以捕捉它们。例如，埃隆·马斯克的推文如何影响加密货币价格可能存在一种模式。但是，在对其推文进行严格训练和评估之前，你不会知道。即使你的所有模型都无法合理预测加密货币的价格，也并不意味着没有模式。
- en: Consider a website like Airbnb with a lot of house listings; each listing comes
    with a zip code. If you want to sort listings into the states they are located
    in, you wouldn’t need an ML system. Since the pattern is simple—each zip code
    corresponds to a known state—you can just use a lookup table.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个像Airbnb这样有大量房源的网站；每个房源都带有一个邮政编码。如果你想将房源按所在州进行分类，你不需要一个机器学习系统。因为模式很简单——每个邮政编码对应一个已知的州——你可以直接使用查找表。
- en: The relationship between a rental price and all its characteristics follows
    a much more complex pattern, which would be very challenging to manually specify.
    ML is a good solution for this. Instead of telling your system how to calculate
    the price from a list of characteristics, you can provide prices and characteristics,
    and let your ML system figure out the pattern. The difference between ML solutions
    and the lookup table solution as well as general traditional software solutions
    is shown in [Figure 1-2](#instead_of_requiring_hand_specified_pat). For this reason,
    ML is also called Software 2.0.^([5](ch01.xhtml#ch01fn5))
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 租金价格与其所有特征之间的关系遵循一种更为复杂的模式，手动指定将会非常具有挑战性。机器学习对此是一个很好的解决方案。与其告诉你的系统如何从特征列表计算价格，不如提供价格和特征，让你的机器学习系统找出这种模式。机器学习解决方案与查找表解决方案以及一般传统软件解决方案的不同之处在[图 1-2](#instead_of_requiring_hand_specified_pat)中有所展示。因此，机器学习也被称为软件2.0。^([5](ch01.xhtml#ch01fn5))
- en: ML has been very successful with tasks with complex patterns such as object
    detection and speech recognition. What is complex to machines is different from
    what is complex to humans. Many tasks that are hard for humans to do are easy
    for machines—for example, raising a number of the power of 10\. On the other hand,
    many tasks that are easy for humans can be hard for machines—for example, deciding
    whether there’s a cat in a picture.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ML在复杂模式任务（如目标检测和语音识别）上取得了很大成功。对机器而言复杂的东西与对人类而言复杂的东西是不同的。对人类来说难的任务对机器来说可能很容易，例如将一个数的幂乘以10。另一方面，对人类来说容易的任务对机器来说可能很难，比如判断一张图片中是否有猫。
- en: '![](Images/dmls_0102.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0102.png)'
- en: Figure 1-2\. Instead of requiring hand-specified patterns to calculate outputs,
    ML solutions learn patterns from inputs and outputs
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. ML解决方案不需要手动指定模式来计算输出，而是从输入和输出中学习模式。
- en: '*3\. Existing data*: data is available, or it’s possible to collect data'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*3\. 现有数据*：数据已经可用，或者可以收集数据。'
- en: Because ML learns from data, there must be data for it to learn from. It’s amusing
    to think about building a model to predict how much tax a person should pay a
    year, but it’s not possible unless you have access to tax and income data of a
    large population.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因为ML是从数据中学习的，所以必须有数据供其学习。想象一下建立一个模型来预测一个人应该每年缴纳多少税，这样的想法很有趣，但如果没有大量人群的税收和收入数据，这是不可能的。
- en: In the [zero-shot learning](https://oreil.ly/ZshSg) (sometimes known as zero-data
    learning) context, it’s possible for an ML system to make good predictions for
    a task without having been trained on data for that task. However, this ML system
    was previously trained on data for other tasks, often related to the task in consideration.
    So even though the system doesn’t require data for the task at hand to learn from,
    it still requires data to learn.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在[零样本学习](https://oreil.ly/ZshSg)（有时称为零数据学习）的背景下，ML系统有可能对一个任务进行良好的预测，而无需对该任务的数据进行训练。然而，这个ML系统之前是通过与考虑任务相关的其他任务的数据进行训练的。因此，即使该系统在处理当前任务时不需要数据来学习，它仍然需要数据来学习。
- en: It’s also possible to launch an ML system without data. For example, in the
    context of continual learning, ML models can be deployed without having been trained
    on any data, but they will learn from incoming data in production.^([6](ch01.xhtml#ch01fn6))
    However, serving insufficiently trained models to users comes with certain risks,
    such as poor customer experience.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以在没有数据的情况下启动一个ML系统。例如，在持续学习的背景下，ML模型可以在没有经过任何数据训练的情况下部署，但它们会从生产中的输入数据中学习。^([6](ch01.xhtml#ch01fn6))
    然而，向用户提供训练不足的模型会带来一定的风险，比如客户体验不佳。
- en: 'Without data and without continual learning, many companies follow a “fake-it-til-you
    make it” approach: launching a product that serves predictions made by humans,
    instead of ML models, with the hope of using the generated data to train ML models
    later.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 没有数据和持续学习的情况下，许多公司采用“假装直到成功”方法：推出一款由人类制定预测而非ML模型的产品，希望后续使用生成的数据来训练ML模型。
- en: '*4\. Predictions*: it’s a predictive problem'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*4\. 预测*：这是一个预测性问题。'
- en: ML models make predictions, so they can only solve problems that require predictive
    answers. ML can be especially appealing when you can benefit from a large quantity
    of cheap but approximate predictions. In English, “predict” means “estimate a
    value in the future.” For example, what will the weather be like tomorrow? Who
    will win the Super Bowl this year? What movie will a user want to watch next?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型进行预测，因此它们只能解决需要预测答案的问题。当你可以从大量廉价但近似的预测中获益时，ML尤其具有吸引力。在英语中，“预测”意味着“估计未来的值”。例如，明天的天气会是什么样？今年超级碗谁会赢？用户下一部想看的电影是什么？
- en: 'As predictive machines (e.g., ML models) are becoming more effective, more
    and more problems are being reframed as predictive problems. Whatever question
    you might have, you can always frame it as: “What would the answer to this question
    be?” regardless of whether this question is about something in the future, the
    present, or even the past.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 随着预测机器（例如ML模型）的效果越来越好，越来越多的问题被重新定义为预测问题。无论你问什么问题，你都可以将其表述为：“对于这个问题的答案是什么？”不管这个问题是关于未来、现在，甚至是过去的事情。
- en: 'Compute-intensive problems are one class of problems that have been very successfully
    reframed as predictive. Instead of computing the exact outcome of a process, which
    might be even more computationally costly and time-consuming than ML, you can
    frame the problem as: “What would the outcome of this process look like?” and
    approximate it using an ML model. The output will be an approximation of the exact
    output, but often, it’s good enough. You can see a lot of it in graphic renderings,
    such as image denoising and screen-space shading.^([7](ch01.xhtml#ch01fn7))'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 计算密集型问题是一类已经非常成功地重新定义为预测性问题的问题之一。与其计算过程的确切结果，这可能比机器学习更加计算昂贵和耗时，你可以将问题描述为：“这个过程的结果会是什么样？”并使用机器学习模型来近似它。输出将是确切输出的近似，但通常已经足够好了。你可以在图形渲染中看到很多这样的应用，比如图像去噪和屏幕空间阴影处理。^([7](ch01.xhtml#ch01fn7))
- en: '*5\. Unseen data*: unseen data shares patterns with the training data'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*5\. 未见数据*：未见数据与训练数据共享模式'
- en: The patterns your model learns from existing data are only useful if unseen
    data also share these patterns. A model to predict whether an app will get downloaded
    on Christmas 2020 won’t perform very well if it’s trained on data from 2008, when
    the most popular app on the App Store was Koi Pond. What’s Koi Pond? Exactly.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 模型从现有数据中学习的模式只有在未见数据也共享这些模式时才有用。一个预测应用程序在2020年圣诞节是否会被下载的模型，如果是基于2008年的数据训练的话，表现可能不会很好，当时App
    Store上最受欢迎的应用是Koi Pond。什么是Koi Pond？恰恰如此。
- en: 'In technical terms, it means your unseen data and training data should come
    from similar distributions. You might ask: “If the data is unseen, how do we know
    what distribution it comes from?” We don’t, but we can make assumptions—such as
    we can assume that users’ behaviors tomorrow won’t be too different from users’
    behaviors today—and hope that our assumptions hold. If they don’t, we’ll have
    a model that performs poorly, which we might be able to find out with monitoring,
    as covered in [Chapter 8](ch08.xhtml#data_distribution_shifts_and_monitoring),
    and test in production, as covered in [Chapter 9](ch09.xhtml#continual_learning_and_test_in_producti).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术角度来看，这意味着你的未见数据和训练数据应该来自相似的分布。你可能会问：“如果数据是未见的，我们怎么知道它来自哪个分布？”我们不知道，但我们可以做出假设——比如我们可以假设明天用户的行为不会与今天的行为有太大的不同——并希望我们的假设成立。如果它们不成立，我们将得到表现不佳的模型，我们可能可以通过监控发现，如第8章所述的[数据分布变化和监控](ch08.xhtml#data_distribution_shifts_and_monitoring)，以及在生产中进行测试，如第9章所述的[持续学习和在生产中进行测试](ch09.xhtml#continual_learning_and_test_in_producti)。
- en: 'Due to the way most ML algorithms today learn, ML solutions will especially
    shine if your problem has these additional following characteristics:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大多数机器学习算法今天的学习方式，机器学习解决方案尤其在以下这些额外特征的问题上表现突出：
- en: 6\. It’s repetitive
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. 它是重复的
- en: 'Humans are great at few-shot learning: you can show kids a few pictures of
    cats and most of them will recognize a cat the next time they see one. Despite
    exciting progress in few-shot learning research, most ML algorithms still require
    many examples to learn a pattern. When a task is repetitive, each pattern is repeated
    multiple times, which makes it easier for machines to learn it.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 人类在少样本学习方面表现出色：你可以向孩子们展示几张猫的图片，他们大多数人在下次看到猫时都会认出猫。尽管在少样本学习研究中取得了令人兴奋的进展，但大多数机器学习算法仍然需要许多例子来学习模式。当任务重复时，每个模式会被多次重复，这使得机器更容易学习它。
- en: 7\. The cost of wrong predictions is cheap
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 7\. 错误预测的成本很低
- en: Unless your ML model’s performance is 100% all the time, which is highly unlikely
    for any meaningful tasks, your model is going to make mistakes. ML is especially
    suitable when the cost of a wrong prediction is low. For example, one of the biggest
    use cases of ML today is in recommender systems because with recommender systems,
    a bad recommendation is usually forgiving—the user just won’t click on the recommendation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你的机器学习模型始终百分之百地表现良好，这对任何有意义的任务来说是高度不可能的，否则你的模型会犯错。机器学习在错误预测成本低的情况下特别适用。例如，今天机器学习最大的用例之一是在推荐系统中，因为在推荐系统中，一个糟糕的推荐通常是可以原谅的——用户只是不会点击推荐。
- en: If one prediction mistake can have catastrophic consequences, ML might still
    be a suitable solution if, on average, the benefits of correct predictions outweigh
    the cost of wrong predictions. Developing self-driving cars is challenging because
    an algorithmic mistake can lead to death. However, many companies still want to
    develop self-driving cars because they have the potential to save many lives once
    self-driving cars are statistically safer than human drivers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个预测错误可能会带来灾难性后果，那么如果正确预测的利益平均超过错误预测的成本，则机器学习可能仍然是一个合适的解决方案。开发自动驾驶汽车具有挑战性，因为算法错误可能导致死亡。然而，许多公司仍希望开发自动驾驶汽车，因为一旦自动驾驶汽车的安全性在统计上超过人类驾驶员，它们有可能拯救许多生命。
- en: 8\. It’s at scale
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 8\. 它是在规模上发生的
- en: ML solutions often require nontrivial up-front investment on data, compute,
    infrastructure, and talent, so it’d make sense if we can use these solutions a
    lot.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习解决方案通常需要对数据、计算、基础设施和人才进行非平凡的前期投资，因此如果我们能够大量使用这些解决方案，这是有道理的。
- en: “At scale” means different things for different tasks, but, in general, it means
    making a lot of predictions. Examples include sorting through millions of emails
    a year or predicting which departments thousands of support tickets should be
    routed to a day.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: “在规模上”对不同的任务意味着不同的事情，但总的来说，它意味着做出许多预测。例如，每年筛选数百万封电子邮件或预测每天将支持票据路由到哪些部门。
- en: A problem might appear to be a singular prediction, but it’s actually a series
    of predictions. For example, a model that predicts who will win a US presidential
    election seems like it only makes one prediction every four years, but it might
    actually be making a prediction every hour or even more frequently because that
    prediction has to be continually updated to incorporate new information.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个问题可能看起来是一个独立的预测，但实际上是一系列预测。例如，预测谁将赢得美国总统选举的模型似乎每四年只做一次预测，但实际上可能每小时甚至更频繁地做出预测，因为该预测必须不断更新以纳入新信息。
- en: Having a problem at scale also means that there’s a lot of data for you to collect,
    which is useful for training ML models.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在规模上存在问题还意味着有大量数据可以收集，这对于训练机器学习模型是有用的。
- en: 9\. The patterns are constantly changing
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 9\. 模式不断变化
- en: Cultures change. Tastes change. Technologies change. What’s trendy today might
    be old news tomorrow. Consider the task of email spam classification. Today an
    indication of a spam email is a Nigerian prince, but tomorrow it might be a distraught
    Vietnamese writer.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 文化在变化，口味在变化，技术在变化。今天流行的东西明天可能就过时了。考虑电子邮件垃圾邮件分类的任务。今天，垃圾邮件的指标是尼日利亚的王子，但明天可能是一个绝望的越南作家。
- en: If your problem involves one or more constantly changing patterns, hardcoded
    solutions such as handwritten rules can become outdated quickly. Figuring how
    your problem has changed so that you can update your handwritten rules accordingly
    can be too expensive or impossible. Because ML learns from data, you can update
    your ML model with new data without having to figure out how the data has changed.
    It’s also possible to set up your system to adapt to the changing data distributions,
    an approach we’ll discuss in the section [“Continual Learning”](ch09.xhtml#continual_learning).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的问题涉及一个或多个不断变化的模式，硬编码的解决方案，如手写规则，可能会很快过时。了解问题的变化，以便相应更新手写规则可能会非常昂贵或不可能。由于机器学习是从数据中学习的，您可以使用新数据更新您的机器学习模型，而无需弄清楚数据如何发生变化。还可以设置系统以适应不断变化的数据分布，这是我们将在[“持续学习”](ch09.xhtml#continual_learning)章节讨论的一种方法。
- en: 'The list of use cases can go on and on, and it’ll grow even longer as ML adoption
    matures in the industry. Even though ML can solve a subset of problems very well,
    it can’t solve and/or shouldn’t be used for a lot of problems. Most of today’s
    ML algorithms shouldn’t be used under any of the following conditions:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 用例列表可以继续延伸，并且随着工业中机器学习的成熟应用，它将变得更加庞大。尽管机器学习可以很好地解决一些问题的子集，但它不能解决和/或不应该用于许多问题。今天的大多数机器学习算法在以下任何情况下都不应使用：
- en: 'It’s unethical. We’ll go over one case study where the use of ML algorithms
    can be argued as unethical in the section [“Case study I: Automated grader’s biases”](ch11.xhtml#case_study_i_automated_graderapostrophe).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是不道德的。我们将在[“案例研究 I：自动评分器的偏见”](ch11.xhtml#case_study_i_automated_graderapostrophe)章节讨论一个案例研究，其中使用机器学习算法可能被认为是不道德的。
- en: Simpler solutions do the trick. In [Chapter 6](ch06.xhtml#model_development_and_offline_evaluatio),
    we’ll cover the four phases of ML model development where the first phase should
    be non-ML solutions.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更简单的解决方案能够达到预期效果。在[第6章](ch06.xhtml#model_development_and_offline_evaluatio)中，我们将介绍机器学习模型开发的四个阶段，其中第一个阶段应该是非机器学习解决方案。
- en: It’s not cost-effective.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它并非成本效益高。
- en: However, even if ML can’t solve your problem, it might be possible to break
    your problem into smaller components, and use ML to solve some of them. For example,
    if you can’t build a chatbot to answer all your customers’ queries, it might be
    possible to build an ML model to predict whether a query matches one of the frequently
    asked questions. If yes, direct the customer to the answer. If not, direct them
    to customer service.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，即使机器学习不能解决你的问题，也可能将问题分解为更小的组件，并使用机器学习解决其中的一些问题。例如，如果你无法建立一个能回答所有客户问题的聊天机器人，可能可以建立一个机器学习模型来预测是否有问题与经常问的问题之一相匹配。如果是，则引导客户查看答案。如果不是，则引导他们联系客服。
- en: I’d also want to caution against dismissing a new technology because it’s not
    as cost-effective as the existing technologies at the moment. Most technological
    advances are incremental. A type of technology might not be efficient now, but
    it might be over time with more investments. If you wait for the technology to
    prove its worth to the rest of the industry before jumping in, you might end up
    years or decades behind your competitors.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我也想警告不要因为一种新技术目前没有现有技术那样的成本效益而将其置之不理。大多数技术进步都是渐进的。一种技术现在可能效率不高，但随着更多投资的时间推移，可能会改善。如果你等待技术向整个行业证明其价值再入局，你可能会落后于竞争对手数年甚至数十年。
- en: Machine Learning Use Cases
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习应用案例
- en: ML has found increasing usage in both enterprise and consumer applications.
    Since the mid-2010s, there has been an explosion of applications that leverage
    ML to deliver superior or previously impossible services to consumers.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习在企业和消费者应用中的使用越来越广泛。自2010年中期以来，已经涌现出利用机器学习提供优越或以前不可能的服务的应用程序。
- en: With the explosion of information and services, it would have been very challenging
    for us to find what we want without the help of ML, manifested in either a *search
    engine* or a *recommender system*. When you visit a website like Amazon or Netflix,
    you’re recommended items that are predicted to best match your taste. If you don’t
    like any of your recommendations, you might want to search for specific items,
    and your search results are likely powered by ML.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 随着信息和服务的爆炸性增长，如果没有**机器学习**的帮助，无论是*搜索引擎*还是*推荐系统*，我们很难找到我们想要的东西。当你访问亚马逊或Netflix等网站时，系统会推荐最符合你口味的物品。如果你不喜欢推荐的任何物品，你可能会想要搜索特定的物品，而你的搜索结果很可能是由机器学习驱动的。
- en: If you have a smartphone, ML is likely already assisting you in many of your
    daily activities. Typing on your phone is made easier with *predictive typing*,
    an ML system that gives you suggestions on what you might want to say next. An
    ML system might run in your photo editing app to suggest how best to enhance your
    photos. You might authenticate your phone using your fingerprint or your face,
    which requires an ML system to predict whether a fingerprint or a face matches
    yours.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有智能手机，机器学习可能已经在许多日常活动中为你提供帮助。在手机上打字变得更容易，这得益于*预测输入*，一个机器学习系统会为你提供下一步可能要说的内容的建议。在你的照片编辑应用中可能运行的机器学习系统会建议如何最佳地增强你的照片。你可能使用你的指纹或面部进行手机认证，这需要一个机器学习系统来预测指纹或面部是否与你的匹配。
- en: The ML use case that drew me into the field was *machine translation*, automatically
    translating from one language to another. It has the potential to allow people
    from different cultures to communicate with each other, erasing the language barrier.
    My parents don’t speak English, but thanks to Google Translate, now they can read
    my writing and talk to my friends who don’t speak Vietnamese.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 吸引我进入这个领域的机器学习应用案例是*机器翻译*，自动将一种语言翻译为另一种语言。这有可能让来自不同文化的人们彼此交流，消除语言障碍。我的父母不会讲英语，但多亏了谷歌翻译，现在他们可以阅读我的文章并与不会讲越南语的朋友交流了。
- en: ML is increasingly present in our homes with smart personal assistants such
    as Alexa and Google Assistant. Smart security cameras can let you know when your
    pets leave home or if you have an uninvited guest. A friend of mine was worried
    about his aging mother living by herself—if she falls, no one is there to help
    her get up—so he relied on an at-home health monitoring system that predicts whether
    someone has fallen in the house.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ML 在我们的家中越来越普遍，例如智能个人助理如 Alexa 和 Google Assistant。智能安全摄像头可以在您的宠物离开家或有不速之客时通知您。我的一个朋友担心他独居的年迈母亲——如果她摔倒了，没人能及时帮助她起身——因此他依赖家庭健康监测系统，该系统可以预测是否有人在家中摔倒。
- en: Even though the market for consumer ML applications is booming, the majority
    of ML use cases are still in the enterprise world. Enterprise ML applications
    tend to have vastly different requirements and considerations from consumer applications.
    There are many exceptions, but for most cases, enterprise applications might have
    stricter accuracy requirements but be more forgiving with latency requirements.
    For example, improving a speech recognition system’s accuracy from 95% to 95.5%
    might not be noticeable to most consumers, but improving a resource allocation
    system’s efficiency by just 0.1% can help a corporation like Google or General
    Motors save millions of dollars. At the same time, latency of a second might get
    a consumer distracted and opening something else, but enterprise users might be
    more tolerant of high latency. For people interested in building companies out
    of ML applications, consumer apps might be easier to distribute but much harder
    to monetize. However, most enterprise use cases aren’t obvious unless you’ve encountered
    them yourself.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管消费者 ML 应用市场正在蓬勃发展，但大多数 ML 应用案例仍然在企业界。企业 ML 应用往往具有与消费者应用截然不同的需求和考虑因素。虽然也有很多例外，但大多数情况下，企业应用可能对精度要求更为严格，但在延迟要求方面更为宽容。例如，将语音识别系统的准确率从
    95% 提高到 95.5% 对大多数消费者来说可能无法察觉，但将资源分配系统的效率提高 0.1% 可帮助像 Google 或通用汽车这样的公司节省数百万美元。同时，一秒钟的延迟可能会让消费者分心并打开其他内容，但企业用户对高延迟可能更加宽容。对于有意从
    ML 应用构建公司的人来说，消费者应用可能更容易分发，但要实现盈利则要困难得多。然而，大多数企业用例除非您自己遇到过，否则不会显而易见。
- en: According to Algorithmia’s 2020 state of enterprise machine learning survey,
    ML applications in enterprises are diverse, serving both internal use cases (reducing
    costs, generating customer insights and intelligence, internal processing automation)
    and external use cases (improving customer experience, retaining customers, interacting
    with customers) as shown in [Figure 1-3](#twozerotwozero_state_of_enterprise_mach).^([8](ch01.xhtml#ch01fn8))
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Algorithmia 2020 年企业机器学习调查，企业中的 ML 应用多种多样，既服务于内部用例（降低成本、生成客户洞察和智能、内部处理自动化），也服务于外部用例（改善客户体验、保留客户、与客户互动），如[图 1-3](#twozerotwozero_state_of_enterprise_mach)所示。^([8](ch01.xhtml#ch01fn8))
- en: '![](Images/dmls_0103.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0103.png)'
- en: 'Figure 1-3\. 2020 state of enterprise machine learning. Source: Adapted from
    an image by Algorithmia'
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-3\. 2020 年企业机器学习现状。来源：Algorithmia 的一幅图像改编
- en: '*Fraud detection* is among the oldest applications of ML in the enterprise
    world. If your product or service involves transactions of any value, it’ll be
    susceptible to fraud. By leveraging ML solutions for anomaly detection, you can
    have systems that learn from historical fraud transactions and predict whether
    a future transaction is fraudulent.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*欺诈检测* 是企业世界中 ML 最古老的应用之一。如果您的产品或服务涉及任何价值的交易，它都可能受到欺诈的影响。通过利用 ML 解决方案进行异常检测，您可以建立从历史欺诈交易中学习并预测未来交易是否属于欺诈行为的系统。'
- en: Deciding how much to charge for your product or service is probably one of the
    hardest business decisions; why not let ML do it for you? *Price optimization*
    is the process of estimating a price at a certain time period to maximize a defined
    objective function, such as the company’s margin, revenue, or growth rate. ML-based
    pricing optimization is most suitable for cases with a large number of transactions
    where demand fluctuates and consumers are willing to pay a dynamic price—for example,
    internet ads, flight tickets, accommodation bookings, ride-sharing, and events.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 决定产品或服务的定价是可能是最难的商业决策之一；为什么不让 ML 为您做呢？*定价优化* 是在特定时间估算价格以最大化定义的目标函数的过程，例如公司的利润、收入或增长率。基于
    ML 的定价优化在交易数量大且需求波动，消费者愿意支付动态价格的情况下最为合适，例如互联网广告、机票、住宿预订、共享乘车和活动。
- en: To run a business, it’s important to be able to forecast customer demand so
    that you can prepare a budget, stock inventory, allocate resources, and update
    pricing strategy. For example, if you run a grocery store, you want to stock enough
    so that customers find what they’re looking for, but you don’t want to overstock,
    because if you do, your groceries might go bad and you lose money.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 经营业务时，能够预测客户需求非常重要，以便你可以准备预算、备货、分配资源和更新定价策略。例如，如果你经营一家杂货店，你希望备货足够，使顾客能够找到他们想要的东西，但你不希望库存过剩，因为如果过剩，你的食品可能会变质，导致损失。
- en: Acquiring a new user is expensive. As of 2019, the average cost for an app to
    acquire a user who’ll make an in-app purchase is $86.61.^([9](ch01.xhtml#ch01fn9))
    The acquisition cost for Lyft is estimated at $158/rider.^([10](ch01.xhtml#ch01fn10))
    This cost is so much higher for enterprise customers. Customer acquisition cost
    is hailed by investors as a startup killer.^([11](ch01.xhtml#ch01fn11)) Reducing
    customer acquisition costs by a small amount can result in a large increase in
    profit. This can be done through better identifying potential customers, showing
    better-targeted ads, giving discounts at the right time, etc.—all of which are
    suitable tasks for ML.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 获取新用户是昂贵的。截至2019年，应用程序获取进行应用内购买用户的平均成本为86.61美元。^([9](ch01.xhtml#ch01fn9)) Lyft的获取成本估计为每位乘客158美元。^([10](ch01.xhtml#ch01fn10))
    对于企业客户来说，这个成本要高得多。投资者认为客户获取成本是创业公司的杀手。^([11](ch01.xhtml#ch01fn11)) 减少客户获取成本即使是小幅度的改善，也能大幅增加利润。可以通过更好地识别潜在客户、展示更精准的广告、在正确的时间提供折扣等方式来实现这一目标，所有这些都是机器学习适合处理的任务。
- en: After you’ve spent so much money acquiring a customer, it’d be a shame if they
    leave. The cost of acquiring a new user is approximated to be 5 to 25 times more
    expensive than retaining an existing one.^([12](ch01.xhtml#ch01fn12)) *Churn prediction*
    is predicting when a specific customer is about to stop using your products or
    services so that you can take appropriate actions to win them back. Churn prediction
    can be used not only for customers but also for employees.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者一旦流失，你花费了大量资金吸引他们，这将是一件令人遗憾的事情。获取新用户的成本大约是保留现有用户的5到25倍。^([12](ch01.xhtml#ch01fn12))
    *流失预测* 是预测特定客户停止使用你的产品或服务的时间，以便你可以采取适当措施挽留他们。流失预测不仅可以用于客户，还可以用于员工。
- en: To prevent customers from leaving, it’s important to keep them happy by addressing
    their concerns as soon as they arise. Automated support ticket classification
    can help with that. Previously, when a customer opened a support ticket or sent
    an email, it needed to first be processed then passed around to different departments
    until it arrived at the inbox of someone who could address it. An ML system can
    analyze the ticket content and predict where it should go, which can shorten the
    response time and improve customer satisfaction. It can also be used to classify
    internal IT tickets.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止客户流失，通过及时解决他们的问题来保持他们的满意度非常重要。自动化支持票据分类可以帮助实现这一目标。以往，当客户打开支持票据或发送电子邮件时，需要先处理，然后传递到不同部门，直到到达能够处理它的人的收件箱。机器学习系统可以分析票据内容并预测应该送到何处，这可以缩短响应时间并提高客户满意度。它还可以用于分类内部IT票据。
- en: Another popular use case of ML in enterprise is brand monitoring. The brand
    is a valuable asset of a business.^([13](ch01.xhtml#ch01fn13)) It’s important
    to monitor how the public and your customers perceive your brand. You might want
    to know when/where/how it’s mentioned, both explicitly (e.g., when someone mentions
    “Google”) or implicitly (e.g., when someone says “the search giant”), as well
    as the sentiment associated with it. If there’s suddenly a surge of negative sentiment
    in your brand mentions, you might want to address it as soon as possible. Sentiment
    analysis is a typical ML task.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 企业中另一个流行的机器学习用例是品牌监控。品牌是企业的宝贵资产。^([13](ch01.xhtml#ch01fn13)) 监控公众和客户对品牌的感知非常重要。你可能想知道它何时/何地/如何被提及，无论是明确（例如，当有人提到“Google”时）还是隐含（例如，当有人说“搜索巨头”时），以及与之相关的情绪。如果你的品牌提及突然出现负面情绪，你可能希望尽快解决。情感分析是典型的机器学习任务。
- en: A set of ML use cases that has generated much excitement recently is in health
    care. There are ML systems that can detect skin cancer and diagnose diabetes.
    Even though many health-care applications are geared toward consumers, because
    of their strict requirements with accuracy and privacy, they are usually provided
    through a health-care provider such as a hospital or used to assist doctors in
    providing diagnosis.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 近期引起了很大兴奋的一组机器学习用例是在健康护理领域。有些机器学习系统可以检测皮肤癌和诊断糖尿病。尽管许多健康护理应用面向消费者，但由于其对准确性和隐私的严格要求，通常通过医院等健康护理提供者提供，或者用于协助医生提供诊断。
- en: Understanding Machine Learning Systems
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习系统
- en: Understanding ML systems will be helpful in designing and developing them. In
    this section, we’ll go over how ML systems are different from both ML in research
    (or as often taught in school) and traditional software, which motivates the need
    for this book.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 理解机器学习系统将有助于设计和开发它们。在本节中，我们将探讨机器学习系统如何与研究中的机器学习（或通常在学校中教授的机器学习）以及传统软件有所不同，从而推动了本书的需求。
- en: Machine Learning in Research Versus in Production
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 研究中与生产中的机器学习
- en: 'As ML usage in the industry is still fairly new, most people with ML expertise
    have gained it through academia: taking courses, doing research, reading academic
    papers. If that describes your background, it might be a steep learning curve
    for you to understand the challenges of deploying ML systems in the wild and navigate
    an overwhelming set of solutions to these challenges. ML in production is very
    different from ML in research. [Table 1-1](#key_differences_between_ml_in_research)
    shows five of the major differences.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 由于工业中的机器学习应用还相对较新，大多数具有机器学习专业知识的人都是通过学术途径获得的：参加课程、进行研究、阅读学术论文。如果您的背景符合这种描述，了解如何在实际环境中部署机器学习系统的挑战，以及应对这些挑战的解决方案可能是一个陡峭的学习曲线。在生产中的机器学习与研究中的机器学习有很大不同。[表1-1](#key_differences_between_ml_in_research)显示了这些主要区别中的五个。
- en: Table 1-1\. Key differences between ML in research and ML in production
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-1\. 研究中的机器学习与生产中的机器学习的主要区别
- en: '|   | Research | Production |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|   | 研究 | 生产 |'
- en: '| --- | --- | --- |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Requirements | State-of-the-art model performance on benchmark datasets |
    Different stakeholders have different requirements |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 要求 | 基准数据集上的最先进模型性能 | 不同的利益相关者有不同的要求 |'
- en: '| Computational priority | Fast training, high throughput | Fast inference,
    low latency |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 计算优先级 | 快速训练，高吞吐量 | 快速推理，低延迟 |'
- en: '| Data | Static^([a](ch01.xhtml#ch01fn14)) | Constantly shifting |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 数据 | 静态^([a](ch01.xhtml#ch01fn14)) | 不断变化的 |'
- en: '| Fairness | Often not a focus | Must be considered |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 公平性 | 通常不是重点 | 必须考虑 |'
- en: '| Interpretability | Often not a focus | Must be considered |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 可解释性 | 通常不是重点 | 必须考虑 |'
- en: '| ^([a](ch01.xhtml#ch01fn14-marker)) A subfield of research focuses on continual
    learning: developing models to work with changing data distributions. We’ll cover
    continual learning in [Chapter 9](ch09.xhtml#continual_learning_and_test_in_producti).
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| ^([a](ch01.xhtml#ch01fn14-marker)) 研究的一个子领域专注于持续学习：开发能够处理不断变化的数据分布的模型。我们将在[第9章](ch09.xhtml#continual_learning_and_test_in_producti)中介绍持续学习。
    |'
- en: Different stakeholders and requirements
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不同的利益相关者和需求
- en: People involved in a research and leaderboard project often align on one single
    objective. The most common objective is model performance—develop a model that
    achieves the state-of-the-art results on benchmark datasets. To edge out a small
    improvement in performance, researchers often resort to techniques that make models
    too complex to be useful.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 参与研究和排行榜项目的人通常会对一个共同的目标进行调整。最常见的目标是模型性能：开发一个能在基准数据集上达到最先进结果的模型。为了在性能上稍微提升，研究人员经常会采用使模型过于复杂而无法实用的技术。
- en: There are many stakeholders involved in bringing an ML system into production.
    Each stakeholder has their own requirements. Having different, often conflicting,
    requirements can make it difficult to design, develop, and select an ML model
    that satisfies all the requirements.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 许多利益相关者参与将机器学习系统投入生产。每个利益相关者都有自己的要求。有不同的、经常相互冲突的要求可能会使得设计、开发和选择能够满足所有要求的机器学习模型变得困难。
- en: 'Consider a mobile app that recommends restaurants to users. The app makes money
    by charging restaurants a 10% service fee on each order. This means that expensive
    orders give the app more money than cheap orders. The project involves ML engineers,
    salespeople, product managers, infrastructure engineers, and a manager:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个移动应用程序，为用户推荐餐馆。该应用通过每笔订单向餐馆收取 10% 的服务费来赚钱。这意味着昂贵的订单比便宜的订单为应用带来更多的收入。该项目涉及到机器学习工程师、销售人员、产品经理、基础设施工程师和一位经理：
- en: ML engineers
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习工程师
- en: Want a model that recommends restaurants that users will most likely order from,
    and they believe they can do so by using a more complex model with more data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 希望有一个推荐用户最可能下单的餐馆的模型，并且他们相信可以通过使用更复杂的模型和更多的数据来实现这一目标。
- en: Sales team
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 销售团队
- en: Wants a model that recommends the more expensive restaurants since these restaurants
    bring in more service fees.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 希望有一个推荐昂贵餐馆的模型，因为这些餐馆带来更多的服务费。
- en: Product team
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 产品团队
- en: Notices that every increase in latency leads to a drop in orders through the
    service, so they want a model that can return the recommended restaurants in less
    than 100 milliseconds.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到每次延迟增加都会导致服务订单量的下降，因此他们希望有一个能在少于 100 毫秒内返回推荐餐馆的模型。
- en: ML platform team
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ML 平台团队
- en: As the traffic grows, this team has been woken up in the middle of the night
    because of problems with scaling their existing system, so they want to hold off
    on model updates to prioritize improving the ML platform.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 随着流量增长，这个团队因为现有系统扩展问题在半夜被唤醒，因此他们希望暂停模型更新，优先改进机器学习平台。
- en: Manager
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 经理
- en: Wants to maximize the margin, and one way to achieve this might be to let go
    of the ML team.^([14](ch01.xhtml#ch01fn15))
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 希望最大化利润率，可能的一种方法是放弃机器学习团队。^([14](ch01.xhtml#ch01fn15))
- en: '“Recommending the restaurants that users are most likely to click on” and “recommending
    the restaurants that will bring in the most money for the app” are two different
    objectives, and in the section [“Decoupling objectives”](ch02.xhtml#decoupling_objectives),
    we’ll discuss how to develop an ML system that satisfies different objectives.
    Spoiler: we’ll develop one model for each objective and combine their predictions.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: “推荐用户最有可能点击的餐馆”和“推荐给应用带来最多收入的餐馆”是两个不同的目标，在 [“解耦目标”](ch02.xhtml#decoupling_objectives)
    部分中，我们将讨论如何开发一个满足不同目标的机器学习系统。剧透：我们将为每个目标开发一个模型，并结合它们的预测结果。
- en: 'Let’s imagine for now that we have two different models. Model A is the model
    that recommends the restaurants that users are most likely to click on, and model
    B is the model that recommends the restaurants that will bring in the most money
    for the app. A and B might be very different models. Which model should be deployed
    to the users? To make the decision more difficult, neither A nor B satisfies the
    requirement set forth by the product team: they can’t return restaurant recommendations
    in less than 100 milliseconds.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们假设有两个不同的模型。模型 A 是推荐用户最有可能点击的餐馆的模型，模型 B 是推荐给应用带来最多收入的餐馆的模型。A 和 B 可能是非常不同的模型。应该将哪个模型部署给用户？为了使决策更加困难，A
    和 B 都不能满足产品团队提出的要求：它们无法在少于 100 毫秒内返回餐馆推荐。
- en: When developing an ML project, it’s important for ML engineers to understand
    requirements from all stakeholders involved and how strict these requirements
    are. For example, if being able to return recommendations within 100 milliseconds
    is a must-have requirement—the company finds that if your model takes over 100
    milliseconds to recommend restaurants, 10% of users would lose patience and close
    the app—then neither model A nor model B will work. However, if it’s just a nice-to-have
    requirement, you might still want to consider model A or model B.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发机器学习项目时，机器学习工程师理解所有利益相关者的需求及其严格程度非常重要。例如，如果能够在 100 毫秒内返回推荐餐馆是一个必须要求——公司发现如果您的模型需要超过
    100 毫秒来推荐餐馆，将有 10% 的用户会失去耐心并关闭应用——那么模型 A 和模型 B 都无法胜任。然而，如果这只是一个不错的要求，您可能仍然需要考虑模型
    A 或模型 B。
- en: Production having different requirements from research is one of the reasons
    why successful research projects might not always be used in production. For example,
    ensembling is a technique popular among the winners of many ML competitions, including
    the famed $1 million Netflix Prize, and yet it’s not widely used in production.
    Ensembling combines “multiple learning algorithms to obtain better predictive
    performance than could be obtained from any of the constituent learning algorithms
    alone.”^([15](ch01.xhtml#ch01fn16)) While it can give your ML system a small performance
    improvement, ensembling tends to make a system too complex to be useful in production,
    e.g., slower to make predictions or harder to interpret the results. We’ll discuss
    ensembling further in the section [“Ensembles”](ch06.xhtml#ensembles).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 生产对研究的不同要求之一是成功的研究项目可能并不总是用于生产。例如，集成是一种在许多机器学习竞赛（包括著名的100万美元Netflix奖）的获胜者中流行的技术，但在生产中并不广泛使用。集成结合了“多种学习算法，以获得比单独任何学习算法更好的预测性能。”^([15](ch01.xhtml#ch01fn16))
    尽管它可以使您的机器学习系统稍微提升性能，但集成往往会使系统过于复杂，难以在生产中使用，例如，预测速度较慢或结果解释较困难。我们将在“集成”章节中进一步讨论集成。
- en: For many tasks, a small improvement in performance can result in a huge boost
    in revenue or cost savings. For example, a 0.2% improvement in the click-through
    rate for a product recommender system can result in millions of dollars increase
    in revenue for an ecommerce site. However, for many tasks, a small improvement
    might not be noticeable for users. For the second type of task, if a simple model
    can do a reasonable job, complex models must perform significantly better to justify
    the complexity.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多任务，性能的微小改进可能会导致收入大幅提升或成本节约。例如，产品推荐系统的点击率提升0.2%可能会使电子商务网站的收入增加数百万美元。然而，对于许多任务来说，微小的改进可能用户察觉不到。对于第二类任务，如果一个简单模型能够做出合理的预测，复杂模型必须有显著更好的表现来证明其复杂性是合理的。
- en: Computational priorities
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算优先级
- en: When designing an ML system, people who haven’t deployed an ML system often
    make the mistake of focusing too much on the model development part and not enough
    on the model deployment and maintenance part.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计机器学习系统时，没有部署过机器学习系统的人经常犯的错误是过于专注于模型开发部分，而忽视了模型部署和维护部分。
- en: During the model development process, you might train many different models,
    and each model does multiple passes over the training data. Each trained model
    then generates predictions on the validation data once to report the scores. The
    validation data is usually much smaller than the training data. During model development,
    training is the bottleneck. Once the model has been deployed, however, its job
    is to generate predictions, so inference is the bottleneck. Research usually prioritizes
    fast training, whereas production usually prioritizes fast inference.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型开发过程中，您可能会训练多个不同的模型，每个模型对训练数据进行多次遍历。然后，每个训练好的模型会对验证数据进行一次预测以报告分数。验证数据通常比训练数据要小得多。在模型开发阶段，训练是瓶颈。然而，一旦模型部署完成，它的工作就是生成预测，因此推断会成为瓶颈。研究通常优先考虑快速训练，而生产通常优先考虑快速推断。
- en: One corollary of this is that research prioritizes high throughput whereas production
    prioritizes low latency. In case you need a refresh, latency refers to the time
    it takes from receiving a query to returning the result. Throughput refers to
    how many queries are processed within a specific period of time.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 其一个推论是，研究优先考虑高吞吐量，而生产则优先考虑低延迟。如果需要刷新记忆，延迟是指从接收查询到返回结果所需的时间。吞吐量是指在特定时间段内处理多少查询。
- en: Terminology Clash
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语冲突
- en: 'Some books make the distinction between latency and response time. According
    to Martin Kleppmann in his book *Designing Data-Intensive Applications*, “The
    response time is what the client sees: besides the actual time to process the
    request (the service time), it includes network delays and queueing delays. Latency
    is the duration that a request is waiting to be handled—during which it is latent,
    awaiting service.”^([19](ch01.xhtml#custom_ch01fn1))'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有些书籍区分延迟和响应时间。根据马丁·克莱普曼在他的书《设计数据密集型应用》中的说法，“响应时间是客户看到的时间：除了处理请求的实际时间（服务时间）外，还包括网络延迟和排队延迟。延迟是请求等待处理的持续时间——在此期间它处于潜伏状态，等待服务。”^([19](ch01.xhtml#custom_ch01fn1))
- en: In this book, to simplify the discussion and to be consistent with the terminology
    used in the ML community, we use latency to refer to the response time, so the
    latency of a request measures the time from when the request is sent to the time
    a response is received.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，为了简化讨论并与机器学习社区使用的术语保持一致，我们使用延迟来指代响应时间，因此请求的延迟测量从发送请求到接收响应的时间。
- en: For example, the average latency of Google Translate is the average time it
    takes from when a user clicks Translate to when the translation is shown, and
    the throughput is how many queries it processes and serves a second.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Google翻译的平均延迟是用户点击翻译按钮到显示翻译结果的平均时间，而吞吐量则是处理和提供的查询数量。
- en: If your system always processes one query at a time, higher latency means lower
    throughput. If the average latency is 10 ms, which means it takes 10 ms to process
    a query, the throughput is 100 queries/second. If the average latency is 100 ms,
    the throughput is 10 queries/second.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的系统始终一次处理一个查询，更高的延迟意味着更低的吞吐量。如果平均延迟为10毫秒，这意味着处理一个查询需要10毫秒，吞吐量为每秒处理100个查询。如果平均延迟为100毫秒，吞吐量为每秒处理10个查询。
- en: However, because most modern distributed systems batch queries to process them
    together, often concurrently, *higher latency might also mean higher throughput*.
    If you process 10 queries at a time and it takes 10 ms to run a batch, the average
    latency is still 10 ms but the throughput is now 10 times higher—1,000 queries/second.
    If you process 50 queries at a time and it takes 20 ms to run a batch, the average
    latency now is 20 ms and the throughput is 2,500 queries/second. Both latency
    and throughput have increased! The difference in latency and throughput trade-off
    for processing queries one at a time and processing queries in batches is illustrated
    in [Figure 1-4](#when_processing_queries_one_at_a_timeco).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于大多数现代分布式系统会批量处理查询以并行处理，*更高的延迟也可能意味着更高的吞吐量*。如果每次处理10个查询，每个批次运行时间为10毫秒，则平均延迟仍为10毫秒，但吞吐量现在提高了10倍——每秒1,000个查询。如果每次处理50个查询，每个批次运行时间为20毫秒，则平均延迟现在为20毫秒，吞吐量为每秒2,500个查询。延迟和吞吐量都得到了提高！处理逐个查询和批量处理查询时的延迟和吞吐量权衡差异如图[1-4](#when_processing_queries_one_at_a_timeco)所示。
- en: '![](Images/dmls_0104.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0104.png)'
- en: Figure 1-4\. When processing queries one at a time, higher latency means lower
    throughput. When processing queries in batches, however, higher latency might
    also mean higher throughput.
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. 当逐个处理查询时，更高的延迟意味着更低的吞吐量。然而，当批量处理查询时，更高的延迟也可能意味着更高的吞吐量。
- en: This is even more complicated if you want to batch online queries. Batching
    requires your system to wait for enough queries to arrive in a batch before processing
    them, which further increases latency.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要批量处理在线查询，情况就更加复杂了。批处理要求系统在足够的查询到达以前等待，然后才能处理，这会进一步增加延迟。
- en: In research, you care more about how many samples you can process in a second
    (throughput) and less about how long it takes for each sample to be processed
    (latency). You’re willing to increase latency to increase throughput, for example,
    with aggressive batching.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究中，你更关心每秒能处理多少样本（吞吐量），而不是每个样本处理需要多长时间（延迟）。你愿意增加延迟以提高吞吐量，例如采用积极的批处理方式。
- en: However, once you deploy your model into the real world, latency matters a lot.
    In 2017, an Akamai study found that a 100 ms delay can hurt conversion rates by
    7%.^([20](ch01.xhtml#ch01fn20)) In 2019, Booking.com found that an increase of
    about 30% in latency cost about 0.5% in conversion rates—“a relevant cost for
    our business.”^([21](ch01.xhtml#ch01fn21)) In 2016, Google found that more than
    half of mobile users will leave a page if it takes more than three seconds to
    load.^([22](ch01.xhtml#ch01fn22)) Users today are even less patient.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一旦你将模型部署到真实世界中，延迟就非常重要了。2017年，Akamai的一项研究发现，100毫秒的延迟可以使转化率下降7%。^([20](ch01.xhtml#ch01fn20))
    2019年，Booking.com发现，延迟增加约30%，转化率会降低约0.5%——“这对我们的业务来说是一个相关成本。”^([21](ch01.xhtml#ch01fn21))
    2016年，Google发现，超过一半的移动用户如果页面加载时间超过三秒，就会离开页面。^([22](ch01.xhtml#ch01fn22)) 如今的用户更加缺乏耐心。
- en: To reduce latency in production, you might have to reduce the number of queries
    you can process on the same hardware at a time. If your hardware is capable of
    processing many more queries at a time, using it to process fewer queries means
    underutilizing your hardware, increasing the cost of processing each query.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 要减少生产中的延迟，你可能需要减少同时处理的查询数量。如果你的硬件能够同时处理更多的查询，而现在却使用它来处理更少的查询，这意味着你在低效地使用你的硬件，增加了每个查询的处理成本。
- en: When thinking about latency, it’s important to keep in mind that latency is
    not an individual number but a distribution. It’s tempting to simplify this distribution
    by using a single number like the average (arithmetic mean) latency of all the
    requests within a time window, but this number can be misleading. Imagine you
    have 10 requests whose latencies are 100 ms, 102 ms, 100 ms, 100 ms, 99 ms, 104
    ms, 110 ms, 90 ms, 3,000 ms, 95 ms. The average latency is 390 ms, which makes
    your system seem slower than it actually is. What might have happened is that
    there was a network error that made one request much slower than others, and you
    should investigate that troublesome request.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑延迟时，重要的是要记住延迟不是一个单一的数字，而是一个分布。使用像平均延迟（算术平均值）这样的单一数字来简化这个分布是很诱人的，但这个数字可能会误导。想象一下，你有10个请求，它们的延迟分别为100毫秒、102毫秒、100毫秒、100毫秒、99毫秒、104毫秒、110毫秒、90毫秒、3,000毫秒、95毫秒。平均延迟为390毫秒，这使得你的系统看起来比实际慢。可能发生的情况是，存在一个网络错误，导致一个请求比其他请求慢得多，你应该调查这个有问题的请求。
- en: It’s usually better to think in percentiles, as they tell you something about
    a certain percentage of your requests. The most common percentile is the 50th
    percentile, abbreviated as p50\. It’s also known as the median. If the median
    is 100 ms, half of the requests take longer than 100 ms, and half of the requests
    take less than 100 ms.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通常最好考虑百分位数，因为它们告诉你有关某个百分比请求的信息。最常见的百分位数是第50百分位数，缩写为p50。它也称为中位数。如果中位数是100毫秒，那么一半的请求耗时超过100毫秒，另一半的请求耗时少于100毫秒。
- en: Higher percentiles also help you discover outliers, which might be symptoms
    of something wrong. Typically, the percentiles you’ll want to look at are p90,
    p95, and p99\. The 90th percentile (p90) for the 10 requests above is 3,000 ms,
    which is an outlier.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 更高的百分位数还帮助你发现异常值，这可能是某些问题的症状。通常你需要关注的百分位数是p90、p95和p99。前10个请求的第90百分位数（p90）为3,000毫秒，这是一个异常值。
- en: Higher percentiles are important to look at because even though they account
    for a small percentage of your users, sometimes they can be the most important
    users. For example, on the Amazon website, the customers with the slowest requests
    are often those who have the most data on their accounts because they have made
    many purchases—that is, they’re the most valuable customers.^([23](ch01.xhtml#ch01fn23))
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 更高的百分位数是重要的，因为即使它们只占你用户的一小部分，有时它们可能是最重要的用户。例如，在亚马逊网站上，最慢请求的客户通常是那些在其账户上有大量数据的客户，因为他们已经进行了多次购买——也就是说，他们是最有价值的客户。^([23](ch01.xhtml#ch01fn23))
- en: It’s a common practice to use high percentiles to specify the performance requirements
    for your system; for example, a product manager might specify that the 90th percentile
    or 99.9th percentile latency of a system must be below a certain number.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用高百分位数来指定系统的性能要求是一种常见做法；例如，产品经理可能会规定系统的第90百分位数或第99.9百分位数的延迟必须低于某个数值。
- en: Data
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: During the research phase, the datasets you work with are often clean and well-formatted,
    freeing you to focus on developing models. They are static by nature so that the
    community can use them to benchmark new architectures and techniques. This means
    that many people might have used and discussed the same datasets, and quirks of
    the dataset are known. You might even find open source scripts to process and
    feed the data directly into your models.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究阶段，你处理的数据集通常是干净且格式良好的，这使你能够专注于开发模型。它们本质上是静态的，因此社区可以用它们来评估新的架构和技术。这意味着许多人可能已经使用和讨论了相同的数据集，数据集的怪异之处是众所周知的。你甚至可能会找到开源脚本来直接处理和提供数据给你的模型。
- en: 'In production, data, if available, is a lot more messy. It’s noisy, possibly
    unstructured, constantly shifting. It’s likely biased, and you likely don’t know
    how it’s biased. Labels, if there are any, might be sparse, imbalanced, or incorrect.
    Changing project or business requirements might require updating some or all of
    your existing labels. If you work with users’ data, you’ll also have to worry
    about privacy and regulatory concerns. We’ll discuss a case study where users’
    data is inadequately handled in the section [“Case study II: The danger of “anonymized”
    data”](ch11.xhtml#case_study_ii_the_danger_of_quotation_m).'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，如果数据可用，它会更加混乱。它可能会有噪声，可能是非结构化的，不断变化的。它可能存在偏见，而你可能不知道它是如何偏见的。如果有标签，它们可能稀疏、不平衡或不正确。项目或业务要求的变化可能需要更新一些或所有现有标签。如果你处理用户数据，你还需要担心隐私和监管问题。我们将在章节[“案例研究二：‘匿名’数据的危险”](ch11.xhtml#case_study_ii_the_danger_of_quotation_m)中讨论一个案例研究，在这个案例中用户数据被不适当地处理。
- en: In research, you mostly work with historical data, e.g., data that already exists
    and is stored somewhere. In production, most likely you’ll also have to work with
    data that is being constantly generated by users, systems, and third-party data.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究中，你主要处理历史数据，例如已经存在并存储在某处的数据。在生产中，很可能你也需要处理由用户、系统和第三方数据不断生成的数据。
- en: '[Figure 1-5](#data_in_research_versus_data_in_product) has been adapted from
    a great graphic by Andrej Karpathy, director of AI at Tesla, that illustrates
    the data problems he encountered during his PhD compared to his time at Tesla.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1-5](#data_in_research_versus_data_in_product) 参考了特斯拉人工智能主管安德烈·卡帕斯的一张精彩图表，该图展示了他在博士期间与在特斯拉任职期间遇到的数据问题的对比。'
- en: '![](Images/dmls_0105.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dmls_0105.png)'
- en: 'Figure 1-5\. Data in research versus data in production. Source: Adapted from
    an image by Andrej Karpathy^([24](ch01.xhtml#ch01fn24))'
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5。研究中的数据与生产中的数据。来源：改编自安德烈·卡帕斯的一幅图像^([24](ch01.xhtml#ch01fn24))
- en: Fairness
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 公平性
- en: 'During the research phase, a model is not yet used on people, so it’s easy
    for researchers to put off fairness as an afterthought: “Let’s try to get state
    of the art first and worry about fairness when we get to production.” When it
    gets to production, it’s too late. If you optimize your models for better accuracy
    or lower latency, you can show that your models beat state of the art. But, as
    of writing this book, there’s no equivalent state of the art for fairness metrics.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究阶段，模型尚未用于人员，所以研究人员很容易将公平性推迟为事后事项：“我们先尝试获得最先进的技术，等到生产阶段再考虑公平性。”当进入生产阶段时，已经为时过晚。如果你优化模型以获得更高的准确性或更低的延迟，你可以证明你的模型超越了最先进技术。但是，截至撰写本书时，公平性指标尚无对应的最先进技术。
- en: You or someone in your life might already be a victim of biased mathematical
    algorithms without knowing it. Your loan application might be rejected because
    the ML algorithm picks on your zip code, which embodies biases about one’s socioeconomic
    background. Your resume might be ranked lower because the ranking system employers
    use picks on the spelling of your name. Your mortgage might get a higher interest
    rate because it relies partially on credit scores, which favor the rich and punish
    the poor. Other examples of ML biases in the real world are in predictive policing
    algorithms, personality tests administered by potential employers, and college
    rankings.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你或者你生活中的某人可能已经是数学算法偏见的受害者，却并不自知。由于机器学习算法可能因为你的邮政编码而拒绝你的贷款申请，这反映了对某人社会经济背景偏见的偏见。你的简历可能因为雇主使用的排名系统偏重你姓名的拼写而排名较低。你的抵押贷款可能会因为部分依赖信用评分，这有利于富人而损害穷人而获得更高的利率。在现实世界中，机器学习偏见的其他例子包括预测性执法算法、潜在雇主进行的人格测试以及大学排名。
- en: In 2019, “Berkeley researchers found that both face-to-face and online lenders
    rejected a total of 1.3 million creditworthy Black and Latino applicants between
    2008 and 2015.” When the researchers “used the income and credit scores of the
    rejected applications but deleted the race identifiers, the mortgage application
    was accepted.”^([25](ch01.xhtml#ch01fn25)) For even more galling examples, I recommend
    Cathy O’Neil’s *Weapons of Math Destruction*.^([26](ch01.xhtml#ch01fn26))
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在2019年，“伯克利研究人员发现，从2008年到2015年，面对面和在线借款人共同拒绝了130万名有信用的黑人和拉丁裔申请人。”当研究人员“使用被拒申请的收入和信用评分，但删除了种族识别符时，抵押贷款申请被接受。”^([25](ch01.xhtml#ch01fn25))
    更令人愤慨的例子，请参阅凯西·奥尼尔的《*数学毁灭之武器*》。^([26](ch01.xhtml#ch01fn26))
- en: ML algorithms don’t predict the future, but encode the past, thus perpetuating
    the biases in the data and more. When ML algorithms are deployed at scale, they
    can discriminate against people at scale. If a human operator might only make
    sweeping judgments about a few individuals at a time, an ML algorithm can make
    sweeping judgments about millions in split seconds. This can especially hurt members
    of minority groups because misclassification on them could only have a minor effect
    on models’ overall performance metrics.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法不是预测未来，而是编码过去，因此会延续数据中的偏见等问题。当机器学习算法大规模部署时，它们可以在大规模范围内歧视人群。如果一个人类操作员可能一次只对少数个体做出全面的判断，机器学习算法可以在几秒钟内对数百万人做出全面的判断。这可能特别伤害少数群体的成员，因为对他们的误分类可能只对模型整体性能指标产生较小的影响。
- en: If an algorithm can already make correct predictions on 98% of the population,
    and improving the predictions on the other 2% would incur multiples of cost, some
    companies might, unfortunately, choose not to do it. During a McKinsey & Company
    research study in 2019, only 13% of the large companies surveyed said they are
    taking steps to mitigate risks to equity and fairness, such as algorithmic bias
    and discrimination.^([27](ch01.xhtml#ch01fn27)) However, this is changing rapidly.
    We’ll cover fairness and other aspects of responsible AI in [Chapter 11](ch11.xhtml#the_human_side_of_machine_learning).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果算法已经可以在98%的人群上做出正确的预测，而在其他2%上改进预测将带来多倍的成本，一些公司可能会不幸选择不这样做。在2019年的麦肯锡公司研究中，只有13%的受访大公司表示他们正在采取措施减少公平和公正风险，如算法偏见和歧视。^([27](ch01.xhtml#ch01fn27))
    然而，这种情况正在迅速改变。我们将在[第11章](ch11.xhtml#the_human_side_of_machine_learning)中讨论公平性和其他责任人工智能的方面。
- en: Interpretability
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**可解释性**'
- en: In early 2020, the Turing Award winner Professor Geoffrey Hinton proposed a
    heatedly debated question about the importance of interpretability in ML systems.
    “Suppose you have cancer and you have to choose between a black box AI surgeon
    that cannot explain how it works but has a 90% cure rate and a human surgeon with
    an 80% cure rate. Do you want the AI surgeon to be illegal?”^([28](ch01.xhtml#ch01fn28))
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在2020年初，图灵奖得主Geoffrey Hinton教授提出了一个备受争议的问题，即解释性在机器学习系统中的重要性：“假设你患有癌症，你必须在一个不能解释其工作原理但治愈率为90%的黑匣子人工智能外科医生和治愈率为80%的人类外科医生之间做出选择，你希望这种AI外科医生被禁止吗？”^([28](ch01.xhtml#ch01fn28))
- en: A couple of weeks later, when I asked this question to a group of 30 technology
    executives at public nontech companies, only half of them would want the highly
    effective but unable-to-explain AI surgeon to operate on them. The other half
    wanted the human surgeon.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 几周后，当我向一群30位公共非技术公司的技术高管提出这个问题时，只有一半的人希望能让高效但无法解释的AI外科医生为他们进行手术。另一半希望是人类外科医生。
- en: While most of us are comfortable with using a microwave without understanding
    how it works, many don’t feel the same way about AI yet, especially if that AI
    makes important decisions about their lives.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大多数人在使用微波炉时不必了解其工作原理，但对于人工智能，特别是如果该人工智能做出对他们生活重要的决策，很多人仍然感到不安。
- en: Since most ML research is still evaluated on a single objective, model performance,
    researchers aren’t incentivized to work on model interpretability. However, interpretability
    isn’t just optional for most ML use cases in the industry, but a requirement.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大多数机器学习研究仍然只在单一目标——模型性能上进行评估，研究人员没有动力去研究模型的可解释性。然而，对于工业界大多数机器学习应用案例而言，解释性不仅是可选的，而是一个必要条件。
- en: First, interpretability is important for users, both business leaders and end
    users, to understand why a decision is made so that they can trust a model and
    detect potential biases mentioned previously.^([29](ch01.xhtml#ch01fn29)) Second,
    it’s important for developers to be able to debug and improve a model.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，对于用户来说，包括业务领导和最终用户，解释性对于理解为何做出某个决策至关重要，这样他们可以信任模型并发现前述潜在偏见的存在。^([29](ch01.xhtml#ch01fn29))
    其次，对于开发人员来说，能够调试和改进模型也非常重要。
- en: Just because interpretability is a requirement doesn’t mean everyone is doing
    it. As of 2019, only 19% of large companies are working to improve the explainability
    of their algorithms.^([30](ch01.xhtml#ch01fn30))
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 仅因为解释性是一个要求，并不意味着每个人都在实施。截至2019年，只有19%的大公司正在努力提高其算法的可解释性。^([30](ch01.xhtml#ch01fn30))
- en: Discussion
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: Some might argue that it’s OK to know only the academic side of ML because there
    are plenty of jobs in research. The first part—it’s OK to know only the academic
    side of ML—is true. The second part is false.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 有人可能会认为，仅了解机器学习的学术方面是可以的，因为研究领域有很多工作。第一部分——仅了解机器学习的学术方面是可以的——是正确的。而第二部分是错误的。
- en: While it’s important to pursue pure research, most companies can’t afford it
    unless it leads to short-term business applications. This is especially true now
    that the research community took the “bigger, better” approach. Oftentimes, new
    models require a massive amount of data and tens of millions of dollars in compute
    alone.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管追求纯粹的研究很重要，但大多数公司无法负担，除非它能带来短期的商业应用。现在研究界采取了“更大，更好”的方法，尤其如此。往往，新模型需要大量数据和数千万美元的计算成本。
- en: As ML research and off-the-shelf models become more accessible, more people
    and organizations would want to find applications for them, which increases the
    demand for ML in production.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习研究和现成模型变得更加可访问，越来越多的人和组织将希望找到它们的应用程序，这增加了对生产中机器学习的需求。
- en: The vast majority of ML-related jobs will be, and already are, in productionizing
    ML.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 绝大多数与机器学习相关的工作将会，或者已经是，在将机器学习投入生产中。
- en: Machine Learning Systems Versus Traditional Software
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习系统与传统软件
- en: Since ML is part of software engineering (SWE), and software has been successfully
    used in production for more than half a century, some might wonder why we don’t
    just take tried-and-true best practices in software engineering and apply them
    to ML.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器学习是软件工程的一部分，并且软件在生产中已经成功使用了半个多世纪，有些人可能会想知道为什么我们不简单地采用经过验证的软件工程最佳实践，并将它们应用到机器学习中。
- en: That’s an excellent idea. In fact, ML production would be a much better place
    if ML experts were better software engineers. Many traditional SWE tools can be
    used to develop and deploy ML applications.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的想法。事实上，如果机器学习专家也是更好的软件工程师，机器学习生产领域将会更好。许多传统的软件工程工具可以用来开发和部署机器学习应用程序。
- en: However, many challenges are unique to ML applications and require their own
    tools. In SWE, there’s an underlying assumption that code and data are separated.
    In fact, in SWE, we want to keep things as modular and separate as possible (see
    the Wikipedia page on [separation of concerns](https://oreil.ly/kH67y)).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，许多挑战是机器学习应用程序独有的，并且需要它们自己的工具。在软件工程中，有一个基本的假设，即代码和数据是分开的。事实上，在软件工程中，我们希望尽可能地保持事物模块化和分离（参见维基百科关于[关注点分离](https://oreil.ly/kH67y)的页面）。
- en: On the contrary, ML systems are part code, part data, and part artifacts created
    from the two. The trend in the last decade shows that applications developed with
    the most/best data win. Instead of focusing on improving ML algorithms, most companies
    will focus on improving their data. Because data can change quickly, ML applications
    need to be adaptive to the changing environment, which might require faster development
    and deployment cycles.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，机器学习系统一部分是代码，一部分是数据，还有一部分是从这两者创建的工件。过去十年的趋势显示，利用最好的数据开发的应用程序胜出。大多数公司不再专注于改进机器学习算法，而是专注于改进它们的数据。因为数据可以迅速变化，机器学习应用程序需要适应不断变化的环境，这可能需要更快的开发和部署周期。
- en: In traditional SWE, you only need to focus on testing and versioning your code.
    With ML, we have to test and version our data too, and that’s the hard part. How
    to version large datasets? How to know if a data sample is good or bad for your
    system? Not all data samples are equal—some are more valuable to your model than
    others. For example, if your model has already trained on one million scans of
    normal lungs and only one thousand scans of cancerous lungs, a scan of a cancerous
    lung is much more valuable than a scan of a normal lung. Indiscriminately accepting
    all available data might hurt your model’s performance and even make it susceptible
    to data poisoning attacks.^([31](ch01.xhtml#ch01fn31))
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的软件工程中，你只需要关注测试和版本控制你的代码。而在机器学习中，我们还必须测试和版本控制我们的数据，这是困难的部分。如何对大型数据集进行版本控制？如何知道数据样本对你的系统是好还是坏？不是所有的数据样本都是平等的——有些对你的模型比其他更有价值。例如，如果你的模型已经在一百万个正常肺部扫描中进行了训练，而只有一千个癌症肺部扫描，那么癌症肺部扫描比正常肺部扫描更有价值。不加区分地接受所有可用数据可能会损害你的模型性能，甚至使其容易受到数据毒化攻击。^([31](ch01.xhtml#ch01fn31))
- en: The size of ML models is another challenge. As of 2022, it’s common for ML models
    to have hundreds of millions, if not billions, of parameters, which requires gigabytes
    of random-access memory (RAM) to load them into memory. A few years from now,
    a billion parameters might seem quaint—like, “Can you believe the computer that
    sent men to the moon only had 32 MB of RAM?”
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型的大小是另一个挑战。截至2022年，ML模型通常具有数亿，甚至数十亿的参数，这需要大量的随机存取内存（RAM）来加载它们到内存中。几年后，十亿个参数可能会显得过时，就像“你能相信那台将人送上月球的计算机只有32MB的RAM吗？”
- en: However, for now, getting these large models into production, especially on
    edge devices,^([32](ch01.xhtml#ch01fn32)) is a massive engineering challenge.
    Then there is the question of how to get these models to run fast enough to be
    useful. An autocompletion model is useless if the time it takes to suggest the
    next character is longer than the time it takes for you to type.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，目前将这些大型模型投入生产，尤其是在边缘设备上^([32](ch01.xhtml#ch01fn32))，是一个巨大的工程挑战。然后问题来了，如何确保这些模型运行速度足够快以便有用。如果自动完成模型建议下一个字符的时间比你输入该字符的时间还长，那么它就毫无用处。
- en: Monitoring and debugging these models in production is also nontrivial. As ML
    models get more complex, coupled with the lack of visibility into their work,
    it’s hard to figure out what went wrong or be alerted quickly enough when things
    go wrong.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中监控和调试这些模型也是非常不简单的。随着ML模型变得越来越复杂，再加上无法深入了解它们工作的可见性，很难找出问题出在哪里，或者在问题出现时快速获得警告。
- en: The good news is that these engineering challenges are being tackled at a breakneck
    pace. Back in 2018, when the Bidirectional Encoder Representations from Transformers
    (BERT) paper first came out, people were talking about how BERT was too big, too
    complex, and too slow to be practical. The pretrained large BERT model has 340
    million parameters and is 1.35 GB.^([33](ch01.xhtml#ch01fn33)) Fast-forward two
    years later, BERT and its variants were already used in almost every English search
    on Google.^([34](ch01.xhtml#ch01fn34))
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，这些工程挑战正在以惊人的速度得到解决。回顾2018年，当双向编码器表示来自变压器（BERT）的论文首次发表时，人们讨论的是BERT太大、太复杂，以及太慢，以至于无法实用。预训练的大型BERT模型有3.4亿个参数，大小为1.35
    GB^([33](ch01.xhtml#ch01fn33))。快进两年，BERT及其变种已经几乎在每一次英文搜索中被谷歌使用^([34](ch01.xhtml#ch01fn34))。
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: This opening chapter aimed to give readers an understanding of what it takes
    to bring ML into the real world. We started with a tour of the wide range of use
    cases of ML in production today. While most people are familiar with ML in consumer-facing
    applications, the majority of ML use cases are for enterprise. We also discussed
    when ML solutions would be appropriate. Even though ML can solve many problems
    very well, it can’t solve all the problems and it’s certainly not appropriate
    for all the problems. However, for problems that ML can’t solve, it’s possible
    that ML can be one part of the solution.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 本开章旨在让读者了解将ML引入现实世界所需付出的努力。我们从今天生产中ML的广泛应用案例开始介绍。虽然大多数人熟悉面向消费者的ML应用，但大多数ML用例是为企业设计的。我们还讨论了ML解决方案何时合适。尽管ML能够很好地解决许多问题，但并不是所有问题都适合ML解决。然而，对于ML无法解决的问题，ML可能仍然是解决方案的一部分。
- en: This chapter also highlighted the differences between ML in research and ML
    in production. The differences include the stakeholder involvement, computational
    priority, the properties of data used, the gravity of fairness issues, and the
    requirements for interpretability. This section is the most helpful to those coming
    to ML production from academia. We also discussed how ML systems differ from traditional
    software systems, which motivated the need for this book.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还突出了研究中ML与生产中ML之间的差异。这些差异包括利益相关者的参与程度、计算优先级、使用数据的属性、公平性问题的严重性以及解释性的要求。这一部分对于从学术界进入ML生产领域的人士尤为有用。我们还讨论了ML系统与传统软件系统的区别，这也是本书编写的动机所在。
- en: ML systems are complex, consisting of many different components. Data scientists
    and ML engineers working with ML systems in production will likely find that focusing
    only on the ML algorithms part is far from enough. It’s important to know about
    other aspects of the system, including the data stack, deployment, monitoring,
    maintenance, infrastructure, etc. This book takes a system approach to developing
    ML systems, which means that we’ll consider all components of a system holistically
    instead of just looking at ML algorithms. We’ll provide detail on what this holistic
    approach means in the next chapter.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统是复杂的，由许多不同的组件组成。在生产中使用机器学习系统的数据科学家和机器学习工程师可能会发现，仅关注机器学习算法部分远远不够。了解系统的其他方面至关重要，包括数据堆栈、部署、监控、维护、基础设施等。本书采用系统方法来开发机器学习系统，这意味着我们将全面考虑系统的所有组成部分，而不仅仅是关注机器学习算法。我们将在下一章节详细介绍这种全面方法的含义。
- en: ^([1](ch01.xhtml#ch01fn1-marker)) Mike Schuster, Melvin Johnson, and Nikhil
    Thorat, “Zero-Shot Translation with Google’s Multilingual Neural Machine Translation
    System,” *Google AI Blog*, November 22, 2016, [*https://oreil.ly/2R1CB*](https://oreil.ly/2R1CB).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.xhtml#ch01fn1-marker)) Mike Schuster, Melvin Johnson和Nikhil Thorat，“使用Google的多语言神经机器翻译系统进行零-shot翻译”，*Google
    AI Blog*，2016年11月22日，[*https://oreil.ly/2R1CB*](https://oreil.ly/2R1CB)。
- en: ^([2](ch01.xhtml#ch01fn2-marker)) Larry Hardesty, “A Method to Image Black Holes,”
    *MIT News*, June 6, 2016, [*https://oreil.ly/HpL2F*](https://oreil.ly/HpL2F).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch01.xhtml#ch01fn2-marker)) Larry Hardesty，“成像黑洞的方法”，*MIT News*，2016年6月6日，[*https://oreil.ly/HpL2F*](https://oreil.ly/HpL2F)。
- en: ^([3](ch01.xhtml#ch01fn3-marker)) I didn’t ask whether ML is sufficient because
    the answer is always no.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch01.xhtml#ch01fn3-marker)) 我没有询问机器学习是否足够，因为答案总是是否定的。
- en: ^([4](ch01.xhtml#ch01fn4-marker)) Patterns are different from distributions.
    We know the distribution of the outcomes of a fair die, but there are no patterns
    in the way the outcomes are generated.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch01.xhtml#ch01fn4-marker)) 模式与分布不同。我们知道公正骰子的结果分布，但在生成结果的方式中没有模式。
- en: ^([5](ch01.xhtml#ch01fn5-marker)) Andrej Karpathy, “Software 2.0,” *Medium*,
    November 11, 2017, [*https://oreil.ly/yHZrE*](https://oreil.ly/yHZrE).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch01.xhtml#ch01fn5-marker)) Andrej Karpathy，“软件2.0”，*Medium*，2017年11月11日，[*https://oreil.ly/yHZrE*](https://oreil.ly/yHZrE)。
- en: ^([6](ch01.xhtml#ch01fn6-marker)) We’ll go over online learning in [Chapter 9](ch09.xhtml#continual_learning_and_test_in_producti).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch01.xhtml#ch01fn6-marker)) 我们将在[第9章](ch09.xhtml#continual_learning_and_test_in_producti)讨论在线学习。
- en: '^([7](ch01.xhtml#ch01fn7-marker)) Steke Bako, Thijs Vogels, Brian McWilliams,
    Mark Meyer, Jan Novák, Alex Harvill, Pradeep Sen, Tony Derose, and Fabrice Rousselle,
    “Kernel-Predicting Convolutional Networks for Denoising Monte Carlo Renderings,”
    *ACM Transactions on Graphics* 36, no. 4 (2017): 97, [*https://oreil.ly/EeI3j*](https://oreil.ly/EeI3j);
    Oliver Nalbach, Elena Arabadzhiyska, Dushyant Mehta, Hans-Peter Seidel, and Tobias
    Ritschel, “Deep Shading: Convolutional Neural Networks for Screen-Space Shading,”
    *arXiv*, 2016, [*https://oreil.ly/dSspz*](https://oreil.ly/dSspz).'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch01.xhtml#ch01fn7-marker)) Steke Bako, Thijs Vogels, Brian McWilliams,
    Mark Meyer, Jan Novák, Alex Harvill, Pradeep Sen, Tony Derose和Fabrice Rousselle，“用于去噪蒙特卡罗渲染的核预测卷积网络”，*ACM
    Transactions on Graphics*，2017年，第36卷，第4期：97，[*https://oreil.ly/EeI3j*](https://oreil.ly/EeI3j)；Oliver
    Nalbach, Elena Arabadzhiyska, Dushyant Mehta, Hans-Peter Seidel和Tobias Ritschel，“深度着色：用于屏幕空间着色的卷积神经网络”，*arXiv*，2016年，[*https://oreil.ly/dSspz*](https://oreil.ly/dSspz)。
- en: ^([8](ch01.xhtml#ch01fn8-marker)) “2020 State of Enterprise Machine Learning,”
    *Algorithmia*, 2020, [*https://oreil.ly/wKMZB*](https://oreil.ly/wKMZB).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch01.xhtml#ch01fn8-marker)) “2020年企业机器学习现状”，*Algorithmia*，2020年，[*https://oreil.ly/wKMZB*](https://oreil.ly/wKMZB)。
- en: ^([9](ch01.xhtml#ch01fn9-marker)) “Average Mobile App User Acquisition Costs
    Worldwide from September 2018 to August 2019, by User Action and Operating System,”
    *Statista*, 2019, [*https://oreil.ly/2pTCH*](https://oreil.ly/2pTCH).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch01.xhtml#ch01fn9-marker)) “2018年9月至2019年8月全球平均移动应用用户获取成本，按用户操作和操作系统分”，*Statista*，2019年，[*https://oreil.ly/2pTCH*](https://oreil.ly/2pTCH)。
- en: ^([10](ch01.xhtml#ch01fn10-marker)) Jeff Henriksen, “Valuing Lyft Requires a
    Deep Look into Unit Economics,” *Forbes*, May 17, 2019, [*https://oreil.ly/VeSt4*](https://oreil.ly/VeSt4).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch01.xhtml#ch01fn10-marker)) Jeff Henriksen，“估值Lyft需要深入研究单位经济学”，*Forbes*，2019年5月17日，[*https://oreil.ly/VeSt4*](https://oreil.ly/VeSt4)。
- en: '^([11](ch01.xhtml#ch01fn11-marker)) David Skok, “Startup Killer: The Cost of
    Customer Acquisition,” *For Entrepreneurs*, 2018, [*https://oreil.ly/L3tQ7*](https://oreil.ly/L3tQ7).'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch01.xhtml#ch01fn11-marker)) David Skok，“初创公司杀手：客户获取成本”，*For Entrepreneurs*，2018年，[*https://oreil.ly/L3tQ7*](https://oreil.ly/L3tQ7)。
- en: ^([12](ch01.xhtml#ch01fn12-marker)) Amy Gallo, “The Value of Keeping the Right
    Customers,” *Harvard Business Review*, October 29, 2014, [*https://oreil.ly/OlNkl*](https://oreil.ly/OlNkl).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch01.xhtml#ch01fn12-marker)) Amy Gallo，“保持正确顾客的价值”，*哈佛商业评论*，2014年10月29日，[*https://oreil.ly/OlNkl*](https://oreil.ly/OlNkl)。
- en: ^([13](ch01.xhtml#ch01fn13-marker)) Marty Swant, “The World’s 20 Most Valuable
    Brands,” *Forbes*, 2020, [*https://oreil.ly/4uS5i*](https://oreil.ly/4uS5i).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch01.xhtml#ch01fn13-marker)) Marty Swant，“全球最有价值品牌”，*福布斯*，2020年，[*https://oreil.ly/4uS5i*](https://oreil.ly/4uS5i)。
- en: ^([14](ch01.xhtml#ch01fn15-marker)) It’s not unusual for the ML and data science
    teams to be among the first to go during a company’s mass layoff, as has been
    reported at [IBM](https://oreil.ly/AfUB5), [Uber](https://oreil.ly/t0QpY), [Airbnb](https://oreil.ly/q4M4E).
    See also Sejuti Das’s analysis “How Data Scientists Are Also Susceptible to the
    Layoffs Amid Crisis,” *Analytics India Magazine*, May 21, 2020, [*https://oreil.ly/jobmz*](https://oreil.ly/jobmz).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch01.xhtml#ch01fn15-marker)) 机器学习和数据科学团队成为公司大规模裁员的首批人员并不罕见，正如在[IBM](https://oreil.ly/AfUB5)，[Uber](https://oreil.ly/t0QpY)，[Airbnb](https://oreil.ly/q4M4E)等公司报道的那样。详见Sejuti
    Das的分析文章“危机中数据科学家也容易被裁员”，*Analytics India Magazine*，2020年5月21日，[*https://oreil.ly/jobmz*](https://oreil.ly/jobmz)。
- en: ^([15](ch01.xhtml#ch01fn16-marker)) Wikipedia, s.v. “Ensemble learning,” [*https://oreil.ly/5qkgp*](https://oreil.ly/5qkgp).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch01.xhtml#ch01fn16-marker)) 维基百科，见“集成学习”，[*https://oreil.ly/5qkgp*](https://oreil.ly/5qkgp)。
- en: ^([16](ch01.xhtml#ch01fn17-marker)) Julia Evans, “Machine Learning Isn’t Kaggle
    Competitions,” 2014, [*https://oreil.ly/p8mZq*](https://oreil.ly/p8mZq).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch01.xhtml#ch01fn17-marker)) Julia Evans，“机器学习不只是Kaggle竞赛”，2014年，[*https://oreil.ly/p8mZq*](https://oreil.ly/p8mZq)。
- en: ^([17](ch01.xhtml#ch01fn18-marker)) Lauren Oakden-Rayner, “AI Competitions Don’t
    Produce Useful Models,” September 19, 2019, [*https://oreil.ly/X6RlT*](https://oreil.ly/X6RlT).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch01.xhtml#ch01fn18-marker)) Lauren Oakden-Rayner，“AI竞赛不会产生有用的模型”，2019年9月19日，[*https://oreil.ly/X6RlT*](https://oreil.ly/X6RlT)。
- en: '^([18](ch01.xhtml#ch01fn19-marker)) Kawin Ethayarajh and Dan Jurafsky, “Utility
    Is in the Eye of the User: A Critique of NLP Leaderboards,” EMNLP, 2020, [*https://oreil.ly/4Ud8P*](https://oreil.ly/4Ud8P).'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch01.xhtml#ch01fn19-marker)) Kawin Ethayarajh和Dan Jurafsky，“效用在用户眼中：对自然语言处理排行榜的批判”，EMNLP，2020年，[*https://oreil.ly/4Ud8P*](https://oreil.ly/4Ud8P)。
- en: '^([19](ch01.xhtml#custom_ch01fn1-marker)) Martin Kleppmann, [*Designing Data-Intensive
    Applications*](https://oreil.ly/8dzD2) (Sebastopol, CA: O’Reilly, 2017).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch01.xhtml#custom_ch01fn1-marker)) Martin Kleppmann，《设计数据密集型应用》（加利福尼亚州塞巴斯托波尔：O’Reilly，2017年），[*https://oreil.ly/8dzD2*](https://oreil.ly/8dzD2)。
- en: '^([20](ch01.xhtml#ch01fn20-marker)) Akamai Technologies, *Akamai Online Retail
    Performance Report: Milliseconds Are Critical*, April 19, 2017, [*https://oreil.ly/bEtRu*](https://oreil.ly/bEtRu).'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](ch01.xhtml#ch01fn20-marker)) Akamai Technologies，《Akamai在线零售业绩报告：毫秒至关重要》，2017年4月19日，[*https://oreil.ly/bEtRu*](https://oreil.ly/bEtRu)。
- en: '^([21](ch01.xhtml#ch01fn21-marker)) Lucas Bernardi, Themis Mavridis, and Pablo
    Estevez, “150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com,”
    KDD ’19, August 4–8, 2019, Anchorage, AK, [*https://oreil.ly/G5QNA*](https://oreil.ly/G5QNA).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch01.xhtml#ch01fn21-marker)) Lucas Bernardi，Themis Mavridis和Pablo Estevez，“Booking.com的150个成功机器学习模型：KDD
    ’19会议上的6个经验教训”，2019年8月4-8日，阿拉斯加州安克雷奇，[*https://oreil.ly/G5QNA*](https://oreil.ly/G5QNA)。
- en: ^([22](ch01.xhtml#ch01fn22-marker)) “Consumer Insights,” Think with Google,
    [*https://oreil.ly/JCp6Z*](https://oreil.ly/JCp6Z).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch01.xhtml#ch01fn22-marker)) “消费者洞察”，Think with Google，[*https://oreil.ly/JCp6Z*](https://oreil.ly/JCp6Z)。
- en: ^([23](ch01.xhtml#ch01fn23-marker)) Kleppmann, [*Designing Data-Intensive Applications*](https://oreil.ly/8dzD2).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](ch01.xhtml#ch01fn23-marker)) Kleppmann，《设计数据密集型应用》，[*https://oreil.ly/8dzD2*](https://oreil.ly/8dzD2)。
- en: ^([24](ch01.xhtml#ch01fn24-marker)) Andrej Karpathy, “Building the Software
    2.0 Stack,” Spark+AI Summit 2018, video, 17:54, [*https://oreil.ly/Z21Oz*](https://oreil.ly/Z21Oz).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](ch01.xhtml#ch01fn24-marker)) Andrej Karpathy，“构建软件2.0堆栈”，Spark+AI Summit
    2018，视频，17:54，[*https://oreil.ly/Z21Oz*](https://oreil.ly/Z21Oz)。
- en: ^([25](ch01.xhtml#ch01fn25-marker)) Khristopher J. Brooks, “Disparity in Home
    Lending Costs Minorities Millions, Researchers Find,” *CBS News*, November 15,
    2019, [*https://oreil.ly/UiHUB*](https://oreil.ly/UiHUB).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ^([25](ch01.xhtml#ch01fn25-marker)) Khristopher J. Brooks，“研究发现，家庭贷款成本中的种族差异使少数民族损失数百万美元”，*CBS新闻*，2019年11月15日，[*https://oreil.ly/UiHUB*](https://oreil.ly/UiHUB)。
- en: '^([26](ch01.xhtml#ch01fn26-marker)) Cathy O’Neil, *Weapons of Math Destruction*
    (New York: Crown Books, 2016).'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ^([26](ch01.xhtml#ch01fn26-marker)) Cathy O’Neil，《数学毁灭的武器》（纽约：Crown Books，2016年）。
- en: ^([27](ch01.xhtml#ch01fn27-marker)) Stanford University Human-Centered Artificial
    Intelligence (HAI), *The 2019 AI Index Report*, 2019, [*https://oreil.ly/xs8mG*](https://oreil.ly/xs8mG).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: ^([27](ch01.xhtml#ch01fn27-marker)) 斯坦福大学人类中心人工智能（HAI），*2019 AI指数报告*，2019年，[*https://oreil.ly/xs8mG*](https://oreil.ly/xs8mG)。
- en: ^([28](ch01.xhtml#ch01fn28-marker)) Tweet by Geoffrey Hinton (@geoffreyhinton),
    February 20, 2020, [*https://oreil.ly/KdfD8*](https://oreil.ly/KdfD8).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: ^([28](ch01.xhtml#ch01fn28-marker)) Geoffrey Hinton（@geoffreyhinton）在2020年2月20日的推特，[*https://oreil.ly/KdfD8*](https://oreil.ly/KdfD8)。
- en: '^([29](ch01.xhtml#ch01fn29-marker)) For certain use cases in certain countries,
    users have a “right to explanation”: a right to be given an explanation for an
    output of the algorithm.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ^([29](ch01.xhtml#ch01fn29-marker)) 对于某些国家的某些使用案例，用户有“解释权”：即对算法输出给出解释的权利。
- en: ^([30](ch01.xhtml#ch01fn30-marker)) Stanford HAI, *The 2019 AI Index Report*.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ^([30](ch01.xhtml#ch01fn30-marker)) Stanford HAI, *The 2019 AI Index Report*.
- en: ^([31](ch01.xhtml#ch01fn31-marker)) Xinyun Chen, Chang Liu, Bo Li, Kimberly
    Lu, and Dawn Song, “Targeted Backdoor Attacks on Deep Learning Systems Using Data
    Poisoning,” *arXiv*, December 15, 2017, [*https://oreil.ly/OkAjb*](https://oreil.ly/OkAjb).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ^([31](ch01.xhtml#ch01fn31-marker)) Xinyun Chen, Chang Liu, Bo Li, Kimberly
    Lu, and Dawn Song, “Targeted Backdoor Attacks on Deep Learning Systems Using Data
    Poisoning,” *arXiv*, December 15, 2017, [*https://oreil.ly/OkAjb*](https://oreil.ly/OkAjb).
- en: ^([32](ch01.xhtml#ch01fn32-marker)) We’ll cover edge devices in [Chapter 7](ch07.xhtml#model_deployment_and_prediction_service).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ^([32](ch01.xhtml#ch01fn32-marker)) 我们将在[第7章](ch07.xhtml#model_deployment_and_prediction_service)中涵盖边缘设备。
- en: '^([33](ch01.xhtml#ch01fn33-marker)) Jacob Devlin, Ming-Wei Chang, Kenton Lee,
    and Kristina Toutanova, “BERT: Pre-training of Deep Bidirectional Transformers
    for Language Understanding,” *arXiv*, October 11, 2018, [*https://oreil.ly/TG3ZW*](https://oreil.ly/TG3ZW).'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '^([33](ch01.xhtml#ch01fn33-marker)) Jacob Devlin, Ming-Wei Chang, Kenton Lee,
    and Kristina Toutanova, “BERT: Pre-training of Deep Bidirectional Transformers
    for Language Understanding,” *arXiv*, October 11, 2018, [*https://oreil.ly/TG3ZW*](https://oreil.ly/TG3ZW).'
- en: ^([34](ch01.xhtml#ch01fn34-marker)) Google Search On, 2020, [*https://oreil.ly/M7YjM*](https://oreil.ly/M7YjM).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ^([34](ch01.xhtml#ch01fn34-marker)) Google Search On, 2020, [*https://oreil.ly/M7YjM*](https://oreil.ly/M7YjM).
