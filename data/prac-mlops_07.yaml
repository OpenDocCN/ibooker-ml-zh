- en: Chapter 7\. MLOps for AWS
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 AWS 上的 MLOps
- en: By Noah Gift
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：Noah Gift
- en: Everybody was scared of him [Dr. Abbott (because he yelled at everyone)]. When
    I was attending, there was a new resident named Harris. Harris was still afraid
    of him [Dr. Abbott] even though he was the chief resident and had been there for
    5 years. Later [Dr. Abbott] has a heart attack and then his heart stops. A nurse
    yells, “Quick, he just had an arrest, come in!” So Harris went in there…leaning
    on the sternum and breaking ribs and stuff. So Harris starts pumping on Abbott
    and he woke up. He woke up! And he looked up at Harris and he said, “You! STOP
    THAT!” So Harris stopped. And that was the last story about Abbott.
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 每个人都害怕他 [Dr. Abbott（因为他对每个人大喊大叫）]。当我在那里时，有一个叫做哈里斯的新住院医生。尽管哈里斯已经是主治医师并在那里工作了5年，但他仍然害怕他
    [Dr. Abbott]。后来 [Dr. Abbott] 发生了心脏病发作，然后心脏停止跳动。一位护士大声喊道，“快，他刚发生了心脏骤停，快进来！” 于是哈里斯走进去……靠在胸骨上，打断了肋骨等。于是哈里斯开始给
    Abbott 做心肺复苏，他醒了过来。他醒了过来！他抬头看着哈里斯说，“你！停下！” 于是哈里斯停了下来。这就是有关 Abbott 的最后一个故事。
- en: ''
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Dr. Joseph Bogen
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Dr. Joseph Bogen
- en: One of the most common questions I get from students is, “which cloud do I pick?”
    I tell them the safe choice is Amazon. It has the widest selection of technology
    and the largest market share. Once you master the AWS cloud, it is easier to master
    other cloud offerings since they also assume you might know AWS. This chapter
    covers the foundations of AWS for MLOps and explores practical MLOps patterns.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我经常从学生那里得到一个最常见的问题：“我应该选择哪个云服务？” 我告诉他们，安全的选择是亚马逊。它拥有最广泛的技术选择和最大的市场份额。一旦掌握了 AWS
    云，就更容易掌握其他云服务，因为它们也假设你可能已经了解 AWS。本章介绍了 AWS 在 MLOps 中的基础，并探讨了实用的 MLOps 模式。
- en: I have a long, rich history of working with AWS. At a sports social network
    I ran as the CTO and General Manager, AWS was a secret ingredient that allowed
    us to scale to millions of users worldwide. I also worked as an SME (subject matter
    expert) on the AWS Machine Learning Certification from scratch in the last several
    years. I have been recognized as an [AWS ML Hero](https://oreil.ly/JbWXC), I am
    also a part of the [AWS Faculty Cloud Ambassador program](https://oreil.ly/WsPtx),
    and have taught thousands of students cloud certifications at UC Davis, Northwestern,
    Duke, and the University of Tennessee. So you can say I am a fan of AWS!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我有着与 AWS 合作的悠久而丰富的历史。在我担任 CTO 和总经理的体育社交网络上，AWS 是一个秘密武器，使我们能够扩展到全球数百万用户。我还在过去几年中从头开始参与了
    AWS 机器学习认证的专家（SME）。我被认定为 [AWS ML Hero](https://oreil.ly/JbWXC)，我还是 [AWS Faculty
    Cloud Ambassador program](https://oreil.ly/WsPtx) 的一员，并在加州大学戴维斯分校、西北大学、杜克大学和田纳西大学教授了数千名学生的云计算证书。所以你可以说我是
    AWS 的粉丝！
- en: Due to the sheer size of the AWS platform, it is impossible to cover every single
    aspect of MLOps. If you want a more exhaustive coverage of all of the available
    AWS platform options, you can also check out [*Data Science on AWS*](https://oreil.ly/0kHOI)
    by Chris Fregly and Antje Barth (O’Reilly), for which I was one of the technical
    editors.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 AWS 平台的庞大规模，不可能涵盖 MLOps 的每一个方面。如果您想要更详尽地了解所有可用的 AWS 平台选项，您也可以查看 Chris Fregly
    和 Antje Barth（O’Reilly）的 [*Data Science on AWS*](https://oreil.ly/0kHOI)，我是其中的技术编辑之一。
- en: Instead, this chapter focuses on higher-level services like AWS Lambda and AWS
    App Runner. More complicated systems like AWS SageMaker are covered in other chapters
    in this and the previously mentioned book. Next, let’s get started building AWS
    MLOps solutions.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，本章侧重于像 AWS Lambda 和 AWS App Runner 这样的高级服务。像 AWS SageMaker 这样的更复杂系统在本书的其他章节中有详细介绍。接下来，让我们开始构建
    AWS MLOps 解决方案。
- en: Introduction to AWS
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS 简介
- en: AWS is the leader in cloud computing for several reasons, including its early
    start and corporate culture. In 2005 and 2006, Amazon launched Amazon Web Services,
    including MTurk (Mechanical Turk), Amazon S3, Amazon EC2, and Amazon SQS.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 之所以成为云计算领导者，原因包括其早期的启动和企业文化。2005年和2006年，亚马逊推出了亚马逊网络服务，包括 MTurk（机械土耳其人）、Amazon
    S3、Amazon EC2 和 Amazon SQS。
- en: To this day, these core offerings are not only still around, but they get better
    by the quarter and year. The reason AWS continues to improve its offerings is
    due to its culture. They say it is always “Day 1” at Amazon, meaning the same
    energy and enthusiasm that happens on Day 1 should happen every day. They also
    place the customer at the “heart of everything” they do. I have used these building
    blocks to build systems scaled to thousands of nodes to do machine learning, computer
    vision, and AI tasks. [Figure 7-1](#Figure-7-0) is an actual whiteboard drawing
    of a working AWS Cloud Technical Architecture shown in a coworking spot in downtown
    San Francisco.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 直到今天，这些核心产品不仅仍然存在，而且每个季度和年度都有所改进。AWS持续改进其产品的原因在于其文化。他们说在亚马逊，永远是“第一天”，这意味着每天都应该保持同样的能量和热情。他们还将客户置于他们所做的一切的“核心”。我已经使用这些基础组件构建了能够处理机器学习、计算机视觉和人工智能任务的成千上万个节点的系统。[图 7-1](#Figure-7-0)
    是在旧金山市中心共享工作空间展示的AWS云技术架构的实际白板绘图。
- en: '![pmlo 0701](Images/pmlo_0701.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0701](Images/pmlo_0701.png)'
- en: Figure 7-1\. AWS Cloud Architecture on whiteboard
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1\. AWS云架构在白板上的图示
- en: This type of culture is very different than Google, which has struggled in cloud
    computing. The Google culture is research-oriented with heavy academic hiring.
    The benefits of this culture are open source projects like Kubernetes and TensorFlow.
    Both are complex engineering marvels. The downside is that the customer is not
    first in the culture, which has hurt Google in the cloud computing market share.
    Many organizations balk at not buying professional services and supporting something
    as critical as cloud computing.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这种文化类型与谷歌非常不同，后者在云计算方面遇到了困难。谷歌文化以研究为导向，重视学术招聘。这种文化的好处是开源项目，如Kubernetes和TensorFlow。两者都是复杂的工程奇迹。缺点是在文化中客户不是第一位，这在云计算市场份额上伤害了谷歌。许多组织对于不购买专业服务并支持像云计算这样关键的事物感到犹豫不决。
- en: Next, let’s take a look at getting started with AWS Services.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何开始使用AWS服务。
- en: Getting Started with AWS Services
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用AWS服务
- en: To get started with AWS initially requires only a [Free Tier account](https://oreil.ly/8hBjG).
    If you are at university, you can also use both [AWS Academy](https://oreil.ly/W079B)
    and [AWS Educate](https://oreil.ly/6ZFNh). AWS Academy provides hands-on certification
    material and labs. AWS Educate delivers sandboxes for classrooms.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用AWS，最初只需要一个[免费层账户](https://oreil.ly/8hBjG)。如果你在大学，你也可以使用[AWS学院](https://oreil.ly/W079B)和[AWS
    Educate](https://oreil.ly/6ZFNh)。AWS学院提供实践认证材料和实验室。AWS Educate为课堂提供沙盒环境。
- en: Once you have an account, the next step is to experiment with the various offerings.
    One way to think about AWS is to compare it to a bulk wholesale store. For example,
    according to [statista](https://oreil.ly/m6lgS), Costco has 795 worldwide locations
    in multiple countries and approximately 1 in 5 Americans shop there. Similarly,
    according to the 2020 [Amazon Web Services whitepaper](https://oreil.ly/w8Jft),
    AWS provides an infrastructure that “powers hundreds of thousands of businesses
    in 190 countries around the world.”
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了账户，下一步是尝试各种服务。思考AWS的一种方式是将其与批量批发店进行比较。例如，根据[statista](https://oreil.ly/m6lgS)，Costco在全球有795个分店，遍布多个国家，大约五分之一的美国人在那里购物。同样，根据2020年的[亚马逊网络服务白皮书](https://oreil.ly/w8Jft)，AWS提供了一个基础设施，支持“全球190个国家数十万家企业”。
- en: 'At Costco, there are three approaches considered relevant to an AWS analogy:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在Costco，有三种方法被认为与AWS类比相关：
- en: A customer could walk in and order a very inexpensive but reasonable quality
    pizza in bulk in the first scenario.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第一种情况下，顾客可以走进去订购一份非常便宜但质量合理的批量披萨。
- en: In a second scenario, a customer new to Costco needs to figure out all of the
    bulk items available to investigate the best way to use Costco. They will need
    to walk through the store and look at the bulk items like sugar to see what they
    could build from these raw ingredients.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第二种情况下，一位新来的Costco顾客需要找出所有的散装商品，以便调查最佳的Costco使用方式。他们需要走过整个商店，看看像糖这样的散装商品，看看他们可以用这些原料建造什么。
- en: In a third scenario, when a customer of Costco knows about the premade meals
    (such as rotisserie chicken, pizza, and more), and they know about all of the
    raw ingredients they could buy, they could, in theory, start a catering company,
    a local deli, or a restaurant utilizing their knowledge of Costco and the services
    it provides.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第三种情况下，当Costco的客户了解到已准备好的餐点（如旋转烤鸡、比萨等）并知道他们可以购买的所有原材料时，他们可以理论上利用自己对Costco及其提供的服务的了解开办一个餐饮公司、当地熟食店或餐厅。
- en: A big box retailer the size of Costco charges more money for prepared food,
    and less money for the raw ingredients. The Costco customer who owns a restaurant
    may choose a different food preparation level depending on the maturity of their
    organization and the problem they aim to solve. [Figure 7-2](#Figure-7-0-1) illustrates
    how these Costco options compare to AWS options.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Costco这样规模的大型零售商对已经准备好的食品收费更多，对生的食材收费更少。Costco的客户可以根据他们组织的成熟度和他们想要解决的问题来选择不同的食品准备水平。[图7-2](#Figure-7-0-1)说明了这些Costco选项与AWS选项的比较。
- en: '![pmlo 0702](Images/pmlo_0702.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0702](Images/pmlo_0702.png)'
- en: Figure 7-2\. Costco versus AWS
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-2\. Costco与AWS
- en: Let’s take the case of a local Hawaii Poke Bowl stand near a famous Hawaii beach.
    The owner could buy Costco’s premade Poke in bulk and sell it at a price that
    is approximately twice their cost. But, on the other hand, a more mature BBQ restaurant
    in Hawaii, with employees who can cook and prepare food, Costco sells this uncooked
    food at a much lower price than the fully prepared Poke.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以夏威夷著名海滩附近的一家当地鱼生碗摊位为例。店主可以批量购买Costco的现成鱼生并以大约两倍成本的价格出售。但相反，夏威夷的另一个成熟的烧烤餐厅，有能力烹饪和准备食物的员工，Costco销售未加工的食品的价格低于已经准备好的鱼生。
- en: Much like Costco, AWS provides different levels of product and it’s up to the
    customer to decide how much they’re going to utilize. Let’s dig into those options
    a bit.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 像Costco一样，AWS提供不同级别的产品，客户可以自行决定他们要利用多少。让我们深入了解这些选项。
- en: Using the “No Code/Low Code” AWS Comprehend solution
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用“No Code/Low Code” AWS Comprehend解决方案
- en: The last example showed how using Costco can benefit different restaurant businesses,
    from one with little to no staff—like a pop-up stand—to a more extensive sit-down
    facility. The more work Costco does in preparing the food, the higher the benefit
    to the customer purchasing it, and also the higher the cost for the food. The
    same concept applies with AWS; the more work AWS does for you, the more you pay
    and the fewer people you need to maintain the service.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个例子展示了如何利用Costco可以使不同的餐厅业务受益，从没有员工的快餐摊位到更大规模的餐厅。Costco在准备食物方面做的工作越多，购买它的顾客的收益就越高，食物的成本也越高。AWS也适用同样的概念；AWS为您做的工作越多，您就需要支付的费用就越高，并且您需要维护服务的人员就越少。
- en: Note
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注：
- en: In economics, the theory of comparative advantage says that you shouldn’t compare
    the cost of something directly. Instead, it would help if you compared the opportunity
    cost of doing it yourself. All cloud providers have this assumption baked in,
    since running a data center and building services on top of that data center is
    their specialization. An organization doing MLOps should focus on creating a product
    for its customers that generates revenue, not re-creating what cloud providers
    do poorly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在经济学中，比较优势理论认为你不应该直接比较某个东西的成本，而是应该比较自己做的机会成本。所有云服务提供商都将这种假设内在化，因为运行数据中心并在该数据中心上构建服务是他们的专长。进行MLOps的组织应该专注于为客户创造产生收入的产品，而不是重新创建云服务提供商做得很糟糕的事情。
- en: 'With AWS, an excellent place to start is to act like the Costco customer who
    orders Costco pizza in bulk. Likewise, a Fortune 500 company may have essential
    requirements to add natural language processing (NLP) to its customer service
    products. It could spend nine months to a year hiring a team and then building
    out these capabilities, or it could start using valuable high-level services like
    [AWS Comprehend for Natural Language Processing](https://oreil.ly/z6vIs). AWS
    Comprehend also enables users to leverage the Amazon API to perform many NLP operations,
    including the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AWS，一个很好的起点是像Costco的客户那样批量订购Costco比萨。同样，一家财富500强公司可能有必要将自然语言处理（NLP）添加到其客户服务产品中，可以花费九个月到一年时间招聘团队并构建这些能力，也可以开始使用宝贵的高级别服务，比如[AWS
    Comprehend for Natural Language Processing](https://oreil.ly/z6vIs)。AWS Comprehend还使用户可以利用亚马逊API执行许多NLP操作，包括以下内容：
- en: Entity detection
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实体检测
- en: Key phrase detection
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键词检测
- en: PII
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PII
- en: Language detection
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言检测
- en: Sentiment
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情绪
- en: For example, you can cut and paste text into the Amazon Comprehend Console,
    and AWS Comprehend will find all of the text’s entities. In the example in [Figure 7-3](#Figure-7-0-2),
    I grabbed the first paragraph of LeBron James’s Wikipedia bio, pasted it into
    the console, clicked Analyze, and it highlighted the entities for me.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以将文本剪切并粘贴到亚马逊理解控制台中，AWS Comprehend 将找到所有文本的实体。在 [图 7-3](#Figure-7-0-2)
    的示例中，我抓取了勒布朗·詹姆斯维基百科传记的第一段，粘贴到控制台，点击分析，它会为我突出显示实体。
- en: '![pmlo 0703](Images/pmlo_0703.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0703](Images/pmlo_0703.png)'
- en: Figure 7-3\. AWS Comprehend
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-3\. AWS Comprehend
- en: Other use cases like reviewing medical records or determining the sentiment
    of a customer service response are equally straightforward with AWS Comprehend
    and the boto3 Python SDK. Next, let’s cover a “hello world” project for DevOps
    on AWS, deploying a static website using Amazon S3.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 其他用例，如审查医疗记录或确定客户服务响应的情绪，同样可以通过 AWS Comprehend 和 boto3 Python SDK 简单实现。接下来，让我们来介绍一个关于在
    AWS 上进行 DevOps 的“hello world”项目，使用 Amazon S3 部署静态网站。
- en: Using Hugo static S3 websites
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Hugo 静态 S3 网站
- en: In the following scenario, an excellent way to explore AWS is to “walk around”
    the console, just as you would walk around Costco in awe the first time you visit.
    You do this by first looking at the foundational components of AWS, i.e., IaaS
    (infrastructure as code). These core services include AWS S3 object storage and
    AWS EC2 virtual machines.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下场景中，探索 AWS 的一个很好的方法是像第一次参观 Costco 时一样“四处走走”控制台。您可以首先查看 AWS 的基础组件，即 IaaS（基础设施即代码）。这些核心服务包括
    AWS S3 对象存储和 AWS EC2 虚拟机。
- en: Here, I’ll walk you through deploying a [Hugo website](https://gohugo.io) on
    [AWS S3 static website hosting](https://oreil.ly/FyHWG) using “hello world” as
    an example. The reason for doing a hello world with Hugo is that it is relatively
    simple to set up and will give you a good understanding of host services using
    core infrastructure. These skills will come in handy later when you learn about
    deploying machine learning applications using continuous delivery.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我将向您介绍如何使用“hello world”示例，在 [AWS S3 静态网站托管](https://oreil.ly/FyHWG) 上部署
    [Hugo 网站](https://gohugo.io)。选择使用 Hugo 进行 hello world 的原因是它相对简单设置，并且将帮助您更好地理解使用核心基础设施进行主机服务。这些技能在您学习使用持续交付部署机器学习应用程序时将非常有用。
- en: Note
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: It is worth noting that Amazon S3 is low cost yet highly reliable. The pricing
    of S3 approaches a penny per GB. This low-cost yet highly reliable infrastructure
    is one of the reasons cloud computing is so compelling.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，亚马逊 S3 具有低成本和高可靠性。 S3 的定价接近每 GB 一分钱。这种低成本且高可靠性的基础设施是云计算如此引人注目的原因之一。
- en: 'You can view the whole project in the [GitHub repo](https://oreil.ly/mYjqN).
    Notice how GitHub is the source of truth for the website because the entire project
    consists of text files: markdown files, the Hugo template, and the build commands
    for the AWS Code build server. Additionally, you can walk through a screencast
    of the continuous deployment there as well. [Figure 7-4](#Figure-7-0-3) shows
    the high-level architecture of this project.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [GitHub 仓库](https://oreil.ly/mYjqN) 中查看整个项目。请注意，GitHub 是网站的真实来源，因为整个项目由文本文件组成：Markdown
    文件，Hugo 模板和 AWS Code 构建服务器的构建命令。此外，您还可以在那里通过连续部署的屏幕录像来了解。[图 7-4](#Figure-7-0-3)
    显示了该项目的高级架构。
- en: '![pmlo 0704](Images/pmlo_0704.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0704](Images/pmlo_0704.png)'
- en: Figure 7-4\. Hugo
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-4\. Hugo
- en: 'The short version of how this project works is through the magic of the *buildspec.yml*
    file. Let’s take a look at how this works in the following example. First, note
    that the `hugo` binary installs, then the `hugo` command runs to generate HTML
    files from the checked-out repo. Finally, the `aws` command `aws s3 sync --delete
    public s3://dukefeb1` is the entire deployment process due to the power of S3
    bucket hosting:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目的工作原理简而言之是通过 *buildspec.yml* 文件的魔力。让我们来看看以下示例中的工作原理。首先，注意 `hugo` 二进制文件安装，然后运行
    `hugo` 命令以从检出的存储库生成 HTML 文件。最后，由于 S3 存储桶托管的强大功能，`aws` 命令 `aws s3 sync --delete
    public s3://dukefeb1` 就是整个部署过程：
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Another way of describing a build system file is that it is a recipe. The information
    in the build configuration files is a “how-to” to perform the same actions in
    an AWS Cloud9 development environment.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 描述构建系统文件的另一种方式是它是一个配方。构建配置文件中的信息是在 AWS Cloud9 开发环境中执行相同操作的“如何”。
- en: As discussed in [Chapter 2](ch02.xhtml#Chapter2), AWS Cloud9 holds a special
    place in my heart because it solves a particular problem. Cloud-based development
    environments let you develop in the exact location where all of the action takes
    place. The example shows how powerful this concept is. Check out the code, test
    it in the cloud, and verify the same tool’s deployment. In [Figure 7-5](#Figure-7-0-4)
    the AWS Cloud9 environment invokes a Python microservice.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第 2 章](ch02.xhtml#Chapter2)所述，AWS Cloud9 在解决特定问题方面具有特殊意义。基于云的开发环境使您能够在发生所有活动的确切位置进行开发。示例展示了这一概念的强大之处。查看代码，在云中进行测试，并验证相同工具的部署。在[图
    7-5](#Figure-7-0-4)中，AWS Cloud9 环境调用了一个 Python 微服务。
- en: '![pmlo 0705](Images/pmlo_0705.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0705](Images/pmlo_0705.png)'
- en: Figure 7-5\. Cloud9
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-5\. Cloud9
- en: Note
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You can watch a walkthrough of Hugo deployment on AWS on the [O’Reilly platform](https://oreil.ly/nSiVH),
    as well follow an additional, more detailed guide on the [Pragmatic AI Labs website](https://oreil.ly/0AmNU).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[O'Reilly 平台上观看 Hugo 在 AWS 上的部署演示](https://oreil.ly/nSiVH)，并参考[Pragmatic
    AI Labs 网站上的更详细指南](https://oreil.ly/0AmNU)。
- en: With the foundations of continuous delivery behind us, let’s get into serverless
    on the AWS Platform.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有了持续交付的基础，让我们深入了解 AWS 平台上的无服务器。
- en: Serverless Cookbook
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无服务器烹饪书
- en: Serverless is a crucial methodology for MLOps. In [Chapter 2](ch02.xhtml#Chapter2),
    I brought up the importance of Python functions. A Python function is a unit of
    work that can both take an input and optionally return an output. If a Python
    function is like a toaster, where you put in some bread, it heats the bread, and
    ejects toast, then serverless is the source of electricity.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器是 MLOps 中至关重要的方法。在[第 2 章](ch02.xhtml#Chapter2)中，我提到了 Python 函数的重要性。Python
    函数是一个可以接收输入并可选择返回输出的工作单元。如果把 Python 函数比作是烤面包机，您放入面包，它加热面包，并弹出烤好的面包，那么无服务器就是电的源泉。
- en: A Python function needs to run somewhere, just like a toaster needs to plug
    into something to work. This concept is what serverless does; it enables code
    to run in the cloud. The most generic definition of serverless is code that runs
    without servers. The servers themselves are abstracted away to allow a developer
    to focus on writing functions. These functions do specific tasks, and these tasks
    could be chained together to build more complex systems, like servers that respond
    to events.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Python 函数需要在某处运行，就像烤面包机需要插电才能工作一样。这就是无服务器的概念；它使代码能够在云中运行。无服务器的最通用定义是无需服务器即可运行的代码。服务器本身被抽象化以便开发人员专注于编写函数。这些函数执行特定任务，可以将这些任务链接在一起构建更复杂的系统，例如响应事件的服务器。
- en: 'The function is the center of the universe with cloud computing. In practice,
    this means anything that is a function could map into a technology that solves
    a problem: containers, Kubernetes, GPUs, or AWS Lambda. As you can see in [Figure 7-6](#Figure-7-1-3),
    there is a rich ecosystem of solutions in Python that map directly to a function.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在云计算中，函数是宇宙的中心。实际上，这意味着任何函数都可以映射到解决问题的技术中：容器、Kubernetes、GPU 或 AWS Lambda。正如您在[图
    7-6](#Figure-7-1-3)中看到的，Python 中有一个丰富的解决方案生态系统直接映射到函数。
- en: The lowest level service that performs serverless on the AWS platform is AWS
    Lambda. Let’s take a look at a [few examples from this repo](https://oreil.ly/TR4E2).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AWS 平台上执行无服务器的最低级别服务是 AWS Lambda。让我们来看看[这个仓库中的几个例子](https://oreil.ly/TR4E2)。
- en: First, one of the simpler Lambda functions to write on AWS is a Marco Polo function.
    A Marco Polo function takes in an event with a name in it. So, for example, if
    the event name is “Marco,” it returns “Polo.” If the event name is something else,
    it returns “No!”
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，AWS 上编写的较为简单的 Lambda 函数之一是马可·波罗函数。马可·波罗函数接收一个包含名称的事件。例如，如果事件名称是“Marco”，它返回“Polo”。如果事件名称是其他内容，则返回“No!”。
- en: '![pmlo 0706](Images/pmlo_0706.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0706](Images/pmlo_0706.png)'
- en: Figure 7-6\. Python functions
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-6\. Python 函数
- en: Note
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Growing up as a teenager in the 1980s and 1990s, Marco Polo was a typical game
    to play in the summer swimming pool. When I worked as a camp counselor at a pool
    near my house it was a favorite of the kids I supervised. The game works by everyone
    getting into a pool and one person closing their eyes and yelling “Marco.” Next,
    the other players in the pool must say, “Polo.” The person with their eyes closed
    uses sound to locate someone to tag. Once someone is tagged, then they are “It.”
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在 1980 年代和 1990 年代成长为青少年时，Marco Polo 是夏季游泳池中的一种典型游戏。当我在家附近的一个游泳池担任营地顾问时，这是我监督的孩子们最喜欢的游戏。游戏的方式是每个人都进入游泳池，有一个人闭上眼睛喊“Marco”，其他游泳者必须回答“Polo”。闭眼的人通过声音找到要标记的人。一旦有人被标记，他们就成了“它”。
- en: 'Here is the AWS Lambda Marco Polo code; note that an `event` passes into the
    `lambda_handler`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 AWS Lambda 的 Marco Polo 代码；请注意 `event` 传递到 `lambda_handler`：
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: With serverless cloud computing, think about a lightbulb in your garage. A lightbulb
    can be turned on many ways, such as manually via the light switch or automatically
    via the garage door open event. Likewise, an AWS Lambda responds to many signals
    as well.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在无服务器云计算中，想象一下车库中的灯泡。灯泡可以通过手动开关或自动通过车库门打开事件等多种方式打开。同样，AWS Lambda 也会响应多种信号。
- en: 'Let’s enumerate the ways both lightbulbs and lambdas can trigger:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们列举灯泡和 Lambda 可以触发的方式：
- en: Lightbulbs
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灯泡
- en: Manually flip on the switch
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动打开开关。
- en: Via the garage door opener
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过车库门开启器。
- en: Nightly security timer that turns on the light at midnight until 6 a.m.
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每晚安全定时器在午夜到上午 6 点之间打开灯光。
- en: AWS Lambda
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS Lambda
- en: Manually invoke via console, AWS command line, or AWS Boto3 SDK
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以通过控制台、AWS 命令行或 AWS Boto3 SDK 手动调用。
- en: Respond to S3 events like uploading a file to a bucket
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应 S3 事件，比如上传文件到一个存储桶中。
- en: Timer invokes nightly to download data
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定时器每晚调用以下载数据。
- en: 'What about a more complex example? With AWS Lambda, it is straightforward to
    integrate an S3 Trigger with computer vision labeling on all new images dropped
    in a folder, with a trivial amount of code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 还有更复杂的例子吗？使用 AWS Lambda，您可以简单地在所有新图像放入文件夹时集成 S3 触发器与计算机视觉标签。代码量微不足道：
- en: '[PRE2]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, you can chain multiple AWS Lambda functions together via AWS Step
    Functions:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以通过 AWS Step Functions 将多个 AWS Lambda 函数串联起来：
- en: '[PRE3]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can see this workflow in action in [Figure 7-7](#Figure-7-0-5).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [Figure 7-7](#Figure-7-0-5) 中看到此工作流程的实际操作。
- en: '![pmlo 0707](Images/pmlo_0707.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0707](Images/pmlo_0707.png)'
- en: Figure 7-7\. Step Functions
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-7\. 步骤函数
- en: 'Even more fun is the fact that you can call AWS Lambda functions via a CLI.
    Here is an example:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 更有趣的是，您可以通过 CLI 调用 AWS Lambda 函数。这里是一个例子：
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: It is important to always refer to the latest AWS documentation for the CLI
    as it is an actively moving target. As of the writing of this book, the current
    CLI version is V2, but you may need to adjust the command line examples as things
    change in the future. You can find the latest documentation at the [AWS CLI Command
    Reference site](https://oreil.ly/c7zU5).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是始终参考最新的 AWS CLI 文档，因为它是一个活跃的目标。截至本书写作时，当前的 CLI 版本是 V2，但您可能需要根据未来的变化调整命令行示例。您可以在[AWS
    CLI 命令参考网站](https://oreil.ly/c7zU5)找到最新的文档。
- en: 'The response of the payload is as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 负载的响应如下：
- en: '[PRE5]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For a more advanced walkthrough of AWS Lambda using Cloud9 and the AWS SAM (Serverless
    Application Model), you can view a walkthrough of a small Wikipedia microservice
    on the [Pragmatic AI Labs YouTube Channel](https://oreil.ly/Zy2Ga) or the [O’Reilly
    Learning Platform](https://oreil.ly/DsL1k).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更高级的 AWS Lambda 演练，请查看[Pragmatic AI Labs YouTube 频道](https://oreil.ly/Zy2Ga)或[O’Reilly
    学习平台](https://oreil.ly/DsL1k)上的小型 Wikipedia 微服务演练。
- en: AWS Lambda is perhaps the most valuable and flexible type of computing you can
    use to serve out predictions for machine learning pipelines or wrangle events
    in the service of an MLOps process. The reason for this is the speed of development
    and testing. Next, let’s talk about a couple of CaaS, or container as a service,
    offerings.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda 可能是您用来为机器学习流水线提供预测或在 MLOps 进程中处理事件的最有价值和灵活的计算类型。这是因为开发和测试的速度。接下来，让我们谈谈一些
    CaaS（容器即服务）的提供。
- en: AWS CaaS
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS CaaS
- en: Fargate is a container as a service offering from AWS that allows developers
    to focus on building containerized microservices. For example, in [Figure 7-8](#Figure-7-3-00),
    when this microservice works in the container, the entire runtime, including the
    packages necessary for deployment, will work in a new environment. The cloud platform
    handles the rest of the deployment.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Fargate是AWS提供的一种容器即服务（CaaS），允许开发人员专注于构建容器化的微服务。例如，在[图 7-8](#Figure-7-3-00)中，当此微服务在容器中工作时，整个运行时，包括部署所需的包，都将在一个新环境中工作。云平台处理其余的部署工作。
- en: '![MLOps for CaaS](Images/pmlo_0708.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![MLOps for CaaS](Images/pmlo_0708.png)'
- en: Figure 7-8\. MLOps for CaaS
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-8\. MLOps for CaaS
- en: Note
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Containers solve many problems that have plagued the software industry. So
    as a general rule, it is a good idea to use them for MLOps projects. Here is a
    partial list of the advantages of containers in projects:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 容器解决了困扰软件行业的许多问题。因此，作为一个一般规则，对于MLOps项目来说，使用它们是个好主意。以下是容器在项目中的一些优点的部分列表：
- en: Allows the developer to mimic the production service locally on their desktop
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许开发人员在本地桌面上模拟生产服务
- en: Allows easy software runtime distribution to customers through public container
    registries like Docker Hub, GitHub Container Registry, and Amazon Elastic Container
    Registry
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许通过公共容器注册表（如Docker Hub、GitHub Container Registry和Amazon Elastic Container Registry）轻松地将软件运行时分发给客户。
- en: 'Allows for GitHub or a source code repo to be “source of truth” and contain
    all aspects of microservice: model, code, IaC, and runtime'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许GitHub或源代码存储库成为“事实上的真实来源”，并包含微服务的所有方面：模型、代码、IaC和运行时
- en: Allows for easy production deployment via CaaS services
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许通过CaaS服务轻松进行生产部署
- en: Let’s look at how you can build a microservice that returns the correct change
    using Flask. [Figure 7-9](#Figure-7-3-1) shows a development workflow on AWS Cloud9\.
    Cloud9 is the development environment; a container gets built and pushed to ECR.
    Later that container runs in ECS.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用Flask构建一个返回正确找零的微服务。[图 7-9](#Figure-7-3-1)展示了在AWS Cloud9上的开发工作流程。Cloud9是开发环境；一个容器被构建并推送到ECR。稍后，该容器在ECS中运行。
- en: '![pmlo 0709](Images/pmlo_0709.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0709](Images/pmlo_0709.png)'
- en: Figure 7-9\. ECS workflow
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-9\. ECS工作流
- en: 'The following is the Python code for *app.py*:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是*app.py*的Python代码：
- en: '[PRE6]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Notice that Flask web microservice responds to change requests via web requests
    to the URL pattern `/change/<dollar>/<cents>`. You can view the complete source
    code for this [Fargate example in the following GitHub repo](https://oreil.ly/3qPHM).
    The steps are as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Flask Web微服务通过网址模式`/change/<dollar>/<cents>`响应更改请求。您可以查看这个[Fargate示例在GitHub存储库中的完整源代码](https://oreil.ly/3qPHM)。以下是步骤：
- en: 'Setup app: virtualenv + `make all`'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置应用程序：virtualenv + `make all`
- en: 'Test app local: `python app.py`'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本地测试应用程序：`python app.py`
- en: 'Curl it to test: `curl localhost:8080/change/1/34`'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用curl进行测试：`curl localhost:8080/change/1/34`
- en: Create ECR (Amazon Container Registry)
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建ECR（Amazon容器注册表）
- en: In [Figure 7-10](#Figure-7-3-2), an ECR repository enables later Fargate deployment.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在[图 7-10](#Figure-7-3-2)，一个ECR存储库使后续的Fargate部署成为可能。
- en: '![pmlo 0710](Images/pmlo_0710.png)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![pmlo 0710](Images/pmlo_0710.png)'
- en: Figure 7-10\. ECR
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-10\. ECR
- en: Build container
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建容器
- en: Push container
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推送容器
- en: 'Run docker local: `docker run -p 8080:8080 changemachine`'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本地运行docker：`docker run -p 8080:8080 changemachine`
- en: Deploy to Fargate
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署到Fargate
- en: Test the public service
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试公共服务
- en: Note
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Any cloud service will have rapid, constant changes in functionality, so it
    is best to read the current documentation. The current [Fargate documentation](https://oreil.ly/G8tPV)
    is a great place to read more about the latest ways to deploy to the service.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 任何云服务都会在功能上迅速变化，因此最好阅读当前的文档。当前的[Fargate文档](https://oreil.ly/G8tPV)是了解部署到该服务的最新方式的好地方。
- en: You can also, optionally, watch a complete walkthrough of a Fargate deployment
    on the [O’Reilly platform](https://oreil.ly/2IpFs).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以选择在[O’Reilly平台](https://oreil.ly/2IpFs)观看完整的Fargate部署演示。
- en: Another option for CaaS is AWS App Runner, which further simplifies things.
    For example, you can deploy straight from source code or point to a container.
    In [Figure 7-11](#Figure-7-3-3), AWS App Runner creates a streamlined workflow
    that connects a source repo, deploy environment, and a resulting secure URL.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个CaaS选项是AWS App Runner，它进一步简化了事务。例如，您可以直接从源代码部署或指向一个容器。在[图 7-11](#Figure-7-3-3)，AWS
    App Runner创建了一个流线型工作流，连接源代码存储库、部署环境和最终的安全URL。
- en: '![pmlo 0711](Images/pmlo_0711.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0711](Images/pmlo_0711.png)'
- en: Figure 7-11\. AWS App Runner
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-11\. AWS App Runner
- en: 'This repository can easily be converted to an AWS App Runner method in the
    AWS wizard with the following steps:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 此存储库可以轻松地转换为 AWS App Runner 方法，只需按照以下步骤在 AWS 向导中操作：
- en: 'To build the project, use the command: `pip install -r requirements.txt`.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要构建该项目，请使用命令：`pip install -r requirements.txt`。
- en: 'To run the project, use: `python app.py`.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要运行该项目，请使用：`python app.py`。
- en: 'Finally, configure the port to use: `8080`.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，配置端口使用：`8080`。
- en: A key innovation, shown in [Figure 7-12](#Figure-7-3-4), is the ability to connect
    many different services on AWS, i.e., core infrastructure, like AWS CloudWatch,
    Load Balancers, Container Services, and API Gateways into one complete offering.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键的创新，如[图 7-12](#Figure-7-3-4)所示，是能够将许多不同的 AWS 服务连接起来，即核心基础设施，如 AWS CloudWatch、负载均衡器、容器服务和
    API 网关，形成一个完整的解决方案。
- en: '![pmlo 0712](Images/pmlo_0712.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0712](Images/pmlo_0712.png)'
- en: Figure 7-12\. AWS App Runner service created
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-12\. AWS App Runner 服务已创建
- en: The final deployed service in [Figure 7-13](#Figure-7-3-5) shows a secure URL
    and the ability to invoke the endpoint and return correct change.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最终部署的服务在[图 7-13](#Figure-7-3-5)中显示了一个安全的 URL，并且能够调用端点并返回正确的更改。
- en: '![pmlo 0713](Images/pmlo_0713.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0713](Images/pmlo_0713.png)'
- en: Figure 7-13\. AWS App Runner deployed
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-13\. AWS App Runner 部署完成
- en: Why is this helpful magic? In a nutshell, all of the logic, including perhaps
    a machine learning model, are in one repo. Thus, this is a compelling style for
    building MLOps-friendly products. In addition, one of the more complex aspects
    of delivering a machine learning application to production is microservice deployment.
    AWS App Runner makes most of the complexity disappear, capturing time for other
    parts of the MLOps problem. Next, let’s discuss how AWS deals with computer vision.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法有何神奇之处？简言之，所有的逻辑，包括可能的机器学习模型，都在一个代码库中。因此，这是构建 MLOps 友好产品的一种引人注目的方式。此外，将机器学习应用程序交付到生产中的一个更复杂的方面是微服务部署。AWS
    App Runner 让大部分复杂性消失，为 MLOps 问题的其他部分节省时间。接下来，让我们讨论 AWS 如何处理计算机视觉。
- en: Computer vision
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: 'I teach an applied computer vision course at [Northwestern’s graduate data
    science program](https://oreil.ly/Q6uRI). This class is delightful to teach because
    we do the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我在[北西大学的研究生数据科学课程](https://oreil.ly/Q6uRI)中教授应用计算机视觉课程。这门课非常有趣，因为我们做以下事情：
- en: Weekly video demos
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每周视频演示
- en: Focus on problem-solving versus coding or modeling
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 焦点放在解决问题上，而不是编码或建模
- en: Use high-level tools like AWS DeepLens, a deep learning–enabled video camera
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用高级工具如 AWS DeepLens，一个支持深度学习的视频摄像机
- en: In practice, this allows a rapid feedback loop that focuses on the problem versus
    the technology to solve the problem. One of the technologies in use is the AWS
    Deep Lens device as shown in [Figure 7-14](#Figure-7-0-5_2). The device is a complete
    computer vision hardware developer kit in that it contains a 1080p camera, operating
    system, and wireless capabilities. In particular, this solves the prototyping
    problem of computer vision.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这允许一个快速的反馈循环，专注于解决问题而不是解决问题的技术。在使用的技术中，AWS Deep Lens 设备是一个例子，如[图 7-14](#Figure-7-0-5_2)所示。该设备是一个完整的计算机视觉硬件开发工具包，包含一个
    1080p 摄像头、操作系统和无线功能。特别是，这解决了计算机视觉原型设计的问题。
- en: '![pmlo 0714](Images/pmlo_0714.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0714](Images/pmlo_0714.png)'
- en: Figure 7-14\. DeepLens
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-14\. DeepLens
- en: Once AWS DeepLens starts capturing video, it splits the video into two streams.
    The Project Stream shown in [Figure 7-15](#Figure-7-0-6) adds real-time annotation
    and sends the packets to the MQ Telemetry Transport (MQTT) service, which is a
    publish-subscribe network protocol.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 AWS DeepLens 开始捕获视频，它将视频分成两个流。在[图 7-15](#Figure-7-0-6)中显示的项目流将实时注释添加到视频并将数据包发送到
    MQTT（消息队列遥测传输）服务，这是一种发布-订阅网络协议。
- en: '![pmlo 0715](Images/pmlo_0715.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0715](Images/pmlo_0715.png)'
- en: Figure 7-15\. Detect
  id: totrans-152
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-15\. 检测
- en: In [Figure 7-16](#Figure-7-0-7), the MQTT packets arrive in real time as the
    objects get detected in the stream.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 7-16](#Figure-7-0-7)中，随着对象在流中被检测到，MQTT 数据包实时到达。
- en: The DeepLens is a “plug and play” technology since it tackles perhaps the most
    challenging part of the problem of building a real-time computer vision prototyping
    system—capturing the data, and sending it somewhere. The “fun” factor of this
    is how easy it is to go from zero to one building solutions with AWS DeepLens.
    Next, let’s get more specific and move beyond just building microservices and
    into building microservices that deploy machine learning code.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: DeepLens 是一种“即插即用”的技术，因为它解决了构建实时计算机视觉原型系统中可能最具挑战性的问题——捕获数据并将其发送到某个地方。这种技术的“乐趣”在于使用
    AWS DeepLens 轻松从零构建解决方案。接下来，让我们更具体地进入，超越仅构建微服务，进入构建部署机器学习代码的微服务。
- en: '![pmlo 0716](Images/pmlo_0716.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0716](Images/pmlo_0716.png)'
- en: Figure 7-16\. MQTT
  id: totrans-156
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-16\. MQTT
- en: MLOps on AWS
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS 上的 MLOps
- en: One way to get started with MLOps on AWS is to consider the following question.
    When given a machine learning problem with three constraints—prediction accuracy,
    explainability, and operations, which two would you focus on to achieve success,
    and in what order?
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AWS 上开始 MLOps 的一种方法是考虑以下问题。当面临一个机器学习问题时，有三个约束条件——预测准确性、可解释性和操作性，你会侧重于哪两个以取得成功，并且顺序是什么？
- en: Many academic-focused data scientists immediately jump to prediction accuracy.
    Building ever-better prediction models is a fun challenge, like playing Tetris.
    Also, the modeling is glamorous and a coveted aspect of the job. Data scientists
    like to show how accurate they can train an academic model using increasingly
    sophisticated techniques.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 许多以学术为重点的数据科学家立即跳到预测准确性。构建越来越好的预测模型是一种有趣的挑战，就像玩俄罗斯方块一样。此外，建模是一项光荣的工作方面，也是工作中令人向往的一部分。数据科学家喜欢展示他们能够使用日益复杂的技术训练学术模型的准确性。
- en: The entire Kaggle platform works on increasing prediction accuracy, and there
    are monetary rewards for the precise model. A different approach is to focus on
    operationalizing the model. This approach’s advantage is that later, model accuracy
    can improve alongside improvements in the software system. Just as the Japanese
    automobile industry focused on Kaizen or continuous improvement, an ML system
    can focus on reasonable initial prediction accuracy and improve quickly.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle 平台的整体工作是提高预测准确性，并为精确模型提供经济奖励。另一种方法是专注于模型的运行化。这种方法的优势在于，随着软件系统的改进，模型的准确性也能得到提高。就像日本汽车工业专注于改善（Kaizen）或持续改进一样，一个机器学习系统可以专注于合理的初始预测准确性，并快速改进。
- en: The culture of AWS supports this concept in the leadership principles of “Bias
    for Action” and “Deliver Results.” “Bias for Action” refers to defaulting to speed
    and delivery results, focusing on the critical inputs to a business, and delivering
    results quickly. As a result, the AWS products around machine learning, like AWS
    SageMaker, show the spirit of this culture of action and results.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 的文化支持“行动偏见”和“交付结果”这一概念。所谓“行动偏见”是指默认选择速度和交付结果，专注于业务的关键输入，并快速交付结果。因此，AWS 围绕机器学习的产品，如
    AWS SageMaker，展现了这种行动和结果导向文化的精神。
- en: Continuous delivery (CD) is a core component in MLOps. Before you can automate
    delivery for machine learning, the Microservice itself needs automation. The specifics
    change depending on the type of AWS service involved. Let’s start with an end-to-end
    example.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付（CD）是 MLOps 中的核心组成部分。在可以为机器学习自动化交付之前，微服务本身需要自动化。具体细节会根据涉及的 AWS 服务类型而变化。让我们从一个端到端的示例开始。
- en: In the following example, an Elastic Beanstalk Flask app continuously deploys
    using all AWS technology from AWS Code Build to AWS Elastic Beanstalk. This “stack”
    is also ideal for deploying ML models. Elastic Beanstalk is a platform as a service
    technology offered by AWS that streamlines much of the work of deploying an application.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，一个 Elastic Beanstalk Flask 应用程序使用 AWS CodeBuild 到 AWS Elastic Beanstalk
    实现持续部署。这种“堆栈”也非常适合部署 ML 模型。Elastic Beanstalk 是 AWS 提供的平台即服务技术，可以简化应用程序部署的大部分工作。
- en: In [Figure 7-17](#Figure-7-1-2), notice that AWS Cloud9 is a recommended starting
    point for development. Next, a GitHub repository holds the source code for the
    project, and as change events occur, it triggers the cloud native build server,
    AWS CodeBuild. Finally, the AWS Code Build process runs continuous integration,
    tests for the code, and provides continuous delivery to AWS Elastic Beanstalk.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 7-17](#Figure-7-1-2) 中，注意 AWS Cloud9 是开发的推荐起点。接下来，一个 GitHub 仓库保存项目的源代码，并在发生变更事件时触发云原生构建服务器
    AWS CodeBuild。最后，AWS CodeBuild 进程运行持续集成，为 AWS Elastic Beanstalk 提供持续交付。
- en: '![pmlo 0717](Images/pmlo_0717.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0717](Images/pmlo_0717.png)'
- en: Figure 7-17\. Elastic Beanstalk
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-17\. 弹性 Beanstalk
- en: Note
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'The source code and a walkthrough of this example are at the following links:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下链接包含源代码和此示例的详细步骤：
- en: '[Source Code](https://oreil.ly/L8ltB)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[源代码](https://oreil.ly/L8ltB)'
- en: '[O’Reilly Platform Video Walkthrough](https://oreil.ly/JUuLO)'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[O’Reilly 平台视频演示](https://oreil.ly/JUuLO)'
- en: 'To replicate this exact project, you can do the following steps:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 要复制此项目，请执行以下步骤：
- en: Check out the repository in AWS Cloud9 or AWS CloudShell if you have strong
    command line skills.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你具备强大的命令行技能，可以在 AWS Cloud9 或 AWS CloudShell 中查看仓库。
- en: 'Create a Python virtualenv and source it and run `make all`:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Python 虚拟环境并激活它，然后运行 `make all`：
- en: '[PRE7]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that `awsebcli` installs via requirements, and this tool controls Elastic
    Beanstalk from the CLI.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，`awsebcli` 通过 requirements 安装，并且此工具从 CLI 控制 Elastic Beanstalk。
- en: 'Initialize new `eb` app:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化新的 `eb` 应用程序：
- en: '[PRE8]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Optionally, you use `eb init` to create SSH keys to shell into the running instances.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可选择使用 `eb init` 创建 SSH 密钥以登录运行实例。
- en: 'Create remote eb instance:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建远程 eb 实例：
- en: '[PRE9]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Setup AWS Code Build Project. Note your Makefile needs to reflect your project
    names:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 AWS Code Build 项目。请注意，您的 Makefile 需要反映您的项目名称：
- en: '[PRE10]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: After you get the project working with continuous deployment, you are ready
    to move to the next step, deploying an ML model. I highly recommend getting a
    “hello world” type project working with continuous deployment like this one before
    you proceed directly into a complex ML project when you are learning new technology.
    Next, let’s look at an intentionally simple MLOps Cookbook that is the foundation
    for many new AWS Services deployments.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用持续部署成功运行项目后，您已准备好进入下一步，部署机器学习模型。我强烈建议您先完成像这样的“Hello World”类型的项目，再深入学习复杂的机器学习项目。接下来，让我们看一个刻意简单的
    MLOps Cookbook，它是许多新 AWS 服务部署的基础。
- en: MLOps Cookbook on AWS
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS 上的 MLOps Cookbook
- en: With the foundational components out of the way, let’s look at a basic machine
    learning recipe and apply it to several scenarios. Notice that this core recipe
    is deployable to many services on AWS and many other cloud environments. This
    following MLOps Cookbook project is intentionally spartan, so the focus is on
    deploying machine learning. For example, this project predicts height from a weight
    input for Major League Baseball players.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 基础组件准备好后，让我们看一个基本的机器学习示例，并将其应用于多种场景。注意，这个核心示例可部署到 AWS 和许多其他云环境的多个服务上。此后的 MLOps
    Cookbook 项目刻意简洁，重点是部署机器学习。例如，此项目根据体重输入预测美国职业棒球大联盟球员的身高。
- en: In [Figure 7-18](#Figure-7-2-0), GitHub is the source of truth and contains
    the project scaffolding. Next, the build service is GitHub Actions, and the container
    service is GitHub Container Registry. Both of these services can easily replace
    any similar offering in the cloud. In particular, on the AWS Cloud, you can use
    AWS CodeBuild for CI/CD and AWS ECR (Elastic Container Registry). Finally, once
    a project has been “containerized,” it opens up the project to many deployment
    targets. On AWS, these include AWS Lambda, AWS Elastic Beanstalk, and AWS App
    Runner.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 7-18](#Figure-7-2-0) 中，GitHub 是信息源并包含项目脚手架。接下来，构建服务是 GitHub Actions，容器服务是
    GitHub Container Registry。这两项服务都可以轻松替代云中的类似服务。特别是在 AWS 云上，你可以使用 AWS CodeBuild
    进行 CI/CD 和 AWS ECR（Elastic Container Registry）。最后，一旦项目被“容器化”，它将面向多个部署目标开放。在 AWS
    上，这些包括 AWS Lambda、AWS 弹性 Beanstalk 和 AWS App Runner。
- en: '![pmlo 0718](Images/pmlo_0718.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0718](Images/pmlo_0718.png)'
- en: Figure 7-18\. MLOps Cookbook
  id: totrans-188
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-18\. MLOps Cookbook
- en: 'The following files are all useful to build solutions in many different recipes:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 以下文件在多个不同的方案中构建解决方案时都非常有用：
- en: Makefile
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Makefile
- en: The Makefile is both a list of recipes and a way to invoke those recipes. View
    the [Makefile in the example GitHub project](https://oreil.ly/paYV6).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Makefile 既是一系列配方的列表，也是调用这些配方的方法。查看 [示例 GitHub 项目中的 Makefile](https://oreil.ly/paYV6)。
- en: requirements.txt
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: requirements.txt
- en: The requirements file contains the list of Python packages for the project.
    Typically these packages are “pinned” to a version number, which limits unexpected
    package dependencies. View the [requirements.txt in the example GitHub project](https://oreil.ly/7p6QH).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: requirements 文件包含项目所需的 Python 包列表。通常这些包会固定版本号，以限制意外的包依赖。查看 [示例 GitHub 项目中的 requirements.txt](https://oreil.ly/7p6QH)。
- en: cli.py
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: cli.py
- en: This command line shows how an ML library can also be invoked from the CLI,
    not just via a web application. View the [cli.py in the example GitHub project](https://oreil.ly/iyI44).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令行显示了如何从CLI调用ML库，而不仅仅是通过Web应用程序。查看[example GitHub项目中的cli.py](https://oreil.ly/iyI44)。
- en: utilscli.py
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: utilscli.py
- en: The utilscli.py is a utility that allows the user to invoke different endpoints,
    i.e., AWS, GCP, Azure, or any production environment. Most machine learning algorithms
    require data to be scaled. This tool simplifies scaling the input and scaling
    back out the output.View the [utilscli.py in the example GitHub project](https://oreil.ly/6tjps).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: utilscli.py是一个实用工具，允许用户调用不同的端点，即AWS、GCP、Azure或任何生产环境。大多数机器学习算法需要数据进行缩放。这个工具简化了输入的缩放和输出的恢复。查看[example
    GitHub项目中的utilscli.py](https://oreil.ly/6tjps)。
- en: app.py
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: app.py
- en: The application file is the Flask web microservice that accepts and returns
    a JSON prediction result via the `/predict` URL endpoint. View the [app.py in
    the example GitHub project](https://oreil.ly/6LTMs).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序文件是Flask Web微服务，通过`/predict` URL端点接受并返回JSON预测结果。查看[example GitHub项目中的app.py](https://oreil.ly/6LTMs)。
- en: mlib.py
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: mlib.py
- en: The model handling library does much of the heavy lifting in a centralized location.
    This library is intentionally very basic and doesn’t solve more complicated issues
    like caching loading of the model or other production issues unique to production
    deployment. View the [mlib.py in the example GitHub project](https://oreil.ly/wgGPC).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 模型处理库在一个集中位置完成了大部分的繁重工作。这个库意在非常基础，不解决像缓存加载模型或其他生产环境独特的更复杂问题。查看[example GitHub项目中的mlib.py](https://oreil.ly/wgGPC)。
- en: htwtmlb.csv
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: htwtmlb.csv
- en: A CSV file is helpful for input scaling. View the [htwtmlb.csv in the example
    GitHub project](https://oreil.ly/cn8ul).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: CSV文件对于输入缩放非常有帮助。查看[example GitHub项目中的htwtmlb.csv](https://oreil.ly/cn8ul)。
- en: model.joblib
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: model.joblib
- en: This model is exported from sklearn but could easily be in another format such
    as ONNX or TensorFlow. Other real-world production considerations could be keeping
    this model in a different location like Amazon S3, in a container, or even hosted
    by AWS SageMaker. View the [model.joblib in the example GitHub project](https://oreil.ly/Y4VV9).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是从sklearn导出的，但也可以很容易地转换为其他格式，比如ONNX或TensorFlow。其他真实世界的生产考虑可能包括将这个模型保存在不同的位置，比如Amazon
    S3、一个容器中，或者甚至由AWS SageMaker托管。查看[example GitHub项目中的model.joblib](https://oreil.ly/Y4VV9)。
- en: Dockerfile
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile
- en: This file enables project containerization and, as a result, opens up many new
    deployment options, both on the AWS platform as well as other clouds. View the
    [Dockerfile in the example GitHub project](https://oreil.ly/QIEAu).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件使项目容器化，从而在AWS平台以及其他云上开放了许多新的部署选项。查看[example GitHub项目中的Dockerfile](https://oreil.ly/QIEAu)。
- en: Baseball_Predictions_Export_Model.ipynb
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Baseball_Predictions_Export_Model.ipynb
- en: The Jupyter notebook is a crucial artifact to include in a machine learning
    project. It shows another developer the thinking behind creating the model and
    provides valuable context for maintaining the project in production. View the
    [Baseball_Predictions_Export_Model.ipynb in the example GitHub project](https://oreil.ly/jvs0O).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter笔记本是机器学习项目中包括的关键工件。它展示了创建模型背后的思路，并为在生产中维护项目提供了宝贵的背景信息。查看[example GitHub项目中的Baseball_Predictions_Export_Model.ipynb](https://oreil.ly/jvs0O)。
- en: These project artifacts are helpful as an educational tool in explaining MLOps
    but may be different or more complex in a unique production scenario. Next, let’s
    discuss how CLI (command line interface) tools help operationalize a machine learning
    project.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这些项目工件对于解释MLOps作为教育工具非常有帮助，但在独特的生产场景中可能会有所不同或更加复杂。接下来，让我们讨论CLI（命令行界面）工具如何帮助操作化机器学习项目。
- en: CLI Tools
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CLI工具
- en: 'In this project, there are two CLI tools. First, the main *cli.py* is the endpoint
    that serves out predictions. For example, to predict the height of an MLB player,
    you use the following command to create a forecast: `./cli.py --weight 180`. Notice
    in [Figure 7-19](#Figure-7-2-1) that the command line option of `--weight` allows
    the user to test out many new prediction inputs quickly.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中有两个CLI工具。首先，主要的*cli.py*是服务预测输出的端点。例如，要预测MLB球员的身高，您可以使用以下命令创建一个预测：`./cli.py
    --weight 180`。请注意，在[图7-19](#Figure-7-2-1)中，`--weight`命令行选项允许用户快速测试许多新的预测输入。
- en: '![pmlo 0719](Images/pmlo_0719.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0719](Images/pmlo_0719.png)'
- en: Figure 7-19\. CLI predict
  id: totrans-214
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-19\. CLI预测
- en: 'So how does this work? Most of the “magic” is via a library that does the heavy
    lifting of scaling the data, making the prediction, then doing an inverse transform
    back:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是如何工作的？大部分的“魔法”是通过一个库来完成的，该库负责扩展数据、进行预测，然后再进行逆转换：
- en: '[PRE11]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, the Click framework wraps the library calls to *mlib.py* and makes a
    clean interface to serve out predictions. There are many advantages to using command
    line tools as the primary interface for interacting with machine learning models.
    The speed to develop and deploy a command line machine learning tool is perhaps
    the most important:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，Click 框架包装了对 *mlib.py* 的库调用，并提供了一个清晰的界面来提供预测服务。使用命令行工具与机器学习模型进行交互的主要优势有很多。快速开发和部署命令行机器学习工具的速度可能是最重要的：
- en: '[PRE12]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The second CLI tool is *utilscli.py*, which performs model retraining and could
    serve as the entry point to do more tasks. For example, this version doesn’t change
    the default `model_name`, but you could add that as an option by [forking this
    repo](https://oreil.ly/dcVf1):'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个 CLI 工具是 *utilscli.py*，它执行模型重新训练，并可以作为执行更多任务的入口点。例如，这个版本不会更改默认的 `model_name`，但你可以通过
    [forking this repo](https://oreil.ly/dcVf1) 添加该选项：
- en: '[PRE13]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Notice that the *mlib.py* again does the heavy lifting, but the CLI provides
    a convenient way to do rapid prototyping of an ML model:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，*mlib.py* 再次承担了大部分的重活，但 CLI 提供了一个便捷的方式来快速原型化一个 ML 模型：
- en: '[PRE14]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[Figure 7-20](#Figure-7-2-2) is an example of retraining the model.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 7-20](#Figure-7-2-2) 是重新训练模型的一个示例。'
- en: '![pmlo 0720](Images/pmlo_0720.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0720](Images/pmlo_0720.png)'
- en: Figure 7-20\. Model retrain
  id: totrans-225
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-20\. 模型重新训练
- en: 'You can also query a deployed API, which will soon tackle the CLI, allowing
    you to change both the host and the value passed into the API. This step uses
    the `requests` library. It can help build a “pure” Python example of a prediction
    tool versus only predicting with a `curl` command. You can see an example of the
    output in [Figure 7-21](#Figure-7-2-3):'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以查询已部署的 API，这很快会处理 CLI，允许你更改主机和传递到 API 的值。这一步骤使用 `requests` 库。它可以帮助构建一个“纯”
    Python 示例，用于预测工具，而不仅仅是通过 `curl` 命令进行预测。你可以在 [图 7-21](#Figure-7-2-3) 中看到输出的一个示例：
- en: '[PRE15]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![pmlo 0721](Images/pmlo_0721.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0721](Images/pmlo_0721.png)'
- en: Figure 7-21\. Predict requests
  id: totrans-229
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-21\. 预测请求
- en: Perhaps you are sold on CLI tools as the ideal way to rapidly deploy ML models,
    thus being a true MLOps-oriented organization. What else could you do? Here are
    two more ideas.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 也许你已经被 CLI 工具作为快速部署 ML 模型的理想方式所吸引，因此成为真正的 MLOps 导向组织。还能做什么？这里有两个更多的想法。
- en: First, you could build a more sophisticated client that makes async HTTP requests
    a deployed web service. This functionality is one of the advantages of building
    utility tools in pure Python. One library to consider for async HTTPS is [Fast
    API](https://oreil.ly/ohpZg).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你可以构建一个更复杂的客户端，使其可以对部署的 Web 服务进行异步 HTTP 请求。这个功能是在纯 Python 中构建实用工具的一个优点之一。一个可以考虑用于异步
    HTTPS 的库是 [Fast API](https://oreil.ly/ohpZg)。
- en: Second, you can continuously deploy the CLI itself. For many SaaS companies,
    university labs, and many more scenarios, this could be the ideal workflow to
    adapt speed and agility as a primary goal. In this example GitHub project there
    is a simple example of [how to containerize a command-line tool](https://oreil.ly/bLC6F).
    The three critical files are the Makefile, the *cli.py*, and the Dockerfile.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，你可以持续部署 CLI 本身。对于许多 SaaS 公司、大学实验室等场景，这可能是适应速度和敏捷性的理想工作流程。在这个示例 GitHub 项目中，有一个关于
    [如何将命令行工具容器化的简单示例](https://oreil.ly/bLC6F)。关键文件包括 Makefile、*cli.py* 和 Dockerfile。
- en: 'Notice that the Makefile makes it easy to “lint” the syntax of the Dockerfile
    using `hadolint`:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Makefile 使用 `hadolint` 轻松“lint” Dockerfile 的语法：
- en: '[PRE16]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The CLI itself is pretty small, one of the valuable aspects of the Click framework:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: CLI 本身非常简洁，这是 Click 框架的一个宝贵特性之一：
- en: '[PRE17]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Finally, the Dockerfile builds the container:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Dockerfile 构建了容器：
- en: '[PRE18]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To run this exact container, you can do the following:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行这个确切的容器，你可以执行以下步骤：
- en: '[PRE19]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is the following:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE20]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This workflow is ideal for ML-based CLI tools! For example, to build this container
    yourself and push it, you could do the following workflow:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工作流程非常适合基于 ML 的 CLI 工具！例如，要自己构建这个容器并推送它，你可以按照以下工作流程进行：
- en: '[PRE21]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This section covered ideas on how to scaffold out Machine Learning projects.
    In particular, three main ideas are worth considering: using containers, building
    a web microservice, and using command line tools. Next, let’s cover Flask microservices
    in more detail.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了如何构建机器学习项目的思路。特别是，有三个主要想法值得考虑：使用容器、构建 Web 微服务以及使用命令行工具。接下来，让我们更详细地讨论 Flask
    微服务。
- en: Flask Microservice
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Flask 微服务
- en: When dealing with MLOps workflows, it is essential to note that a Flask ML microservice
    can operate in many ways. This section covers many of these examples.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理 MLOps 工作流时，值得注意的是，Flask ML 微服务可以以多种方式运行。本节涵盖了许多这些示例。
- en: 'Let’s first take a look at the core of the Flask machine learning microservice
    application in the following example. Note, again, that most of the heavy lifting
    is via the *mlib.py* library. The only “real” code is the Flask route that does
    the following `@app.route("/predict", methods=[''POST''])` post request. It accepts
    a JSON payload looking similar to `{"Weight": 200}`, then returns a JSON result:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们首先看一下下面示例中 Flask 机器学习微服务应用程序的核心。请注意，大部分繁重的工作是通过 *mlib.py* 库完成的。唯一的“真实”代码是
    Flask 路由，执行以下 `@app.route("/predict", methods=[''POST''])` 的 POST 请求。它接受一个类似 `{"Weight":
    200}` 的 JSON 负载，然后返回一个 JSON 结果：'
- en: '[PRE22]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This Flask web service runs in a straightforward manner using `python app.py`.
    For example, you run the Flask microservice as follows with the command `python
    app.py`:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Flask Web 服务使用 `python app.py` 运行非常简单。例如，您可以使用 `python app.py` 命令来运行 Flask
    微服务：
- en: '[PRE23]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To serve a prediction against the application, run the `predict.sh`. Notice,
    a small `bash` script can help debug your application without having to type out
    all of the jargon of `curl`, which can cause you to make syntax mistakes:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 要对应用程序进行预测服务，请运行 `predict.sh`。请注意，一个小的 `bash` 脚本可以帮助您调试应用程序，而无需输入所有 `curl` 的术语，这可能会导致语法错误：
- en: '[PRE24]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The results of the prediction show that the Flask endpoint returns a JSON payload:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 预测结果显示，Flask 端点返回一个 JSON 负载：
- en: '[PRE25]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note that the earlier *utilscli.py* tool could also make web requests to this
    endpoint. You could also use [httpie](https://httpie.io) or the [postman](https://postman.com)
    tool. Next, let’s discuss how a containerization strategy works for this microservice.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，早期的 *utilscli.py* 工具也可以向此端点发出 web 请求。您还可以使用 [httpie](https://httpie.io)
    或者 [postman](https://postman.com) 工具。接下来，让我们讨论容器化策略在这个微服务中的应用。
- en: Containerized Flask microservice
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器化的 Flask 微服务
- en: The following is an example of how to build the container and run it locally.
    (You can find the contents of [*predict.sh* on GitHub](https://oreil.ly/XhRfL).)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是构建容器并在本地运行的示例。（您可以在 GitHub 上找到 [*predict.sh* 的内容](https://oreil.ly/XhRfL)。）
- en: '[PRE26]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Adding a container workflow is straightforward, and it enables an easier development
    method since you can share a container with another person on your team. It also
    opens up the option to deploy your machine learning application to many more platforms.
    Next, let’s talk about how to build and deploy containers automatically.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 添加容器工作流程非常简单，并且它能够支持更简单的开发方法，因为您可以与团队中的其他人共享容器。它还打开了将您的机器学习应用程序部署到更多平台的选项。接下来，让我们谈谈如何自动构建和部署容器。
- en: Automatically build container via GitHub Actions and push to GitHub Container
    Registry
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过 GitHub Actions 自动构建容器并推送到 GitHub 容器注册表
- en: 'As covered earlier in the book, the container workflow of GitHub Actions is
    a valuable ingredient for many recipes. It may make sense to build a container
    programmatically with GitHub Actions and push it to the GitHub Container Registry.
    This step could serve both as a test of the container build process and deploy
    target—say you are deploying the CLI tool discussed earlier. This example is what
    that code looks like in practice. Note you would need to change the `tags` to
    your Container Registry (shown in [Figure 7-22](#Figure-7-2-4)):'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本书前面所述，GitHub Actions 的容器工作流对于许多场景都是一种有价值的成分。通过 GitHub Actions 自动构建容器并推送到
    GitHub 容器注册表是有意义的。这一步骤可以同时作为容器构建过程和部署目标的测试，比如您要部署前面讨论过的 CLI 工具。下面是实际的代码示例。请注意，您需要更改
    `tags` 来匹配您的容器注册表（如 [图 7-22](#Figure-7-2-4) 所示）：
- en: '[PRE27]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![pmlo 0722](Images/pmlo_0722.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0722](Images/pmlo_0722.png)'
- en: Figure 7-22\. GitHub Container Registry
  id: totrans-265
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-22\. GitHub 容器注册表
- en: SaaS (software as a service) build systems and SaaS container registries are
    helpful outside of just the core cloud environment. They verify to the developers
    both inside and outside your company that the container workflow is valid. Next,
    let’s tie together many of the concepts in this chapter and use a high-level PaaS
    offering.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: SaaS（即服务软件）构建系统和 SaaS 容器注册表不仅仅在核心云环境之外也很有帮助。它们向开发人员验证，无论是内部还是外部的开发人员，容器工作流程都是有效的。接下来，让我们将本章的许多概念联系起来，使用一个高级
    PaaS 提供。
- en: AWS App Runner Flask microservice
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS App Runner Flask 微服务
- en: AWS App Runner is a high-level service that dramatically simplifies MLOps. For
    example, the previous Python MLOps cookbook recipes are straightforward to integrate
    with just a few AWS App Runner service clicks. In addition, as [Figure 7-23](#Figure-7-2-1-1)
    shows, AWS App Runner points to a source code repo, and it will auto-deploy on
    each change to GitHub.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: AWS App Runner 是一个高级服务，大大简化了 MLOps。例如，之前的 Python MLOps cookbook 配方只需几次 AWS App
    Runner 服务点击即可轻松集成。此外，如[图 7-23](#Figure-7-2-1-1)所示，AWS App Runner 指向一个源代码库，并且它会在每次
    GitHub 更改时自动部署。
- en: Once it’s deployed, you can open up either AWS Cloud9 or AWS CloudShell, clone
    the Python MLOps Cookbook repo, and then use *utilscli.py* to query the endpoint
    given to you from the App Runner service. The successful query in AWS CloudShell
    is displayed in [Figure 7-24](#Figure-7-2-1-2).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦部署完成，您可以打开 AWS Cloud9 或 AWS CloudShell，克隆 Python MLOps Cookbook 存储库，然后使用 *utilscli.py*
    查询来自 App Runner 服务的端点。在 AWS CloudShell 中成功查询显示在[图 7-24](#Figure-7-2-1-2)中。
- en: '![pmlo 0723](Images/pmlo_0723.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0723](Images/pmlo_0723.png)'
- en: Figure 7-23\. AWS App Runner
  id: totrans-271
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-23\. AWS App Runner
- en: '![pmlo 0724](Images/pmlo_0724.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0724](Images/pmlo_0724.png)'
- en: Figure 7-24\. AWS App Runner prediction result
  id: totrans-273
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-24\. AWS App Runner 预测结果
- en: In a nutshell, high-level AWS services allow you to do MLOps more efficiently
    since less effort goes toward DevOps build processes. So next, let’s move onto
    another computer option for AWS, AWS Lambda.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，高级 AWS 服务使您能够更高效地进行 MLOps，因为较少的工作量用于 DevOps 构建流程。接下来，让我们转向 AWS 的另一个计算机选项，AWS
    Lambda。
- en: AWS Lambda Recipes
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS Lambda 配方
- en: Install [SAM (AWS Serverless Application Model) as AWS documentation instructs](https://oreil.ly/94HDD).
    AWS Cloud9 has it installed already. You can [find the recipes on GitHub](https://oreil.ly/AM38b).
    AWS Lambda is essential because of how deeply integral it is to AWS. Let’s explore
    how to use modern best practices to deploy a serverless ML model next.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 安装[SAM（AWS 无服务器应用程序模型）如 AWS 文档所示](https://oreil.ly/94HDD)。AWS Cloud9 已经安装了它。您可以在
    GitHub 上[找到配方](https://oreil.ly/AM38b)。AWS Lambda 是重要的，因为它与 AWS 的深度集成。让我们探讨如何使用现代最佳实践部署无服务器
    ML 模型。
- en: An efficient and recommended method to deploy software to production is through
    [SAM](https://oreil.ly/uhBSr). This approach’s innovation combines Lambda functions,
    event sources, and other resources as a deployment process and development toolkit.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 一种有效且推荐的将软件部署到生产环境的方法是通过[SAM](https://oreil.ly/uhBSr)。这种方法的创新结合了 Lambda 函数、事件源和其他资源作为部署过程和开发工具包。
- en: In particular, the key benefits of SAM, according to AWS, include single-deployment
    configuration, an extension of AWS CloudFormation, built-in best practices, local
    debugging and testing, and deep integration with development tools, including
    my favorite, Cloud9.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，根据 AWS 的说法，SAM 的关键优势包括单一部署配置、AWS CloudFormation 的扩展、内置最佳实践、本地调试和测试，以及与开发工具（包括我喜欢的
    Cloud9）的深度集成。
- en: To get started, first, you should [install the AWS SAM CLI](https://oreil.ly/qPVNh).
    After that, you can refer to the official guide for the best results.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，首先应该[安装 AWS SAM CLI](https://oreil.ly/qPVNh)。之后，可以参考官方指南获取最佳结果。
- en: AWS Lambda-SAM Local
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS Lambda-SAM Local
- en: 'To get started with SAM Local, you can try the following workflow for a new
    project:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 SAM Local，您可以尝试以下新项目的工作流程：
- en: Install SAM (as shown previously)
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 SAM（如前所示）
- en: '`sam init`'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sam init`'
- en: '`sam local invoke`'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sam local invoke`'
- en: Note
  id: totrans-285
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'If building on Cloud9, it’s probably a good idea to resize using [utils/resize.sh](https://oreil.ly/Tony1):'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在 Cloud9 上构建，使用[utils/resize.sh](https://oreil.ly/Tony1)调整大小可能是个好主意：
- en: '[PRE28]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This trick gives you more disk size to build multiple containers with SAM local
    or any other AWS Container workflow.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这个技巧可以为您提供更大的磁盘大小，以构建多个容器，使用 SAM local 或任何其他 AWS 容器工作流程。
- en: 'Here is a typical SAM init layout, which is only slightly different for an
    ML project:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个典型的 SAM 初始化布局，对于 ML 项目来说稍有不同：
- en: '[PRE29]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: With this foundational knowledge in place, let’s move on to doing more with
    AWS Lambda and SAM.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些基础知识，让我们继续深入了解如何使用 AWS Lambda 和 SAM。
- en: AWS Lambda-SAM Containerized Deploy
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS Lambda-SAM 容器化部署
- en: 'Now let’s dive into a containerized workflow for SAM since it supports registering
    a container that AWS Lambda uses. You can see the [containerized SAM-Lambda deploy
    the project in the following repo](https://oreil.ly/3ALrA). First, let’s cover
    the key components. The critical steps to deploy to SAM include the following
    files:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们深入了解 SAM 的容器化工作流程，因为它支持注册 AWS Lambda 使用的容器。您可以在以下存储库中查看 [容器化 SAM-Lambda
    部署项目](https://oreil.ly/3ALrA)。首先，让我们介绍关键组件。部署到 SAM 的关键步骤包括以下文件：
- en: '*App.py* (the AWS Lambda entry point)'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*App.py*（AWS Lambda 入口点）'
- en: The Dockerfile (what gets built and sent to Amazon ECR)
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dockerfile（用于构建并发送到 Amazon ECR 的内容）
- en: '*Template.yaml* (used by SAM to deploy the app)'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Template.yaml*（SAM 用于部署应用程序的模板）'
- en: 'The lambda handler does very little because the hard work is still happening
    in the *mlib.py* library. One “gotcha” to be aware of with AWS Lambda is that
    you need to use different logic handling in lambda functions depending on how
    they are invoked. For example, if the Lambda invokes via the console or Python,
    then there is no web request body, but in the case of integration with API Gateway,
    the payload needs to be extracted from the `body` of the event:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 处理程序几乎没有做什么，因为所有的工作仍然在 *mlib.py* 库中进行。在使用 AWS Lambda 时需要注意的一个“陷阱”是，根据调用方式，Lambda
    函数需要使用不同的逻辑处理。例如，如果 Lambda 通过控制台或 Python 调用，则没有 Web 请求体，但在与 API 网关集成的情况下，需要从事件的
    `body` 中提取负载：
- en: '[PRE30]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The project contains a Dockerfile that builds the lambda for the ECR location.
    Notice that it can pack into the Docker container in the case of a smaller ML
    model and even be programmatically retrained and packed via AWS CodeBuild:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 项目包含一个 Dockerfile，用于构建位于 ECR 位置的 Lambda。注意，在较小的 ML 模型的情况下，它可以打包进 Docker 容器中，甚至可以通过
    AWS CodeBuild 进行程序化的重新训练和打包：
- en: '[PRE31]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The SAM template controls the IaC (Infrastructure as Code) layer, allowing
    for an easy deployment process:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: SAM 模板控制 IaC（基础设施即代码）层，使部署过程变得简单：
- en: '[PRE32]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The only steps left to do are to run two commands: `sam build` and `sam deploy
    --guided`, which allows you to walk through the deployment process. For example,
    in [Figure 7-25](#Figure-7-2-7), the `sam build` notice builds the container and
    then prompts you to either test locally via `sam local invoke` or do the guided
    deploy.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下要做的步骤就是运行两个命令：`sam build` 和 `sam deploy --guided`，这允许您通过部署过程。例如，在 [图 7-25](#Figure-7-2-7)
    中，`sam build` 通知构建容器，然后提示您要么通过 `sam local invoke` 进行本地测试，要么执行引导部署。
- en: '![pmlo 0726](Images/pmlo_0726.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0726](Images/pmlo_0726.png)'
- en: Figure 7-25\. SAM build
  id: totrans-305
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-25\. SAM 构建
- en: 'You can invoke a `sam local invoke -e payload.json` with the following body
    to test locally:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令 `sam local invoke -e payload.json` 调用本地测试：
- en: '[PRE33]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Notice that the container spins up, and a payload is sent and returned. This
    testing process is invaluable before your deploy the application to ECR:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，容器启动并发送负载返回。在将应用程序部署到 ECR 之前，这个测试过程非常有价值：
- en: '[PRE34]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: You can do a guided deployment with testing out of the way, as shown in [Figure 7-26](#Figure-7-2-8).
    Take special note that the prompts guide each step of the deployment process if
    you select this option.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成测试后，您可以进行引导式部署，如 [图 7-26](#Figure-7-2-8) 所示。特别注意，如果选择此选项，提示将引导每个部署步骤。
- en: '![pmlo 0727](Images/pmlo_0727.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0727](Images/pmlo_0727.png)'
- en: Figure 7-26\. SAM guided deploy
  id: totrans-312
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-26\. SAM 引导部署
- en: Once you have deployed your lambda, there are multiple ways to both use it and
    test it. Perhaps one of the easiest is to verify the image is via the AWS Lambda
    Console (see [Figure 7-27](#Figure-7-2-9)).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦部署了 Lambda，有多种方式可以使用和测试它。其中一种最简单的方式是通过 AWS Lambda 控制台验证图像（参见 [图 7-27](#Figure-7-2-9)）。
- en: '![pmlo 0728](Images/pmlo_0728.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0728](Images/pmlo_0728.png)'
- en: Figure 7-27\. Test AWS Lambda in Console
  id: totrans-315
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-27\. 在控制台中测试 AWS Lambda
- en: Two ways to test the actual API itself include the AWS Cloud9 Console and also
    the Postman tool. Figures [7-29](#Figure-7-2-10) and [7-30](#Figure-7-2-11) show
    examples of both.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 测试实际 API 的两种方法包括 AWS Cloud9 控制台和 Postman 工具。图示分别展示了 [图 7-29](#Figure-7-2-10)
    和 [图 7-30](#Figure-7-2-11) 的示例。
- en: '![pmlo 0729](Images/pmlo_0729.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0729](Images/pmlo_0729.png)'
- en: Figure 7-28\. Invoke Lambda Cloud9
  id: totrans-318
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-28\. 调用 Lambda Cloud9
- en: '![pmlo 0730](Images/pmlo_0730.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0730](Images/pmlo_0730.png)'
- en: Figure 7-29\. Test AWS Lambda with Postman
  id: totrans-320
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-29\. 使用 Postman 测试 AWS Lambda
- en: Other deployment targets to consider deploying this base machine learning recipe
    include Flask Elastic Beanstalk and AWS Fargate. Different variations on the recipe
    include other HTTP services, such as [fastapi](https://oreil.ly/YVz0t), or the
    use of a pretrained model available via the AWS Boto3 API versus training your
    model.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 其他部署目标，考虑部署这个基础机器学习配方的包括Flask Elastic Beanstalk和AWS Fargate。对这个配方的不同变体包括其他HTTP服务，如[fastapi](https://oreil.ly/YVz0t)，或者使用通过AWS
    Boto3 API可用的预训练模型而不是训练您自己的模型。
- en: AWS Lambda is one of the most exciting technologies to build distributed systems
    that incorporate data engineering and machine learning engineering. Let’s talk
    about a real-world case study next.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda是构建集成数据工程和机器学习工程的分布式系统中最激动人心的技术之一。接下来让我们谈一个真实案例研究。
- en: Applying AWS Machine Learning to the Real World
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将AWS机器学习应用于现实世界
- en: Let’s dive into examples of how to use AWS machine learning resources in the
    real world. In this section, several MLOps take on what is involved in actual
    companies doing machine learning.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨如何在现实世界中使用AWS机器学习资源的示例。在本节中，几个MLOps负责实际公司进行机器学习的部分。
- en: Note
  id: totrans-325
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'There are many ways to use AWS for MLOps and an almost infinite number of real-world
    combinations of services. Here is a partial list of recommended machine learning
    engineering patterns on AWS:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多方法可以在MLOps中使用AWS，以及几乎无数种服务的实际组合。以下是AWS上推荐的部分机器学习工程模式列表：
- en: Container as a service (CaaS)
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 容器即服务（CaaS）
- en: For organizations struggling to get something going, CaaS is a great place to
    start the MLOps journey. A recommended service is AWS App Runner.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些难以推动某些事情的组织来说，CaaS是开始MLOps旅程的一个好地方。推荐的服务是AWS App Runner。
- en: SageMaker
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker
- en: For larger organizations with different teams and big data, SageMaker is an
    excellent platform to focus on because it allows for fine-grained security and
    enterprise-level deployment and training.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 对于拥有不同团队和大数据的大型组织，SageMaker是一个出色的平台，因为它允许进行细粒度安全和企业级部署和训练。
- en: Serverless with AI APIs
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AI API的无服务器方案
- en: For small startups that need to move very quickly, an excellent initial approach
    to doing MLOps is to use pretrained models via an API along with a serverless
    technology like AWS Lambda.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要迅速推进的小型初创公司，一个极好的初始方法是使用预训练模型通过API以及像AWS Lambda这样的无服务器技术进行MLOps。
- en: Conclusion
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This chapter covers both well-traveled roads and unique corners of AWS. A key
    takeaway is that AWS is the largest cloud platform. There are many different ways
    to approach a problem using AWS technology, from building an entire company that
    does machine learning, as the case studies discuss, to using high-level Computer
    Vision APIs.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了AWS的熟悉领域和独特角落。一个关键的经验教训是AWS是最大的云平台。使用AWS技术解决问题的方法有很多，从像案例研究讨论的那样构建一家全面从事机器学习的公司，到使用高级计算机视觉API。
- en: 'In particular, for business and technical leaders, I would recommend the following
    best practices to bootstrap MLOps capabilities as quickly as possible:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是对于业务和技术领导者，我建议采用以下最佳实践，尽快启动MLOps能力：
- en: Engage with AWS Enterprise Support.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与AWS企业支持互动。
- en: Get your team certified on AWS starting with the AWS Solutions Architect or
    Cloud Practitioner exam and AWS Certified Machine Learning Specialty.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让您的团队从AWS解决方案架构师或云从业者考试以及AWS认证机器学习专业人士开始认证。
- en: Obtain quick wins by using AI APIs like AWS Comprehend, AWS Rekognition, and
    high-level PaaS offerings like AWS App Runner or AWS Lambda.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用像AWS Comprehend、AWS Rekognition这样的AI API以及像AWS App Runner或AWS Lambda这样的高级PaaS产品，获得快速成功。
- en: Focus on automation and ensure that you automate everything you can, from the
    data ingestion and the feature store to the modeling and the deployment of the
    ML model.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于自动化，并确保您能自动化的所有内容，从数据摄入和特征存储到建模和ML模型的部署。
- en: Start using SageMaker as an MLOps long-term investment and use it for longer
    term or more complex projects alongside more accessible solutions.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始将SageMaker作为MLOps的长期投资，并将其用于更长期或更复杂的项目以及更易访问的解决方案。
- en: Finally, if you are serious about using AWS as an individual, including starting
    a career as an AWS machine learning expert, it can be beneficial and lucrative
    to get certified. [Appendix B](app02.xhtml#cloud-certification) gives you a quick
    primer on how to prepare for the AWS Certification exams. A final recommended
    task would be to go through some exercises and critical thinking questions to
    practice AWS further.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果你想在个人层面认真使用AWS，并希望作为AWS机器学习专家开始职业生涯，获得认证可能非常有益和有利可图。[附录 B](app02.xhtml#cloud-certification)为你提供了如何准备AWS认证考试的快速入门指南。最后推荐的任务是通过一些练习和批判性思维问题进一步练习AWS技能。
- en: Our next chapter moves away from AWS and digs into Azure.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一章不再涉及AWS，而是深入研究Azure。
- en: Exercises
  id: totrans-343
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Build a machine learning continuous delivery pipeline for a Flask web service
    using Elastic Beanstalk. You can refer to the [GitHub repository](https://oreil.ly/J5Btz)
    as a starting point.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Elastic Beanstalk为Flask Web服务构建一个机器学习持续交付管道。你可以参考这个[GitHub仓库](https://oreil.ly/J5Btz)作为起点。
- en: Start an Amazon SageMaker instance and build and deploy the [US census data
    for the population segmentation example](https://oreil.ly/yKrhb).
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动一个Amazon SageMaker实例，并构建和部署[美国人口普查数据用于人口分割示例](https://oreil.ly/yKrhb)。
- en: Build a CaaS machine learning prediction service using AWS Fargate. You can
    use this [GitHub repo](https://oreil.ly/opQJh) as a starting point.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用AWS Fargate构建一个CaaS机器学习预测服务。你可以使用这个[GitHub仓库](https://oreil.ly/opQJh)作为起点。
- en: Build a serverless data engineering prototype using this [GitHub repo](https://oreil.ly/3klFK)
    as a starting point.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用这个[GitHub仓库](https://oreil.ly/3klFK)作为起点，构建一个无服务器数据工程原型。
- en: Build a computer vision trigger that detects labels; use this [GitHub repo](https://oreil.ly/xKv0p)
    as a starting point.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用这个[GitHub仓库](https://oreil.ly/xKv0p)作为起点，构建一个检测标签的计算机视觉触发器。
- en: 'Use the MLOps Cookbook base project and deploy to as many different targets
    as you can: Containerized CLI, EKS, Elastic Beanstalk, Spot Instances, and anything
    else you can think of.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MLOps Cookbook基础项目，并部署到尽可能多的不同目标：容器化CLI、EKS、Elastic Beanstalk、Spot实例，以及你能想到的其他任何目标。
- en: Critical Thinking Discussion Questions
  id: totrans-350
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批判性思维讨论问题
- en: Why do organizations doing machine learning use a data lake? What is the core
    problem they solve?
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么从事机器学习的组织会使用数据湖？它们解决了什么核心问题？
- en: What is a use case for using prebuilt models like AWS Comprehend versus training
    your sentiment analysis model?
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预构建模型如AWS Comprehend与训练自己的情感分析模型相比，有什么使用案例？
- en: Why would an organization use AWS SageMaker versus Pandas, sklearn, Flask, and
    Elastic Beanstalk? What are the use cases for both?
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么组织会选择AWS SageMaker而不是Pandas、sklearn、Flask和Elastic Beanstalk？它们各自的使用案例是什么？
- en: What are the advantages of a containerized machine learning model deployment
    process?
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是容器化机器学习模型部署流程的优势？
- en: A colleague says they are confused about where to start with machine learning
    on AWS due to the variety of offerings. How would you recommend they approach
    their search?
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一位同事说他们对如何开始AWS上的机器学习感到困惑，因为提供了多种服务。你会如何推荐他们开始搜索？
