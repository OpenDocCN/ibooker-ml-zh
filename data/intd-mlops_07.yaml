- en: Chapter 5\. Preparing for Production
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章。准备生产
- en: Joachim Zentici
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Joachim Zentici
- en: Confirming that something works in the laboratory has never been a sure sign
    it will work well in the real world, and machine learning models are no different.
    Not only is the production environment typically very different from the development
    environment, but the commercial risks associated with models in production are
    much greater. It is important that the complexities of the transition to production
    are understood and tested and that the potential risks have been adequately mitigated.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 确认某些东西在实验室中运行良好从来不是它在真实世界中运行良好的确切标志，机器学习模型也不例外。生产环境通常与开发环境大不相同，而与生产中模型相关的商业风险则更大。重要的是要理解和测试生产过渡的复杂性，并充分减轻潜在风险。
- en: This chapter explores the steps required to prepare for production (highlighted
    in the context of the entire life cycle in [Figure 5-1](#preparing_for_production_highlighted_in)).
    The goal is to illustrate, by extension, the elements that must be considered
    for robust MLOps systems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了为生产做好准备所需的步骤（在整个生命周期的背景下突出显示在[图 5-1](#preparing_for_production_highlighted_in)中）。目标是通过扩展来说明必须考虑的用于强大
    MLOps 系统的元素。
- en: '![](assets/imlo_0501.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/imlo_0501.png)'
- en: Figure 5-1\. Preparing for production highlighted in the larger context of the
    ML project life cycle
  id: totrans-5
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-1。在 ML 项目生命周期的更大背景下突出显示的准备生产
- en: Runtime Environments
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行时环境
- en: The first step in sending a model to production is making sure it’s technically
    possible. As discussed in [Chapter 3](ch03.html#key_mlops_features), ideal MLOps
    systems favor rapid, automated deployment over labor-intensive processes, and
    runtime environments can have a big effect on which approach prevails.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型部署到生产环境的第一步是确保技术上可行。正如在[第三章](ch03.html#key_mlops_features)中讨论的那样，理想的 MLOps
    系统更倾向于快速、自动化的部署，而不是繁琐的流程，运行时环境可能会极大地影响哪种方法更为主流。
- en: 'Production environments take a wide variety of forms: custom-built services,
    data science platforms, dedicated services like TensorFlow Serving, low-level
    infrastructure like Kubernetes clusters, JVMs on embedded systems, etc. To make
    things even more complex, consider that in some organizations, multiple heterogeneous
    production environments coexist.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 生产环境采用多种形式：定制服务、数据科学平台、像 TensorFlow Serving 这样的专用服务、低级基础设施如 Kubernetes 集群、嵌入式系统上的
    JVM 等等。更复杂的是，考虑到某些组织中存在多个异构的生产环境并存。
- en: Ideally, models running in the development environment would be validated and
    sent as is to production; this minimizes the amount of adaptation work and improves
    the chances that the model in production will behave as it did in development.
    Unfortunately, this ideal scenario is not always possible, and it’s not unheard
    of that teams finish a long-term project only to realize it can’t be put in production.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，运行在开发环境中的模型可以直接验证并如同原样送到生产环境；这样可以最小化适应工作量，并提高模型在生产中表现与开发中一致的机会。不幸的是，这种理想情况并不总是可能的，有时团队在长期项目完成后却发现无法投入生产。
- en: Adaptation from Development to Production Environments
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从开发到生产环境的适应
- en: In terms of adaptation work, on one end of the spectrum, the development and
    production platforms are from the same vendor or are otherwise interoperable,
    and the dev model can run without any modification in production. In this case,
    the technical steps required to push the model into production are reduced to
    a few clicks or commands, and all efforts can be focused on validation.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在适应工作方面，从开发到生产平台的两端可能来自同一供应商或者可互操作，开发模型可以在生产中无需任何修改即可运行。在这种情况下，将模型推送到生产所需的技术步骤被简化为几次点击或命令，所有的努力都可以集中在验证上。
- en: On the other end of the spectrum, there are cases where the model needs to be
    reimplemented from scratch—possibly by another team, and possibly in another programming
    language. Given the resources and time required, there are few cases today where
    this approach makes sense. However, it’s still the reality in many organizations
    and is often a consequence of the lack of appropriate tooling and processes. The
    reality is that handing over a model for another team to reimplement and adapt
    for the production environment means that model won’t reach production for months
    (maybe years), if at all.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，有些情况下需要从头开始重新实现模型，可能是由另一个团队完成，可能是用另一种编程语言。考虑到所需的资源和时间，今天有很少的情况适合这种方法。然而，在许多组织中，这仍然是现实，并且往往是由于缺乏合适的工具和流程。事实上，将模型交给另一个团队重新实现并适应生产环境意味着该模型可能需要数月（甚至数年）才能投入生产，如果能投入的话。
- en: Between these two extreme cases, there can be a number of transformations performed
    on the model or the interactions with its environment to make it compatible with
    production. In all cases, it is crucial to perform validation in an environment
    that mimics production as closely as possible, rather than in the development
    environment.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种极端情况之间，可以对模型或与其环境的交互执行许多转换。在所有情况下，至关重要的是在尽可能接近生产环境的环境中进行验证，而不是在开发环境中进行验证。
- en: Tooling considerations
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工具考虑
- en: The format required to send to production should be considered early, as it
    may have a large impact on the model itself and the quantity of work required
    to productionalize it. For example, when a model is developed using scikit-learn
    (Python) and production is a Java-based environment that expects PMML or ONNX
    as input, conversion is obviously required.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 发送到生产环境所需的格式应该早早考虑，因为它可能对模型本身和生产工作的数量产生重大影响。例如，当使用 scikit-learn（Python）开发模型，而生产环境是期望输入
    PMML 或 ONNX 的基于 Java 的环境时，显然需要进行转换。
- en: In this case, teams should set up tooling while developing the model, ideally
    before the first version of the model is finished or even started. Failure to
    create this pipeline up front would block the validation process (and, of course,
    final validation should not be performed on the scikit-learn model, as it’s not
    the one that will be put into production).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，团队应在开发模型时设置工具链，最好在第一个版本完成甚至开始之前。如果未能提前创建此流程，将会阻塞验证过程（当然，最终验证不应该在 scikit-learn
    模型上执行，因为它不是将投入生产的模型）。
- en: Performance considerations
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 性能考虑
- en: Another common reason conversion may be required is for performance. For example,
    a Python model will typically have higher latency for scoring a single record
    than its equivalent converted to C++. The resulting model will likely be dozens
    of times faster (although obviously it depends on many factors, and the result
    can also be a model that is dozens of times slower).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的转换需求是出于性能考虑。例如，Python 模型通常在对单个记录进行评分时的延迟要高于其转换为 C++ 的等效模型。由此产生的模型可能会快几十倍（尽管显然这取决于许多因素，结果也可能是速度慢几十倍的模型）。
- en: Performance also comes into play when the production model must run on a low-power
    device. In the specific case of deep neural networks, for example, trained models
    can become extremely large with billions or hundreds of billions of parameters.
    Running them on small devices is simply impossible, and running them on standard
    servers can be slow and expensive.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当生产模型必须在低功耗设备上运行时，性能也是一个考虑因素。例如，在深度神经网络的特定情况下，训练模型可能会变得极其庞大，拥有数十亿或数百亿个参数。在小设备上运行它们简直是不可能的，而在标准服务器上运行它们可能会慢且昂贵。
- en: 'For these models, an optimized runtime is not enough. To obtain better performance,
    the model definition must be optimized. One solution is to use compression techniques:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些模型，仅优化运行时是不够的。为了获得更好的性能，必须优化模型定义。一种解决方案是使用压缩技术：
- en: With quantization, the model can be trained using 32-bit floating-point numbers
    and used for inference at a lower precision so that the model requires less memory
    and is faster while accuracy is mostly preserved.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过量化，模型可以使用32位浮点数进行训练，并以较低精度进行推断，从而减少模型的内存需求并提高速度，同时基本保持精度。
- en: With pruning, one simply removes weights (or even entire layers) from the neural
    network. This is a rather radical approach, but some methods allow for the preservation
    of accuracy.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过修剪，可以简单地从神经网络中移除权重（甚至整个层）。这是一个相当激进的方法，但一些方法可以保持精度。
- en: With distillation, a smaller “student” network is trained to mimic a bigger,
    more powerful network. Done appropriately, this can lead to better models (as
    compared to trying to train the smaller network directly from the data).
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用蒸馏，可以训练一个更小的“学生”网络来模仿一个更大、更强大的网络。如果操作得当，这可以比直接从数据训练更小的网络得到更好的模型。
- en: These methods are efficient if the initial model is trained in a way that reduces
    information loss while performing them, so these operations are not simply conversions
    of the trained model post hoc, but rather orient the way the model is trained.
    These methods are still very recent and quite advanced but already commonly used
    in natural language processing (NLP) pretrained models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果初始模型在训练时减少信息损失，这些方法就会非常有效，因此这些操作不仅仅是事后将训练好的模型进行转换，而是调整模型训练方式的方向。这些方法虽然很新，也很先进，但在预训练的自然语言处理（NLP）模型中已经广泛应用。
- en: Data Access Before Validation and Launch to Production
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在验证和投入生产之前获取数据访问权限
- en: Another technical aspect that needs to be addressed before validation and launch
    to production is data access. For example, a model evaluating apartment prices
    may use the average market price in a zip code area; however, the user or the
    system requesting the scoring will probably not provide this average and would
    most likely provide simply the zip code, meaning a lookup is necessary to fetch
    the value of the average.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要在验证和投入生产之前解决的技术问题是数据访问。例如，评估公寓价格的模型可能会使用邮政编码区域的市场平均价格；然而，请求评分的用户或系统可能不会提供这个平均值，而只会提供邮政编码，这意味着需要查找以获取平均值。
- en: In some cases, data can be frozen and bundled with the model. But when this
    is not possible (e.g., if the dataset is too large or the enrichment data needs
    to always be up to date), the production environment should access a database
    and thus have the appropriate network connectivity, libraries, or drivers required
    to communicate with the data storage installed, and authentication credentials
    stored in some form of production configuration.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，数据可以被冻结并与模型捆绑。但当这不可能时（例如，数据集太大或丰富数据需要始终保持最新状态），生产环境应该访问数据库，因此必须安装适当的网络连接、库或驱动程序以与数据存储通信，并存储在某种形式的生产配置中的认证凭据。
- en: Managing this setup and configuration can be quite complex in practice since,
    again, it requires appropriate tooling and collaboration (in particular to scale
    to more than a few dozen models). When using external data access, model validation
    in situations that closely match production is even more critical as technical
    connectivity is a common source of production malfunction.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中管理这种设置和配置可能非常复杂，因为它需要适当的工具和协作（特别是在扩展到超过几十个模型时）。在使用外部数据访问时，在与生产紧密匹配的情况下进行模型验证尤为关键，因为技术连接常常是生产故障的常见源头。
- en: Final Thoughts on Runtime Environments
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对运行时环境的最终思考
- en: Training a model is usually the most impressive computation, requiring a high
    level of software sophistication, massive data volumes, and high-end machines
    with powerful GPUs. But in the whole life cycle of a model, there is a good chance
    that most of the compute is spent at inference time (even if this computation
    is orders of magnitude simpler and faster). This is because a model is trained
    once and can be used billions of times for inference.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型通常是最耗费计算资源的过程，需要高级软件技术、海量数据和配置强大的GPU高端机器。但在模型的整个生命周期中，大部分计算资源很可能都会在推理时消耗（即使这种计算比训练简单和快得多）。这是因为模型只需训练一次，就可以用于数十亿次推理。
- en: Scaling inference on complex models can be expensive and have significant energy
    and environmental impact. Lowering the complexity of models or compressing extremely
    complex models can lower the infrastructure cost of operating machine learning
    models.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在复杂模型上扩展推理可能非常昂贵，并且具有显著的能源和环境影响。降低模型复杂性或压缩极其复杂的模型可以降低操作机器学习模型的基础设施成本。
- en: It’s important to remember that not all applications require deep learning,
    and in fact, not all applications require machine learning at all. A valuable
    practice to control complexity in production is to develop complex models only
    to provide a baseline for what seems achievable. What goes into production can
    then be a much simpler model, with the advantages of lowering the operating risk,
    increasing computational performance, and lowering power consumption. If the simple
    model is close enough to the high complexity baseline, then it can be a much more
    desirable solution for production.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，并非所有应用程序都需要深度学习，事实上，并非所有应用程序都需要机器学习。在生产中控制复杂性的一种有价值的实践是仅开发复杂模型以提供看似可行的基准。然后，投入生产的可以是一个更简单的模型，具有降低操作风险、提高计算性能和降低功耗的优点。如果简单模型接近高复杂性基准，那么它可能是更为理想的解决方案。
- en: Model Risk Evaluation
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型风险评估
- en: Before exploring how validation should be done in an ideal MLOps system, it’s
    important to consider the purpose of validation. As discussed in [Chapter 4](ch04.html#developing_models),
    models attempt to mimic reality, but they are imperfect; their implementation
    can have bugs, as can the environment they are executing in. The indirect, real-world
    impact a model in production can have is never certain, and the malfunctioning
    of a seemingly insignificant cog can have tremendous consequences in a complex
    system.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在探讨在理想的 MLOps 系统中如何进行验证之前，重要的是考虑验证的目的。如[第四章](ch04.html#developing_models)所述，模型试图模拟现实，但它们是不完美的；它们的实施可能存在错误，环境也可能存在问题。模型在生产中可能产生的间接实际影响从未确定，看似微不足道的零件故障可能在复杂系统中造成巨大后果。
- en: The Purpose of Model Validation
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型验证的目的
- en: It is, to some extent, possible (not to mention absolutely necessary) to anticipate
    the risks of models in production and thus design and validate so as to minimize
    these risks. As organizations become more and more complex, it is essential to
    understand that involuntary malfunctions or malicious attacks are potentially
    threatening in most uses of machine learning in the enterprise, not only in financial
    or safety-related applications.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在某种程度上，预见在生产中模型的风险并设计和验证以尽量减少这些风险是可能的（更不用说绝对必要的）。随着组织变得越来越复杂，了解机器学习在企业中的大多数应用中无意故障或恶意攻击潜在威胁的重要性至关重要，这不仅限于金融或与安全相关的应用。
- en: 'Before putting a model in production (and in fact constantly from the beginning
    of the machine learning project), teams should ask the uncomfortable questions:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型投入生产之前（事实上，从机器学习项目开始的时候就应该如此），团队应该问一些不舒服的问题：
- en: What if the model acts in the worst imaginable way?
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果模型以最坏的可能方式行事会发生什么？
- en: What if a user manages to extract the training data or the internal logic of
    the model?
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户成功提取了训练数据或模型的内部逻辑会发生什么？
- en: What are the financial, business, legal, safety, and reputational risks?
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 金融、商业、法律、安全和声誉风险是什么？
- en: For high-risk applications, it is essential that the whole team (and in particular
    the engineers in charge of validation) be fully aware of these risks so that they
    can design the validation process appropriately and apply the strictness and complexity
    appropriate for the magnitude of the risks.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于高风险应用程序，整个团队（特别是负责验证的工程师）充分了解这些风险至关重要，以便他们可以适当地设计验证流程，并应用适合风险程度的严格性和复杂性。
- en: In many ways, machine learning risk management covers model risk management
    practices that are well established in many industries, such as banking and insurance.
    However, machine learning introduces new types of risks and liabilities, and as
    data science gets democratized, it involves many new organizations or teams that
    have no experience with more traditional model risk management.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多方面，机器学习风险管理涵盖了许多行业（如银行和保险业）中已经建立的模型风险管理实践。然而，机器学习引入了新类型的风险和责任，随着数据科学的普及化，涉及到许多没有传统模型风险管理经验的新组织或团队。
- en: The Origins of ML Model Risk
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML 模型风险的起源
- en: The magnitude of risk ML models can bring is hard to model for mathematical
    reasons, but also because the materialization of risks arises through real-world
    consequences. The ML metrics, and in particular the cost matrix, allow teams to
    evaluate the average cost of operating a model in its “nominal” case, meaning
    on its cross-validation data, compared to operating a perfect magical model.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数学原因，机器学习模型可能带来的风险大小难以建模，同时风险的具体化是通过真实世界的后果而来。机器学习指标，特别是成本矩阵，允许团队评估在其“标准”情况下运行模型的平均成本，即在其交叉验证数据上，与运行完美的魔法模型相比。
- en: 'But while computing this expected cost can be very important, a wide range
    of things can go wrong well beyond expected cost. In some applications, the risk
    can be a financially unbounded liability, a safety issue for individuals, or an
    existential threat for the organization. ML model risk originates essentially
    from:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管计算预期成本非常重要，但是事情出了意外的范围远远超出了预期成本。在某些应用中，风险可能是财务上无限的责任，个人的安全问题，或者对组织的生存威胁。机器学习模型的风险主要源自：
- en: Bugs, errors in designing, training, or evaluating the model (including data
    prep)
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在设计、训练或评估模型（包括数据准备）中的错误或缺陷
- en: Bugs in the runtime framework, bugs in the model post-processing/conversion,
    or hidden incompatibilities between the model and its runtime
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行框架中的错误，模型后处理/转换中的错误，或者模型与其运行时之间的隐藏不兼容性。
- en: Low quality of training data
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据质量低
- en: High difference between production data and training data
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产数据与训练数据之间的高差异
- en: Expected error rates, but with failures that have higher consequences than expected
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期错误率，但是失败的后果比预期更严重
- en: Misuse of the model or misinterpretation of its outputs
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的误用或其输出的误解
- en: Adversarial attacks
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对抗性攻击
- en: Legal risk originating in particular from copyright infringement or liability
    for the model output
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 法律风险，特别是来自版权侵权或对模型输出的责任
- en: Reputational risk due to bias, unethical use of machine learning, etc.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于偏见、机器学习的不道德使用等而引起的声誉风险。
- en: 'The probability of materialization of the risk and its magnitude can be amplified
    by:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 风险的具体化概率及其大小可能会被以下因素放大：
- en: Broad use of the model
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的广泛应用
- en: A rapidly changing environment
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境快速变化
- en: Complex interactions between models
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型之间复杂的交互作用
- en: The following sections provide more details on these threats and how to mitigate
    them, which should ultimately be the goal of any MLOps system the organization
    puts in place.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分详细介绍了这些威胁及其如何减轻，这应该是组织实施的任何MLOps系统的最终目标。
- en: Quality Assurance for Machine Learning
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的质量保证
- en: Software engineering has developed a mature set of tools and methodologies for
    quality assurance (QA), but the equivalent for data and models is still in its
    infancy, which makes it challenging to incorporate into MLOps processes. The statistical
    methods as well as documentation best practices are well known, but implementing
    them at scale is not common.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 软件工程已经为质量保证（QA）开发了一套成熟的工具和方法，但是数据和模型的等效物仍处于初级阶段，这使得将其纳入MLOps流程变得具有挑战性。统计方法以及文档编写的最佳实践是众所周知的，但在规模上实施并不常见。
- en: Though it’s being covered as a part of this chapter on preparing for production,
    to be clear, QA for machine learning does not occur only at the final validation
    stage; rather, it should accompany all stages of model development. Its purpose
    is to ensure compliance with processes as well as ML and computational performance
    requirements, with a level of detail that is proportionate to the level of risk.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本章在为生产准备的一部分中进行了覆盖，但要明确的是，机器学习的质量保证并不仅限于最终验证阶段；相反，它应伴随模型开发的所有阶段进行。其目的是确保符合流程以及机器学习和计算性能要求，并且其详细程度与风险水平成比例。
- en: In the case where the people in charge of validation are not the ones who developed
    the model, it is essential that they have enough training in machine learning
    and understand the risks so that they can design appropriate validation or detect
    breaches in the validation proposed by the development team. It is also essential
    that the organization’s structure and culture give them the authority to appropriately
    report issues and contribute to continuous improvement or block passage to production
    if the level of risk justifies it.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果负责验证的人员不是开发模型的人员，他们足够了解机器学习并理解风险非常重要，以便设计适当的验证或检测开发团队提出的验证中的漏洞。组织的结构和文化赋予他们适当报告问题和促进持续改进或阻止投入生产的权威同样至关重要，如果风险水平合理，必须有权利行使它。
- en: Robust MLOps practices dictate that performing QA before sending to production
    is not only about technical validation. It is also the occasion to create documentation
    and validate the model against organizational guidelines. In particular, this
    means the origin of all input datasets, pretrained models, or other assets should
    be known, as they could be subject to regulations or copyrights. For this reason
    (and for computer security reasons in particular), some organizations choose to
    allow only whitelisted dependencies. While this can significantly impact the ability
    of data scientists to innovate quickly, though the list of dependencies can be
    reported and checked partly automatically, it can also provide additional safety.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 强大的MLOps实践规定，在发送到生产之前进行QA不仅仅是技术验证。这也是创造文档和根据组织指南验证模型的机会。特别是，这意味着所有输入数据集、预训练模型或其他资产的来源都应该是已知的，因为它们可能受到法规或版权的约束。出于这个原因（特别是出于计算机安全原因），一些组织选择只允许白名单依赖项。虽然这可能会显著影响数据科学家快速创新的能力，尽管依赖项列表可以部分自动报告和检查，但也可以提供额外的安全性。
- en: Key Testing Considerations
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要测试考虑因素
- en: Obviously, model testing will consist of applying the model to carefully curated
    data and validating measurements against requirements. How the data is selected
    or generated as well as how much data is required is crucial, but it will depend
    on the problem tackled by the model.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，模型测试将包括将模型应用于精心筛选的数据，并根据要求验证测量。数据的选择或生成方式以及所需的数据量至关重要，但这将取决于模型处理的问题。
- en: There are some scenarios in which the test data should not always match “real-world”
    data. For example, it can be a good idea to prepare a certain number of scenarios,
    and while some of them should match realistic situations, other data should be
    specifically generated in ways that could be problematic (e.g., extreme values,
    missing values).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些情况下，测试数据不应总是与“真实世界”数据匹配。例如，准备一定数量的场景可能是一个好主意，其中一些场景应该与现实情况相匹配，其他数据应特别生成以可能引发问题的方式（例如，极端值、缺失值）。
- en: Metrics must be collected on both statistical (accuracy, precision, recall,
    etc.) as well as computational (average latency, 95th latency percentile, etc.)
    aspects, and the test scenarios should fail if some assumptions on them are not
    verified. For example, the test should fail if the accuracy of the model falls
    below 90%, the average inference time goes above 100 milliseconds, or more than
    5% of inferences take more than 200 milliseconds. These assumptions can also be
    called *expectations*, *checks*, or *assertions*, as in traditional software engineering.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 必须收集统计（准确性、精度、召回率等）以及计算（平均延迟、第95百分位延迟等）方面的度量，并且如果对它们的一些假设未经验证，则测试场景应该失败。例如，如果模型的准确性低于90％、平均推断时间超过100毫秒或超过5％的推断时间超过200毫秒，则测试应该失败。这些假设也可以称为*期望*、*检查*或*断言*，就像传统软件工程中一样。
- en: Statistical tests on results can also be performed but are typically used for
    subpopulations. It is also important to be able to compare the model with its
    previous version. It can allow putting in place a champion/challenger approach
    (described in detail in [“Champion/Challenger”](ch07.html#championsoliduschallenger))
    or checking that a metric does not suddenly drop.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对结果进行统计测试也是可能的，但通常用于子群体。能够比较模型与其先前版本也很重要。它可以实施冠军/挑战者方法（详细描述在[“冠军/挑战者”](ch07.html#championsoliduschallenger)）或检查指标是否突然下降。
- en: In addition to validating the ML and computational performance metrics, model
    stability is an important testing property to consider. When changing one feature
    slightly, one expects small changes in the outcome. While this cannot be always
    true, it is generally a desirable model property. A very unstable model introduces
    a lot of complexity and loopholes in addition to delivering a frustrating experience,
    as the model can feel unreliable even if it has decent performance. There is no
    single answer to model stability, but generally speaking, simpler models or more
    regularized ones show better stability.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 除了验证机器学习和计算性能指标之外，模型稳定性是一个重要的测试属性需要考虑。当略微改变一个特征时，预期结果会有轻微变化。尽管这并非总是正确的，但通常是一个期望的模型属性。一个非常不稳定的模型会引入很多复杂性和漏洞，同时即使具有良好的性能，模型也可能感觉不可靠，这会带来令人沮丧的体验。关于模型稳定性没有单一的答案，但一般来说，更简单或更规范化的模型表现出更好的稳定性。
- en: Reproducibility and Auditability
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可复现性和可审计性
- en: Reproducibility in MLOps does not have the same meaning as in academia. In the
    academic world, reproducibility essentially means that the findings of an experiment
    are described well enough that another competent person can replicate the experiment
    using the explanations alone, and if the person doesn’t make any mistakes, they
    will arrive at the same conclusion.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MLOps 中，可复现性与学术界并不具有相同的意义。在学术界，可复现性基本上意味着实验的发现描述得足够好，以至于另一位胜任的人士仅凭解释就能复制实验，如果该人没有任何错误，他们将得出相同的结论。
- en: In general, reproducibility in MLOps also involves the ability to easily rerun
    the exact same experiment. It implies that the model comes with detailed documentation,
    the data used for training and testing, and with an artifact that bundles the
    implementation of the model plus the full specification of the environment it
    was run in (see [“Version Management and Reproducibility”](ch04.html#version_management_and_reproducibility)).
    Reproducibility is essential to prove model findings, but also to debug or build
    on a previous experiment.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，在 MLOps 中，可复现性还包括轻松重新运行完全相同的实验的能力。这意味着模型配备了详细的文档、用于训练和测试的数据，并且具有捆绑模型实现以及运行环境完整规范的工件（参见[“版本管理和可复现性”](ch04.html#version_management_and_reproducibility)）。可复现性对证明模型发现至关重要，同时也有助于调试或在先前实验基础上进行构建。
- en: 'Auditability is related to reproducibility, but it adds some requirements.
    For a model to be auditable, it must be possible to access the full history of
    the ML pipeline from a central and reliable storage and to easily fetch metadata
    on all model versions including:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 可审计性与可复现性有关，但它增加了一些要求。要使模型可审计，必须能够从中心和可靠的存储访问整个 ML 管道的完整历史，并轻松获取所有模型版本的元数据，包括：
- en: The full documentation
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全面的文档
- en: An artifact that allows running the model with its exact initial environment
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个工件，允许在其精确的初始环境中运行模型
- en: Test results, including model explanations and fairness reports
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试结果，包括模型解释和公平性报告
- en: Detailed model logs and monitoring metadata
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 详细的模型日志和监控元数据
- en: Auditability can be an obligation in some highly regulated applications, but
    it has benefits for all organizations because it can facilitate model debugging,
    continuous improvement, and keeping track of actions and responsibilities (which
    is an essential part of governance for responsible applications of ML, as discussed
    at length in [Chapter 8](ch08.html#model_governance)). A full QA toolchain for
    machine learning—and, thus, MLOps processes—should provide a clear view of model
    performance with regard to requirements while also facilitating auditability.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 可审计性在某些高度监管的应用程序中可能是一种义务，但对所有组织都有益处，因为它可以促进模型调试、持续改进，并跟踪行动和责任（这是负责任地应用机器学习的治理的重要组成部分，详细讨论见[第8章](ch08.html#model_governance)）。用于机器学习和因此
    MLOps 过程的完整 QA 工具链应该提供对模型性能符合要求的清晰视图，同时也促进可审计性。
- en: Even when MLOps frameworks allow data scientists (or others) to find a model
    with all its metadata, understanding the model itself can still be challenging
    (see [“Impact of Responsible AI on Modeling”](ch04.html#impact_of_responsible_ai_on_modeling)
    for a detailed discussion).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在 MLOps 框架允许数据科学家（或其他人员）找到具有所有元数据的模型时，理解模型本身仍然可能具有挑战性（详见[“负责任人工智能对建模的影响”](ch04.html#impact_of_responsible_ai_on_modeling)进行详细讨论）。
- en: To have a strong practical impact, auditability must allow for intuitive human
    understanding of all the parts of the system and their version histories. This
    doesn’t change the fact that understanding a machine learning model (even a relatively
    simple one) requires appropriate training, but depending on the criticality of
    the application, a wider audience may need to be able to understand the details
    of the model. As a result, full auditability comes at a cost that should be balanced
    with the criticality of the model itself.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要在实践中产生强大的影响，审计必须允许直观地理解系统的所有部分及其版本历史。这并不改变理解机器学习模型（甚至是相对简单的模型）需要适当的培训的事实，但根据应用的关键性，更广泛的受众可能需要能够理解模型细节。因此，全面的审计性需要付出一定的成本，这应该与模型本身的关键性取得平衡。
- en: Machine Learning Security
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习安全
- en: As a piece of software, a deployed model running in its serving framework can
    present multiple security issues that range from low-level glitches to social
    engineering. Machine learning introduces a new range of potential threats where
    an attacker provides malicious data designed to cause the model to make a mistake.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一款软件，部署在其服务框架中的模型可能存在多个安全问题，从低级别的故障到社会工程学。机器学习引入了一系列潜在威胁，攻击者提供恶意数据，旨在使模型出错。
- en: There are numerous cases of potential attacks. For example, spam filters were
    an early application of machine learning essentially based on scoring words that
    were in a dictionary. One way for spam creators to avoid detection was to avoid
    writing these exact words while still making their message easily understandable
    by a human reader (e.g., using exotic Unicode characters, voluntarily introducing
    typos, or using images).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多潜在攻击案例。例如，垃圾邮件过滤器是机器学习的早期应用，基本上是基于对字典中的单词进行打分。垃圾邮件创作者避免检测的一种方法是避免使用这些确切的单词，同时仍然使其消息对人类读者易于理解（例如，使用异国情调的Unicode字符，故意引入拼写错误或使用图像）。
- en: Adversarial Attacks
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对抗攻击
- en: 'A more modern but quite analogous example of a machine learning model security
    issue is an adversarial attack for deep neural networks in which an image modification
    that can seem minor or even impossible for a human eye to notice can cause the
    model to drastically change its prediction. The core idea is mathematically relatively
    simple: since deep learning inference is essentially matrix multiplication, carefully
    chosen small perturbations to coefficients can cause a large change in the output
    numbers.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更现代但相当类似的例子是机器学习模型安全问题中的对抗攻击，特别是针对深度神经网络的对抗攻击，其中对人眼来说可能看起来微小甚至不可能察觉的图像修改可以导致模型显著改变其预测。其核心思想在数学上相对简单：由于深度学习推理本质上是矩阵乘法，精心选择的小扰动系数可以导致输出数字的大幅变化。
- en: '[One example of this](https://arxiv.org/abs/1707.08945) is that small stickers
    glued to road signs can confuse an autonomous car’s computer vision system, rendering
    signs invisible or incorrectly classified by the system, while remaining fully
    visible and understandable to a human being. The more the attacker knows about
    the system, the more likely they are to find examples that will confuse it.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[这个例子](https://arxiv.org/abs/1707.08945)是，小贴纸粘在路标上可以迷惑自动驾驶汽车的计算机视觉系统，使得标志对系统来说看不见或者分类错误，但对人类来说仍然是完全可见和理解的。攻击者对系统了解越多，就越有可能找到能够迷惑它的例子。'
- en: A human can use reason to find these examples (in particular for simple models).
    However, for more complex models like deep learning, the attacker will probably
    need to perform many queries and either use brute force to test as many combinations
    as possible or use a model to search for problematic examples. The difficulty
    of countermeasures is increasing with the complexity of models and their availability.
    Simple models such as logistic regressions are essentially immune, while an open
    source pretrained deep neural network will basically always be vulnerable, even
    with advanced, [built-in attack detectors](https://arxiv.org/abs/1705.07263).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 人类可以使用理性来找到这些例子（特别是对于简单模型）。然而，对于更复杂的深度学习模型，攻击者可能需要执行许多查询，要么使用蛮力测试尽可能多的组合，要么使用模型搜索问题示例。随着模型复杂性和其可用性的增加，对抗措施的难度也在增加。像逻辑回归这样的简单模型基本上是免疫的，而开源预训练深度神经网络即使配备先进的[内置攻击检测器](https://arxiv.org/abs/1705.07263)也基本上是脆弱的。
- en: Adversarial attacks don’t necessarily happen at inference time. If an attacker
    can get access to the training data, even partially, then they get control over
    the system. This kind of attack is traditionally known as a *poisoning attack*
    in computer security.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗攻击不一定发生在推断时。如果攻击者能够部分获取训练数据，那么他们就控制了系统。这种攻击通常被称为计算机安全中的“毒化攻击”。
- en: One famous example is the [Twitter chatbot released by Microsoft in 2016](https://oreil.ly/aBGVq).
    Just a few hours after launch, the bot started to generate very offensive tweets.
    This was caused by the bot adapting to its input; when realizing that some users
    submitted a large amount of offensive content, the bot started to replicate. In
    theory, a poisoning attack can occur as a result of an intrusion or even, in a
    more sophisticated way, through pretrained models. But in practice, one should
    mostly care about data collected from easily manipulated data sources. Tweets
    sent to a specific account are a particularly clear example.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一个著名的例子是微软在2016年发布的[Twitter聊天机器人](https://oreil.ly/aBGVq)。发布几小时后，该机器人开始生成非常冒犯性的推文。这是由于机器人适应其输入；当意识到一些用户提交了大量冒犯性内容时，机器人开始复制。理论上，毒化攻击可以由入侵或甚至更复杂地通过预训练模型引起。但实际上，大多数情况下应关注来自易于操纵的数据源收集的数据。发送给特定账户的推文是一个特别明显的例子。
- en: Other Vulnerabilities
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他漏洞
- en: 'Some patterns do not exploit machine learning vulnerabilities per se, but they
    do use the machine learning model in ways that lead to undesirable situations.
    One example is in credit scoring: for a given amount of money, borrowers with
    less flexibility tend to choose a longer period to lower the payments, while borrowers
    who are not concerned about their ability to pay may choose a shorter period to
    lower the total cost of credit. Salespeople may advise those who do not have a
    good enough score to shorten their payments. This increases the risk for the borrower
    *and* the bank and is not a meaningful course of action. Correlation is not causality!'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一些模式并非利用机器学习漏洞本身，但它们确实以导致不良情况的方式使用机器学习模型。一个例子是信用评分：对于一定金额的贷款，灵活性较低的借款人倾向于选择较长的还款期以降低月供，而不太担心还款能力的借款人可能选择较短的还款期以降低总成本。销售人员可能建议那些信用评分不够好的人缩短还款期。这增加了借款人和银行的风险，并不是一个有意义的行动。相关性不等于因果关系！
- en: Models can also leak data in many ways. Since the machine learning models can
    fundamentally be considered a summary of the data they have been trained on, they
    can leak more or less precise information on the training data, up to the full
    training set in some cases. Imagine, for example, that a model predicts how much
    someone is paid using the nearest neighbor algorithm. If one knows the zip code,
    age, and profession of a certain person registered on the service, it’s pretty
    easy to obtain that person’s exact income. There are a wide range of attacks that
    can extract information from models in this way.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 模型也可以通过多种方式泄露数据。由于机器学习模型基本上可以被视为对其训练数据的总结，它们可以泄漏更多或更少精确的训练数据信息，有时甚至泄漏整个训练集。例如，假设一个模型使用最近邻算法预测某人的收入。如果知道某人注册在服务上的邮政编码、年龄和职业，那么获取该人的确切收入就非常容易。有各种攻击方式可以从模型中提取信息。
- en: In addition to technical hardening and audit, governance plays a critical role
    in security. Responsibilities must be assigned clearly and in a way that ensures
    an appropriate balance between security and capacity of execution. It is also
    important to put in place feedback mechanisms, and employees and users should
    have an easy channel to communicate breaches (including, potentially, “bug bounty
    programs” that reward reporting vulnerabilities). It is also possible, and necessary,
    to build safety nets around the system to mitigate the risks.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 除了技术强化和审计之外，治理在安全中起着至关重要的作用。责任必须明确分配，并确保在安全与执行能力之间达到适当的平衡。建立反馈机制也非常重要，员工和用户应该有一个便捷的渠道来报告违规行为（包括潜在的“漏洞赏金计划”来奖励漏洞报告）。此外，建立系统安全网以减少风险也是可能且必要的。
- en: Machine learning security shares many common traits with general computer system
    security, one of the main ideas being that security is not an additional independent
    feature of the system; that is, generally you cannot secure a system that is not
    designed to be secure, and the organization processes must take into account the
    nature of the threat from the beginning. Strong MLOps processes, including all
    of the steps in preparing for production described in this chapter, can help make
    this approach a reality.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习安全与一般计算机系统安全有许多共同特征，其中一个主要观点是安全不是系统的额外独立特性；换句话说，通常不能保护一个本身设计不安全的系统，组织的流程必须从一开始就考虑到威胁的本质。强大的MLOps流程，包括本章描述的所有准备生产的步骤，可以帮助实现这种方法。
- en: Model Risk Mitigation
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型风险缓解
- en: Generally speaking, as discussed in detail in [Chapter 1](ch01.html#why_now_and_challenges),
    the broader the model deployment, the greater the risk. When risk impact is high
    enough, it is essential to control the deployment of new versions, which is where
    tightly controlled MLOps processes come into play in particular. Progressive or
    canary rollouts should be a common practice, with new versions of models being
    served to a small proportion of the organization or customer base first and slowly
    increasing that proportion, while monitoring behavior and getting human feedback
    if appropriate.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，如在[第1章](ch01.html#why_now_and_challenges)详细讨论的那样，模型部署越广泛，风险就越大。当风险影响足够大时，控制新版本的部署至关重要，这就是严格控制的MLOps流程特别重要的地方。渐进式或金丝雀发布应该是常规做法，首先将新模型版本提供给组织或客户群体的一小部分，并逐步增加比例，同时监控行为并在必要时获取人类反馈。
- en: Changing Environments
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变化的环境
- en: Rapidly changing environments also multiply risk, as mentioned earlier in this
    chapter. Changes in inputs is a related and also well-identified risk, and [Chapter 7](ch07.html#monitoring_and_feedback_loop)
    dives into these challenges and how to address them in more detail. But what’s
    important to note is that the speed of change can amplify the risk depending on
    the application. Changes may be so fast that they have consequences even before
    the monitoring system sends alerts. That is to say, even with an efficient monitoring
    system and a procedure to retrain models, the time necessary to remediate may
    be a critical threat, especially if simply retraining the model on new data is
    not sufficient and a new model must be developed. During this time, the production
    systems misbehaving can cause large losses for the organization.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 急速变化的环境也会增加风险，正如本章前文所述。输入的变化是一个相关且被充分认识的风险，[第7章](ch07.html#monitoring_and_feedback_loop)深入探讨了这些挑战及其详细解决方法。但需要注意的是，变化的速度可以根据应用放大风险。变化可能如此之快，以至于在监控系统发送警报之前就已经产生后果。也就是说，即使有高效的监控系统和重新训练模型的程序，应对所需的时间可能是一个关键威胁，尤其是如果仅仅在新数据上重新训练模型不足以应对，还需开发新模型。在此期间，生产系统的失控可能会给组织造成巨大损失。
- en: To control this risk, monitoring via MLOps should be reactive enough (typically,
    alerting on distributions computed every week might not be enough), and the procedure
    should consider the period necessary for remediation. For example, in addition
    to retraining or rollout strategies, the procedure may define thresholds that
    would trigger a degraded mode for the system. A degraded mode may simply consist
    of a warning message displayed for end users, but could be as drastic as shutting
    down the dysfunctional system to avoid harm until a stable solution can be deployed.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了控制这种风险，通过MLOps进行的监控应该足够灵活反应（通常每周警报分布可能不够），并且该程序应考虑到修复所需的时段。例如，除了重新训练或部署策略外，该程序可能定义触发系统降级模式的阈值。降级模式可能只是向最终用户显示警告消息，但也可能会像关闭有问题的系统那样极端，以避免损害，直到能够部署稳定的解决方案为止。
- en: Less dramatic issues that are frequent enough can also do harm that quickly
    becomes difficult to control. If the environment changes often, even if remediation
    never seems urgent, a model can always be slightly off, never operating within
    its nominal case, and the operating cost can be challenging to evaluate. This
    can only be detected through dedicated MLOps, including relatively long-term monitoring
    and reevaluating the cost of operating the model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 经常发生的较少戏剧性问题也可能造成难以控制的伤害。如果环境经常变化，即使没有及时的修复，模型也可能总是有些偏差，从未在其名义情况下运行，并且操作成本可能难以评估。这只能通过专门的
    MLOps 检测到，包括相对长期的监控和重新评估模型操作成本。
- en: In many cases, retraining the model on more data will increasingly improve the
    model, and this problem will eventually disappear, but this can take time. Before
    this convergence, a solution might be to use a less complex model that may have
    a lower evaluated performance and may be more consistent in a frequently changing
    environment.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，对更多数据重新训练模型将逐渐改善模型，这个问题最终会消失，但这可能需要时间。在此收敛之前，一种解决方案可能是使用较少复杂的模型，该模型可能在频繁变化的环境中具有较低的评估性能，可能更加一致。
- en: Interactions Between Models
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型之间的相互作用
- en: Complex interactions between models is probably the most challenging source
    of risk. This class of issue will be a growing concern as ML models become pervasive,
    and it’s an important potential area of focus for MLOps systems. Obviously, adding
    models will often add complexity to an organization, but the complexity does not
    necessarily grow linearly in proportion to the number of models; having two models
    is more complicated to understand than the sum since there are potential interactions
    between them.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 模型之间复杂的相互作用可能是最具挑战性的风险来源。随着机器学习模型的普及，这类问题将成为一个越来越重要的关注点，也是 MLOps 系统的一个重要潜在领域。显然，增加模型往往会给组织增加复杂性，但这种复杂性并不一定与模型数量成比例地线性增长；有两个模型比它们的总和更复杂理解，因为它们之间可能存在潜在的相互作用。
- en: Moreover, the total complexity is heavily determined by how the interactions
    with models are designed at a local scale and governed at an organizational scale.
    Using models in chains (where a model uses inputs from another model) can create
    significant additional complexity as well as totally unexpected results, whereas
    using models in independent parallel processing chains, which are each as short
    and explainable as possible, is a much more sustainable way to design large-scale
    deployment of machine learning.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，总体复杂性很大程度上由局部尺度上的模型相互作用设计和组织尺度上的治理所决定。在链式使用模型（一个模型使用另一个模型的输入）时，可能会产生显著的额外复杂性以及完全意想不到的结果，而在独立并行处理链中使用模型，每个链尽可能简短和可解释，是设计大规模机器学习部署的更可持续方式。
- en: First, the absence of obvious interactions between models makes the complexity
    grow closer to linearly (though note that, in practice, it is rarely the case,
    as there can always be interactions in the real world even if models are not connected).
    Also, models used in redundant chains of processing can avoid errors—that is,
    if a decision is based on several independent chains of processing with methods
    as different as possible, it can be more robust.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，模型之间明显缺乏交互作用会使复杂性接近线性增长（尽管实际上很少见，因为即使模型不连接，现实世界中总是可能存在交互作用）。此外，使用冗余处理链中的模型可以避免错误——即，如果决策基于几个独立的处理链，其方法尽可能不同，可能更加稳健。
- en: Finally, generally speaking, the more complex the model, the more complex its
    interactions with other systems may be, as it may have many edge cases, be less
    stability in some domains, overreact to the changes of an upstream model, or confuse
    a sensitive downstream model, etc. Here again, we see that model complexity has
    a cost, and a potentially highly unpredictable one at that.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一般而言，模型越复杂，其与其他系统的交互可能越复杂，因为它可能有许多边界情况，在某些领域中的稳定性较差，对上游模型的变化反应过度，或者混淆敏感的下游模型等等。在这里，我们再次看到模型复杂性具有成本，而且可能是高度不可预测的成本。
- en: Model Misbehavior
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型的错误行为
- en: A number of measures can be implemented to avoid model misbehavior, including
    examining its inputs and outputs in real time. While training a model, it is possible
    to characterize its domain of applicability by examining the intervals on which
    the model was trained and validated. If the value of a feature at inference time
    is out of bounds, the system can trigger appropriate measures (e.g., rejecting
    the sample or dispatching a warning message).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 可以采取多种措施来避免模型的误行为，包括实时检查其输入和输出。在训练模型时，可以通过检查模型训练和验证的区间来确定其适用领域。如果推理时某个特征值超出了范围，系统可以触发适当的措施（例如拒绝样本或发送警告消息）。
- en: Controlling feature-value intervals is a useful and simple technique, but it
    might be insufficient. For example, when training an algorithm to evaluate car
    prices, the data may have provided examples of recent light cars and old heavy
    cars, but no recent heavy cars. The performance of a complex model for these is
    unpredictable. When the number of features is large, this issue becomes unavoidable
    due to the curse of dimensionality—i.e., the number of combinations is exponential
    relative to the number of features.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 控制特征值区间是一种有用且简单的技术，但可能不足以解决问题。例如，当训练评估汽车价格的算法时，数据可能提供了最近的轻型汽车和旧重型汽车的示例，但没有最近的重型汽车。这些情况下，对于复杂模型的性能是不可预测的。当特征数量很大时，由于维数灾难的存在，即特征组合的数量相对于特征数量呈指数增长，这个问题变得不可避免。
- en: In these situations, more sophisticated methods can be used, including anomaly
    detection to identify records where the model is used outside of its application
    domain. After scoring, the outputs of the model can be examined before confirming
    the inference. In the case of classification, many algorithms provide certainty
    scores in addition to their prediction, and a threshold can be fixed to accept
    an inference output. Note that these certainty scores do not typically translate
    into probabilities, even if they are named this way in the model.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，可以使用更复杂的方法，包括异常检测来识别模型在其应用领域之外使用的记录。在评分之后，可以在确认推理之前检查模型的输出。对于分类问题，许多算法除了提供预测外还提供确信度分数，可以设定一个阈值来接受推理输出。请注意，即使这些确信度分数在模型中以此方式命名，它们通常不会转化为概率。
- en: '*Conformal prediction* is a set of techniques that helps calibrate these scores
    to obtain an accurate estimation of the probability of correctness. For regression,
    the value can be checked against a predetermined interval. For example, if the
    model predicts a car costs $50 or $500,000, you may not want to commit any business
    on this prediction. The complexity of the implemented techniques should be relevant
    for the level of risk: a highly complex, highly critical model will require more
    thorough safeguards.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*合一预测* 是一组技术，有助于校准这些得分，以获得正确性概率的准确估计。对于回归问题，可以将预测值与预定区间进行检查。例如，如果模型预测汽车价格为$50或$500,000，您可能不希望根据此预测做任何业务承诺。实施技术的复杂性应与风险水平相关联：高度复杂且高度关键的模型将需要更严格的保护措施。'
- en: Closing Thoughts
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结思考
- en: 'In practice, preparing models for production starts from the beginning at the
    development phase; that is to say, the requirements of production deployments,
    security implications, and risk mitigation aspects should be considered when developing
    the models. MLOps includes having a clear validation step before sending models
    to production, and the key ideas to successfully prepare models for productions
    are:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，准备模型投入生产的工作从开发阶段开始；也就是说，在开发模型时应考虑到生产部署的需求、安全影响以及风险缓解方面。MLOps 包括在将模型送入生产之前进行明确的验证步骤，成功准备模型投入生产的关键思想包括：
- en: Clearly identifying the nature of the risks and their magnitudes
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明确识别风险的性质及其大小
- en: Understanding model complexity and its impact at multiple levels, including
    increased latency, increased memory and power consumption, lower ability to interpret
    inference in production, and a harder-to-control risk
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解模型复杂性及其在多个层面上的影响，包括增加的延迟、增加的内存和功耗、在生产中解释推理的能力降低以及更难控制的风险
- en: Providing a simple but clear standard of quality, making sure the team is appropriately
    trained and the organization structure allows for fast and reliable validation
    processes
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供简单而清晰的质量标准，确保团队接受了适当的培训，并且组织结构允许快速可靠的验证流程
- en: Automating all the validation that can be automated to ensure it is properly
    and consistently performed while maintaining the ability to deploy quickly
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化所有可以自动化的验证，以确保它被正确且一致地执行，同时保持快速部署的能力
