- en: Chapter 3\. Managing the Machine Learning Experiment Lifecycle with MLflow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章。使用MLflow管理机器学习实验生命周期
- en: Machine learning development and data science are often done in collaboration—but
    building models collaboratively, while experimenting with a large combination
    of features, standardization techniques, and hyperparameters, is a complex undertaking.
    Part of the reason for this is simply because it’s a complex task to track experiments,
    reproduce results, package models for deployment, and store and manage those models
    in a way that ensures they are well documented and provide the desired accuracy.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习开发和数据科学通常是协作进行的，但在尝试大量特征组合、标准化技术和超参数的组合的同时共同构建模型，是一个复杂的任务。部分原因在于追踪实验、复现结果、打包模型以便部署以及以确保其良好文档记录并提供所需准确性的方式存储和管理模型，这本身就是一项复杂的任务。
- en: To facilitate this process, there is a need to evolve the machine learning development
    workflow so it is more robust, predictable, and standardized. To this end, many
    organizations have started to build internal machine learning platforms to manage
    the machine learning lifecycle. However, these platforms often support only a
    small set of built-in algorithms, dictated by the company’s infrastructure and
    the software that is available, without much openness to supporting new software
    due to the added complexity. Moreover, these platforms are usually not open source,
    and users cannot easily leverage new machine learning libraries or share their
    work with others in the community.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进这一过程，需要演进机器学习开发工作流程，使其更加健壮、可预测和标准化。为此，许多组织已开始构建内部机器学习平台来管理机器学习生命周期。然而，这些平台通常仅支持一小部分内置算法，由公司基础设施和可用软件决定，对于支持新软件可能存在较大复杂性。此外，这些平台通常不是开源的，用户难以轻松利用新的机器学习库或与社区中其他人分享其工作。
- en: 'Managing the machine learning experiment lifecycle, sometimes referred to as
    *MLOps*, is a combination of machine learning, development, and operations. The
    machine learning part is all about the experiment itself: training, tuning, and
    finding the optimal model. Development is about developing the pipelines and tools
    to take the machine learning model from the development/experimental stage into
    staging and production. And last, operations is about the CI/CD tools and monitoring,
    managing, and serving the models at scale. [Figure 3-1](#the_lifecycle_of_an_ml_modelcomma_from)
    illustrates the steps of the machine learning model’s lifecycle, each of which
    must be supported by the MLOps teams.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 管理机器学习实验生命周期，有时被称为*MLOps*，是机器学习、开发和运维的结合体。机器学习部分涉及实验本身：训练、调整和找到最优模型。开发则是开发流水线和工具，将机器学习模型从开发/实验阶段进入分阶段和生产阶段。最后，运维则涉及CI/CD工具和监控，管理和扩展规模化服务模型。[Figure 3-1](#the_lifecycle_of_an_ml_modelcomma_from)
    描绘了机器学习模型生命周期的步骤，MLOps团队必须支持每一个步骤。
- en: '![](assets/smls_0301.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/smls_0301.png)'
- en: Figure 3-1\. The lifecycle of a machine learning model, from development to
    archiving
  id: totrans-5
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1。机器学习模型的生命周期，从开发到归档
- en: Machine learning experiments can be organized in machine learning pipeline code
    or machine learning modules living in a repository, such as a Git branch. They
    contain the *code*, the *data*, and the *model* and are an integral part of the
    machine learning software lifecycle.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习实验可以通过机器学习流水线代码或存储在仓库中的机器学习模块来组织，例如 Git 分支。它们包含了*代码*、*数据*和*模型*，是机器学习软件生命周期的一个组成部分。
- en: Machine Learning Lifecycle Management Requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习生命周期管理需求
- en: 'The aim of most machine learning projects is to reach the position where they
    have covered all the requirements and developed all capabilities needed to tackle
    the business problem or question at hand. However, defining (let alone meeting)
    all the requirements of the machine learning lifecycle is often easier said than
    done. Furthermore, sometimes these requirements can come from external entities.
    For example, if I am conducting machine learning research for a new drug, it might
    be that my project and outcomes need to adhere to US Food and Drug Administration
    (FDA) requirements. To gain FDA approval, data on the drug’s effects must have
    been reviewed, and the drug must have been determined to provide benefits that
    outweigh its known and potential risks for the intended population. This means,
    at the very least, that the machine learning experiment needs to be *reproducible*.
    Of course, this is just one of the requirements. Many of the others come from
    a software engineering process called the *software development lifecycle* (SDLC).
    Generally speaking, the SDLC includes seven stages: *planning*, *analysis*, *design*,
    *development*, *testing*, *implementation*, and *maintenance*. We can translate
    these into machine learning lifecycle stages, focusing on the areas that are relevant
    to machine learning. That is, taking a closer look at what those stages involve,
    we can make decisions about how to implement them and adopt concepts that are
    relevant to machine learning, leveraging existing SDLC tools and methodologies.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习项目的目标是达到涵盖所有要求并开发所有需要解决的业务问题或问题的能力的位置。然而，定义（更不用说满足）机器学习生命周期的所有要求通常说起来比做起来更容易。此外，有时这些要求可能来自外部实体。例如，如果我为新药进行机器学习研究，可能需要我的项目和结果符合美国食品和药物管理局（FDA）的要求。要获得FDA批准，必须已经审查了药物效果的数据，并且确定该药物对预期人群的已知和潜在风险的益处大于其风险。这意味着至少需要使机器学习实验具有*可重现性*。当然，这只是其中的一个要求。许多其他要求来自称为*软件开发生命周期*（SDLC）的软件工程过程。一般来说，SDLC
    包括七个阶段：*规划*、*分析*、*设计*、*开发*、*测试*、*实施*和*维护*。我们可以将这些阶段转化为机器学习生命周期阶段，专注于与机器学习相关的领域。也就是说，仔细研究这些阶段涉及的内容，我们可以决定如何实施它们，并采纳对机器学习相关的概念，利用现有的SDLC工具和方法论。
- en: 'On the technical side, we can distill the following set of core requirements:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术方面，我们可以概括出以下核心要求：
- en: Reproducibility
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**可重现性**'
- en: This refers to the ability to run your algorithm repeatedly on different datasets
    and obtain the same (or similar) results. Analyzing, reporting, auditing, and
    interpreting data are all aspects of this process, meaning each step in the lifecycle
    needs to be tracked and saved.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这指的是能够在不同数据集上重复运行算法并获得相同（或相似）结果的能力。分析、报告、审计和解释数据都是这一过程的方面，意味着生命周期的每个步骤都需要进行跟踪和保存。
- en: Code version control
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 代码版本控制
- en: Software developers often use version control for their code, and machine learning
    developers should too. Maintaining a history of all the different versions of
    the code, parameters, and data can help us in collaborating with others and keeping
    track of all the variations of the experiments we conduct.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发人员通常会为他们的代码使用版本控制，机器学习开发人员也应该如此。维护代码、参数和数据的所有不同版本历史可以帮助我们与他人合作，并跟踪我们进行的各种实验变体。
- en: Data version control
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据版本控制
- en: As mentioned previously, a machine learning experiment consists of code, data,
    and a model. When conducting such an experiment, it is essential to track and
    log the code and data that produced a specific model. Just as our code changes,
    our data changes as well. We might extract new features or perform different kinds
    of preprocessing on the data itself, resulting in variations of the dataset that
    we need to log for future use. Tools that enable data version control give us
    these capabilities. Note that out of the box, MLflow (the tool discussed in this
    chapter) doesn’t provide data version control; however, there are other open source
    tools that do, such as [lakeFS](https://oreil.ly/AzqiF), [DVC](https://oreil.ly/HQJCE),
    and others.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前提到的，机器学习实验包括代码、数据和模型。在进行这类实验时，跟踪和记录生成特定模型的代码和数据是至关重要的。就像我们的代码会变化一样，我们的数据也会变化。我们可能会从数据中提取新特征或对数据本身进行不同种类的预处理，导致数据集的变化需要记录以备将来使用。支持数据版本控制的工具为我们提供了这些能力。需要注意的是，MLflow（本章讨论的工具）并未提供数据版本控制；然而，有其他开源工具可以提供这样的功能，比如[lakeFS](https://oreil.ly/AzqiF)，[DVC](https://oreil.ly/HQJCE)等。
- en: There are various tools available to manage the machine learning experiment
    lifecycle that can ensure that these three requirements are met. For this book,
    I chose MLflow, because it is open source, natively integrated with Apache Spark,
    and abstracts away complex functionality while allowing flexibility for collaboration
    and expansion to other tools. In the remainder of this chapter, I will introduce
    this tool and how it enables us to manage our machine learning experiments.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种工具可用于管理机器学习实验生命周期，以确保满足这三个要求。对于本书，我选择了 MLflow，因为它是开源的，与 Apache Spark 原生集成，并且在抽象复杂功能的同时允许灵活协作和扩展到其他工具。在本章的其余部分，我将介绍此工具及其如何帮助我们管理机器学习实验。
- en: What Is MLflow?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLflow 是什么？
- en: MLflow is a platform that makes it simpler to manage the entire machine learning
    lifecycle. It enables you to track your experiments and their results, deploy
    and manage your models, and package your machine learning code in a reusable,
    reproducible format. It provides a central model registry that supports versioning
    and annotating, as well as model serving capabilities. It does that by redefining
    experimentation logs and module structure.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 是一个简化整个机器学习生命周期管理的平台。它使您能够跟踪实验及其结果，部署和管理模型，并将机器学习代码打包成可重复使用的格式。它提供了支持版本控制和注释的中央模型注册表，以及模型服务功能。它通过重新定义实验日志和模块结构来实现这一点。
- en: At a high level, the two main components are the tracking server and the model
    registry, as shown in [Figure 3-2](#the_two_main_mlflow_components_left_par).
    The others, which we will look at in more detail later, are supporting components
    of the flow. After the model is registered, the team can build automated jobs
    and use REST-serving APIs to move it downstream. Notice that the open source platform
    itself does not support model monitoring and the like, which requires dedicated
    engineering work.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，主要组件是跟踪服务器和模型注册表，如图[3-2](#the_two_main_mlflow_components_left_par)所示。我们稍后会更详细地查看其他支持流程的组件。在模型注册后，团队可以构建自动化作业，并使用
    REST 服务 API 将其向下移动。请注意，开源平台本身不支持模型监控等功能，这需要专门的工程工作。
- en: '![](assets/smls_0302.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/smls_0302.png)'
- en: Figure 3-2\. The two main MLflow components (courtesy of [Databricks](https://oreil.ly/iUkGX))
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. MLflow 的两个主要组件（由[Databricks](https://oreil.ly/iUkGX)提供）
- en: Software Components of the MLflow Platform
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLflow 平台的软件组件
- en: 'To better understand how it works, let’s take a look at MLflow’s software components:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解其工作原理，让我们来看看 MLflow 的软件组件：
- en: Storage
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 存储
- en: MLflow provides support for connecting to multiple storage types (directories
    of files, databases, etc.) and leveraging them to track the machine learning workflow.
    The storage contains all the information about the experiments, parameters, results
    of different runs, etc.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 提供支持连接到多种存储类型（文件目录、数据库等）并利用它们来跟踪机器学习工作流程。存储包含有关实验、参数、不同运行结果等的所有信息。
- en: Backend server
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 后端服务器
- en: This component is responsible for communicating information from the database/storage,
    UI, SDK, and CLI to the rest of the components, capturing logs from experiments,
    etc.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此组件负责将来自数据库/存储、UI、SDK 和 CLI 的信息传递给其他组件，捕获实验日志等。
- en: Frontend
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 前端
- en: This is the UI side, where we can interact with and track experiments and the
    results of different runs in a visual manner.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 UI 界面，我们可以以可视化的方式与不同运行的实验及其结果进行交互和跟踪。
- en: API and CLI
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: API 和 CLI
- en: MLflow also has a Python API and command-line interface for interaction and
    experiment tracking.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 还具有用于交互和实验跟踪的 Python API 和命令行界面。
- en: We can interact with the MLflow platform via the API, the CLI, or the UI. Behind
    the scenes, it tracks all the information we provide it with. Using the API/CLI
    generates dedicated directories that you can push to a Git repository to facilitate
    collaboration. [Figure 3-3](#tracking_multiple_runs_as_part_of_an_ex) shows an
    example of what the UI looks like when managing multiple runs of an experiment.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过 API、CLI 或 UI 与 MLflow 平台进行交互。在幕后，它跟踪我们提供的所有信息。使用 API/CLI 会生成专用目录，您可以将其推送到
    Git 存储库以便协作。[图 3-3](#tracking_multiple_runs_as_part_of_an_ex) 展示了管理实验多次运行时 UI
    的示例。
- en: '![](assets/smls_0303.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/smls_0303.png)'
- en: Figure 3-3\. Tracking multiple runs as part of an experiment
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. 跟踪实验中多次运行
- en: Users of the MLflow Platform
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLflow 平台的用户
- en: 'As you can imagine, many teams and individuals are involved in the process
    of productionizing machine learning and developing and managing the lifecycle
    end to end. Because of this, MLflow has a broad range of potential users, including
    the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所想象的那样，许多团队和个人参与到机器学习的产品化过程中，并进行端到端的生命周期开发和管理。因此，MLflow 具有广泛的潜在用户，包括以下几类：
- en: Individual users
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 个人用户
- en: As an individual, you can use MLflow to track experiments locally on your machine,
    organize code in projects for future use, and output models that you can later
    test on fresh data. You can also use it for organizing your research work.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作为个人，您可以使用 MLflow 在本地跟踪实验，组织代码以备将来使用，并输出模型，稍后可以使用新数据进行测试。您还可以将其用于组织您的研究工作。
- en: Data science teams
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学团队
- en: Teams of data scientists working on the same problem and experimenting with
    different models can easily share and compare their results using MLflow. The
    teams will often create a shared Git repository to hold the artifacts. Everyone
    on the team can save, track, download, and run their or another team member’s
    model, or use the UI to track the various parameters and get a better understanding
    of the experiment stage.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 处理同一问题并尝试不同模型的数据科学团队可以轻松使用 MLflow 共享和比较他们的结果。团队通常会创建一个共享的 Git 仓库来保存这些成果。团队中的每个人都可以保存、跟踪、下载并运行自己或其他团队成员的模型，或者使用界面来跟踪各种参数，更好地理解实验阶段。
- en: Organizations
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 组织
- en: From an organizational point of view, you can package training and data preparation
    steps for team collaboration and compare results from various teams working on
    the same task. MLflow allows you to streamline and standardize the process of
    moving from research and development to staging and production.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从组织角度来看，您可以为团队协作打包训练和数据准备步骤，并比较各个团队在同一任务上的结果。MLflow 允许您简化和标准化从研究和开发到暂存和生产的流程。
- en: Machine learning engineers/developers
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习工程师/开发者
- en: Often, data scientists will work together with machine learning/AI engineers.
    Using MLflow, data scientists and engineers can publish code to GitHub in the
    MLflow Project format, making it easy for anyone to run their code. In addition,
    machine learning engineers can output models in the MLflow Model format to automatically
    support deployment using MLflow’s built-in tools. Machine learning engineers can
    also work together with the DevOps team to define the webhooks in MLflow databases
    for moving the model between development stages (from development, to validating,
    staging, production, and archiving).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家经常与机器学习/人工智能工程师合作。使用 MLflow，数据科学家和工程师可以以 MLflow 项目格式发布代码到 GitHub，使任何人都可以运行他们的代码。此外，机器学习工程师可以以
    MLflow 模型格式输出模型，以自动支持使用 MLflow 内置工具进行部署。机器学习工程师还可以与 DevOps 团队合作，在 MLflow 数据库中定义
    Webhook，用于在开发阶段之间移动模型（从开发、验证、暂存、生产到归档）。
- en: MLflow Components
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLflow 组件
- en: 'MLflow is organized into four main components: *MLflow Tracking* for capturing
    the parameters and information related to the experiment and logging the results,
    *MLflow Projects* for packaging the project code in a directory or Git repository,
    *MLflow Models* for packaging and deploying models in different formats, and *MLflow
    Model Registry*, which provides a centralized repository for storing and tracking
    all the different versions of your models. Let’s take a look at each of these
    in more detail.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 主要分为四个组件：*MLflow 追踪* 用于捕获实验相关的参数和信息，并记录结果，*MLflow 项目* 用于将项目代码打包到目录或 Git
    仓库中，*MLflow 模型* 用于以不同格式打包和部署模型，以及 *MLflow 模型注册表*，提供一个集中存储和跟踪所有模型不同版本的库。让我们详细看看每个组件。
- en: MLflow Tracking
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLflow 追踪
- en: '[MLflow Tracking](https://oreil.ly/uiJ87) can be used in a standalone script
    (not bound to any specific framework) or notebook. It provides an API, UI, and
    CLI for logging experiment parameters, code itself and its versions, machine learning
    metrics, and output files produced when running your machine learning code so
    you can visualize them later. It also enables you to log and query experiments
    using Python and some other APIs.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[MLflow 追踪](https://oreil.ly/uiJ87) 可以在独立脚本（不绑定到任何特定框架）或笔记本中使用。它提供了 API、界面和
    CLI，用于记录实验参数、代码本身及其版本、机器学习指标以及在运行机器学习代码时生成的输出文件，以便稍后可视化。它还使您能够使用 Python 和其他一些
    API 记录和查询实验。'
- en: 'MLflow Tracking is based on the concept of recording *runs*, or individual
    executions of some piece of data science code. The data that is recorded includes
    the code version, the start and end time, the source file or project, the parameters
    and metrics, and any artifacts that are generated (such as images, models, or
    data files). You can record runs from wherever you run your code using MLflow’s
    Python, R, Java, and REST APIs, and you can define where they are recorded: to
    local files, a database, or remotely to a tracking server. By default, the MLflow
    Python API logs runs locally to files in the *mlruns* directory. Runs can be organized
    into *experiments*, grouping together and providing easy access to all the runs
    for a specific task.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow Tracking基于记录*运行*或某些数据科学代码的单独执行的概念。记录的数据包括代码版本、开始和结束时间、源文件或项目、参数和指标，以及生成的任何工件（如图像、模型或数据文件）。您可以使用MLflow的Python、R、Java和REST
    API从任何地方记录运行您的代码，并且可以定义它们的记录位置：到本地文件、数据库或远程跟踪服务器。默认情况下，MLflow Python API将运行记录到*mlruns*目录中的本地文件中。运行可以组织成*实验*，为特定任务将所有运行组合在一起并提供简单访问。
- en: You can record runs in a standalone program, on a remote cloud machine, or in
    a notebook. If you record your runs in an MLflow Project (discussed in [“MLflow
    Projects”](#mlflow_projects)), MLflow tracks the project URI and source version.
    Later, you can query all the recorded runs using the [Tracking UI](https://oreil.ly/N_qBg)
    or the MLflow API.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在独立程序、远程云机器或笔记本中记录运行。如果您在一个MLflow项目中记录您的运行（在[“MLflow Projects”](#mlflow_projects)中讨论），MLflow会跟踪项目URI和源版本。稍后，您可以使用[Tracking
    UI](https://oreil.ly/N_qBg)或MLflow API查询所有记录的运行。
- en: Using MLflow Tracking to record runs
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用MLflow Tracking记录运行
- en: Let’s assume we have a TensorFlow experiment that we want to run and track with
    MLflow. Depending on the flavor of the model we would like to track, we will import
    the relevant library as the first step. This will be either `mlflow.tensorflow`
    or `mlflow.keras`; use the one that supports the training algorithm you are using.
    Subsequently, we can leverage the platform’s autologging capabilities or log the
    parameters and metrics programmatically—I’ll show you how to do both.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个TensorFlow实验，我们想要使用MLflow运行和跟踪。根据我们想要跟踪的模型的类型，我们将作为第一步导入相关的库。这将是`mlflow.tensorflow`或`mlflow.keras`之一；使用支持您正在使用的训练算法的库。随后，我们可以利用平台的自动记录功能或以编程方式记录参数和指标
    — 我将展示如何两者都做。
- en: 'To start the run, in Python we can use the `with` operator with `mlflow.start_run`.
    This API call starts a new run within an experiment, if one exists. If no experiment
    exists, it automatically creates a new one. You can create your own experiment
    with the `mlflow.create_experiment` API or via the UI. Within the run, you develop
    your training code and leverage `log_param` and `log_metric` for tracking important
    information. At the end, you log your model and all necessary artifacts (more
    on that later). Check out the following code snippet to better understand how
    the flow works:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动运行，在Python中我们可以使用`with`运算符和`mlflow.start_run`。这个API调用在实验中启动一个新的运行，如果存在的话。如果没有实验存在，它会自动创建一个新的实验。您可以使用`mlflow.create_experiment`
    API或通过UI创建您自己的实验。在运行中，您开发您的训练代码，并利用`log_param`和`log_metric`跟踪重要信息。最后，您记录您的模型和所有必要的工件（稍后详述）。查看以下代码片段，以更好地理解流程如何工作：
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: At the time of writing, `mlflow.tensorflow.autolog` is an experimental method
    in version 1.20.2\. It uses the TensorFlow *callbacks* mechanism to perform different
    actions at particular stages in the training procedure. Callbacks can be passed
    to TensorFlow methods such as `fit`, `evaluate`, and `predict` in order to hook
    into the various stages of the model training and inference lifecycle. For example,
    you can leverage them to perform certain actions at the end of an epoch or to
    reduce compute costs by stopping training when it has reached the desired accuracy,
    by configuring parameters during the run.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，`mlflow.tensorflow.autolog`是版本1.20.2中的一个实验性方法。它使用TensorFlow的*回调*机制在训练过程的特定阶段执行不同的操作。回调可以传递给TensorFlow的方法，如`fit`、`evaluate`和`predict`，以便在模型训练和推断生命周期的各个阶段进行钩子操作。例如，您可以利用它们在epoch结束时执行某些操作，或者通过配置参数在运行期间达到所需的精度时停止训练以减少计算成本。
- en: An *epoch* is a single pass over the whole dataset. In each epoch, you can access
    the logs and programmatically make decisions using callbacks. Callbacks in TensorFlow
    are part of the Keras library `tf.keras.callbacks.Callback`, while in PyTorch
    they are part of `pytorch_lightning.callbacks`. In PyTorch, callbacks are often
    implemented with extensions, such as the open source PyTorch Lightning library,
    developed by Grid.AI.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*Epoch*是对整个数据集的单次遍历。在每个epoch中，您可以访问日志并使用回调进行程序化决策。TensorFlow中的回调是Keras库`tf.keras.callbacks.Callback`的一部分，而在PyTorch中它们是`pytorch_lightning.callbacks`的一部分。在PyTorch中，回调通常是通过扩展实现的，例如由Grid.AI开发的开源PyTorch
    Lightning库。'
- en: At the beginning of the training, the `autolog` function logs all the configurations
    that are relevant for the training. Then, at the end of each epoch, it captures
    the log metrics. At the end of the training, it logs the model by calling `mlflow.log_model`.
    As a result, it covers logging the whole lifecycle, and you can add any other
    parameters and artifacts you wish to log with it using the available functions
    (`mlflow.log_param`, `mlflow.log_metric`, `mlflow.log_artifact`, etc.).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练开始时，`autolog`函数记录所有与训练相关的配置。然后，在每个epoch结束时，它捕获日志指标。在训练结束时，通过调用`mlflow.log_model`记录模型。因此，它覆盖了整个生命周期的日志记录，并且您可以使用可用函数（`mlflow.log_param`、`mlflow.log_metric`、`mlflow.log_artifact`等）添加任何其他参数和工件。
- en: 'Autologging is also available for PyTorch, as demonstrated in the following
    code snippet:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于PyTorch，也可以使用自动记录，如下面的代码片段所示：
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: MLflow supports other frameworks and flavors of machine learning too, but not
    all of them are supported as part of the open source solution. For additional
    details, check out the fully managed and hosted version of MLflow provided by
    [Databricks](https://oreil.ly/sN3i0).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow还支持其他框架和机器学习的变体，但并非所有都作为开源解决方案的一部分受支持。有关详细信息，请查看由[Databricks](https://oreil.ly/sN3i0)提供的MLflow的完全托管和托管版本。
- en: Tip
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: For now, it is recommended that you programmatically log the parameters, metrics,
    models, and artifacts as a general rule, as autologging is not currently fully
    supported in the open source version of MLflow. The same recommendation applies
    when working with Spark MLlib.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 目前建议您按照一般规则将参数、指标、模型和工件进行程序化记录，因为在MLflow的开源版本中当前不完全支持自动记录。在使用Spark MLlib时也适用相同的建议。
- en: Logging your dataset path and version
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 记录您的数据集路径和版本
- en: For experiment tracking, reproducibility, and collaboration purposes, I advise
    logging the dataset path and version together with the model name and path during
    the training phase. In the future, this will enable you to reproduce the model
    given the exact dataset when necessary and to differentiate between models that
    were trained with the same algorithm but different versions of the input. Make
    sure to track all hyperparameters, parameters, and seed data as well!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 出于实验跟踪、可重现性和协作目的，我建议在训练阶段同时记录数据集路径和版本以及模型名称和路径。将来，这将使您能够在必要时重现模型，并区分使用相同算法但不同输入版本训练的模型。确保跟踪所有超参数、参数和种子数据！
- en: 'For that, I recommend using the `mlflow.log_param` function, as it enables
    you to log all the parameters in one call. This produces a batch log that is simpler
    to track later:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我建议使用`mlflow.log_param`函数，因为它可以让您在一次调用中记录所有参数。这将生成一个批量日志，稍后跟踪更简单：
- en: '[PRE2]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Another recommended option is setting tags on the run by passing the `tags`
    argument to `start_run`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个推荐的选项是通过将`tags`参数传递给`start_run`来动态设置标签：
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: MLflow provides a flexible API. It is up to you to decide how to structure your
    experiment logs, with these recommendations in mind. [Figure 3-4](#the_mlflow_experiment_dashboard)
    shows the MLflow dashboard, where you can track your experiments and view the
    parameters and tags, among other elements.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow提供了一个灵活的API。根据这些建议，您可以自行决定如何结构化您的实验日志。[图3-4](#the_mlflow_experiment_dashboard)展示了MLflow仪表板，您可以在其中跟踪您的实验并查看参数和标签等其他元素。
- en: '![](assets/smls_0304.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/smls_0304.png)'
- en: Figure 3-4\. The MLflow experiment dashboard
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-4\. MLflow实验仪表板
- en: Tip
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'MLflow provides the option to log all the contents of a local directory as
    artifacts of the run, creating a new active run if there isn’t one: `mlflow.log_artifacts(local_dir,
    artifact_path=None)`. However, I advise against using this, since it copies everything
    in the given `local_dir` and writes it in the `artifact_path`. When I work with
    large-scale data for training, I prefer to avoid copying data unless it’s really
    necessary.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 提供了一个选项，可以将本地目录的所有内容作为运行的工件进行记录，如果没有运行则创建一个新的活动运行：`mlflow.log_artifacts(local_dir,
    artifact_path=None)`。但是，我建议避免使用这个选项，因为它会复制给定 `local_dir` 中的所有内容并将其写入 `artifact_path`。当我处理大规模数据进行训练时，除非确实需要，我更倾向于避免复制数据。
- en: 'By now, you understand the responsibility of the MLflow Tracking component:
    to log all the information needed to package up your project. Next, let’s take
    a look at MLflow Projects.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经了解了 MLflow Tracking 组件的责任：记录所有打包项目所需的信息。接下来，让我们来看看 MLflow 项目。
- en: MLflow Projects
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLflow 项目
- en: An [MLflow Project](https://oreil.ly/jIfya) is a standard format for packaging
    code in a reusable and reproducible way. The MLflow Projects component includes
    an API and command-line tools for executing projects and making it possible to
    chain projects together into workflows.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[MLflow 项目](https://oreil.ly/jIfya) 是一种将代码打包成可重复使用和可重现的标准格式。MLflow 项目组件包括用于执行项目的
    API 和命令行工具，并使得将项目链接成工作流成为可能。'
- en: 'Each project is simply a directory or Git repository containing a set of code
    files and a descriptor file (a YAML file called *MLproject*) to specify its dependencies
    and how to run the code. The MLflow Project format captures all the relevant data
    that is needed to reproduce and deploy the model, including the environment data.
    According to the docs, at the time of writing, MLflow supports four different
    project environments: virtualenv environments (supporting Python packages available
    on the Python Package Index, aka PyPI), *conda environments* (supporting Python
    packages and native libraries), Docker container environments (allowing for non-Python
    dependencies such as Java libraries), and the system environment. The system environment
    is supplied at runtime, and all the project’s dependencies must be installed before
    project execution. When using a conda environment, by default MLflow uses the
    system path to find and run the conda binary. You can decide to use a different
    conda installation by changing the `MLFLOW_CONDA_HOME` environment variable.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 每个项目只是一个包含一组代码文件和一个描述文件（一个名为 *MLproject* 的 YAML 文件）的目录或 Git 仓库，用于指定其依赖关系和如何运行代码。MLflow
    项目格式捕捉了所有复制和部署模型所需的相关数据，包括环境数据。根据文档，在编写时，MLflow 支持四种不同的项目环境：virtualenv 环境（支持 Python
    包，可通过 Python 包索引（PyPI）获取），*conda 环境*（支持 Python 包和本地库），Docker 容器环境（允许非 Python 依赖项，如
    Java 库），以及系统环境。系统环境在运行时提供，并且必须在项目执行之前安装所有项目依赖项。使用 conda 环境时，默认情况下 MLflow 使用系统路径来查找和运行
    conda 二进制文件。您可以通过更改 `MLFLOW_CONDA_HOME` 环境变量来决定使用不同的 conda 安装位置。
- en: 'Your project may have multiple entry points for invoking runs with named parameters.
    Since MLflow Projects support conda, you can specify code dependencies through
    a conda environment by leveraging the MLflow CLI:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您的项目可能有多个入口点，可以通过命名参数调用运行。由于 MLflow 项目支持 conda，您可以通过利用 MLflow CLI 在 conda 环境中指定代码依赖：
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Running the experiment using the `-P` command-line parameter gives us the flexibility
    to change parameters using the CLI. Here, we overwrite the parameter we passed
    to the `log_metric` function (`mlflow.log_metric("alpha", 0.1)`), changing the
    value to `0.5`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `-P` 命令行参数运行实验使我们能够使用 CLI 更改参数。在这里，我们覆盖了传递给 `log_metric` 函数的参数（`mlflow.log_metric("alpha",
    0.1)`），将其值更改为 `0.5`。
- en: MLflow Models
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLflow 模型
- en: The [MLflow Models component](https://oreil.ly/0SMx0) is used for packaging
    machine learning models in multiple formats, called *flavors*. Deployment tools
    can use these flavors to understand the model, making it possible to write tools
    that work with models from any machine learning library. MLflow Models provides
    several standard flavors that MLflow’s built-in deployment tools support, such
    as a `python_function` flavor that describes how to run the model as a Python
    function. A model of this flavor can be deployed to a Docker-based REST server,
    to a cloud server, or as a user-defined function. Since you output MLflow Models
    as artifacts using the tracking API during their run, MLFlow will automatically
    tag the correct project.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[MLflow Models 组件](https://oreil.ly/0SMx0)用于将机器学习模型打包成多种格式，称为*flavors*。部署工具可以使用这些*flavors*来理解模型，从而可以编写适用于任何机器学习库模型的工具。MLflow
    Models 提供了几种标准的*flavors*，MLflow 内置的部署工具支持这些*flavors*，例如 `python_function` *flavor*
    描述了如何将模型作为 Python 函数运行。使用这种*flavor*的模型可以部署到基于 Docker 的 REST 服务器、云服务器或作为用户定义函数。由于在运行期间使用跟踪
    API 输出 MLflow Models 作为工件，MLFlow 将自动标记正确的项目。'
- en: 'Running the experiment in [“MLflow Tracking”](#mlflow_tracking) will record
    the run and output a model directory with the following outline:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [“MLflow Tracking”](#mlflow_tracking) 中运行实验将记录运行并输出一个带有以下大纲的模型目录：
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This directory contains all the information we need to reproduce the experiment.
    Let’s look at the structure. The first line of output, `58dc6db17fb5471a9a46d​87506da983f`,
    is the experiment’s 128-bit universally unique identifier (UUID). At the root
    of the directory, there is a YAML file named *meta.yaml* that contains metadata
    about the experiment. With that, we already have extensive traceability information
    available to us and a solid foundation to continue our experiments. There are
    also four subdirectories: *artifacts*, which contains any artifacts that are logged;
    *metrics*, which contains the metrics that are logged; and *params* and *tags*,
    which contain the parameters and tags set for the run. The *MLmodel* file can
    define multiple flavors that the model supports as well as provide additional
    information about the model.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这个目录包含了我们复现实验所需的所有信息。让我们来看看结构。输出的第一行，`58dc6db17fb5471a9a46d​87506da983f`，是实验的
    128 位全局唯一标识符（UUID）。在目录的根目录下，有一个名为 *meta.yaml* 的 YAML 文件，其中包含有关实验的元数据。有了这个，我们已经有了丰富的可追溯信息以及继续实验的坚实基础。还有四个子目录：*artifacts*
    包含记录的任何工件；*metrics* 包含记录的度量；*params* 和 *tags* 包含运行设置的参数和标签。*MLmodel* 文件可以定义模型支持的多个*flavors*以及有关模型的其他信息。
- en: MLflow Model Registry
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLflow 模型注册表
- en: During experiments, we may generate a large number of models. The [MLflow Model
    Registry](https://oreil.ly/zKGAn) provides a centralized storage for those models,
    as well as a set of APIs for interacting with them and a dedicated UI for visualization.
    It also allows us to manage the full lifecycle of an MLflow Model through the
    CLI. The Model Registry enables us to access a broad set of metadata about all
    our models, including which experiment and run created the model (its “lineage”),
    the model version and stage (e.g., staging, production, archived), and any annotations
    describing the model. We can also add comments about the models in the registry,
    rename them, transition them between stages, and serve them from the registry.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验过程中，我们可能会生成大量的模型。[MLflow Model Registry](https://oreil.ly/zKGAn) 提供了一个集中存储这些模型的地方，以及用于与它们交互的一组
    API 和专用 UI 进行可视化。它还允许我们通过 CLI 管理 MLflow Model 的整个生命周期。模型注册表使我们能够访问关于所有模型的广泛元数据，包括创建模型的实验和运行（其“血统”）、模型版本和阶段（例如，暂存、生产、存档），以及描述模型的任何注释。我们还可以在注册表中为模型添加评论、重命名它们、在不同阶段之间转换并从注册表中提供服务。
- en: Registering models
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注册模型
- en: 'During the training cycle, we produce multiple models so that we can ultimately
    pick the most suitable one. As you learned in [Chapter 10](ch10.xhtml#deployment_patterns_for_machine_learnin),
    the models can be logged implicitly with `autolog` or explicitly with the `log_model`
    function. At this point, the model is not yet in the registry; to add it, we need
    to *register* it. There are a few different ways to do this. To register a model
    during a run, we can include the `regis⁠tered​_model_name` parameter, as shown
    here:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练周期中，我们生成多个模型，以便最终选择最合适的模型。正如您在 [第 10 章](ch10.xhtml#deployment_patterns_for_machine_learnin)
    中学到的那样，这些模型可以使用 `autolog` 隐式记录，也可以使用 `log_model` 函数显式记录。此时，模型尚未注册到注册表中；要添加它，我们需要
    *注册* 它。有几种不同的方法可以做到这一点。要在运行过程中注册模型，可以包含 `regis⁠tered​_model_name` 参数，如下所示：
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This registers the model as a new model with version 1, if no model with that
    name exists in the registry; if there’s already a model with that name, it registers
    it as a new version. You can also use the `register_model` method after you’ve
    completed your experiment and decided which model you want to register, passing
    it the model’s `run_id` and the name to register it as. For additional details
    on this and other registration options, see the [documentation](https://oreil.ly/1T-0O).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果注册表中不存在具有该名称的模型，则将此模型注册为新模型的版本 1；如果已经存在具有该名称的模型，则将其注册为新版本。您还可以在完成实验并决定要注册哪个模型后，使用
    `register_model` 方法，传递模型的 `run_id` 和要注册的名称。有关此及其他注册选项的详细信息，请参阅 [文档](https://oreil.ly/1T-0O)。
- en: Transitioning between model stages
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在模型阶段之间过渡
- en: 'At a high level, a machine learning model’s lifecycle has five stages: development,
    validation, staging, production, and archived. MLflow allows us to connect to
    CI/CD tools to transition our models between these stages. For that, we need to
    write dedicated scripts that listen for model status change events and, upon an
    update, trigger the desired script. You can also leverage webhooks or other mechanisms
    of your preference.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，机器学习模型的生命周期有五个阶段：开发、验证、暂存、生产和存档。MLflow 允许我们连接到 CI/CD 工具，以在这些阶段之间转换我们的模型。为此，我们需要编写专用脚本来监听模型状态变更事件，并在更新时触发所需的脚本。您还可以利用
    Webhooks 或其他您喜欢的机制。
- en: 'When we first log a model using the `log_model` API of the corresponding model
    flavor (Keras or TensorFlow), it is assigned the status `None`, which means it’s
    in the development stage. To promote the model from the development stage to staging
    in the database, use the `MlflowClient` API:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们首次使用对应模型风格（Keras 或 TensorFlow）的 `log_model` API 记录模型时，它被赋予 `None` 状态，表示它处于开发阶段。要将模型从开发阶段提升到数据库中的暂存阶段，可以使用
    `MlflowClient` API：
- en: '[PRE7]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`MlflowClient` is the Python client to interact with the tracking server. The
    `transition_model_version_stage` function allows us to update the model stage
    and invoke the desired CI/CD scripts. The `stage` parameter accepted the following
    values: `Staging|Archived|Production|None`. Setting this parameter to `Staging`,
    given a configured environment that tracks model status, will open a request to
    transition the model from `None` status to `Staging` status for integration testing
    in a staging environment. We will discuss this in more detail in [Chapter 10](ch10.xhtml#deployment_patterns_for_machine_learnin).'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`MlflowClient` 是与跟踪服务器交互的 Python 客户端。`transition_model_version_stage` 函数允许我们更新模型阶段并调用所需的
    CI/CD 脚本。`stage` 参数接受以下值：`Staging|Archived|Production|None`。将此参数设置为 `Staging`，在配置了跟踪模型状态的环境中，将打开一个请求，将模型从
    `None` 状态转换为 `Staging` 状态，以进行在暂存环境中的集成测试。我们将在 [第 10 章](ch10.xhtml#deployment_patterns_for_machine_learnin)
    中更详细地讨论这个问题。'
- en: Using MLflow at Scale
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大规模使用 MLflow
- en: 'As mentioned earlier, MLflow Tracking stores information on experiments and
    runs as well as artifacts related to the runs (model-related files). It uses two
    components for storage, which can be either local or remote: a *backend store*
    for information about experiments (runs, parameters, metrics, tags, annotations,
    etc.) and an *artifact store* for storing the models themselves and any related
    files, objects, model summaries, etc. MLflow, like most frameworks, offers various
    configuration options, including what to use for storage. If you work locally
    on your machine, you can save artifacts and information about your experiments
    to your local disk. If you work from a notebook on a cloud or other remote server,
    you can save your projects to the storage you have available there. [Figure 3-5](#mlflow_tracking_storage_options)
    shows the different storage options.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，MLflow Tracking 存储实验和运行相关的信息以及与运行相关的工件（模型相关文件）。它使用两个组件进行存储，可以是本地或远程的：一个*后端存储*用于实验的信息（运行、参数、指标、标签、注释等），还有一个*工件存储*用于存储模型本身以及任何相关的文件、对象、模型摘要等。像大多数框架一样，MLflow
    提供了各种配置选项，包括存储选项。如果您在本地机器上工作，可以将工件和实验信息保存到本地磁盘。如果您在云端笔记本或其他远程服务器上工作，可以将项目保存到可用的存储空间上。[图 3-5](#mlflow_tracking_storage_options)展示了不同的存储选项。
- en: '![](assets/smls_0305.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/smls_0305.png)'
- en: Figure 3-5\. MLflow Tracking storage options
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5\. MLflow Tracking 存储选项
- en: The artifact store can be any local or remote file store (though note that a
    local file store is not a scalable option). The backend store can be a local or
    remote file store or a database. When running MLflow on your local machine, the
    backend and artifact stores can share a single directory on the local filesystem,
    or you can choose to store experiment-related entities in a database such as PostgreSQL
    or SQLite. [Figure 3-6](#mlflow_tracking_server_sql_table_hierar) shows what the
    table hierarchy might look like in this case.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 工件存储可以是任何本地或远程文件存储（尽管请注意本地文件存储不是可扩展的选项）。后端存储可以是本地或远程文件存储，也可以是数据库。当在本地机器上运行MLflow时，后端和工件存储可以共享本地文件系统上的单个目录，或者您可以选择将与实验相关的实体存储在诸如PostgreSQL或SQLite等数据库中。[图 3-6](#mlflow_tracking_server_sql_table_hierar)展示了在这种情况下表层次结构可能看起来如何。
- en: '![](assets/smls_0306.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/smls_0306.png)'
- en: Figure 3-6\. MLflow tracking server SQL table hierarchy
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-6\. MLflow 跟踪服务器 SQL 表层次结构
- en: Let’s dive deeper into a potential scalable solution. MLflow supports distributed
    architectures, where the tracking server, backend store, and artifact store reside
    on remote hosts. For scaling and team collaboration, this configuration is preferable
    to running on *localhost*. [Figure 3-7](#distributed_configuration_example_left)
    shows what this might look like. As you can see, there can be multiple hosts.
    Here, the user runs MLflow on their local machine, and the tracking server itself
    and both stores reside remotely.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨一个潜在的可扩展解决方案。MLflow 支持分布式架构，在此架构中，跟踪服务器、后端存储和工件存储位于远程主机上。为了扩展和团队协作，这种配置优于在*localhost*上运行。[图 3-7](#distributed_configuration_example_left)展示了这种情况可能的外观。正如您所见，这里可以有多个主机。在这里，用户在其本地机器上运行MLflow，而跟踪服务器本身和两个存储则位于远程。
- en: '![](assets/smls_0307.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/smls_0307.png)'
- en: Figure 3-7\. Distributed configuration example
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-7\. 分布式配置示例
- en: The backend store can be a file store or a database-backed store, but for a
    scalable approach we will use PostgreSQL (an open source database that has great
    support by the community). To connect with it using Python, MLflow uses [SQLAlchemy](https://www.sqlalchemy.org).
    For our artifact store, where we will store our models, we should choose a location
    that is suitable for big data. We can configure this using the `artifact-root`
    parameter when we run the tracking server from the command line.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 后端存储可以是文件存储或数据库支持的存储，但为了实现可扩展性，我们将使用PostgreSQL（一个由社区广泛支持的开源数据库）。MLflow 在Python中使用[SQLAlchemy](https://www.sqlalchemy.org)与之连接。对于我们的工件存储，我们应选择一个适合大数据的位置。我们可以在从命令行运行跟踪服务器时使用`artifact-root`参数来配置这一点。
- en: Warning
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: 'There is often a huge knowledge gap between developers and data scientists;
    while the former are experts in building software, the latter are experts in building
    machine learning models and solving business problems. That sometimes creates
    a dissonance between coding best practices and data science best practices, which
    leads to general software antipatterns, especially when dealing with large-scale
    data or complex systems. For example, if our dataset is relatively small (say,
    100 MB), we can save the dataset together with the machine learning experiment
    code and output in a Git repository if we wish to do so. However, as we move through
    the stages of productionizing machine learning—development, validation, testing
    in staging, and so on—to comply with organizational rules around privacy, access
    control, etc., we often need to use cloud storage solutions instead (typically
    cloud-based object-storage services such as Azure Blob, AWS S3, and others). The
    takeaway: *don’t store large data files as artifacts in MLflow.*'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员和数据科学家之间经常存在巨大的知识差距；前者是软件构建的专家，后者则是构建机器学习模型和解决业务问题的专家。这有时会导致编码最佳实践与数据科学最佳实践之间的不和谐，尤其是在处理大规模数据或复杂系统时。例如，如果我们的数据集相对较小（比如，100
    MB），我们可以选择将数据集与机器学习实验代码和输出一起保存在Git存储库中。然而，随着我们逐步推进机器学习的生产化阶段——开发、验证、在测试环境中测试等——为了遵循围绕隐私、访问控制等的组织规则，我们通常需要使用云存储解决方案（通常是基于云的对象存储服务，如Azure
    Blob、AWS S3等）。重要的是：*不要将大型数据文件作为MLflow的产物存储*。
- en: Summary
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'At this point, you have a decent understanding of what MLflow is and how to
    use it to manage your machine learning experiments. This is an important task,
    and the differentiator between experimenting with machine learning and actually
    using it as part of an organization’s R&D lifecycle. We’ll talk more about MLflow
    in [Chapter 10](ch10.xhtml#deployment_patterns_for_machine_learnin), when we discuss
    deployment. In the next chapter, we’ll dive into working with the data itself:
    ingesting it, preprocessing it, and exploring it.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，您已经对MLflow有了相当不错的理解，并且知道如何使用它来管理您的机器学习实验。这是一项重要的任务，也是进行机器学习实验与将其作为组织研发生命周期的一部分实际使用之间的区别。在我们讨论部署时，我们将在[第10章](ch10.xhtml#deployment_patterns_for_machine_learnin)中进一步讨论MLflow。在下一章中，我们将深入探讨与数据本身的工作：摄取它，预处理它，并探索它。
