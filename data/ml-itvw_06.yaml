- en: 'Chapter 6\. Technical Interview: Model Deployment and End-to-End ML'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 技术面试：模型部署和端到端ML
- en: In Chapters [3](ch03.html#technical_interviewcolon_machine_learnin) and [4](ch04.html#technical_interviewcolon_model_training),
    you got an overview of important interview concepts related to ML algorithms,
    model training, and evaluation. For ML models to have an impact on users, whether
    they are your company’s customers or internal users and fellow employees, the
    model needs to be *deployed*.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[3](ch03.html#technical_interviewcolon_machine_learnin)章和第[4](ch04.html#technical_interviewcolon_model_training)章中，你已经对与ML算法、模型训练和评估相关的重要面试概念有了概览。为了让ML模型对用户产生影响，无论是公司的客户还是内部用户和同事，模型都需要*部署*。
- en: There are many levels of being deployed, but the most important thing is that
    the end goal for the model is achieved. If your model is being run manually and
    ad hoc every time the marketing team asks for new results, and that’s working
    well, then that could be your level of deployment. Or, you could have a fully
    automated system where the model goes out to customers as part of an A/B test,
    without the person who trained the model needing to do anything beyond the model
    training. That could be the level of deployment in a situation where the end goal
    calls for it.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 部署有许多层次，但最重要的是实现模型的最终目标。如果你的模型是手动运行的，并且每次市场团队请求新结果时都是临时的，而且运行良好，那可能就是你的部署级别。或者，你可以拥有一个完全自动化的系统，在这种情况下，模型会作为A/B测试的一部分发送给客户，训练模型的人除了进行模型训练外不需要做任何事情。这可能是需要的部署级别。
- en: 'On that note, it’s not required for ML professionals to know all the details
    of model deployment. If you’re applying for one of the following jobs, however,
    it would be useful to brush up on the topics mentioned in this section. Roles
    that are likely to require deeper knowledge on model deployment include:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一句，ML专业人士并不需要了解模型部署的所有细节。然而，如果你申请以下职位之一，熟悉本节提到的话题会很有用。通常需要更深入了解模型部署的角色包括：
- en: Machine learning engineer that doesn’t only do model training
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不仅仅进行模型训练的机器学习工程师
- en: MLOps engineer
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLOps工程师
- en: Data scientist or MLE at a startup that doesn’t have additional dedicated people
    working on ML deployment
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在初创公司担任数据科学家或MLE，并且没有其他专门从事ML部署的人员
- en: Coincidentally, the more your job falls into this type of role, the higher the
    possibility that the interviews will also include the coding questions mentioned
    in [Chapter 5](ch05.html#technical_interviewcolon_coding) that overlap with software
    engineering interview loops.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 巧合的是，如果你的工作正好属于这种类型的角色，那么面试中可能还会包括与软件工程面试环节重叠的编码问题，如第[5](ch05.html#technical_interviewcolon_coding)章所述。
- en: 'On the other hand, you can likely skim through or skip this chapter if the
    company or team you’re interested in has very defined roles, and the role you’re
    applying for does not need to do hands-on deployment, or the jobs you’re interested
    in are the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果你感兴趣的公司或团队有非常明确的角色划分，而你申请的职位不需要进行实际的部署工作，或者你感兴趣的工作包括以下工作：
- en: Product data scientist
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品数据科学家
- en: Data scientist, applied scientist, MLE, and so on, that focuses on model development
    or other analytics
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家、应用科学家、MLE等，专注于模型开发或其他分析工作
- en: 'This chapter will walk through model deployment, model monitoring after deployment,
    and other end-to-end ML processes and tools. In addition, I will briefly summarize
    more advanced ML interview topics: systems design, technical deep dives on past
    projects, and product sense. This is so that you are aware of the topics and how
    to prepare for them if you do encounter them. The good news is that the more difficult
    variants are only expected at senior or staff+ levels, not at entry level.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍模型部署、部署后的模型监控，以及其他端到端的机器学习流程和工具。此外，我还将简要总结更高级的机器学习面试话题：系统设计、过往项目的技术深度探索和产品感。这样你就知道这些话题，以及如果遇到它们该如何准备。好消息是，更难的变种通常只在高级或资深以上的职位中才会遇到，而不是在入门级别。
- en: Model Deployment
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型部署
- en: An analogy I’ve used for a model being deployed is that it’s “live and on air.”
    In ML roles, this is an important part of the machine learning lifecycle, as discussed
    in [Chapter 1](ch01.html#machine_learning_roles_and_the_interview). Interviews
    for roles focused on ML deployment could touch on topics such as ML or software
    infrastructure (which facilitates the model serving), ML hypothesis testing, monitoring,
    model updates, and so on, once the model is deployed.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我用来描述模型部署的类比是它“实时且在空中”。在机器学习角色中，这是机器学习生命周期的重要部分，如[第1章](ch01.html#machine_learning_roles_and_the_interview)所述。关于机器学习部署的面试可能涉及的主题包括机器学习或软件基础设施（用于支持模型服务）、机器学习假设检验、监控、模型更新等等，一旦模型部署完成。
- en: This is a type of ML experience that may be harder to gain through self-learning
    since when we build ML models as a side project, there may not be users to test
    them on in the first place. Thus, it’s not often a priority in my experience when
    it comes to side projects.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的机器学习经验可能通过自学更难获得，因为当我们作为副业构建机器学习模型时，首先可能没有用户进行测试。因此，在我看来，这通常不是副业项目的重点。
- en: Next, I’ll outline some reasons why model deployment is important in industry
    and show you how to mentally connect from the model training and development work
    to the deployment work.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将概述模型部署在工业界的重要性的一些原因，并向你展示如何在心理上从模型训练和开发工作转向部署工作。
- en: The Main Experience Gap for New Entrants into the ML Industry
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新加入机器学习行业的主要经验差距
- en: The concepts of production and deployment were unfamiliar to me when I was starting
    out in the ML field. Hence, I include this section describing how I was first
    exposed to the concepts and how I bridged the gap from theoretical ML knowledge
    to standalone projects to full-fledged projects. I hope you find this story relatable
    and helpful.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我开始进入机器学习领域时，**生产**和**部署**的概念对我来说是陌生的。因此，我包括了这一部分，描述了我如何首次接触这些概念，并如何从理论的机器学习知识过渡到独立项目再到成熟项目。希望这个故事能让你感同身受，并对你有所帮助。
- en: 'During my master’s program at the University of Toronto, I used Python on Jupyter
    Notebooks for some of my research projects. For these projects, I scraped and
    acquired data programmatically, wrote scripts to clean them, and analyzed the
    data. During this time, I used my laptop for computation: I installed Python packages
    directly on my laptop’s local environment. During development, I was able to quickly
    make edits to my code since I was the only person working on it. I didn’t back
    the code up apart from making copies locally on my laptop. After the ML model
    training and analysis were done, I created some visualizations and put them into
    a paper format with LaTeX, and that was the end of that project. I never ran any
    of those scripts again.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我在多伦多大学的硕士项目期间，我在Jupyter笔记本上使用Python进行了一些研究项目。对于这些项目，我以编程方式进行数据抓取和获取，编写脚本进行数据清理，并分析数据。在这段时间里，我用我的笔记本电脑进行计算：我直接在笔记本电脑的本地环境安装Python包。在开发过程中，由于我是唯一的工作人员，我能够快速地编辑我的代码。除了在我的笔记本电脑上本地制作副本之外，我没有对代码进行备份。在完成机器学习模型的训练和分析后，我创建了一些可视化内容，并将它们放入LaTeX格式的论文中，这就是项目的结束。我从未再次运行过那些脚本。
- en: 'This is all suitable for a learning environment but very different from the
    working environment in industry. Many ML practitioners have shared their experiences
    shifting their mindsets, too: models now need to be *deployed*, able to be run,
    and easily modified by other colleagues, and the code needs to be backed up and
    rerun—often automatically!'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些对学习环境来说都是合适的，但与工业环境中的工作环境非常不同。许多机器学习从业者也分享了他们调整心态的经历：现在模型需要*部署*，能够运行，并且可以轻松地被其他同事修改，代码也需要被备份并重新运行
    —— 通常是自动化地！
- en: Production is a spectrum, depending on the company where you’re applying. For
    some teams, your main ML deliverable may be generating some plots after training
    the model once, and that could be similar to your experience in school or with
    a personal project. For other teams (and anecdotally, these jobs are more competitive),
    production could come with expectations for uptime and running for millions of
    users. In those cases, what works for a simple development environment likely
    will be different from production.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**生产**是一个光谱，取决于你申请的公司。对于某些团队来说，你的主要机器学习成果可能仅仅是在训练模型后生成一些图表，这可能类似于你在学校或个人项目中的经验。对于其他团队（据说这些岗位更具竞争力），生产可能会伴随对可用性和百万用户运行的期望。在这些情况下，一个简单的开发环境中有效的方法可能与生产环境中的不同。'
- en: At my first job, the ML models I developed had to run for millions of users
    every day. Compared to my grad school projects that only had several thousand
    records, the computation that was required was very different, and I could no
    longer run it on my laptop. At that first job, I had to learn to remote session
    into our local cloud computation and work with code on a virtual machine. I also
    had to learn how to use version control so that the code could be backed up and
    easily shared with colleagues. I had to write tests so that new changes to the
    code could be automatically tested; this wasn’t something I did in my school projects
    since I manually tested each change. Finally, my ML models at my first job had
    to be run with a scheduler so that it could generate predictions at least once
    a day—a far cry from my ML models at school that I ran only one time after the
    training process to generate the full results.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的第一份工作中，我开发的机器学习模型每天都必须为数百万用户运行。与我在研究生项目中只有几千条记录的项目相比，所需的计算方式完全不同，我无法再在我的笔记本电脑上运行它。在那份第一份工作中，我不得不学习远程进入我们本地云计算并在虚拟机上工作的方法。我还不得不学习使用版本控制，以便代码可以备份并轻松与同事共享。我不得不编写测试代码，以便自动测试每次更改；这是我在学校项目中没有做过的，因为我手动测试了每个更改。最后，我的第一份工作中的机器学习模型必须通过调度程序运行，以便每天至少生成一次预测结果——这与我在学校的机器学习模型只运行一次训练过程后生成完整结果完全不同。
- en: I share all of this to say, if you’re able to gain some of this experience at
    school with collaborative projects that use version control (Git, GitHub, etc.),
    then you’ll be able to speak more articulately about some of these skills. If
    you didn’t have the opportunity to learn collaborative development, then it’ll
    serve you well to skim some of this chapter regardless of the role you’re applying
    for so that you can familiarize yourself with what you might need to learn on
    the job.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我分享这些是为了表明，如果你能在学校通过使用版本控制（Git、GitHub 等）进行协作项目中获得这些经验，那么你将能更加流利地谈论这些技能。如果你没有机会学习协作开发，那么无论你申请什么角色，浏览一些本章内容都会对你有所帮助，以便你能熟悉可能需要在工作中学习的内容。
- en: Tip
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Nowadays, I recommend that candidates try deploying a simple web app with tools
    such as [Streamlit](https://streamlit.io). In the past, I have deployed my side
    projects with Flask locally or on hosting sites like [Heroku](https://oreil.ly/D86D9).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我建议候选人尝试使用诸如 [Streamlit](https://streamlit.io) 这样的工具部署一个简单的 Web 应用程序。过去，我已经使用
    Flask 在本地部署过我的项目，或者在 [Heroku](https://oreil.ly/D86D9) 这样的托管网站上部署过。
- en: Should Data Scientists and MLEs Know This?
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学家和 MLE 是否应该了解这些？
- en: 'This type of question comes up a lot from job seekers, such as “Should A know
    Docker?” “Should B know Tableau?” For example:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 求职者经常会提出这种类型的问题，例如“A是否应该了解 Docker？”“B是否应该了解 Tableau？”例如：
- en: Should data scientists know Kubernetes?
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家是否应该了解 Kubernetes？
- en: Should MLEs know the math behind ML algorithms?
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLE 是否应该了解机器学习算法背后的数学？
- en: Should data scientists know Docker?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家是否应该了解 Docker？
- en: 'My answer: *you* have to make the decision for *your own situation* on whether
    you should learn technology X at this specific time in your ML career, and here’s
    how.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我的回答是：*你*必须根据*你自己的情况*决定在你的机器学习职业生涯中是否应该学习技术 X，以下是如何进行决策的。
- en: 'Let’s use Kubernetes as an example—you might be trying to figure out if you
    should know it. My opinion is that there’s an order to things: first, know what’s
    necessary for *the role you’re applying for*. Use the methods outlined in Chapters
    [1](ch01.html#machine_learning_roles_and_the_interview) and [2](ch02.html#machine_learning_job_application_and_res)
    to see what part of the machine learning lifecycle you’re interested in and then
    parse out via job postings whether the job you’re applying for requires you to
    know Kubernetes. If the role doesn’t require it, focus on preparing other core
    topics, such as model training and evaluation.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以 Kubernetes 为例——你可能正在尝试弄清楚你是否应该了解它。我认为事情是有先后顺序的：首先，了解*你申请的角色*需要什么是必要的。使用第
    [1](ch01.html#machine_learning_roles_and_the_interview) 章和第 [2](ch02.html#machine_learning_job_application_and_res)
    章中概述的方法，看看你对机器学习生命周期的哪个部分感兴趣，然后通过工作职位描述确定你申请的工作是否需要你了解 Kubernetes。如果角色不要求这一点，专注于准备其他核心主题，如模型训练和评估。
- en: If the roles you’re aiming for do require Kubernetes experience or other types
    of deployment knowledge, such as setting up Jenkins, GitHub actions, and general
    CI/CD, then definitely do some research and gain some hands-on experience with
    them in a toy project.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你瞄准的角色确实需要 Kubernetes 经验或其他类型的部署知识，比如设置 Jenkins、GitHub 操作和通用 CI/CD，那么务必进行一些研究，并在一个玩具项目中获得一些实际经验。
- en: Going a step further, it’s important to read through various trusted and relevant
    sources on the topic and gather a wide range of perspectives.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 更进一步，阅读有关该主题的各种可靠和相关来源，并收集广泛的观点是非常重要的。
- en: 'For example, Chip Huyen, author of [*Designing Machine Learning Systems*](https://oreil.ly/j9Obs)
    (O’Reilly), wrote in a blog post, “Why Data Scientists Shouldn’t Need to Know
    Kubernetes”:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Chip Huyen，《*设计机器学习系统*》（O’Reilly）的作者，在一篇博文中写道：“为什么数据科学家不需要了解 Kubernetes”：
- en: Owning a data science project end-to-end allows faster execution and lower communication
    overhead. However, it’d only make sense if we have good tools to abstract away
    lower level infrastructure to help data scientists focus on actual data science
    instead of configuration files.^([1](ch06.html#ch06fn1))
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 拥有一个端到端的数据科学项目可以实现更快的执行和更低的沟通开销。然而，只有当我们有好的工具来抽象出较低级别的基础设施，帮助数据科学家专注于实际的数据科学而不是配置文件时，才有意义。^([1](ch06.html#ch06fn1))
- en: 'I also recommend Eugene Yan’s blog post “Unpopular Opinion: Data Scientists
    Should be More End-to-End,”^([2](ch06.html#ch06fn2)) in which he writes: “I’m
    trying to convince [readers] that end-to-end visibility, cohesion (i.e., reverse
    Conway’s law), and ownership leads to better outcomes.”^([3](ch06.html#ch06fn3))
    But he’s not necessarily “pushing for data scientists/ML engineers to be full-stack
    and have in-depth knowledge of how to set up K8s, do PhD-level research, design
    front-end, etc.,” he adds.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我还推荐 Eugene Yan 的博文“不受欢迎的观点：数据科学家应该更具端到端”，^([2](ch06.html#ch06fn2)) 在这篇文章中他写道：“我试图说服[读者]，端到端的可见性、内聚性（即反向康威定律）和所有权会带来更好的结果。”^([3](ch06.html#ch06fn3))
    但他并不一定“主张数据科学家/ML工程师应该全栈，并且深入了解如何设置 K8s，进行博士级研究，设计前端等等。”他补充道。
- en: 'At this point, after looking at job postings and various trusted opinions,
    you might make a decision: “I don’t need to learn Kubernetes *right now,* but
    it might be helpful *eventually.*”'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在此时点，在查看工作职位和各种可靠意见后，你可能会做出决定：“我现在*不需要*学习 Kubernetes，但将来可能会有帮助。”
- en: 'Whether your conclusion is yes or no, I think the best kind of answer assumes
    that you can *reevaluate* the answer when circumstances change. As with all careers,
    whether you should know X, Y, or Z technology will be fluid! As your career grows,
    you might find yourself in one of the following situations:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你的结论是肯定还是否定，我认为最好的答案类型是假设当情况改变时，你可以*重新评估*这个答案。就像所有职业一样，无论你是否应该了解 X、Y 或 Z 技术都是会变化的！随着你的职业发展，你可能会发现自己处于以下某种情况中：
- en: Moving into a startup and having to take on a broader range of responsibilities
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进入初创企业并承担更广泛职责
- en: Wanting to get promoted, and it’s required to have more experience in X
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想要晋升，需要更多 X 经验
- en: Wanting to move laterally into another ML role that requires more experience
    in X
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想要横向转入另一个需要更多 X 经验的 ML 角色
- en: In those scenarios, you will eventually need to know X! But that doesn’t mean
    you need to know it now. Since you might be short on time for interview prep,
    treat it as constrained optimization. You probably have a limited amount of energy,
    preparation time, and research time that you can spend finding an ideal job. You
    should prioritize the activities that give you the most optimized interview results.
    If that’s learning Kubernetes, then focus on learning it. If that’s model training,
    then focus on model training first and use the remaining time on other tasks.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情景中，最终你可能需要了解 X！但这并不意味着你现在就需要了解它。由于你可能在面试准备上时间不足，把它看作是受限制的优化问题。你可能有限的精力、准备时间和研究时间可以用来找到理想的工作。你应该优先考虑那些能给你最优化面试结果的活动。如果学习
    Kubernetes 能达到这个效果，那就专注于学习它。如果是模型训练，那就首先专注于模型训练，然后把剩余时间用在其他任务上。
- en: End-to-End Machine Learning
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 端到端机器学习
- en: '*End-to-end* is a term used to refer to an entire workflow, the “ends” being
    the beginning and the end of the project or workflow. There’s been discussion
    around whether ML practitioners should be more end-to-end, and you might be wondering
    whether you should be. To tie to the machine learning lifecycle, the answer is
    that you should know about multiple aspects of the lifecycle (refer back to [Figure 1-5](ch01.html#machine_learning_lifecycle_with_more_fin)),
    not just one part of it.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*端到端* 是一个用来指代整个工作流的术语，“端”是项目或工作流的开始和结束。关于 ML 从业者是否应该更全面已经有了讨论，你可能会想知道你是否应该这样做。要联系机器学习生命周期，答案是你应该了解多个生命周期的方面（参见
    [图1-5](ch01.html#machine_learning_lifecycle_with_more_fin)），而不仅仅是其中的一部分。'
- en: A similar term in software engineering is *full-stack engineer* or *full-stack
    developer*, and sometimes full-stack data scientist, full-stack MLE, and the like
    also refer to those roles being responsible for more of the end-to-end ML process.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件工程中，类似的术语是 *全栈工程师* 或 *全栈开发者*，有时候全栈数据科学家、全栈MLE等也指那些负责更多端到端 ML 过程的角色。
- en: 'My answer is going to be similar to the “Should I know this?*”* question: look
    into your job role and see what’s needed. Then determine what’s a priority and
    what’s most beneficial.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我的答案会与“我需要知道这个吗？”的问题类似：审视你的工作角色，看看需要什么。然后确定什么是优先的，什么是最有益的。
- en: Tip
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'As Eugene Yan writes in his blog post, “Unpopular Opinion: Data Scientists
    Should be More End-to-End,” it’s helpful to be *aware* of the end-to-end ML process,
    but you don’t have to be an expert in every single thing.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如 Eugene Yan 在他的博客文章中所写，“不受欢迎的观点：数据科学家应该更全面”，了解端到端的 ML 过程是有帮助的，但你不必成为每一个方面的专家。
- en: Here’s my own story of becoming more end-to-end over time, but not as an entry-level
    candidate. When I got my first DS/ML job, I didn’t know much about model deployment
    at scale or tools like Docker or Kubernetes,^([4](ch06.html#ch06fn4)) and I didn’t
    know data engineering and SQL that well either. During that first job, I learned
    more about data engineering and SQL to an advanced level, and Docker to an intermediate
    level, but I still didn’t know Kubernetes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我自己的故事，随着时间的推移变得更加全面，但不是作为一名初级候选人。当我得到我的第一份数据科学/机器学习工作时，我对规模化模型部署或像 Docker
    或 Kubernetes 这样的工具了解不多，^[4](ch06.html#ch06fn4) 我对数据工程和 SQL 也不太熟悉。在那份工作期间，我学到了更多关于数据工程和
    SQL 到高级水平，Docker 到中级水平，但我仍然不了解 Kubernetes。
- en: 'During my second job, which was at a startup, I was responsible for more of
    the machine learning lifecycle, so I needed to learn more about deploying models
    in a scaled-up manner. In that scenario, it made sense to catch up on those technologies
    and become even more end-to-end to better connect the ML workflow to the non-ML
    portion of our app stack. I’ve spoken on the benefit of being more end-to-end
    in my keynote at the [O’Reilly AI Superstream: MLOps](https://oreil.ly/pb83P),
    which is that understanding the deployment process helps ML practitioners be more
    efficient at completing ML projects.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '在我的第二份工作中，我在一家初创公司，我负责更多的机器学习生命周期，因此我需要学习更多关于规模化部署模型的技术。在那种情况下，学习这些技术并使得端到端连接
    ML 工作流到我们应用堆栈的非 ML 部分变得更加合理。我在 [O''Reilly AI Superstream: MLOps](https://oreil.ly/pb83P)
    上的主题演讲中谈到，了解部署过程如何帮助 ML 从业者更有效地完成 ML 项目。'
- en: 'Overall, I think it’s benefited my career to become more end-to-end. However,
    this has happened over the course of many years: I didn’t know so much at the
    beginning of my ML career but instead picked up knowledge project by project,
    role by role. So don’t worry too much about claims that you need to know X, Y,
    or Z: evaluate your situation by looking at the roles that you are most interested
    in and prioritize the top skills to succeed in those interviews. You can also
    quickly gain a high-level overview of other skills from books like this one before
    diving deeper. You can pick up new skills later on the job or through continued
    self-learning, as I did.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我认为成为更全面的人对我的职业生涯有益。然而，这是在多年的时间内发生的：我在我的 ML 生涯开始时并不了解很多，而是逐项目、逐角色地积累知识。所以不要太担心需要了解
    X、Y 或 Z 的说法：通过审视你最感兴趣的角色，并优先考虑成功面试的顶级技能来评估你的情况。在深入之前，你也可以通过像这本书这样的书籍快速获取其他技能的高级概述。你可以在工作中或通过持续的自学中后续学习新技能，就像我一样。
- en: The following sections will cover cloud environments and local environments,
    model deployment technologies, cloud providers, and additional tooling. If you’re
    already familiar with the concepts or feel that some sections aren’t relevant
    for you right now, feel free to skip them. You can also come back to this chapter
    when the topics become more relevant.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分将涵盖云环境和本地环境、模型部署技术、云提供商和额外的工具。如果你已经熟悉这些概念或者觉得某些部分现在对你来说不相关，可以跳过它们。当这些话题变得更相关时，你也可以回到本章节。
- en: Cloud Environments and Local Environments
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云环境和本地环境
- en: In [Chapter 4](ch04.html#technical_interviewcolon_model_training), I talked
    about model training and evaluation. What I didn’t detail in that chapter is the
    development environment. Models are trained somewhere and evaluated somewhere.
    That environment could be a local machine (such as your MacBook Pro), a cloud
    virtual machine (VM), and so on.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第四章](ch04.html#technical_interviewcolon_model_training)中，我谈到了模型训练和评估。但我没有在那一章节详细描述开发环境。模型在某处训练并在另一处评估。该环境可以是本地机器（比如你的MacBook
    Pro）、云虚拟机（VM）等等。
- en: Additionally, the environment where the models are trained usually differs from
    the production environment. For example, the model could be trained on a VM and
    bundled up as a pickle file, then copied over by a script to the production environment,
    which could be in a completely different Google Cloud Platform (GCP) namespace
    that the person training the model might not have personal access to.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，模型训练的环境通常与生产环境不同。例如，模型可以在VM上训练并打包成pickle文件，然后通过脚本复制到生产环境，这个生产环境可能在完全不同的Google
    Cloud Platform（GCP）命名空间中，训练模型的人可能没有个人访问权限。
- en: Whether working on the cloud or locally, you have to be mindful of the handover
    between the model training and deployment. How are the model training artifacts
    being shipped over to production? What’s the production process, and *where* is
    each step in the process happening? Is there even a production process? Knowing
    the basics of the types of locations that ML workflows are built on can help you
    with the tasks of streamlining, automating, or optimizing ML deployment. This
    isn’t often asked about directly in interviews, but it’s an important foundation
    for other model-deployment topics in your interviews.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是在云端还是本地工作，你都必须注意模型训练与部署之间的交接。模型训练的工件是如何运送到生产环境的？生产过程是什么样的，每个步骤在*哪里*进行？甚至是否有生产流程？了解ML工作流建立在哪些类型的位置基础上的基础知识，可以帮助你简化、自动化或优化ML部署的任务。这通常不会直接在面试中询问，但对于面试中其他与模型部署相关的话题是一个重要的基础。
- en: Summary of local environments
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本地环境总结
- en: 'When I first started out in data, it was already more common to train models
    on a remote or cloud environment or provision a cloud VM. However, there are some
    things that aren’t running on beefy compute and can still commonly be done locally
    on your machine (depending where you work). These include:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当我刚开始涉足数据领域时，已经更普遍地在远程或云环境中训练模型或配置云虚拟机。然而，有一些事情并非在高性能计算上运行，仍然可以在本地机器上常见地完成（取决于你的工作场所）。这些包括：
- en: Connecting to a remote data store and running a Jupyter Notebook locally for
    ad hoc exploratory data analysis
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接到远程数据存储并在本地运行Jupyter Notebook进行临时的探索性数据分析
- en: Doing a quick prototype of model training on a small sample of data but running
    the full training remotely
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在小样本数据上快速原型化模型训练，但是完整的训练是远程进行的
- en: Testing the ML service locally, if the company’s tech stack is set up to run
    locally
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果公司的技术堆栈设置成可以在本地运行ML服务进行测试
- en: Local machines are often a *development* environment only, unless you’re a startup
    running a server off a single machine (very unlikely because of downtime or compute
    concerns). For this book, I won’t discuss cases where a single local server is
    being run.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 本地机器通常只是*开发*环境，除非你是一家初创公司在单台机器上运行服务器（这种情况非常少见，因为会存在停机或计算问题）。在本书中，我不会讨论仅运行单个本地服务器的情况。
- en: It is important to know how your *development* environment runs on a local machine,
    such as a laptop, so that you know how it can be replicated on your production
    environment, and vice versa. Setting up [Docker](https://oreil.ly/wsewB) (to be
    covered later in this chapter) and dependency management like [Pipenv](https://oreil.ly/kIiKf),
    [Poetry](https://oreil.ly/wPvpO), and the like in Python are essential so that
    what runs on someone’s laptop will run in production or even on another coworker’s
    laptop!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 了解你的*开发*环境在本地机器（如笔记本电脑）上的运行方式非常重要，这样你就知道如何在生产环境及其反之上复制它。设置[Docker](https://oreil.ly/wsewB)（稍后在本章中介绍）和依赖管理如[Pipenv](https://oreil.ly/kIiKf)、[Poetry](https://oreil.ly/wPvpO)等在Python中是必不可少的，这样在某人的笔记本电脑上运行的内容将在生产环境甚至另一个同事的笔记本电脑上运行！
- en: Summary of cloud environments
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**云环境总结**'
- en: While “cloud” has become the umbrella term for using remote servers managed
    by a third party, there are some nuances important to ML and different ways that
    cloud environments are deployed. Next, I’ll walk through a few types of development
    environments.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管“云”已成为由第三方管理的远程服务器使用的总称，但在ML中有一些重要的细微差别以及云环境部署的不同方式。接下来，我将详细介绍几种开发环境类型。
- en: Public cloud provider
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**公共云提供商**'
- en: '*Public cloud* refers to cloud services from vendors such as GCP, Amazon Web
    Services (AWS), Microsoft Azure, and many more, which I’ll cover more in [“Overview
    of Cloud Providers”](#overview_of_cloud_providers). What makes this service different
    from private cloud from the same vendor, however, is that hardware-wise, the same
    servers could run workloads from multiple companies—that is, they are *multitenant*.
    The upside of public cloud providers is their sheer convenience to set up, which
    makes public cloud a very popular choice for software companies.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*公共云*指的是来自诸如GCP、Amazon Web Services（AWS）、Microsoft Azure等供应商的云服务，我将在[“云供应商概述”](#overview_of_cloud_providers)中更详细地介绍。然而，与同一供应商的私有云相比，硬件方面，同一台服务器可以运行来自多家公司的工作负载——也就是说，它们是*多租户*的。公共云提供商的优势在于其极大的便利性，这使得公共云成为软件公司非常流行的选择。'
- en: 'Here are some additional considerations with using public cloud: because of
    the vast resources of large vendors, using public cloud can be generally secure,
    but for regulatory reasons, it might be the least ideal option. The process of
    migrating to the public cloud could cause downtime and disrupt day-to-day operations,
    which could be massively inconvenient. If you’re preparing to work in a small
    to midsize company in ML, you’re likely to use public or private cloud. If you’re
    in a larger company in a highly regulated industry, you’ll likely use on-premises
    or local cloud and/or work locally.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用公共云时需要考虑的一些额外问题包括：由于大型供应商的大量资源，使用公共云通常是安全的，但由于法规原因，这可能不是最理想的选择。向公共云迁移的过程可能会导致停机并破坏日常运营，这可能极其不便。如果你准备在ML中的中小型公司工作，你可能会使用公共或私有云。如果你在高度监管的大公司工作，你可能会使用本地部署或本地云和/或本地工作。
- en: Public cloud became popular with the rise of platforms like AWS, prompting many
    companies to move workloads to cloud services from on-prem (on-premises) servers.
    However, many workflows or data stores still cannot be moved to the public cloud
    for regulatory reasons.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 随着AWS等平台的兴起，公共云变得流行起来，促使许多公司将工作负载从本地（on-premises）服务器迁移到云服务上。然而，由于法规原因，许多工作流程或数据存储仍无法迁移到公共云。
- en: On-premises and private cloud
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*本地部署和私有云*'
- en: In some larger corporations, it’s not uncommon to own servers and host on-premises
    platforms on them. When I worked at a large telecommunications company, it owned
    many servers itself. In fact, many of the servers that large public cloud providers
    use are leased from or owned by telecommunications companies. The company kept
    some servers for private use, and it had its [own instances of GitLab](https://oreil.ly/Osuho)
    and other services. Many enterprise software solutions also offer self-hosted
    solutions that come with the benefits of having enterprise support. This is called
    *on-premises*.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些大型公司中，拥有服务器并在其上托管本地平台并不罕见。当我在一家大型电信公司工作时，它拥有许多自己的服务器。事实上，许多大型公共云提供商使用的服务器是从电信公司租赁或拥有的。该公司保留了一些服务器供私人使用，并拥有自己的[GitLab实例](https://oreil.ly/Osuho)和其他服务。许多企业软件解决方案也提供自托管解决方案，具有企业支持的好处。这被称为*本地部署*。
- en: 'The reasons for self-hosting many services include:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 自托管许多服务的原因包括：
- en: The company owns the servers, and it’s more secure than the same servers having
    exposure to the public cloud.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公司拥有服务器，比将同一批服务器暴露于公共云更安全。
- en: It’s easier in some cases for regulatory purposes, such as General Data Protection
    Regulation (GDPR), a European Union regulation on information privacy.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在某些情况下，出于监管目的，如欧盟的通用数据保护条例（General Data Protection Regulation，GDPR），信息隐私的法规更容易实施。
- en: Highly regulated industries like financial services and legal institutions have
    additional requirements for where the data is stored and if public cloud can be
    used to store personal identifiable information (PII).
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 金融服务和法律机构等高度受监管的行业对数据存储位置有额外要求，并且是否可以使用公共云来存储个人可识别信息（PII）。
- en: '*Private cloud* sits between public cloud and on-premises/local cloud. The
    vendor, such as AWS, that hosts the servers guarantees that the servers are [dedicated
    to](https://oreil.ly/4Mkcu) one enterprise customer only (single tenant),^([5](ch06.html#ch06fn5))
    as opposed to shared hardware that the public cloud uses. Companies might use
    a mix of all of these, including public cloud, depending on what is feasible and
    balancing trade-offs of costs, convenience, and regulations.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*私有云*位于公共云和本地/私有云之间。如AWS等供应商托管服务器并保证这些服务器仅用于一家企业客户（单租户），^([5](ch06.html#ch06fn5))与公共云使用的共享硬件相对立。公司可能会根据可行性和成本、便利性及法规平衡各种权衡因素，使用这些解决方案的混合方式，包括公共云。'
- en: Note
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If your role is not responsible for evaluating, setting up, or automating the
    deployment environments, the environments on which you are developing ML will
    not make a huge difference in your interview. When I worked on local cloud, it
    was slightly less convenient compared to private or public cloud (in my opinion)
    but overall required similar knowledge. If you’ve worked with one remote environment,
    you can work with another. However, if you’re part of the MLOps platform team
    proper, you might be required to learn more about the underlying workings of the
    platforms you work with.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的角色不负责评估、设置或自动化部署环境，那么您开发机器学习的环境在面试时不会有太大差别。当我使用本地云时，与私有云或公共云相比（依我之见），便利性略逊一筹，但总体上需要的知识相似。如果您已经使用了一个远程环境，那么您也可以使用另一个。然而，如果您是MLOps平台团队的一员，可能需要更多地了解您所使用平台的基本工作原理。
- en: On the other hand, there’s also been a phenomenon called [*cloud repatriation*](https://oreil.ly/2qcrO)^([6](ch06.html#ch06fn6))
    where companies that have moved to public cloud services are now reevaluating
    and moving back to local cloud because of the various benefits of local cloud.
    In my observation, larger companies have more bandwidth to self-host local cloud
    instances because they have more staff and thus can afford to have dedicated staff
    to maintain those local servers and communicate with the vendor consultants on
    how to troubleshoot when things go wrong. When I was at a large company, one of
    its platform vendors was IBM; when there was an issue with our local instance
    of IBM’s platform, one of the senior members on the data science team would call
    IBM and schedule a meeting so that IBM could help troubleshoot. It was nice to
    have IBM support staff available around the clock, but as you can imagine, the
    costs for said support and consulting were high as well.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，还出现了所谓的[*云回归*](https://oreil.ly/2qcrO)^([6](ch06.html#ch06fn6))现象，即曾经转向公共云服务的公司现在正在重新评估并回到本地云，因为本地云的各种优势。据我观察，大公司有更多资源自行托管本地云实例，因为他们拥有更多员工，因此能够负担得起专职人员来维护这些本地服务器，并与供应商顾问沟通，解决出现问题时的故障排除方法。在我曾供职的一家大公司，其中一个平台供应商是IBM；当IBM平台的本地实例出现问题时，数据科学团队的高级成员之一会联系IBM，并安排会议，以便IBM提供故障排除支持。全天候提供IBM支持服务确实很好，但你可以想象，支持和咨询的成本也相当高。
- en: Smaller to midsize companies might find maintaining a local cloud cumbersome,
    costly, and too much of an overhead. Public or private cloud might remain the
    most common option for this type of company.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 较小至中型公司可能会发现维护本地云既繁琐又昂贵，而且开销太大。对于这类公司，公共或私有云可能仍然是最常见的选择。
- en: Overview of Model Deployment
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型部署概述
- en: After models are trained and ready, it’s time to deploy them (to production)!
    At different types of companies, this process can be very different. There are
    various levels of production, as I mentioned earlier in this chapter, but the
    goal is for the model to be *useful*.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练完成并准备就绪后，是时候部署它们（到生产环境）了！在不同类型的公司中，这个过程可能大不相同。正如我在本章前面提到的，生产环境有不同的层次，但目标是让模型变得*有用*。
- en: Here is a nonexhaustive list of examples of deployment, ranging from the least
    complex level to the most complex:^([7](ch06.html#id1749))
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些部署示例的非详尽列表，从最简单的级别到最复杂的级别：^([7](ch06.html#id1749))
- en: The ML model is stored somewhere and run ad hoc; results are saved locally.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型被某处存储并按需运行；结果在本地保存。
- en: The ML model is stored and run ad hoc, but results are written to a central
    location.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型被某处存储并按需运行，但结果写入到一个中心位置。
- en: The ML model is stored somewhere and automatically run as a batch process, and
    results are written out.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型被某处存储并自动运行为批处理过程，并将结果写出。
- en: The ML model is wrapped in a simple web app such as [Flask](https://oreil.ly/QetyX),
    and the app is spun up via a Docker container.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型被包装在一个简单的Web应用程序中，例如[Flask](https://oreil.ly/QetyX)，并通过Docker容器启动。
- en: The ML model is wrapped in a simple app and called via [Google Cloud Functions](https://oreil.ly/IEjDe)
    or [AWS Lambda](https://oreil.ly/GRK30).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型被包装在一个简单的应用程序中，并通过[Google Cloud Functions](https://oreil.ly/IEjDe)或[AWS
    Lambda](https://oreil.ly/GRK30)调用。
- en: The ML model is served somewhere and orchestrated and managed by Kubernetes;
    almost everything is automated.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型被某处提供并由Kubernetes编排和管理；几乎所有事情都是自动化的。
- en: And so on.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 等等。
- en: Depending on the company you’re interviewing with and its typical mode of deployment,
    there will be different expectations for you. If you’re interviewing for a company
    with a mature tech or ML team, you’ll likely be expected to know about the tools
    related to levels 5 and 6 in the preceding list. The company size is less the
    deciding factor than the maturity of the tech stack; when I was at a 200-person
    startup, our tech stack was working at level 6.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您面试的公司及其典型的部署模式，您会有不同的期望。如果您正在面试一个技术或机器学习团队成熟的公司，您可能需要了解与上述列表中5和6级相关的工具。公司规模不如技术栈的成熟度重要；当我在一个有200人的初创公司时，我们的技术栈正处于第6级。
- en: This means that, in general, if you’re in an ML role that is responsible for
    parts of the platform, deployment, and production lifecycle, you’ll need to spend
    more time studying if you don’t happen to have work experience in these technologies
    and tools. For ML teams with low maturity, such as those at levels 1–4, you might
    be juggling this role while also being the same person who trains the ML models.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，一般来说，如果您在一个负责平台的部分、部署和生产生命周期的机器学习角色中，如果您恰好没有这些技术和工具的工作经验，您将需要更多时间进行学习。对于成熟度较低的机器学习团队（如1至4级），您可能会在训练机器学习模型的同时，负责处理这些角色。
- en: As an ML team grows more mature, it’ll become less useful for the same person
    to train the model and also build an automated platform. A person or team doing
    multiple things at once won’t be able to focus on making the ML models the best
    they can be, especially as more and more models are needed as the company grows.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 随着一个机器学习团队的成熟度增加，同一个人既训练模型又构建自动化平台的价值将会减少。一个人或一个团队一次做多件事情，将无法专注于使机器学习模型达到最佳状态，特别是随着公司需要越来越多的模型。
- en: For example, an ecommerce company that started out making a simple forecasting
    model for inventory may want to develop models to recommend items in its newsletters.
    Then, the company may want to add a robust model for sales periods only. Or, perhaps
    fraudulent accounts were using the company’s goods to obscure the flow of stolen
    money; someone at the company may issue a directive to create a fraud-detection
    model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个电子商务公司最初可能制作了一个简单的库存预测模型，后来可能希望开发推荐商品的模型，用于其新闻通讯。然后，公司可能希望仅在销售期间添加一个强大的销售模型。或者，也许有人在公司发现欺诈账户正在使用公司的商品来掩盖偷来的资金流；那么该公司的某人可能会发布指令创建一个欺诈检测模型。
- en: At the point where an ML team acquires more and more responsibilities, the team
    will become tired of duct tape (quick, ad hoc) fixes and want to start introducing
    some developer overhead, such as containerization and version control. Today,
    companies generally start with those right from the beginning, but only a few
    years ago, some teams with less mature software or ML teams might not have been
    using Docker, and you’d be surprised to learn that some companies and teams only
    started formalizing Git a few years ago (as of the time of writing in 2023). Nowadays,
    it’s likely that knowledge about Docker and version control (such as Git) are
    more expected skills than before.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个机器学习团队承担了越来越多的责任时，团队会厌倦用胶带（快速、临时的）修复方法，并希望开始引入一些开发者的额外工作量，比如容器化和版本控制。今天，公司通常从一开始就开始使用这些工具，但仅仅几年前，一些软件不够成熟或者机器学习团队可能并未使用
    Docker，而有些公司和团队直到几年前（截至2023年）才正式开始使用 Git。如今，对 Docker 和版本控制（如 Git）的知识的需求可能比以往更高。
- en: Introduction to Docker
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Docker 简介
- en: Docker allows software applications and their dependencies to be wrapped up
    together and be *portable*—that is, with a Docker container, the same software
    should be able to run the same way on any compatible machine. On the other hand,
    running the same script on your colleague’s system Python environment might work
    fine, but running the same script on your laptop might not work without the environment
    being *portable*. Thus, Docker also serves the purpose of making the environment
    independent of the infrastructure it’s running on.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 允许将软件应用程序及其依赖项打包在一起，并且是*可移植*的——也就是说，使用 Docker 容器，相同的软件应该能在任何兼容的机器上以相同的方式运行。另一方面，同事的系统上可能可以运行相同脚本，但在你的笔记本电脑上运行同样的脚本可能需要环境*可移植*。因此，Docker
    还可以使环境与运行它的基础设施无关。
- en: 'Containerization isn’t new: in the past, VMs were pretty commonly used to address
    a similar problem—for example, someone working on a Linux machine wanting to test
    something on Windows could install a Windows VM, and vice versa. The downside
    is that the installations were entire operating systems, which is a lot of bloat
    just to test out something on another environment. With Docker containers, you
    don’t need to install the entire OS (unless specifically desired). For example,
    you can have a Docker image that specifies the Python environment;^([8](ch06.html#ch06fn7))
    the container uses the host’s operating system but still provides the isolation
    from other parts of the host machine that VMs provide.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 容器化并不是什么新鲜事物：过去，虚拟机（VMs）经常用来解决类似的问题——例如，一个在 Linux 机器上工作的人想要在 Windows 上测试某些东西，可以安装一个
    Windows 虚拟机，反之亦然。缺点是，安装的是整个操作系统，这在其他环境上测试时会导致大量冗余。使用 Docker 容器，你不需要安装整个操作系统（除非特意如此）。例如，你可以有一个
    Docker 镜像指定 Python 环境；^([8](ch06.html#ch06fn7)) 容器使用主机的操作系统，但仍然提供了虚拟机隔离其他部分的功能。
- en: A *Docker image* is a read-only template with instructions for creating a *Docker
    container*.^([9](ch06.html#ch06fn8)) So images are like a mold. The instructions
    that define this mold are in a *Dockerfile*. A Docker container is the runnable
    instance of an image, which you can create, start, stop, and so on. You can create
    multiple identical containers from one single image. For an example, see [Figure 6-1](#dockerfilecomma_docker_imagecomma_and_do).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*Docker 镜像* 是一个只读模板，包含创建 *Docker 容器* 的指令。^([9](ch06.html#ch06fn8)) 因此，镜像就像一个模具。定义这个模具的指令在
    *Dockerfile* 中。Docker 容器是镜像的可运行实例，你可以创建、启动、停止等等。你可以从一个单一镜像创建多个相同的容器实例。有关示例，请参见
    [图 6-1](#dockerfilecomma_docker_imagecomma_and_do)。'
- en: '![Dockerfile, Docker image, and Docker container.](assets/mlin_0601.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![Dockerfile、Docker 镜像和 Docker 容器。](assets/mlin_0601.png)'
- en: Figure 6-1\. Dockerfile, Docker image, and Docker container.
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-1\. Dockerfile、Docker 镜像和 Docker 容器。
- en: Orchestrating with Kubernetes
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 与 Kubernetes 协调
- en: Modern web services are often expected by users to have high availability. Good
    practices like dockerization help package software in an easily portable manner,
    which help applications be released without downtime. However, that is only a
    piece of the puzzle; technologies like Kubernetes *orchestrate* containerized
    applications to run at the right place and the right times in an automated way.
    Of course, people (could it be you?) who are responsible for ML application orchestration
    will need to set up the automations and tweak the configurations and policies.^([10](ch06.html#ch06fn9))
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现代 Web 服务通常要求具备高可用性。像 Docker 化这样的良好实践有助于将软件以易于移植的方式打包，这有助于应用程序在无需停机的情况下发布。然而，这只是一个谜题的一部分；像
    Kubernetes 这样的技术可以自动化地编排容器化应用程序，使其在正确的位置和时间运行。当然，负责 ML 应用程序编排的人（也可能是你？）需要设置自动化并调整配置和策略。^([10](ch06.html#ch06fn9))
- en: Note that the responsibilities of a job role that touches on orchestration could
    differ among companies. Some companies might have a DevOps engineer maintain the
    orchestration infrastructure. However, I’ve seen in many larger and more mature
    ML organizations that there are infrastructure engineers, MLOps engineers, and
    MLEs who might all be responsible for at least part of the uptime requirements
    for ML applications.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，涉及编排的职位角色的责任在不同公司可能有所不同。一些公司可能会让 DevOps 工程师维护编排基础设施。然而，我见过许多更大更成熟的 ML 组织中有基础设施工程师、MLOps
    工程师和 ML 工程师（MLE），他们可能都至少负责 ML 应用程序的一部分正常运行时间要求。
- en: 'I’ve given an overview of Docker and Kubernetes in this book, but since I don’t
    have sufficient space to cover as much as a DevOps/MLOps book could focus on,
    here are some additional resources from O’Reilly that I have found useful:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我概述了 Docker 和 Kubernetes，但由于篇幅有限，无法像 DevOps/MLOps 书籍那样详细涵盖，因此这里提供了一些我在
    O'Reilly 发现的有用资源：
- en: '[*Kubernetes: Up and Running*](https://oreil.ly/PgXCJ) by Brendan Burns et
    al.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*Kubernetes 实战*](https://oreil.ly/PgXCJ) 由 Brendan Burns 等人编写。'
- en: '[*Kubernetes Best Practices*](https://oreil.ly/K9HBS) by Brendan Burns et al.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*Kubernetes 最佳实践*](https://oreil.ly/K9HBS) 由 Brendan Burns 等人编写。'
- en: If all of this is completely new to you, don’t worry. In my work experience,
    I’ve been able to learn most of the containerization and orchestration tools on
    the job. In fact, I’d say that hands-on learning on work projects within working
    hours has contributed to most of my knowledge in this space so far.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些对你完全陌生，不用担心。根据我的工作经验，在工作中我已经学会了大部分容器化和编排工具。事实上，我可以说，在工作时间内通过实践项目的学习贡献了我在这一领域的大部分知识。
- en: Additional Tooling to Know
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外的工具
- en: 'Here I discuss a couple of other tools that are helpful to know about:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我讨论了一些其他有用的工具：
- en: ML pipelines and platforms
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ML 管道和平台
- en: Nowadays, there are many ML platforms that handle parts of the automation for
    ML workflows, and it’s useful to be aware of them. If you happen to find out before
    the interview which platform(s) the company you’re interviewing for uses, be sure
    to check out said platform’s documentation page to find out common terminology
    and tools that the platform provides. These ML platforms can include Airflow,
    MLflow, Kubeflow, Mage, and the like.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现今有许多处理 ML 工作流自动化部分的 ML 平台，了解它们是非常有用的。如果你事先得知你面试的公司使用的平台是哪个（些），务必查阅该平台的文档页面，了解平台提供的常见术语和工具。这些
    ML 平台可以包括 Airflow、MLflow、Kubeflow、Mage 等。
- en: CI/CD
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: CI/CD
- en: In an organization where the software team is more automated and mature, you
    might need to know more about continuous integration, continuous delivery (CI/CD)
    tools and technologies. Having these tools set up allows for software to be automatically
    deployed when new commits are merged into the main branch (this is a simplified
    example for understanding). This reduces much of the manual work when updates
    need to be refreshed manually all the time. See [Figure 6-2](#sample_flowchart_of_what_is_automated_wi)
    for an example of automating updating the source code, creating the software build,^([11](ch06.html#ch06fn10))
    testing, and deploying. Some tools for CI/CD, in combination with version control,
    could include Jenkins, GitHub actions, and GitLab CI/CD.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个软件团队更加自动化和成熟的组织中，你可能需要了解更多关于持续集成、持续交付（CI/CD）工具和技术的内容。配置这些工具可以在新的提交合并到主分支时自动部署软件（这是一个简化的例子以便理解）。这样做可以减少手动更新代码的工作量。参见
    [图 6-2](#sample_flowchart_of_what_is_automated_wi)，了解自动化更新源代码、创建软件构建^([11](ch06.html#ch06fn10))、测试和部署的示例。一些CI/CD工具，结合版本控制，可能包括
    Jenkins、GitHub actions 和 GitLab CI/CD。
- en: '![Sample flowchart of what is automated with CI/CD after a code change; source:
    “CI/CD Pipeline: A Gentle Introduction,” Marko Anastasov, Semaphore](assets/mlin_0602.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![CI/CD在代码更改后自动化流程的示例流程图；来源：“CI/CD Pipeline: A Gentle Introduction,” Marko
    Anastasov, Semaphore](assets/mlin_0602.png)'
- en: 'Figure 6-2\. Sample flowchart of what is automated with CI/CD after a code
    change; source: [“CI/CD Pipeline: A Gentle Introduction,” Marko Anastasov, Semaphore](https://oreil.ly/SUkIQ).'
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6-2\. CI/CD在代码更改后自动化流程的示例流程图；来源：[“CI/CD Pipeline: A Gentle Introduction,”
    Marko Anastasov, Semaphore](https://oreil.ly/SUkIQ)。'
- en: On-Device Machine Learning
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设备端机器学习
- en: There are also specific fields in ML related to on-device deployment, or edge
    deployment. Techniques like quantization^([12](ch06.html#ch06fn11)) make ML models
    smaller and efficient enough to run on mobile devices, IoT devices, and other
    types of edge devices. This requires a lot of additional considerations when it
    comes to deployment. This is a more advanced topic, so I encourage you to supplement
    your knowledge if you require it for interviews.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，还有一些特定领域与设备端部署或边缘部署相关。诸如量化^([12](ch06.html#ch06fn11)) 这类技术使得机器学习模型更小更高效，可以在移动设备、物联网设备以及其他类型的边缘设备上运行。在部署时，这需要考虑许多额外的因素。这是一个更高级的话题，所以如果你为面试需要这方面的知识，我建议你进一步补充。
- en: 'You can read more about on-device ML via the following resources:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下资源了解更多关于设备端机器学习的内容：
- en: '[“On-Device Machine Learning”](https://oreil.ly/n4riR) by Google for Developers'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“设备端机器学习”](https://oreil.ly/n4riR) 由 Google for Developers 提供'
- en: '[*AI and Machine Learning for On-Device Development*](https://oreil.ly/HvZtW)
    by Laurence Moroney (O’Reilly)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*AI和机器学习用于设备端开发*](https://oreil.ly/HvZtW) 由 Laurence Moroney（O’Reilly）撰写'
- en: '[“TensorFlow Lite: Solution for Running ML On-Device”](https://oreil.ly/bk4dZ/),
    a talk by Pete Warden and Nupur Garg (Google)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“TensorFlow Lite: 运行设备端机器学习的解决方案”](https://oreil.ly/bk4dZ/)，由 Pete Warden
    和 Nupur Garg（Google）演讲'
- en: Interviews for Roles Focused on Model Training
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面向模型训练角色的面试
- en: Even if you are applying primarily for the roles that do ML model training,
    don’t underestimate how some of this higher-level knowledge can help you in your
    interviews. Since there are many knowledgeable candidates in the ML training space,
    if you are tied on that front with another candidate, having more knowledge or
    experience with model deployment practices and collaborating cross-team could
    be a tiebreaker. However, you should prioritize the core ML training competencies
    in Chapters [3](ch03.html#technical_interviewcolon_machine_learnin) and [4](ch04.html#technical_interviewcolon_model_training)
    if your role is less focused on ML operations.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你主要申请的是机器学习模型训练相关的角色，也不要低估一些高级知识对你面试的帮助。由于在机器学习训练领域有很多有经验的候选人，如果在这方面与其他候选人处于同一水平，拥有更多的模型部署实践和跨团队协作经验可能会起到决定性作用。不过，如果你的角色不太侧重于机器学习运维，你应该优先考虑第
    [3](ch03.html#technical_interviewcolon_machine_learnin) 章和第 [4](ch04.html#technical_interviewcolon_model_training)
    章中的核心机器学习训练能力。
- en: As a personal anecdote, at some places where I’ve successfully gotten an offer,
    I’ve received feedback that the interviewers were impressed with how I connected
    the ML training to the deployment process. For example, during interviews I mentioned
    how I optimized ML inputs to ensure that the ML model could still run fast enough
    to satisfy the requirements in production. Candidates who are mindful of the end-to-end
    process can shorten the time it takes to go from ML model prototyping to being
    integrated into the company’s product (such as a RecSys on a shopping site).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 作为个人趣闻，我成功获得过的一些工作中，面试官反馈称他们对我如何将机器学习训练与部署过程联系起来印象深刻。例如，在面试中我提到如何优化机器学习输入，以确保模型在生产环境中仍能以足够快的速度运行以满足要求。那些对端到端过程留心的候选人可以缩短从机器学习模型原型到集成到公司产品（例如购物网站上的推荐系统）所需的时间。
- en: Therefore, in industry it’s important for candidates to not treat the ML models
    as mere curiosity projects—using as much data at runtime as possible and requiring
    too long to iterate on or no way to debug. That works fine on a research or ad
    hoc basis where the entire model is run only at rarer intervals. But in production,
    where an outage or bug could cause the loss of revenue or user trust, it’s important
    to prune some things and ensure the related scripts can be debugged.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在工业界，候选人不能将机器学习模型仅视为好奇的项目——在运行时使用尽可能多的数据并且需要过长时间来迭代或无法调试。这在仅在较少的时间间隔内运行整个模型的研究或临时基础上效果不错。但是在生产环境中，如果出现故障或错误可能导致收入或用户信任的损失，修剪一些内容并确保相关脚本可以进行调试是很重要的。
- en: Articulating my opinion and experiences on this matter helped set me apart from
    candidates who seemed to not take any responsibility for the usability of their
    ML models downstream.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个问题上表达我的观点和经验有助于我区别于那些似乎对其机器学习模型的可用性后续处理不负责任的候选人。
- en: Model Monitoring
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型监控
- en: After the model is trained (via the process outlined in [Chapter 4](ch04.html#technical_interviewcolon_model_training)),
    you still have to deploy it to production. Before that, however, it is important
    to decide on and set up monitoring so that you can detect problems with the model
    in production as early as possible. For example, if the model is constantly rejecting
    loan applicants, you’ll want someone on the ML team to be looking into why and
    potentially bringing it up with the business or product team. Other types of monitoring
    to set up could include an alert when the data pipeline is failing and so on.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型经过（如[第四章](ch04.html#technical_interviewcolon_model_training)中概述的过程）训练后，您仍然需要将其部署到生产环境中。在此之前，决定并设置监控非常重要，以便尽早检测到生产中模型存在的问题。例如，如果模型不断拒绝贷款申请人，您希望机器学习团队中的某人查明原因，并有可能与业务或产品团队讨论。可以设置的其他监控类型包括在数据管道失败时发出警报等。
- en: In this section, I’ll cover common setups for monitoring, such as dashboards
    and data quality checks. I’ll also cover specific ML-related monitoring, such
    as accuracy-related metrics.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我将介绍常见的监控设置，如仪表板和数据质量检查。我还将涵盖特定的与机器学习相关的监控，例如与准确性相关的指标。
- en: Tip
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Job candidates who don’t have experience deploying ML models to production can
    mimic some of this experience by deploying some simple web apps, as mentioned
    earlier in this chapter.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 那些没有经验将机器学习模型部署到生产环境中的求职者可以通过部署一些简单的Web应用程序来模仿这些经验，正如本章前面提到的。
- en: Monitoring Setups
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控设置
- en: Here are a few common ways of monitoring ML models once they are live in production.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些在生产环境中监控机器学习模型后常见的方法。
- en: Dashboards
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 仪表板
- en: Dashboards are often the first step in monitoring. You might not have automated
    data quality checks yet, but many companies I’ve seen have at least some sort
    of dashboard to monitor ML predictions.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板通常是监控的第一步。您可能尚未自动化数据质量检查，但我看过的许多公司至少有某种形式的仪表板来监控机器学习预测。
- en: 'Here are some important considerations when you are creating dashboards for
    ML monitoring:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建用于机器学习监控的仪表板时，有几个重要的考虑因素：
- en: Keep the visualization as simple as possible.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 保持可视化尽可能简单。
- en: If it’s too complicated, people will stop looking at it, which defeats the purpose
    of creating one.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果太复杂，人们会停止查看，这违背了创建仪表板的初衷。
- en: Make the labels as clear as possible.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 尽可能使标签清晰明了。
- en: Team members I’ve worked with and mentored in the past know that if the labels
    aren’t there or aren’t clear in any visualization, I will mention their importance
    in a code review. In particular, please don’t forget the axis labels.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 过去我与合作并指导过的团队成员都知道，如果任何可视化中缺少或者标签不清晰，我会在代码审查中提到它们的重要性。特别是，请不要忘记轴标签。
- en: Show patterns well.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 良好地显示模式。
- en: Sometimes the default scale can’t show the differences or magnitude well enough;
    for example, sometimes the graph gets very cramped. You can use log transforms
    to make a graph more readable.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 有时默认的比例尺不能很好地显示差异或大小；例如，有时图表非常拥挤。您可以使用对数变换使图表更易读。
- en: Warning
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Some of these points aren’t determined during the interview but much earlier.
    For example, if you linked a GitHub portfolio on your resume, the interviewers
    might have looked at it. If the dashboards or graphs on the portfolio are horribly
    unclear and lack axis labels, then that already gives a negative impression before
    the interview even happens.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这些点有些并不是在面试期间确定的，而是在更早的阶段。例如，如果您在简历中链接了GitHub作品集，面试官可能已经看过了。如果作品集中的仪表板或图表非常不清晰，并且缺少轴标签，那么甚至在面试之前就已经给出了负面印象。
- en: 'In terms of implementation, here are some common tools for visualization and
    monitoring:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施方面，这里是一些常见的可视化和监控工具：
- en: 'Custom dashboards: [Seaborn](https://oreil.ly/m-0-g), [Plotly](https://plotly.com),
    [Matplotlib](https://oreil.ly/s2smF), and [Bokeh](http://bokeh.org)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义仪表板：[Seaborn](https://oreil.ly/m-0-g)，[Plotly](https://plotly.com)，[Matplotlib](https://oreil.ly/s2smF)，以及[Bokeh](http://bokeh.org)
- en: 'End-to-end platforms: [Amazon SageMaker dashboards](https://oreil.ly/zuL3R)
    and [Google’s Vertex AI monitoring](https://oreil.ly/GEIlI)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端到端平台：[Amazon SageMaker仪表板](https://oreil.ly/zuL3R)和[Google的Vertex AI监控](https://oreil.ly/GEIlI)
- en: 'Other business intelligence (BI) tools: [Microsoft Power BI](https://oreil.ly/dSwsq),
    [Tableau](https://oreil.ly/xPRW6), and [Looker](https://oreil.ly/Xokd6)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他商业智能（BI）工具：[Microsoft Power BI](https://oreil.ly/dSwsq)，[Tableau](https://oreil.ly/xPRW6)，以及[Looker](https://oreil.ly/Xokd6)
- en: Data quality checks
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据质量检查
- en: Since dashboards are something to check manually, you may want to add automated
    checks to save time and ensure accuracy. These checks could include checking for
    missing values in the incoming data or even checking for a distribution shift
    in the data.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 由于仪表板需要手动检查，您可能希望添加自动化检查以节省时间并确保准确性。这些检查可以包括检查传入数据中的缺失值，甚至检查数据的分布是否发生变化。
- en: 'Tools for data checks or data unit tests include:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 数据检查或数据单元测试工具包括：
- en: '[Great Expectations](https://oreil.ly/OvPXL) (see [Figure 6-3](#screenshot_of_great_expectationsapostrop))'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Great Expectations](https://oreil.ly/OvPXL)（见[图 6-3](#screenshot_of_great_expectationsapostrop)）'
- en: '[deequ](https://oreil.ly/zIGqn)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[deequ](https://oreil.ly/zIGqn)'
- en: '[dbt](https://oreil.ly/WROHG) (pipelines can include tests)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[dbt](https://oreil.ly/WROHG)（流水线可以包括测试）'
- en: '![Screenshot of Great Expectations’ Expectations, which can test if data fulfills
    certain requirements](assets/mlin_0603.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![Great Expectations期望的屏幕截图，可测试数据是否满足某些要求](assets/mlin_0603.png)'
- en: Figure 6-3\. Screenshot of Great Expectations’ Expectations, which can test
    if data fulfills certain requirements.
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-3\. Great Expectations期望的屏幕截图，可测试数据是否满足某些要求。
- en: Alerts
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 警报
- en: 'Now that you have automated the detection of data quality drops or shifts,
    you can set up alerts. An alert policy includes the logic for the alerts, such
    as: if the column starts having too many Null values, notify this Slack channel.
    [Figure 6-4](#screenshot_of_great_expectations-id00011) shows an example of how
    a test would appear on Slack via [Great Expectations](https://oreil.ly/UV9ey).'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经自动化了检测数据质量下降或变化的过程，您可以设置警报。警报策略包括警报的逻辑，例如：如果某列开始出现过多的空值，请通知这个Slack频道。[图 6-4](#screenshot_of_great_expectations-id00011)展示了通过[Great
    Expectations](https://oreil.ly/UV9ey)在Slack上显示测试的示例。
- en: '![ Screenshot of Great Expectations’ website: Slack notification example; source:
    Great Expectations documentation](assets/mlin_0604.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![Great Expectations网站的屏幕截图：Slack通知示例；来源：Great Expectations文档](assets/mlin_0604.png)'
- en: 'Figure 6-4\. Screenshot of Great Expectations’ website: Slack notification
    example; source: [Great Expectations documentation](https://oreil.ly/7Nozg).'
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-4\. Great Expectations网站的屏幕截图：Slack通知示例；来源：[Great Expectations文档](https://oreil.ly/7Nozg)。
- en: ML-Related Monitoring Metrics
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与机器学习相关的监控指标
- en: 'Previously, I discussed overall monitoring setups and data monitoring, and
    now I’ll drill down on metrics that measure model performance itself, or the outputs
    and predictions of the models. This is often asked in interviews to determine
    how you would handle model performance changes. Here are some categories of metrics
    to use:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我讨论了整体监控设置和数据监控，现在我将深入介绍衡量模型性能本身或模型的输出和预测的度量标准。这通常是面试中被问及的问题，用以确定您将如何处理模型性能变化。以下是一些可用的度量指标类别：
- en: Accuracy-related metrics
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 准确度相关的度量指标
- en: You can monitor and track accuracy-related metrics, although this might require
    the entire feedback loop to be complete. For example, in a churn-prediction model,
    you might predict that one user will churn during this month’s cycle. After a
    month, you then check if that prediction was indeed correct and do the same across
    all predictions in the month. If your model accuracy is lower than expected, then
    note that as something to investigate.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以监控和跟踪准确性相关的度量指标，尽管这可能需要完整的反馈循环才能完成。例如，在一个流失预测模型中，您可能预测本月的周期内某个用户将会流失。一个月后，您再检查该预测是否正确，并对整月的所有预测执行相同的操作。如果您的模型准确性低于预期，则将其作为需要调查的内容记录下来。
- en: Prediction-related metrics
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 与预测相关的度量指标
- en: In cases where it’s important for the model to react more quickly than you have
    the feedback loop for, you can monitor the prediction metrics as well. For example,
    if the model starts to predict an abnormally high volume of fraud alerts (you
    can determine the threshold beforehand), investigate if anything has changed.
    Since you have data quality checks set up from the previous step, that can be
    a good starting point. In other words, use the output of the models as an alarm
    and troubleshoot it via investigating the inputs or other factors, such as recent
    world events or sales.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型需要比反馈循环更快做出反应的情况下，您还可以监视预测度量指标。例如，如果模型开始预测异常高的欺诈警报（您可以事先确定阈值），请调查是否有任何变化。由于您已经从前一步骤设置了数据质量检查，这可能是一个很好的起点。换句话说，使用模型的输出作为警报，并通过调查输入或其他因素（如最近的世界事件或销售）进行故障排除。
- en: Overview of Cloud Providers
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云供应商概述
- en: In this section, I’ll give an overview of the big three cloud providers. In
    ML interviews, I don’t think it makes a big difference which one you have experience
    with, as long as you have awareness of how they work. As an example, my first
    job used local cloud, but my second job, which primarily used GCP, was fine with
    that experience since it demonstrated that I could work with remote machines.
    My third job used a mix of AWS and GCP and didn’t mind at all that I had only
    used GCP thus far, with small exposure to Azure.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我将概述三大主要云供应商。在机器学习面试中，我认为您拥有哪种云供应商的经验并不重要，只要您了解它们的工作原理即可。例如，我的第一份工作使用本地云，但我的第二份工作主要使用GCP，并且对此经验非常满意，因为它证明了我能够使用远程机器。我的第三份工作同时使用AWS和GCP，并且完全不介意我到目前为止只使用了GCP，并且对Azure的接触很少。
- en: Once you get used to the main components, each big three cloud provider’s functionality
    generally has equivalents. I still often find myself googling something like “GCP
    [terminology] AWS equivalent,” where [terminology] could be something like [service
    accounts](https://oreil.ly/cAi6q) since they are called something else in AWS.
    I later found that they are simply called [IAM roles](https://oreil.ly/f5hTc).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你熟悉了主要组件，每个主要的三大云供应商的功能通常都有对应的功能。我经常发现自己搜索诸如“GCP [术语] AWS 对应物”，其中[术语]可能是像[服务帐户](https://oreil.ly/cAi6q)这样的东西，因为它们在AWS中被称为其他名称。后来我发现它们简单地称为[IAM
    角色](https://oreil.ly/f5hTc)。
- en: Of course, an employer might expect the candidate to come in without much time
    to onboard and get used to a new technology, simple as it is. In those situations,
    the candidate who has experience with the platform that the company uses could
    get priority. I consider those situations to be something out of the candidate’s
    control and knowledge, and you shouldn’t feel too bad if you suspect a case like
    this.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，雇主可能期望候选人在没有太多时间进行培训和适应新技术的情况下就开始工作。在这种情况下，有经验使用公司平台的候选人可能会得到优先考虑。我认为这些情况是候选人无法控制和了解的，如果你怀疑出现了这种情况，也不要感到太难过。
- en: GCP
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GCP
- en: 'GCP (Google Cloud Platform) is Google’s cloud offering. In my experience at
    multiple workplaces that use GCP, it’s pretty easy to use (in my opinion). The
    main tools I’ve seen in a data science/ML workflow are (this is a nonexhaustive
    list):'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: GCP（Google Cloud Platform）是Google的云服务。在我在多个使用GCP的工作场所的经验中，我认为它非常易于使用。我在数据科学/ML工作流中看到的主要工具有（这是一个非详尽列表）：
- en: '[Google Colab](https://oreil.ly/TH4I6)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[Google Colab](https://oreil.ly/TH4I6)'
- en: This is a popular solution for creating, hosting, and sharing Jupyter Notebooks.
    It can be used for R&D, exploratory data analysis, and model training.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这是创建、托管和共享Jupyter Notebooks的流行解决方案。可用于研发、探索性数据分析和模型训练。
- en: '[Google Cloud Storage (GCS)](https://oreil.ly/36cYD) and buckets'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[Google Cloud Storage（GCS）](https://oreil.ly/36cYD)和buckets'
- en: Used to store some inputs and outputs of model training.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 用于存储部分模型训练输入和输出。
- en: '[Google Cloud databases](https://oreil.ly/XKsAe)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[Google Cloud数据库](https://oreil.ly/XKsAe)'
- en: Includes Cloud SQL, BigQuery, Bigtable, Firestore, and so on. These are analytical
    databases, sometimes used as a feature store for batch ML.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 包括Cloud SQL、BigQuery、Bigtable、Firestore等。这些是分析型数据库，有时用作批处理ML的特征存储。
- en: '[Google Kubernetes Engine (GKE)](https://oreil.ly/C4WyB)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[Google Kubernetes Engine（GKE）](https://oreil.ly/C4WyB)'
- en: For larger-scale operations, this tool uses Kubernetes to orchestrate the ML
    deployments like autoscaling when more compute resources are needed.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较大规模的操作，此工具使用Kubernetes来 orchestrate ML 部署，例如在需要更多计算资源时进行自动扩展。
- en: '[Kubeflow on Google Cloud](https://oreil.ly/MU_jW)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[Google Cloud上的Kubeflow](https://oreil.ly/MU_jW)'
- en: You can run tools for model management on GCP, such as Kubeflow, MLflow, and
    so on.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在GCP上运行模型管理工具，如Kubeflow、MLflow等。
- en: '[Vertex AI](https://oreil.ly/YGf0I)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[Vertex AI](https://oreil.ly/YGf0I)'
- en: At the time of writing, this feature is undergoing some updates and changes,
    but its purpose is to be an end-to-end ML solution.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 撰写时，此功能正在进行一些更新和更改，但其目的是成为端到端的ML解决方案。
- en: Of course, depending on the ML company you join, there can be a mix and match
    of tools since, at the end of the day, all these components are simply a means
    to an end. As I said before, you don’t need to know all of them; I’m mentioning
    some of these tools to help you gain general name recognition and get a sense
    of what each tool does.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，根据您加入的ML公司，可能会混合使用不同的工具，因为归根结底，所有这些组件只是达到目标的手段。正如我之前说的，您不需要了解所有这些工具；我提到一些工具是为了帮助您获得一般的名字识别和了解每个工具的功能。
- en: To get started with ML on Google’s tech stack for free, you can use Google Colab’s
    free tier, which is quite good, in my experience. Then, you can use [GCP’s free
    tier](https://oreil.ly/PAhx9), up to certain monthly quotas. Beyond that, there’s
    also a [free trial up to $300 in Cloud Billing credits](https://oreil.ly/wnTr1)
    (available at the time of writing).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Google技术堆栈上免费开始使用ML，您可以使用Google Colab的免费套餐，在我的经验中非常好用。然后，您可以使用[GCP的免费套餐](https://oreil.ly/PAhx9)，在特定的月度配额之内。此外，还有一个[高达300美元的云计费信用的免费试用](https://oreil.ly/wnTr1)（撰写时可用）。
- en: 'Google provides a mix of free and paid ML courses; at the time of writing,
    here is their [foundational courses page](https://oreil.ly/KGEZn) and their [Machine
    Learning Engineer Learning Path](https://oreil.ly/SVQZ2). There’s also the [Google
    Cloud Skills Boost](https://oreil.ly/mkFKt): training services with video lectures
    and hands-on labs to GCP via Qwiklabs.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Google提供了一系列免费和付费的ML课程；撰写时，这是他们的[基础课程页面](https://oreil.ly/KGEZn)和他们的[机器学习工程师学习路径](https://oreil.ly/SVQZ2)。还有[Google
    Cloud技能提升](https://oreil.ly/mkFKt)：提供视频讲座和Qwiklabs的实践实验室培训服务。
- en: AWS
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS
- en: 'Amazon Web Services (AWS) is another very popular cloud platform, owned by
    Amazon. It has a host of ML-related features and services; here is a nonexhaustive
    list:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Web Services（AWS）是另一个非常流行的云平台，由亚马逊拥有。它具有多种与ML相关的功能和服务；以下是一个非详尽列表：
- en: '[Amazon Simple Storage Service (S3)](https://oreil.ly/XaWmX)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[Amazon Simple Storage Service（S3）](https://oreil.ly/XaWmX)'
- en: Storage solution that can be used to store some inputs and outputs of model
    training.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 可用于存储部分模型训练输入和输出的存储解决方案。
- en: '[Amazon Elastic Kubernetes Service (EKS)](https://oreil.ly/kwSLG)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[Amazon Elastic Kubernetes Service（EKS）](https://oreil.ly/kwSLG)'
- en: Fully managed Kubernetes to orchestrate ML deployments like autoscaling when
    more compute resources are needed.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 完全托管的Kubernetes，用于 orchestrate ML 部署，例如在需要更多计算资源时进行自动扩展。
- en: '[Amazon EC2](https://oreil.ly/oNArn)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '[Amazon EC2](https://oreil.ly/oNArn)'
- en: Compute layer on AWS used to provision VMs.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS上用于创建VM的计算层。
- en: '[Amazon SageMaker](https://oreil.ly/i-BAn)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[Amazon SageMaker](https://oreil.ly/i-BAn)'
- en: Managed ML platform, model store, and feature store. It includes [model versioning](https://oreil.ly/Ydcvj),
    [model monitoring dashboards](https://oreil.ly/8YnQA), and more.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 管理的 ML 平台，模型存储和特征存储。其中包括 [模型版本控制](https://oreil.ly/Ydcvj)、[模型监控仪表板](https://oreil.ly/8YnQA)
    等。
- en: To get started for free, use [AWS free tier](https://oreil.ly/Q8OOr) (available
    at the time of writing). AWS has official free lessons to guide you through the
    platform.^([15](ch06.html#ch06fn14)) The [AWS Machine Learning Learning Plan](https://oreil.ly/rinPk)
    is also free (at the time of writing). I recommend getting a quick view via the
    official free courses first, since they are usually shorter, and focusing on what
    the providers themselves consider the most important parts to learn.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 要免费入门，请使用 [AWS 免费层](https://oreil.ly/Q8OOr)（截至撰写本文时）。AWS 有官方免费课程指导您使用平台。^([15](ch06.html#ch06fn14))
    [AWS 机器学习学习计划](https://oreil.ly/rinPk) 也是免费的（截至撰写本文时）。我建议先通过官方的免费课程快速浏览一下，因为它们通常较短，并专注于供应商认为最重要的学习部分。
- en: Microsoft Azure
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Microsoft Azure
- en: 'Here is a nonexhaustive list of ML tools on Azure, Microsoft’s cloud platform:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 Azure 上的机器学习工具的非详尽列表，这是微软的云平台：
- en: '[Azure Blob Storage](https://oreil.ly/b8jnH)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '[Azure Blob 存储](https://oreil.ly/b8jnH)'
- en: Storage solution that can be used to store some inputs and outputs of model
    training
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 可用于存储部分模型训练输入和输出的存储解决方案
- en: '[Azure Virtual Machines](https://oreil.ly/UrntN)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[Azure 虚拟机](https://oreil.ly/UrntN)'
- en: The compute layer on Microsoft Azure
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft Azure 上的计算层
- en: '[Azure Machine Learning](https://oreil.ly/ci02E)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[Azure 机器学习](https://oreil.ly/ci02E)'
- en: End-to-end platform for the ML lifecycle
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习生命周期的端到端平台
- en: To get started, you can use the [free services](https://oreil.ly/48cUE) that
    are available on Azure. Azure has official free lessons on ML training on the
    [Machine Learning for Data Scientists page](https://oreil.ly/LVJ_s).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 Azure 上提供的 [免费服务](https://oreil.ly/48cUE)。Azure 在 [数据科学家的机器学习培训](https://oreil.ly/LVJ_s)
    页面上有官方的免费课程。
- en: Developer Best Practices for Interviews
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面试中的开发者最佳实践
- en: During interviews, it’s useful to see if candidates have experience working
    in a proper software environment. For entry-level candidates, I expect to be coaching
    and mentoring them on the tools they haven’t used before. But I’ve seen a lot
    of people coming out of school who already have used tools like Git and have learned
    the process of getting code reviews in their school assignments or at their co-op
    intern placements, so to be realistic with you, the competition is pretty fierce
    out there. Even at the co-op/intern level, I’ve interviewed and mentored many
    candidates (for example, from the University of Waterloo, my alma mater) who have
    gained full-time-equivalent experience with the general developer tools described
    in this section.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在面试过程中，了解候选人是否具有在正式软件环境中工作的经验非常有用。对于入门级候选人，我期望能够在他们之前未使用过的工具上进行指导和辅导。但我见过很多刚从学校毕业的人，他们已经在学校作业或实习中使用过像
    Git 这样的工具，并学会了进行代码审查的流程，所以说实话，竞争相当激烈。甚至在实习阶段，我曾面试并指导过许多候选人（例如来自我的母校滑铁卢大学），他们在本节描述的通用开发者工具上已经获得了全职等效的经验。
- en: Tip
  id: totrans-211
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: This section is very useful for anyone working in ML, not just those focusing
    on model deployment.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何从事机器学习工作的人来说，这一节都非常有用，不仅仅是那些专注于模型部署的人。
- en: Version Control
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 版本控制
- en: Any job candidate for an ML position should have some experience using version
    control. Most commonly, version control is done with [Git](https://git-scm.com).
    Companies often use online platforms like [GitHub](https://github.com) or [GitLab](https://oreil.ly/coJq7)
    that support Git version control. The goal of version control is to be able to
    track changes to the code, roll back (reset) to a previous version of the code,
    and collaborate easily with other team members. When you’re the only person working
    on the codebase (e.g., on your personal project), you might not see the point
    and instead use copy-paste to back up your code. However, when it comes to any
    larger codebase that two or more people work on, save yourself the headache and
    use version control.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 任何申请机器学习职位的候选人都应该有一些使用版本控制的经验。最常见的版本控制是使用 [Git](https://git-scm.com)。公司通常使用像
    [GitHub](https://github.com) 或 [GitLab](https://oreil.ly/coJq7) 这样支持 Git 版本控制的在线平台。版本控制的目标是能够跟踪代码的变化，回滚（重置）到以前的代码版本，并轻松与团队其他成员合作。当你是唯一在代码库上工作的人（例如在你的个人项目上），你可能看不到它的意义，而是使用复制粘贴来备份你的代码。然而，当涉及到任何两个或更多人共同工作的更大代码库时，请节省自己的头疼时间，使用版本控制。
- en: In my personal view, spending a little time upfront setting up version control
    pays for itself exponentially; without version control, you could waste hundreds
    of hours trying to pass code between multiple people or panicking when the code
    breaks and you can’t recover a past version that works. I’m shuddering thinking
    about it.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在我个人看来，花一点时间来设置版本控制前期投入的回报将是指数级的；没有版本控制，你可能会浪费数百小时尝试在多人之间传递代码，或者在代码出现问题且无法恢复之前有效版本时产生恐慌。一想到这些，我就不寒而栗。
- en: Dependency Management
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 依赖管理
- en: For ML roles that require the candidate to have strong software development
    skills, dependency management could be a topic of discussion during interviews.
    In development, it’s a best practice to use some sort of tool for portability,
    but at a more granular, project level. This could be as simple as having set up
    Python dependency management, such as [Poetry](https://oreil.ly/nyt4A) or [Pipenv](https://oreil.ly/Ev5kg).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要候选人具备强大软件开发技能的机器学习角色，依赖管理可能是面试讨论的一个话题。在开发中，使用某种工具来实现可移植性是最佳实践，但在更细粒度的项目级别上，也是必要的。这可以简单地通过设置Python依赖管理来实现，比如[Poetry](https://oreil.ly/nyt4A)或[Pipenv](https://oreil.ly/Ev5kg)。
- en: The list is nonexhaustive, but it shows that you can keep in mind code portability
    and working together as a team to ship software/ML solutions. Knowing dependency
    management best practices ties in with the section “Docker” earlier in this chapter,
    where it’s useful to show that the candidate can integrate easily into a collaborative
    software development workflow with a team.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 列表并不全面，但它显示了你可以牢记代码的可移植性，并与团队一起合作交付软件/机器学习解决方案。了解依赖管理的最佳实践与本章早期讨论的“Docker”部分相关，显示了候选人可以轻松融入与团队合作的协作软件开发工作流程。
- en: Code Review
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码审查
- en: When you make changes to production code at work, there’s often a review process
    during which other team members can give you feedback. You’ll need to demonstrate
    that the code works as intended and doesn’t break anything; tests are a common
    way to do this.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在工作中对生产代码进行更改时，通常会有一个审查过程，在这个过程中，其他团队成员可以给你反馈。你需要证明代码按预期工作，并且没有出现任何问题；测试是一个常见的方法来做到这一点。
- en: Those who are new to the industry or fresh out of school are less likely to
    have gone through a code-review process. In the interview, this doesn’t matter
    too much, but one thing behavioral interviews can test is whether a candidate
    can take feedback well. This is to prevent friction after the candidate joins
    the team and is part of code review; people who can take constructive feedback
    well and not make it personal will be easier to work with. It’s out of scope for
    this book to talk more about ways to give and take feedback in code review, but
    I hope that you can see why some interview questions are designed to get an insight
    into how you might react in code reviews, a very common part of the ML/software
    workflow. To learn more, a useful starting point is the [“Respectful Changes”
    page](https://oreil.ly/w21h1) from Chromium Docs and the [“How to Write Code Review
    Comments” section](https://oreil.ly/0xQBP) of Google’s [Engineering Practices
    Documentation](https://oreil.ly/bgso7).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 那些刚入行或刚从学校毕业的人可能没有经历过代码审查流程。在面试中，这并不太重要，但行为面试可以测试候选人是否能够接受反馈。这是为了防止候选人加入团队后与代码审查产生摩擦；能够良好接受建设性反馈并不将其个人化的人更容易合作。本书不涵盖更多关于如何在代码审查中给予和接受反馈的方式，但我希望你能理解为什么一些面试问题旨在了解你在代码审查中可能的反应，这是ML/软件工作流程中非常普遍的一部分。要了解更多信息，可以从Chromium文档的[“尊重更改”页面](https://oreil.ly/w21h1)和Google的[“如何撰写代码审查评论”部分](https://oreil.ly/0xQBP)开始。
- en: As a cautionary example, I’ve seen candidates respond noncollaboratively and
    with aggressive defensiveness when probed about a mistake or misunderstanding
    in an interview. Recently, I heard of a candidate who even emailed to further
    criticize the interviewers and insult the company when they couldn’t answer the
    questions well. If a candidate reacts like that to a standardized, well-conducted,
    and professional one-hour interview, then how would they react to a code review?
    How would their coworkers who work day in and day out with that person feel if
    they can’t even handle one hour of interaction? It’s an easy way to not be hired,
    that’s for sure.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个警示的例子，我见过有候选人在面试中对错误或误解作出非协作性和攻击性的反应。最近，我听说过一个候选人在无法很好地回答问题时，甚至发邮件进一步批评面试官并侮辱公司。如果一个候选人对一个标准化、良好进行的、专业的一小时面试都反应如此，那么他们如何对待代码审查呢？如果他们连一小时的互动都不能处理，那么与他们一起工作日复一日的同事会有什么感觉呢？这是一个不被雇佣的简单方式，毫无疑问。
- en: Tests
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试
- en: In many coding teams, it’s a best practice to write tests for code. In Python,
    you can use packages like [pytest](https://oreil.ly/pv2TP) and unittest (PyUnit).
    It doesn’t really matter which one you know; you can see a detailed comparison
    on the Pytest with Eric blog.^([17](ch06.html#ch06fn16))
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多编码团队中，为代码编写测试是一种最佳实践。在Python中，你可以使用像[pytest](https://oreil.ly/pv2TP)和unittest（PyUnit）这样的包。你了解哪一个并不是很重要；你可以在Eric的Pytest博客中看到详细的比较^([17](ch06.html#ch06fn16))。
- en: In many coding interviews, a hidden requirement is that you include tests for
    your code. This could be the case even if it’s not included in the description.
    For example, I’ve had live coding interviews on HackerRank or CoderPad that expected
    tests, but this wasn’t mentioned, and I also had a take-home coding exercise that
    expected the candidate to proactively add tests.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多编码面试中，一个隐藏的要求是你必须为你的代码编写测试。即使在描述中没有包含这一点，也可能是这样。例如，我曾经在HackerRank或CoderPad上进行过现场编码面试，期望有测试，但这并没有在描述中提到，我还有一次回家编码练习，期望候选人主动添加测试。
- en: Tip
  id: totrans-226
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Just to be safe, mention some test cases during your coding interview. The interviewer
    will usually expect you to at least mention it; if it’s out of scope to fully
    code out during the interview, they will let you know. If it’s a take-home exercise,
    I highly recommend writing some tests for it.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保险起见，在编码面试期间提到一些测试用例是很重要的。面试官通常期望你至少提到它；如果在面试过程中无法完全编码出来，他们会告诉你。如果是一项回家作业，我强烈建议你为此编写一些测试。
- en: On the interviewer side, I also expect interviewees either to ask if they should
    add tests or to proactively add them. Some interviewers who follow the same track
    as the software engineer interview track might even expect interviewees to use
    [test-driven development (TDD)](https://oreil.ly/qviBo),^([18](ch06.html#ch06fn17))
    although I’ve found that to be rarer. If the interviewers expect something specific
    such as TDD, then they will mention it in their interview brief.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 从面试官的角度来看，我也希望面试者要么询问是否应该添加测试，要么主动添加它们。一些遵循软件工程师面试路线的面试官甚至可能期望面试者使用[测试驱动开发（TDD）](https://oreil.ly/qviBo)^([18](ch06.html#ch06fn17))，尽管我发现这种情况较少。如果面试官期望特定的东西，比如TDD，那么他们会在面试简报中提到。
- en: 'Here are some resources for reading more about writing tests for ML workflows:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些关于为ML工作流编写测试的资源：
- en: '[“How to Unit Test Deep Learning: Tests in TensorFlow, Mocking and Test Coverage”](https://oreil.ly/PBBge)
    by Sergios Karagiannakos'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“如何对深度学习进行单元测试：TensorFlow中的测试、模拟和测试覆盖率”](https://oreil.ly/PBBge) 作者：Sergios
    Karagiannakos'
- en: '[“Getting Started with Testing in Python”](https://oreil.ly/tfkuh) by Anthony
    Shaw'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“Python测试入门”](https://oreil.ly/tfkuh) 作者：Anthony Shaw'
- en: Additional Technical Interview Components
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他技术面试组成部分
- en: As you saw in [Figure 1-1](ch01.html#overview_of_this_bookapostrophes_chapter),
    there are additional interview types. Usually, they are more advanced components,
    assessing candidates on various combinations of ML, coding, training, and deployment
    (content that has been covered so far in Chapters [3](ch03.html#technical_interviewcolon_machine_learnin),
    [4](ch04.html#technical_interviewcolon_model_training), and [5](ch05.html#technical_interviewcolon_coding)
    and this chapter).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[图1-1](ch01.html#overview_of_this_bookapostrophes_chapter)中看到的，还有其他类型的面试。通常，它们是更高级的组件，评估候选人在ML、编码、训练和部署的各种组合上的能力（迄今为止在第[3](ch03.html#technical_interviewcolon_machine_learnin)、[4](ch04.html#technical_interviewcolon_model_training)和[5](ch05.html#technical_interviewcolon_coding)章中已涵盖的内容）。
- en: 'Additional types that you might commonly hear about are:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能经常听到的其他类型包括：
- en: Machine learning systems design interview
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习系统设计面试
- en: Technical deep-dive interview
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技术深度挖掘面试
- en: Take-home exercises
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回家作业
- en: Product sense
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品感觉
- en: I will briefly go through each of these interview types, so you are aware of
    how to prepare for them. I personally didn’t need to prepare for these types of
    interviews when I was looking for my entry-level role, as ML theory and coding
    were sufficient. However, I have encountered more and more advanced interviews
    as I progressed to senior and staff+ roles. Each company may ask for only some
    of these or none at all, so what you encounter in your interviews will differ.
    For example, Meta asks MLE candidates systems design questions, not just candidates
    at the “senior” level.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我将简要介绍每种面试类型，以便你了解如何为它们做准备。当我寻找我的入门级职位时，我个人并不需要为这些类型的面试做准备，因为机器学习理论和编码就足够了。然而，随着我晋升到高级和高级以上职位，我遇到了越来越多的高级面试。每家公司可能只会要求其中的一些，或者完全不要求，所以你在面试中遇到的情况可能会有所不同。例如，Meta要求MLE候选人进行系统设计问题的答辩，而不仅仅是“高级”级别的候选人。
- en: Machine Learning Systems Design Interview
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习系统设计面试
- en: 'ML systems design interviews and questions ask you to design something in an
    often hypothetical scenario. This could include asking you to design a brand-new
    system from scratch or how you’d hypothetically design a known system. Examples
    include:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ML系统设计面试和问题要求你在通常是假设的情景中设计某事物。这可能包括要求你从头设计一个全新的系统，或者你如何假设地设计一个已知的系统。例如：
- en: “Imagine you are part of an ecommerce company’s ML team. It is aiming to use
    ML to increase customer retention. Walk through your initial approaches and how
    you would accomplish this.”
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “假设你是电子商务公司ML团队的一员。它旨在利用ML提高客户保留率。请详细说明你的初始方法和如何实现这一目标。”
- en: “How would you introduce ML-powered restaurant recommendations on Google Maps?”
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “你如何在Google Maps上引入基于ML的餐厅推荐？”
- en: “The online game our company is developing uses reinforcement learning to improve
    player experience. How would you design such a system?”
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “我们公司正在开发的在线游戏使用强化学习来提升玩家体验。你如何设计这样一个系统？”
- en: 'ML systems design questions are often open ended, with plenty of back-and-forth
    with the interviewer asking follow-up questions that they find interesting. ML
    systems design questions can be quite challenging for a couple of reasons:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ML系统设计问题通常是开放式的，面试官会就他们感兴趣的问题进行反复交流。ML系统设计问题可能会因为以下几个原因而变得相当具有挑战性：
- en: They likely don’t have a 100% correct answer.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 他们可能没有一个100%正确的答案。
- en: Since the questions are often about hypothetical scenarios, the questions themselves
    might also change on the fly. For example, I (as the candidate) might ask the
    interviewer, “How many daily users are we expecting for this ML system?” Given
    the same question, by design the interviewer might not have defined all the parameters
    of the scenario and makes up a plausible number on the spot. Lots of what you
    do during the ML systems design is merely estimation and back-of-the-envelope
    math, and there is often no correct tool to choose (e.g., for some scenarios,
    you could use either XGBoost or CatBoost).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 由于问题通常涉及假设的情景，问题本身也可能会在过程中发生变化。例如，我（作为候选人）可能会问面试官，“我们对这个ML系统预计会有多少日活跃用户？”在相同的问题下，面试官可能并没有定义场景的所有参数，并会即兴提出一个合理的数字。在机器学习系统设计中，你所做的很多事情仅仅是估算和粗略计算，并没有正确的工具可供选择（例如，对于某些情景，你可以使用XGBoost或CatBoost）。
- en: ML systems design questions have high variance between each company, team, and
    interviewer.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 不同公司、团队和面试官之间的ML系统设计问题有很大的变化。
- en: Much of your performance depends not only on your initial design but also on
    how you can respond to open-ended questions that could go in any direction. The
    interviewer could be curious about how you’d deal with the speed of the ML inference,
    and you could spend another five minutes on that topic. Or, by chance, they might
    ask instead about how you’d ensure that data quality is high before training the
    models. Treat it like improv and be able to adjust to how the conversation is
    flowing between you and your interviewer.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 你的表现很大程度上不仅取决于你最初的设计，还取决于你如何应对可能朝任何方向发展的开放式问题。面试官可能会对你如何处理ML推断速度感到好奇，你可能会在这个话题上再花五分钟。或者，碰巧的话，他们可能会问到在训练模型之前如何确保数据质量高。像即兴表演一样处理，并且能够根据你与面试官之间的对话流动进行调整。
- en: Do yourself a favor and check the job posting to see what aspects you should
    focus on. Even in a scenario where the systems design questions ask you to design
    an end-to-end ML project, you can spend more time focusing on the core competencies
    of the position during the job interview. If you’re interviewing for a data scientist
    position that trains and evaluates ML models, then elaborate more on that and
    less on the deployment. Don’t ignore other aspects of the ML system if it’s an
    end-to-end system question, though. If you’re interviewing for an MLE position
    that focuses on deployment, spend a little more time on that instead of getting
    stuck in a rabbit hole about data engineering. If in doubt, ask your interviewer
    if you’re focusing on the right thing and if they’d like to dive deeper on any
    topic.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 务必查看职位发布内容，了解应重点关注的方面。即使在系统设计问题要求你设计端到端ML项目的情况下，你也可以花更多时间专注于职位核心能力。如果你正在应聘数据科学家职位，负责训练和评估ML模型，那就详细阐述这一点，而不要过多涉及部署。不过，如果问题涉及端到端系统，也不要忽视ML系统的其他方面。如果你正在应聘注重部署的MLE职位，花更多时间在此方面，而不要陷入关于数据工程的兔子洞。如有疑问，询问面试官是否专注在正确的方向，并询问是否希望在任何主题上深入讨论。
- en: Depending on the interviewer, they may have different ideas of what kind of
    answer they want. Some interviewers want you to start with talking about the data
    and the specific features available, if they are continuous or categorical, etc.
    Some other interviewers might not focus as much on those details. As an interviewee,
    it’s important to check in with the interviewer about the level of detail they’re
    looking for.
  id: totrans-251
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 根据面试官的不同，他们可能对所需答案有不同的想法。一些面试官希望你从数据和具体特征开始谈起，例如它们是否连续或分类等。其他一些面试官可能不会过多关注这些细节。作为面试者，与面试官确认他们期望的详细程度至关重要。
- en: ''
  id: totrans-252
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Serena McDonnell, Lead Data Scientist, ex-Shopify
  id: totrans-253
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Serena McDonnell，前Shopify首席数据科学家
- en: I won’t provide further examples here, since they would build on and combine
    the information from the ML algorithm, ML evaluation, ML deployment, and coding
    interviews that we’ve already discussed in this book. For entry-level roles, if
    there are systems design questions, they will focus on skills that have been covered
    in the previous chapters. The most advanced systems design questions are mostly
    reserved for more senior and staff+ roles.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里不会提供更多例子，因为它们将建立在并结合我们已经讨论过的ML算法、ML评估、ML部署和编码面试信息的基础上。对于入门级角色，如果存在系统设计问题，它们将专注于在前几章中已涵盖的技能。最高级别的系统设计问题主要保留给更高级别和高级职位。
- en: 'For greater depth on this subject, I recommend the following resources:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 欲深入了解此主题，我推荐以下资源：
- en: '[“ML Systems Design Interview Guide”](https://oreil.ly/QuMZw) by Patrick Halina'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“ML系统设计面试指南”](https://oreil.ly/QuMZw)，Patrick Halina著'
- en: '*Machine Learning System Design Interview* by Ali Aminian and Alex Xu (ByteByteGo)'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习系统设计面试*，Ali Aminian和Alex Xu著（ByteByteGo）'
- en: 'Search YouTube videos on example system design interviews for ML; this is a
    good example: [“Harmful Content Removal: Machine Learning (System Design) Staff
    Level Mentorship”](https://oreil.ly/RsjeE) by Interviewing.io. (This question
    is aimed at the L7 staff position.)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索YouTube视频，了解关于ML系统设计面试的示例；这是一个很好的例子：[“有害内容移除：机器学习（系统设计）高级别导师”](https://oreil.ly/RsjeE)，由Interviewing.io提供。（此问题针对L7级别职位。）
- en: In Meta’s interview prep guide, you’ll see repeated mentions of expecting candidates
    to come up with potential risks and mitigations for the ML designs they propose.
    This is a useful pattern of thinking for all ML interviews and a sign of a more
    effective and thoughtful ML practitioner. A useful and important way to improve
    your discussion of possible risks is to read about AI biases because they are
    a big part of risks. Research from Timnit Gebru and Joy Buolamwini are good resources;
    for example, they investigate [ML algorithms’ accuracy disparities](https://oreil.ly/db8Iq)
    on gender and race (via skin type).^([19](ch06.html#ch06fn18)) Meta’s own blog
    on progress and learnings in AI fairness and transparency also mentions various
    risks and mitigations.^([20](ch06.html#ch06fn19)) Meta’s efforts include creating
    more datasets to “help researchers evaluate their computer vision and audio models
    for accuracy across a diverse set of ages, genders, skin tones, and ambient lighting
    conditions.”
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在Meta的面试准备指南中，你会看到反复提到期望候选人对他们提出的ML设计的潜在风险和缓解方法。这是所有ML面试中思考的有用模式，也是一个更有效和深思熟虑的ML从业者的标志。改善你对可能风险的讨论的一个有用和重要的方法是阅读关于AI偏见的文章，因为它们是风险的重要组成部分。来自Timnit
    Gebru和Joy Buolamwini的研究是良好的资源；例如，他们调查了[ML算法在性别和种族（通过皮肤类型）上的准确性差异](https://oreil.ly/db8Iq)。Meta自己在AI公平和透明度方面的博客中也提到了各种风险和缓解措施。Meta的努力包括创建更多数据集，以“帮助研究人员评估他们的计算机视觉和音频模型在不同年龄、性别、肤色和环境光照条件下的准确性”。
- en: Technical Deep-Dive Interview
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术深度挖掘面试
- en: Technical deep-dive questions allow you to walk through something *you’ve designed
    and built* from scratch in the past, discussing the trade-offs and challenges
    you encountered along the way and how you addressed them. I have frequently seen
    this type of question grouped under behavioral questions that are related to past
    projects; for example, Shopify places a large emphasis on [technical deep dives
    in its technical interview loop](https://oreil.ly/c_F8P).^([21](ch06.html#ch06fn20))
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 技术深度挖掘问题允许你逐步讲解你过去从零开始设计和构建的东西，讨论你遇到的折衷和挑战，以及你是如何解决它们的。我经常看到这种类型的问题被归类为与过去项目相关的行为问题；例如，Shopify在其技术面试环节中非常强调[技术深度挖掘](https://oreil.ly/c_F8P)。
- en: Note
  id: totrans-262
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'There are many companies that do this type of interview, and I’ve heard it
    called many names: case study interviews (different from the consulting type of
    case studies), reverse systems design, retrospective systems design, and whatnot.
    I’m borrowing Shopify’s term, *technical* *deep dive*, to refer to this kind of
    interview and interview questions in this book.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多公司进行这种类型的面试，我听过它被称为许多名字：案例研究面试（与咨询类型的案例研究不同），反向系统设计，回顾性系统设计等等。我借用Shopify的术语*技术深度挖掘*来指代这种类型的面试和本书中的面试问题。
- en: Depending on the interview phase and the interviewer, answering this type of
    question can require more technical explanation and a deeper dive than the usual
    behavioral interview, and it has the depth and volleying that systems design has.
    However, it *differs* from the regular systems design questions with plenty of
    preparation material online since those questions focus on hypothetical situations
    instead of something you actually built in a former job or project. Anecdotally,
    the more senior I get, the more questions I have gotten that are of the technical
    deep-dive variant.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 根据面试阶段和面试官的不同，回答这类问题可能需要比通常的行为面试更深入的技术解释和深度挖掘，具有系统设计的深度和交互。然而，它与通常的系统设计问题有所不同，因为在线上有大量的准备材料，那些问题聚焦于假设情境，而不是你过去的工作或项目中实际构建的东西。个人经历来说，我越来越多地收到类似技术深度挖掘变种的问题。
- en: Take-Home Exercise Tips
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在家练习的技巧
- en: Sometimes, companies will provide an exercise or assessment for the candidate
    to do at home. These might be graded automatically, and a candidate would be passed
    or failed. There are also open-ended take-home exercises where the goal isn’t
    to pass or fail the candidate by the exercise alone but to combine it with an
    interview discussion where the candidate walks the interviewers through their
    solutions.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，公司会为候选人提供一项在家完成的练习或评估。这些可能会自动评分，候选人将被通过或失败。也有开放式的在家练习，其目标不是仅通过练习来判断候选人的通过与否，而是将其与面试讨论结合起来，候选人通过解释其解决方案来进行讨论。
- en: 'The tips for ML algorithms and coding from previous chapters all apply:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 前几章关于ML算法和编码的技巧仍然适用：
- en: Make sure you can not only explain the algorithms but also the trade-offs as
    well as why and how you decided on your approach.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保你不仅能解释算法，还能解释权衡以及为什么和如何决定你的方法。
- en: Explain your thought process clearly to interviewers with docstrings in the
    code as well as verbally during the interviews.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在面试中通过代码中的文档字符串和口头表达清楚你的思维过程。
- en: Write tests!
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写测试！
- en: Product Sense
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 产品感知
- en: In data science and ML interviews, especially in big tech, a hidden requirement
    is that candidates possess some “product sense.” This is an umbrella term some
    companies use to describe whether a job candidate has practical knowledge on how
    ML benefits the company’s products.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学和机器学习面试中，特别是在大型科技公司，一个隐藏的要求是候选人具备一定的“产品感知”。这是一些公司用来描述一个求职者是否具备关于如何使机器学习对公司产品有益的实际知识的统称。
- en: 'This can be shown when speaking about ML products and when you research the
    company’s products. It’s important to understand common product objectives for
    ML, such as:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈论机器学习产品以及研究公司的产品时，可以展示这一点。理解机器学习的常见产品目标非常重要，比如：
- en: Increase user convenience
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高用户便利性
- en: Decrease user churn
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少用户流失率
- en: Improve onboarding experience
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改善入职体验
- en: This is becoming more well-known nowadays; if you look up “data science product
    sense” on a search engine, some guides will show up. However, many candidates
    don’t think about preparing for this unless it’s explicitly mentioned by the recruiter
    or during the hiring process. As an ML candidate, you can integrate product sense
    into your behavioral interviews, systems design interviews, technical deep dives,
    and so on. The way you would prepare is to borrow from product manager interviews.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这种情况越来越为人所知；如果你在搜索引擎上查找“数据科学产品感知”，会显示一些指南。然而，很多候选人除非招聘人员或招聘过程中明确提到，否则不会考虑为此做准备。作为一个机器学习候选人，你可以将产品感知融入到你的行为面试、系统设计面试、技术深入分析等中。你的准备方式是借鉴产品经理面试的方式。
- en: Tip
  id: totrans-278
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: From an interviewer’s perspective, I think of it this way. Does the candidate
    care only about model accuracy metrics, or do they also care about monthly average
    users of the product? Do they connect the ML they’re building to the product?
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 从面试官的角度来看，我这样想。候选人是否只关心模型准确度指标，还是也关心产品的月均活跃用户？他们是否将他们正在构建的机器学习与产品联系起来？
- en: 'Don’t underestimate this—when I was starting out in the ML field, much more
    experienced people and successful peers recommended that I learn more about and
    understand the business side. This is one way that mentorship benefited my career:
    there is a lot of information that’s not shared in question-bank-type interview
    guides. In turn, I have included as much of that latent information as possible
    in this book.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 不要低估这一点——当我刚开始进入机器学习领域时，更有经验的人和成功的同行建议我更多地了解和理解业务方面。这是导师对我的职业生涯有益的一种方式：有许多信息在问题库类型的面试指南中没有被分享。反过来，我在这本书中尽可能包含了尽可能多的潜在信息。
- en: 'Here are some resources to get started:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些入门资源：
- en: '[“The Ultimate Guide to Cracking Product Case Interviews for Data Scientists”
    (Part 1)](https://oreil.ly/E83EC) by Emma Ding'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“数据科学家破解产品案例面试终极指南”（第一部分）](https://oreil.ly/E83EC) 作者 Emma Ding'
- en: Exponent videos on product sense, such as this [“Meta/Facebook Product Manager
    Mock Interview”](https://oreil.ly/pLj8E)
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于产品感知的指数视频，例如这个[“Meta/Facebook 产品经理模拟面试”](https://oreil.ly/pLj8E)
- en: '[*Cracking the PM Interview*](https://oreil.ly/ESol4) by Gayle Laakmann McDowell
    and Jackie Bavaro (CareerCup)'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*破解产品经理面试*](https://oreil.ly/ESol4) 作者 Gayle Laakmann McDowell 和 Jackie Bavaro（CareerCup）'
- en: Sample Interview Questions on MLOps
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps的样例面试问题
- en: Here are some interview questions I’ve used to interview MLOps engineers and
    MLEs who work on infrastructure. These interview questions include sample answers
    to help provide inspiration for your own potential responses. I want to point
    out that these questions mostly hinge on asking about your experience; most likely,
    the MLOps engineer and MLE will share the core coding interview loop ([Chapter 5](ch05.html#technical_interviewcolon_coding))
    with other roles, and then the resume walk-through and technical deep-dive questions
    will include questions such as the ones I’ve given here. As I mentioned in [Chapter 5](ch05.html#technical_interviewcolon_coding),
    those roles that are more focused on operations might also have more specialized
    coding questions that are similar to questions asked of DevOps engineers. At the
    risk of repeating myself too much, it is best that you double-check the job posting
    and with your recruiter and hiring manager, if possible, on the focus and expectations
    of the interview.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列举了一些我用来面试从事基础设施工作的 MLOps 工程师和 MLE 的面试问题。这些面试问题包括示例答案，旨在为你的潜在回答提供灵感。我想指出，这些问题主要是询问你的经验；很可能，MLOps
    工程师和 MLE 会与其他角色分享核心的编码面试循环（[第五章](ch05.html#technical_interviewcolon_coding)），然后简历详细讨论和技术深度挖掘问题中将包括类似我提供的这些问题。如我在[第五章](ch05.html#technical_interviewcolon_coding)中提到的，那些更专注于运营的角色可能也会有更专业的编码问题，类似于对
    DevOps 工程师提出的问题。为了不重复太多，最好你在可能的情况下，仔细检查职位发布和与招聘人员及招聘经理沟通，了解面试的重点和期望。
- en: Note
  id: totrans-287
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: For this chapter, it’s especially important to note that your answers will differ
    depending on your own experience; these answers are only high-level, relatively
    generic examples to show you what an answer might look like. *Do not* use them
    as a real answer in your interviews unless you’ve done the tasks/projects mentioned
    in the example answers.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，特别需要注意的是，你的答案会因个人经验而异；这些答案只是高层次、相对通用的示例，展示了一个答案可能的样子。*请勿*在面试中将其作为真正的答案，除非你已经完成了示例答案中提到的任务/项目。
- en: 'Interview question 6-1: Can you walk through an example where you improved
    the scalability of ML infrastructure?'
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 6-1：你能详细描述一个你如何提升机器学习基础设施可扩展性的例子吗？
- en: Example answer
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: Using scaling on Kubernetes helped; for example, horizontal scaling helped distribute
    the same workload across more instances. In cases when the heavy load came from
    request volume, I used [load balancing](https://oreil.ly/g3E7F) with the Google
    Kubernetes Engine. In the past, I’ve used autoscaling features in cloud platforms,
    such as when I was working with GCP.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 的扩展帮助了；例如，水平扩展有助于将相同的工作负载分布到更多实例中。在请求量大时，我使用[负载平衡](https://oreil.ly/g3E7F)与
    Google Kubernetes Engine。在过去，我在与 GCP 合作时使用过云平台的自动扩展功能。
- en: 'Interview question 6-2: How do you handle the monitoring and performance tracking
    of ML models in production?'
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 6-2：你如何处理生产环境中机器学习模型的监控和性能跟踪？
- en: Example answer
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: For machine learning, I’ve learned that what’s different between monitoring
    an ML application in production as opposed to an application without ML is the
    data and model-related monitoring. This includes monitoring for data drift, model
    accuracy and drifts, and so on. For this, I use tools such as Great Expectations
    or [Alibi Detect](https://oreil.ly/Lk4CR). In particular, at my previous company
    we used Great Expectations to check for sudden large amounts of missing values
    or distribution shifts.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习，我了解到，在生产环境中监控机器学习应用程序与监控非机器学习应用程序之间的不同之处在于数据和与模型相关的监控。这包括数据漂移、模型准确性和漂移等的监控。为此，我使用诸如
    Great Expectations 或 [Alibi Detect](https://oreil.ly/Lk4CR) 的工具。特别是，在我之前的公司，我们使用
    Great Expectations 来检查突然出现的大量缺失值或分布变化。
- en: In addition, using those monitoring tools, I can create alerts and have recurring
    anomaly-detection jobs on those platforms to report errors or drifts. On the service
    availability side (more general, less ML specific), tools such as Grafana, [ELK
    Stack](https://oreil.ly/SwUDT) (Elasticsearch, Logstash, and Kibana, aka Elastic
    Stack), and Prometheus are commonly used.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，使用这些监控工具，我可以创建警报并在这些平台上定期进行异常检测任务，以报告错误或漂移。在服务可用性方面（更一般，不太与 ML 相关），常用的工具如
    Grafana、[ELK Stack](https://oreil.ly/SwUDT)（Elasticsearch、Logstash 和 Kibana，也称为
    Elastic Stack）和 Prometheus。
- en: 'Interview question 6-3: What kind of CI/CD pipeline for ML models have you
    built, and how?'
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 6-3：你曾经构建过什么样的机器学习模型的持续集成/持续交付（CI/CD）流水线，具体是怎么实现的？
- en: Example answer
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: I started by automating the steps involved in the ML pipeline, such as tidying
    up the scripts for data preprocessing, model training, and evaluation. Then I
    integrated those steps into a CI/CD pipeline with [Jenkins](https://oreil.ly/dvtoY),
    triggering a pipeline run when there are changes to the code on our GitHub repo.
    This pipeline includes spinning up the environment, code linting, and testing,
    followed by automatic model deployment to a staging environment for further testing.
    Upon successful validation, the model is copied over to the production environment.
    These steps automated the deployment process, saving on manual deployment time
    and also allowing for quality control.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我首先自动化了 ML 管道中涉及的步骤，如整理数据预处理、模型训练和评估的脚本。然后，我将这些步骤集成到一个 CI/CD 管道中，使用[Jenkins](https://oreil.ly/dvtoY)触发代码库
    GitHub 上的代码更改时运行管道。该管道包括环境搭建、代码检查和测试，随后自动将模型部署到一个用于进一步测试的演示环境。在验证成功后，模型将复制到生产环境。这些步骤自动化了部署过程，节省了手动部署时间，同时也允许质量控制。
- en: Summary
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, I walked through the ML roles who might be interviewed on specialized
    knowledge of their operations and infrastructure experience. Next, I discussed
    some levels and examples of end-to-end machine learning, which differ depending
    on the size and maturity of the data team.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我演示了 ML 角色在其运营和基础设施经验方面可能会接受的面试。接下来，我讨论了端到端机器学习的几个级别和示例，这些因数据团队的规模和成熟度而异。
- en: You also read about different types of cloud environments, trade-offs between
    private and public cloud, and common tools for ML model deployment and orchestration.
    I then discussed some model monitoring setups once the model has been deployed.
    I gave a brief overview of the popular cloud providers, noting that most cloud
    providers have a similar toolkit, and if you use vendors that are not mentioned
    in this book, you’ll likely still find the equivalent services (just named something
    else).
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 你还阅读了不同类型的云环境、私有云和公有云之间的权衡以及 ML 模型部署和编排的常见工具。接着，我讨论了模型部署后的一些监控设置。我简要概述了流行的云服务提供商，指出大多数云提供商都有类似的工具集，如果你使用本书未提及的供应商，可能仍然会找到相应的服务（只是名称可能不同）。
- en: I brought up some developer best practices that are foundational for operations
    and software-heavy roles. Many of these things are naturally learned with work
    experience, but for folks with school or bootcamp experience, you can still demonstrate
    these skills with group projects or open source contributions.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我提出了一些开发者的最佳实践，这些实践对运维和软件开发密集型角色至关重要。很多这些内容会随着工作经验自然而然地学会，但对于有学校或者 bootcamp
    经验的人来说，你仍然可以通过团队项目或开源贡献来展示这些技能。
- en: Finally, I covered additional types of interviews for ML roles, such as systems
    design, technical deep dive, and product sense. In the next chapter, we’ll move
    onto behavioral interviews and how to succeed at them.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我介绍了 ML 角色的其他类型面试，例如系统设计、技术深度挖掘和产品意识。在下一章中，我们将继续讨论行为面试以及如何在面试中取得成功。
- en: ^([1](ch06.html#ch06fn1-marker)) Chip Huyen, “Why Data Scientists Shouldn’t
    Need to Know Kubernetes” (blog), September 13, 2021, [*https://oreil.ly/6c35m*](https://oreil.ly/6c35m).
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch06.html#ch06fn1-marker)) Chip Huyen，《为什么数据科学家不需要了解 Kubernetes》，博客，2021年9月13日，[*https://oreil.ly/6c35m*](https://oreil.ly/6c35m)。
- en: '^([2](ch06.html#ch06fn2-marker)) Eugene Yan, “Unpopular Opinion: Data Scientists
    Should Be More End-to-End” (blog), August 2020, [*https://oreil.ly/iUnlj*](https://oreil.ly/iUnlj).'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch06.html#ch06fn2-marker)) Eugene Yan，《不受欢迎的观点：数据科学家应该更加端到端》，博客，2020年8月，[*https://oreil.ly/iUnlj*](https://oreil.ly/iUnlj)。
- en: ^([3](ch06.html#ch06fn3-marker)) For more on Conway’s law, see “Conway’s Law,”
    Wikipedia, updated October 2, 2023, [*https://oreil.ly/wJIN7*](https://oreil.ly/wJIN7).
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch06.html#ch06fn3-marker)) 想了解更多康威定律的内容，请参考“康威定律”，维基百科，更新时间为2023年10月2日，[*https://oreil.ly/wJIN7*](https://oreil.ly/wJIN7)。
- en: ^([4](ch06.html#ch06fn4-marker)) For this example, you don’t have to know how
    they work either. Later in this chapter, I’ll give an overview of Docker and Kubernetes,
    so don’t worry.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch06.html#ch06fn4-marker)) 对于这个例子，你也不需要知道它们是如何工作的。本章稍后我将概述 Docker 和 Kubernetes，所以不用担心。
- en: ^([5](ch06.html#ch06fn5-marker)) “Selecting the Right Cloud for Workloads—Differences
    Between Public, Private, and Hybrid,” Amazon Web Services, accessed October 24,
    2023, [*https://oreil.ly/KX5FE*](https://oreil.ly/KX5FE).
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch06.html#ch06fn5-marker)) “选择适合工作负载的正确云——公有云、私有云和混合云的区别”，Amazon Web Services，访问时间为2023年10月24日，[*https://oreil.ly/KX5FE*](https://oreil.ly/KX5FE)。
- en: ^([6](ch06.html#ch06fn6-marker)) Tytus Kurek, “What Is Cloud Repatriation?”
    *Ubuntu* (blog), March 17, 2023, [*https://oreil.ly/2qcrO*](https://oreil.ly/2qcrO).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch06.html#ch06fn6-marker)) Tytus Kurek, “什么是云重返？” *Ubuntu* (博客), 2023年3月17日,
    [*https://oreil.ly/2qcrO*](https://oreil.ly/2qcrO).
- en: ^([7](ch06.html#id1749-marker)) The order of least to most complex might depend
    on the exact tech stack and use case, but let’s just use the order in this list
    for the sake of illustration.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch06.html#id1749-marker)) 从技术堆栈和用例的确切情况来看，从最简单到最复杂的顺序可能有所不同，但让我们只按照这个列表的顺序来进行说明。
- en: ^([8](ch06.html#ch06fn7-marker)) “Containerize a Python Environment,” Docker
    Docs, accessed October 24, 2023, [*https://oreil.ly/fwWoP*](https://oreil.ly/fwWoP).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch06.html#ch06fn7-marker)) “将Python环境容器化,” Docker文档, 访问于2023年10月24日, [*https://oreil.ly/fwWoP*](https://oreil.ly/fwWoP).
- en: ^([9](ch06.html#ch06fn8-marker)) “Docker Overview,” Docker Docs, accessed October
    24, 2023, [*https://oreil.ly/JsMan*](https://oreil.ly/JsMan).
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch06.html#ch06fn8-marker)) “Docker概述,” Docker文档, 访问于2023年10月24日, [*https://oreil.ly/JsMan*](https://oreil.ly/JsMan).
- en: ^([10](ch06.html#ch06fn9-marker)) “Policies,” Kubernetes Documentation, updated
    May 29, 2023, [*https://oreil.ly/P37UZ*](https://oreil.ly/P37UZ).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch06.html#ch06fn9-marker)) “政策,” Kubernetes文档, 更新于2023年5月29日, [*https://oreil.ly/P37UZ*](https://oreil.ly/P37UZ).
- en: ^([11](ch06.html#ch06fn10-marker)) Converting source code files into standalone
    software artifact(s), often called a *software build*, or simply a *build*.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch06.html#ch06fn10-marker)) 将源代码文件转换为独立软件工件（通常称为*软件构建*或简称*构建*）。
- en: ^([12](ch06.html#ch06fn11-marker)) “Quantization,” Hugging Face, accessed October
    24, 2023, [*https://oreil.ly/L-RAZ*](https://oreil.ly/L-RAZ).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch06.html#ch06fn11-marker)) “量化,” Hugging Face, 访问于2023年10月24日, [*https://oreil.ly/L-RAZ*](https://oreil.ly/L-RAZ).
- en: ^([13](ch06.html#ch06fn12-marker)) “Announcing Cloud Run, the Newest Member
    of Our Serverless Stack,” *Google Cloud* (blog), April 9, 2019, [*https://oreil.ly/f5hTc*](https://oreil.ly/f5hTc).
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch06.html#ch06fn12-marker)) “宣布Cloud Run，我们无服务器堆栈的最新成员,” *Google Cloud*
    (博客), 2019年4月9日, [*https://oreil.ly/f5hTc*](https://oreil.ly/f5hTc).
- en: ^([14](ch06.html#ch06fn13-marker)) Craig Wiley, “Google Cloud Unveils Vertex
    AI, One Platform, Every ML Tool You Need,” Google Cloud (blog), May 18, 2021,
    [*https://oreil.ly/hfL1h*](https://oreil.ly/hfL1h).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch06.html#ch06fn13-marker)) Craig Wiley, “Google Cloud推出Vertex AI，一站式ML工具平台,”
    Google Cloud (博客), 2021年5月18日, [*https://oreil.ly/hfL1h*](https://oreil.ly/hfL1h).
- en: ^([15](ch06.html#ch06fn14-marker)) For an overview of free and paid courses,
    see “Cloud Roles—Skill Builder,” AWS Training and Certification, accessed October
    24, 2023, [*https://oreil.ly/f9jH-*](https://oreil.ly/f9jH-).
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch06.html#ch06fn14-marker)) 关于免费和付费课程的概述，请参阅“云角色—技能构建者,” AWS培训与认证, 访问于2023年10月24日,
    [*https://oreil.ly/f9jH-*](https://oreil.ly/f9jH-).
- en: ^([16](ch06.html#ch06fn15-marker)) “gittutorial—A Tutorial Introduction to Git,”
    Git, accessed October 24, 2023, [*https://oreil.ly/C7KCS*](https://oreil.ly/C7KCS).
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch06.html#ch06fn15-marker)) “gittutorial—Git的入门教程,” Git, 访问于2023年10月24日,
    [*https://oreil.ly/C7KCS*](https://oreil.ly/C7KCS).
- en: ^([17](ch06.html#ch06fn16-marker)) Eric Sales De Andrade, “Pytest vs Unittest
    (Honest Review of the Two Most Popular Python Testing Frameworks,” Pytest with
    Eric (blog), updated October 24, 2023, [*https://oreil.ly/rYCOR*](https://oreil.ly/rYCOR).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch06.html#ch06fn16-marker)) Eric Sales De Andrade, “Pytest vs Unittest（对两个最流行的Python测试框架的诚实评价）,”
    Pytest with Eric (博客), 更新于2023年10月24日, [*https://oreil.ly/rYCOR*](https://oreil.ly/rYCOR).
- en: ^([18](ch06.html#ch06fn17-marker)) “Test-Driven Development,” Wikipedia, updated
    August 27, 2023, [*https://oreil.ly/i5tPU*](https://oreil.ly/i5tPU).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch06.html#ch06fn17-marker)) “测试驱动开发,” Wikipedia, 更新于2023年8月27日, [*https://oreil.ly/i5tPU*](https://oreil.ly/i5tPU).
- en: '^([19](ch06.html#ch06fn18-marker)) Joy Buolamwini and Timnit Gebru, “Gender
    Shades: Intersectional Accuracy Disparities in Commercial Gender Classification,”
    *Proceedings of the First Conference on Fairness, Accountability and Transparency*
    81 (2018), 77–91, [*https://oreil.ly/spsb7*](https://oreil.ly/MVmNZ).'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch06.html#ch06fn18-marker)) Joy Buolamwini 和 Timnit Gebru, “性别色调：商业性别分类中的交叉准确性差异,”
    *公平性、问责性和透明度第一次会议论文集* 81 (2018), 77–91, [*https://oreil.ly/spsb7*](https://oreil.ly/MVmNZ).
- en: ^([20](ch06.html#ch06fn19-marker)) “Meta’s Progress and Learnings in AI Fairness
    and Transparency,” *Meta* (blog), January 11, 2023, [*https://oreil.ly/AOwku*](https://oreil.ly/AOwku).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](ch06.html#ch06fn19-marker)) “Meta在AI公平性和透明度方面的进展与学习,” *Meta* (博客), 2023年1月11日,
    [*https://oreil.ly/AOwku*](https://oreil.ly/AOwku).
- en: '^([21](ch06.html#ch06fn20-marker)) Ashley Sawatsky, “Shopify’s Technical Interview
    Process: What to Expect and How to Prepare,” *Shopify Engineering* (blog), July
    7, 2022, [*https://oreil.ly/QaUfA*](https://oreil.ly/QaUfA).'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch06.html#ch06fn20-marker)) Ashley Sawatsky，“Shopify的技术面试流程：期望及如何准备”，*Shopify
    Engineering*（博客），2022年7月7日，[*https://oreil.ly/QaUfA*](https://oreil.ly/QaUfA)。
- en: '[*OceanofPDF.com*](https://oceanofpdf.com)'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '[*OceanofPDF.com*](https://oceanofpdf.com)'
