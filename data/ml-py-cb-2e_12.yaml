- en: Chapter 12\. Model Selection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 12 章 模型选择
- en: 12.0 Introduction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12.0 引言
- en: In machine learning, we use training algorithms to learn the parameters of a
    model by minimizing some loss function. However, many learning algorithms (e.g.,
    support vector classifier and random forests) have additional *hyperparameters*
    that are defined by the user and affect how the model will learn its parameters.
    As we mentioned earlier in the book, *parameters* (also sometimes called model
    weights) are what models learn during the training process, whereas hyperparameters
    are provided manually by us (the users).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，我们使用训练算法通过最小化某个损失函数来学习模型的参数。然而，许多学习算法（例如支持向量分类器和随机森林）有额外的 *超参数*，由用户定义，并影响模型学习其参数的方式。正如我们在本书的前面提到的，*参数*（有时也称为模型权重）是模型在训练过程中学习的内容，而超参数是我们手动提供的（用户提供的）内容。
- en: For example, random forests are collections of decision trees (hence the word
    *forest*); however, the number of decision trees in the forest is not learned
    by the algorithm and must be set prior to fitting. This is often referred to as
    *hyperparameter tuning*, *hyperparameter optimization*, or *model selection*.
    Additionally, we might want to try multiple learning algorithms (for example,
    trying both support vector classifier and random forests to see which learning
    method produces the best model).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，随机森林是决策树的集合（因此有 *森林* 一词）；然而，森林中决策树的数量并非由算法学习，而必须在拟合之前设置好。这通常被称为 *超参数调优*、*超参数优化*
    或 *模型选择*。此外，我们可能希望尝试多个学习算法（例如尝试支持向量分类器和随机森林，看哪种学习方法产生最佳模型）。
- en: 'While there is widespread terminology variation in this area, in this book
    we refer to selecting both the best learning algorithm and its best hyperparameters
    as model selection. The reason is straightforward: imagine we have data and want
    to train a support vector classifier with 10 candidate hyperparameter values and
    a random forest classifier with 10 candidate hyperparameter values. The result
    is that we are trying to select the best model from a set of 20 candidate models.
    In this chapter, we will cover techniques to efficiently select the best model
    from the set of candidates.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在这个领域术语广泛变化，但在本书中，我们将选择最佳学习算法及其最佳超参数称为模型选择。原因很简单：想象我们有数据，并且想要训练一个支持向量分类器，有
    10 个候选超参数值，以及一个随机森林分类器，有 10 个候选超参数值。结果是我们尝试从一组 20 个候选模型中选择最佳模型。在本章中，我们将介绍有效地从候选集中选择最佳模型的技术。
- en: Throughout this chapter we will refer to specific hyperparameters, such as C
    (the inverse of regularization strength). Don’t worry if you don’t know what the
    hyperparameters are. We will cover them in later chapters. Instead, just treat
    hyperparameters like the settings for the learning algorithm that we must choose
    before starting training. In general, finding the model and associated hyperparameters
    that yield the best performance is the result of experimentation—trying a bunch
    of things out and seeing what works best.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将提到特定的超参数，比如 C（正则化强度的倒数）。如果你不知道超参数是什么，不要担心。我们将在后面的章节中介绍它们。相反，只需将超参数视为在开始训练之前必须选择的学习算法的设置。通常，找到能够产生最佳性能的模型和相关超参数是实验的结果——尝试各种可能性并找出最佳的那个。
- en: 12.1 Selecting the Best Models Using Exhaustive Search
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12.1 使用穷举搜索选择最佳模型
- en: Problem
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to select the best model by searching over a range of hyperparameters.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你想通过搜索一系列超参数来选择最佳模型。
- en: Solution
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use scikit-learn’s `GridSearchCV`:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 的 `GridSearchCV`：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Discussion
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: '`GridSearchCV` is a brute-force approach to model selection using cross-validation.
    Specifically, a user defines sets of possible values for one or multiple hyperparameters,
    and then `GridSearchCV` trains a model using every value and/or combination of
    values. The model with the best performance score is selected as the best model.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '`GridSearchCV` 是一种使用交叉验证进行模型选择的蛮力方法。具体来说，用户定义一个或多个超参数可能的值集合，然后 `GridSearchCV`
    使用每个值和/或值组合来训练模型。选择具有最佳性能得分的模型作为最佳模型。'
- en: 'For example, in our solution we used logistic regression as our learning algorithm
    and tuned two hyperparameters: C and the regularization penalty. We also specified
    two other parameters, the solver and max iterations. Don’t worry if you don’t
    know what these terms mean; we cover them in the next few chapters. Just realize
    that C and the regularization penalty can take a range of values, which have to
    be specified prior to training. For C, we define 10 possible values:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在我们的解决方案中，我们使用逻辑回归作为我们的学习算法，并调整了两个超参数：C和正则化惩罚。我们还指定了另外两个参数，解算器和最大迭代次数。如果您不知道这些术语的含义也没关系；我们将在接下来的几章中详细讨论它们。只需意识到C和正则化惩罚可以取一系列值，这些值在训练之前必须指定。对于C，我们定义了10个可能的值：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Similarly, we define two possible values for the regularization penalty: `[''l1'',
    ''l2'']`. For each combination of C and regularization penalty values, we train
    the model and evaluate it using k-fold cross-validation. In our solution, we have
    10 possible values of C, 2 possible values of regularization penalty, and 5 folds.
    They create 10 × 2 × 5 = 100 candidate models, from which the best is selected.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们定义了两个正则化惩罚的可能值：`['l1', 'l2']`。对于每个C和正则化惩罚值的组合，我们训练模型并使用k折交叉验证进行评估。在我们的解决方案中，C有10个可能的值，正则化惩罚有2个可能的值，并且使用5折交叉验证。它们创建了10
    × 2 × 5 = 100个候选模型，其中选择最佳模型。
- en: 'Once `GridSearchCV` is complete, we can see the hyperparameters of the best
    model:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成`GridSearchCV`，我们可以看到最佳模型的超参数：
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'By default, after identifying the best hyperparameters, `GridSearchCV` will
    retrain a model using the best hyperparameters on the entire dataset (rather than
    leaving a fold out for cross-validation). We can use this model to predict values
    like any other scikit-learn model:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，确定了最佳超参数后，`GridSearchCV`会在整个数据集上重新训练一个模型（而不是留出一个折用于交叉验证）。我们可以像对待其他scikit-learn模型一样使用该模型来预测值：
- en: '[PRE6]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'One `GridSearchCV` parameter is worth noting: `verbose`. While mostly unnecessary,
    it can be reassuring during long searching processes to receive an indication
    that the search is progressing. The `verbose` parameter determines the number
    of messages outputted during the search, with `0` showing no output, and `1` to
    `3` outputting additional messages.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`GridSearchCV`的一个参数值得注意：`verbose`。虽然大多数情况下不需要，但在长时间搜索过程中，接收到搜索正在进行中的指示可能会让人放心。`verbose`参数确定了搜索过程中输出消息的数量，`0`表示没有输出，而`1`到`3`表示额外的输出消息。'
- en: See Also
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[scikit-learn documentation: GridSearchCV](https://oreil.ly/XlMPG)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[scikit-learn文档：GridSearchCV](https://oreil.ly/XlMPG)'
- en: 12.2 Selecting the Best Models Using Randomized Search
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12.2 使用随机搜索选择最佳模型
- en: Problem
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want a computationally cheaper method than exhaustive search to select the
    best model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望选择最佳模型的计算成本较低的方法。
- en: Solution
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use scikit-learn’s `RandomizedSearchCV`:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用scikit-learn的`RandomizedSearchCV`：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Discussion
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: In [Recipe 12.1](#selecting-best-models-using-exhaustive-search), we used `GridSearchCV`
    on a user-defined set of hyperparameter values to search for the best model according
    to a score function. A more efficient method than `GridSearchCV`’s brute-force
    search is to search over a specific number of random combinations of hyperparameter
    values from user-supplied distributions (e.g., normal, uniform). scikit-learn
    implements this randomized search technique with `RandomizedSearchCV`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Recipe 12.1](#selecting-best-models-using-exhaustive-search)中，我们使用`GridSearchCV`在用户定义的一组超参数值上搜索最佳模型，根据评分函数。比`GridSearchCV`的蛮力搜索更高效的方法是从用户提供的分布（例如正态分布、均匀分布）中随机组合一定数量的超参数值进行搜索。scikit-learn使用`RandomizedSearchCV`实现了这种随机搜索技术。
- en: 'With `RandomizedSearchCV`, if we specify a distribution, scikit-learn will
    randomly sample without replacement hyperparameter values from that distribution.
    As an example of the general concept, here we randomly sample 10 values from a
    uniform distribution ranging from 0 to 4:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`RandomizedSearchCV`，如果我们指定一个分布，scikit-learn将从该分布中随机抽样且不重复地抽取超参数值。例如，这里我们从范围为0到4的均匀分布中随机抽取10个值作为一般概念的示例：
- en: '[PRE10]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Alternatively, if we specify a list of values, such as two regularization penalty
    hyperparameter values `['l1', 'l2']`, `RandomizedSearchCV` will randomly sample
    with replacement from the list.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果我们指定一个值列表，例如两个正则化惩罚超参数值`['l1', 'l2']`，`RandomizedSearchCV`将从列表中进行带替换的随机抽样。
- en: 'Just like with `GridSearchCV`, we can see the hyperparameter values of the
    best model:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 就像`GridSearchCV`一样，我们可以看到最佳模型的超参数值：
- en: '[PRE12]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'And just like with `GridSearchCV`, after the search is complete `RandomizedSearchCV`
    fits a new model using the best hyperparameters on the entire dataset. We can
    use this model like any other in scikit-learn; for example, to make predictions:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 就像使用`GridSearchCV`一样，在完成搜索后，`RandomizedSearchCV`会使用最佳超参数在整个数据集上拟合一个新模型。我们可以像使用
    scikit-learn 中的任何其他模型一样使用这个模型；例如，进行预测：
- en: '[PRE14]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The number of sampled combinations of hyperparameters (i.e., the number of candidate
    models trained) is specified with the `n_iter` (number of iterations) setting.
    It’s worth noting that `RandomizedSearchCV` isn’t inherently faster than `GridSearchCV`,
    but it often achieves comparable performance to `GridSearchCV` in less time just
    by testing fewer combinations.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数组合的采样数量（即训练的候选模型数量）由`n_iter`（迭代次数）设置指定。值得注意的是，`RandomizedSearchCV`并不比`GridSearchCV`更快，但通常在较短时间内通过测试更少的组合来实现与`GridSearchCV`可比较的性能。
- en: See Also
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[scikit-learn documentation: RandomizedSearchCV](https://oreil.ly/rpiSs)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[scikit-learn 文档：RandomizedSearchCV](https://oreil.ly/rpiSs)'
- en: '[Random Search for Hyper-Parameter Optimization](https://oreil.ly/iBcbo)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于超参数优化的随机搜索](https://oreil.ly/iBcbo)'
- en: 12.3 Selecting the Best Models from Multiple Learning Algorithms
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12.3 从多个学习算法中选择最佳模型
- en: Problem
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to select the best model by searching over a range of learning algorithms
    and their respective hyperparameters.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在一系列学习算法及其相应的超参数上进行搜索，您可以选择最佳模型。
- en: Solution
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Create a dictionary of candidate learning algorithms and their hyperparameters
    to use as the search space for `GridSearchCV`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个包含候选学习算法及其超参数的字典，作为`GridSearchCV`的搜索空间：
- en: '[PRE16]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Discussion
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: 'In the previous two recipes, we found the best model by searching over possible
    hyperparameter values of a learning algorithm. However, what if we are not certain
    which learning algorithm to use? scikit-learn allows us to include learning algorithms
    as part of the search space. In our solution we define a search space that includes
    two learning algorithms: logistic regression and random forest classifier. Each
    learning algorithm has its own hyperparameters, and we define their candidate
    values using the format `classifier__[*hyperparameter name*]`. For example, for
    our logistic regression, to define the set of possible values for regularization
    hyperparameter space, `C`, and potential types of regularization penalties, `penalty`,
    we create a dictionary:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两个示例中，我们通过搜索学习算法的可能超参数值来找到最佳模型。但是，如果我们不确定要使用哪种学习算法怎么办？scikit-learn 允许我们将学习算法作为搜索空间的一部分。在我们的解决方案中，我们定义了一个搜索空间，其中包含两个学习算法：逻辑回归和随机森林分类器。每个学习算法都有自己的超参数，并且我们使用`classifier__[*hyperparameter
    name*]`的格式定义其候选值。例如，对于我们的逻辑回归，为了定义可能的正则化超参数空间`C`的可能值集合以及潜在的正则化惩罚类型`penalty`，我们创建一个字典：
- en: '[PRE18]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can also create a similar dictionary for the random forest hyperparameters:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以为随机森林的超参数创建一个类似的字典：
- en: '[PRE19]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After the search is complete, we can use `best_estimator_` to view the best
    model’s learning algorithm and hyperparameters:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 完成搜索后，我们可以使用 `best_estimator_` 查看最佳模型的学习算法和超参数：
- en: '[PRE20]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Just like with the last two recipes, once we have fit the model selection search,
    we can use this best model just like any other scikit-learn model:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 就像前面两个示例一样，一旦我们完成了模型选择搜索，我们就可以像使用任何其他 scikit-learn 模型一样使用这个最佳模型：
- en: '[PRE22]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 12.4 Selecting the Best Models When Preprocessing
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12.4 在预处理时选择最佳模型
- en: Problem
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to include a preprocessing step during model selection.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望在模型选择过程中包含一个预处理步骤。
- en: Solution
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Create a pipeline that includes the preprocessing step and any of its parameters:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '创建一个包含预处理步骤及其任何参数的管道： '
- en: '[PRE24]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Discussion
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Very often we will need to preprocess our data before using it to train a model.
    We have to be careful to properly handle preprocessing when conducting model selection.
    First, `GridSearchCV` uses cross-validation to determine which model has the highest
    performance. However, in cross-validation, we are in effect pretending that the
    fold held out as the test set is not seen, and thus not part of fitting any preprocessing
    steps (e.g., scaling or standardization). For this reason, we cannot preprocess
    the data and then run `GridSearchCV`. Rather, the preprocessing steps must be
    a part of the set of actions taken by `GridSearchCV`.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用数据训练模型之前，我们通常需要对数据进行预处理。在进行模型选择时，我们必须小心处理预处理。首先，`GridSearchCV`使用交叉验证确定哪个模型性能最高。然而，在交叉验证中，我们实际上是在假装保留为测试集的折叠是不可见的，因此不是拟合任何预处理步骤的一部分（例如，缩放或标准化）。因此，我们不能对数据进行预处理然后运行`GridSearchCV`。相反，预处理步骤必须成为`GridSearchCV`采取的操作集的一部分。
- en: 'This might appear complex, but scikit-learn makes it simple. `FeatureUnion`
    allows us to combine multiple preprocessing actions properly. In our solution,
    we use `FeatureUnion` to combine two preprocessing steps: standardize the feature
    values (`StandardScaler`) and principal component analysis (`PCA`). This object
    is called `preprocess` and contains both of our preprocessing steps. We then include
    `preprocess` in a pipeline with our learning algorithm. The result is that this
    allows us to outsource the proper (and confusing) handling of fitting, transforming,
    and training the models with combinations of hyperparameters to scikit-learn.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来很复杂，但scikit-learn让它变得简单。`FeatureUnion`允许我们正确地组合多个预处理操作。在我们的解决方案中，我们使用`FeatureUnion`来组合两个预处理步骤：标准化特征值（`StandardScaler`）和主成分分析（`PCA`）。该对象称为`preprocess`，包含我们的两个预处理步骤。然后，我们将`preprocess`包含在一个管道中与我们的学习算法一起。结果是，这使我们能够将拟合、转换和训练模型与超参数组合的正确（而令人困惑的）处理外包给scikit-learn。
- en: Second, some preprocessing methods have their own parameters, which often have
    to be supplied by the user. For example, dimensionality reduction using PCA requires
    the user to define the number of principal components to use to produce the transformed
    feature set. Ideally, we would choose the number of components that produces a
    model with the greatest performance for some evaluation test metric.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，一些预处理方法有它们自己的参数，通常需要用户提供。例如，使用PCA进行降维需要用户定义要使用的主成分数量，以产生转换后的特征集。理想情况下，我们会选择产生在某个评估测试指标下性能最佳模型的组件数量。
- en: 'Luckily, scikit-learn makes this easy. When we include candidate component
    values in the search space, they are treated like any other hyperparameter to
    be searched over. In our solution, we defined `features__pca__n_components'':
    [1, 2, 3]` in the search space to indicate that we want to discover if one, two,
    or three principal components produce the best model.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '幸运的是，scikit-learn使这变得容易。当我们在搜索空间中包含候选组件值时，它们被视为要搜索的任何其他超参数。在我们的解决方案中，我们在搜索空间中定义了`features__pca__n_components'':
    [1, 2, 3]`，以指示我们要发现一个、两个或三个主成分是否产生最佳模型。'
- en: 'After model selection is complete, we can view the preprocessing values that
    produced the best model. For example, we can see the best number of principal
    components:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型选择完成后，我们可以查看产生最佳模型的预处理值。例如，我们可以查看最佳的主成分数量：
- en: '[PRE26]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 12.5 Speeding Up Model Selection with Parallelization
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12.5 使用并行化加快模型选择速度
- en: Problem
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to speed up model selection.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 需要加快模型选择速度。
- en: Solution
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use all the cores in your machine by setting `n_jobs=-1`, which enables you
    to train multiple models simultaneously:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 通过设置`n_jobs=-1`来利用机器中的所有核心，从而使您能够同时训练多个模型：
- en: '[PRE28]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Discussion
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: In the recipes in this chapter, we have kept the number of candidate models
    small to make the code complete quickly. However, in the real world we may have
    many thousands or tens of thousands of models to train. As a result, it can take
    many hours to find the best model.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的示例中，我们将候选模型的数量保持较少，以使代码迅速完整。但是，在现实世界中，我们可能有成千上万甚至成千上万个模型要训练。因此，找到最佳模型可能需要花费很多小时。
- en: To speed up the process, scikit-learn lets us train multiple models simultaneously.
    Without going into too much technical detail, scikit-learn can simultaneously
    train models up to the number of cores on the machine. Most modern laptops have
    at least four cores, so (assuming you’re currently on a laptop) we can potentially
    train four models at the same time. This will dramatically increase the speed
    of our model selection process. The parameter `n_jobs` defines the number of models
    to train in parallel.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加快这一过程，scikit-learn 允许我们同时训练多个模型。不深入技术细节，scikit-learn 可以同时训练多达机器上的核心数量的模型。现代大多数笔记本电脑至少有四个核心，因此（假设您当前使用的是笔记本电脑），我们可以同时训练四个模型。这将大大增加我们模型选择过程的速度。参数
    `n_jobs` 定义了并行训练的模型数量。
- en: 'In our solution, we set `n_jobs` to `-1`, which tells scikit-learn to use *all*
    cores. However, by default `n_jobs` is set to `1`, meaning it uses only one core.
    To demonstrate this, if we run the same `GridSearchCV` as in the solution, but
    with `n_jobs=1`, we can see it takes significantly longer to find the best model
    (note that exact time will depend on your computer):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的解决方案中，我们将 `n_jobs` 设置为 `-1`，这告诉 scikit-learn 使用 *所有* 核心。然而，默认情况下 `n_jobs`
    被设置为 `1`，这意味着它只使用一个核心。为了演示这一点，如果我们像在解决方案中一样运行相同的 `GridSearchCV`，但使用 `n_jobs=1`，我们可以看到找到最佳模型要花费显著更长的时间（确切时间取决于您的计算机）：
- en: '[PRE30]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 12.6 Speeding Up Model Selection Using Algorithm-Specific Methods
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12.6 使用算法特定方法加速模型选择
- en: Problem
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to speed up model selection without using additional compute power.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要加速模型选择，但不使用额外的计算资源。
- en: Solution
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'If you are using a select number of learning algorithms, use scikit-learn’s
    model-specific cross-validation hyperparameter tuning, `LogisticRegressionCV`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用一些特定的学习算法，请使用 scikit-learn 的模型特定的交叉验证超参数调整，例如 `LogisticRegressionCV`：
- en: '[PRE32]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Discussion
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Sometimes the characteristics of a learning algorithm allow us to search for
    the best hyperparameters significantly faster than either brute-force or randomized
    model search methods. In scikit-learn, many learning algorithms (e.g., ridge,
    lasso, and elastic net regression) have an algorithm-specific cross-validation
    method to take advantage of this. For example, `LogisticRegression` is used to
    conduct a standard logistic regression classifier, while `LogisticRegressionCV`
    implements an efficient cross-validated logistic regression classifier that can
    identify the optimum value of the hyperparameter C.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候学习算法的特性使我们能够比蛮力或随机模型搜索方法显著更快地搜索最佳超参数。在 scikit-learn 中，许多学习算法（例如岭回归、套索回归和弹性网络回归）都有一种特定于算法的交叉验证方法，以利用这一点。例如，`LogisticRegression`
    用于进行标准的逻辑回归分类器，而 `LogisticRegressionCV` 实现了一个高效的交叉验证逻辑回归分类器，可以识别超参数 C 的最佳值。
- en: scikit-learn’s `LogisticRegressionCV` method includes a parameter `Cs`. If supplied
    a list, `Cs` contains the candidate hyperparameter values to select from. If supplied
    an integer, the parameter `Cs` generates a list of that number of candidate values.
    The candidate values are drawn logarithmically from a range between 0.0001 and
    10,0000 (a range of reasonable values for C).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 的 `LogisticRegressionCV` 方法包括参数 `Cs`。如果提供了一个列表，`Cs` 包含要从中选择的候选超参数值。如果提供了一个整数，参数
    `Cs` 将生成该数量的候选值列表。候选值从 0.0001 到 10,0000 的对数范围内抽取（这是 C 的合理值范围）。
- en: However, a major downside to `LogisticRegressionCV` is that it can only search
    a range of values for C. In [Recipe 12.1](#selecting-best-models-using-exhaustive-search)
    our possible hyperparameter space included both C and another hyperparameter (the
    regularization penalty norm). This limitation is common to many of scikit-learn’s
    model-specific cross-validated approaches.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`LogisticRegressionCV` 的一个主要缺点是它只能搜索 C 的一系列值。在 [配方 12.1](#selecting-best-models-using-exhaustive-search)
    中，我们的可能超参数空间包括 C 和另一个超参数（正则化惩罚范数）。这种限制是许多 scikit-learn 模型特定的交叉验证方法的共同特点。
- en: See Also
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[scikit-learn documentation: LogisticRegressionCV](https://oreil.ly/uguJi)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[scikit-learn 文档：LogisticRegressionCV](https://oreil.ly/uguJi)'
- en: '[scikit-learn documentation: Model specific cross-validation](https://oreil.ly/6xfn6)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[scikit-learn 文档：模型特定的交叉验证](https://oreil.ly/6xfn6)'
- en: 12.7 Evaluating Performance After Model Selection
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12.7 在模型选择后评估性能
- en: Problem
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to evaluate the performance of a model found through model selection.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望评估通过模型选择找到的模型的性能。
- en: Solution
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use nested cross-validation to avoid biased evaluation:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 使用嵌套交叉验证以避免偏倚评估：
- en: '[PRE34]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Discussion
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Nested cross-validation during model selection is a difficult concept for many
    people to grasp the first time. Remember that in k-fold cross-validation, we train
    our model on *k–1* folds of the data, use this model to make predictions on the
    remaining fold, and then evaluate our model on how well its predictions compare
    to the true values. We then repeat this process *k* times.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型选择过程中的嵌套交叉验证对许多人来说是一个难以理解的概念。请记住，在 k 折交叉验证中，我们在数据的 *k-1* 折上训练模型，使用该模型对剩余的一折进行预测，然后评估我们的模型预测与真实值的比较。然后我们重复这个过程
    *k* 次。
- en: 'In the model selection searches described in this chapter (i.e., `GridSearchCV`
    and `RandomizedSearchCV`), we used cross-validation to evaluate which hyperparameter
    values produced the best models. However, a nuanced and generally underappreciated
    problem arises: since we used the data to select the best hyperparameter values,
    we cannot use that same data to evaluate the model’s performance. The solution?
    Wrap the cross-validation used for model search in another cross-validation! In
    nested cross-validation, the “inner” cross-validation selects the best model,
    while the “outer” cross-validation provides an unbiased evaluation of the model’s
    performance. In our solution, the inner cross-validation is our `GridSearchCV`
    object, which we then wrap in an outer cross-validation using `cross_val_score`.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章描述的模型选择搜索中（即 `GridSearchCV` 和 `RandomizedSearchCV`），我们使用交叉验证来评估哪些超参数值产生了最佳模型。然而，一个微妙且通常被低估的问题出现了：因为我们使用数据来选择最佳的超参数值，所以我们不能再使用同样的数据来评估模型的性能。解决方案是？将用于模型搜索的交叉验证包装在另一个交叉验证中！在嵌套交叉验证中，“内部”交叉验证选择最佳模型，而“外部”交叉验证提供了模型性能的无偏评估。在我们的解决方案中，内部交叉验证是我们的
    `GridSearchCV` 对象，然后我们使用 `cross_val_score` 将其包装在外部交叉验证中。
- en: 'If you are confused, try a simple experiment. First, set `verbose=1` so we
    can see what is happening:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感到困惑，可以尝试一个简单的实验。首先，设置 `verbose=1`，这样我们可以看到发生了什么：
- en: '[PRE36]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Next, run `gridsearch.fit(features, target)`, which is our inner cross-validation
    used to find the best model:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，运行 `gridsearch.fit(features, target)`，这是我们用来找到最佳模型的内部交叉验证：
- en: '[PRE37]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'From the output you can see the inner cross-validation trained 20 candidate
    models five times, totaling 100 models. Next, nest `clf` inside a new cross-validation,
    which defaults to five folds:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看出，内部交叉验证训练了 20 个候选模型五次，总计 100 个模型。接下来，将 `clf` 嵌套在一个新的交叉验证中，默认为五折：
- en: '[PRE39]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The output shows that the inner cross-validation trained 20 models five times
    to find the best model, and this model was evaluated using an outer five-fold
    cross-validation, creating a total of 500 models trained.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，内部交叉验证训练了 20 个模型五次，以找到最佳模型，然后使用外部五折交叉验证评估了该模型，总共训练了 500 个模型。
