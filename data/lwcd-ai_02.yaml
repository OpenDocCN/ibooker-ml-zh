- en: Chapter 2\. Data Is the First Step
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 数据是第一步
- en: This chapter provides an overview of the use cases and datasets used in the
    book while also providing information on where to find data sources for further
    study and practice. You’ll also learn about data types, and the difference between
    batch and streaming data. You’ll get hands-on practice with data preprocessing
    using Google’s free browser-based open source Jupyter Notebook. The chapter concludes
    with a section on using GitHub to create a data repository for the selected projects
    used in the book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了本书中使用的用例和数据集，并提供了关于在哪里找到数据源进行进一步研究和实践的信息。您还将了解数据类型以及批处理和流处理数据之间的区别。您将通过使用谷歌免费基于浏览器的开源Jupyter
    Notebook进行数据预处理的实际操作。本章最后部分讲述了使用GitHub为本书中使用的选定项目创建数据存储库的方法。
- en: Overview of Use Cases and Datasets Used in the Book
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书用例和数据集概述
- en: Hopefully, you picked up our book to learn ML not from a math-first or algorithm-first
    approach but from a project-based approach. The use cases we’ve chosen are designed
    to teach you ML using actual, real-world data across different sectors. There
    are use cases for healthcare, retail, energy, telecommunications, and finance.
    The use case on customer churn can be applied to any sector. Each of the use case
    projects can stand on its own if you have some data preprocessing experience,
    so feel free to skip ahead to what you need to learn to upskill yourself. [Table 2-1](#list_of_use_cases_by_industry_sector_an)
    shows each section, its use case, sector, and whether it is no-code or low-code.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您能从我们的书中学习机器学习，而不是从数学或算法优先的角度，而是从基于项目的方法。我们选择的用例旨在使用不同部门的实际、真实世界的数据来教授您机器学习。有医疗保健、零售、能源、电信和金融等各种部门的用例。客户流失的用例可以应用于任何部门。如果您具有一些数据预处理经验，每个用例项目都可以独立存在，因此请随时跳到您需要学习以提升技能的内容。[表
    2-1](#list_of_use_cases_by_industry_sector_an) 显示了每个部分、其用例、部门以及是否为无代码或低代码。
- en: Table 2-1\. List of use cases by industry sector and coding type
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-1\. 按行业部门和编码类型列出的用例列表
- en: '| Section | Use case | Sector | Type |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '| 部分 | 用例 | 部门 | 类型 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1 | Product pricing | Retail | N/A |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 产品定价 | 零售 | 不适用 |'
- en: '| 2 | Heart disease | Healthcare | Low-code data preprocessing |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 心脏病 | 医疗保健 | 低代码数据预处理 |'
- en: '| 3 | Marketing campaign | Energy | No-code (AutoML) |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 市场营销活动 | 能源 | 无代码（AutoML） |'
- en: '| 4 | Advertising media channel sales | Insurance | No-code (AutoML) |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 广告媒体渠道销售 | 保险 | 无代码（AutoML） |'
- en: '| 5 | Fraud detection | Financial | No-code (AutoML) |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 欺诈检测 | 金融 | 无代码（AutoML） |'
- en: '| 6 | Power plant production prediction | Energy | Low-code (BigQuery ML) |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 发电厂生产预测 | 能源 | 低代码（BigQuery ML） |'
- en: '| 7 | Customer churn prediction | Telecommunications | Low-code (scikit-learn
    and Keras) |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 客户流失预测 | 电信 | 低代码（scikit-learn 和 Keras） |'
- en: '| 8 | Improve custom model performance | Automotive | Custom-code (scikit-learn,
    Keras, BigQuery ML) |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 提升自定义模型性能 | 汽车 | 自定义代码（scikit-learn、Keras、BigQuery ML） |'
- en: '1\. Retail: Product Pricing'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 零售：产品定价
- en: This section begins with a use case designed to illustrate the role of data
    in decision making. In this use case, you are in charge of marketing for a company
    that makes umbrellas, and the *business goal* is to increase sales. If you reduce
    the selling price of your existing umbrellas, can you predict how many umbrellas
    you will sell? [Figure 2-1](#data_elements_that_impact_a_price_reduc) shows the
    data elements that may impact a price reduction strategy to increase sales.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本节以一个旨在说明数据在决策中的角色的用例开始。在这个用例中，您负责一家生产雨伞的公司的市场营销工作，*业务目标*是增加销量。如果降低现有雨伞的销售价格，您能预测将会销售多少把雨伞吗？[图
    2-1](#data_elements_that_impact_a_price_reduc) 展示了可能影响价格降低策略以增加销售的数据元素。
- en: '![Data elements that impact a price reduction strategy to increase sales](assets/lcai_0201.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![影响价格降低策略以增加销售的数据元素](assets/lcai_0201.png)'
- en: Figure 2-1\. Data elements that impact a price reduction strategy to increase
    sales.
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-1\. 影响价格降低策略以增加销售的数据元素。
- en: '2\. Healthcare: Heart Disease Campaign'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 医疗保健：心脏病宣传
- en: In this one, you are a healthcare consultant and are given data on heart disease
    mortality for populations over the age of 35 in the United States. The goal is
    to analyze the heart disease mortality data and suggest a possible use case in
    a heart disease prevention campaign. For example, one possible use case would
    be to track trends in heart disease mortality over time or to develop and validate
    models for predicting heart disease mortality. This dataset is dirty. Some fields
    have missing values. One field is missing. In working through these issues, you
    learn to import data into a Python Jupyter Notebook, analyze it, and fix dirty
    elements. [Figure 2-2](#data_elements_for_a_heart_disease_morta) shows the data
    elements that contribute to your analysis.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你是一名医疗保健顾问，提供了美国35岁以上人群心脏病死亡率的数据。目标是分析心脏病死亡率数据，并建议在心脏病预防活动中可能的用例。例如，一个可能的用例是跟踪心脏病死亡率随时间的趋势，或者开发和验证预测心脏病死亡率的模型。这些数据集有脏数据。一些字段有缺失值。一个字段缺失。在解决这些问题时，你学会了将数据导入Python
    Jupyter Notebook，分析数据，并修复脏数据元素。[图2-2](#data_elements_for_a_heart_disease_morta)展示了对你的分析有贡献的数据要素。
- en: '![Data elements for a heart disease mortality use case](assets/lcai_0202.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![心脏病死亡率用例的数据要素](assets/lcai_0202.png)'
- en: Figure 2-2\. Data elements for a heart disease mortality use case.
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-2\. 心脏病死亡率用例的数据要素。
- en: '3\. Energy: Utility Campaign'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 能源：公用事业活动
- en: Here, you are a business analyst working for a utility company. You are tasked
    with developing a marketing and outreach program that targets communities with
    high electrical energy consumption. The data has already been preprocessed. You
    do not have an ML background or any programming knowledge. You elect to use AutoML
    as your ML framework. [Figure 2-3](#data_elements_that_contribute_to_the_ut) shows
    the data elements that contribute to your model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你是一名为公用事业公司工作的业务分析师。你的任务是开发一个针对高电能消费社区的营销和宣传计划。数据已经预处理过。你没有ML背景或任何编程知识。你决定使用AutoML作为你的ML框架。[图2-3](#data_elements_that_contribute_to_the_ut)展示了对你的模型有贡献的数据要素。
- en: '![Data elements that contribute to the utility energy campaign](assets/lcai_0203.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![对公用事业能源活动有贡献的数据要素](assets/lcai_0203.png)'
- en: Figure 2-3\. Data elements that contribute to the utility energy campaign.
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-3\. 对公用事业能源活动有贡献的数据要素。
- en: '4\. Insurance: Advertising Media Channel Sales Prediction'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 保险：广告媒体渠道销售预测
- en: In this section, you work on a team charged with developing a media strategy
    for an insurance company. The team wants to develop an ML model to predict sales
    based on advertising spend in various media channels. You are tasked with performing
    exploratory data analysis and with building and training the model. You do not
    have an ML background or any programming knowledge. You elect to use AutoML as
    your ML framework. [Figure 2-4](#data_elements_that_contribute_to_media) shows
    the data elements that contribute to your model.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，你将与一个负责为保险公司制定媒体战略的团队合作。团队希望开发一个基于各种媒体渠道广告支出预测销售的ML模型。你的任务是进行探索性数据分析，并建立和训练模型。你没有ML背景或任何编程知识。你决定使用AutoML作为你的ML框架。[图2-4](#data_elements_that_contribute_to_media)展示了对你的模型有贡献的数据要素。
- en: '![Data elements that contribute to media channel sales prediction](assets/lcai_0204.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![影响媒体渠道销售预测的数据要素](assets/lcai_0204.png)'
- en: Figure 2-4\. Data elements that contribute to media channel sales prediction.
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-4\. 影响媒体渠道销售预测的数据要素。
- en: '5\. Financial: Fraud Detection'
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 金融：欺诈检测
- en: Your goal in this project is to build a model to predict whether a financial
    transaction is fraudulent or legitimate. Your new company is a mobile payment
    service that serves hundreds of thousands of users. Fraudulent transactions are
    fairly rare and are usually caught by other protections. However, the unfortunate
    truth is that some of these are slipping through the cracks and negatively impacting
    your users. The dataset in this section consists of transaction data that has
    been simulated to replicate user behavior and fraudulent transactions. You do
    not have an ML background or any programming knowledge. You elect to use AutoML
    as your ML framework. [Figure 2-5](#data_elements_that_contribute_to_a_frau) shows
    the data elements that contribute to your model.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，您的目标是构建一个模型，预测金融交易是否是欺诈性或合法的。您的新公司是一家移动支付服务，为数十万用户提供服务。欺诈交易相对较少，并且通常会被其他保护措施捕捉到。然而，不幸的事实是，一些欺诈交易会逃过检查，对您的用户造成负面影响。本节中的数据集包含已模拟以复制用户行为和欺诈交易的交易数据。您没有机器学习背景或任何编程知识。您选择使用自动机器学习（AutoML）作为您的机器学习框架。[图 2-5](#data_elements_that_contribute_to_a_frau)
    显示了贡献到您模型的数据元素。
- en: '![Data elements that contribute to a fraud detection model](assets/lcai_0205.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![贡献到欺诈检测模型的数据元素](assets/lcai_0205.png)'
- en: Figure 2-5\. Data elements that contribute to a fraud detection model.
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-5\. 贡献到欺诈检测模型的数据元素。
- en: '6\. Energy: Power Production Prediction'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 能源：电力生产预测
- en: Your goal in this project will be to predict the net hourly electrical energy
    output for a combined cycle power plant (CCPP) given the weather conditions near
    the plant at the time. The dataset in this section contains data points collected
    from a CCPP over a six-year period (2006–2011) when the power plant was set to
    work with a full load. The data is aggregated per hour, though the exact hour
    for the recorded weather conditions and energy production is not supplied in the
    dataset. From a practical viewpoint, this means that you will not be able to treat
    the data as sequence or time-series data, where you use information from previous
    records to predict future records. You have some Structured Query Language (SQL)
    knowledge from working with databases. You elect to use Google’s BigQuery Machine
    Learning as your ML framework. [Figure 2-6](#data_elements_that_contribute_to_the_el)
    shows the data elements that contribute to your model.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，您的目标将是预测一个联合循环发电厂（CCPP）在接近厂区的天气条件下的净每小时电能输出。本节中的数据集包含从2006年到2011年的六年期间（当发电厂设定为全负荷运行时）收集的数据点。数据按小时聚合，尽管数据集中没有提供记录天气条件和能量生产的确切小时。从实际角度来看，这意味着您将无法将数据视为序列或时间序列数据，其中您使用先前记录的信息来预测未来记录。您从与数据库一起使用结构化查询语言（SQL）中获得了一些知识。您选择使用Google的BigQuery机器学习作为您的机器学习框架。[图 2-6](#data_elements_that_contribute_to_the_el)
    显示了贡献到您模型的数据元素。
- en: '![Data elements that contribute to the electrical energy output model](assets/lcai_0206.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![贡献到电力能量输出模型的数据元素](assets/lcai_0206.png)'
- en: Figure 2-6\. Data elements that contribute to the electrical energy output model.
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-6\. 贡献到电力能量输出模型的数据元素。
- en: '7\. Telecommunications: Customer Churn Prediction'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 电信业务：客户流失预测
- en: Your goal in this project will be to predict customer churn for a telecommunications
    company. *Customer churn* is defined as the *attrition rate* for customers, or
    in other words, the rate of customers that choose to stop using services. Telecommunications
    companies often sell their products at a monthly rate or via annual contracts,
    so *churn* here will represent when a customer cancels their subscription or contract
    in the following month. The dataset contains both numeric variables and categorical
    variables, where the variable takes on a value from a discrete set of possibilities.
    You have some Python knowledge and find AutoML very powerful, yet are looking
    to learn low-code solutions that allow you to have a bit more control over your
    model. You elect to use scikit-learn and Keras as ML frameworks. [Figure 2-7](#data_elements_that_contribute_to_the_cu)
    shows the data elements that contribute to your model.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您在这个项目中的目标是预测电信公司的客户流失。*客户流失* 定义为客户的*流失率*，或者换句话说，选择停止使用服务的客户比率。电信公司通常以月租费或年度合同销售其产品，因此在此处的*流失*
    将表示客户在接下来的一个月内取消其订阅或合同。数据集包含数值变量和分类变量，其中变量取自离散可能性集。您具备一些Python知识，并认为AutoML非常强大，但希望学习允许您对模型有更多控制的低代码解决方案。您选择使用scikit-learn和Keras作为ML框架。[图 2-7](#data_elements_that_contribute_to_the_cu)显示了贡献到您模型的数据元素。
- en: '![Data elements that contribute to the customer churn model](assets/lcai_0207.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![贡献到客户流失模型的数据元素](assets/lcai_0207.png)'
- en: Figure 2-7\. Data elements that contribute to the customer churn model.
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-7\. 贡献到客户流失模型的数据元素。
- en: '8\. Automotive: Improve Custom Model Performance'
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 汽车：改进定制模型性能
- en: Your goal in this project (as a newer member of an ML team) will be to improve
    the performance of an ML model trained to predict the auction price of used cars.
    The initial model is a linear regression model in scikit-learn  and does not quite
    meet your business goals. You will ultimately explore using tools in scikit-learn,
    Keras, and BigQuery ML to improve your model performance. The training, validation,
    and testing datasets used for training the linear regression model have been supplied
    to you as CSV files. These datasets have been cleaned (missing and incorrect values
    have been remedied appropriately), and the code that was used to build the scikit-learn
    linear regression model has also been provided. [Figure 2-8](#data_elements_that_contribute_to_the_au)
    shows the data elements that contribute to your model.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中（作为机器学习团队的新成员），您的目标是改进训练用于预测二手车拍卖价格的机器学习模型的性能。初始模型是一个使用scikit-learn进行线性回归的模型，并且并不完全符合您的业务目标。您最终将探索使用scikit-learn、Keras和BigQuery
    ML中的工具来提高模型性能。用于训练线性回归模型的训练、验证和测试数据集已作为CSV文件提供给您。这些数据集已经经过清洗（缺失和不正确的值已经得到适当修复），并且提供了用于构建scikit-learn线性回归模型的代码。[图 2-8](#data_elements_that_contribute_to_the_au)显示了贡献到您模型的数据元素。
- en: '![Data elements that contribute to the automotive pricing model](assets/lcai_0208.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![贡献汽车定价模型的数据元素](assets/lcai_0208.png)'
- en: Figure 2-8\. Data elements that contribute to the automotive pricing model.
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-8\. 贡献到汽车定价模型的数据元素。
- en: Data and File Types
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据和文件类型
- en: Data is really the first step, so let’s go over some basic terminology and concepts
    around data. If you are already familiar with the differences between quantitative
    and qualitative data; between structured, semistructured, and unstructured data;
    and batch and streaming data, then skip to [“An Overview of GitHub and Google’s
    Colab”](#an_overview_of_github_and_googleapostro), where you can start creating
    the Jupyter Notebook in GitHub.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据确实是第一步，所以让我们来了解一些围绕数据的基本术语和概念。如果您已经熟悉定量数据和定性数据之间的区别；结构化、半结构化和非结构化数据之间的区别；以及批处理和流处理数据之间的区别，则跳到[“GitHub和Google
    Colab概述”](#an_overview_of_github_and_googleapostro)，在那里您可以开始在GitHub中创建Jupyter笔记本。
- en: Quantitative and Qualitative Data
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定量和定性数据
- en: 'In data analysis, you work with two types of data: quantitative and qualitative.
    If it can be counted or measured, and given a numerical value, it’s quantitative
    data. Quantitative data can tell you how many, how much, or how often—for example,
    how many people visited the website to view the product catalog? How much revenue
    did the company make this fiscal year? How often do the machines that manufacture
    your umbrella handles break?'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据分析中，你将处理两种类型的数据：定量数据和定性数据。如果可以计数或测量，并给出一个数值，那么它就是定量数据。定量数据可以告诉你多少，多少钱，或者多频繁——例如，有多少人访问网站查看产品目录？公司本财年收入多少？制造伞把的机器多频繁损坏？
- en: Unlike quantitative data, qualitative data cannot be measured or counted and
    can include almost any non-numerical data. It’s descriptive, expressed in terms
    of language rather than numbers. Why is this distinction important in ML? If you
    have qualitative data, then you need to preprocess it so that it *becomes* quantitative—that
    is because you cannot feed qualitative data into an ML model. You will learn how
    to handle some qualitative data in subsequent chapters.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 与定量数据不同，定性数据无法测量或计数，几乎可以包括任何非数字数据。它是描述性的，用语言而不是数字表达。在机器学习中，为什么这种区别很重要？如果你有定性数据，那么你需要预处理它，使其*变成*定量数据——因为你不能将定性数据输入机器学习模型。你将在后续章节学习如何处理一些定性数据。
- en: Structured, Unstructured, and Semistructured Data
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结构化、非结构化和半结构化数据
- en: 'Data can be grouped into three buckets: structured, unstructured, and semistructured.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以分为三大类：结构化数据、非结构化数据和半结构化数据。
- en: '*Structured* data is information that has been formatted and transformed into
    a well-defined data model. A data model is a way of organizing and structuring
    data so that it can be easily understood and manipulated. Data models are used
    in a variety of applications, including databases, software applications, and
    data warehouses. Structured data is well organized. [Table 2-2](#schema_and_field_value_information_fo)
    shows the schema and data type used in [Chapter 4](ch04.html#use_automl_to_predict_advertising_media)’s
    Advertising Media Channel Sales Prediction use case. Note that there is a column
    name and column type. There are four columns of numeric (quantitative) data that
    feed into the AutoML model.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*结构化*数据是已格式化并转换为明确定义的数据模型的信息。数据模型是一种组织和结构化数据的方式，使其易于理解和操作。数据模型应用广泛，包括数据库、软件应用程序和数据仓库。结构化数据组织有序。[表2-2](#schema_and_field_value_information_fo)显示了在[第4章](ch04.html#use_automl_to_predict_advertising_media)的广告媒体频道销售预测用例中使用的模式和数据类型。请注意，这里有列名和列类型。有四列数字（定量）数据，供AutoML模型使用。'
- en: Table 2-2\. Schema and field value information for the advertising dataset from
    [Chapter 4](ch04.html#use_automl_to_predict_advertising_media)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表2-2。广告数据集的模式和字段值信息，来自[第4章](ch04.html#use_automl_to_predict_advertising_media)
- en: '| Column name | Column type | Notes about field values |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 列名 | 列类型 | 关于字段值的注释 |'
- en: '| --- | --- | --- |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Digital | Numeric | Budget of advertisements in digital |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 数字 | 数字 | 数字 |'
- en: '| Newspaper | Numeric | Budget of advertisements in newspaper |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 报纸 | 数字 | 广告预算 |'
- en: '| Radio | Numeric | Budget of advertisements in radio |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 无线电 | 数字 | 广告预算 |'
- en: '| TV | Numeric | Budget of advertisements in TV |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 电视 | 数字 | 广告预算 |'
- en: 'Here are some examples of structured data:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些结构化数据的例子：
- en: Customer records
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户记录
- en: Product inventory
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品库存
- en: Financial data
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 财务数据
- en: Transaction logs
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交易日志
- en: Website analytics data
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网站分析数据
- en: Log files
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志文件
- en: '*Unstructured* data is data that is not structured or tabular or formatted
    in a specific way. Here are some examples of unstructured data:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*非结构化*数据是没有结构化或表格化或特定格式的数据。以下是一些非结构化数据的例子：'
- en: Social media posts
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交媒体帖子
- en: Chats (text)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天记录（文本）
- en: Videos
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频
- en: Photos
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 照片
- en: Web pages
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网页
- en: Audio files
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频文件
- en: '*Semistructured* data is a type of structured data that lies between structured
    and unstructured data. It doesn’t have a tabular data model but can include tags
    and semantic markers for records and fields in a dataset. Semistructured data
    is, essentially, a combination of structured and unstructured. Videos may contain
    meta tags that relate to the date or location, but the information within has
    no structure.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*半结构化*数据是介于结构化和非结构化数据之间的一种类型的结构化数据。它没有表格化的数据模型，但可以包含数据集中记录和字段的标签和语义标记。半结构化数据实质上是结构化和非结构化数据的组合。视频可能包含与日期或位置相关的元标签，但内部信息没有结构。'
- en: 'Here are some examples of semistructured data:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些半结构化数据的例子：
- en: CSV, XML, JSON files
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CSV，XML，JSON 文件
- en: HTML
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTML
- en: Email (Emails are considered semistructured data because they have some structure,
    but not as much as structured data. Emails typically contain a header, a body,
    and attachments. The header contains information about the sender, recipient,
    and date of the message. The body of the message contains the text of the message.)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电子邮件（电子邮件被视为半结构化数据，因为它们有一定的结构，但不如结构化数据那么多。电子邮件通常包含标题，正文和附件。标题包含有关发件人，收件人和消息日期的信息。消息正文包含消息的文本。）
- en: '[Figure 2-9](#unstructuredcomma_semistructuredcomma_a) compares unstructured,
    semistructured, and structured data.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-9](#unstructuredcomma_semistructuredcomma_a) 比较了非结构化、半结构化和结构化数据。'
- en: '![Unstructured, semistructured, and structured data examples](assets/lcai_0209.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![非结构化、半结构化和结构化数据示例](assets/lcai_0209.png)'
- en: Figure 2-9\. Unstructured, semistructured, and structured data examples.
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-9\. 非结构化、半结构化和结构化数据示例。
- en: Data File Types
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据文件类型
- en: You just learned about the different types of data, and several file types were
    mentioned. There are many different types of data file formats, each with its
    own purpose. [Table 2-3](#common_data_file_types) shows some of the most common
    data file types.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 刚刚您了解了不同类型的数据，提到了几种文件类型。有许多不同类型的数据文件格式，每种都有其特定的用途。[表 2-3](#common_data_file_types)
    展示了一些最常见的数据文件类型。
- en: Table 2-3\. Common data file types
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-3\. 常见数据文件类型
- en: '| Common data file types | Common file extensions |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 常见数据文件类型 | 常见文件扩展名 |'
- en: '| --- | --- |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Text files are files that contain plain text. They are typically used to
    store documents, such as letters, reports, and code. | Some common text file extensions
    include .txt, .csv, .tsv, .log, and .json. |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 文本文件是包含纯文本的文件。它们通常用于存储文档，如信件，报告和代码。 | 一些常见的文本文件扩展名包括 .txt，.csv，.tsv，.log
    和 .json。 |'
- en: '| Spreadsheet files are files that contain data in a tabular format. They are
    typically used to store financial data, sales data, and other tabular data. |
    Some common spreadsheet file extensions include .xls, .xlsx, and .csv. |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 电子表格文件是以表格格式存储数据的文件。它们通常用于存储财务数据，销售数据和其他表格数据。 | 一些常见的电子表格文件扩展名包括 .xls，.xlsx
    和 .csv。 |'
- en: '| Image files are files that contain images. They are typically used to store
    photos, graphics, and other visual content. | Some common image file extensions
    include .jpg, .png, and .gif. |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 图像文件是包含图像的文件。它们通常用于存储照片，图形和其他视觉内容。 | 一些常见的图像文件扩展名包括 .jpg，.png 和 .gif。 |'
- en: '| Audio files are files that contain audio recordings. They are typically used
    to store music, podcasts, and other audio content. | Some common audio file extensions
    include .mp3, .wav, and .ogg. |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 音频文件是包含音频录音的文件。它们通常用于存储音乐，播客和其他音频内容。 | 一些常见的音频文件扩展名包括 .mp3，.wav 和 .ogg。 |'
- en: '| Video files are files that contain video recordings. They are typically used
    to store movies, TV shows, and other video content. | Some common video file extensions
    include .mp4, .avi, and .mov. |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 视频文件是包含视频录制的文件。它们通常用于存储电影，电视节目和其他视频内容。 | 一些常见的视频文件扩展名包括 .mp4，.avi 和 .mov。
    |'
- en: '| Webpage files are files that contain webpages. They are typically used to
    store HTML code, CSS code, and JavaScript code. | Some common webpage file extensions
    include .html, .htm, and .php. |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 网页文件是包含网页的文件。它们通常用于存储 HTML 代码，CSS 代码和 JavaScript 代码。 | 一些常见的网页文件扩展名包括 .html，.htm
    和 .php。 |'
- en: How Data Is Processed
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据的处理方式
- en: 'There are two main modes of how data is processed: batch processing and real-time
    processing. Batch processing is a mode of data processing where data is collected
    over a period of time and then processed at a later time. This is a common mode
    of data processing for large datasets, as it can be more efficient to process
    the data in batches than to process it in real time. Real-time processing is a
    mode of data processing where data is processed as soon as it is collected. This
    is a common mode of data processing for applications where the data needs to be
    processed quickly, such as fraud detection or stock trading.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理有两种主要模式：批处理和实时处理。批处理是一种数据处理模式，其中数据在一段时间内收集，然后在稍后处理。这是处理大型数据集的常见模式，因为批量处理数据比实时处理效率更高。实时处理是一种数据处理模式，数据在收集后立即处理。这是一种常见的数据处理模式，适用于需要快速处理数据的应用，如欺诈检测或股票交易。
- en: The frequency of how data is processed can also vary. Continuous processing
    is a mode of data processing where data is processed continuously, as it is collected.
    This is a common mode of data processing for applications where the data needs
    to be processed in real time. Periodic processing is a mode of data processing
    where data is processed at regular intervals. This is a common mode of data processing
    for applications where the data does not need to be processed in real time, such
    as financial reporting.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理的频率也可能不同。连续处理是一种数据处理模式，数据在收集时连续处理。这是处理数据需要实时处理的应用程序常见模式。周期性处理是一种数据处理模式，数据在规则间隔内处理。这是处理数据不需要实时性的应用程序常见模式，如财务报告。
- en: The mode and frequency of how data is processed depends on the specific needs
    of the application. For example, an application that needs to process large datasets
    may use batch processing, while an application that needs to process data in real
    time may use real-time processing. [Table 2-4](#summary_of_the_different_modes_and_freq)
    summarizes the different modes and frequencies of data processing.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理的模式和频率取决于应用程序的具体需求。例如，需要处理大数据集的应用程序可能会使用批处理，而需要实时处理数据的应用程序可能会使用实时处理。[表 2-4](#summary_of_the_different_modes_and_freq)
    总结了数据处理的不同模式和频率。
- en: Table 2-4\. Summary of the different modes and frequencies of data processing
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-4\. 不同数据处理模式和频率的总结
- en: '| Mode | Frequency | Description |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 模式 | 频率 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Batch processing | Intermittent | Data is collected over a period of time
    and then processed at a later time. |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 批处理 | 间歇性 | 数据在一段时间内收集，然后在稍后处理。 |'
- en: '| Real-time processing | Continuous | Data is processed as soon as it is collected.
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 实时处理 | 持续 | 数据在收集后立即处理。 |'
- en: '| Periodic processing | Intermittent | Data is processed at regular intervals.
    |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 周期性处理 | 间歇性 | 数据定期处理。 |'
- en: Batch data and streaming data are two different types of data that are processed
    differently.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理数据和流数据是两种不同类型的数据，它们被不同方式处理。
- en: '*Batch* data is data that is collected over a period of time and then processed
    at a later time.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*批处理* 数据是一种在一段时间内收集，然后在稍后处理的数据。'
- en: '*Streaming* data is data that is processed as it is received.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*流数据* 是一种在接收时立即处理的数据。'
- en: Batch data requires data to be collected in batches before it can be processed,
    stored, analyzed, and fed into an ML model.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理数据要求在处理、存储、分析并喂入机器学习模型之前收集数据成批处理。
- en: Streaming data flows in continuously and can be processed, stored, analyzed,
    and acted on as soon as it is generated. Streaming data can come from a wide variety
    of distributed sources in many different formats. Simply stated, streaming data
    is data that is generated continuously and in real time. This type of data can
    be used to train ML models that can make predictions in real time. For example,
    a streaming data model could be used to detect fraud or predict customer churn.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 数据流是持续不断地流入，可以立即处理、存储、分析和实时操作。流数据可以来自多种不同格式的分布式源头。简而言之，流数据是连续生成并且实时的数据。这种类型的数据可以用来训练能够实时进行预测的机器学习模型。例如，流数据模型可以用于检测欺诈或预测客户流失。
- en: An Overview of GitHub and Google’s Colab
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GitHub 和 Google 的 Colab 概述
- en: This section talks about how to set up a Jupyter Notebook and GitHub project
    repository. The GitHub repository can hold your datasets and the low-code project
    notebooks you create—such as the Jupyter Notebooks mentioned in this book.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讲述如何设置 Jupyter Notebook 和 GitHub 项目仓库。GitHub 仓库可以存放你的数据集和低代码项目笔记本，比如本书提到的
    Jupyter 笔记本。
- en: Use GitHub to Create a Data Repository for Your Projects
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 GitHub 创建数据仓库来管理你的项目
- en: GitHub is a code repository where you store your Jupyter notebooks and experimental
    raw data for free. Let’s get started!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub 是一个代码仓库，你可以免费存储你的 Jupyter 笔记本和实验原始数据。让我们开始吧！
- en: 1\. Sign up for a new GitHub account
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 注册一个新的 GitHub 账户
- en: GitHub offers personal accounts for individuals and organizations. When you
    create a personal account, it serves as your identity on *[GitHub.com](http://github.com)*.
    When you create a personal account, you must select a billing plan for the account.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub 提供个人账户和组织账户。创建个人账户时，它作为你在 *[GitHub.com](http://github.com)* 上的身份。创建个人账户时，必须为账户选择一个计费计划。
- en: 2\. Set up your project’s GitHub repo
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 设置你的项目 GitHub 仓库
- en: To set up your first GitHub repo, see the full steps in the “Use GitHub to Create
    a Data Repository for Your Projects” page in Chapter 2 of the book’s [GitHub repo](https://oreil.ly/supp-lcai).
    You can also refer to [GitHub documentation](https://oreil.ly/1iJ-w) on how to
    create a repo.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置您的第一个 GitHub 存储库，请查看书中第 2 章“使用 GitHub 创建项目数据存储库”页面的完整步骤，位于[GitHub 存储库](https://oreil.ly/supp-lcai)。您还可以参考[GitHub
    文档](https://oreil.ly/1iJ-w)了解如何创建存储库。
- en: Type a short, memorable name for your repository; for example, low-code book
    projects. A description is optional, but in this exercise, enter **Low-code AI
    book projects**. Choose a repository visibility—in this case, the default is Public,
    which means anyone on the internet can see this repository. [Figure 2-10](#create_a_new_repository_page)
    shows what your setup should look like.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为您的存储库键入一个简短且易记的名称；例如，低代码书籍项目。描述是可选的，但在此练习中，请输入**低代码 AI 书籍项目**。选择存储库可见性——在这种情况下，默认为
    Public，这意味着任何人都可以在互联网上看到此存储库。[图 2-10](#create_a_new_repository_page)展示了您的设置应该是什么样子。
- en: '![Create a new repository page](assets/lcai_0210.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![创建新存储库页面](assets/lcai_0210.png)'
- en: Figure 2-10\. Create a new repository page.
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-10\. 创建新存储库页面。
- en: 'Have GitHub create a *README.md* file. This is where you can write a long description
    for your project. Keep the other defaults: `.gitignore` lets you choose which
    files not to track, and a license tells others what they can and can’t do with
    your code. Lastly, GitHub reminds you that you are creating a public repository
    in your personal account. When done, click “Create repository.” [Figure 2-11](#initialize_the_repo_settings)
    shows what the page should look like.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让 GitHub 创建一个 *README.md* 文件。这是您可以为项目撰写长描述的地方。保留其他默认设置：`.gitignore` 允许您选择不要跟踪的文件，许可证告诉其他人可以做什么以及不能做什么。最后，GitHub
    提醒您正在创建一个公共存储库，该存储库位于您的个人帐户中。完成后，单击“创建存储库”。[图 2-11](#initialize_the_repo_settings)展示了页面的样子。
- en: '![Initialize the repo settings](assets/lcai_0211.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![初始化存储库设置](assets/lcai_0211.png)'
- en: Figure 2-11\. Initialize the repo settings.
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-11\. 初始化存储库设置。
- en: After clicking “Create repository,” the repo page appears, as shown in [Figure 2-12](#your_github_repo_page).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 单击“创建存储库”后，将显示存储库页面，如[图 2-12](#your_github_repo_page)所示。
- en: '![Your GitHub repo page](assets/lcai_0212.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![您的 GitHub 存储库页面](assets/lcai_0212.png)'
- en: Figure 2-12\. Your GitHub repo page.
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-12\. 您的 GitHub 存储库页面。
- en: Note
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'In the next section, you will create a Jupyter Notebook in Google’s Colaboratory.
    You will save the notebook file from Colab into GitHub, which will create a file
    under the *Main* branch. Creating a file in GitHub is a great way to improve collaboration
    on a project. It provides a number of features that can help teams work more effectively
    together:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将在 Google 的 Colaboratory 中创建一个 Jupyter Notebook。您将从 Colab 中保存笔记本文件到 GitHub，这将在
    *Main* 分支下创建一个文件。在 GitHub 中创建文件是改进项目协作的好方法。它提供了许多功能，可以帮助团队更有效地协同工作：
- en: Version control
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 版本控制
- en: GitHub tracks changes to files. This means that everyone who has access to the
    file can see the changes that have been made, and they can revert to a previous
    version if necessary.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub 跟踪文件的更改。这意味着所有有权访问文件的人都可以看到已经进行的更改，并且可以在必要时返回到以前的版本。
- en: Pull requests
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 拉取请求
- en: Pull requests allow collaborators to propose changes to a file. This gives everyone
    a chance to review the changes before they are merged into the main branch.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 拉取请求允许协作者提出对文件的更改。这使每个人都有机会审查更改，然后将其合并到主分支中。
- en: Issues
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 问题
- en: Issues can be used to track bugs or feature requests. This allows everyone to
    collaborate on solving problems and adding new features.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用问题来跟踪错误或功能请求。这样每个人都可以合作解决问题并添加新功能。
- en: Comments
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 评论
- en: Comments can be added to files to provide feedback or ask questions. This allows
    for a more collaborative way of working on code.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 可以向文件添加评论以提供反馈或提问。这种方式可以更加协作地处理代码。
- en: Using Google’s Colaboratory for Low-Code AI Projects
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Google 的 Colaboratory 进行低代码 AI 项目
- en: Years ago, if you wanted to learn Python, you had to download the Python interpreter
    and install it on your computer. This could be a daunting task for beginners,
    as it required knowledge of how to install software and configure your computer.
    Today, there are many ways to learn Python without having to install anything
    on your computer. You can use online IDEs (integrated development environments)
    that allow you to write and run Python code in a web browser. You can also use
    cloud-based Python environments that provide you with access to a Python interpreter
    and all the libraries you need to get started.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 多年前，如果你想学习Python，你必须下载Python解释器并在计算机上安装。对于初学者来说，这可能是一项艰巨的任务，因为它需要了解如何安装软件和配置计算机。如今，有许多学习Python的方法，而无需在计算机上安装任何东西。你可以使用在线集成开发环境（IDE），它允许你在网页浏览器中编写和运行Python代码。你还可以使用基于云的Python环境，提供Python解释器和你开始所需的所有库的访问权限。
- en: 'These online and cloud-based resources make it easier than ever to learn Python,
    regardless of your level of experience or technical expertise. Here are some of
    the benefits of using online and cloud-based resources to learn Python:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这些在线和基于云的资源使得无论你的经验或技术水平如何，学习Python都比以往更容易。以下是使用在线和基于云的资源学习Python的一些好处：
- en: No installation required
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 无需安装
- en: You can start learning Python right away, without having to download or install
    any software.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以立即开始学习Python，无需下载或安装任何软件。
- en: Access from anywhere
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 可从任何地方访问
- en: You can use online and cloud-based resources to learn Python from anywhere,
    as long as you have an internet connection.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 只要有互联网连接，你就可以在任何地方使用在线和基于云的资源学习Python。
- en: Affordable
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 费用低廉
- en: Online and cloud-based resources are often free or very affordable.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在线和基于云的资源通常是免费的或价格非常实惠的。
- en: Easy to use
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 易于使用
- en: Online and cloud-based resources are designed to be easy to use, even for beginners.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 即使对于初学者，在线和基于云的资源也设计得易于使用。
- en: You build your low-code Python Jupyter Notebook using Google’s Colaboratory,
    or Colab. Colab is a hosted Jupyter Notebook service that requires no setup to
    use, while providing access to computing resources, including graphical processing
    units (GPUs). Colab runs in your web browser and allows you to write and execute
    Python code. Colab notebooks are stored in Google Drive and can be shared similarly
    to how you share Google Docs or Sheets.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Google的Colaboratory构建你的低代码Python Jupyter Notebook，或者简称Colab。Colab是一个托管的Jupyter
    Notebook服务，无需设置即可使用，同时提供访问计算资源，包括图形处理单元（GPU）。Colab在你的Web浏览器中运行，允许你编写和执行Python代码。Colab笔记本存储在Google
    Drive中，并可以像分享Google文档或表格一样分享。
- en: Google Colaboratory is free to use, and there is no need to sign up for any
    accounts or pay for any subscriptions. You can share your notebooks with others
    and work on projects together.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Google Colaboratory免费使用，无需注册任何帐户或支付订阅费用。你可以与他人分享你的笔记本并共同完成项目。
- en: 1\. Create a Colaboratory Python Jupyter Notebook
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 创建Colaboratory Python Jupyter笔记本
- en: Go to [Colab](https://colab.research.google.com) to create a new Python Jupyter
    notebook. [Figure 2-13](#google_colab_home_page) shows the home screen.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 前往[Colab](https://colab.research.google.com)创建一个新的Python Jupyter笔记本。[图 2-13](#google_colab_home_page)显示了主屏幕。
- en: '![Google Colab home page](assets/lcai_0213.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![Google Colab首页](assets/lcai_0213.png)'
- en: Figure 2-13\. Google Colab home page.
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-13\. Google Colab主页。
- en: Title the notebook in the title bar as shown in [Figure 2-14](#title_notebook_and_add_a_new_cell_code)
    (A) and expand to show the table of contents (B). Then click the + Code button
    (C) to add a cell to hold your code. The + Text button allows you to add text,
    such as documentation.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在标题栏中为笔记本命名，如[图 2-14](#title_notebook_and_add_a_new_cell_code)（A）所示，并展开显示目录（B）。然后点击+
    Code按钮（C）添加一个用于存放代码的单元格。+ Text按钮允许你添加文本，如文档。
- en: '![Title notebook and add a new cell code](assets/lcai_0214.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![标题笔记本和添加新单元格代码](assets/lcai_0214.png)'
- en: Figure 2-14\. Title notebook and add a new cell code.
  id: totrans-156
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-14\. 标题笔记本和添加新单元格代码。
- en: 2\. Import libraries and dataset using Pandas
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 使用Pandas导入库和数据集
- en: Once you have added the code cell, you need to import any libraries you will
    need. In this simple example, you’ll just import Pandas. Type **`import pandas
    as pd`** into the cell and run it by clicking the arrow, as shown in [Figure 2-15](#code_to_import_pandas).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 添加了代码单元格后，你需要导入所需的任何库。在这个简单的例子中，你只需在单元格中输入**`import pandas as pd`**并点击箭头运行，如[图 2-15](#code_to_import_pandas)所示。
- en: '![Code to import Pandas](assets/lcai_0215.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![导入Pandas的代码](assets/lcai_0215.png)'
- en: Figure 2-15\. Code to import Pandas.
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-15\. 导入Pandas的代码。
- en: The Pandas library is used for data analysis. Typically, when you import a library,
    you want to provide a way to use it without having to write out the words *Pandas*
    each time. Thus, the *pd* is a short-hand name (or alias) for Pandas. This alias
    is generally used by convention to shorten the module and submodule names.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 库用于数据分析。通常，当你导入一个库时，你希望能够在不每次都写出 *Pandas* 的情况下使用它。因此，*pd* 是 Pandas 的一个缩写名称（或别名）。这种别名通常按照惯例用于缩短模块和子模块的名称。
- en: The dataset is from the *[data.gov](http://data.gov)* website. It is entitled
    [“Heart Disease Mortality Data Among US Adults”](https://oreil.ly/yq1hY) ([Figure 2-16](#heart_disease_mortality_data_among_us_a)).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集来自 *[data.gov](http://data.gov)* 网站。它名为 [“美国成年人心脏病死亡数据”](https://oreil.ly/yq1hY)（参见
    [图 2-16](#heart_disease_mortality_data_among_us_a)）。
- en: '![Heart disease mortality data among US adults by region](assets/lcai_0216.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![美国成年人心脏病死亡数据按地区](assets/lcai_0216.png)'
- en: Figure 2-16\. Heart disease mortality data among US adults by region.
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-16\. 美国成年人心脏病死亡数据按地区。
- en: Scroll down the page until you get to the section shown in [Figure 2-17](#downloads_and_resources_page).
    Now, there are two ways you can import the file into your Jupyter Notebook. You
    can download the file to your desktop and then import it, or you can use the URL.
    Let’s use the URL method. Click on the Comma Separated Values File shown in [Figure 2-17](#downloads_and_resources_page),
    which takes you to the URL download shown in [Figure 2-18](#comma_separated_values_file_url_link).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动页面直到到达 [图 2-17](#downloads_and_resources_page) 所示的部分。现在，有两种方法可以将文件导入到你的 Jupyter
    Notebook 中。你可以将文件下载到你的桌面，然后导入它，或者你可以使用 URL。让我们使用 URL 方法。点击 [图 2-17](#downloads_and_resources_page)
    中显示的逗号分隔值文件，该文件将带你到 URL 下载链接，如 [图 2-18](#comma_separated_values_file_url_link)
    所示。
- en: '![Downloads and resources page](assets/lcai_0217.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![下载和资源页面](assets/lcai_0217.png)'
- en: Figure 2-17\. Downloads and resources page.
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-17\. 下载和资源页面。
- en: '![Comma separated values file URL link](assets/lcai_0218.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![逗号分隔值文件 URL 链接](assets/lcai_0218.png)'
- en: Figure 2-18\. Comma separated values file URL link.
  id: totrans-169
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-18\. 逗号分隔值文件 URL 链接。
- en: Copy the URL shown in [Figure 2-18](#comma_separated_values_file_url_link) from
    the website. Then, go to your Google Colab notebook and type in the code shown
    in [Figure 2-19](#code_to_read_the_url_into_a_pandas_data) into a new cell (A).
    Run the cell by clicking the arrow (B).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 从网站上复制 [图 2-18](#comma_separated_values_file_url_link) 中显示的 URL。然后，转到你的 Google
    Colab 笔记本，并在新的单元格（A）中输入 [图 2-19](#code_to_read_the_url_into_a_pandas_data) 中显示的代码。通过点击箭头（B）运行单元格。
- en: '![Code to read the URL into a Pandas DataFrame](assets/lcai_0219.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![读取 URL 到 Pandas DataFrame 的代码](assets/lcai_0219.png)'
- en: Figure 2-19\. Code to read the URL into a Pandas DataFrame.
  id: totrans-172
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-19\. 读取 URL 到 Pandas DataFrame 的代码。
- en: You have written code to import the dataset into a Pandas DataFrame. A Pandas
    DataFrame is a two-dimensional data structure that is used to store data in a
    table format. It is similar to a spreadsheet.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经编写了导入数据集到 Pandas DataFrame 的代码。Pandas DataFrame 是一个用于以表格格式存储数据的二维数据结构。它类似于电子表格。
- en: Now you add code to show the first five rows (or *head*) of the DataFrame. Add
    a new cell, type **`heart_df.head()`** into the cell, and run the cell. The code
    and output are shown in [Figure 2-20](#first_five_rows_of_the_dataframe).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，添加代码显示 DataFrame 的前五行（或 *head*）。添加一个新的单元格，输入 **`heart_df.head()`** 并运行单元格。代码和输出如
    [图 2-20](#first_five_rows_of_the_dataframe) 所示。
- en: '![First five rows of the DataFrame](assets/lcai_0220.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![DataFrame 的前五行](assets/lcai_0220.png)'
- en: Figure 2-20\. First five rows of the DataFrame. Some columns were removed for
    the sake of readability.
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-20\. DataFrame 的前五行。为了便于阅读，某些列已被移除。
- en: Add a new code cell. Type **`heart_df.info()`** and run the cell to see information
    on the DataFrame. The `.info()` method gives you information on your dataset.
    The information contains the number of columns, column labels, column data types,
    memory usage, range index, and the number of cells in each column (non-null values).
    [Figure 2-21](#dataframe_information_output) shows the output. Exact values may
    differ depending on when data is downloaded.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一个新的代码单元格。输入 **`heart_df.info()`** 并运行单元格以查看 DataFrame 的信息。`.info()` 方法为你提供了数据集的信息。信息包括列数、列标签、列数据类型、内存使用情况、范围索引以及每列（非空值）的单元格数。
    [图 2-21](#dataframe_information_output) 显示了输出。具体数值可能因数据下载时期而异。
- en: '![DataFrame information output](assets/lcai_0221.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![DataFrame 信息输出](assets/lcai_0221.png)'
- en: Figure 2-21\. DataFrame information output.
  id: totrans-179
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-21\. DataFrame 信息输出。
- en: From what the `.info()` output shows, you have 15 string object columns (which
    is qualitative data) and 4 numeric columns (quantitative data). Think of `int64`
    as a number without a decimal (for example, 25) and `float64` as a number with
    a decimal (25.5).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 `.info()` 输出显示，你有15列字符串对象（即定性数据）和4列数值列（即定量数据）。将 `int64` 视为没有小数的数字（例如，25），将
    `float64` 视为有小数的数字（例如，25.5）。
- en: 3\. Data validation
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 数据验证
- en: As a best practice, validate any data you import from a URL—especially if you
    have a CSV file format to compare it with. If the dataset page had listed more
    metadata about the data, such as the number of columns and the column names, you
    could have avoided the steps to follow. But alas, it is the nature of working
    with data!
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最佳实践，验证从 URL 导入的任何数据——特别是如果你有一个 CSV 文件格式可以进行比较。如果数据集页面列出了有关数据的更多元数据，例如列数和列名，你可能可以避免后续步骤。但遗憾的是，这是与数据工作的本质！
- en: Now, return to the *[data.gov](http://data.gov)* page and download the CSV file
    to your computer. You are going to validate that the file you have downloaded
    matches the file you imported from the URL.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，返回 *[data.gov](http://data.gov)* 页面并下载 CSV 文件到你的计算机。你将验证所下载的文件与从 URL 导入的文件是否匹配。
- en: You do this by uploading the downloaded file to your Colab notebook and then
    reading that file into a Pandas DataFrame. Expand the table of contents in your
    [Chapter 2](#data_is_the_first_step) notebook by selecting the folder shown in
    [Figure 2-22](#upload_file_to_your_colab_notebook) (A). Then, to upload a file,
    select the up arrow folder (B).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过将下载的文件上传到你的 Colab 笔记本，然后将该文件读入 Pandas DataFrame 中来完成此操作。通过选择 [章节2](#data_is_the_first_step)
    笔记本中显示的文件夹来展开目录，你的屏幕应该显示如 [图2-22](#upload_file_to_your_colab_notebook)（A）所示。然后，要上传文件，请选择向上箭头文件夹（B）。
- en: '![Upload file to your Colab notebook](assets/lcai_0222.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![将文件上传到你的Colab笔记本](assets/lcai_0222.png)'
- en: Figure 2-22\. Upload file to your Colab notebook.
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-22\. 将文件上传到你的Colab笔记本。
- en: As you upload the file, you will see the warning message shown in [Figure 2-23](#warning_message_that_any_uploaded_files).
    This warning basically states that any file you upload will not be saved if the
    runtime is terminated (which can happen if you close out of Colab). Note that
    runtime provides the program with the environment it needs to run.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当你上传文件时，你会看到如 [图2-23](#warning_message_that_any_uploaded_files) 所示的警告消息。该警告基本上指出，如果运行时终止（例如关闭
    Colab），则不会保存你上传的任何文件。请注意，运行时为程序提供其运行所需的环境。
- en: '![Warning message that any uploaded files are not permanently saved](assets/lcai_0223.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![警告消息指出任何上传的文件都不会被永久保存](assets/lcai_0223.png)'
- en: Figure 2-23\. Warning message that any uploaded files are not permanently saved.
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-23\. 警告消息指出任何上传的文件都不会被永久保存。
- en: Refresh your notebook browser tab after the upload and expand it to see the
    table of contents. Your screen should look as shown in [Figure 2-24](#table_of_contents_that_shows_uploaded_f).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 上传后刷新你的笔记本浏览器选项卡并展开以查看目录。你的屏幕应该显示如 [图2-24](#table_of_contents_that_shows_uploaded_f)
    所示。
- en: '![Table of contents that shows uploaded file](assets/lcai_0224.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![显示已上传文件的目录](assets/lcai_0224.png)'
- en: Figure 2-24\. Table of contents that shows uploaded file.
  id: totrans-192
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-24\. 显示已上传文件的目录。
- en: Note how long the filename is—go ahead and rename it by right-clicking on the
    file and renaming it *heart.csv*. Your screen should look as shown in [Figure 2-25](#select_quotation_markrename_filequotati).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 注意文件名有多长——右键单击文件并将其重命名为 *heart.csv*。你的屏幕应该显示如 [图2-25](#select_quotation_markrename_filequotati)
    所示。
- en: '![Select “Rename file” option](assets/lcai_0225.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![选择“重命名文件”选项](assets/lcai_0225.png)'
- en: Figure 2-25\. Select “Rename file” option.
  id: totrans-195
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-25\. 选择“重命名文件”选项。
- en: Your screen should look as shown in [Figure 2-26](#file_renamed_to_heartdotcsv)
    after renaming the file.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在重命名文件后，你的屏幕应该显示如 [图2-26](#file_renamed_to_heartdotcsv) 所示。
- en: '![File renamed to heart.csv](assets/lcai_0226.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![文件重命名为 heart.csv](assets/lcai_0226.png)'
- en: Figure 2-26\. File renamed to heart.csv.
  id: totrans-198
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-26\. 文件重命名为 heart.csv。
- en: So, you’ve renamed your file to *heart.csv*. Now you need to copy the path of
    the file, as shown in [Figure 2-27](#copying_the_path_of_the_file). Why? You will
    need the exact location to input as a parameter in the Pandas `read.csv` method.
    Right-click on the *heart.csv* file to get the path.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你已经将文件重命名为 *heart.csv*。现在你需要复制文件路径，如 [图2-27](#copying_the_path_of_the_file)
    所示。为什么？因为你将需要将该路径作为 Pandas `read.csv` 方法的参数输入。右键单击 *heart.csv* 文件以获取路径。
- en: '![Copying the path of the file](assets/lcai_0227.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![复制文件路径](assets/lcai_0227.png)'
- en: Figure 2-27\. Copying the path of the file.
  id: totrans-201
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-27\. 复制文件路径。
- en: 'Add a code cell and type in the following code. Make sure to paste the path
    to the file between the two single quote marks around */content/heart.csv*. Run
    the cell and review the output:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一个代码单元，并输入以下代码。确保在*/content/heart.csv*两个单引号之间粘贴文件路径。运行单元并查看输出：
- en: '[PRE0]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Type **`heart_df.info()`** into a new cell. Run the cell to see DataFrame information.
    Compare the total columns from Figures [2-21](#dataframe_information_output) to
    [2-28](#year_column_showing_as_numeric_or_intsi). [Figure 2-21](#dataframe_information_output)
    has 19 columns and [Figure 2-28](#year_column_showing_as_numeric_or_intsi) has
    20 columns. This means that by uploading the file, a Year column was added. The
    `Year` datatype is not a numeric value—it has numbers, but those numbers are meant
    to rank and order, not calculate on. [Figure 2-28](#year_column_showing_as_numeric_or_intsi)
    indicates you have your first case of dirty data for our machine learning use
    case.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新的单元格中输入**`heart_df.info()`**。运行单元以查看 DataFrame 信息。将 Figures [2-21](#dataframe_information_output)
    和 [2-28](#year_column_showing_as_numeric_or_intsi) 的总列数进行比较。[Figure 2-21](#dataframe_information_output)
    有 19 列，而 [Figure 2-28](#year_column_showing_as_numeric_or_intsi) 有 20 列。这意味着通过上传文件，添加了一个年份列。`Year`
    数据类型不是数值类型——它包含数字，但这些数字是用来排序和排列的，并非用于计算。[Figure 2-28](#year_column_showing_as_numeric_or_intsi)
    表明，这是我们机器学习用例的第一个脏数据案例。
- en: '![Year column showing as numeric or int64](assets/lcai_0228.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![年份列显示为数字或 int64](assets/lcai_0228.png)'
- en: Figure 2-28\. Year column showing as `int64`.
  id: totrans-206
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 2-28\. 年份列显示为 `int64`。
- en: Type **`heart_df.isnull().sum()`** into a new cell as shown in [Figure 2-29](#isnull_output_showing_some_columns_with).
    Run the cell. Are there any null values? A *null value* is a value that indicates
    the absence of a value. You have your second case of dirty data! Three of your
    columns have null values. You will learn how to deal with missing values in a
    subsequent chapter. Since you really don’t have a use case yet, you may be wondering
    whether you really need all of these features. Note that features are the input
    data that is used to train a model. The model then uses the features to make predictions.
    You’ll learn about feature selection in a subsequent chapter.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在新的单元格中输入**`heart_df.isnull().sum()`**，如 [Figure 2-29](#isnull_output_showing_some_columns_with)
    所示。运行该单元格。是否有任何空值？*空值* 是指表示值不存在的值。这是你的第二个脏数据案例！你的三列存在空值。在后续章节中，你将学习如何处理缺失值。由于目前你还没有使用案例，你可能会想知道你是否真的需要所有这些特征。请注意，特征是用于训练模型的输入数据。然后模型使用这些特征进行预测。在后续章节中，你将学习特征选择。
- en: '![IsNull output showing some columns with null values](assets/lcai_0229.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![IsNull 输出显示部分列存在空值](assets/lcai_0229.png)'
- en: Figure 2-29\. `IsNull` output showing the number of null cells in the three
    columns with null values.
  id: totrans-209
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 2-29\. `IsNull` 输出显示了三列中空值的数量。
- en: What are your data quality issues?
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 你的数据质量问题是什么？
- en: Missing values
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值
- en: Most algorithms do not accept missing values. Therefore, when we see missing
    values in our dataset, there may be a tendency to just “drop all the rows” with
    missing values. However, there are various ways you can deal with missing values,
    as explained in the following note.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数算法不接受缺失值。因此，当我们在数据集中看到缺失值时，可能倾向于只是“删除所有具有缺失值的行”。然而，你可以用不同的方式处理缺失值，如下文所述。
- en: Note
  id: totrans-213
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'There are two main approaches to handling missing values in a dataset in ML:
    deletion or imputation.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ML 数据集中处理缺失值有两种主要方法：删除或插补。
- en: '*Deletion* involves removing the rows or columns with missing values from the
    dataset. This can be done by dropping all rows with missing values, dropping all
    columns with missing values, or dropping rows or columns with a certain threshold
    of missing values.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '*删除* 涉及从数据集中删除具有缺失值的行或列。可以通过删除所有具有缺失值的行、删除所有具有缺失值的列或删除具有一定缺失值阈值的行或列来完成此操作。'
- en: '*Imputation* involves filling in the missing values with estimates. There are
    many different imputation techniques, including (1) mean imputation, which replaces
    missing values with the mean of the observed values for that variable; (2) median
    imputation, which replaces missing values with the median of the observed values
    for that variable; (3) mode imputation, which replaces missing values with the
    most frequent value of the variable; and (4) regression imputation, which uses
    a regression model to predict the missing values based on the observed values
    of other variables.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '*插补* 涉及用估计值填充缺失值。有许多不同的插补技术，包括 (1) 均值插补，用该变量观察值的均值替换缺失值；(2) 中位数插补，用该变量观察值的中位数替换缺失值；(3)
    众数插补，用该变量的最频繁值替换缺失值；以及 (4) 回归插补，使用回归模型根据其他变量的观察值预测缺失值。'
- en: Although Pandas will fill in the blank space with *NaN (not a number)*, we should
    handle them in some way. More on that later in the book.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Pandas 会用 *NaN (不是一个数字)* 填补空白处，我们应该以某种方式处理它们。书中稍后将详细介绍。
- en: Data type incorrect
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 数据类型不正确
- en: '`Year` is shown as an `int64` data type and should be a string object—where
    you would need to handle it as a qualitative, categorical feature.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '`Year` 显示为 `int64` 数据类型，应为字符串对象——您需要将其处理为定性分类特征。'
- en: Categorical columns
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 分类列
- en: There are quite a number of string object features—which are not numeric. You
    cannot feed values like this into an ML model. These features need to be *one-hot
    encoded*. You’ll see this in a subsequent chapter.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 有相当多的字符串对象特征——这些特征不是数值型的。您不能将此类值馈送到 ML 模型中。这些特征需要进行 *one-hot 编码*。您将在后续章节中看到这一点。
- en: 4\. A little bit of exploratory data analysis
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 一些探索性数据分析
- en: Before concluding this section, let’s look at some simple ways to explore the
    data. Want to see all of the unique values in the feature `Stratification2`? Type
    **`heart_df.Stratification2.unique()`** into a new cell as shown in [Figure 2-30](#code_to_show_unique_values_of_column_st).
    Run the cell.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束本节之前，让我们看看探索数据的一些简单方法。想看到特征 `Stratification2` 中的所有唯一值吗？请在新的单元格中输入 **`heart_df.Stratification2.unique()`**，如
    [图2-30](#code_to_show_unique_values_of_column_st) 所示。运行该单元格。
- en: '![Code to show unique values of column Stratification2](assets/lcai_0230.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![显示列 Stratification2 的唯一值的代码](assets/lcai_0230.png)'
- en: Figure 2-30\. Code to show unique values of column `Stratification2`.
  id: totrans-225
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-30\. 显示列 `Stratification2` 的唯一值的代码。
- en: Let’s use Seaborn’s violin plot to visualize this feature. Seaborn is a Python
    library for making statistical graphics. You can write all of this in the same
    cell, as shown in [Figure 2-31](#violin_plot_of_stratificationtwo_column). This
    code uses the `Data_Value` feature as the *x* and the `Stratification2` as the
    *y*. Note that the `Data_Value` feature is the count of heart disease in each
    region and by group, as shown in [Figure 2-32](#distribution_plot_of_heart_disease_coun).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 Seaborn 的小提琴图来可视化这个特征。Seaborn 是一个用于制作统计图形的 Python 库。您可以在同一个单元格中编写所有内容，如
    [图2-31](#violin_plot_of_stratificationtwo_column) 所示。此代码使用 `Data_Value` 特征作为 *x*
    轴，`Stratification2` 作为 *y* 轴。请注意，`Data_Value` 特征是每个地区和组中心脏病的计数，如 [图2-32](#distribution_plot_of_heart_disease_coun)
    所示。
- en: '![Violin plot of Stratification2 column](assets/lcai_0231.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![Stratification2 列的小提琴图](assets/lcai_0231.png)'
- en: Figure 2-31\. Violin plot of `Stratification2` column.
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-31\. `Stratification2` 列的小提琴图。
- en: The “long tails” indicate there are more outliers in the data for that particular
    feature. The large shape of the violin body indicates how many heart disease cases
    are distributed by race.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: “长尾”表明该特定特征的数据中存在更多的异常值。小提琴图主体的大形状显示了按种族分布的心脏病病例数量。
- en: '![Distribution plot of heart disease count](assets/lcai_0232.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![心脏病计数分布图](assets/lcai_0232.png)'
- en: Figure 2-32\. Distribution plot of heart disease count.
  id: totrans-231
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-32\. 心脏病计数分布图。
- en: Note
  id: totrans-232
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Seaborn’s violin plot is a good way to visualize the distribution of a univariate
    set of data.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: Seaborn 的小提琴图是可视化单变量数据分布的一种好方法。
- en: It is used to visualize the distribution of numerical data. Unlike a box plot
    that can only show summary statistics, violin plots depict summary statistics
    and the density of each variable.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 用于可视化数值数据分布。与只能显示摘要统计信息的箱线图不同，小提琴图描绘了每个变量的摘要统计信息和密度。
- en: In later chapters, you’ll perform more data analysis and learn data preprocessing.
    For now, save your notebook to GitHub. On the Colab menu, click File > Save a
    copy in GitHub, as shown in [Figure 2-33](#how_to_save_a_file_copy_of_the_notebook).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在后续章节中，您将进行更多的数据分析，并学习数据预处理。现在，将您的笔记本保存到GitHub。在Colab菜单中，点击“文件” > “在GitHub中保存副本”，如[图 2-33](#how_to_save_a_file_copy_of_the_notebook)所示。
- en: '![How to save a file copy of the notebook in GitHub](assets/lcai_0233.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![如何在GitHub中保存笔记本文件副本](assets/lcai_0233.png)'
- en: Figure 2-33\. How to save a file copy of the notebook in GitHub.
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-33\. 如何在GitHub中保存笔记本文件副本。
- en: '[Figure 2-34](#colabapostrophes_github_export_window) shows the setup. From
    the drop-down under Repository, select the repo to save your notebook to. Under
    Branch, select Notebooks (you created this earlier). Keep the default “Include
    a link to Colaboratory.” This will show a link in GitHub that allows you to open
    your notebook directly from GitHub.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-34](#colabapostrophes_github_export_window)显示了设置。从“存储库”下拉菜单中选择要将笔记本保存到的存储库。在“分支”下选择“笔记本”（您之前创建了这个）。保持默认的“包括指向Colaboratory的链接”。这将在GitHub上显示一个链接，允许您直接从GitHub打开您的笔记本。'
- en: '![Colab’s GitHub export window](assets/lcai_0234.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![Colab的GitHub导出窗口](assets/lcai_0234.png)'
- en: Figure 2-34\. Colab’s GitHub export window.
  id: totrans-240
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-34\. Colab的GitHub导出窗口。
- en: After Colab copies the notebook to GitHub, it takes you directly to GitHub,
    as shown in [Figure 2-35](#notebook_copied_to_github).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在Colab将笔记本复制到GitHub后，它会直接带您到GitHub，如[图 2-35](#notebook_copied_to_github)所示。
- en: '![Notebook copied to GitHub](assets/lcai_0235.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![笔记本已复制到GitHub](assets/lcai_0235.png)'
- en: Figure 2-35\. Notebook copied to GitHub.
  id: totrans-243
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-35\. 笔记本已复制到GitHub。
- en: Refresh the screen in the repo. You should see your Colab Jupyter notebook,
    as shown in [Figure 2-36](#copy_of_colab_jupyter_notebook_in_githu).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 刷新存储库中的屏幕。您应该会看到您的Colab Jupyter笔记本，如[图 2-36](#copy_of_colab_jupyter_notebook_in_githu)所示。
- en: '![Copy of Colab Jupyter notebook in GitHub](assets/lcai_0236.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![Colab Jupyter笔记本的副本在GitHub中](assets/lcai_0236.png)'
- en: Figure 2-36\. Copy of Colab Jupyter notebook in GitHub.
  id: totrans-246
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-36\. Colab Jupyter笔记本的副本在GitHub中。
- en: Summary
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: This chapter provided an overview of the use cases and datasets used in the
    book. You learned about data types and the difference between structured, semistructured,
    and unstructured and batch and streaming data. You got hands-on practice with
    a free browser-based Python Jupyter Notebook and GitHub. You discovered that dirty
    data is tricky and can impact data type and data ingestion into an ML model.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了书中使用的用例和数据集。您了解了数据类型以及结构化、半结构化和非结构化数据以及批处理和流处理数据之间的区别。您通过一个免费的基于浏览器的Python
    Jupyter笔记本和GitHub进行了实际操作。您发现脏数据很棘手，可能会影响ML模型中的数据类型和数据摄取。
- en: In the next chapter, you’ll learn about ML frameworks and you’ll get to work
    with AutoML. You are given a preprocessed dataset, and all you’ll have to do is
    upload the dataset into the AutoML framework and you will be able to build and
    train a predictive model without writing a single line of code.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将了解ML框架，并开始使用AutoML。您将获得一个预处理过的数据集，您只需将数据集上传到AutoML框架中，就能够构建和训练预测模型，而无需编写一行代码。
