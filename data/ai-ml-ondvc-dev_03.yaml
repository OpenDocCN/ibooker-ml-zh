- en: Chapter 3\. Introduction to ML Kit
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章 介绍ML Kit
- en: In the first two chapters of this book, you took a look at the foundations of
    machine learning and deep learning to build some basic models. For the rest of
    the book, you’re going to switch gears and explore how to implement models on
    mobile devices. A powerful toolkit that allows you to implement preexisting models
    (aka turnkey scenarios) as well as custom models is Google’s ML Kit. In this chapter
    you’ll explore how to use ML Kit to run Android or iOS models entirely on your
    device. The model will stay on-device, giving your users speed and privacy advantages.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书的前两章中，你已经了解了机器学习和深度学习的基础，构建了一些基本模型。接下来的书籍内容，你将转变方向，探索如何在移动设备上实现模型。一个强大的工具包，可以让你实现预先存在的模型（即即插即用的场景），以及自定义模型，就是Google的ML
    Kit。在本章中，你将探索如何使用ML Kit在Android或iOS设备上运行模型。模型将保持在设备上，为用户带来速度和隐私优势。
- en: Note
  id: totrans-2
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: I would strongly recommend going through this chapter in detail, particularly
    if you aren’t super familiar with how to implement add-on libraries for both Android
    and iOS. I’ll go through it in a lot of detail here, and subsequent chapters will
    refer back to this one.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对如何为Android和iOS实现附加库不是特别熟悉，我强烈建议你详细阅读本章内容。我会在这里详细讲解，并且后续章节将参考本章。
- en: 'There are three main scenarios where ML Kit can be used:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit可以应用于三种主要场景：
- en: Turnkey solutions where a model *already* exists in ML Kit to implement what
    you need
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即插即用的解决方案中，ML Kit中已经存在的模型可以实现你需要的功能
- en: Rapid prototyping using a generic model for a specific task; for example, if
    you want to build a vision app, don’t have a model for your needs yet, but want
    to determine if it’s possible with your device
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用通用模型快速原型化特定任务；例如，如果你想构建一个视觉应用程序，但是还没有符合你需求的模型，想确定它是否可行于你的设备上
- en: Building apps with custom models like those we explored in [Chapter 2](ch02.html#introduction_to_computer_vision)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建使用像我们在[第2章](ch02.html#introduction_to_computer_vision)中探索的自定义模型的应用程序
- en: In this chapter I’ll explore some turnkey solutions, so you can understand how
    to get up and running quickly with ML models in your apps. In the subsequent chapters,
    we’ll explore how to use ML Kit initially to prototype vision and natural language
    processing (NLP) scenarios before building custom models and implementing them.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将探讨一些即插即用的解决方案，这样你就可以理解如何在应用程序中快速启动和运行ML模型。在随后的章节中，我们将探讨如何最初使用ML Kit原型化视觉和自然语言处理（NLP）场景，然后构建自定义模型并实现它们。
- en: I think it’s easier to learn hands-on than it is to discuss lots of background
    information, so let’s just get right into it and explore how to build some apps
    using ML Kit, starting with a face detection app on Android and iOS.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为通过动手操作学习要比讨论大量背景信息更容易，所以让我们直接开始，探索如何使用ML Kit构建一些应用程序，首先从Android和iOS上的人脸检测应用程序开始。
- en: Building a Face Detection App on Android
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Android上构建人脸检测应用程序
- en: Over the next few pages you’ll look at building an app that performs face detection
    using an ML model that is pretrained and immediately available to you to use without
    further training. You can see an example of a face detection for a single face
    in [Figure 3-1](#detecting_a_single_face_in_a_picture).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几页中，你将学习如何构建一个应用程序，使用一个预训练的ML模型进行人脸检测，该模型可以立即使用，无需进一步训练。你可以看到一个例子，在一张图片中检测单个人脸，参见[图3-1](#detecting_a_single_face_in_a_picture)。
- en: '![](assets/aiml_0301.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0301.png)'
- en: Figure 3-1\. Detecting a single face in a picture
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1 检测图片中的单个人脸
- en: The same model (and thus the simple app) can also recognize *multiple* faces
    in a picture; you can see this in [Figure 3-2](#detecting_multiple_faces_in_an_image).
    I find this particularly impressive because if you look at the woman in the foreground,
    her face is turned away from the camera, and we see it only in profile, but the
    model can still detect it!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的模型（因此也是简单的应用程序）也可以识别图片中的多个人脸；你可以在[图3-2](#detecting_multiple_faces_in_an_image)中看到这一点。我觉得这特别令人印象深刻，因为如果你看前景中的女性，她的脸转向摄像机，我们只能看到她的侧脸，但模型仍然能够检测到！
- en: '![](assets/aiml_0302.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0302.png)'
- en: Figure 3-2\. Detecting multiple faces in an image
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2 检测图像中的多个人脸
- en: Let’s take a look at how to get started with creating an app like this on Android!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在Android上开始创建这样一个应用程序！
- en: 'Step 1: Create the App with Android Studio'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤1：使用Android Studio创建应用程序
- en: The rest of this tutorial will use Android Studio and will expect you to have
    at least a basic knowledge of this tool, along with Android app development using
    Kotlin. If you’re not familiar with these, I’d recommend taking Google’s free
    course on [Android Development in Kotlin](https://oreil.ly/bOja4). If you don’t
    have Android Studio already, you can download it from [*https://developer.android.com/studio/*](https://developer.android.com/studio/)*.*
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的其余部分将使用 Android Studio，并期望您至少具有基本的工具知识，以及使用 Kotlin 进行 Android 应用程序开发的知识。如果您对此不熟悉，建议您参加
    Google 的免费课程 [使用 Kotlin 进行 Android 开发](https://oreil.ly/bOja4)。如果您还没有安装 Android
    Studio，可以从 [*https://developer.android.com/studio/*](https://developer.android.com/studio/)
    下载。
- en: The first step will be to create an app using Android Studio. So, when you use
    the File → New command, you’ll get a dialog asking you to select a project template
    ([Figure 3-3](#starting_a_new_app_in_android_studio)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步将是使用 Android Studio 创建一个应用程序。因此，当您使用 File → New 命令时，将会弹出一个对话框，要求您选择一个项目模板（见
    [图 3-3](#starting_a_new_app_in_android_studio)）。
- en: Select the Empty Activity template and click Next.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 选择空白活动模板，然后点击下一步。
- en: The next dialog (Configure Your Project) will ask you for the name, location,
    and language of your project. Use whatever suits you here, but for the namespaces
    to be the same as my code, you might want to use the name FD and the package name
    *com.example.fd* as shown in [Figure 3-4](#configuring_the_project).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个对话框（配置您的项目）将要求您输入项目的名称、位置和语言。在这里使用任何适合您的选项，但为了使命名空间与我的代码相同，您可能想要使用名称 FD 和包名
    *com.example.fd*，如 [图 3-4](#configuring_the_project) 中所示。
- en: '![](assets/aiml_0303.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0303.png)'
- en: Figure 3-3\. Starting a new app in Android Studio
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. 在 Android Studio 中开始一个新的应用程序
- en: '![](assets/aiml_0304.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0304.png)'
- en: Figure 3-4\. Configuring the project
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. 配置项目
- en: Click Finish and Android Studio will create a boilerplate application with a
    single empty activity. We can use this going forward to build the face detector.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 点击完成，Android Studio 将创建一个带有单个空活动的样板应用程序。我们可以使用这个应用程序来构建人脸检测器。
- en: 'Step 2: Add and Configure ML Kit'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '步骤 2: 添加和配置 ML Kit'
- en: 'Android Studio allows you to add external libraries using the [Gradle build
    tool](https://gradle.org). It can be a little confusing at first because there
    are *two* Gradle files in your project, one which defines the overall build infrastructure
    for the project and one for your app. To add ML Kit you use the latter of these—the
    build.gradle for your app. In the IDE, you’ll see something like [Figure 3-5](#exploring_your_gradle_scripts)
    for your Gradle scripts folder, so note that the second entry is for Module: app.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Android Studio 允许您使用 [Gradle 构建工具](https://gradle.org) 添加外部库。起初可能会有点混乱，因为您的项目中有
    *两个* Gradle 文件，一个定义了项目的整体构建基础设施，另一个是您的应用程序的构建.gradle 文件。要添加 ML Kit，您使用后者——您的应用程序的
    build.gradle。在 IDE 中，您会看到类似 [图 3-5](#exploring_your_gradle_scripts) 的 Gradle 脚本文件夹，因此请注意，第二个条目是模块：app。
- en: '![](assets/aiml_0305.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0305.png)'
- en: Figure 3-5\. Exploring your Gradle scripts
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5\. 探索您的 Gradle 脚本
- en: 'Open the build.gradle file for Module: app, and you’ll see a number of configuration
    entries. Right at the bottom of it you’ll see a section called dependencies. This
    will contain a number of `implementation`, `testImplementation`, and `androidTestImplementation`
    entries. You add your dependencies here, and for ML Kit face detection you can
    add the implementation details shown here:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 build.gradle 文件，位于模块：app 中，您将看到许多配置条目。在底部右侧，您将看到一个名为 dependencies 的部分。这里包含多个
    `implementation`、`testImplementation` 和 `androidTestImplementation` 条目。您可以在这里添加您的依赖项，例如
    ML Kit 人脸检测的实现细节如下所示：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Versions may be different for you—these are the latest versions at time of writing—and
    note that you are only adding the *last* line in the preceding listing, which
    defines the implementation for ML Kit face detection.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 版本可能与您的情况有所不同——这些是撰写时的最新版本，并注意，您仅需添加前一清单中的 *最后* 一行，用于定义 ML Kit 人脸检测的实现。
- en: 'Step 3: Define the User Interface'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '步骤 3: 定义用户界面'
- en: We’ll keep this as simple as possible so that we can get to the face detection
    code as quickly as possible! So, in Android Studio, find the res folder, and within
    it, see layout and then *activity_main.xml* as shown in [Figure 3-6](#finding_the_activity_declaration).
    This is an XML file that declares what your user interface will look like!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尽可能保持简单，以便尽快进入人脸检测代码！因此，在 Android Studio 中找到 res 文件夹，在其中查看 layout，然后看到 *activity_main.xml*，如
    [图 3-6](#finding_the_activity_declaration) 所示。这是一个 XML 文件，声明了您的用户界面将如何显示！
- en: '![](assets/aiml_0306.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0306.png)'
- en: Figure 3-6\. Finding the activity declaration
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-6\. 查找活动声明
- en: 'When you open it, you’ll probably see a layout editor with a simple layout
    containing the text “Hello World.” Switch to the Code view for the editor by selecting
    the “code” icon at the top right of the screen. You should then see XML code for
    the layout that looks something like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当你打开它时，你可能会看到一个布局编辑器，布局很简单，只包含文本“Hello World”。通过在屏幕右上角选择“code”图标，切换到编辑器的代码视图。然后你应该会看到类似这样的布局的XML代码：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Delete the TextView entry in the middle, and update it with a new Button and
    ImageView so that the listing will look like this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 删除中间的TextView条目，并更新为一个新的Button和ImageView，使得清单看起来像这样：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You now have a very basic user interface containing a button and an image. You
    can load your image to the ImageView, and when you press the button, it will call
    ML Kit to detect the faces in the image contained in the ImageView and then draw
    the rectangles indicating their location.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有一个非常基本的用户界面，包含一个按钮和一个图像。你可以将图像加载到ImageView中，当你按下按钮时，它将调用ML Kit来检测ImageView中图像中的人脸，并绘制指示其位置的矩形。
- en: 'Step 4: Add the Images as Assets'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 4：将图像作为资产添加
- en: Android Studio doesn’t create an assets folder for you by default, so you’ll
    have to manually create one yourself to load images from it. The easiest way to
    do this is on the file structure for your project. Find the folder your code is
    located in, and within the *app/src/main* folder, create a directory called *assets*.
    Android Studio will then recognize this as your assets directory. Copy some pictures
    to this (or just use the ones from my GitHub) and they’ll be ready to use.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Android Studio默认不为你创建一个资产文件夹，所以你需要手动创建一个来从中加载图像。最简单的方法是在项目的文件结构上进行操作。找到代码所在的文件夹，在*app/src/main*文件夹内创建一个名为*assets*的目录。Android
    Studio会将其识别为你的资产目录。将一些图片复制到这里（或者直接使用我GitHub上的图片），它们就可以使用了。
- en: When you are done and it’s configured correctly, Android Studio will recognize
    the folder as an assets folder, and you’ll be able to browse it. See [Figure 3-7](#setting_up_your_assets).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成配置并且正确设置时，Android Studio会将该文件夹识别为资产文件夹，你可以浏览它。参见[图 3-7](#setting_up_your_assets)。
- en: '![](assets/aiml_0307.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0307.png)'
- en: Figure 3-7\. Setting up your assets
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-7\. 设置你的资产
- en: You’re now ready to begin coding, so let’s start by setting up the user interface
    with a default picture.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经准备好开始编码了，让我们从使用默认图片设置用户界面开始。
- en: 'Step 5: Load the UI with a Default Picture'
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 5：使用默认图片加载用户界面
- en: 'In your *MainActivity.kt* file, you should see a function called `onCreate`.
    This gets called when the activity is created. In here, add the following code
    at the bottom, under the `setContentView` line:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的*MainActivity.kt*文件中，你应该看到一个名为`onCreate`的函数。当活动创建时会调用此函数。在这里，在`setContentView`行的下面，添加以下代码：
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This creates a handle to the ImageView control that you added to the layout
    and calls it `img`. It then gets the file called *face-test.jpg* and loads it
    from the assets folder using a helper function called `assetsToBitmap`, which
    you’ll see in a moment. Once the bitmap is ready it will call `apply`, which allows
    you to execute code upon the bitmap being loaded, and it sets the image bitmap
    property of `img` to the bitmap, thus loading the image into the ImageView.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个对你在布局中添加的ImageView控件的引用，并将其命名为`img`。然后它获取名为*face-test.jpg*的文件，并使用名为`assetsToBitmap`的帮助函数从资产文件夹加载它，你马上就会看到这个函数。一旦位图准备就绪，它将调用`apply`，允许你在位图加载时执行代码，并将`img`的图像位图属性设置为位图，从而将图像加载到ImageView中。
- en: 'The helper function to load the bitmap from the assets folder is here:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 从资产文件夹加载位图的帮助函数在这里：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For this sample, the helper function is within the activity. Good programming
    practice for larger apps would have a helper class with functions like this one
    available.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，帮助函数位于活动内部。对于更大的应用程序，良好的编程实践会将类似这样的帮助函数放在一个可用的帮助类中。
- en: This simply opens the assets and uses a `BitmapFactory` to stream the content
    of the image into a nullable `Bitmap`. If you run the app, it will now look like
    [Figure 3-8](#running_the_app).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这简单地打开资产，并使用`BitmapFactory`将图像内容流式传输到可为空的`Bitmap`中。如果你运行应用程序，它现在看起来会像[图 3-8](#running_the_app)。
- en: '![](assets/aiml_0308.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0308.png)'
- en: Figure 3-8\. Running the app
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-8\. 运行应用程序
- en: We can see that it’s very basic, just an image and a button, but at least our
    image has been loaded into the ImageView! Next up we’ll code the button and have
    it call ML Kit’s face detector for us!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这非常基础，只有一个图像和一个按钮，但至少我们的图像已经加载到了ImageView中！接下来我们将编写按钮，并让它调用ML Kit的人脸检测器！
- en: 'Step 6: Call the Face Detector'
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第6步：调用人脸检测器
- en: 'The [face detection API](https://oreil.ly/CPJWS) has many options that you
    can call, and these are accessible via a `FaceDetectorOptions` object. I’m not
    going to go into detail here about all the options that are available—you can
    check the documentation for that—but before calling the API you will need to set
    up the options that you’ll use to call it with. This is done using a `FaceDetectorOptions.Builder()`
    object, and here’s an example:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[人脸检测API](https://oreil.ly/CPJWS)有许多您可以调用的选项，这些选项可通过`FaceDetectorOptions`对象访问。我不会在这里详细介绍所有可用的选项——您可以查看文档来了解——但在调用API之前，您需要设置要使用的选项。这是使用`FaceDetectorOptions.Builder()`对象完成的，以下是一个示例：'
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: There are many options that you can set here for various landmarks on the face,
    or classifications such as eyes open or closed, but as we’re just doing a bounding
    box I’ve selected a simple set of options where I just ask for it to be fast!
    (If you want it to be more accurate, you can use `PERFORMANCE_MODE_ACCURATE`,
    which will generally take a little longer, and may perform better when there are
    multiple faces in a scene.)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有许多选项，您可以设置不同面部的标志性地标或分类，比如睁眼或闭眼，但由于我们只是做一个边界框，我选择了一组简单的选项，只需快速完成！（如果您希望更精确，可以使用`PERFORMANCE_MODE_ACCURATE`，这通常会花费更长时间，并且在场景中存在多个面时可能表现更好。）
- en: 'Next you’ll create an instance of the detector using these options, and pass
    it the bitmap. As the bitmap was a nullable type (i.e., `Bitmap?`), and `InputImage.fromBitmap`
    won’t take nullable types, you postfix `bitmap` with `!!` to get it to recognize
    it. Here’s the code:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将使用这些选项创建检测器的实例，并将其传递给位图。由于位图是可空类型（即`Bitmap?`），并且`InputImage.fromBitmap`不会接受可空类型，因此您需要在`bitmap`后面加上`!!`以使其识别。以下是代码：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can get the results from the detector by calling `detector.process` and
    passing it your image. If it succeeds, you’ll get a callback to its `onSuccessListener`,
    which will contain a list of faces. If it fails you’ll get an `onFailureListener`,
    which you can use to track the exception:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过调用`detector.process`并将其传递给您的图像来获取检测器的结果。如果成功，您将获得其`onSuccessListener`的回调，其中将包含一系列面部。如果失败，您将获得一个`onFailureListener`，您可以使用它来跟踪异常：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Within the `onSuccessListener`, you can then use `bitmap?.apply` again to call
    a function, but this time you can set the image bitmap to the return of a function
    called `drawWithRectangle`, passing it the list of faces. This will take the bitmap
    and draw the rectangles on it. You’ll see that in the next step.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在`onSuccessListener`中，您可以再次使用`bitmap?.apply`调用一个函数，但这次您可以将图像位图设置为调用名为`drawWithRectangle`的函数的返回值，将面部列表传递给它。这将获取位图并在其上绘制矩形。您将在下一步中看到这一点。
- en: 'But first, add all this code to the `onCreate` as part of an `onClickListener`
    for the button. Here’s the complete code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，请将所有这些代码添加到`onCreate`中，作为按钮的`onClickListener`的一部分。以下是完整的代码：
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Step 7: Add the Bounding Rectangles'
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第7步：添加边界框
- en: 'Upon success the face detection API will return a list of faces to its caller,
    and in the previous step you took this list and passed it to a `bitmap?.apply`
    function, requesting to set the image bitmap to the return from a function called
    `drawWithRectangle`. Let’s explore that here:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 成功时，人脸检测API将向其调用者返回一系列面部，而在前面的步骤中，您获取了此列表并将其传递给了`bitmap?.apply`函数，请求将图像位图设置为从名为`drawWithRectangle`的函数返回的结果。让我们在这里探讨一下：
- en: '[PRE9]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The function will make a copy of the bitmap that was used to call it and then
    initialize a `Canvas` with that bitmap. Then, for each face in the list of faces,
    it can call the `boundingBox` property to get a rectangle object for that face.
    What’s really nice is that ML Kit has scaled this rectangle to your image already,
    you don’t need to do any further decoding.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数将复制用于调用它的位图，然后使用该位图初始化一个`Canvas`。然后，对于面部列表中的每个面部，它可以调用`boundingBox`属性以获取该面部的矩形对象。真正不错的是，ML
    Kit已经将此矩形按比例缩放到您的图像上，您无需进行进一步的解码。
- en: So, in that case you can just call a `Paint()` object, define a rectangle with
    its `apply` method, and use `canvas.drawRect` to draw it. The canvas was initialized
    with your bitmap, so the rectangles will be drawn on it.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，在这种情况下，你可以直接调用一个`Paint()`对象，使用它的`apply`方法定义一个矩形，并使用`canvas.drawRect`来绘制它。Canvas是用你的位图初始化的，所以矩形将会在其上绘制。
- en: 'It will repeat this for all other faces, and when it’s done it will return
    the new, marked-up bitmap with the rectangles on it. And as this was in turn used
    to apply to the main bitmap that is in the ImageView (see [“Step 6: Draw the Bounding
    Boxes”](ch04.html#step_six_draw_the_bounding_boxes)), the new bitmap will be written
    to the ImageView and the UI updated. You can see the results in [Figure 3-9](#figure_three_nine_your_app_with_a_bound).'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 它将为所有其他面部重复此过程，并在完成后返回具有矩形标记的新位图。由于这是用于应用于ImageView中的主位图的（参见[“第6步：绘制边界框”](ch04.html#step_six_draw_the_bounding_boxes)），新位图将被写入ImageView并更新UI。你可以在[图3-9](#figure_three_nine_your_app_with_a_bound)中看到结果。
- en: '![](assets/aiml_0309.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0309.png)'
- en: Figure 3-9\. Your app with a bounding box
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-9\. 带有边界框的您的应用程序
- en: 'If you want to experiment with other images, just add them to the assets folder,
    and change this line from step 5 to contain the filename of the image you want
    to work with:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想尝试其他图片，只需将它们添加到assets文件夹中，并将第5步中的此行更改为所需工作的图片文件名：
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You’ve now created your first Android app that uses a turnkey ML Kit–based model
    to detect faces! There’s lots more that this API can do, including finding landmarks
    on a face such as eyes and ears, detecting contours, and classifying if the eyes
    are open, the person is smiling, and much more. You have everything you need to
    get started, so have fun enhancing this app.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经创建了使用即插即用的ML Kit模型检测人脸的第一个Android应用程序！此API还可以执行许多其他操作，包括查找脸部的标志点，如眼睛和耳朵，检测轮廓，并分类眼睛是否睁开，人是否微笑等等。您已经准备好开始了，所以尽情增强这个应用程序吧。
- en: For the rest of this chapter, we’ll switch gears and look at how to build the
    same app, but on iOS!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将转而看看如何构建相同的应用程序，但是在iOS上！
- en: Building a Face Detector App for iOS
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为iOS构建人脸检测器应用程序
- en: Let’s now explore how we would build a very similar app for iOS using ML Kit’s
    face detection. For iOS you’ll need to use a Mac computer as the developer box,
    as well as the Xcode environment for coding, debugging and testing.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们探索如何使用ML Kit的人脸检测构建一个非常相似的iOS应用程序。对于iOS，您需要使用Mac计算机作为开发者工作站，以及Xcode环境进行编码、调试和测试。
- en: 'Step 1: Create the Project in Xcode'
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1步：在Xcode中创建项目
- en: To start, launch Xcode and select New Project. You’ll see the new project templates
    dialog, which looks like [Figure 3-10](#new_app_templates)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请启动Xcode并选择新项目。你会看到新项目模板对话框，类似于[图3-10](#new_app_templates)
- en: Make sure you select iOS at the top of the screen, and then App as the app type.
    Click Next and you’ll be asked to fill out some details. Keep all of the defaults
    except for the product name; in my case I called it firstFace, but it’s up to
    you what name you use. Just be sure to keep the interface at Storyboard, the Life
    Cycle at UIKit App Delegate, and the language at Swift as shown in [Figure 3-11](#choosing_project_options).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在屏幕顶部选择iOS，然后将App作为应用程序类型。点击下一步，会要求你填写一些细节。除了产品名称，保留所有默认设置；在我的案例中，我称之为firstFace，但你可以使用任何你喜欢的名称。只需确保将界面保持为Storyboard，生命周期为UIKit
    App Delegate，并将语言设置为Swift，如[图3-11](#choosing_project_options)所示。
- en: After clicking Next, Xcode will create a template project for you. At this point
    you should close Xcode, as you will need to do some configuration outside of the
    IDE before you start coding. You’ll see that in the next step where you add the
    ML Kit libraries using Cocoapods.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 点击下一步后，Xcode将为您创建一个模板项目。此时应关闭Xcode，因为您需要在IDE之外进行一些配置，然后开始编码。您将在下一步看到如何使用Cocoapods添加ML
    Kit库。
- en: '![](assets/aiml_0310.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0310.png)'
- en: Figure 3-10\. New app templates
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-10\. 新应用模板
- en: '![](assets/aiml_0311.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0311.png)'
- en: Figure 3-11\. Choosing project options
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-11\. 选择项目选项
- en: 'Step 2: Using CocoaPods and Podfiles'
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步：使用CocoaPods和Podfiles
- en: A common technology for managing dependencies in iOS development is [CocoaPods](https://cocoapods.org).
    It’s somewhat analogous to the Gradle files you saw in the Android section earlier
    in this chapter, and it’s designed to make handling dependency files as easy as
    possible. You’ll use CocoaPods through a Podfile, which defines the dependencies
    that you’ll add to your app.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在 iOS 开发中管理依赖项的常见技术是[CocoaPods](https://cocoapods.org)。这在某种程度上类似于前几章中看到的 Android
    部分中的 Gradle 文件，并且旨在尽可能简化处理依赖文件。您将通过一个 Podfile 使用 CocoaPods，该文件定义了要添加到应用程序中的依赖项。
- en: I won’t go into a lot of detail on CocoaPods in this chapter, but please ensure
    that it’s installed and ready to go or you won’t be able to continue beyond this
    point for this sample, as it strongly depends on using CocoaPods to integrate
    ML Kit into your iOS app.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我不会详细介绍 CocoaPods，但请确保已安装并准备好使用，否则您将无法继续进行本示例，因为它严重依赖于使用 CocoaPods 将 ML
    Kit 集成到您的 iOS 应用程序中。
- en: When you created the project earlier, it was stored in a directory with the
    project name. So, for example, in my case I called it firstFace and stored it
    on the Desktop. Within that folder is an Xcode project file called *firstFace.xcodeproj*
    and a folder, also called *firstFace*.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建项目时，它存储在一个与项目名称相同的目录中。例如，在我的情况下，我将其称为 firstFace 并将其存储在桌面上。在该文件夹中包含一个名为*firstFace.xcodeproj*的
    Xcode 项目文件和一个名为*firstFace*的文件夹。
- en: 'Within your project folder, alongside the *.xcodeproj* file, create a new text
    file called Podfile, with no extension. Edit the contents of this file so that
    it reads like this—changing `firstFace` to whatever your project is called:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目文件夹中，与*.xcodeproj*文件并列，创建一个名为 Podfile 的新文本文件，没有扩展名。编辑此文件的内容，使其如下所示——将`firstFace`更改为您的项目名称：
- en: '[PRE11]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Then, using Terminal, go to the project folder (it should contain the *.xcproject*
    file) and type `**pod install**`. If it executes correctly, you should see something
    like [Figure 3-12](#running_pod_install).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用终端进入项目文件夹（它应包含*.xcproject*文件），并输入`**pod install**`。如果执行正确，您应该看到类似[图 3-12](#running_pod_install)的内容。
- en: Note
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: At the time of writing this book, M1-based Macs were relatively rare. Some testers
    encountered issues with `pod install` and it gave errors with *ffi_c.bundle*.
    To get around these, please ensure you are using the latest install of CocoaPods,
    or use the [documented workaround](https://oreil.ly/BqxCx).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写本书时，基于 M1 芯片的 Mac 相对较少。一些测试者在执行`pod install`时遇到了问题，并出现了*ffi_c.bundle*的错误。为了解决这些问题，请确保您使用的是最新版本的
    CocoaPods，或者使用[已记录的解决方法](https://oreil.ly/BqxCx)。
- en: This will download the dependencies and install them in a new workspace called
    *firstFace.xcworkspace*. Use this to load your work going forward. So now, from
    within the terminal, you can type `**open firstFace.xcworkspace**`.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这将下载依赖项并将它们安装在名为*firstFace.xcworkspace*的新工作空间中。今后可以使用它来加载您的工作。因此，现在，您可以在终端中输入`**open
    firstFace.xcworkspace**`。
- en: '![](assets/aiml_0312.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0312.png)'
- en: Figure 3-12\. Running `pod install`
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-12\. 运行`pod install`
- en: 'Step 3: Create the User Interface'
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 3 步：创建用户界面
- en: We’ll build the simplest app we can, but it will still need some UI elements.
    To keep it as basic as possible, these will be an ImageView and a Button. So,
    with Xcode open (to the *.xcworkspace* file as shown in the previous section),
    find the *Main.storyboard* file in the project, and open the tools library using
    View → Show Library.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建我们可以构建的最简单的应用程序，但它仍然需要一些 UI 元素。为了使其尽可能基本，这些将是一个 ImageView 和一个 Button。因此，打开
    Xcode（打开 *.xcworkspace* 文件，如前一节所示），找到项目中的*Main.storyboard*文件，并使用 View → Show Library
    打开工具库。
- en: You’ll see a list of UI elements, as shown in [Figure 3-13](#adding_the_ui_elements).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到一个 UI 元素列表，如[图 3-13](#adding_the_ui_elements)所示。
- en: '![](assets/aiml_0313.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0313.png)'
- en: Figure 3-13\. Adding the UI elements
  id: totrans-111
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-13\. 添加 UI 元素
- en: Using this, and with the *Main.storyboard* active in the editor, drag an ImageView
    and a Button onto the design surface of the storyboard. Your IDE should look a
    little like [Figure 3-14](#your_main_storyboard) when you are done.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此方法，并且在编辑器中激活*Main.storyboard*时，将 ImageView 和 Button 拖放到故事板的设计表面上。完成后，您的 IDE
    应该看起来像[图 3-14](#your_main_storyboard)。
- en: '![](assets/aiml_0314.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0314.png)'
- en: Figure 3-14\. Your main storyboard
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-14\. 您的主故事板
- en: From the editor menu, you should see an entry called Assistant, which, if you
    select it, will open a code window alongside or below the visual editor.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 从编辑器菜单中，您应该看到一个称为 Assistant 的条目，如果选择它，将在视觉编辑器的旁边或下方打开一个代码窗口。
- en: Holding the Ctrl key, drag the button to the code just beneath `class ViewController`,
    and a pop-up window will appear. See [Figure 3-15](#connecting_ui_with_code_in_xcode).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 按住 Ctrl 键，将按钮拖动到 `class ViewController` 下方的代码中，会弹出一个窗口。参见 [图 3-15](#connecting_ui_with_code_in_xcode)。
- en: '![](assets/aiml_0315.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0315.png)'
- en: Figure 3-15\. Connecting UI with code in Xcode
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-15\. 在 Xcode 中连接 UI 与代码
- en: In the Connection setting, select Action, and in the Name field, enter buttonPressed,
    and then press the Connect button.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在连接设置中，选择 Action，在名称字段中输入 buttonPressed，然后按 Connect 按钮。
- en: 'The following code will be generated for you:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将为您生成：
- en: '[PRE12]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Similarly, while holding the Ctrl key, drag the UIImageView control to your
    code window, and when the window from [Figure 3-15](#connecting_ui_with_code_in_xcode)
    pops up, keep the Connection setting to Outlet, but set the name to imageView
    before clicking Connect. This will generate code like this:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，按住 Ctrl 键，将 UIImageView 控件拖动到代码窗口中，当出现来自 [图 3-15](#connecting_ui_with_code_in_xcode)
    的窗口时，保持连接设置为 Outlet，但将名称设置为 imageView，然后点击连接。这将生成如下代码：
- en: '[PRE13]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that the `IB` here stands for “Interface Builder,” so you’ve created an
    Interface Builder *action* that will run when the button is pressed, and an Interface
    Builder *outlet* that will allow you to refer to or set the contents of the UIImageView
    element by addressing it as `imageView`.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这里的 `IB` 代表“Interface Builder”，因此你已经创建了一个 Interface Builder *action*，当按钮被按下时将运行，以及一个
    Interface Builder *outlet*，允许你通过 `imageView` 引用或设置 UIImageView 元素的内容。
- en: Next, let’s add the JPEG of the woman’s face to the app as an asset. This is
    as simple as dragging and dropping it onto the project explorer in Xcode. Go to
    Finder, get the image, and drag and drop it onto the left pane of Xcode where
    all your code files are. A dialog will pop up asking you to “Choose options for
    adding these files.” Accept the defaults and click Finish.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们将女士面部的 JPEG 图像作为资源添加到应用程序中。只需将其拖放到 Xcode 项目资源管理器中即可完成。在 Finder 中找到图片，将其拖放到
    Xcode 左侧面板的代码文件区域。会弹出一个对话框询问“选择添加这些文件的选项”。接受默认设置并点击完成。
- en: You should see the file (in this case I called it *face1.jpg*) in your project
    as an asset. See [Figure 3-16](#adding_a_file_to_your_project).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会在项目中看到这个文件（在本例中我称其为 *face1.jpg*）作为资源。参见 [图 3-16](#adding_a_file_to_your_project)。
- en: '![](assets/aiml_0316.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0316.png)'
- en: Figure 3-16\. Adding a file to your project
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-16\. 将文件添加到项目中
- en: 'You can now load the image into your `imageView` by adding code to the `viewDidLoad()`
    function:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以通过在 `viewDidLoad()` 函数中添加代码来将图片加载到 `imageView` 中：
- en: '[PRE14]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You could run the app now and have a very boring UI with just an image and a
    button in it. But you’d know it worked!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以运行应用程序，它将展示一个非常简单的 UI，只有一个图片和一个按钮。但你会知道它是有效的！
- en: Note
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The iOS Simulator provides an environment where you can emulate iOS devices.
    At the time of writing, some third-party libraries aren’t supported in the simulator
    on M1 macs. As such, you can run either on a device, or you can choose the “My
    Mac - Designed for iPad” runtime. The screenshots for the rest of this chapter
    were taken from this target system, running on an M1 Mac Mini.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: iOS 模拟器提供了一个可以模拟 iOS 设备的环境。在撰写本文时，某些第三方库在 M1 Mac 上的模拟器中不受支持。因此，你可以选择在设备上运行，或者选择“我的
    Mac - iPad 设计”运行时。本章其余部分的屏幕截图均来自此目标系统，运行在 M1 Mac Mini 上。
- en: 'The final part of your user interface elements will be a view that can be used
    for adding annotations to the image—for example, the bounding box for the face.
    We’ll do this using code, so, add the following to *ViewController.swift*:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 用户界面元素的最后部分将是一个视图，可用于向图像添加注释，例如人脸的边界框。我们将使用代码完成这一步骤，因此，请将以下内容添加到 *ViewController.swift*
    文件中：
- en: '[PRE15]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This will just give us a view that will load after the main view containing
    the rest of the UI elements (note the precondition).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这将仅仅给我们一个视图，在主视图加载后加载其余 UI 元素（请注意先决条件）。
- en: 'This overlay view can then be loaded and activated on top of your `imageView`
    by updating `viewDidLoad` like this:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以通过更新 `viewDidLoad` 方法，将此覆盖视图加载并激活在 `imageView` 上层显示，如下所示：
- en: '[PRE16]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now that we’ve created the entire user interface—consisting of the UIImageView
    for the picture, the button for the user to press, and the annotation overlay
    to render the bounding box, we’re ready to start coding the logic that will use
    ML Kit to detect the face. You’ll see that next.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了整个用户界面，包括用于图片的 UIImageView，供用户按下的按钮，以及用于呈现边界框的注释覆盖层，我们准备开始编写将使用 ML
    Kit 检测面部的逻辑。接下来将看到这一部分。
- en: 'Step 4: Add the Application Logic'
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 4：添加应用程序逻辑
- en: When the user presses the button, we will want to invoke ML Kit, pass it the
    image, get the details for the bounding box that indicates the location of the
    face, and then render that on the view. Let’s look at how to code this step by
    step.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户按下按钮时，我们希望调用ML Kit，将图像传递给它，获取指示人脸位置的边界框的详细信息，然后在视图上呈现它。让我们逐步看如何编写这个过程。
- en: 'First, you’ll need to import the ML Kit libraries:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要导入ML Kit库：
- en: '[PRE17]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, let’s set up the ML Kit face detector. To do this, you’ll first need
    to create a `FaceDetectorOptions` object and set up some of its properties. In
    this case we’ll just do some basic options—getting all contours for the face,
    and asking it for fast performance:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们设置ML Kit人脸检测器。为此，您首先需要创建一个`FaceDetectorOptions`对象，并设置一些其属性。在这种情况下，我们只会执行一些基本选项——获取所有人脸轮廓，并要求它提供快速性能：
- en: '[PRE18]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, once we have the options, we can use them to instantiate a `faceDetector`:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，一旦我们有了选项，我们可以使用它们来实例化一个`faceDetector`：
- en: '[PRE19]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You’ll probably notice at this point that your code will give you an error
    because it can’t find `FaceDetectorOptions`. That’s OK. It just means they’re
    in a library that you haven’t referenced yet. You can fix that with some imports
    at the top of your code. These will give you the ML Kit face detection libraries,
    as well as the helper libraries for general computer vision:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，您可能会注意到您的代码会因为找不到`FaceDetectorOptions`而出错。没关系，这只是意味着它们在您尚未引用的库中。您可以通过在代码顶部添加一些导入来修复它。这些将为您提供ML
    Kit人脸检测库以及一般计算机视觉的辅助库：
- en: '[PRE20]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Recall earlier that you created an Interface Builder action that would execute
    when the user pressed the button. Let’s start there and have it run a custom function
    (which you’ll create in a moment) when the user touches the button:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，您之前创建了一个Interface Builder动作，当用户按下按钮时将执行它。让我们从这里开始，并让它在用户触摸按钮时运行一个自定义函数（您马上就会创建）。
- en: '[PRE21]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we can code this function up—its job will be to take the image and pass
    it to the face detector. Once the face detector does its job, it can handle the
    return. So we can keep the function very simple:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以编写此函数——它的工作是接收图像并将其传递给人脸检测器。一旦人脸检测器完成其工作，它就能处理返回的内容。因此，我们可以使函数非常简单：
- en: '[PRE22]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: You haven’t yet written the `processResult` function, so Xcode will give you
    a warning. Don’t worry—you’ll implement that next.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您还没有编写`processResult`函数，所以Xcode会给出警告。不用担心——您接下来会实现它。
- en: To allow ML Kit to recognize many different object types, the pattern is to
    convert all images into a `VisionImage` object. This object supports construction
    from a variety of formats, and here we do so from a `UIImage`. We’ll first create
    an instance of a `VisionImage` and set its orientation to be the same as the original
    image. Then, we process the image using the face detector object created earlier.
    This will return features and/or errors, so we can pass *these* to a function
    called `processResult`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使ML Kit能够识别多种不同类型的对象，模式是将所有图像转换为`VisionImage`对象。此对象支持多种格式的构建，我们在这里从`UIImage`开始。我们将首先创建一个`VisionImage`实例，并将其方向设置为与原始图像相同。然后，我们使用之前创建的人脸检测器对象处理图像。这将返回特征和/或错误，因此我们可以将*它们*传递给名为`processResult`的函数。
- en: 'So here’s the code for `processResult` (abbreviated by removing error handling,
    which you shouldn’t do in a production app!), and its job is to get the details
    back from ML Kit’s face detector:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这是`processResult`的代码（通过删除错误处理进行了缩写，生产应用程序中不应该这样做！），它的工作是从ML Kit的人脸检测器获取细节：
- en: '[PRE23]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note that the coordinates of the bounding boxes returned by ML Kit are not the
    same as the coordinates of the image in the iOS user interface for various reasons,
    including the fact that they’re based on the resolution of the image, and not
    the number of pixels that are rendered on the screen, as well as things like the
    aspect ratio. So, a `transformMatrix` function needs to be created to convert
    between the coordinates returned from ML Kit and the onscreen ones. This is used
    to create the `transformedRect`—which will be the frame of the face in screen
    coordinates. Finally, a rectangle will be added to the `annotationOverlayView`,
    which will frame the face for us.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由ML Kit返回的边界框的坐标与iOS用户界面中图像的坐标不同，原因包括它们基于图像的分辨率，而不是屏幕上渲染的像素数量，以及诸如纵横比之类的因素。因此，需要创建一个`transformMatrix`函数来在ML
    Kit返回的坐标和屏幕上的坐标之间进行转换。这用于创建`transformedRect`——它将是屏幕坐标中人脸的框架。最后，将向`annotationOverlayView`添加一个矩形，它将为我们框出人脸。
- en: 'The full code for the helper functions—transforming the rectangle’s coordinates
    and applying it to the overlay—is here:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 辅助函数的完整代码——转换矩形坐标并将其应用于覆盖层——在此处：
- en: '[PRE24]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: And this will give you all the code you need. As you can see most of it is really
    for the user interface logic—converting the coordinates, plotting the rectangles,
    etc. The face detection is relatively simple—just three lines of code in the `runFaceContourDetection`
    function!
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为您提供所需的所有代码。正如您所见，其中大部分实际上是用于用户界面逻辑——转换坐标、绘制矩形等。人脸检测相对简单——在 `runFaceContourDetection`
    函数中只需三行代码！
- en: Running the app and pressing the button should frame the face like in [Figure 3-17](#framing_a_face_on_ios).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 运行应用程序并按下按钮应该像在[图 3-17](#framing_a_face_on_ios)中那样框住脸。
- en: '![](assets/aiml_0317.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0317.png)'
- en: Figure 3-17\. Framing a face on iOS
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-17\. iOS 上的人脸框架
- en: Again, this is a super simple example, but the pattern is very typical of a
    far more sophisticated app. The goal with ML Kit is to make the ML part of application
    development as easy as possible, and hopefully the face detection part of this
    app proved that.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这只是一个非常简单的示例，但该模式非常典型，适用于更复杂的应用程序。ML Kit 的目标是尽可能简化应用程序开发中的 ML 部分，希望此应用程序的人脸检测部分能证明这一点。
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you had a brief introduction to using ML Kit for mobile machine
    learning in your apps. You saw how to use it in both Android and iOS to build
    a very simple app that detected a face in a given image and plotted a rectangle
    over that face. Importantly you saw how to include ML Kit via Gradle on Android
    and CocoaPods on iOS. Over the next few chapters, we’ll go deeper into some common
    scenarios across each platform starting with vision apps in [Chapter 4](ch04.html#computer_vision_apps_with_ml_kit_on_and)
    using Android.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您简要介绍了如何在移动应用程序中使用 ML Kit 进行移动机器学习。您看到了如何在 Android 和 iOS 上使用它来构建一个非常简单的应用程序，该应用程序检测给定图像中的面部并在该面部上绘制一个矩形。重要的是，您看到了如何通过在
    Android 上使用 Gradle 和在 iOS 上使用 CocoaPods 来包含 ML Kit。在接下来的几章中，我们将更深入地探讨每个平台上一些常见的场景，首先是在使用
    Android 的[第四章](ch04.html#computer_vision_apps_with_ml_kit_on_and)中进行视觉应用程序。
