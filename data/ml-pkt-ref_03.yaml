- en: 'Chapter 3\. Classification Walkthrough: Titanic Dataset'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章。分类演练：泰坦尼克数据集
- en: This chapter will walk through a common classification problem using the [Titanic
    dataset](https://oreil.ly/PjceO). Later chapters will dive into and expand on
    the common steps performed during an analysis.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将通过使用[泰坦尼克数据集](https://oreil.ly/PjceO)来解决一个常见的分类问题。后面的章节将深入探讨并扩展在分析过程中执行的常见步骤。
- en: Project Layout Suggestion
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目布局建议
- en: An excellent tool for performing exploratory data analysis is [Jupyter](https://jupyter.org).
    Jupyter is an open-source notebook environment that supports Python and other
    languages. It allows you to create *cells* of code or Markdown content.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 进行探索性数据分析的一个很好的工具是[Jupyter](https://jupyter.org)。Jupyter是一个支持Python和其他语言的开源笔记本环境。它允许您创建代码或Markdown内容的*单元格*。
- en: I tend to use Jupyter in two modes. One is for exploratory data analysis and
    quickly trying things out. The other is more of a deliverable style where I format
    a report using Markdown cells and insert code cells to illustrate important points
    or discoveries. If you aren’t careful, your notebooks might need some refactoring
    and application of software engineering practices (remove globals, use functions
    and classes, etc.).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我倾向于使用Jupyter有两种模式。一种是用于探索性数据分析和快速尝试。另一种是更多地以可交付的方式使用，我使用Markdown单元格格式化报告，并插入代码单元格以说明重要的观点或发现。如果你不小心，你的笔记本可能需要一些重构和应用软件工程实践（删除全局变量，使用函数和类等）。
- en: The [cookiecutter data science package](https://oreil.ly/86jL3) suggests a layout
    to create an analysis that allows for easy reproduction and sharing code.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[cookiecutter数据科学包](https://oreil.ly/86jL3)建议了一个布局，用于创建一个分析，以便轻松复制和共享代码。'
- en: Imports
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入
- en: 'This example is based mostly on [pandas](http://pandas.pydata.org/), [scikit-learn](https://scikit-learn.org/),
    and [Yellowbrick](http://www.scikit-yb.org/). The pandas library gives us tooling
    for easy data munging. The scikit-learn library has great predictive modeling,
    and Yellowbrick is a visualization library for evaluating models:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子主要基于[pandas](http://pandas.pydata.org/)、[scikit-learn](https://scikit-learn.org/)和[Yellowbrick](http://www.scikit-yb.org/)。pandas库为我们提供了方便的数据整理工具。scikit-learn库具有出色的预测建模能力，而Yellowbrick是一个用于评估模型的可视化库。
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Warning
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: 'You might find documentation and examples online that include star imports
    like:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会发现在线文档和示例包括星号导入，例如：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Refrain from using star imports. Being explicit makes your code easier to understand.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 避免使用星号导入。显式表达会使您的代码更易于理解。
- en: Ask a Question
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提出问题
- en: In this example, we want to create a predictive model to answer a question.
    It will classify whether an individual survives the Titanic ship catastrophe based
    on individual and trip characteristics. This is a toy example, but it serves as
    a pedagogical tool for showing many steps of modeling. Our model should be able
    to take passenger information and predict whether that passenger would survive
    on the Titanic.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们想要创建一个预测模型来回答一个问题。它将根据个人和旅行特征对个体是否在泰坦尼克号船难中幸存进行分类。这是一个玩具示例，但它作为一个教学工具，展示了建模的许多步骤。我们的模型应该能够获取乘客信息并预测该乘客在泰坦尼克号上是否会幸存。
- en: This is a classification question, as we are predicting a label for survival;
    either they survived or they died.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个分类问题，因为我们正在预测幸存的标签；他们是否幸存下来。
- en: Terms for Data
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据术语
- en: We typically train a model with a matrix of data. (I prefer to use pandas DataFrames
    because it is very nice to have column labels, but numpy arrays work as well.)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常用一个数据矩阵来训练模型。（我更喜欢使用pandas DataFrames，因为它很方便有列标签，但numpy数组也可以使用。）
- en: 'For supervised learning, such as regression or classification, our intent is
    to have a fuction that transforms features into a label. If we were to write this
    as an algebra formula, it would look like this:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于监督学习，如回归或分类，我们的目的是有一个将特征转换为标签的函数。如果我们将其写成代数公式，它会像这样：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: X is a matrix. Each row represents a *sample* of data or information about an
    individual. Every column in X is a *feature*. The output of our function, y, is
    a vector that contains labels (for classification) or values (for regression)
    (see [Figure 3-1](#idx1)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: X是一个矩阵。每一行代表数据的一个*样本*或关于一个个体的信息。X中的每一列都是一个*特征*。我们函数的输出y是一个包含标签（用于分类）或值（用于回归）的向量（见[图3-1](#idx1)）。
- en: '![Structured data layout.](assets/mlpr_0301.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![结构化数据布局。](assets/mlpr_0301.png)'
- en: Figure 3-1\. Structured data layout.
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1。结构化数据布局。
- en: This is standard naming procedure for naming the data and the output. If you
    read academic papers or even look at the documentation for libraries, they follow
    this convention. In Python, we use the variable name `X` to hold the sample data
    even though capitalization of variables is a violation of standard naming conventions
    (PEP 8). Don’t worry, everyone does it, and if you were to name your variable
    `x`, they might look at you funny. The variable `y` stores the labels or targets.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是标准命名过程，用于命名数据和输出。如果您阅读学术论文或查看库的文档，它们会遵循这种约定。在Python中，我们使用变量名`X`来保存样本数据，即使变量的大写是违反标准命名约定（PEP
    8）的。不用担心，每个人都这样做，如果您将变量命名为`x`，可能会让人觉得有点奇怪。变量`y`存储标签或目标。
- en: '[Table 3-1](#table_3_1) shows a basic dataset with two samples and three features
    for each sample.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 3-1](#table_3_1) 显示了一个基本数据集，包括两个样本和每个样本的三个特征。'
- en: Table 3-1\. Samples (rows) and features (columns)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-1\. 样本（行）和特征（列）
- en: '| pclass | age | sibsp |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| pclass | age | sibsp |'
- en: '| --- | --- | --- |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | 29 | 0 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 29 | 0 |'
- en: '| 1 | 2 | 1 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | 1 |'
- en: Gather Data
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集数据
- en: 'We are going to load an Excel file (make sure you have pandas and xlrd^([1](ch03.html#idm46066905711928))
    installed) with the Titanic features. It has many columns, including a survived
    column that contains the label of what happened to an individual:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将加载一个Excel文件（确保已安装pandas和xlrd^([1](ch03.html#idm46066905711928))），其中包含泰坦尼克号的特征。它有许多列，包括一个包含个体生存情况的survived列：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following columns are included in the dataset:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包括以下列：
- en: pclass - Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd)
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pclass - 乘客等级（1 = 1等，2 = 2等，3 = 3等）
- en: survival - Survival (0 = No, 1 = Yes)
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生存 - 生存（0 = 否，1 = 是）
- en: name - Name
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 姓名 - 姓名
- en: sex - Sex
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性别 - 性别
- en: age - Age
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄 - 年龄
- en: sibsp - Number of siblings/spouses aboard
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: sibsp - 船上兄弟姐妹/配偶的数量
- en: parch - Number of parents/children aboard
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: parch - 船上父母/子女的数量
- en: ticket - Ticket number
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 票 - 票号
- en: fare - Passenger fare
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 票价 - 乘客票价
- en: cabin - Cabin
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 舱室 - 舱室
- en: embarked - Point of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 登船 - 登船点（C = 瑟堡，Q = 皇后镇，S = 南安普顿）
- en: boat - Lifeboat
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 船 - 救生艇
- en: body - Body identification number
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尸体 - 尸体识别号码
- en: home.dest - Home/destination
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 家庭/目的地 - 家庭/目的地
- en: Pandas can read this spreadsheet and convert it into a DataFrame for us. We
    will need to spot-check the data and ensure that it is OK for performing analysis.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas可以读取此电子表格，并将其转换为DataFrame。我们需要抽查数据，并确保可以进行分析。
- en: Clean Data
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清洗数据
- en: Once we have the data, we need to ensure that it is in a format that we can
    use to create a model. Most scikit-learn models require that our features be numeric
    (integer or float). In addition, many models fail if they are passed missing values
    (`NaN` in pandas or numpy). Some models perform better if the data is *standardized*
    (given a mean value of 0 and a standard deviation of 1). We will deal with these
    issues using pandas or scikit-learn. In addition, the Titanic dataset has *leaky*
    features.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们拥有数据，我们需要确保它以我们可以用来创建模型的格式存在。大多数scikit-learn模型要求我们的特征是数字（整数或浮点数）。此外，如果模型传递了缺失值（pandas或numpy中的`NaN`），许多模型将失败。某些模型如果数据经过*标准化*（具有平均值为0和标准偏差为1）处理，性能会更好。我们将使用pandas或scikit-learn解决这些问题。此外，泰坦尼克号数据集具有*泄漏*特征。
- en: Leaky features are variables that contain information about the future or target.
    There’s nothing bad in having data about the target, and we often have that data
    during model creation time. However, if those variables are not available when
    we perform a prediction on a new sample, we should remove them from the model
    as they are leaking data from the future.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 泄漏特征是包含有关未来或目标信息的变量。拥有关于目标的数据并不是坏事，并且在模型创建时我们经常会有这些数据。然而，如果这些变量在我们对新样本进行预测时不可用，我们应该将它们从模型中删除，因为它们会泄漏未来的数据。
- en: Cleaning the data can take a bit of time. It helps to have access to a subject
    matter expert (SME) who can provide guidance on dealing with outliers or missing
    data.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 清洗数据可能需要一些时间。最好有专业主题专家（SME），可以提供处理异常值或缺失数据的指导。
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We typically see `int64`, `float64`, `datetime64[ns]`, or `object`. These are
    the types that pandas uses to store a column of data. `int64` and `float64` are
    numeric types. `datetime64[ns]` holds date and time data. `object` typically means
    that it is holding string data, though it could be a combination of string and
    other types.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常看到`int64`，`float64`，`datetime64[ns]`或`object`。这些是pandas用于存储数据列的类型。`int64`和`float64`是数值类型。`datetime64[ns]`存储日期和时间数据。`object`通常意味着它存储字符串数据，虽然可能是字符串和其他类型的组合。
- en: When reading from CSV files, pandas will try to coerce data into the appropriate
    type, but will fall back to `object`. Reading data from spreadsheets, databases,
    or other systems may provide better types in the DataFrame. In any case, it is
    worthwhile to look through the data and ensure that the types make sense.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在从 CSV 文件读取时，pandas 将尝试将数据强制转换为适当的类型，但会退回到 `object`。从电子表格、数据库或其他系统读取数据可能会提供
    DataFrame 中更好的类型。无论如何，浏览数据并确保类型合理都是值得的。
- en: Integer types are typically fine. Float types might have some missing values.
    Date and string types will need to be converted or used to feature engineer numeric
    types. String types that have low cardinality are called categorical columns,
    and it might be worthwhile to create dummy columns from them (the `pd.get_dummies`
    function takes care of this).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 整数类型通常没问题。浮点类型可能有一些缺失值。日期和字符串类型将需要转换或用于特征工程数字类型。低基数的字符串类型称为分类列，从中创建虚拟列可能是值得的（`pd.get_dummies`
    函数负责此操作）。
- en: Note
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Up to pandas 0.23, if the type is `int64`, we are guaranteed that there are
    no missing values. If the type is `float64`, the values might be all floats, but
    also could be integer-like numbers with missing values. The pandas library converts
    integer values that have missing numbers to floats, as this type supports missing
    values. The `object` typically means string types (or both string and numeric).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 0.23 版本之前，如果类型为 `int64`，我们可以确保没有缺失值。如果类型为 `float64`，值可能是所有浮点数，也可能是类似整数的数字，带有缺失值。pandas
    库将具有缺失数字的整数值转换为浮点数，因为这种类型支持缺失值。`object` 通常意味着字符串类型（或字符串和数字混合）。
- en: As of pandas 0.24, there is a new `Int64` type (notice the capitalization).
    This is not the default integer type, but you can coerce to this type and have
    support for missing numbers.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从 pandas 0.24 开始，有一个新的 `Int64` 类型（请注意大小写）。这不是默认的整数类型，但您可以强制转换为此类型并支持缺失数字。
- en: 'The pandas-profiling library includes a profile report. You can generate this
    report in a notebook. It will summarize the types of the columns and allow you
    to view details of quantile statistics, descriptive statistics, a histogram, common
    values, and extreme values (see Figures [3-2](#pp1) and [3-3](#pp2)):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: pandas-profiling 库包括一个配置报告。您可以在笔记本中生成此报告。它将总结列的类型，并允许您查看分位数统计、描述统计、直方图、常见值和极端值的详细信息（见图
    [3-2](#pp1) 和 [3-3](#pp2)）：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Pandas-profiling summary.](assets/mlpr_0302.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![Pandas-profiling 概要。](assets/mlpr_0302.png)'
- en: Figure 3-2\. Pandas-profiling summary.
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. Pandas-profiling 概要。
- en: '![Pandas-profiling variable details.](assets/mlpr_0303.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![Pandas-profiling 变量详细信息。](assets/mlpr_0303.png)'
- en: Figure 3-3\. Pandas-profiling variable details.
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. Pandas-profiling 变量详细信息。
- en: 'Use the `.shape` attribute of the DataFrame to inspect the number of rows and
    columns:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DataFrame 的 `.shape` 属性来检查行数和列数：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Use the `.describe` method to get summary stats as well as see the count of
    nonnull data. The default behavior of this method is to only report on numeric
    columns. Here the output is truncated to only show the first two columns:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `.describe` 方法获取摘要统计信息，并查看非空数据的计数。此方法的默认行为是仅报告数值列。这里的输出被截断，仅显示前两列：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The count statistic only includes values that are not NaN, so it is useful for
    checking whether a column is missing data. It is also a good idea to spot-check
    the minimum and maximum values to see if there are outliers. Summary statistics
    are one way to do this. Plotting a histogram or a box plot is a visual representation
    that we will see later.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 计数统计仅包括不是 NaN 的值，因此用于检查列是否缺少数据是有用的。还可以通过查看最小值和最大值来检查是否存在异常值。总结统计是一种方法。绘制直方图或箱线图是稍后将要看到的视觉表示。
- en: We will need to deal with missing data. Use the `.isnull` method to find columns
    or rows with missing values. Calling `.isnull` on a DataFrame returns a new DataFrame
    with every cell containing a `True` or `False` value. In Python, these values
    evaluate to `1` and `0`, respectively. This allows us to sum them up or even calculate
    the percent missing (by calculating the mean).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要处理缺失数据。使用 `.isnull` 方法查找具有缺失值的列或行。在 DataFrame 上调用 `.isnull` 返回一个新的 DataFrame，其中每个单元格包含
    `True` 或 `False` 值。在 Python 中，这些值分别计算为 `1` 和 `0`，这使我们可以对它们进行求和或计算缺失百分比（通过计算均值）。
- en: 'The code indicates the count of missing data in each column:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 代码指示每列中缺失数据的计数：
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Tip
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'Replace `.sum` with `.mean` to get the percentage of null values. By default,
    calling these methods will apply the operation along axis 0, which is along the
    index. If you want to get the counts of missing features for each sample, you
    can apply this along axis 1 (along the columns):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 用`.mean`替换`.sum`以获得null值的百分比。默认情况下，调用这些方法将沿着axis 0（沿着索引）应用操作。如果你想获得每个样本的缺失特征的计数，你可以沿axis
    1（沿着列）应用此方法：
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: A SME can help in determining what to do with missing data. The age column might
    be useful, so keeping it and interpolating values could provide some signal to
    the model. Columns where most of the values are missing (cabin, boat, and body)
    tend to not provide value and can be dropped.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一家中小企业可以帮助确定如何处理缺失数据。年龄列可能是有用的，所以保留它并插值值可能会为模型提供一些信号。大多数值缺失的列（舱位、船和尸体）往往没有提供价值，可以删除。
- en: The body column (body identification number) is missing for many rows. We should
    drop this column at any rate because it leaks data. This column indicates that
    the passenger did not survive; by necessity our model could use that to cheat.
    We will pull it out. (If we are creating a model to predict if a passenger would
    die, knowing that they had a body identification number a priori would let us
    know they were already dead. We want our model to not know that information and
    make the prediction based on the other columns.) Likewise, the boat column leaks
    the reverse information (that a passenger survived).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: body列（身体识别号）对于许多行来说是缺失的。无论如何，我们都应该删除这一列，因为它泄漏了数据。这一列表示乘客没有生存；我们的模型可能会利用这一点来作弊。我们会把它拿出来。（如果我们创建一个模型来预测乘客是否会死亡，知道他们有一个身体识别号的先验信息会让我们知道他们已经死了。我们希望我们的模型不知道这些信息，而是根据其他列进行预测。）同样，船列泄漏了相反的信息（乘客幸存了）。
- en: 'Let’s look at some of the rows with missing data. We can create a boolean array
    (a series with `True` or `False` to indicate if the row has missing data) and
    use it to inspect rows that are missing data:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看一些缺失数据的行。我们可以创建一个布尔数组（一个包含`True`或`False`以指示行是否有缺失数据的系列），并使用它来检查缺失数据的行：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We will impute (or derive values for) the missing values for the age column
    later.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后将为年龄列填充（或推导出）缺失值。
- en: 'Columns with type of `object` tend to be categorical (but they may also be
    high cardinality string data, or a mix of column types). For `object` columns
    that we believe to be categorical, use the `.value_counts` method to examine the
    counts of the values:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 类型为`object`的列往往是分类的（但它们也可能是高基数字符串数据，或者是列类型的混合）。对于我们认为是分类的`object`列，可以使用`.value_counts`方法来检查值的计数：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Remember that pandas typically ignores null or NaN values. If you want to include
    those, use `dropna=False` to also show counts for NaN:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，pandas通常会忽略null或NaN值。如果你想包括这些值，请使用`dropna=False`来显示NaN的计数：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We have a couple of options for dealing with missing embarked values. Using
    S might seem logical as that is the most common value. We could dig into the data
    and try and determine if another option is better. We could also drop those two
    values. Or, because this is categorical, we can ignore them and use pandas to
    create dummy columns if these two samples will just have 0 entries for every option.
    We will use this latter choice for this feature.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于处理缺失的登船值，我们有几个选项。使用S可能看起来是合乎逻辑的，因为那是最常见的值。我们可以深入研究数据，尝试确定是否有其他更好的选项。我们也可以删除这两个值。或者，因为这是分类的，我们可以忽略它们，并使用pandas来创建虚拟列，如果这两个样本只是每个选项都有0个条目的话。对于这个特征，我们将选择后者。
- en: Create Features
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建特征
- en: We can drop columns that have no variance or no signal. There aren’t features
    like that in this dataset, but if there was a column called “is human” that had
    1 for every sample this column would not be providing any information.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以删除没有方差或没有信号的列。在这个数据集中没有这样的特征，但是如果有一个名为“is human”的列，其中每个样本都有1，那么这一列将不提供任何信息。
- en: Alternatively, unless we are using NLP or extracting data out of text columns
    where every value is different, a model will not be able to take advantage of
    this column. The name column is an example of this. Some have pulled out the title
    t from the name and treated it as categorical.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，除非我们正在使用自然语言处理或从文本列中提取数据，其中每个值都不同，否则模型将无法利用此列。姓名列就是一个例子。有些人已经从姓名中提取了标题t，并将其视为分类。
- en: We also want to drop columns that leak information. Both boat and body columns
    leak whether a passenger survived.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还想删除泄露信息的列。船和body列都泄漏了乘客是否幸存的信息。
- en: 'The pandas `.drop` method can drop either rows or columns:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: pandas的`.drop`方法可以删除行或列：
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We need to create dummy columns from string columns. This will create new columns
    for sex and embarked. Pandas has a convenient `get_dummies` function for that:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要从字符串列创建虚拟列。这将为性别和登船港口创建新的列。Pandas提供了一个方便的`get_dummies`函数来实现：
- en: '[PRE14]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'At this point the sex_male and sex_female columns are perfectly inverse correlated.
    Typically we remove any columns with perfect or very high positive or negative
    correlation. Multicollinearity can impact interpretation of feature importance
    and coefficients in some models. Here is code to remove the sex_male column:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，性别_male和性别_female列是完全逆相关的。通常我们会删除任何具有完美或非常高正负相关性的列。多重共线性可能会影响某些模型中特征重要性和系数的解释。以下是删除性别_male列的代码：
- en: '[PRE15]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Alternatively, we can add a `drop_first=True` parameter to the `get_dummies`
    call:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以在`get_dummies`调用中添加一个`drop_first=True`参数：
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create a DataFrame (`X`) with the features and a series (`y`) with the labels.
    We could also use numpy arrays, but then we don’t have column names:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个带有特征的DataFrame（`X`）和一个带有标签的系列（`y`）。我们也可以使用numpy数组，但那样我们就没有列名了：
- en: '[PRE17]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Tip
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'We can use the [pyjanitor library](https://oreil.ly/_IWbA) to replace the last
    two lines:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用[pyjanitor库](https://oreil.ly/_IWbA)来替换最后两行：
- en: '[PRE18]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Sample Data
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例数据
- en: 'We always want to train and test on different data. Otherwise you don’t really
    know how well your model generalizes to data that it hasn’t seen before. We’ll
    use scikit-learn to pull out 30% for testing (using `random_state=42` to remove
    an element of randomness if we start comparing different models):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们总是希望在不同的数据集上进行训练和测试。否则，你不会真正知道你的模型在未见过的数据上的泛化能力。我们将使用scikit-learn将30%的数据分离出来进行测试（使用`random_state=42`以消除比较不同模型时的随机性影响）：
- en: '[PRE19]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Impute Data
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 插补数据
- en: The age column has missing values. We need to impute age from the numeric values.
    We only want to impute on the training set and then use that imputer to fill in
    the date for the test set. Otherwise we are leaking data (cheating by giving future
    information to the model).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 年龄列存在缺失值。我们需要从数值中插补年龄。我们只想在训练集上进行插补，然后使用该插补器填充测试集的数据。否则我们会泄漏数据（通过向模型提供未来信息来作弊）。
- en: Now that we have test and train data, we can impute missing values on the training
    set, and use the trained imputers to fill in the test dataset. The [fancyimpute
    library](https://oreil.ly/Vlf9e) has many algorithms that it implements. Sadly,
    most of these algorithms are not implemented in an *inductive* manner. This means
    that you cannot call `.fit` and then `.transform`, which means you cannot impute
    for new data based on how the model was trained.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了测试和训练数据，我们可以在训练集上填补缺失值，并使用训练好的插补器填补测试数据集。[fancyimpute库](https://oreil.ly/Vlf9e)实现了许多算法。不幸的是，这些算法大多数不是以*归纳*的方式实现的。这意味着你不能先调用`.fit`再调用`.transform`，这也意味着你不能基于模型训练的方式来对新数据进行插补。
- en: 'The `IterativeImputer` class (which was in fancyimpute but has been migrated
    to scikit-learn) does support inductive mode. To use it we need to add a special
    experimental import (as of scikit-learn version 0.21.2):'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`IterativeImputer`类（原本在fancyimpute中，但已迁移到scikit-learn）支持归纳模式。要使用它，我们需要添加一个特殊的实验性导入（从scikit-learn版本0.21.2开始）：'
- en: '[PRE20]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'If we wanted to impute with the median, we can use pandas to do that:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想使用中位数进行插补，我们可以使用pandas来实现：
- en: '[PRE21]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Normalize Data
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准化数据
- en: Normalizing or preprocessing the data will help many models perform better after
    this is done. Particularly those that depend on a distance metric to determine
    similarity. (Note that tree models, which treat each feature on its own, don’t
    have this requirement.)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据进行归一化或预处理后，许多模型的性能会有所提高。特别是那些依赖距离度量来确定相似性的模型。（请注意，树模型会单独处理每个特征，因此不需要此要求。）
- en: We are going to standardize the data for the preprocessing. Standardizing is
    translating the data so that it has a mean value of zero and a standard deviation
    of one. This way models don’t treat variables with larger scales as more important
    than smaller scaled variables. I’m going to stick the result (numpy array) back
    into a pandas DataFrame for easier manipulation (and to keep column names).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对数据进行标准化预处理。标准化是将数据转换为均值为零、标准差为一的形式。这样模型不会认为具有较大数值范围的变量比具有较小数值范围的变量更重要。我将结果（numpy数组）放回到pandas
    DataFrame中，以便更轻松地进行操作（并保留列名）。
- en: 'I also normally don’t standardize dummy columns, so I will ignore those:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常也不会对虚拟列进行标准化，所以我会忽略它们：
- en: '[PRE22]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Refactor
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重构
- en: 'At this point I like to refactor my code. I typically make two functions. One
    for general cleaning, and another for dividing up into a training and testing
    set and to perform mutations that need to happen differently on those sets:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我喜欢重构我的代码。我通常制作两个函数。一个用于一般清理，另一个用于将其分成训练和测试集，并执行那些需要在这些集上以不同方式进行的突变：
- en: '[PRE23]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Baseline Model
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基线模型
- en: Creating a baseline model that does something really simple can give us something
    to compare our model to. Note that using the default `.score` result gives us
    the accuracy which can be misleading. A problem where a positive case is 1 in
    10,000 can easily get over 99% accuracy by always predicting negative.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个做某些非常简单的基线模型可以让我们有比较的依据。请注意，使用默认的`.score`结果给出的是准确率，这可能会误导。一个问题，其中正例是10,000中的1，通过始终预测负例很容易得到超过99%的准确率。
- en: '[PRE24]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Various Families
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同的家族
- en: This code tries a variety of algorithm families. The “No Free Lunch” theorem
    states that no algorithm performs well on all data. However, for some finite set
    of data, there may be an algorithm that does well on that set. (A popular choice
    for structured learning these days is a tree-boosted algorithm such as XGBoost.)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码尝试了多种算法家族。"没有免费午餐"定理指出，没有一个算法能在所有数据上表现良好。然而，对于某些有限的数据集，可能有一个算法能够在该集上表现良好。（这些天结构化学习的流行选择是一种树提升算法，如XGBoost。）
- en: Here we use a few different families and compare the AUC score and standard
    deviation using k-fold cross-validation. An algorithm that has a slightly smaller
    average score but tighter standard deviation might be a better choice.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用几个不同的家族，并使用k折交叉验证比较AUC得分和标准差。一个平均分数稍微低一些但标准差较小的算法可能是一个更好的选择。
- en: 'Because we are using k-fold cross-validation, we will feed the model all of
    `X` and `y`:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们使用了k折交叉验证，我们将向模型提供所有的`X`和`y`：
- en: '[PRE25]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Stacking
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 堆叠
- en: 'If you were going down the Kaggle route (or want maximum performance at the
    cost of interpretability), *stacking* is an option. A stacking classifier takes
    other models and uses their output to predict a target or label. We will use the
    previous models’ outputs and combine them to see if a stacking classifier can
    do better:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在走Kaggle的路线（或者想要以解释性为代价的最大性能），*堆叠* 是一个选项。堆叠分类器使用其他模型的输出来预测目标或标签。我们将使用之前模型的输出并将它们结合起来，看看堆叠分类器是否可以做得更好：
- en: '[PRE26]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In this case it looks like performance went down a bit, as well as standard
    deviation.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，看起来性能稍微下降了一点，以及标准差。
- en: Create Model
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建模型
- en: 'I’m going to use a random forest classifier to create a model. It is a flexible
    model that tends to give decent out-of-the-box results. Remember to train it (calling
    `.fit`) with the training data from the data that we split earlier into a training
    and testing set:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用随机森林分类器来创建一个模型。这是一个灵活的模型，往往能够给出不错的开箱即用结果。记得用我们之前拆分的训练和测试数据（调用`.fit`）来训练它：
- en: '[PRE27]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Evaluate Model
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: 'Now that we have a model, we can use the test data to see how well the model
    generalizes to data that it hasn’t seen before. The `.score` method of a classifier
    returns the average of the prediction accuracy. We want to make sure that we call
    the `.score` method with the test data (presumably it should perform better with
    the training data):'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个模型，我们可以使用测试数据来查看模型对它之前未见过的数据的泛化能力。分类器的`.score`方法返回预测准确率的平均值。我们希望确保用测试数据调用`.score`方法（假定它在训练数据上表现更好）：
- en: '[PRE28]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We can also look at other metrics, such as precision:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看其他指标，比如精确度：
- en: '[PRE29]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'A nice benefit of tree-based models is that you can inspect the feature importance.
    The feature importance tells you how much a feature contributes to the model.
    Note that removing a feature doesn’t mean that the score will go down accordingly,
    as other features might be colinear (in this case we could remove either the sex_male
    or sex_female column as they have a perfect negative correlation):'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 基于树的模型的一个好处是可以检查特征重要性。特征重要性告诉您一个特征对模型的贡献有多大。请注意，去除一个特征并不意味着分数会相应下降，因为其他特征可能是共线的（在这种情况下，我们可以删除性别_male或性别_female列，因为它们具有完美的负相关性）：
- en: '[PRE30]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The feature importance is calculated by looking at the error increase. If removing
    a feature increases the error in the model, the feature is more important.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 特征重要性是通过查看错误增加来计算的。如果去除一个特征增加了模型的错误，那么这个特征就更重要。
- en: I really like the SHAP library for exploring what features a model deems important,
    and for explaining predictions. This library works with black-box models, and
    we will show it later.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我非常喜欢SHAP库，用于探索模型认为重要的特征，并解释预测。该库适用于黑盒模型，我们稍后会展示它。
- en: Optimize Model
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化模型
- en: 'Models have *hyperparameters* that control how they behave. By varying the
    values for these parameters, we change their performance. Sklearn has a grid search
    class to evaluate a model with different combinations of parameters and return
    the best result. We can use those parameters to instantiate the model class:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 模型有控制它们行为的*超参数*。通过改变这些参数的值，我们改变它们的性能。Sklearn有一个网格搜索类来评估具有不同参数组合的模型，并返回最佳结果。我们可以使用这些参数来实例化模型类：
- en: '[PRE31]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We can pass in a `scoring` parameter to `GridSearchCV` to optimize for different
    metrics. See [Chapter 12](ch12.html#metrics1) for a list of metrics and their
    meanings.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以传递`scoring`参数给`GridSearchCV`以优化不同的指标。详见[第12章](ch12.html#metrics1)了解指标及其含义的列表。
- en: Confusion Matrix
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'A confusion matrix allows us to see the correct classifications as well as
    false positives and false negatives. It may be that we want to optimize toward
    false positives or false negatives, and different models or parameters can alter
    that. We can use sklearn to get a text version, or Yellowbrick for a plot (see
    [Figure 3-4](#id0)):'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵允许我们查看正确的分类，以及假阳性和假阴性。也许我们希望优化假阳性或假阴性，不同的模型或参数可以改变这一点。我们可以使用sklearn获取文本版本，或使用Yellowbrick进行绘图（参见[图 3-4](#id0)）：
- en: '[PRE32]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![Yellowbrick confusion matrix. This is a useful evaluation tool that presents
    the predicted class along the bottom and the true class along the side. A good
    classifier would have all of the values along the diagonal, and zeros in the other
    cells.](assets/mlpr_0304.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![Yellowbrick混淆矩阵。这是一个有用的评估工具，显示了底部的预测类别和侧面的真实类别。一个好的分类器应该在对角线上有所有的值，并且其他单元格中为零。](assets/mlpr_0304.png)'
- en: Figure 3-4\. Yellowbrick confusion matrix. This is a useful evaluation tool
    that presents the predicted class along the bottom and the true class along the
    side. A good classifier would have all of the values along the diagonal, and zeros
    in the other cells.
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. Yellowbrick混淆矩阵。这是一个有用的评估工具，显示了底部的预测类别和侧面的真实类别。一个好的分类器应该在对角线上有所有的值，并且其他单元格中为零。
- en: ROC Curve
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ROC曲线
- en: 'A receiver operating characteristic (ROC) plot is a common tool used to evaluate
    classifiers. By measuring the area under the curve (AUC), we can get a metric
    to compare different classifiers (see [Figure 3-5](#id0a)). It plots the true
    positive rate against the false positive rate. We can use sklearn to calculate
    the AUC:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 接收操作特征曲线（ROC）图是评估分类器常用的工具。通过测量曲线下面积（AUC），我们可以得到一个比较不同分类器的度量。它绘制了真正率与假阳性率。我们可以使用sklearn来计算AUC：
- en: '[PRE33]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Or Yellowbrick to visualize the plot:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 或者使用Yellowbrick来可视化绘图：
- en: '[PRE34]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![ROC curve. This shows the true positive rate against the false positive rate.
    In general, the further it bulges out the better. Measuring the AUC gives a single
    number to evaluate. Closer to one is better. Below .5 is a poor model.](assets/mlpr_0305.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![ROC曲线。显示真正率与假阳性率。一般来说，曲线越凸出越好。通过测量AUC可以得到一个评估数字。接近1表示更好。低于0.5是一个较差的模型。](assets/mlpr_0305.png)'
- en: Figure 3-5\. ROC curve. This shows the true positive rate against the false
    positive rate. In general, the further it bulges out the better. Measuring the
    AUC gives a single number to evaluate. Closer to one is better. Below .5 is a
    poor model.
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5\. ROC曲线。显示真正率与假阳性率。一般来说，曲线越凸出越好。通过测量AUC可以得到一个评估数字。接近1表示更好。低于0.5是一个较差的模型。
- en: Learning Curve
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习曲线
- en: 'A learning curve is used to tell us if we have enough training data. It trains
    the model with increasing portions of the data and measures the score (see [Figure 3-6](#id1a)).
    If the cross-validation score continues to climb, then we might need to invest
    in gathering more data. Here is a Yellowbrick example:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 学习曲线用于告诉我们是否有足够的训练数据。它使用数据的增加部分来训练模型，并测量得分（参见[图 3-6](#id1a)）。如果交叉验证得分继续上升，那么我们可能需要投资获取更多数据。以下是一个Yellowbrick示例：
- en: '[PRE35]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![This learning curve shows that as we add more training samples, our cross-validation
    (testing) scores appear to improve.](assets/mlpr_0306.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![这个学习曲线显示随着我们增加更多的训练样本，我们的交叉验证（测试）得分似乎在提高。](assets/mlpr_0306.png)'
- en: Figure 3-6\. This learning curve shows that as we add more training samples,
    our cross-validation (testing) scores appear to improve.
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-6\. 这个学习曲线显示，随着我们添加更多的训练样本，我们的交叉验证（测试）分数似乎在改善。
- en: Deploy Model
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署模型
- en: 'Using Python’s `pickle` module, we can persist models and load them. Once we
    have a model, we call the `.predict` method to get a classification or regression
    result:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python的`pickle`模块，我们可以持久化模型并加载它们。一旦我们有了一个模型，我们调用`.predict`方法来获得分类或回归结果：
- en: '[PRE36]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Using [Flask](https://palletsprojects.com/p/flask) to deploy a web service for
    prediction is very common. There are now other commercial and open source products
    coming out that support deployment. Among them are [Clipper](http://clipper.ai/),
    [Pipeline](https://oreil.ly/UfHdP), and [Google’s Cloud Machine Learning Engine](https://oreil.ly/1qYkH).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[Flask](https://palletsprojects.com/p/flask)部署预测的Web服务非常普遍。现在有其他商业和开源产品推出，支持部署。其中包括[Clipper](http://clipper.ai/)，[Pipeline](https://oreil.ly/UfHdP)，和[Google的云机器学习引擎](https://oreil.ly/1qYkH)。
- en: ^([1](ch03.html#idm46066905711928-marker)) Even though we don’t directly call
    this library, when we load an Excel file, pandas leverages it behind the scenes.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.html#idm46066905711928-marker)) 即使我们不直接调用这个库，当我们加载一个Excel文件时，pandas在后台利用它。
