- en: Chapter 2\. Strategic Steps to Innovate with Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 利用数据进行创新的战略步骤
- en: The reason your leadership is providing the funds for you to build a data platform
    is very likely because they want the organization to innovate. They want the organization
    to discover new areas to operate in, to create better ways of operating the business,
    or to serve better-quality products to more customers. Innovation of this form
    typically happens through better understanding of customers, products, or the
    market. Whether your organization wants to reduce user churn or acquire new users
    or predict the repair cycle of a product or identify whether a lower-cost alternative
    will be popular, the task starts with data collection and analysis. Data is needed
    to analyze the current state of the business, identify shortcomings or opportunities,
    implement ways to improve upon the status quo, and measure the impact of those
    changes. Often, business unit–specific data has to be analyzed in conjunction
    with other data (both from across the organization and with data from suppliers
    and marketplaces). When building a data platform, it is important to be intentional
    and keep the ultimate “why” (of fostering innovation) firmly in mind.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 您的领导之所以为您建立数据平台提供资金，很可能是因为他们希望组织进行创新。他们希望组织发现新的运营领域，创造业务运营的更好方式，或向更多客户提供更高质量的产品。这种形式的创新通常是通过更好地理解客户、产品或市场来实现的。无论您的组织是否希望减少用户流失，获取新用户，预测产品的维修周期，还是确定低成本替代品是否受欢迎，任务始于数据收集和分析。需要数据来分析业务的当前状态，识别缺陷或机会，实施改进现状的方式，并衡量这些变化的影响。通常，必须将特定于业务单元的数据与其他数据（既来自整个组织，又来自供应商和市场的数据）结合起来进行分析。在构建数据平台时，重要的是有意识地并将最终的“为什么”（促进创新）牢牢记在心中。
- en: In this chapter, you will learn the seven strategic steps to take when you are
    building a platform to foster innovation, why these steps are essential, and how
    to achieve them using present-day cloud technologies. Think of these steps as
    forming a pyramid (as depicted in [Figure 2-1](#the_seven_step_journey_we_suggest_to_bu)),
    where each step serves as the foundation for the steps that follow.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习到构建促进创新平台的七个战略步骤，为什么这些步骤至关重要，以及如何利用现代云技术实现这些步骤。将这些步骤看作是一个金字塔（如[图2-1](#the_seven_step_journey_we_suggest_to_bu)所示），其中每一步都作为后续步骤的基础。
- en: In this chapter, we will crystallize the concepts that underlie all the steps
    but defer details on their implementation to later chapters. For example, while
    we will describe the concept of breaking down silos in this chapter, we’ll describe
    the architecture of the analytics hub or data mesh approaches to do so in Chapters
    [5](ch05.html#architecting_a_data_lake), [6](ch06.html#innovating_with_an_enterprise_data_ware),
    and [7](ch07.html#converging_to_a_lakehouse).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将阐明贯穿所有步骤的概念，但将其实施细节推迟到后续章节。例如，虽然我们将在本章描述打破业务隔离的概念，但我们将在第[5](ch05.html#architecting_a_data_lake)、[6](ch06.html#innovating_with_an_enterprise_data_ware)和[7](ch07.html#converging_to_a_lakehouse)章节中描述分析中心或数据网格方法的架构。
- en: '![The seven-step journey we suggest to build a cloud data and AI platform](assets/adml_0201.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![我们建议构建云数据和AI平台的七步旅程](assets/adml_0201.png)'
- en: Figure 2-1\. The seven-step journey we suggest to build a cloud data and AI
    platform
  id: totrans-5
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-1 我们建议构建云数据和AI平台的七步旅程
- en: 'Step 1: Strategy and Planning'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一步：战略与规划
- en: 'For the final six steps to be successful, you need to first formulate a strategic
    plan wherein you identify three main components:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 要使最后六个步骤成功，首先需要制定战略计划，在这个计划中，您需要确定三个主要组成部分：
- en: Goals
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: What are the ambitions that the organization has when it comes to making the
    best use of data? It is important to dig deeper and identify goals that go beyond
    cost savings. Specifically, it is important to identify the decisions that will
    be made using the data and the metrics by which you can know the transformation
    has been successful.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在利用数据做出最佳利用时，组织的雄心是什么？深入挖掘并确定超越成本节约的目标至关重要。具体来说，重要的是确定将使用数据做出的决策以及可以通过哪些指标来知道转型是否成功。
- en: Stakeholders
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 利益相关者
- en: Who are the people in the organization who have the mandate to sponsor and drive
    deeper transformations? It is important to ensure that you bring together all
    these stakeholders—in our experience, IT projects tend to be underresourced and
    always in imminent risk of failure, whereas business-driven projects have longer-term
    executive support and funding. Business projects also have a higher return on
    investment.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 谁在组织中有权支持和推动更深层次的转型？确保你汇聚所有这些利益相关者非常重要——根据我们的经验，IT项目往往资源不足，并且总是面临失败的风险，而业务驱动的项目则拥有长期的高级管理支持和资金支持。业务项目还具有更高的投资回报率。
- en: Change management process
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 变革管理过程
- en: How do you effectively cascade and communicate the approach to the entire organization
    to get sponsorship of the final users?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如何有效地向整个组织传播并沟通方法，以获得最终用户的支持？
- en: This strategic planning needs to be periodically revisited. Are the goals still
    the same? Are there new stakeholders who need to be briefed? Is there discontent
    brewing in the ranks?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这种战略规划需要定期重新审视。目标是否依然相同？是否有新的利益相关者需要简报？是否在内部积聚不满情绪？
- en: Let’s look at these three components one by one.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐个来看这三个组成部分。
- en: Strategic Goals
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 战略目标
- en: You should be clear-headed about your goals when building a data and AI/ML platform.
    Very often, stakeholders will frame goals in terms of the limitations of the current
    platform. For example, the goal might be stated as “We want to be able to create
    monthly statements for our three million customers within three hours” if your
    current most painful problem is that reporting workloads cause cascading outages.
    However, you don’t want your goal in building a platform to be narrowly defined
    by a single use case. Instead, you want to start from a clear-headed view of the
    strategic goals you want to achieve.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建数据和AI/ML平台时，你应该对自己的目标有清晰的认识。利益相关者经常会将目标框定为当前平台的限制。例如，如果你当前最痛苦的问题是报告工作量导致连锁性故障，那么目标可能会表述为“我们希望能在三小时内为我们三百万客户创建月度结算单”。然而，在构建平台的目标时，你不希望目标被单一用例所狭隘定义。相反，你希望从对你想要实现的战略目标的清晰视角出发。
- en: Design your system based on the strategic direction of the business. What is
    the desired turnaround time for shipping information to be provided for new purchases?
    What is the anticipated growth in customer numbers? Will the mix of customers
    who arrive via mobile versus via brokers change over time? What is the expected
    headcount in the IT team? Does the business wish to enable field personnel to
    make more decisions? Do you want to send out monthly statements, or do you want
    to dynamically generate reports of historical activity on demand? How do we plan
    to make money from this reporting? Will we change our business practices based
    on these results? What do reports need to provide to support our current business
    in the field? The inability of the current platform to support these needs will
    naturally fall out from these strategic concerns, but this allows you to holistically
    frame the requirements of the system instead of being tied down by a single use
    case and old ways of thinking. This also helps you communicate the need for the
    system to nontechnical executives.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 根据企业的战略方向设计你的系统。对于为新购买提供信息的期望交付时间是多少？客户数量的预期增长是多少？通过移动设备与通过经纪人到达的客户比例会随时间而改变吗？IT团队的预期人数是多少？企业是否希望使现场人员能够做出更多决策？你希望发送月度结算单，还是希望根据需求动态生成历史活动报告？我们计划通过这些报告赚钱吗？我们是否会根据这些结果改变业务实践？报告需要提供什么支持我们当前的业务在现场？当前平台无法支持这些需求将自然地从这些战略问题中出现，但这使你能够全面地构建系统需求，而不是被单一用例和旧有思维所束缚。这也有助于你向非技术性高管传达对系统的需求。
- en: If possible, get numeric estimates for these strategic business goals over the
    next two to three years to help you make cost-effective decisions. For example,
    it can be tempting to simply say, “Queries should run as fast as possible,” but
    that is a recipe for building an overengineered and costly system. Instead, if
    you know that you will have, at peak, 1,500 concurrent queries each processing
    100 GB of data that need to take less than 10 seconds to run, you can choose technology
    that achieves your goal without breaking the bank. This also works in reverse.
    Knowing that the business is acquiring customers at a 60% year-over-year basis,
    it might be clear that the clickstream dataset is poised to be on the order of
    1 TB/day. This will prevent you from making shortsighted decisions that need to
    be unwound.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，获取未来两到三年这些战略业务目标的数值估计，以帮助您做出成本效益的决策。例如，简单地说“查询应尽可能快速运行”可能会导致建立一个过度工程化和昂贵的系统。相反，如果您知道在峰值时会有1500个并发查询，每个查询处理100
    GB的数据，需要在10秒内完成，那么您可以选择能够实现目标而不至于倾家荡产的技术。这也适用于反向情况。知道业务以60%的年增长率获取客户，可能清楚地了解到点击流数据集可能每天将达到1
    TB的规模。这将防止您做出短视的决策，需要撤销。
- en: This is often limited by the time horizon over which you can foresee business
    growth. It is also subject to real-world events. For example, the COVID-19 pandemic
    of 2020 upended many businesses’ plans and accelerated a move toward digital and
    omnichannel experiences. Sometimes, you build a system that has to be scrapped
    and rebuilt, but you can minimize how often this happens by thinking expansively
    about contingencies.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常受到您可以预见业务增长的时间范围的限制。它也受现实世界事件的影响。例如，2020年的COVID-19大流行颠覆了许多企业的计划，并加速了向数字和全渠道体验的转变。有时，您可能构建一个必须被废弃并重建的系统，但通过广泛考虑备用方案，可以减少这种情况发生的频率。
- en: 'Although the details may differ, we find that the strategic goals identified
    at most organizations ultimately require the following of their data platform:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管细节可能有所不同，但我们发现大多数组织在其数据平台上最终需要实现以下战略目标：
- en: Reduce the cost of operating the data and AI platform.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 降低运营数据和AI平台的成本。
- en: In particular, linearly growing IT costs with growth in dataset sizes can be
    unsustainable.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，随着数据集大小的增长，IT成本呈线性增长可能变得不可持续。
- en: Increase the speed of innovation by accelerating the time to get value from
    new projects.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通过加快从新项目中获取价值的时间来增加创新速度。
- en: Experimenting on new ideas should not face months-long delays procuring machines,
    installing software, getting access to datasets, etc.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在新想法上进行实验不应面临数月的延迟，如获取机器、安装软件、获取数据集访问权限等。
- en: Democratize insights from data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 民主化数据洞察。
- en: Enable domain experts and people in the field to interact with the data directly
    and gain insights.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使领域专家和领域内人员能够直接与数据互动并获得洞察。
- en: Incorporate predictive analytics, not just descriptive analytics, into decision
    making.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 将预测分析纳入决策制定，而不仅仅是描述性分析。
- en: For example, rather than simply measuring the amount of material used last week,
    predict the amount of material needed over the following week based on the amounts
    used in the recent past.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，不仅仅是测量上周使用的材料量，而是根据最近使用的量预测下周所需的材料量。
- en: The relative prioritization varies between businesses (as it should). Many startups
    and digital natives emphasize speed of innovation and flexibility to grow, whereas
    many mature enterprises emphasize cost over flexibility. For example, a startup
    might use a petabyte-scale DWH even though its data is small because it expects
    to see 10x annual growth. A more mature business might choose to use batch processing
    because it is less expensive than stream processing. These different starting
    points impact the type of innovation and growth possible—the petabyte-scale DWH
    might allow the startup to target recommendations based on every payment transaction
    as they happen, whereas the more mature business might only send recommendation
    emails daily, and only to customers who made large orders.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 相对优先级因企业而异（正常情况下应如此）。许多初创企业和数字原住民强调创新速度和灵活性的增长，而许多成熟企业则强调成本优先于灵活性。例如，一家初创企业可能会使用PB级数据仓库，即使其数据规模很小，因为它预计每年增长10倍。而一家更成熟的企业可能会选择批处理，因为它比流处理更便宜。这些不同的起点会影响可能的创新和增长类型——PB级数据仓库可以让初创企业基于每笔支付交易实时推荐，而更成熟的企业可能仅在每天发送推荐电子邮件，并且仅针对进行大笔订单的客户。
- en: Identify Stakeholders
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定利益相关者。
- en: A solid definition of the strategy starts with the correct requirements gathering.
    To do that successfully, it is incredibly important to identify the right people
    within the organization who are able to understand the needs and effectively collaborate
    across all the different business units to reduce the risk of choosing the wrong
    approach and solution. But who are the right people?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一个坚实的战略定义始于正确的需求收集。要成功做到这一点，识别组织内能够理解需求并有效跨所有不同业务单位合作以减少选择错误方法和解决方案风险的合适人员至关重要。但是，谁才是合适的人呢？
- en: Are we talking about people coming from the business (e.g., CEO or chief financial
    officer [CFO]), or is it better to rely on the IT team (e.g., CIO, CTO, chief
    data officer [CDO], etc.)? Well, it really depends on the organization. We have
    seen many different approaches, but the one common theme is that this kind of
    transformation journey usually has the highest rate of success when supported
    directly by the business. Why? Many times, the IT organization may be mandated
    only with keeping things running and reducing costs year over year. If your stakeholders
    are only in IT, their incentives are very different than if your group of stakeholders
    includes people from BUs who need to develop new products, reach more customers,
    or fundamentally change the business.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是在讨论来自业务方面的人（例如，首席执行官或首席财务官[CFO]），还是依靠IT团队（例如，首席信息官[CIO]，首席技术官[CTO]，首席数据官[CDO]等）？嗯，这实际上取决于组织的情况。我们看到了许多不同的方法，但一个共同的主题是：当直接由业务支持时，这种转型旅程通常拥有最高的成功率。为什么？很多时候，IT组织可能只被授权保持事务运行并每年降低成本。如果您的利益相关者仅来自IT部门，他们的激励与如果您的利益相关者包括需要开发新产品、吸引更多客户或从根本上改变业务的BU中的人是非常不同的。
- en: By making the definition of a new data platform more than just a pure IT activity,
    you can raise the visibility of the transformation and ensure that the new platform
    allows the organization to solve so many business problems that were not addressable
    before (e.g., real-time analysis).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将新数据平台的定义提升至不仅仅是一个纯粹的IT活动，您可以提高转型的可见度，并确保新平台使组织能够解决以前无法解决的许多业务问题（例如实时分析）。
- en: 'Even within the area of the company that supports the initiative, it is crucial
    to have full commitment from all the people involved. But these may be very busy
    people with insufficient time and expertise to spend on this transformation project.
    Therefore, another key question to ask is: does the company have enough internal
    people (with the right skills and experience) to support the initiative? Or do
    you need to get someone outside the company to steer the project in the right
    direction? It is not just a matter of technical knowledge but also a matter of
    leadership and management to ensure that the design and implementation of the
    data platform are successful and that the business outcomes are positive.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在支持该倡议的公司部门内部，也极为关键地需要来自所有参与者的全力支持。但这些人可能非常忙，没有足够的时间和专业知识来投入到这个转型项目中。因此，另一个关键问题是：公司是否拥有足够内部人员（具备正确技能和经验）来支持该倡议？还是需要从公司外部找人来引导项目朝正确方向发展？这不仅仅是技术知识的问题，还涉及领导力和管理，以确保数据平台的设计和实施成功，业务成果积极。
- en: Change Management
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变更管理
- en: Once you have identified the goals and the people who should steer toward the
    objectives, next you must define a strategy for the change management. Organizations
    can have the most ambitious goals supported by the most influential people, but
    they will have tremendous difficulty implementing the project if there is no clear
    mission to effectively cascade the message down the chain.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了目标和应该朝向目标努力的人员，接下来您必须为变更管理定义一项策略。组织可以拥有最具野心的目标，由最有影响力的人支持，但如果没有明确的使命来有效地沿链路传递消息，实施项目将非常困难。
- en: When embracing a project like data-driven transformation, we have seen so many
    companies forgetting to put the focus on the *cultural aspect* of the transformation
    and treating it as a merely technological project. Business users, and employees
    who will leverage the data platform in general, should be ready to embrace the
    change, and this can be achieved only via adequate processes and the right skills.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当接受像数据驱动转型这样的项目时，我们看到很多公司忽视了转型的*文化方面*，将其仅仅视为一个技术项目。业务用户和一般将利用数据平台的员工，应准备好接受这种变革，而这只能通过适当的流程和正确的技能来实现。
- en: 'As shown in [Figure 2-2](#peoplecomma_processcomma_and_technology), change
    management is an intersection among people, technology, and process:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [Figure 2-2](#peoplecomma_processcomma_and_technology) 所示，变更管理是人、技术和过程的交汇点：
- en: People and technology
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 人与技术
- en: It is essential to develop a comprehensive training program to enable employees
    to utilize the new resources that are made available to them within the organization.
    This can be done either by the company itself (internally delivered) or by a partner
    (externally delivered). The more emphasis organizations place on upskilling their
    workforce, the more successful they will be in achieving their overall business
    goals.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于组织内新资源的全面培训计划至关重要，以使员工能够有效利用这些资源。这可以由公司自行实施（内部交付），也可以由合作伙伴实施（外部交付）。组织越重视提升员工技能，就越能成功地实现其整体业务目标。
- en: People and process
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 人与过程
- en: 'It is always a matter of leadership. Leaders within the company have to foster
    the overall message; when people are enthused by leadership (and this is another
    link to the fact that stakeholders are super important!), the level of adoption
    increases. We have seen so many projects failing because of the lack of proper
    support from the same people who launched the initiative. It is important that
    leaders work on several internal campaigns to properly spread the message across
    the company, helping people to embrace the change. Some common questions to ask
    are: How are the teams structured? Have they got executive sponsorship? How are
    cloud projects budgeted, governed, assessed?'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这始终是领导力的问题。公司内的领导必须推动整体信息传递；当人们受到领导激励时（这也与利益相关者的重要性有关！），采纳程度就会提高。我们看到很多项目因启动方未能提供适当支持而失败。领导必须通过多个内部活动来正确传播信息，帮助员工接受变革。一些常见问题包括：团队结构如何？是否得到高层赞助？云项目的预算、治理和评估如何进行？
- en: Process and technology
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 过程与技术
- en: 'This is related to the ability of the organization to take advantage of adoption
    of cloud native services for scaling. Some common questions are: What is the extent
    to which the organization abstracts away the infrastructure with managed and serverless
    cloud services? What is the level of implementation of the automation processes
    and the programmable infrastructure code that runs through it? Automation is a
    critical asset for success because from one side it reduces the human effort,
    and in parallel it helps with making low-risk and frequent changes that are the
    key ingredients for innovation.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这与组织利用云原生服务进行扩展的能力相关。一些常见问题是：组织在多大程度上通过托管和无服务器云服务来抽象基础设施？自动化流程的实施水平以及运行其中的可编程基础设施代码如何？自动化对成功至关重要，因为它不仅减少了人力投入，同时有助于进行低风险且频繁的变更，这是创新的关键要素之一。
- en: Success requires all three elements to work together cohesively. Many organizations
    have achieved this by setting up a dedicated group of people called the *Center
    of Excellence* (CoE) whose goal is to set the direction and drive the company
    in the direction of a people-process-technology harmony. We will revisit this
    concept with a concrete example in [Chapter 12](ch12.html#data_platform_modernization_a_model_cas).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 成功需要这三个要素紧密协同工作。许多组织通过建立一个名为“卓越中心”（CoE）的专门团队来实现这一点，该团队的目标是在人、过程和技术的和谐方向上设定方向并推动公司发展。我们将在
    [第12章](ch12.html#data_platform_modernization_a_model_cas) 中通过一个具体的例子重新讨论这个概念。
- en: '![People, process, and technology working together toward success](assets/adml_0202.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![人、过程和技术共同努力实现成功](assets/adml_0202.png)'
- en: Figure 2-2\. People, process, and technology working together toward success
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-2. 人、过程和技术共同努力实现成功
- en: 'Step 2: Reduce Total Cost of Ownership by Adopting a Cloud Approach'
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二步：通过采用云方法降低总拥有成本
- en: The first step for most enterprises, after creating the strategy, is to define
    (*and find*) a budget. Moving your enterprise DWH and data lakes to the cloud
    can save you a considerable amount of the cost of a legacy implementation. Let’s
    look at why this is and how you can set yourself up for maximum savings.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数企业来说，制定战略后的第一步是定义（*并找到*）预算。将企业的数据仓库和数据湖迁移到云端可以大大节省传统实施成本。让我们看看其中的原因以及如何实现最大的节省。
- en: Why Cloud Costs Less
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为何云端成本更低
- en: 'Migrating data to the cloud can save you money due to several factors:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据迁移到云端可以通过几个因素节省费用：
- en: Reduction in operating costs
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 减少运营成本
- en: On premises, your company bears the entire cost to operate the system, and much
    of the maintenance is done manually. Cloud providers (who we will call hyperscalers),
    on the other hand, have built incredibly cost-efficient ways to manage large clusters
    of machines. Amazon, for example, brings their expertise running one of the world’s
    largest and most reliable websites in a very low-margin business to provide cloud
    infrastructure at a very low cost. Similarly, Google runs nine services that have
    to be run very efficiently because over a billion users of each of these services
    (like Search, Gmail, and YouTube) use them for free. Users of the public cloud
    benefit from the low cost due to the high degree of automation built into the
    operation of cloud services. The majority of cloud services do not require maintenance
    because most of the activities (e.g., hardware maintenance, security checks, packages
    updates, etc.) are managed automatically under the hood.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业内部，您的公司承担了操作系统的全部成本，并且大部分维护工作是手动完成的。另一方面，云服务提供商（我们称之为超大规模云服务提供商）已经建立了非常高效的方式来管理大型机群。例如，亚马逊通过运行世界上最大且最可靠的网站之一，并且在非常低的利润率业务中提供云基础设施，积累了丰富的经验。同样，谷歌运行了九项服务，这些服务必须非常高效地运行，因为每项服务（如搜索、Gmail和YouTube）每天有超过十亿用户免费使用。公共云的用户因云服务操作中内置的高度自动化而受益于低成本。由于大多数活动（如硬件维护、安全检查、软件包更新等）在幕后自动管理，大多数云服务无需维护。
- en: Right-sizing of compute and storage
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 计算和存储的合适规模化
- en: Instead of purchasing equipment that matches anticipated peak usage, cloud providers
    allow you to scale computational resources according to demand and usage. For
    example, you could start your systems small and increase the number of machines
    as the number of reports to be created grows over time. This benefit applies both
    to services from the cloud providers (such as Amazon EMR, Google Cloud Dataproc,
    and Azure HDInsight) and to third-party tools such as Databricks or Teradata Vantage
    that run on top of cloud infrastructure.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 与购买符合预期峰值使用的设备不同，云服务提供商允许根据需求和使用量扩展计算资源。例如，您可以从小规模系统开始，并随着报告数量的增加逐步增加机器数量。这一优势不仅适用于来自云服务提供商（如Amazon
    EMR、Google Cloud Dataproc和Azure HDInsight）的服务，还适用于在云基础设施上运行的第三方工具，如Databricks或Teradata
    Vantage。
- en: Autoscaling of workloads
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 工作负载的自动扩展
- en: Many cloud services (e.g., Azure Cosmos DB, AWS Aurora, Google Cloud Composer,
    Snowflake, and Actian Avalanche) allow you to assign more machines during peak
    hours and fewer machines during off-hours. Note that we said fewer machines, not
    zero. Although it can be tempting to completely shut down services during off-hours,
    consider whether you really want to retain that brick-and-mortar model. Your company’s
    website, hopefully, is not shut down at night. Your backend systems should not
    be, either. Retaining the ability to service the occasional urgent request at
    night tends to pay off in dramatic fashion.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 许多云服务（例如Azure Cosmos DB、AWS Aurora、Google Cloud Composer、Snowflake和Actian Avalanche）允许您在高峰时段分配更多机器，在低峰时段减少机器数量。请注意，我们说的是减少机器数量，而不是降至零。尽管在低峰时段完全关闭服务可能很诱人，但请考虑您是否真的希望保留传统的实体模型。希望您公司的网站不会在夜间关闭。您的后端系统也不应如此。在夜间保留处理偶尔紧急请求的能力通常能带来显著的回报。
- en: Serverless workloads
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器工作负载
- en: A few modern cloud services (e.g., BigQuery on Google Cloud Platform, Athena
    on AWS, Azure Functions) are serverless—you get to submit code and the system
    takes care of executing it for you. Think of a serverless system as an autoscaling
    cluster that is shared among all the hyperscaler’s customers. Thus, serverless
    systems bring the cost benefits of operating cloud infrastructure all the way
    up the stack. Because labor tends to be the most expensive line item on an IT
    budget, serverless cloud services lead to the most cost-effective solutions. Note
    that many vendors position their autoscaling services as “serverless,” so you
    should verify that the service in question is truly serverless—you get the cost
    benefits of serverless only if it is multitenant. If the cluster belongs to you,
    you will need to manage the cluster (for example, find out who runs what jobs
    on the cluster and when), and so you are not getting the labor cost advantage
    that accrues to serverless solutions.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一些现代云服务（例如Google Cloud平台上的BigQuery，AWS上的Athena，Azure Functions）是无服务器的——您只需提交代码，系统会为您执行。将无服务器系统视为一个共享给所有超级承载商客户的自动扩展集群。因此，无服务器系统带来了操作云基础设施的成本优势，全面提升了栈。由于劳动力往往是IT预算中最昂贵的项目，无服务器云服务导致了最具成本效益的解决方案。请注意，许多供应商将其自动扩展服务定位为“无服务器”，因此您应验证所涉服务是否真正无服务器——只有在它是多租户的情况下，您才能获得无服务器的成本优势。如果集群属于您，您将需要管理该集群（例如，了解谁在集群上运行什么作业及何时运行），因此您将无法获得无服务器解决方案所带来的劳动力成本优势。
- en: Now that you have a better understanding of why cloud may cost less, let’s have
    a look at how to estimate the amount of savings you may achieve.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您对为何云端成本较低有了更好的理解，让我们来看看如何估算您可能实现的节省金额。
- en: How Much Are the Savings?
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 节省了多少？
- en: In [Figure 2-3](#monthly_cost_left_parenthesisin_usdrigh), we have shown the
    results of a proof of concept (PoC) we carried out on a real-world data lake.
    We first moved the workload as-is to the cloud, then put it on autoscaling infrastructure,
    and finally modernized it. We measured what the cloud costs would be. Because
    this was a PoC, the systems were not run long enough in these configurations to
    measure personnel costs to operate these systems.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图2-3](#monthly_cost_left_parenthesisin_usdrigh)中，我们展示了我们在一个真实数据湖上进行的概念验证（PoC）的结果。我们首先将工作负载不加修改地移到了云端，然后放在了自动扩展基础设施上，并最终进行了现代化。我们测量了云端成本会是多少。因为这是一个概念验证，系统在这些配置下运行的时间不足以测量运营这些系统的人员成本。
- en: '![Monthly cost (in USD) of operating a 100-node data lake; personnel costs
    to operate the system not included](assets/adml_0203.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![操作100节点数据湖的月度成本（以USD计），不包括运营系统的人员成本](assets/adml_0203.png)'
- en: Figure 2-3\. Monthly cost (in USD) of operating a 100-node data lake; personnel
    costs to operate the system not included
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-3\. 操作100节点数据湖的月度成本（以USD计），不包括运营系统的人员成本
- en: Actual savings will vary, of course, depending on the specific details of your
    platform and workload. As a ballpark estimate, simply moving a workload as-is
    to the cloud tends to provide a savings of about 10%. Adding right-sizing tends
    to add an additional 5%. Autoscaling tends to add a 40% savings, and serverless
    tends to tack on an additional 30%. If you take advantage of all these savings—for
    example, by changing a workload that uses Hive on premises to using a serverless
    solution on the cloud—the cost savings can be as high as 95%. It is essential
    to analyze the source workload before migrating it to the cloud. In some cases,
    a pure lift-and-shift migration may not be beneficial because the workload was
    developed to leverage specific hardware features of the on-premises environment.
    In these cases, it is important to evaluate updating the code (when possible)
    to modernize the workload and make it able to leverage autoscaling and serverless
    capabilities.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 实际节省金额会有所不同，当然，这取决于您平台和工作负载的具体细节。粗略估计，将工作负载不加修改地迁移到云端通常能节省约10%的成本。添加适当规模调整通常可以额外节省5%。自动扩展通常能节省40%，而无服务器方案则额外增加30%的节省。如果您利用了所有这些节省方式——例如，将在本地使用Hive的工作负载改为在云端使用无服务器解决方案——成本节省可能高达95%。在迁移工作负载到云端之前，分析源工作负载是至关重要的。在某些情况下，纯粹的提升和迁移可能并不划算，因为工作负载是为了利用本地环境的特定硬件功能而开发的。在这些情况下，评估更新代码（如果可能的话）以现代化工作负载，并使其能够利用自动扩展和无服务器功能，变得尤为重要。
- en: When Does Cloud Help?
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云服务何时有助于成本节省？
- en: Adding fuel to all of this is basic cloud economics. Ignoring the impact of
    pricing discounts, it costs the same to run a job on 10 machines for 10 hours
    as it does to run the job on 100 machines for 1 hour or to run the job on 1,000
    machines for 6 minutes. The ability to give you access to 1,000 “warm” instances
    for 6 minutes out of a multitenant cluster is what makes serverless so cost-effective.
    Of course, it is not just cost—what is the business benefit of taking a job that
    takes 10 hours today and having the results be available in 6 minutes? Very often,
    what happens is that an operation that used to be done once a month gets done
    every day because the more timely decision carries a business value that far exceeds
    the increase in computational cost.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都加剧了基本的云经济学。忽略定价折扣的影响，同样的成本用于在10台机器上运行10小时的作业，与在100台机器上运行1小时的作业或在1,000台机器上运行6分钟的作业是相同的，或者在多租户集群中为您提供6分钟内访问1,000个“热”实例的能力是使无服务器如此具有成本效益的原因。当然，这不仅仅是成本问题——今天需要10小时才能完成的操作，结果在6分钟内就可以得到，这带来的商业价值往往远远超过计算成本的增加。
- en: 'What kind of workloads don’t benefit from a whole move to the cloud? From a
    general point of view, any kind of workload can be a potential target for a cloud
    environment to get all the benefits we mentioned earlier. There could be some
    cases where a hybrid approach (e.g., one part of the workload in the on-premises
    environment and the rest in the cloud), which we will explore in depth in [Chapter 9](ch09.html#extending_a_data_platform_using_hybrid),
    may have a better fit: let’s think about a workload that is consistent (i.e.,
    does not need to grow and does not have spikes), large scaled, and very specific,
    like a global-scale numerical weather forecasting model. In this case, there is
    a part of the workload that requires specialized hardware (e.g., shared memory,
    high-speed interconnects), which obviates the immediate hardware cost advantage
    of the cloud, and specialized operations personnel who understand weather models,
    and it experiences almost the same load day in and day out. This part can be retained
    on premises while having other collateral elements (e.g., data backup) that can
    immediately benefit from a cloud adoption.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 什么样的工作负载不会从整体迁移到云上受益？从一般的角度来看，任何类型的工作负载都可以成为云环境的潜在目标，以获取前面提到的所有好处。在某些情况下可能会更适合混合方法（例如，在本地环境中的一部分工作负载和其余部分在云中），我们将在[第9章](ch09.html#extending_a_data_platform_using_hybrid)深入探讨：让我们考虑一种一致的工作负载（即不需要增长且没有峰值），大规模且非常特定，例如全球范围的数值天气预报模型。在这种情况下，有一部分工作负载需要专用硬件（例如共享内存、高速互联），这消除了云的即时硬件成本优势，以及需要理解天气模型的专业操作人员，并且它几乎每天经历相同的负载。这部分可以保留在本地，同时可以立即从云采纳中受益的其他配套元素（例如数据备份）。
- en: Ephemeral and spiky workloads tend to benefit the most from a cloud move, mostly
    by reducing the need to spend valuable time doing resource provisioning. Ephemeral
    and spiky workloads will also benefit from autoscaling and the cloud economics
    of pay-for-what-you-use. So, when prioritizing a cloud move based on cost, start
    with the ephemeral and spiky workloads.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 短暂和峰值工作负载往往最能从云迁移中受益，主要通过减少耗费宝贵时间进行资源配置的需求。短暂和峰值工作负载还将从自动缩放和按需支付的云经济学中受益。因此，在基于成本的云迁移优先考虑时，首先考虑短暂和峰值工作负载。
- en: Additionally, the risk associated with employee turnover is reduced with cloud
    computing since the technology stack is well known and enterprise support is available.
    With bespoke data centers, on the other hand, your IT department may have you
    by the network cables!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，与云计算相关联的员工流失风险也减少了，因为技术栈是众所周知的，企业支持是可用的。另一方面，使用定制数据中心，您的IT部门可能会被网络电缆所困扰！
- en: 'Step 3: Break Down Silos'
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤3：打破信息孤岛
- en: Once you have migrated all your data to the cloud, you can start to look at
    how to get more value from it. One of the best ways to start getting value from
    data is to break down data silos. In other words, avoid having multiple, disjointed,
    and sometimes invisible datasets. We are now in the third level of the [Figure 2-1](#the_seven_step_journey_we_suggest_to_bu)
    pyramid.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将所有数据迁移到云上，您可以开始考虑如何从中获得更多价值。从数据中获得价值的最佳方法之一是打破数据孤岛。换句话说，避免拥有多个、不连贯的、有时不可见的数据集。我们现在处于[图2-1](#the_seven_step_journey_we_suggest_to_bu)金字塔的第三层。
- en: Breaking down data silos involves striking the right balance between decentralization
    and value. Decentralization is good because data quality reduces the farther away
    from the domain experts the data gets. So you have to give domain experts control
    over the data. Don’t centralize data in IT. At the same time, remember that you
    get the greatest AI/ML value by combining data that you have across your organization
    and even data shared by partners. Breaking silos between different parts of the
    organization is key.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 打破数据孤岛涉及在分散化和价值之间取得适当的平衡。分散化是好的，因为数据质量随着数据远离领域专家而降低。因此，您必须让领域专家对数据有控制权。不要将数据集中在IT部门。与此同时，请记住，通过组合您在整个组织中甚至合作伙伴共享的数据，您可以获得最大的AI/ML价值。打破组织不同部分之间的壁垒至关重要。
- en: How do you square this circle? How do you allow different parts of the organization
    to maintain control of their data but provide access to the data to anyone who’s
    allowed to do so? We explore how in the following section.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如何解决这个难题？如何让组织的不同部分保持对其数据的控制，同时允许任何有权限的人访问数据？我们在接下来的部分探讨如何做到这一点。
- en: Unifying Data Access
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统一数据访问
- en: What will not work is to have each team put its data on a cluster and then manage
    access to that cluster. Instead, centralize data on the cloud. Note that a centralized
    storage location does not mean a centralized ownership structure. For example,
    the data could be stored on Azure Blob Storage, but every department could put
    “their” data in “their” bucket.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 不会起作用的方法是让每个团队将其数据放在一个集群上，然后管理对该集群的访问。相反，请将数据集中存储在云上。请注意，集中存储位置并不意味着集中所有权结构。例如，数据可以存储在Azure
    Blob Storage上，但每个部门都可以将“他们的”数据放在“他们的”存储桶中。
- en: Access to data should be managed through the cloud provider’s IAM. Avoid the
    temptation of carrying over on-premises authentication mechanisms like LDAP or
    Kerberos to the cloud. If you need to maintain a hybrid infrastructure, map on-premises
    Kerberos roles to Cloud IAM. If you are using software that needs its own authentication
    mechanism (e.g., MySQL), use an authentication proxy to avoid proliferation of
    login mechanisms. Avoid using software that provides neither IAM nor proxies to
    IAM. Having data and insights locked in will cause you a lot of heartache in the
    long term, whatever that software’s near-term benefits.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 访问数据应通过云服务提供商的IAM进行管理。避免使用像LDAP或Kerberos这样的本地认证机制转移到云端的诱惑。如果需要维护混合基础设施，则将本地Kerberos角色映射到云IAM。如果使用需要自己的认证机制的软件（例如MySQL），请使用认证代理以避免登录机制的扩散。避免使用既不提供IAM也不提供IAM代理的软件。长期来看，无论软件的近期好处如何，数据和见解锁定都会给您带来很多痛苦。
- en: 'If you are multicloud, ensure that you standardize on a SaaS single sign-on
    (SSO) authentication mechanism such as Okta and then map the Okta authentication
    to each of the clouds’ IAMs. An alternative approach, if you have a “main” cloud,
    is to federate that cloud’s IAM with others: for example, you might federate Google
    Cloud Identity to use Azure Active Directory if Azure is your main cloud but you
    wish to have some data workloads on Google Cloud.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用多云解决方案，请确保标准化SaaS单点登录（SSO）认证机制，如Okta，然后将Okta认证映射到每个云的IAM。另一种方法是，如果您有一个“主要”云端，可以将该云端的IAM与其他云端进行联合：例如，如果Azure是您的主要云端，但您希望在Google
    Cloud上执行一些数据工作负载，您可以将Google Cloud Identity联合到Azure Active Directory上。
- en: Make sure that access to data is auditable based on the actual user making the
    request, not through service accounts that break the link back to an individual
    user. Because privacy and government regulations on access to data continue to
    become stricter, avoid getting locked into any software that operates in their
    own cloud project or reads data in an opaque way.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 确保根据实际用户提出请求进行数据访问审计，而不是通过破坏与个人用户之间联系的服务帐户。由于隐私和政府对数据访问的监管规定持续变得更加严格，请避免使用任何以其自己的云项目运行或以不透明方式读取数据的软件。
- en: What this means is that each department would manage their data and classify
    their data. For example, they could tag some of the columns in their DWH as containing
    financial data. The data governance policy might be that the only people allowed
    to view financial data are people in accounting and vice presidents and above.
    This policy is enforced by the IT department (not the data owner) using cloud
    IAM.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着每个部门都会管理和分类他们的数据。例如，他们可以将数据仓库中的某些列标记为包含财务数据。数据治理政策可能规定只有会计部门的人员和副总裁及以上人员才能查看财务数据。这一政策由IT部门（而非数据所有者）通过云IAM实施。
- en: Don’t fall into the temptation of centralizing the control of data to break
    down silos. Data quality reduces the further away from the domain experts you
    get. You want to make sure that domain experts create datasets and own buckets.
    This allows for local control, but access to these datasets will be controlled
    through Cloud IAM roles and permissions. The use of encryption, access transparency,
    and masking/dynamic techniques can help ensure org-wide security even if the responsibility
    of data accuracy lies with the domain teams.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 不要陷入集中控制数据以打破孤立的诱惑中。数据质量与您离开领域专家越远就会降低。您需要确保领域专家创建数据集并拥有桶。这允许本地控制，但通过Cloud IAM角色和权限控制对这些数据集的访问。即使数据准确性的责任属于领域团队，使用加密、访问透明度和掩码/动态技术可以帮助确保组织范围的安全性。
- en: Choosing Storage
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择存储
- en: Where should you store the data?
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该将数据存储在哪里？
- en: Store structured and semistructured data in a location that is optimized for
    SQL analytics. Google BigQuery, AWS Redshift, Azure Synapse, Actian Avalanche,
    Snowflake, etc., are good choices. These tools allow you to centralize the data
    and still have different datasets managed by different teams but as part of the
    same larger DWH.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化了SQL分析的位置存储结构化和半结构化数据。Google BigQuery，AWS Redshift，Azure Synapse，Actian Avalanche，Snowflake等都是不错的选择。这些工具允许您集中数据，仍然由不同团队管理不同数据集，但作为同一大型DWH的一部分。
- en: Another option is to store the structured or semistructured data in an open
    format such as Parquet using a distributed table format like Apache Iceberg or
    Databricks Delta Lake on top of a cloud blob store like AWS S3\. While you may
    take a bit of a performance hit in SQL analytics when you store data in these
    open formats (as opposed to native storage mechanisms like Capacitor in BigQuery),
    the lower cost of storage and the flexibility to support non-SQL analytics (such
    as ML) might make this a worthwhile trade-off.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是将结构化或半结构化数据存储在像Parquet这样的开放格式中，使用像Apache Iceberg或Databricks Delta Lake这样的分布式表格式，放在AWS
    S3这样的云块存储之上。虽然在SQL分析中，将数据存储在这些开放格式中可能会导致性能有所下降（与像BigQuery中的本机存储机制Capacitor相比），但存储成本较低以及支持非SQL分析（如ML）的灵活性可能会使这成为一种值得的权衡选择。
- en: Unstructured data should be stored in a format and location that is optimized
    for reading from a variety of computational engines—Spark, Beam, TensorFlow, PyTorch,
    etc. Aim to use standard cloud-friendly formats such as Parquet, Avro, TensorFlow
    Records, and Zarr and store the files on Google Cloud Storage, Azure Blob Storage,
    or AWS S3\. Comma-separated values (CSV) and JavaScript Object Notation (JSON)
    are human readable and relatively easy to process, and so have their place as
    well.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 非结构化数据应存储在优化了从各种计算引擎（如Spark、Beam、TensorFlow、PyTorch等）读取的格式和位置。目标是使用标准的云友好格式，如Parquet、Avro、TensorFlow
    Records和Zarr，并将文件存储在Google Cloud Storage、Azure Blob Storage或AWS S3上。逗号分隔值（CSV）和JavaScript对象表示法（JSON）易于阅读并且相对易于处理，因此也有它们的位置。
- en: Note
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If the data is held by a fully managed service, make sure that you have direct,
    live access to the data without having to go through its query interface. When
    using Databricks, for example, you have the option to store data as Apache Parquet
    files on any cloud storage. BigQuery, as another example, offers a Storage API
    to directly read the columnar data instead of going through its query interface
    or exporting data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据由完全托管的服务持有，请确保您可以直接、实时访问数据，而无需经过其查询接口。例如，在使用Databricks时，您可以选择将数据存储为任何云存储上的Apache
    Parquet文件。另一个例子是BigQuery，它提供了一个Storage API，可以直接读取列式数据，而不需要经过其查询接口或导出数据。
- en: Our recommendation to choose the storage layer based on type of data might seem
    surprising. Shouldn’t you store “raw” data in a data lake and “clean” data in
    a DWH? As mentioned in [Chapter 1](ch01.html#modernizing_your_data_platform_an_intro),
    data lakes and DWHs are converging, and it doesn’t make sense to treat them separately
    any more. Instead, you want to think about the characteristics of the data and
    the type of processing that you will want to do on the data. Some of your “raw”
    data, if it is structured, will be in Redshift/BigQuery, and some of your processed
    data, if unstructured, will reside in a blob storage service.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据类型选择存储层的建议可能会让人感到意外。您应该将“原始”数据存储在数据湖中，将“清洁”数据存储在DWH中吗？正如在[第1章](ch01.html#modernizing_your_data_platform_an_intro)中提到的，数据湖和DWH正在融合，将它们分开处理不再有意义。相反，您需要考虑数据的特性以及您将要在数据上执行的处理类型。如果您的“原始”数据是结构化的，则将位于Redshift/BigQuery中，如果是非结构化的，则将驻留在blob存储服务中。
- en: Typically, each analytics dataset or bucket will be in a single cloud region
    (or multi­re⁠gion such as EU or US). We term such a storage layer a *distributed
    data layer* to avoid getting sidetracked by the lake versus warehouse debate.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，每个分析数据集或存储桶都位于单个云区域（或多个区域，例如欧盟或美国）。我们将这样的存储层称为*分布式数据层*，以避免陷入湖库辩论。
- en: Encourage teams to provide wide access to their datasets (“default open”). Data
    owners control access and are responsible for classifying the data subject to
    org-wide data governance policies. Specialized teams may also have the ability
    to tag datasets (for privacy, etc.). Permissions to their datasets are managed
    by the data owners. Upskill your workforce so that they are discovering and tagging
    datasets and building integration pipelines to continually increase the breadth
    and coverage of your distributed data layer.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励团队广泛访问其数据集（“默认开放”）。数据所有者控制访问权限，并负责对符合组织范围数据治理政策的数据进行分类。专业团队还可以标记数据集（用于隐私等）。数据集的权限由数据所有者管理。提升您的工作人员技能，使他们可以发现和标记数据集，并构建集成管道，持续扩展您的分布式数据层的广度和覆盖范围。
- en: Semantic Layer
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语义层
- en: One collateral effect you may experience when you build a democratized data
    culture is that you may start to see analytics silos. The same variable may be
    called by different column names in different parts of the organization. Each
    time a key performance indicator (KPI) is calculated is one more opportunity for
    it to be calculated in a wrong or inconsistent way. So encourage data analytics
    teams to build a semantic layer^([1](ch02.html#ch01fn4)) (so that vocabularies
    can be standardized and KPIs can be computed once and reused everywhere else)
    and apply governance through it—see [Figure 2-4](#global_logical_semantic_layer_to_guaran).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当您建立民主化的数据文化时，可能会出现一个副作用，即可能开始出现分析孤立。同一个变量在组织的不同部分可能会被称为不同的列名。每次计算关键绩效指标（KPI）都是计算错误或不一致的又一机会。因此，鼓励数据分析团队建立语义层^([1](ch02.html#ch01fn4))（以标准化词汇并在其他地方重复使用KPI计算）并通过其施加治理
    — 见 [图 2-4](#global_logical_semantic_layer_to_guaran)。
- en: '![Global logical semantic layer to guarantee unified KPIs and definitions across
    the different domains](assets/adml_0204.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![跨不同领域确保统一KPI和定义的全局逻辑语义层](assets/adml_0204.png)'
- en: Figure 2-4\. Global logical semantic layer to guarantee unified KPIs and definitions
    across the different domains
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-4\. 跨不同领域确保统一KPI和定义的全局逻辑语义层
- en: Tools like Looker, Informatica, Collibra, AtScale, and Cube can help define
    and standardize the semantic layer. Using such tools has the advantage of being
    multicloud and spanning between on premises and cloud. Thus, you can standardize
    your data governance across all your environments. On the cloud, the actual queries
    are carried out by the underlying DWH, so there is no data duplication when using
    these tools to create dashboards.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 类似Looker、Informatica、Collibra、AtScale和Cube这样的工具可以帮助定义和标准化语义层。使用这些工具的优势是可以在多云和本地环境之间跨越。因此，您可以在所有环境中标准化数据治理。在云中，通过底层数据仓库执行实际查询，因此在使用这些工具创建仪表板时不会有数据重复。
- en: Do not make copies of data. Extracts and copies increase security risk, make
    data dependencies hard to track, and decrease the timeliness of analysis. Establish
    a lightweight semantic layer and bring compute to the single source of data.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 不要复制数据。提取和复制会增加安全风险，使数据依赖关系难以追踪，并降低分析的及时性。建立轻量级语义层，并将计算带到单一数据源。
- en: Note
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Regardless of where you store the data, you should bring computational resources
    to that data. For example, you might store your data on Azure Blob Storage as
    Parquet files and use Databricks or HDInsight to process the data using Spark.
    Treat compute and storage as separate, and ensure that you mix and match according
    to workload. For example, your structured data can be in BigQuery, but you can
    choose to do your processing using SQL in Big­Query, Java/Python Apache Beam in
    Cloud Dataflow, or Spark on Cloud Dataproc.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您将数据存储在何处，都应将计算资源带到数据中。例如，您可以将数据存储在Azure Blob Storage中的Parquet文件中，并使用Databricks或HDInsight使用Spark处理数据。将计算与存储分开，并根据工作负载进行混合匹配。例如，您的结构化数据可以在BigQuery中，但您可以选择使用BigQuery中的SQL进行处理，云数据流中的Java/Python
    Apache Beam，或者在Cloud Dataproc上使用Spark。
- en: There is also a trend toward providing consistent control panes across different
    environments. Google’s BigQuery Omni, for example, allows you to process data
    in AWS S3 buckets, Azure Blob Storage, and MySQL from the BigQuery interface.
    Tools like Informatica, Collibra, Looker, etc., provide a consistent interface
    to data in different clouds and on-prem environments.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个趋势是在不同环境中提供一致的控制面板。例如，Google的BigQuery Omni允许您在AWS S3存储桶、Azure Blob存储和MySQL中处理数据，都通过BigQuery界面。像Informatica、Collibra、Looker等工具为不同云和本地环境中的数据提供了一致的界面。
- en: As you have seen, removing silos is a key step in unlocking the power of the
    data because it enables better visibility and better collaboration among teams.
    Let’s see now how you can move into the next steps to leverage this amount of
    data at your disposal in an even faster way.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，消除信息孤岛是解锁数据力量的关键步骤，因为它能提升可见性并促进团队更好的协作。现在让我们看看如何进入下一步，以更快的方式利用您手头的大量数据。
- en: 'Step 4: Make Decisions in Context Faster'
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤 4：更快地在上下文中做决策
- en: The value of a business decision decreases with latency and distance. For example,
    suppose you are able to approve a loan in one minute or in one day. The one-minute
    approval is much, much more valuable than the one-day turnaround. Similarly, if
    you are able to make a decision that takes into account spatial context (whether
    it is based on where the user currently lives or where they are currently visiting),
    that decision is much more valuable than one devoid of spatial context. Therefore,
    an important modernization goal of your platform should be that you can do geographic
    information systems (GIS), streaming, and ML on data without making copies of
    the data. The principle of the previous section, of bringing compute to the data,
    should apply to GIS, streaming, and ML as well.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 业务决策的价值随着延迟和距离的增加而降低。例如，假设您能在一分钟或一天内批准贷款。一分钟批准远比一天回转更有价值。同样，如果您能做出考虑到空间上下文的决策（无论是基于用户当前居住地还是当前访问地），那么这种决策比没有空间上下文的决策更有价值。因此，您的平台的一个重要现代化目标应该是能够在不复制数据的情况下进行地理信息系统（GIS）、流媒体和机器学习（ML）。前面部分的原则，即将计算带到数据中，也应适用于GIS、流媒体和ML。
- en: Batch to Stream
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从批处理到流处理
- en: In many of the organizations that we work with, the size of data has been increasing
    between 30% and 100% year on year. Due to the power of compounding, this translates
    to planning for a 4x to 32x data growth over the next five years.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们合作的许多组织中，数据的大小每年增加30%至100%不等。由于复利的力量，这意味着在未来五年内需要规划4倍至32倍的数据增长。
- en: One of the counterintuitive aspects of a dramatic increase in data volumes is
    that it starts to make sense to process the data *more* frequently the larger
    the data volume gets. For example, suppose a business was creating a daily report
    based on its website traffic and this report took two hours to create. If the
    website traffic grows by 4x, the report will take eight hours to create unless
    the business puts four times the number of machines on the job. Rather than do
    this, an approach that makes the reports more timely is to compute statistics
    on six hours of data four times a day and aggregate these reports to create daily
    reports that are updated four times a day, as shown in [Figure 2-5](#spreading_out_processing_can_lead_to_lo).
    The computational cost of both these approaches is nearly the same, yet the second
    approach can bring considerable business benefits. Extrapolate this approach,
    and it makes sense to have a constantly updating dashboard—you can see 24-hour
    aggregates that are up-to-the-minute. As data volumes increase, many businesses
    have this conversation and change from batch data processing to stream processing.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据量显著增加的情况下，一个反直觉的方面是，随着数据量的增加，更频繁地处理数据开始变得有意义。例如，假设一个企业基于其网站流量创建每日报告，并且这份报告需要两小时才能生成。如果网站流量增长了4倍，那么生成报告将需要八个小时，除非企业将工作机器的数量增加四倍。与此相反，一个使报告更及时的方法是每天四次计算六小时的数据统计，并汇总这些报告以创建每日报告，如[图 2-5](#spreading_out_processing_can_lead_to_lo)所示。这两种方法的计算成本几乎相同，但第二种方法能带来显著的商业利益。延伸这种方法，有一个不断更新的仪表板是合理的——您可以看到最新的24小时汇总数据。随着数据量的增加，许多企业进行这种对话，并从批量数据处理转向流数据处理。
- en: '![Spreading out processing can lead to lower latencies, fewer spikes, and less
    computational overhead](assets/adml_0205.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![扩展处理可以降低延迟、减少峰值和减少计算开销](assets/adml_0205.png)'
- en: Figure 2-5\. Spreading out processing can lead to lower latencies, fewer spikes,
    and less computational overhead
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-5。扩展处理可以降低延迟、减少峰值和减少计算开销
- en: Contextual Information
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上下文信息
- en: Another key element of speeding up decision making is automating it. As data
    quality increases, or as the business changes its focus to its long tail of customers,
    there is an increasing need to cut down friction in the user experience. A frequent,
    expert user of your products will put up with a lot more than an occasional, less
    sophisticated user. Being able to catch frustrated users and provide them contextual
    help becomes important.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 加速决策的另一个关键因素是自动化。随着数据质量的提高，或者企业将焦点转向长尾客户，减少用户体验中的摩擦变得越来越重要。经常使用您产品的专业用户可以容忍比偶尔使用的不那么复杂的用户更多的问题。能够捕捉到沮丧的用户并为他们提供上下文帮助变得重要。
- en: Real-time, location-based visualizations are increasingly how decisions get
    made. In many cases, these visualizations are built into the application that
    the user is using. For example, Shopify provides vendors with graphs and charts
    that depict how their store is performing. To do this at scale, the graphics are
    actually embedded into the website, rather than being a standalone dashboard product.
    It is a best practice to ensure that location information is part of your data
    schema, whether it is the location of a store or the location of a delivery truck.
    So if your schema includes an address, make sure the schema requires that the
    address be geocoded and made to be in canonical form. It is very difficult to
    retroactively add clean geographic information to datasets.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 实时、基于位置的可视化越来越成为决策的方式。在许多情况下，这些可视化是内置到用户正在使用的应用程序中的。例如，Shopify为供应商提供显示其店铺表现的图表和图形。为了以规模做到这一点，这些图形实际上是嵌入到网站中，而不是作为独立的仪表板产品。确保位置信息成为数据模式的一部分是最佳实践，无论是店铺的位置还是交付卡车的位置。因此，如果您的模式包括地址，请确保模式要求地址进行地理编码并以规范形式呈现。在数据集中事后添加干净的地理信息非常困难。
- en: Cost Management
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本管理
- en: While few technology executives would quibble with the preceding, streaming
    has the reputation of being expensive to implement, monitor, and maintain over
    time.^([2](ch02.html#ch01fn5)) How can you enable real-time decision making without
    breaking your budget?
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然很少有技术高管会对上述观点提出异议，但流处理被认为在实施、监控和长期维护上成本高昂^([2](ch02.html#ch01fn5))。如何在不超出预算的情况下实现实时决策？
- en: First, do not build two systems, one for batch and the other for streaming.
    Instead, treat batch processing as a special case of streaming. Software tools
    like Apache Flink and Apache Beam (even Spark Structured Streaming) make this
    possible. Second, do not custom-build monitoring, observability, late arrival,
    scaling, and so on. Flink and Beam are open source technologies, but to execute
    them, leverage fully managed services such as Kinesis Data Analytics on AWS or
    Cloud Dataflow on GCP—this is because the skill to manage and troubleshoot streaming
    infrastructure is quite rare.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，不要构建两个系统，一个用于批处理，另一个用于流处理。相反，将批处理视为流处理的特殊情况。像Apache Flink和Apache Beam（甚至是Spark
    Structured Streaming）这样的软件工具使这成为可能。其次，不要自定义构建监控、可观察性、延迟到达、扩展等功能。Flink和Beam是开源技术，但要执行它们，应该利用AWS上的Kinesis数据分析或GCP上的Cloud
    Dataflow等全面托管的服务——这是因为管理和故障排除流处理基础设施的技能相当罕见。
- en: The alternate approach is to treat stream processing as a special case of batch
    (or vice versa per Flink’s philosophy). People who do this try to do micro-batching,
    by processing tiny bits of data as quickly as possible. This kind of approach
    can work when very fresh data, but not necessarily real time, is needed. It means
    that it is not acceptable to wait an hour or a day for batch processing to run,
    but at the same time it is not important to know what happened in the last few
    seconds.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是将流处理视为批处理的特殊情况（或反之，正如Flink的理念所述）。这些做法试图通过尽快处理微小数据块来进行微批处理。当需要非常新鲜的数据，但不一定是实时的时候，这种方法是有效的。这意味着不能等待一小时或一天才运行批处理，但同时也不重要知道过去几秒钟发生了什么。
- en: Next, land the streaming data into a DWH or storage tier that provides the latest
    information to readers (and is capable of handling them at scale). In other words,
    as long as you can land the data in real time, all analytics on the data will
    reflect the latest information without any further effort on your part.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将实时数据传送到支持大规模处理的DWH或存储层，为读者提供最新信息。换句话说，只要能实时传送数据，所有对数据的分析都将反映最新信息，而无需进一步努力。
- en: Now that you have seen how we can leverage up-to-date and context-related information,
    let’s have a look at how to infuse AI/ML to have a better understanding of the
    data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了如何利用最新和与上下文相关的信息，让我们看看如何融入人工智能/机器学习来更好地理解数据。
- en: 'Step 5: Leapfrog with Packaged AI Solutions'
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5步：利用封装的人工智能解决方案实现跨越式发展
- en: One of the most exciting developments in technology in the 2010s was the rise
    of deep learning, a branch of AI. AI encompasses the class of problems where a
    computer can be used as a decision-making tool. Commonly, AI systems were built
    by programming computers to think or act like humans. To do so, the thought process
    of experts had to be carefully encoded into rules that the computers could follow.
    Because humans often cannot precisely explain their judgment, such expert systems
    rarely performed very well.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在2010年代技术领域最激动人心的发展之一是深度学习的崛起，这是人工智能的一个分支。人工智能包括那些需要计算机作为决策工具的问题类别。通常情况下，人工智能系统是通过编程让计算机像人类一样思考或行动来构建的。为此，专家的思维过程必须被精确地编码为计算机可以遵循的规则。由于人类经常无法准确解释他们的判断，这样的专家系统很少表现得非常出色。
- en: ML is a class of AI techniques where, instead of capturing human logic, the
    ML “model” is shown a large number of correct decisions and the model is expected
    to infer how to make a correct decision in the future. Because collecting data
    can be easier than capturing logic, ML was able to solve a wide range of problems.
    However, the data usually had to be structured data, of the sort held in relational
    databases. In the mid-2010s, a set of techniques called deep learning achieved
    prominence. These techniques, which employed “deep neural networks,” were capable
    of understanding unstructured data like images, speech, video, natural language
    text, etc. That, in turn, has led to the development of technology like Google
    Photos (i.e., ability to search pictures using natural language queries) or Alexa
    (i.e., interaction via NLP). In the enterprise, too, deep learning has enabled
    organizations to extract information from unstructured data like product catalogs
    and user reviews. Prebuilt generative AI solutions are becoming available for
    enterprise use cases such as content creation, customer experience, coding copilots,
    and other workflow assistants.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一类人工智能技术，它不再捕捉人类的逻辑，而是向机器学习“模型”展示大量正确的决策，并期望该模型推断如何在未来做出正确的决策。因为收集数据比捕捉逻辑更容易，机器学习能够解决各种问题。然而，数据通常必须是结构化数据，类似于关系数据库中保存的数据。在2010年代中期，一组称为深度学习的技术开始占据主导地位。这些技术使用“深度神经网络”，能够理解图像、语音、视频、自然语言文本等非结构化数据。这反过来促成了像谷歌相册（即使用自然语言查询搜索图片的能力）或亚历克斯（即通过自然语言处理进行交互）等技术的发展。在企业中，深度学习还使组织能够从产品目录和用户评价等非结构化数据中提取信息。预建的生成式人工智能解决方案正在逐渐为企业使用情景（如内容创作、客户体验、编程协作伴侣和其他工作流辅助工具）所接受。
- en: 'Because AI is getting more mature, it is no longer necessary to invest considerable
    engineering time into building AI capabilities in your organization. Instead,
    you can leverage the benefits of AI through the many AI solutions that you can
    buy or customize. These fall into a few categories: predictive analytics, understanding
    and generating data, personalization, and packaged solutions.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 由于人工智能变得更加成熟，你不再需要在组织中投入大量工程时间来构建人工智能能力。相反，你可以通过购买或定制许多人工智能解决方案来利用人工智能的好处。这些解决方案可以分为几类：预测分析、数据理解与生成、个性化以及封装的解决方案。
- en: Predictive Analytics
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测分析
- en: ML models are trained from examples of correct decisions. An enterprise DWH
    is often a great source of such training examples. For example, suppose you are
    in the business of buying used cars, repairing them, and selling them. You would
    like to create a system to estimate the cost of repairing a vehicle bought at
    auction. It is clear that the historical data you have of your business is a good
    source of what the repair costs actually were for vehicles that you purchased
    and fixed up. In other words, the correct answers for historical data are present
    in the data in your DWH (see [Figure 2-6](#the_enterprise_dwh_is_a_source_of_train))
    and can be used to train an ML model. The trained ML model can then be used to
    predict the cost of repairing vehicles that subsequently come up for auction.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型是从正确决策的示例中进行训练的。企业数据仓库通常是这类训练示例的重要来源。例如，假设您从事购买二手车、修复并销售的业务。您希望创建一个系统来估算在拍卖会上购买的车辆维修成本。显然，您的业务历史数据是对您购买和修复车辆的实际维修成本的良好来源。换句话说，您的数据仓库中存在历史数据的正确答案（见[图2-6](#企业数据仓库是ML模型训练)），可以用来训练ML模型。训练好的ML模型随后可以用于预测随后拍卖的车辆的维修成本。
- en: '![The enterprise DWH is a source of training examples for ML models](assets/adml_0206.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![企业数据仓库是ML模型训练示例的来源](assets/adml_0206.png)'
- en: Figure 2-6\. The enterprise DWH is a source of training examples for ML models
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-6\. 企业数据仓库是ML模型训练示例的来源
- en: Problems like detecting a fraudulent transaction or estimating when a machine
    is going to fail, whether an ad will be clicked on, how many items will be sold,
    whether a customer will make a purchase, and so on are examples of predictive
    analytics problems. These problems can be trained by teaching the model to predict
    one value in the historical record based on the other factors that have also been
    captured.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如检测欺诈交易或估计机器故障时间、广告点击率、销售商品数量、顾客购买意愿等问题，都属于预测分析问题的例子。这些问题可以通过训练模型，使其基于已捕获的其他因素来预测历史记录中的一个值。
- en: Understanding what factors affect something like the repair cost and bringing
    all the data in the organization that bears upon this estimate into the DWH are
    prerequisites to successfully do predictive analytics. Once you have built an
    enterprise DWH, there are a large number of prebuilt forecasting solutions available
    to create the necessary model. Indeed, DWHs such as AWS Redshift and Google BigQuery
    provide the ability to train custom ML models without moving the data out of the
    DWH by connecting to AWS SageMaker and Google Cloud Vertex AI respectively.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 理解影响维修成本的因素，并将组织中与此估算相关的所有数据引入数据仓库，是成功进行预测分析的先决条件。一旦建立了企业数据仓库（DWH），就可以使用大量预先构建的预测解决方案来创建必要的模型。事实上，像AWS
    Redshift和Google BigQuery这样的数据仓库提供了在不将数据移出数据仓库的情况下训练自定义ML模型的能力，分别通过连接AWS SageMaker和Google
    Cloud Vertex AI实现。
- en: Understanding and Generating Unstructured Data
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解和生成非结构化数据
- en: 'Problems like identifying eye disease from retinal images, detecting an illegal
    left turn from a traffic camera, transcribing text from videos, and identifying
    abusive language in reviews are examples of using ML models to interpret unstructured
    data: images, videos, or natural language.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如从视网膜图像识别眼病、从交通摄像头检测非法左转、从视频中转录文本以及从评论中识别滥用语言等问题，都是利用ML模型来解释非结构化数据（图像、视频或自然语言）的例子。
- en: Deep learning has revolutionized the understanding of unstructured data, with
    each successive generation of models lowering the error rate to the point that
    products like question answering in Google Home, Smart Reply in Gmail, and photograph
    retrieval in Google Photos are highly accurate.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习彻底改变了对非结构化数据的理解，每一代模型的进步都将错误率降低到产品如Google Home中的问答、Gmail中的智能回复以及Google Photos中的照片检索极其准确的程度。
- en: Unlike with predictive analytics, it is rarely necessary to create and train
    models to understand unstructured data. Instead, prebuilt models like Azure Vision
    API, Google Video Intelligence API, and AWS Comprehend can be used as-is. Use
    these APIs to enrich your data. For example, even with no ML knowledge, a developer
    can use Google’s NLP API to extract the sentiment of reviews and add the sentiment
    as an extra column in your DWH.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 与预测分析不同，理解非结构化数据很少需要创建和训练模型。相反，可以直接使用像Azure Vision API、Google Video Intelligence
    API和AWS Comprehend这样的预构建模型。使用这些API来丰富你的数据。例如，即使没有机器学习知识，开发者也可以使用Google的NLP API提取评论的情感，并将情感作为额外列添加到你的数据仓库中。
- en: 'What if the label provided by these prebuilt models is insufficient for your
    use case? Perhaps the image recognition API returns a response indicating that
    the image contains a screw, but you want the API to return a value that it is
    Item #BD-342-AC in your catalog. Even in that case, it is not necessary to train
    models from scratch. AutoML models (i.e., a standard ML model for a problem space
    such as image recognition that can be trained with custom data) such as those
    from Google Cloud, Azure, H2O.ai, DataRobot, etc., are customizable by simply
    fine-tuning them on your own data, often with as few as a dozen examples of each
    type. AutoML models exist for images, video, and natural language. Use them to
    get high-quality customized APIs that work for your problem.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些预构建模型提供的标签不足以满足你的用例怎么办？也许图像识别API返回的响应表明图像中有一个螺丝，但你希望API返回的是你的目录中的项目编号#BD-342-AC。即使在这种情况下，也不需要从头开始训练模型。像Google
    Cloud、Azure、H2O.ai、DataRobot等提供的AutoML模型（即针对某个问题领域（如图像识别）的标准机器学习模型，可以用自定义数据进行训练）只需在自己的数据上进行微调，就可以进行定制，通常只需几十个样本即可。AutoML模型适用于图像、视频和自然语言。利用它们，可以获得高质量的定制API，满足你的问题需求。
- en: Besides interpreting unstructured data, AI techniques also exist to generate
    it. Called generative AI (we’ll discuss this further in [Chapter 10](ch10.html#ai_application_architecture)),
    it can be used to generate text, images, speech, music, and videos. Here, too,
    prebuilt (“foundational”) models exist that can already solve a wide variety of
    problems (called *zero-shot learning*). These are available through APIs from
    both cloud vendors (Azure OpenAI, Vertex AI) and independents (such as OpenAI,
    Anthropic, Midjourney, Cohere, etc.).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 除了解释非结构化数据外，人工智能技术还有生成数据的能力。称为生成式人工智能（我们将在[第10章](ch10.html#ai_application_architecture)进一步讨论），它可以用于生成文本、图像、语音、音乐和视频。在这里，也存在预构建的（“基础”）模型，这些模型已经能够解决各种问题（称为*零样本学习*）。这些模型通过云供应商（Azure
    OpenAI、Vertex AI）和独立供应商（如OpenAI、Anthropic、Midjourney、Cohere等）的API提供。
- en: In many enterprise use cases, it is necessary to integrate the data and ML platforms
    to the generative AI models to “ground” the models in reality. For example, it
    is possible to customize the behavior of foundational generative AI models by
    just passing in a few examples (called *few-shot learning*) and crafting an appropriate
    input (called a *prompt*). These examples can be obtained from the data platform.
    Frameworks such as Hugging Face and LangChain offer open source solutions to specific
    problems like question answering based on enterprise documents. This involves
    retrieving the appropriate documents, again from a data platform through a vector
    similarity search, and running the chain on the ML platform. Sometimes, these
    are available as fully managed solutions on the cloud (e.g., Google Enterprise
    Search). Finally, it is possible to fine-tune these foundational models for specific
    tasks (called *supervised fine-tuning*), and the cloud providers offer this capability
    through their ML platforms.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在许   在许多企业用例中，将数据和机器学习平台与生成式人工智能模型集成是必要的，以便将模型“嵌入”到现实中。例如，只需通过传入一些示例（称为*少样本学习*）和制作适当的输入（称为*提示*），就可以定制基础生成式人工智能模型的行为。这些示例可以从数据平台获取。像Hugging
    Face和LangChain这样的框架提供了开源解决方案，解决诸如基于企业文档的问答等特定问题。这涉及从数据平台通过向量相似度搜索检索适当的文档，然后在机器学习平台上运行链条。有时，这些服务在云上作为完全托管的解决方案（例如，Google企业搜索）提供。最后，可以针对特定任务（称为*有监督的微调*）对这些基础模型进行微调，云服务提供商通过他们的机器学习平台提供此功能。
- en: Personalization
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 个性化
- en: Rather than provide the exact same product to all users, ML offers the opportunity
    to provide a more tailored experience. Problems such as customer segmentation,
    targeting, and product recommendations fall into the category of personalization.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习不同于为所有用户提供完全相同的产品，它提供了提供更为个性化体验的机会。例如，客户细分、定位和产品推荐等问题属于个性化范畴。
- en: Personalization is driven by the historical behavior of your customers. For
    example, if you are a retailer, you might recommend products to users based on
    other people’s behavior (“People who bought this item also bought...”), based
    on their own purchase history, or based on item similarity. All this information
    is present in your enterprise DWH (or at least, it can be). Therefore, you can
    power recommendation engines off your storage engine.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 个性化是由您客户的历史行为驱动的。例如，如果您是零售商，您可以基于其他人的行为（“购买此商品的人还购买了…”）、基于他们自己的购买历史或基于商品相似性向用户推荐产品。所有这些信息都包含在您的企业数据仓库中（或至少可以）。因此，您可以基于存储引擎为推荐引擎提供动力。
- en: And indeed, Google BigQuery ML has a recommendation module, and Google’s Recommendations
    AI operates off BigQuery data. Similarly, recommendation modules in Azure Machine
    Learning operate off Azure Synapse.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Google BigQuery ML确实有一个推荐模块，Google的推荐 AI 则基于 BigQuery 数据运行。同样，Azure Machine
    Learning 中的推荐模块则基于 Azure Synapse 运行。
- en: In all three categories of AI considered in this section, it is possible to
    stand up a quick prototype in a matter of hours to days. The models all exist;
    the data requirements are not onerous, and you can train ML models with a single
    click or single SQL query.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节考虑的所有三类 AI 中，都可以在几小时到几天内快速建立原型。模型已经存在；数据需求并不繁琐，您可以通过一次点击或单个 SQL 查询训练 ML 模型。
- en: Packaged Solutions
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 封装解决方案
- en: In addition to the individual ML models and techniques discussed in the previous
    sections, always be on the lookout for packaged solutions that solve domain-specific
    problems in a turnkey way.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 除了前面讨论的个别 ML 模型和技术之外，还应该注意解决特定领域问题的封装解决方案。
- en: For example, conversational AI that interacts via natural language can accurately
    handle common, routine questions like finding out store hours of operation or
    requesting a restaurant reservation. Conversational AI is now capable of populating
    the screen of a call center support agent with suggested answers to the customer’s
    question. Such solutions are readily integrable into an enterprise’s telephone
    system.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，通过自然语言进行交互的对话 AI 能够准确处理常见的例行问题，如查询营业时间或预订餐厅。对话 AI 现在能够向呼叫中心支持代理人的屏幕推荐答案。这类解决方案可以轻松集成到企业的电话系统中。
- en: Solutions like order to cash, inventory management, shelf-out identification,
    etc., are ready to integrate into your business. Doubtless, by the time you are
    reading this, many more packaged and turnkey solutions will be available. We encourage
    you to leapfrog the limitations of what you can realistically achieve with your
    current technology stack by adopting these packaged solutions.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 例如订单到现金、库存管理、货架出库识别等解决方案，都可以直接集成到您的业务中。毫无疑问，在您阅读此文时，会有更多的封装和即插即用解决方案可用。我们鼓励您通过采纳这些封装解决方案，跨越当前技术堆栈能实现的限制。
- en: 'Step 6: Operationalize AI-Driven Workflows'
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤 6：操作化 AI 驱动的工作流程
- en: The last stage of your data platform strategy is to go beyond simple predictions
    and decisions to automating end-to-end workflows. You want to be able to solve
    business problems in a fully automated and autonomous way. For example, you don’t
    want to merely predict when a machine will fail next; you want to schedule maintenance
    for the machine before it fails. In fact, you want to do this optimally so that
    your operating cost is lower, machines last longer, and your repair facility is
    not overwhelmed. To achieve all this, you must first of all understand what level
    of automation you want to have within your organization (e.g., fully automated
    or just assistance?), and then you need to focus on building a data culture to
    build a path toward your desired goal. Last but not least, you need to reinforce
    your data scientists team that is the fuel for the realization of your AI desires.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据平台战略的最后阶段是超越简单的预测和决策，实现端到端工作流程的自动化。您希望能够以完全自动化和自主的方式解决业务问题。例如，您不仅仅希望预测下一次机器故障的时间；您希望在机器故障之前安排维护。事实上，您希望以最佳方式进行，以降低运营成本，延长机器寿命，并确保维修设施不会不堪重负。要实现所有这些目标，首先必须明确您组织内希望拥有的自动化水平（例如，完全自动化还是仅辅助？），然后需要专注于建立数据文化，为实现您的AI愿景铺平道路。最后但同样重要的是，您需要加强数据科学家团队，他们是实现您AI愿望的动力源泉。
- en: Identifying the Right Balance of Automation and Assistance
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定自动化和辅助之间的合理平衡
- en: In our experience, many organizations make many decisions in a one-off way.
    If they used a data-driven approach and invested in making those data-driven decisions
    more systematically, they would reap hefty dividends.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的经验，许多组织通常以一种临时的方式做出许多决策。如果他们采用数据驱动的方法，并投资于更系统地做出这些数据驱动决策，他们将获得丰厚的回报。
- en: Such systematic automation is one reason to break down silos, gain a consolidated
    view of data, and make prescriptive recommendations—as depicted in [Figure 2-7](#increasing_data_maturity_of_an_enterpri),
    this is the logical end station of the data transformation journey. As the data
    maturity of an enterprise deepens, leadership needs to encourage the movement
    of the enterprise from one stage to the next.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的系统自动化是打破信息孤岛、获得数据整合视图并做出建议的一个原因——正如[图 2-7](#increasing_data_maturity_of_an_enterpri)所示，这是数据转型旅程的逻辑终点。随着企业数据成熟度的提升，领导层需要鼓励企业从一个阶段向下一个阶段迈进。
- en: '![Increasing data maturity of an enterprise](assets/adml_0207.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![企业数据成熟度提升](assets/adml_0207.png)'
- en: Figure 2-7\. Increasing data maturity of an enterprise
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-7\. 企业数据成熟度提升
- en: To achieve this increasing maturity, it is necessary for both executives and
    staff to be clear-headed about what the final goal is. Is it full automation of
    decisions? Is it AI-guided decision making? In other words, are humans out of
    the loop? Or are they “over” the loop?
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这种增长的成熟度，高管和员工都需要明确最终目标是什么。是决策的全面自动化吗？是AI引导的决策吗？换句话说，人类是否完全不参与？还是他们处于“上级”地位？
- en: Consider, for example, the difference in the way navigation instructions are
    generated by Google Maps and by your nation’s air traffic control system. The
    former is an example of humans out of the loop. It is fully automated. In the
    air traffic control case, the system provides guidance, but it is a human who
    gives the final navigation instructions to landing aircraft. Of course, in both
    cases, humans receive and act on the navigation instructions.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑谷歌地图生成导航指令与您国家的空中交通管制系统生成导航指令的差异。前者是无人参与的例子。它是完全自动化的。在空中交通管制的情况下，系统提供指导，但最终导航指令是由人类发出的。当然，在两种情况下，人类都会接收并执行导航指令。
- en: The right balance of automation versus assistance is something that organizations
    usually settle on after a fair bit of experimentation. It varies from industry
    to industry and from organization to organization. The relative mix is often one
    of the ways that different businesses in the same industry compete with one another.
    As such, this is usually something that is led by product management, not engineering.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化与辅助之间的正确平衡通常需要组织进行相当多的实验后才能确定。它因行业和组织而异。相对混合通常是同行业不同企业竞争的方式之一。因此，产品管理通常主导此过程，而非工程。
- en: Building a Data Culture
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建立数据文化
- en: It will be necessary for the organization to build applications and systems
    to achieve the end goal, whether the goal is full automation or to provide assistance
    to experts. Building such a system will require the organization to inculcate
    a data culture.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 组织需要建立应用程序和系统来实现最终目标，无论目标是完全自动化还是为专家提供帮助。构建这样的系统将需要组织内树立数据文化。
- en: It is not enough to simply put in place an analytics data platform. It is also
    necessary to change the culture of the organization to one where data-driven experiments
    are the norm and successful experiments get operationalized and scaled.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅建立分析数据平台是不够的。还需要将组织的文化转变为数据驱动的实验成为常态，并且成功的实验得到操作和扩展。
- en: '[Building a data culture](https://oreil.ly/yVykJ) is key to unlocking innovation
    because you will enhance data literacy within the organization, spreading the
    knowledge needed to read and work with the data. Just because you have built a
    platform that enables data silos to be broken doesn’t mean that they will be.
    Just because decisions can be made in a data-driven manner does not mean that
    old heuristics will be easily discarded.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[构建数据文化](https://oreil.ly/yVykJ) 对于释放创新至关重要，因为这将增强组织内的数据素养，传播处理数据所需的知识。仅仅因为您建立了一个能够打破数据孤岛的平台，并不意味着它们会被打破。仅仅因为可以以数据驱动的方式做出决策，并不意味着旧的经验法则会轻易被抛弃。'
- en: Successful organizations undertake a transformation program that involves providing
    training on data tools (such as business intelligence dashboards and embedded
    analytics) to their entire creative workforce. They seek to change the way employees
    are rewarded, to encourage risk taking and entrepreneurship. They seek to put
    in place ways to measure everything that is important to the business. Finally,
    they are looking to equip their workforce with data tools so that they can effect
    change.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 成功的组织进行转型计划，涉及向其整个创意人才提供数据工具培训（如商业智能仪表板和嵌入式分析）。他们试图改变员工的奖励方式，鼓励承担风险和创业精神。他们试图建立衡量业务重要指标的方法。最后，他们试图为员工提供数据工具，以便他们能够促成变革。
- en: Populating Your Data Science Team
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建设您的数据科学团队
- en: 'There are several roles that your data platform will need to enable for your
    organization to realize value from its data and AI investments: data engineers,
    data scientists, ML engineers, developers, and domain experts. Unless all these
    groups are actively collaborating on your data platform, you cannot say that you
    have built a future-ready data platform.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 您的组织需要通过数据平台来实现其数据和人工智能投资的价值，因此需要启用几种角色：数据工程师、数据科学家、机器学习工程师、开发人员和领域专家。除非所有这些群体都在您的数据平台上积极合作，否则无法说您已经建立了一个未来准备好的数据平台。
- en: Data engineers ingest, prepare, and transform data. They use ETL tools to land
    the data in the DWH. They monitor the data pipelines to ensure that the pipelines
    are running correctly and not corrupting the data feeds.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师负责数据的摄取、准备和转换。他们使用ETL工具将数据落地到数据仓库（DWH）。他们监控数据管道，确保管道正常运行且不会破坏数据源。
- en: Data scientists carry out data analytics to help decision makers gain visibility
    into how the business is performing, answer hypotheticals, model outcomes, and
    create innovative models. A key decision maker here is the product management
    team. Data science teams do analysis that helps inform product managers on ROI
    of different items on the product roadmap. For example, a data scientist in an
    agricultural technology company might provide answers to questions about the yield
    per acre of different seeds and how it depends on the soil type. They might answer
    hypotheticals such as the anticipated profits if the product mix at a store were
    to be changed to have more of one seed than another. They might also model answers
    to questions such as the ROI of improving availability in smaller stores. Finally,
    data scientists may break down a business strategy, such as creating personalized
    harvest planning, into component models and build them.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家进行数据分析，帮助决策者了解业务的表现情况，回答假设问题，建模结果，并创建创新模型。在这里，产品管理团队是一个关键的决策者。数据科学团队进行分析，帮助产品经理评估产品路线图上不同项目的投资回报率。例如，农业技术公司的数据科学家可能回答有关不同种子每英亩产量以及它们如何依赖土壤类型的问题。他们可能回答假设问题，例如如果商店的产品组合改变为某种种子比另一种更多，预期利润会是多少。他们还可能建模回答如何提高小型店铺供应能力的问题的答案。最后，数据科学家可能会分解业务策略，例如创建个性化的收获计划，并构建组成模型。
- en: Once a model is created, it needs to be run routinely. ML engineers encapsulate
    the entire workflow in an ML pipeline and then ensure that it is executed in such
    a way that it can be monitored. Models are monitored both for resilience (Is the
    model running? Is it handling all the users requesting predictions?) and for accuracy
    (Are the results correct?). Models tend to drift over time. Sometimes this is
    because the environment itself changes (a new type of pest starts to affect a
    certain type of seed, so its yield estimates are no longer valid), and sometimes
    it is because users adapt to the model (farmers start to plant more soybeans than
    corn in response to price changes of the corresponding seed varieties, and this
    changes the demand for certain types of fertilizers). ML engineers look for such
    drift and retrain the model with new data. This is called MLOps.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型创建完成，需要定期运行。ML工程师将整个工作流封装在ML管道中，并确保以可监控的方式执行。模型在弹性（模型是否在运行？是否处理所有请求预测的用户？）和准确性（结果是否正确？）方面进行监控。模型随时间漂移。有时这是因为环境本身发生变化（新类型的害虫开始影响某种类型的种子，因此其产量估计不再有效），有时是因为用户适应了模型（农民开始根据对应种子品种价格变化调整种植大豆而非玉米，从而改变了对某些类型肥料的需求）。ML工程师寻找这种漂移并用新数据重新训练模型。这被称为MLOps。
- en: Deployed models are available as APIs. Developers invoke the models and depict
    their results in the applications that end users use.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 部署的模型可作为API提供。开发人员调用模型，并将其结果展示在最终用户使用的应用程序中。
- en: Domain experts, also known as business analysts, employ predictive analytics
    to enable data-driven decision making. Data scientists observe the decisions that
    experts make, and they look at ways to speed up the decision making by breaking
    down data silos that prevent this data from being accessed routinely. They use
    packaged AI solutions to enrich the data, and thus they continue the cycle of
    data-powered innovation.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 领域专家，也称为业务分析师，利用预测分析来实现数据驱动的决策。数据科学家观察专家们的决策，并寻找加快决策过程的方法，通过打破阻碍数据常规访问的数据孤岛来实现。他们使用打包的AI解决方案来丰富数据，从而继续数据驱动创新的循环。
- en: 'Step 7: Product Management for Data'
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7步：数据的产品管理
- en: To maximize the leverage you get from data, apply product management principles.^([3](ch02.html#ch01fn6))
    A few years ago, what many executives meant by “treating data as a product” was
    that they wanted to monetize their data directly, such as by selling it on a data
    marketplace. However, today such marketplaces tend to mostly contain data created
    by companies that specialize in aggregating data across many sources (e.g., retail
    footfall, credit card receipts, product reviews). Few companies have found success
    monetizing their first-party data.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要最大化从数据中获得的影响力，请应用产品管理原则。^([3](ch02.html#ch01fn6)) 几年前，许多高管所说的“将数据视为产品”的意思是，他们希望直接变现他们的数据，例如通过在数据市场上出售。然而，如今这样的市场主要包含由专门整合多来源数据的公司创建的数据（例如零售流量、信用卡收据、产品评论）。很少有公司成功变现其第一方数据。
- en: So what does it mean today when a typical business aspires to treat data as
    a product?
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，当今一家典型企业希望将数据视为产品时，这意味着什么？
- en: Applying Product Management Principles to Data
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将产品管理原则应用于数据
- en: Our preferred way to think about this is to combine the desired outcome and
    the process to get there. The desired outcome is that your organization will maximize
    the leverage it gets from its data by treating it as a product, and here the characteristics
    highlighted by the definitions above (usefulness, standardization, governance)
    are important. We take an expansive view of what a data product is—datasets qualify,
    but so do data pipelines, dashboards, data-reliant applications, and ML models.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们推荐的思考方式是将期望的结果与实现这一结果的过程结合起来。期望的结果是，通过将数据视为产品来最大化组织从数据中获取的影响力，而上述定义中突出的特征（有用性、标准化、治理）在此非常重要。我们对数据产品的看法是广义的——数据集是符合条件的，但数据管道、仪表板、依赖数据的应用程序和ML模型也是如此。
- en: Desired outcomes are valuable only when accompanied by a path to get there.
    To treat data as a product, apply product management principles when conceiving
    and building data products. What product management principles? (1) Have a product
    strategy, (2) be customer-centric, (3) do lightweight product discovery, and (4)
    focus on finding market fit. We recommend adopting 10 data practices (see [Figure 2-8](#product_managing_data))
    aligned to these principles.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 期望结果仅在伴随着实现路径时才有价值。要将数据视为产品，在构思和构建数据产品时应用产品管理原则。什么产品管理原则？（1）有产品战略，（2）以客户为中心，（3）进行轻量级产品发现，以及（4）专注于找到市场适配度。我们建议采用10种数据实践（参见[图2-8](#product_managing_data)），与这些原则保持一致。
- en: '![Product managing data](assets/adml_0208.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![产品管理数据](assets/adml_0208.png)'
- en: Figure 2-8\. Product managing data
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-8\. 产品管理数据
- en: 1\. Understand and Maintain a Map of Data Flows in the Enterprise
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 理解并维护企业数据流图
- en: One key job of a product manager is simplification. Treating data as a product
    means that the data product team maintains a high-level model of data flows in
    the business that can be easily communicated for discoverability. You need to
    maintain this map at multiple levels of granularity.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 产品经理的一个关键工作是简化。将数据视为产品意味着数据产品团队维护业务中数据流的高级模型，可供发现时轻松传达。您需要在多个粒度级别维护此映射。
- en: 'Imagine that you have an ecommerce site. At the highest level, for the ecommerce
    site, it might be:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个电子商务网站。在电子商务网站的最高层次上，它可能是：
- en: Web traffic
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络流量
- en: Product catalog
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品目录
- en: Web content
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Web内容
- en: Orders
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 订单
- en: Inventory
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 库存
- en: Customer survey
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户调查
- en: At the next level of granularity, web traffic might be broken down into session
    data, page data, etc. Capture how each dataset is collected, how it is processed,
    what roles can access it and how, whether personally identifiable information
    (PII) or other attributes are present, what quality assurances are made, etc.
    Also capture the production use cases for each dataset. As you go from higher
    levels of granularity to lower levels, the mapping starts to include details of
    your data platform implementation. It starts to become a data catalog.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在更精细的层次上，Web流量可能会被分解为会话数据、页面数据等。捕获每个数据集是如何收集的，它是如何处理的，可以访问它的角色是谁，以及如何访问，是否包含个人可识别信息（PII）或其他属性，做了什么质量保证等。还要捕获每个数据集的生产使用案例。随着从更高层次到更低层次的转变，映射开始包括数据平台实施的细节。它开始成为数据目录。
- en: 2\. Identify Key Metrics
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 确定关键指标
- en: 'A data catalog is simply a record of what currently exists. It does not capture
    why the data is important or whether the data is fit for purpose (unless you leverage
    ad hoc tags to do that). It doesn’t tell you what needs to be improved. An important
    part of your data product strategy is to get alignment across the enterprise on
    your key metrics—what you will measure, how you will measure it, and what the
    target number for the metric is (goals will change over time). The universe of
    metrics that you track should include:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 数据目录只是当前存在的记录。它不包括为何数据重要或数据是否适合特定目的（除非您利用临时标签来做到这一点）。它不告诉您需要改进什么。您的数据产品战略的重要部分是在企业中对关键指标达成一致——您将如何测量它们，以及该指标的目标数字是什么（目标会随时间而变化）。您跟踪的指标宇宙应包括：
- en: Business KPIs
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 业务关键绩效指标（KPIs）
- en: What business outcomes need to be enabled by data?
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 数据需要通过何种业务结果来启用？
- en: SLA
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: SLA
- en: What is the data availability? Data quality? Refresh rate?
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的可用性如何？数据质量如何？刷新频率如何？
- en: Engagement
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 参与度
- en: How widely and how often is the data used across the company?
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 公司内部数据的广泛使用频率如何？
- en: Satisfaction
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 满意度
- en: How satisfied are customers (could be internal) with what data is available
    and how easy it is to use?
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 客户对可用数据的满意度如何，以及使用起来有多容易（可能是内部客户）？
- en: For the hypothetical ecommerce site introduced in the previous step, the business
    outcomes might involve increasing customer lifetime value, increasing free-tier
    conversions, etc. The SLA for the inventory displayed to internal purchasers (for
    restocking) might be that it’s available 99.99% of the time, at an hourly refresh,
    and is maintained to be above the next week’s predicted sales. You might want
    the inventory predictions to be used not only by internal purchases but also by
    logistics teams and incorporated into dashboards. And you might have a measure
    of how often the predicted inventory amounts are overridden.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在前一步介绍的假设电子商务网站，业务结果可能涉及增加客户生命周期价值、增加免费版转化率等。向内部采购人员展示的库存的服务级别协议可能是，其可用性为99.99%，每小时刷新一次，并维持在下周预测销售额之上。您可能希望库存预测不仅被内部采购使用，还被物流团队使用，并纳入仪表板中。您可能还需要衡量预测的库存量被覆盖的频率。
- en: 3\. Agreed Criteria, Committed Roadmap, and Visionary Backlog
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 同意的标准、承诺的路线图和有远见的产品积压清单
- en: The data catalog is a record of what currently exists. The metrics capture what
    your goals are. Neither of these explains where you are going next.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 数据目录是当前存在内容的记录。度量指标捕获您的目标是什么。但这两者都没有解释接下来的方向。
- en: 'It is important to adapt the product vision over time based on customer feedback,
    stakeholder input, and market conditions. During all this, your stakeholders will
    ask you for features and timelines and expect you to keep your commitments. To
    handle change and user feedback, you need three things:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 根据客户反馈、利益相关者意见和市场条件，随着时间推移调整产品愿景非常重要。在此期间，您的利益相关者会要求您提供功能和时间表，并期望您信守承诺。为了处理变更和用户反馈，您需要三样东西：
- en: Prioritization criteria are what stakeholders agree on beforehand—this enables
    transparency and buy-in across the org on the product roadmap.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优先级标准是利益相关者事先同意的内容，这有助于在产品路线图上实现透明度和买入。
- en: The product roadmap itself is informed by a process of product discovery so
    that the team can avoid agreeing to timelines in the absence of information and
    prototyping.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品路线图本身是通过产品发现过程得出的，以便团队避免在没有信息和原型的情况下同意时间表。
- en: Things that you think are important but are yet to be roadmapped will be captured
    in a product backlog. Typically, the product backlog consists of customer problems
    that need to be solved (not features that have to be built). In many ways, the
    backlog (not the roadmap) forms your longer-term product vision. Organize the
    backlog to tell a clear story.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您认为重要但尚未在路线图上的事项将被纳入产品积压清单中。通常，产品积压清单包括需要解决的客户问题（而非必须构建的功能）。在许多方面，积压清单（而不是路线图）构成了您较长期的产品愿景。组织积压清单以讲述一个清晰的故事。
- en: The roadmap needs to be high commitment—you should be able to commit to the
    timelines and features on the roadmap. A great way to do this is to get agreement
    on prioritization criteria, do product discovery, and maintain a product backlog.^([4](ch02.html#ch01fn7))
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 路线图需要高度的承诺 —— 您应该能够承诺在路线图上的时间表和功能。实现这一目标的好方法是达成优先级标准的一致意见，进行产品发现，并维护产品积压清单。^([4](ch02.html#ch01fn7))
- en: Recalling that one of our hypothetical data products (see previous step) is
    inventory predictions for the upcoming week, we need to agree on how we measure
    how good the predictions are. Is it that we rarely run out? That we minimize the
    costs of procuring and storing the items? Is the running out at the warehouse
    level? Or at the company level? These form the prioritization criteria. If someone
    asks you to customize the inventory model for perishable goods, is it worth doing?
    You will initially add it to a product backlog. Then you’ll do product discovery
    to determine the ROI of doing such a project—this will include the cost of increasing/decreasing
    refrigeration at the warehouses, for example. Only when you know the value will
    you add this to your product roadmap.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 请回想一下我们的一个假设数据产品（参见前一步），即下周的库存预测，我们需要就如何衡量预测效果达成一致。是罕见出现缺货？是尽量减少采购和存储物品的成本？是仓库级别的缺货？还是公司级别的？这些构成了优先级标准。如果有人要求您定制易腐产品的库存模型，是否值得？您将首先将其添加到产品积压清单中。然后，您将进行产品发现，以确定此类项目的投资回报率
    —— 这将包括例如增加/减少仓库制冷成本等成本。只有在您了解其价值后，才会将其添加到产品路线图中。
- en: 4\. Build for the Customers You Have
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 为您拥有的客户构建
- en: 'Too often, data teams get caught up in technology slogans: they only provide
    APIs, or insist that everyone publishes data into their enterprise DWH, or expect
    conformance to a single dictionary.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 数据团队往往会陷入技术口号中：他们只提供API，或者坚持所有人将数据发布到他们的企业数据仓库中，或者期望符合单一词典的规范。
- en: Take a leaf out of product management and develop a deep knowledge of who your
    customers are. What are they building? A mobile app or a monthly report? What
    do they know? SQL or Java? What tools do they use? Dashboards or TensorFlow? Do
    they need alerts whenever the data changes? Do they need moving averages of the
    data in real time? Do they care about test coverage?
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 借鉴产品管理的经验，深入了解您的客户是非常重要的。他们在构建什么？一个移动应用程序还是一个月度报告？他们了解什么？SQL还是Java？他们使用什么工具？仪表板还是TensorFlow？他们是否需要在数据变更时接收警报？他们是否需要实时数据的移动平均值？他们是否关心测试覆盖率？
- en: Then, serve data in ways that your target customers can use it. For example,
    you might serve the data in a DWH (to data analysts), make it accessible via APIs
    (to developers), publish it in feature stores (to data scientists), or provide
    a semantic layer usable in dashboards (to business users).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，以目标客户可以使用的方式提供数据服务。例如，您可以将数据提供给数据仓库（供数据分析师使用），通过API可访问（供开发人员使用），发布到特征存储中（供数据科学家使用），或提供可在仪表板中使用的语义层（供业务用户使用）。
- en: If the hypothetical inventory prediction data product that we are using as our
    example will be leveraged by internal purchasers who are business users, the predictions
    will have to be served in the application that is used for ordering replenishments.
    So the predictions will likely have to be accessible via an API for the application
    developers to use.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们用作示例的假设性库存预测数据产品将由内部购买者（即业务用户）利用，那么预测结果将需要在用于订购补货的应用程序中提供。因此，预测结果可能需要通过API让应用程序开发人员使用。
- en: 5\. Don’t Shift the Burden of Change Management
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 不要转嫁变更管理的负担
- en: Change and conflict are inevitable. The suppliers of data will change formats;
    the consumers of data will have new needs; the data velocity will change; the
    same data might be provided in multiple channels; your customers will move to
    an alternate supplier due to cost. These are not solely the problem of the team
    that makes the changes or the team that uses the data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 变更和冲突是不可避免的。数据的供应商会改变格式；数据的消费者会有新的需求；数据速度会发生变化；同样的数据可能会通过多个渠道提供；由于成本，您的客户可能会转向其他供应商。这些问题不仅仅是变更团队或数据使用团队的问题。
- en: A big part of treating data as a product is to ensure that users of data are
    not stuck with change management responsibilities. As much as possible, make sure
    to evolve schema and services so that changes are transparent to downstream users.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据视为产品的重要部分是确保数据用户不要被困在变更管理责任中。尽可能确保演变模式和服务，以便变更对下游用户是透明的。
- en: When backward-incompatible change inevitably happens, version the changes and
    work with stakeholders to move them from older versions of the data to newer versions.
    This might involve creating a migration team whose job is to move the enterprise
    from one version to the next.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当不可避免地发生向后不兼容的变更时，对变更进行版本化，并与相关利益相关者合作，将它们从旧版本的数据移至新版本。这可能涉及创建一个迁移团队，其任务是将企业从一个版本迁移到下一个版本。
- en: What’s true of change management is also true of security. Make sure to build
    safeguards for PII and compliance instead of shifting the burden to users of your
    data products.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 变更管理的真理也适用于安全性。确保为个人身份识别信息（PII）和合规性构建保障措施，而不是将这一责任转嫁给您的数据产品的用户。
- en: Suppose our hypothetical inventory prediction data product is customized to
    include predictions of perishable goods. If this involves requesting additional
    information on the items being sold, you will have to take on the responsibility
    of ensuring that your item catalog is enhanced for all existing items. This data
    engineering work is part of the scoping of the project, and it feeds into the
    ROI of whether that work is worth doing.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的假设性库存预测数据产品定制为包括易腐商品的预测。如果这涉及请求关于所售商品的额外信息，您将需要承担确保所有现有商品的商品目录得到增强的责任。这些数据工程工作是项目范围的一部分，它对项目的投资回报率是否值得进行的评估起到了支持作用。
- en: 6\. Interview Customers to Discover Their Data Needs
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 采访客户，发现他们的数据需求
- en: How do you evolve the product backlog, prioritize needs, and add to the roadmap?
    An important discipline is to ensure that you are constantly talking to customers
    and discovering what data they need to solve the problems that they are encountering.
    What shortcomings of the current data products are they having to work around?
    These problems feed into your product backlog, for you to prioritize and solve.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何演变产品积压，优先需求，并添加到路线图中？一个重要的原则是确保你不断与客户交流，并发现他们需要解决的问题所需的数据是什么。当前数据产品的哪些问题他们必须解决？这些问题反馈到你的产品积压中，供你优先解决。
- en: It is important that before any new data product idea enters the product roadmap
    that the need for the product has been validated by potential (internal or external)
    customers. Building on spec (“build it and they will come”) is extremely risky.
    Much safer is to build implementations of ideas that have already been validated
    with customers.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何新数据产品概念进入产品路线图之前，重要的是通过潜在的（内部或外部）客户验证产品的需求。按规格构建（“构建它，他们就会来”）非常冒险。更安全的做法是构建已经得到客户验证的想法的实现。
- en: How do you do that?
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你怎么做到这一点？
- en: 7\. Whiteboard and Prototype Extensively
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 大量使用白板和原型
- en: Whiteboard the design of the data product with customers who want it. This ensures
    that what you land on in the data platform will meet their needs in terms of quality,
    completeness, latency, etc. Walk through potential uses of data with them before
    you build any data pipelines or transformations.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 与希望获取数据产品的客户一起用白板设计。这样可以确保你在数据平台上达成的内容能够满足他们在质量、完整性、延迟等方面的需求。在构建任何数据管道或转换之前，先与他们一起讨论数据的潜在用途。
- en: One of the best tools here is a prototype. Many use cases of data can be validated
    by building a minimum viable prototype. What do we mean? If the sales team believes
    that building a customer data platform will help them cross-sell products, validate
    this by picking up a set of records from the individual products’ sales pipelines,
    doing the match manually, and trying to cross-sell the resulting customers.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个最好的工具是原型。许多数据用例可以通过构建一个最小可行原型来验证。我们是什么意思？如果销售团队认为构建客户数据平台将有助于他们交叉销售产品，请通过从各个产品的销售管道中提取一组记录，手动匹配，并尝试交叉销售所得客户来验证这一点。
- en: 'We recommend using a prototype, plus interviews with potential users of the
    final product, to scope the problem in terms of:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议使用原型，以及与最终产品的潜在用户进行的访谈，来界定问题的范围：
- en: 'What needs to be built: identify everything, from data pipelines to user interfaces
    that are needed for the project to succeed'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要构建的内容：识别一切，从数据管道到项目成功所需的用户界面
- en: The ROI that you can expect in terms of business KPIs
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 业务关键绩效指标方面你可以期待的投资回报率
- en: Do this before you write any code. It’s only when you have a clear idea of what
    needs to be built and the expected ROI that you should add the project to your
    roadmap. Until then, keep the problem in your backlog.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写任何代码之前先做这些。只有当你清楚知道需要构建什么以及预期的投资回报率时，才应将项目添加到你的路线图中。在此之前，请将问题保留在你的积压工作中。
- en: In the case of our hypothetical inventory predictions data product, you would
    have validated the input schema and how the predictions will be used with the
    key product users, checked how much more refrigeration warehouses can accommodate,
    etc. You’ll do this before you write any code, perhaps by doing the predictions
    in a spreadsheet and game-playing the whole set of scenarios for a wide variety
    of products.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们假设的库存预测数据产品，你将通过验证输入模式及其如何与主要产品用户使用预测，检查冷藏仓库可以容纳多少等来做到这一点。你会在编写任何代码之前做这些，也许通过在电子表格中进行预测，并为各种产品的一整套情景进行游戏化处理。
- en: 8\. Build Only What Will Be Used Immediately
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 只构建即将立即使用的内容
- en: 'Prioritize going to production quickly over having all the necessary features
    built. This means that you should be using agile, iterative processes to build
    only the datasets, data pipelines, analytics, etc., that are immediately required.
    Don’t focus on developing too many features that don’t have a significant impact:
    the effort you’re putting in won’t be worth it.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 优先快速投入生产，而不是构建所有必要的功能。这意味着你应该使用敏捷、迭代的过程，只构建立即需要的数据集、数据管道、分析等。不要专注于开发太多没有重大影响的功能：你投入的努力将不值得。
- en: Use the product backlog to capture future needs. Build those capabilities only
    after you have identified customers who will use those features and can give you
    feedback in whiteboarding/prototyping sessions.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 利用产品待办事项捕捉未来需求。仅在确定将使用这些功能的客户并能在白板/原型会议上给您反馈后构建这些能力。
- en: 9\. Standardize Common Entities and KPIs
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 标准化常见实体和关键绩效指标
- en: Provide canonical, enriched datasets for common entities and KPIs that will
    be standard across the business. Usually, these enriched entities power a large
    number of high-ROI use cases (e.g., customer data platform, content management
    platform) or are required for regulatory/compliance purposes (e.g., the way to
    calculate taxes).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 为常见实体和关键绩效指标提供规范化、丰富的数据集，这些将在业务中标准化。通常，这些丰富的实体支持大量高回报投资用例（例如客户数据平台、内容管理平台）或用于监管/合规目的（例如计算税收的方法）。
- en: Typically, you’ll have only a handful of these standardized datasets and metrics
    because such enrichment requires significant collaboration across business units
    and reduces their release velocity.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您只会有少数这些标准化的数据集和指标，因为这种丰富需要跨业务单元的大量协作，并减少其发布速度。
- en: 10\. Provide Self-Service Capabilities in Your Data Platform
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10\. 在您的数据平台中提供自助服务能力
- en: You have to balance flexibility and standardization in a way that fits your
    organization. Do not go overboard with the previous step (of standardization).
    Do not build centralized datasets that have everything anyone could ever want.
    Instead, enable teams to be self-sufficient. This is the microservices principle
    as applied to data.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要在符合组织的方式中平衡灵活性和标准化。不要在上述标准化步骤中过度。不要构建每个人都可能需要的中心化数据集。相反，使团队能够自给自足。这是将微服务原则应用于数据的方式。
- en: One way to achieve this balance is to provide small, self-contained datasets
    that customers can customize by joining with other datasets in domain-specific
    ways. Often, this is implemented as a data mesh, with each business unit responsible
    for the quality of the datasets that it publishes into a shared analytics hub.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这种平衡的一种方式是提供小型、自包含的数据集，客户可以通过与领域特定的其他数据集联接来进行定制。通常，这被实现为数据网格，每个业务单元负责其发布到共享分析中心的数据集的质量。
- en: Summary
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: 'In this chapter you have understood more about the process that organizations
    should put in place to innovate with data. The key takeaways from this chapter
    are as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您已经更多了解了组织应该建立的创新数据流程。本章的主要收获如下：
- en: Create a strategic plan by identifying key business goals, gathering the right
    stakeholders, and setting in place change management across the enterprise. Ensure
    that your set of stakeholders includes the business units that will most benefit
    from the data platform if they were to adopt it.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过确定关键业务目标、收集正确的利益相关者，并在整个企业中实施变更管理来创建战略计划。确保您的利益相关者组包括如果采用数据平台将最受益的业务单元。
- en: Reduce total cost of ownership by moving to the cloud. When doing so, do not
    try to replicate the technology choices you made on premises. Instead, select
    technologies that autoscale, separate compute and storage, embrace NoOps, and
    allow you to power all sorts of applications without data movement.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过迁移到云端来降低总体拥有成本。在这样做时，不要试图复制您在本地环境中做出的技术选择。相反，选择能够自动扩展、分离计算与存储、拥抱无运维操作（NoOps），并且能够支持各种应用程序而无需数据移动的技术。
- en: Break down data silos so that data from across the organization can be joined
    together. It is important to ensure that each individual department controls its
    data and is responsible for its quality. However, all the data is available on
    a uniform platform to enable cross-organization access.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打破数据孤岛，使得整个组织的数据可以被联合起来。确保每个部门都控制其数据并对其质量负责非常重要。然而，所有数据都可以在统一平台上获取，以便实现跨组织访问。
- en: Make decisions in context faster by streaming data into your DWH in real time
    and ensuring that data access always reflects the latest data. The data tables
    should, wherever relevant, include contextual metadata such as location information.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将数据实时流入数据仓库（DWH）并确保数据访问始终反映最新数据，从而更快地在上下文中做出决策。数据表应在适当的情况下包含上下文元数据，例如位置信息。
- en: Take advantage of customizable and adaptable AI models so you don’t have to
    build bespoke AI models. These help regardless of whether your need is for predictive
    analysis, understanding unstructured data, or personalization. Predictive analytics
    and personalization can be driven from your data platform. Unstructured data can
    be added to your data platform by processing it using prebuilt AI models.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用可定制和适应性强的AI模型，您无需建立定制的AI模型。这些模型有助于预测分析、理解非结构化数据或个性化需求。预测分析和个性化可以从您的数据平台驱动。通过使用预构建的AI模型处理，可以将非结构化数据添加到您的数据平台中。
- en: Expand beyond one-off ML models and into automating entire workflows. This step
    is often led by product management, and analysis here often informs the product
    roadmap.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展至自动化整个工作流程，而非仅限于一次性机器学习模型。这一步骤通常由产品管理团队主导，并且这里的分析常常为产品路线图提供信息。
- en: Build a culture of innovation by hiring and staffing teams that consist of data
    engineers, data scientists, ML engineers, developers, and business analysts.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过雇佣和配置由数据工程师、数据科学家、机器学习工程师、开发人员和业务分析师组成的团队，建立创新文化。
- en: 'Use product management principles to formulate your data product strategy:
    be customer-centric, discover products through whiteboarding and prototyping,
    and find the right balance between standardization and flexibility.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用产品管理原则制定您的数据产品战略：以客户为中心，通过白板绘制和原型设计发现产品，并在标准化与灵活性之间找到合适的平衡点。
- en: 'In this chapter, we discussed a strategy for how to build an innovative data
    organization. In the next chapter, we’ll focus on a key aspect you have to keep
    in mind when designing your data analytics platform: skills that existing employees
    currently possess or will need to pick up.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了构建创新数据组织的策略。在下一章中，我们将专注于设计数据分析平台时需要考虑的一个关键方面：现有员工目前具备或将需要掌握的技能。
- en: ^([1](ch02.html#ch01fn4-marker)) A layer of abstraction that provides a consistent
    way to understand data. It translates complex information into familiar business
    terms such as product, customer, or revenue to offer a unified, consolidated view
    of data across the organization.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch02.html#ch01fn4-marker)) 提供一种抽象层，为理解数据提供一种统一的方式。它将复杂信息转换为熟悉的业务术语，例如产品、客户或收入，以提供组织内数据的统一和整合视图。
- en: ^([2](ch02.html#ch01fn5-marker)) Please be advised that switching from batch
    processing to streaming processing is not necessarily more expensive. In fact,
    it may save you money in the long run because you do not need to reprocess the
    same data multiple times a day with multiple batch runs. You can process it in
    real time instead.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch02.html#ch01fn5-marker)) 请注意，从批处理转换到流处理未必更加昂贵。事实上，长远来看，这可能会为您节省开支，因为您无需通过多次批处理运行多次重新处理相同的数据。您可以选择实时处理。
- en: ^([3](ch02.html#ch01fn6-marker)) This section is based on the LinkedIn post
    [“How to Treat Data as a Product”](https://oreil.ly/VvwDi) by one of the authors
    of this book.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch02.html#ch01fn6-marker)) 本节基于LinkedIn文章[“如何将数据视为产品”](https://oreil.ly/VvwDi)，该文章由本书的一位作者撰写。
- en: ^([4](ch02.html#ch01fn7-marker)) Please note that a product roadmap is a living
    document that is subject to change based on market and business requirements.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch02.html#ch01fn7-marker)) 请注意，产品路线图是一个动态的文件，根据市场和业务需求可能会有所变化。
