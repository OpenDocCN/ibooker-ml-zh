- en: Chapter 20\. AI Ethics, Fairness, and Privacy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 20 章. AI伦理、公平性与隐私
- en: In this book you’ve taken a programmer’s tour of the APIs available in the TensorFlow
    ecosystem to train models for a variety of tasks and deploy those models to a
    number of different surfaces. It’s this methodology of *training* models, using
    labeled data instead of explicitly programming logic yourself, that is at the
    heart of the machine learning and, by extension, artificial intelligence revolution.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，您已经通过TensorFlow生态系统中提供的API接口进行了程序员的讲解，以训练多种任务的模型并将这些模型部署到多个不同的平台上。正是这种*训练*模型的方法，使用标记数据而不是显式编程逻辑，这是机器学习以及人工智能革命的核心。
- en: In [Chapter 1](ch01.xhtml#introduction_to_tensorflow), we condensed the changes
    this involves for a programmer into a diagram, shown in [Figure 20-1](#traditional_programming_versus_machine_).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第一章](ch01.xhtml#introduction_to_tensorflow) 中，我们将这对程序员所涉及的变化概括成了一个图表，如 [图 20-1](#traditional_programming_versus_machine_)
    所示。
- en: '![Traditional programming versus machine learning](Images/aiml_2001.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![传统编程与机器学习对比](Images/aiml_2001.png)'
- en: Figure 20-1\. Traditional programming versus machine learning
  id: totrans-4
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-1. 传统编程与机器学习对比
- en: This leads to a new challenge. With source code, it’s possible to inspect how
    a system works by stepping through and exploring the code. But when you build
    a model, even a simple one, the outcome is a binary file consisting of the learned
    parameters within the model. These can be weights, biases, learned filters, and
    more. As a result, they can be quite obscure, leading to difficulty in interpreting
    what they do and how they work.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这带来了一个新的挑战。使用源代码，可以通过逐步执行和探索代码来检查系统的工作原理。但是，当您构建一个模型时，即使是一个简单的模型，其结果是一个包含模型内部学习参数的二进制文件。这些参数可以是权重、偏置、学习到的滤波器等。因此，它们可能非常晦涩，导致难以理解其作用和工作原理。
- en: And if we, as a society, begin to depend on trained models to help us with computing
    tasks, it’s important for us to have some level of transparency regarding how
    the models work—so it’s important for you, as an AI engineer, to understand building
    for ethics, fairness, and privacy. There’s enough to learn to fill several books,
    so in this chapter we’ll really only be scraping the surface, but I hope it’s
    a good introduction to helping you learn what you need to know.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们作为一个社会开始依赖训练模型来帮助我们进行计算任务，那么了解模型工作方式的透明度对我们非常重要——因此，作为AI工程师，了解以道德、公平和隐私为构建目标是非常重要的。有很多内容需要学习，以至于可以填满几本书，因此在本章中我们只是触及了皮毛，但我希望这能为您提供一个良好的入门，帮助您了解所需知识。
- en: 'Most importantly, building systems with a view to being fair to users isn’t
    a new thing, nor is it virtue signaling or political correctness. Regardless of
    anybody’s feelings about the importance of engineering for overall fairness, there’s
    one indisputable fact that I aim to demonstrate in this chapter: that building
    systems with a view to being both *fair* and *ethical* is the right thing to do
    from an engineering perspective and will help you avoid future technical debt.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，以用户公平为目标构建系统并不是一件新事情，也不是虚伪的表现或政治正确。无论任何人对工程整体公平性重要性的感受如何，这一章的一个不可争议的事实是：从工程角度来看，构建既
    *公平* 又 *道德* 的系统是正确的做法，并将帮助您避免未来的技术债务。
- en: Fairness in Programming
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 程序公平性
- en: While recent advances in machine learning and AI have brought the concepts of
    ethics and fairness into the spotlight, it’s important to note that disparity
    and unfairness have always been topics of concern in computer systems. In my career,
    I have seen many examples where a system has been engineered for one scenario
    without considering the overall impact with regard to fairness and bias.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最近机器学习和人工智能的进展使道德和公平的概念成为关注焦点，但需要注意的是，不平等和不公平在计算机系统中一直是关注的话题。在我的职业生涯中，我看到过许多例子，其中系统在设计某个场景时没有考虑到公平性和偏见的整体影响。
- en: 'Consider this example: your company has a database of its customers and wants
    to launch a marketing campaign to target more customers in a particular zip code
    where it has identified a growth opportunity. To do so, the company will send
    discount coupons to people in that zip code with whom it has connected, but who
    haven’t yet purchased anything. You could write SQL like this to identify these
    potential customers:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这个例子：您的公司拥有客户数据库，并希望推出一项营销活动，以在已识别增长机会的特定邮政编码区域中更多地接触客户。为此，公司将向该邮政编码区域中已经连接但尚未购买任何产品的人员发送折扣券。您可以编写如下SQL来识别这些潜在客户：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This might seem to be perfectly sensible code. But consider the demographics
    at that zip code. What if the majority of people who live there are of a particular
    race or age? Instead of growing your customer base evenly, you could be overtargeting
    one segment of the population, or worse, discriminating against another by offering
    discounts to people of one race but not another. Over time, continually targeting
    like this could result in a customer base that is skewed against the demographics
    of society, ultimately painting your company into a corner of primarily serving
    one segment of society.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来可能是非常合理的代码。但考虑一下该邮政编码的人口统计数据。如果那里的大多数居民是特定种族或年龄段的人，你可能会过度针对某个人群，或更糟糕的是，通过给某个种族提供折扣而对另一个种族不做任何优惠来进行歧视。随着时间的推移，持续这样的目标定位可能导致一个对社会人口统计数据不平衡的客户基础，最终将你的公司局限在主要服务于社会某个细分市场的境地。
- en: Here’s another example—and this one really happened to me! Back in [Chapter 1](ch01.xhtml#introduction_to_tensorflow),
    I used a few emoji to demonstrate the concept of machine learning for activity
    detection (see [Figure 20-2](#emoji_to_demonstrate_machine_learning)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一个例子——这件事真的发生在我身上！回到 [第一章](ch01.xhtml#introduction_to_tensorflow)，我使用了几个表情符号来演示活动检测的机器学习概念（见
    [图 20-2](#表情符号来演示机器学习)）。
- en: '![Emoji to demonstrate machine learning](Images/aiml_2002.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![用于演示机器学习的表情符号](Images/aiml_2002.png)'
- en: Figure 20-2\. Emoji to demonstrate machine learning
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-2\. 表示机器学习的表情符号
- en: There’s a story behind these that started several years ago. I was fortunate
    enough to visit Tokyo, and at the time I was beginning to learn how to run. A
    good friend of mine in the city invited me to run around the Imperial Palace.
    She sent a text with a couple of emoji in it that looked like [Figure 20-3](#text_containing_emoji).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这背后有一个故事，几年前开始。我有幸访问东京，当时我开始学习跑步。我在城市的一位好友邀请我绕着皇宫跑步。她发了一条带有几个表情符号的短信，看起来像是 [图
    20-3](#包含表情符号的文本)。
- en: '![Text containing emoji](Images/aiml_2003.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![包含表情符号的文本](Images/aiml_2003.png)'
- en: Figure 20-3\. Text containing emoji
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-3\. 包含表情符号的文本
- en: The text contained two emoji, a woman running and a man running. I wanted to
    reply and send the same emoji, but was doing it from a desktop chat application,
    which didn’t have the modern ability to pick an emoji from a list. If you wanted
    an emoji, you had to type a shortcode.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 文本包含两个表情符号，一个是跑步的女性，另一个是跑步的男性。我想回复并发送相同的表情符号，但是我使用的是桌面聊天应用程序，它没有现代的能力从列表中选择表情符号。如果你想要一个表情符号，你必须输入一个简码。
- en: When I typed the shortcode (running), I would get the male emoji. But if I wanted
    the female emoji, there seemed to be no way of doing it. After a bit of Googling,
    I found that I could get the female emoji by typing (running)+♀. Then the question
    became, how do you type ♀?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当我输入简码（running）时，我得到男性表情符号。但如果我想要女性表情符号，似乎没有办法做到。经过一番谷歌搜索，我发现可以通过输入 (running)+♀
    来获得女性表情符号。然后问题来了，如何输入 ♀？
- en: It depends on the operating system, but for example, on Windows you have to
    hold Alt and type 12 on the numeric keypad. On Linux you have to press Left Ctrl-Shift-U
    and then type the Unicode for the symbol, which is 2640.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这取决于操作系统，但例如在Windows上，你必须按住Alt键并在数字键盘上输入12。在Linux上，你必须按下左Ctrl-Shift-U，然后输入该符号的Unicode码，即2640。
- en: That’s a lot of work to get a female emoji, not to mention that the implicit
    declaration of a female emoji is a male one that gets modified to make it female
    with the addition of ♀. This is not inclusive programming. But how did it arise?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得女性表情符号需要这么多的工作，更不用说隐含声明一个女性表情符号是一个男性符号，通过添加 ♀ 来修改成女性。这不是包容性编程。但它是如何产生的呢？
- en: 'Consider the history of emoji. When they were first used, they were simply
    characters in text that were typed with a sideways view, like :) for smiling or
    ;) for winking, or my personal favorite *:) which looks like Ernie from *Sesame
    Street*. They’re inherently genderless because they’re so low-resolution. As emoji
    (or emoticons) evolved from characters to graphics, they were typically monochrome
    “stick man”–type illustrations. The clue is in the name—stick *man*. As graphics
    became better, particularly on mobile devices, the emoji then became clearer.
    For example, in the original iPhone OS (2.2), the running emoji (renamed “Person
    Running”) looked like this: ![Inline](Images/icon5.png).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下表情符号的历史。当它们首次使用时，它们只是文本中的字符，是侧面视图键入的，例如 :) 表示微笑或 ;) 表示眨眼，或者我个人最喜欢的 *:) ，看起来像
    Sesame Street 中的 Ernie。它们本质上是无性别的，因为它们的分辨率很低。由于表情符号（或表情符号）从字符演变为图形，它们通常是单色的“小人”类型插图。名称中的线索就在这里——小*人。随着图形的改进，特别是在移动设备上，表情符号变得更加清晰。例如，在最初的
    iPhone OS（2.2）中，跑步表情符号（重命名为“人物跑步”）看起来像这样：![内联](Images/icon5.png)。
- en: As graphics improved further and screen pixel densities increased, the emoji
    continued to evolve, and by iOS 13.3 it looked like [Figure 20-4](#person_running_emoji_from_ios_onethreed).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 随着图形的进一步改进和屏幕像素密度的增加，表情符号继续演变，到 iOS 13.3 时看起来像[图 20-4](#person_running_emoji_from_ios_onethreed)。
- en: '![Person Running emoji from iOS 13.3](Images/aiml_2004.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![iOS 13.3 中的人物跑步表情符号](Images/aiml_2004.png)'
- en: Figure 20-4\. Person Running emoji from iOS 13.3
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-4\. iOS 13.3 中的人物跑步表情符号
- en: When it comes to engineering, as well as improving the graphics, it’s important
    to maintain *backward compatibility*—so if earlier versions of your software used
    the shortcode (running) to indicate a stick man running, later versions with richer
    graphics can give you a graphic like this one, which is now very clearly a man
    running.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在工程方面，除了改进图形外，保持*向后兼容性*也非常重要——因此，如果您的软件的早期版本使用简码（running）来表示小人跑步，那么具有更丰富图形的后续版本可以为您提供这样一个图形，现在非常明显是一个男性在跑步。
- en: 'Consider what this would look like in pseudocode:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下这在伪代码中会是什么样子：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is well-engineered code because it maintains backward compatibility as
    the graphic changes. You never need to update your code for new screens and new
    graphics; you just change the `personRunning` resource. But the *effect* changes
    for your end users, so you then identify that you also need to have a Woman Running
    emoji to be fair.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这是良好设计的代码，因为它在图形变化时保持了向后兼容性。您永远不需要为新屏幕和新图形更新代码；您只需更改`personRunning`资源即可。但是对于您的最终用户来说，*效果*会发生变化，因此您随后确定您还需要有一个女性跑步表情符号以保持公平。
- en: 'You can’t use the same shortcode, however, and you don’t want to break backward
    compatibility, so you have to amend your code, maybe to something like this:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 但是您不能使用相同的简码，也不想破坏向后兼容性，因此您必须修改您的代码，也许类似于这样：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: From a coding perspective, this makes sense. You can provide the additional
    functionality without breaking backward compatibility, and it’s easy to remember—if
    you want a female runner you use a female Venus symbol. But life isn’t just from
    a coding perspective, as this example shows. Engineering like this led to a runtime
    environment that adds excess friction to the use cases of a significant portion
    of the population.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 从编码的角度来看，这是有道理的。你可以提供额外的功能而不会破坏向后兼容性，而且很容易记住——如果你想要一个女性跑步者，你可以使用女性金星符号。但生活并不仅仅是从编码的角度来看，正如这个例子所示。这样的工程设计导致了运行时环境对大部分人口的使用案例增加了过多的摩擦。
- en: The technical debt incurred from the beginning, when gender equality wasn’t
    considered when creating emoji, still lingers to this day in workarounds like
    this. Check the [Woman Running page](https://oreil.ly/o6O8g) on Emojipedia, and
    you’ll see that this emoji is defined as a zero-width joiner (ZWJ) sequence that
    combines Person Running, a ZWJ, and a Venus symbol. The only way to try to give
    end users the proper experience of having a female running emoji is to implement
    a workaround.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从一开始，在创建表情符号时并未考虑到性别平等所产生的技术债务，直到今天仍然存在，像这样的解决方案仍然存在。查看Emojipedia上的[女性跑步页面](https://oreil.ly/o6O8g)，您会看到这个表情符号被定义为零宽连接器（ZWJ）序列，将人物跑步、ZWJ和金星符号组合在一起。尝试为最终用户提供正确的女性跑步表情符号体验的唯一方法是实施解决方案。
- en: Fortunately, as many apps that offer emoji now use a selector where you choose
    it from a menu, as opposed to typing a shortcode, the issue has become somewhat
    hidden. But it’s still there under the surface, and while this example is rather
    trivial, I hope it demonstrates how past decisions that didn’t consider fairness
    or bias can have ramifications further down the line. Don’t sacrifice your future
    to save your present!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，现在许多提供表情符号的应用程序使用选择器，你可以从菜单中选择表情符号，而不是输入简码，这个问题已经在某种程度上隐藏起来。但它仍然潜藏在表面之下，虽然这个例子相当微不足道，但我希望它能展示出过去未考虑公平性或偏见的决策如何在后续产生影响。不要为了现在的利益牺牲你的未来！
- en: So, back to AI and machine learning. As we’re at the dawn of a new age of application
    types, it’s vitally important for you to consider all aspects of the use of your
    application. You want to ensure that fairness is built in as much as possible.
    You also want to ensure that bias is avoided as much as possible. It’s the right
    thing to do, and it can help avoid the technical debt of future workarounds.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，回到人工智能和机器学习。因为我们正处在应用类型新时代的黎明时期，对于你考虑应用程序使用的所有方面至关重要。你希望尽可能地确保公平性内置。你还希望尽可能避免偏见。这是正确的做法，可以帮助避免未来解决方案的技术债务。
- en: Fairness in Machine Learning
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的公平性
- en: 'Machine learning systems are data-driven, not code-driven, so identifying biases
    and other problematic areas becomes an issue of understanding your data. It requires
    tooling to help you explore your data and see how it flows through a model. Even
    if you have excellent data, a poorly engineered system could lead to issues. The
    following are some tips to consider when building ML systems that can help you
    avoid such issues:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统是数据驱动的，而不是代码驱动的，因此识别偏见和其他问题区域成为理解你的数据的问题。需要工具来帮助你探索数据，看看它如何通过模型流动。即使你有优秀的数据，一个工程不良的系统也可能导致问题。以下是一些在构建机器学习系统时需要考虑的提示，可以帮助你避免这些问题：
- en: Determine if ML is actually necessary
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 确定机器学习是否真的必要
- en: It might go without saying, but, as new trends hit the technology market, there’s
    always pressure to implement them. There’s often a push from investors, or from
    sales channels or elsewhere, to show that you are cutting-edge and using the latest
    and greatest. As such, you may be given the requirement to incorporate machine
    learning into your product. But what if it isn’t necessary? What if, in order
    to hit this nonfunctional requirement, you paint yourself into a corner because
    ML isn’t suited to the task, or because while it might be useful in the future,
    you don’t have adequate data coverage right now?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当新趋势冲击技术市场时，通常存在施加压力的情况来实施这些趋势。投资者、销售渠道或其他地方往往会推动你展示自己是前沿并使用最新最好的技术。因此，你可能被要求将机器学习整合到你的产品中。但如果这并非必要呢？如果为了满足这个非功能性需求，你却因为机器学习不适合这项任务，或者因为虽然它可能在未来有用，但你现在没有足够的数据覆盖率，而把自己逼入死胡同呢？
- en: I once attended a student competition where the participants took on the challenge
    of image generation using generative adversarial networks (GANs) to predict what
    the lower half of a face looks like based on the upper half of the face. This
    was during a flu season before COVID-19, and, in a classic example of Japanese
    grace, many people were wearing face masks. The idea was to see if one could predict
    the face below the mask. For this task they needed access to facial data, so they
    used the IMDb dataset of [face images with age and gender labels](https://oreil.ly/uUIV6).
    The problem? Given that the source is IMDb, the vast majority of the faces in
    this dataset are not Japanese. As such, their model did a great job of predicting
    *my* face, but not their own. In the rush to produce an ML solution when there
    wasn’t adequate data coverage, the students produced a biased solution. This was
    just a show-and-tell competition, and their work was brilliant, but it was a great
    reminder that rushing to market with an ML product when one isn’t necessarily
    needed, or when there isn’t sufficient data to build a proper model, can lead
    you down the road of building biased models and incurring heavy future technical
    debt.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾参加过一个学生竞赛，参赛者挑战使用生成对抗网络（GANs）生成图像，根据脸部的上半部分预测下半部分的样子。那是在COVID-19之前的流感季节，许多人戴着口罩，体现了日本人的经典风度。他们的想法是看看是否能预测口罩下面的脸部。为此，他们需要访问面部数据，所以他们使用了带有年龄和性别标签的IMDb数据集中的[面部图像](https://oreil.ly/uUIV6)。问题在于？考虑到数据来源是IMDb，这个数据集中绝大多数的面孔并不是日本人。因此，他们的模型在预测*我的*脸时表现出色，但对他们自己的脸却不够准确。在没有足够数据覆盖的情况下，匆忙推出机器学习解决方案会导致产生偏见的解决方案。这只是一个展示竞赛，他们的工作非常出色，但它也是一个很好的提醒：在没有真正需要的情况下或者没有足够的数据来构建适当的模型时，急于将机器学习产品推向市场，可能会导致建立偏见模型并承担未来严重的技术债务的风险。
- en: Design and implement metrics from day one
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从第一天起设计并实施度量标准。
- en: Or maybe that should read from day zero, as we’re all programmers here. In particular,
    if you are amending or upgrading a non-ML system to add ML, you should do as much
    as you can to track how your system is currently being used. Consider the emoji
    story from earlier as an example. If people had identified early on—given there
    are as many female runners as male runners—that having a male Person Running emoji
    was a user experience mistake, then a problem might never have arisen at all.
    You should always try to understand your users’ needs so that as you design a
    data-oriented architecture for ML, you can ensure that you have adequate coverage
    to meet these needs, and possibly predict future trends and get ahead of them.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 或者说，从零开始，因为我们都是程序员。特别是，如果您正在修改或升级非机器学习系统以添加机器学习功能，则应尽可能跟踪当前系统的使用情况。考虑之前的表情符号故事作为一个例子。如果人们早早地意识到——因为女性跑步者和男性跑步者一样多——拥有一个男性跑步者表情符号是一个用户体验的错误，那么问题可能根本就不会出现。您应该始终尝试了解用户的需求，以便在为机器学习设计数据导向架构时，确保您有足够的覆盖范围来满足这些需求，并可能预测未来的趋势并超前应对。
- en: Build a minimum viable model and iterate
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个最小可行模型并进行迭代。
- en: You should experiment with building a minimum viable model *before* you set
    any expectations about deploying ML models into your system. ML and AI are not
    a magic solution for everything. Given the data at hand, build a minimum viable
    product (MVP) that gets you on the road to having ML in your system. Does it do
    the job? Do you have a pathway to gathering more of the data needed to extend
    the system while keeping it fair for all users? Once you have your MVP, iterate,
    prototype, and continue to test before rushing something to production.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在您设定任何部署机器学习模型到系统中的期望之前，您应该尝试构建一个最小可行模型*。机器学习和人工智能并非万能解决方案。在手头的数据基础上，构建一个能让您开始将机器学习应用到系统中的最小可行产品（MVP）。它能胜任工作吗？您有获取更多所需数据以扩展系统的路径吗？同时保持公平对待所有用户？一旦有了您的MVP，进行迭代、原型设计，并继续测试，而不是仓促投入生产。
- en: Ensure your infrastructure supports rapid redeployment
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您的基础设施支持快速重新部署。
- en: Whether you are deploying your model to a server with TensorFlow Serving, to
    mobile devices with TensorFlow Lite, or to browsers with TensorFlow.js, it’s important
    to keep an eye on how you can *redeploy* the model if needed. If you hit a scenario
    where it is failing (for any reason, not just bias), it’s good to have the ability
    to rapidly deploy a new model without breaking your end users’ experience. Using
    a configuration file with TensorFlow Serving, for example, allows you to define
    multiple models with named values that you can use to rapidly switch between them.
    With TensorFlow Lite, your model is deployed as an asset, so instead of hardcoding
    that into your app, you might want the app to check the internet for updated versions
    of the model and update if it detects one. In addition, abstracting the code that
    runs inference with a model—avoiding hardcoded labels, for example—can help you
    to avoid regression errors when you redeploy.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您将模型部署到使用 TensorFlow Serving 的服务器，使用 TensorFlow Lite 的移动设备，还是使用 TensorFlow.js
    的浏览器中，都需要注意如何在需要时重新部署模型的能力。如果遇到失败的情况（不仅仅是偏见），能够快速部署新模型而不会影响到最终用户的体验是非常重要的。例如，使用
    TensorFlow Serving 的配置文件允许您定义多个带有命名值的模型，以便快速在它们之间进行切换。对于 TensorFlow Lite，您的模型被部署为一个资产，因此不需要将其硬编码到应用程序中，您可以让应用程序检查互联网上是否有更新版本的模型，并在检测到更新时进行更新。此外，通过抽象运行推断的代码（例如避免硬编码的标签），可以帮助您避免重新部署时的回归错误。
- en: Tools for Fairness
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 公平性工具
- en: There’s a growing market for tooling for understanding the data used to train
    models, the models themselves, and the inference output of the models. We’ll explore
    a few of the currently available options here.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个不断增长的工具市场，用于理解训练模型使用的数据、模型本身以及模型推断的输出。我们将在这里探讨一些当前可用的选项。
- en: The What-If Tool
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是工具？
- en: One of my favorites is the What-If Tool from Google. Its aim is to let you inspect
    an ML model with minimal coding required. With this tool, you can inspect the
    data and the output of the model for that data together. It has a [walkthrough](https://oreil.ly/sRv23)
    that uses a model based on about 30,000 records from the 1994 US Census dataset
    that is trained to predict what a person’s income might be. Imagine, for example,
    that this is used by a mortgage company to determine whether a person may be able
    to pay back a loan, and thus to determine whether or not to grant them the loan.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我最喜欢的之一是来自 Google 的 What-If 工具。它的目标是让您无需编写大量代码即可检查 ML 模型。通过这个工具，您可以同时检查数据和模型对该数据的输出。它有一个[演示](https://oreil.ly/sRv23)，使用基于
    1994 年美国人口普查数据集的约 30,000 条记录的模型进行训练，该模型旨在预测一个人的收入可能是多少。例如，想象一下，这被一家抵押贷款公司用来确定一个人是否有能力偿还贷款，从而决定是否授予他们贷款。
- en: One part of the tool allows you to select an inference value and see the data
    points from the dataset that led to that inference. For example, consider [Figure 20-5](#using_the_what_if_tool).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 工具的一部分允许您选择一个推断值，并查看导致该推断的数据集中的数据点。例如，请参考[图 20-5](#using_the_what_if_tool)。
- en: This model returns a probability of low income from 0 to 1, with values below
    0.5 indicating high income and those above 0.5 low income. This user had a score
    of 0.528, and in our hypothetical mortgage application scenario could be rejected
    as having too low an income. With the tool, you can actually change some of the
    user’s data—for example, their age—and see what the effect on the inference would
    be. In the case of this person, changing their age from 42 to 48 gave them a score
    on the other side of the 0.5 threshold, and as a result changed them from being
    a “reject” on the loan application to an “accept.” Note that nothing else about
    the user was changed—just their age. This gives a strong signal that there’s a
    potential age bias in the model.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型返回一个从 0 到 1 的低收入概率，其中数值低于 0.5 表示高收入，高于 0.5 表示低收入。这位用户的得分为 0.528，在我们的假设抵押贷款申请场景中，可能因收入过低而被拒绝。通过这个工具，你实际上可以改变用户的一些数据，比如他们的年龄，然后看看推断结果会如何改变。在这个人的情况下，将他们的年龄从
    42 岁改变到 48 岁，使得他们的得分跨过了 0.5 的门槛，结果从贷款申请的“拒绝”变成了“接受”。请注意，除了年龄之外，用户的任何其他信息都没有改变。这表明模型可能存在年龄偏见的强烈信号。
- en: The What-If Tool allows you to experiment with various signals like this, including
    details like gender, race, and more. To prevent a one-off situation being the
    tail that wags the dog, causing you to change your entire model to prevent an
    issue that lies with one customer and not the model itself, the tool includes
    the ability to find the nearest counterfactuals. That is, it finds the closest
    set of data that results in a different inference so you can start to dive into
    your data (or model architecture) in order to find biases.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: What-If 工具允许您尝试各种信号，包括性别、种族等详细信息。为了避免单一情况成为主导因素，导致您修改整个模型以防止一个客户问题，而非模型本身，该工具包含寻找最接近反事实的能力。也就是说，它找到一组最接近的数据，导致不同的推断，以便您开始深入研究数据（或模型架构），以查找偏见。
- en: '![Using the What-If Tool](Images/aiml_2005.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![使用 What-If 工具](Images/aiml_2005.png)'
- en: Figure 20-5\. Using the What-If Tool
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-5\. 使用 What-If 工具
- en: I’m just touching the surface of what the What-If Tool can do here, but I’d
    strongly recommend checking it out. There are lots of [examples](https://oreil.ly/NQPB6)
    of what you can do with it on the site. At its core—as the name suggests—it gives
    you tools to test “what-if” scenarios before you deploy. As such, I believe it
    can be an essential part of your ML toolbox.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里只是触及了 What-If 工具可以做的一部分，但我强烈建议您去了解它。网站上有很多[示例](https://oreil.ly/NQPB6)，展示了您可以使用它做什么。正如其名称所示，它提供了在部署之前测试“假设”场景的工具。因此，我相信它可以成为您机器学习工具箱中的重要组成部分。
- en: Facets
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Facets
- en: '[Facets](https://oreil.ly/g7fQM) is a tool that can complement the What-If
    Tool to give you a deep dive into your data through visualizations. The goal of
    Facets is to help you understand the distribution of values across features in
    your dataset. It’s particularly useful if your data is split into multiple subsets
    for training, testing, validation, or other uses. In such cases, you can easily
    end up in a situation where data in one split is skewed in favor of a particular
    feature, leading you to have a faulty model. This tool can help you determine
    whether you have sufficient coverage of each feature for each split.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[Facets](https://oreil.ly/g7fQM) 是一个可以通过可视化为您提供数据深入洞察的工具，可以补充 What-If 工具的作用。Facets
    的目标是帮助您了解数据集中各个特征的值分布情况。如果您的数据分成多个子集用于训练、测试、验证或其他用途，这将特别有用。在这种情况下，您可能很容易陷入一个数据集中某个分割对某个特定特征偏向的情况，导致您拥有一个有缺陷的模型。该工具可以帮助您确定每个分割中每个特征是否有足够的覆盖度。'
- en: For example, using the same US Census dataset as in the previous example with
    the What-If Tool, a little examination shows that the training/test splits are
    very good, but use of the capital gain and capital loss features might have a
    skewing effect on the training. Note in [Figure 20-6](#using_facets_to_explore_a_dataset),
    when inspecting quantiles, that the large crosses are very well balanced across
    all of the features except these two. This indicates that the majority of the
    data points for these values are zeros, but there are a few values in the dataset
    that are much higher. In the case of capital gain, you can see that 91.67% of
    the training set is zeros, with the other values being close to 100,000\. This
    might skew your training, and can be seen as a debugging signal. This could introduce
    a bias in favor of a very small part of your population.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用与上一个示例中相同的美国人口普查数据集和 What-If 工具进行简单检查显示，训练/测试分割非常好，但使用资本收益和资本损失特征可能会对训练产生偏倚影响。请参见[图
    20-6](#using_facets_to_explore_a_dataset)，当检查分位数时，大交叉点在除这两个特征外的所有特征上非常平衡。这表明这些值的大多数数据点为零，但数据集中有一些值明显较高。在资本收益的情况下，您可以看到训练集的
    91.67% 为零，其余值接近 100,000。这可能会导致您的训练产生偏差，并可视为调试信号。这可能会导致您的人口中的一小部分产生偏向性。
- en: '![Using Facets to explore a dataset](Images/aiml_2006.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Facets 探索数据集](Images/aiml_2006.png)'
- en: Figure 20-6\. Using Facets to explore a dataset
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-6\. 使用 Facets 探索数据集
- en: Facets also includes a tool called Facets Dive that lets you visualize the contents
    of your dataset according to a number of axes. It can help identify errors in
    your dataset, or even preexisting biases so you know how to handle them. For example,
    consider [Figure 20-7](#a_deep_dive_with_facets), where I split the dataset by
    target, education level, and gender.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Facets 还包括一种称为 Facets Dive 的工具，可让您根据多个轴可视化数据集的内容。它可以帮助识别数据集中的错误，甚至是现有的偏见，以便您知道如何处理它们。例如，请参见[图
    20-7](#a_deep_dive_with_facets)，在此图中，我按目标、教育水平和性别拆分数据集。
- en: '![A deep dive with Facets](Images/aiml_2007.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Facets 进行深入分析](Images/aiml_2007.png)'
- en: Figure 20-7\. A deep dive with Facets
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-7\. 使用 Facets 进行深入分析
- en: 'Red means “high income predicted,” and left to right are levels of education.
    In almost every case the probability of a male having a high income is greater
    than a female, and, in particular, with higher levels of education the contrast
    becomes stark. Look, for example, at the 13–14 column (which is the equivalent
    of a bachelor’s degree): the data shows a far higher percentage of men being high
    earners than women with the same education level. While there are many other factors
    in the model to determine earning level, having such a disparity for highly educated
    people is a likely indicator of bias in the model.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 红色表示“预测高收入”，从左到右是教育水平。在几乎所有情况下，男性有高收入的概率都大于女性，特别是在较高的教育水平下，这种对比变得非常明显。例如看看 13-14
    列（相当于学士学位）：数据显示男性高收入者的比例远高于同等教育水平的女性。虽然模型中还有许多其他因素来决定收入水平，但在高度受教育的人群中出现这样的差异很可能是模型中偏见的指标。
- en: To help you identify features such as these, along with the What-If Tool, I
    strongly recommend using Facets to explore your data and your model’s output.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您识别这些功能，以及使用 What-If 工具，我强烈建议使用 Facets 来探索您的数据和模型输出。
- en: Both of these tools come from the People + AI Research (PAIR) team at Google.
    I’d recommend you bookmark [their site](https://oreil.ly/Asc1P) to keep an eye
    on the latest releases, as well as the [People + AI Guidebook](https://oreil.ly/0k_jn)
    to help you follow a human-centered approach to AI.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个工具都来自Google的People + AI Research（PAIR）团队。我建议您收藏[他们的网站](https://oreil.ly/Asc1P)以获取最新发布的信息，以及[People
    + AI Guidebook](https://oreil.ly/0k_jn)来帮助您遵循以人为本的AI方法。
- en: Federated Learning
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联邦学习
- en: After your models are deployed and distributed, there’s a huge opportunity for
    them to be continually improved, based on how they are used by your entire user
    base. On-device keyboards with predictive text, for example, must learn from every
    user to be effective. But there’s a catch—in order for a model to learn, the data
    needs to be collected, and gathering data from end users to train a model, particularly
    without their consent, can be a massive invasion of privacy. It’s not right for
    every word your end users type to be used to improve keyboard predictions, because
    then the contents of every email, every text, every message would be known to
    an outside third party. So, to allow for this type of learning, a technique to
    maintain the user’s privacy, while also sharing the valuable parts of the data,
    needs to be used. This is commonly called *federated learning*, and we’ll explore
    it in this section.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的模型部署并分发后，它们有巨大的机会在基于整个用户群体使用情况的基础上持续改进。例如，具有预测文本的设备键盘必须从每个用户那里学习以提高效果。但是有一个问题——为了模型学习，需要收集数据，而未经用户同意收集数据来训练模型，尤其是这种涉及到隐私的行为可能会是一种巨大的侵犯。并不是每个用户输入的每个字都应该被用来改进键盘预测，因为那样每封电子邮件、每条短信的内容都会被外部第三方知晓。因此，为了实现这种学习方式，需要采用一种技术来保护用户隐私，同时分享数据的有价值部分。这通常被称为*联邦学习*，我们将在本节中探讨它。
- en: The core idea behind federated learning is that user data is *never* sent to
    a central server. Instead, a procedure like the one outlined in the following
    sections is used.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习的核心思想是用户数据*永远*不会发送到中央服务器。而是使用像以下各节中概述的过程。
- en: Step 1\. Identify Available Devices for Training
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '-   步骤 1\. 确定可用于训练的设备'
- en: First of all, you’ll need to identify a set of your users who are suitable for
    training work. It’s important to consider the impact on the user performing on-device
    training. To determine whether the device is available, weigh factors such as
    whether the device is already in use, or whether it is plugged into a power supply
    (see [Figure 20-8](#identifying_available_devices)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要确定一组适合进行训练工作的用户。考虑对用户进行设备上训练的影响至关重要。要确定设备是否可用，请权衡诸如设备是否已在使用中或是否已连接电源等因素（参见[图
    20-8](#identifying_available_devices)）。
- en: '![Identifying available devices](Images/aiml_2008.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![识别可用设备](Images/aiml_2008.png)'
- en: Figure 20-8\. Identifying available devices
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-8\. 识别可用设备
- en: Step 2\. Identify Suitable Available Devices for Training
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '-   步骤 2\. 确定适合用于训练的设备'
- en: Of the available ones, not all will be suitable. They may not have sufficient
    data, they may not have been used recently, etc. There are a number of factors
    that could determine suitability, based on your training criteria. Based on these,
    you’ll have to filter the available devices down into a set of *suitable* available
    devices ([Figure 20-9](#choosing_suitable_available_devices)).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些设备可能不太适合。它们可能没有足够的数据，可能最近没有使用过等等。基于您的训练标准，可能有多个因素会决定适合性。基于这些因素，您将不得不将可用设备过滤成一组*适合的*可用设备（参见[图 20-9](#choosing_suitable_available_devices)）。
- en: '![Choosing suitable available devices](Images/aiml_2009.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![选择适合的可用设备](Images/aiml_2009.png)'
- en: Figure 20-9\. Choosing suitable available devices
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-9\. 选择适合的可用设备
- en: Step 3\. Deploy a Trainable Model to Your Training Set
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3\. 将可训练模型部署到您的训练集
- en: Now that you’ve identified a set of suitable available devices, you can deploy
    a model to them ([Figure 20-10](#deploying_a_new_training_model_to_the_d)). The
    model will be trained *on the devices,* which is why devices that are not currently
    in use and are plugged in (to avoid draining the battery) are the suitable family
    to use. *Note that there is no public API to do on-device training with TensorFlow
    at this time.* You can test this environment in Colab, but there’s no Android/iOS
    equivalent at the time of writing.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经确定了一组适合的可用设备，可以将模型部署到这些设备上（参见[图 20-10](#deploying_a_new_training_model_to_the_d)）。模型将在设备上进行训练，这就是为什么那些当前未被使用且已插入（以避免电池耗尽）的设备是合适的选择家庭使用的原因。*请注意，目前没有公共
    API 可以在 TensorFlow 中进行设备端训练。* 您可以在 Colab 中测试这个环境，但在撰写本文时还没有 Android/iOS 的等效方案。
- en: '![Deploying a new training model to the devices](Images/aiml_2010.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![将新的训练模型部署到设备](Images/aiml_2010.png)'
- en: Figure 20-10\. Deploying a new training model to the devices
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-10\. 将新的训练模型部署到设备
- en: Step 4\. Return the Results of the Training to the Server
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 4\. 将训练结果返回给服务器
- en: Note that the *data* used to train the model on the individual’s device *never*
    leaves the device. However weights, biases, and other parameters learned by the
    model can leave the device. Another level of security and privacy can be added
    here (discussed in [“Secure Aggregation with Federated Learning”](#secure_aggregation_with_federated_learn)).
    In this case, the values learned by each of the devices can be passed to the server,
    which can then aggregate them back into the master model, effectively creating
    a new version of the model with the distributed learning of each of the clients
    ([Figure 20-11](#creating_a_new_master_model_from_the_le)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在个体设备上训练模型所使用的*数据*永远不会离开该设备。但是，模型学习到的权重、偏差和其他参数可以离开设备。可以在此添加另一层安全性和隐私性（详见[“使用联邦学习进行安全聚合”](#secure_aggregation_with_federated_learn)）。在这种情况下，每个设备学习到的值可以传递给服务器，服务器随后可以将它们聚合回主模型，有效地创建一个具有每个客户端分布式学习的新版本模型（参见[图 20-11](#creating_a_new_master_model_from_the_le)）。
- en: '![Creating a new master model from the learnings of the clients](Images/aiml_2011.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![从客户学习中创建新的主模型](Images/aiml_2011.png)'
- en: Figure 20-11\. Creating a new master model from the learnings of the clients
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-11\. 从客户学习中创建新的主模型
- en: Step 5\. Deploy the New Master Model to the Clients
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 5\. 将新的主模型部署到客户端
- en: Then, as clients become available to receive the new master model, it can get
    deployed to them, so everyone can access the new functionality ([Figure 20-12](#the_new_master_model_gets_deployed_to_a)).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，随着客户端可用于接收新的主模型，它可以被部署到它们，以便每个人都可以访问新功能（参见[图 20-12](#the_new_master_model_gets_deployed_to_a)）。
- en: Following this pattern will allow you to have a conceptual framework where you
    have a centralized model that can be trained from the experiences of all of your
    users, without violating their privacy by sending data to your server. Instead,
    a subset of the training is done directly on their devices, and the *results*
    of that training are all that ever leaves the device. As described next, a method
    called *secure aggregation* can be used to provide an additional layer of privacy
    through obfuscation.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循这种模式将使您拥有一个概念框架，在这个框架中，您可以从所有用户的经验中训练一个集中模型，而不会通过将数据发送到您的服务器来侵犯他们的隐私。相反，训练的一个子集直接在他们的设备上完成，并且该训练的*结果*是离开设备的唯一内容。接下来描述的方法称为*安全聚合*，可以通过混淆提供额外的隐私保护层。
- en: '![The new master model gets deployed to all of the clients](Images/aiml_2012.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![新的主模型部署到所有客户端](Images/aiml_2012.png)'
- en: Figure 20-12\. The new master model gets deployed to all of the clients
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-12\. 新的主模型部署到所有客户端
- en: Secure Aggregation with Federated Learning
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用联邦学习进行安全聚合
- en: The previous walkthrough demonstrated the conceptual framework of federated
    learning. This can be combined with the concept of secure aggregation to further
    obfuscate the learned weights and biases while in transit from the client to the
    server. The idea behind it is simple. The server pairs up devices with others
    in a buddy system. For example, consider [Figure 20-13](#buddy_devices), where
    there are a number of devices, each of which is given two buddies. Each buddy
    pair is sent the same random value to be used as a multiplier to obfuscate the
    data it sends.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的步骤演示了联邦学习的概念框架。这可以与安全聚合的概念结合起来，以在从客户端到服务器的传输过程中进一步混淆学习到的权重和偏差。其背后的想法很简单。服务器将设备配对到另一个设备组成伙伴系统。例如，考虑
    [图 20-13](#buddy_devices)，其中有多个设备，每个设备都有两个伙伴。每对伙伴都会接收相同的随机值，用作混淆其发送的数据的乘数。
- en: '![Buddy devices](Images/aiml_2013.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![伙伴设备](Images/aiml_2013.png)'
- en: Figure 20-13\. Buddy devices
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-13\. 伙伴设备
- en: 'Here, the first device is buddied with the second, as indicated by the dark
    triangles. These are values that, when combined, will cancel each other out: so,
    the dark “down” triangle could be 2.0, and the dark “up” could be 0.5\. When multiplied
    together, they give 1\. Similarly, the first device is paired with the third device.
    Every device has two “buddies,” where the number on that device has a counterpart
    on the other.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，第一个设备与第二个设备配对，由暗色三角形指示。这些数值在合并时会互相抵消：所以，暗色的“向下”三角形可能是 2.0，而暗色的“向上”可能是 0.5。当它们相乘时，结果为
    1。类似地，第一个设备与第三个设备配对。每个设备都有两个“伙伴”，设备上的数字与另一设备上的对应。
- en: The data from a particular device, represented by a circle in [Figure 20-14](#sending_values_to_the_server_with_secur),
    can then be combined with the random factors before being sent to the server.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 特定设备的数据，由 [图 20-14](#sending_values_to_the_server_with_secur) 中的圆圈表示，可以在发送到服务器之前与随机因子结合。
- en: '![Sending values to the server with secure aggregation](Images/aiml_2014.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![使用安全聚合将数值发送到服务器](Images/aiml_2014.png)'
- en: Figure 20-14\. Sending values to the server with secure aggregation
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-14\. 使用安全聚合将数值发送到服务器
- en: The server, knowing the values sent to the buddies, can cancel them out and
    just get the payload. While the data is in transit to the server it is obfuscated
    by the keys.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器了解发送给伙伴的数值后，可以取消这些数值，只获取有效载荷。数据在传输到服务器时，会被密钥混淆。
- en: Federated Learning with TensorFlow Federated
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Federated 进行联邦学习
- en: '[TensorFlow Federated (TFF)](https://oreil.ly/dLgJu) is an open source framework
    that gives you federated learning functionality in a simulated server environment.
    At the time of writing it’s still experimental, but it’s worth looking into. TFF
    is designed with two core APIs. The first is the Federated Learning API, which
    gives you a set of interfaces that add federated learning and evaluation capabilities
    to your existing models. It allows you to, for example, define distributed variables
    that are impacted by learned values from distributed clients. The second is the
    Federated Core API, which implements the federated communication operations within
    a functional programming environment. It’s the foundation for existing deployed
    scenarios such as the Google keyboard, [Gboard](https://arxiv.org/pdf/1811.03604.pdf).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[TensorFlow Federated (TFF)](https://oreil.ly/dLgJu) 是一个开源框架，在模拟服务器环境中提供联邦学习功能。在撰写本文时，它仍处于实验阶段，但值得关注。TFF
    设计有两个核心 API。第一个是联邦学习 API，为您的现有模型添加了联邦学习和评估功能的一组接口。例如，它允许您定义受分布式客户端学习值影响的分布式变量。第二个是联邦核心
    API，在功能编程环境中实现了联邦通信操作。它是如 Google 键盘 [Gboard](https://arxiv.org/pdf/1811.03604.pdf)
    等现有部署方案的基础。'
- en: I won’t go into detail on how to use TFF in this chapter because it’s still
    in its early stages, but I encourage you to check it out to prepare for the day
    that on-device federated learning libraries become available!
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会在本章详细介绍如何使用 TFF，因为它仍处于早期阶段，但我鼓励您查看它，以便为设备上的联邦学习库成熟的那一天做好准备！
- en: Google’s AI Principles
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌的 AI 原则
- en: 'TensorFlow was created by Google’s engineers as an outcropping of many existing
    projects built by the company for its products and internal systems. After it
    was open sourced, many new avenues for machine learning were discovered, and the
    pace of innovation in the fields of ML and AI is staggering. With this in mind,
    Google decided to put out a [public statement](https://ai.google/principles) outlining
    its principles with regard to how AI should be created and used. They’re a great
    guideline for responsible adoption, and worth exploring. In summary, the principles
    are:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是由谷歌工程师基于公司产品和内部系统中的许多现有项目开发的。在其开源后，发现了许多机器学习新路径，并且在机器学习和人工智能领域的创新速度惊人。考虑到这一点，谷歌决定发布一份[公开声明](https://ai.google/principles)，概述其关于如何创建和使用人工智能的原则。这些原则是负责任采纳的良好指导方针，值得探索。总之，这些原则包括：
- en: Be socially beneficial
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对社会有益
- en: Advances in AI are transformative, and, as that change happens, the goal is
    to take into account all social and economic factors, proceeding only where the
    overall likely benefits outstrip the foreseeable risks and downsides.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的进步是变革性的，随着这种变化的发生，目标是考虑所有社会和经济因素，仅在总体上可能的好处超过可预见的风险和不利因素时才进行推进。
- en: Avoid creating or reinforcing unfair bias
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 避免创建或强化不公平的偏见
- en: As discussed in this chapter, bias can easily creep into any system. AI—particularly
    in cases where it transforms industry—presents an opportunity to *remove* existing
    biases, as well as to ensure that *new* biases don’t arise. One should be mindful
    of this.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章讨论的那样，偏见可以轻易地渗入任何系统。人工智能——特别是在它转变行业的情况下——为消除现有偏见提供了机会，同时确保不会产生新的偏见。应当谨记这一点。
- en: Be built and tested for safety
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为安全性而建立和测试
- en: Google continues to develop strong safety and security practices to avoid unintended
    harm from AI. This includes developing AI technologies in constrained environments
    and continually monitoring their operation after deployment.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌继续发展强大的安全与保障实践，以避免人工智能带来的意外伤害。这包括在受限环境中开发人工智能技术，并在部署后持续监控其运行。
- en: Be accountable to people
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对人负责
- en: The goal is to build AI systems that are subject to appropriate human direction
    and control. This means that appropriate opportunities for feedback, appeal, and
    relevant explanations must always be provided. Tooling to enable this will be
    a vital part of the ecosystem.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是构建受适当人类指导和控制的人工智能系统。这意味着必须始终提供适当的反馈、申诉和相关解释的机会。支持这一点的工具将是生态系统中至关重要的一部分。
- en: Incorporate privacy design principles
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 纳入隐私设计原则
- en: AI systems must incorporate safeguards that ensure adequate privacy and inform
    users of how their data will be used. Opportunities for notice and consent should
    be obvious.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统必须纳入确保充分隐私和告知用户其数据使用方式的保障措施。应当明确提供通知和同意的机会。
- en: Uphold high standards of scientific excellence
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 维护高科学卓越标准
- en: Technological innovation is at its best when it is done with scientific rigor
    and a commitment to open inquiry and collaboration. If AI is to help unlock knowledge
    in critical scientific domains, it should aspire to the high standards of scientific
    excellence that are expected in those areas.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当技术创新在科学严谨性和对开放探讨与协作的承诺下进行时，其表现最佳。如果人工智能要帮助揭示关键科学领域的知识，它应当努力达到这些领域期望的科学卓越标准。
- en: Be made available for uses that accord with these principles
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 提供符合这些原则的用途
- en: While this point might seem a little meta, it’s important to reinforce that
    the principles don’t stand alone, nor are they just for the people building systems.
    They’re also intended to give guidelines for how the systems you build can be
    used. It’s good to be mindful of how someone might use your systems in a way you
    didn’t intend, and as such, good to have a set of principles for your users too!
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这一点可能显得有些元信息，但重要的是强调这些原则并不孤立存在，也不仅仅适用于构建系统的人员。它们也旨在为您构建的系统如何被使用提供指导。意识到某人可能以您未曾预期的方式使用您的系统是件好事，因此为您的用户设立一套原则也是非常必要的！
- en: Summary
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: And that brings us to the end of this book. It’s been an amazing and fun journey
    for me to write it, and I hope you’ve found value in reading it! You’ve come a
    long way, from the “Hello World” of machine learning through building your first
    computer vision, natural language processing, and sequence modeling systems and
    more. You’ve practiced deploying models everywhere from on mobile devices to the
    web and the browser, and in this chapter we wrapped up with a glimpse into the
    bigger world of how and why you should use your models in a mindful and beneficial
    way. You saw how bias is a problem in computing, and potentially a huge one in
    AI, but also how there is an opportunity now, with the field in its infancy, to
    be at the forefront of eliminating it as much as possible. We explored some of
    the tooling available to help you in this task, and you got an introduction to
    federated learning and how it might be the future of mobile application development
    in particular.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这本书就要告一段落了。对我来说，写作过程是一段令人惊奇而有趣的旅程，希望你在阅读中找到了价值！你已经走过了漫长的路程，从机器学习的“Hello World”开始，逐步构建了你的第一个计算机视觉、自然语言处理和序列建模系统等等。你已经在从移动设备到网络和浏览器的各个地方部署模型，并且在本章中，我们通过一瞥了解了如何以一种审慎和有益的方式使用你的模型，以及为什么要这样做。你看到了偏见在计算中是一个问题，尤其在人工智能中可能是一个巨大的问题，但同时也看到了现在是一个机会，因为这个领域正处于起步阶段，我们有机会尽可能地在前沿消除这些问题。我们探讨了一些可用的工具来帮助你完成这一任务，并且你对联邦学习有了初步了解，以及它如何可能成为移动应用开发的未来。
- en: Thank you so much for sharing this journey with me! I look forward to hearing
    your feedback and answering whatever questions I can.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢你和我一起分享这段旅程！期待听到你的反馈，并尽我所能回答任何问题。
