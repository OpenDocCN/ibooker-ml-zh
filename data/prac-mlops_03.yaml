- en: Chapter 3\. MLOps for Containers and Edge Devices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章。用于容器和边缘设备的MLOps
- en: By Alfredo Deza
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：Alfredo Deza
- en: 'Split-brain experiments started with the problem of interocular transfer. That
    is, if one learns with one eye how to solve a problem, then with that eye covered
    and using the other eye, one readily solves the problem without further learning.
    This is called “interocular transfer of learning.” Of course, the learning is
    not in the eye and then transferred to the other eye, but that is the way it is
    usually described. The fact that transfer occurs may seem obvious, but it is in
    the questioning of the obvious that discoveries are often produced. In this case,
    the question was: How can the learning with one eye appear with use of the other?
    Put in experimentally testable terms, where are the two eyes connected? Experiments
    showed that the transfer actually occurs between the hemispheres by way of the
    corpus callosum.'
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 分裂脑实验始于眼间转移问题。也就是说，如果一个人用一只眼睛学会了解决一个问题，然后用另一只眼睛遮盖住，并使用另一只眼睛，他就能轻松地解决这个问题，而无需进一步学习。这被称为“学习的眼间转移”。当然，学习并不是在眼睛中进行然后转移到另一只眼睛，但通常是这样描述的。转移发生的事实可能显而易见，但质疑显而易见的东西往往会产生发现。在这种情况下，问题是：一个眼睛学习后，如何在使用另一个眼睛时表现出来？放在可以实验测试的术语中，这两只眼睛在哪里连接？实验表明，转移实际上是通过大脑半球之间的胼胝体进行的。
- en: ''
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Dr. Joseph Bogen
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作者：Dr. Joseph Bogen
- en: When I started in technology, virtual machines (virtualized servers hosted in
    a physical machine), were well positioned and pervasive—it was easy to find them
    everywhere, from hosting providers to regular companies with big servers in the
    IT room. A lot of online software providers were offering virtualized hosting.
    At work, I honed my skills, trying to learn as much as possible about virtualization.
    The ability to run virtual machines within some other host offered a lot of (welcomed)
    flexibility.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始涉足技术领域时，虚拟机（托管在物理机器上的虚拟化服务器）处于非常有利且普遍的位置——无论是从托管提供商到在IT房间里拥有大型服务器的普通公司，到处都能找到它们。很多在线软件提供商都提供虚拟化托管服务。在工作中，我不断磨练技能，努力学习虚拟化技术的方方面面。能够在其他主机上运行虚拟机提供了很多（受欢迎的）灵活性。
- en: 'Whenever a new technology solves a problem (or any number of issues really),
    a trail of other problems tags along to be resolved. With virtual machines, one
    of these problems was to deal with moving them around. If host server *A* needed
    to have a new operating system installed, a system administrator would need to
    move the virtual machines over to host server *B*. Virtual machines were as large
    as the data when initially configured: a 50 GB *virtual drive* meant a file representing
    the virtual drive existed at 50 gigabytes. Moving around 50 gigabytes from one
    server to the other would take time. If you are moving around a critical service
    running a virtual machine, how can you minimize downtime?'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 每当新技术解决一个问题（或者任意数量的问题），就会带来一系列其他问题需要解决。对于虚拟机来说，其中一个问题是如何处理它们的移动。如果主机服务器*A*需要安装新操作系统，系统管理员需要将虚拟机迁移到主机服务器*B*。虚拟机的大小与初始配置时的数据大小一样大：一个50
    GB的*虚拟驱动器*意味着存在一个大小为50GB的虚拟驱动器文件。将50GB从一个服务器移动到另一个服务器将花费时间。如果您正在移动运行虚拟机的关键服务，如何最小化停机时间？
- en: 'Most of these issues had their strategies to minimize downtime and increase
    robustness: snapshots, recovery, backups. Software projects like the *Xen Project*
    and *VMWare* specialized in making these issues relatively easy to solve, and
    cloud providers practically eliminated them.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数这些问题都有它们的策略来最小化停机时间并增加鲁棒性：快照、恢复、备份。像*Xen Project*和*VMWare*这样的软件项目专门解决这些问题，而云服务提供商则几乎消除了这些问题。
- en: These days, virtual machines still have an important place in cloud offerings.
    Google Cloud calls them *Compute Engine*, for example, and other providers have
    a similar reference. A lot of these virtual machines offer enhanced GPUs to provide
    better performance targeted at machine learning operations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，虚拟机在云计算中仍然占据重要地位。例如，Google Cloud 将其称为*Compute Engine*，其他提供商也有类似的参考名称。许多这些虚拟机提供增强型GPU，以提供针对机器学习操作的更好性能。
- en: 'Although virtual machines are here to stay, it is increasingly important to
    grasp two types of technologies for model deployments: containers and edge devices.
    It is unreasonable to think that a virtual machine would be well suited to run
    on an edge device (like a cellphone) or quickly iterate during development with
    a reproducible set of files. You will not always face a decision of using one
    or the other, but possessing a clear understanding of these options (and how they
    operate) will make you a better machine learning engineer.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机虽然依然存在，但越来越重要的是掌握两种模型部署技术：容器和边缘设备。认为虚拟机适合在边缘设备（如手机）上运行或在开发过程中快速迭代并使用可重现文件集是不合理的。你不会总是需要选择其中一种，但对这些选择（以及它们的运作方式）有清晰的理解会使你成为更好的机器学习工程师。
- en: Containers
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器
- en: 'With all the power and robustness of virtual machines, it is critical to grasp
    containers and containerization technology in general. I remember being in the
    audience at PyCon in Santa Clara in 2013, when Docker was announced. It felt incredible!
    The *lean virtualization* demoed was not new for Linux. What was new and sort
    of revolutionary was the tooling. Linux has had *LXC* (or *Linux containers*),
    which provided a lot of the functionality we take for granted with containers
    today. But the tooling for LXC is dismal, and Docker brought one key factor to
    successfully become a leader: easy collaboration and sharing through a registry.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然虚拟机拥有强大和稳健的功能，但理解容器和容器化技术是至关重要的。我记得2013年在圣克拉拉的PyCon大会上，Docker被宣布时的那种感觉！展示的*精简虚拟化*对于Linux并不新鲜。新颖和革命性的是工具链。Linux早已有*LXC*（或*Linux容器*），提供了今天我们认为理所当然的许多容器功能。但LXC的工具链令人沮丧，而Docker带来了一个成功的关键因素：通过注册表轻松的协作和分享。
- en: Registries allow any developer to *push* their changes to a central location
    where others can then *pull* those changes and run them locally. Registry support
    with the same tooling that deals with containers (and all seamlessly) propelled
    the technology forward at an incredible pace.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 注册表允许任何开发者*推送*他们的更改到一个中心位置，其他人可以*拉取*这些更改并在本地运行。使用与容器相关的同样工具支持注册表（一切无缝衔接），极大推动了技术的快速发展。
- en: Tip
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Tip
- en: For this section, make sure you have a container runtime installed. For the
    examples in this section, it might be easier to use [Docker](https://oreil.ly/iEX4x).
    After installation, ensure that the `docker` command will show the help output
    to verify a successful install.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，请确保已安装容器运行时。对于这一节中的示例，使用[Docker](https://oreil.ly/iEX4x)可能会更容易。安装完成后，请确保`docker`命令显示帮助输出，以验证安装是否成功。
- en: One of the most significant [descriptions](https://oreil.ly/SQUjS) I’ve seen
    about containers in comparison to virtual machines comes from Red Hat. In short,
    containers are all about the application itself, and only what the application
    is (like the source code and other supporting files) versus what it needs to run
    (like databases). Traditionally, engineers often use virtual machines like an
    all-in-one service where the database, the web server, and any other system service
    are installed, configured, and run. These types of applications are *monolithic*,
    with tied interdependencies in an all-in-one machine.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有关容器与虚拟机对比的最重要[描述](https://oreil.ly/SQUjS)之一来自红帽。简而言之，容器专注于应用程序本身，只有应用程序本身（如源代码和其他支持文件），而不是运行所需的（如数据库）。传统上，工程师经常使用虚拟机作为一体化服务，其中安装、配置和运行数据库、Web
    服务器和其他系统服务。这些类型的应用程序是*单块式*的，所有组件在一个机器上有紧密的互联依赖。
- en: A *microservice*, on the other hand, is an application that is fully decoupled
    from system requirements like databases and can run independently. Although you
    can use virtual machines as microservices, it is more common to find containers
    fitting better in that concept.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*微服务*是一个与数据库等系统要求完全解耦的应用程序，可以独立运行。虽然你可以将虚拟机用作微服务，但通常容器更适合这个概念。
- en: If you are already familiar with creating and running containers, in [“Infrastructure
    as Code for Continuous Delivery of ML Models”](ch04.xhtml#Section-continuous-delivery-of-ml-models)
    I cover how to build them programmatically with pretrained models, which takes
    these concepts and enhances them with automation.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经熟悉创建和运行容器，在[“用于机器学习模型持续交付的基础设施即代码”](ch04.xhtml#Section-continuous-delivery-of-ml-models)一章中，我详细介绍了如何使用预训练模型程序化地构建它们，这进一步将这些概念与自动化融合。
- en: Container Runtime
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器运行时
- en: You might’ve noticed that I’ve mentioned containers, Docker, and container runtime.
    These terms might get confusing, primarily when people use them interchangeably.
    Since Docker (the company) initially developed the tooling to create, manage,
    and run containers, it became common to say “Docker container.” The runtime—that
    is, the required software to run a container in a system—was also created by Docker.
    A few years after the new container technology’s initial release, Red Hat (the
    company behind the RHEL operating system) contributed to making a different way
    to run containers, with a new (alternative) runtime environment. This new environment
    also brought a new set of tools to operate containers, with some compatibility
    with those provided by Docker. If you ever hear about container runtime, you have
    to be aware that there is more than one.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，我提到了容器、Docker 和容器运行时。当人们将它们混用时，这些术语可能会令人困惑。由于 Docker（公司）最初开发了用于创建、管理和运行容器的工具，因此将“Docker
    容器”称为常见用语。运行时——也就是在系统中运行容器所需的软件——也是由 Docker 创建的。在新容器技术发布几年后，红帽（负责 RHEL 操作系统的公司）贡献了一种不同的容器运行方式，使用了新的（替代的）运行环境。这种新环境还引入了一套新的操作容器工具，与
    Docker 提供的工具有一定的兼容性。如果你听说过容器运行时，你必须意识到不止一种存在。
- en: Some benefits of these new tools and runtime mean that you are no longer required
    to use a superuser account with extensive privileges, which makes sense for many
    different use cases. Although Red Hat and many other open source contributors
    have done an excellent job with these tools, it is still somewhat complicated
    to run them in operating systems that aren’t Linux. On the other hand, Docker
    makes the work a seamless experience regardless of whether you are using Windows,
    MacOS, or Linux. Let’s get started by going through all the steps needed to create
    a container.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这些新工具和运行时的一些好处意味着，你不再需要使用具有广泛权限的超级用户账户，这对许多不同的使用情况是合理的。尽管红帽和许多其他开源贡献者在这些工具上做得很好，但在非
    Linux 操作系统上运行它们仍然有些复杂。另一方面，Docker 使工作无缝体验，无论你使用 Windows、MacOS 还是 Linux。让我们开始通过完成创建容器所需的所有步骤来开始。
- en: Creating a Container
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建容器
- en: 'The *Dockerfile* is at the heart of creating containers. Anytime you are creating
    a container, you must have the Dockerfile present in the current directory. This
    special file can have several sections and commands that allow creating a container
    image. Open a new file and name it *Dockerfile* and add the following contents
    to it:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*Dockerfile* 是创建容器的核心。每次你创建一个容器时，必须在当前目录中有 Dockerfile 存在。这个特殊文件可以有几个部分和命令，允许创建容器镜像。打开一个新文件并命名为
    *Dockerfile*，并将以下内容添加到其中：'
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The file has two sections; a unique keyword delimits each one. These keywords
    are known as *instructions*. The beginning of the file uses the `FROM` instruction,
    which determines what the base for the container is. The *base* (also referred
    to as *base image*) is the CentOS distribution at version 8\. The version, in
    this case, is a tag. Tags in containers define a point in time. When there are
    no tags defined, the default is the *latest* tag. It is common to see versions
    used as tags, as is the case in this example.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 文件有两个部分；每个部分都由唯一的关键字分隔。这些关键字被称为*指令*。文件的开头使用了`FROM`指令，它确定容器的基础是什么。*基础*（也称为*基础镜像*）是
    CentOS 发行版的第 8 版。在这种情况下，版本是一个标签。在容器中，标签定义了一个时间点。当没有定义标签时，默认为*latest*标签。通常情况下，版本会被用作标签，就像这个例子中的情况一样。
- en: 'One of the many useful aspects of containers is that they can be composed of
    many layers, and these layers can be used or reused in other containers. This
    layering workflow prevents a base layer of 10 megabytes from getting downloaded
    every time for each container that uses it. In practice, you will download the
    10 megabyte layer once and reuse it many times. This is *very* different from
    virtual machines, where it doesn’t matter if these virtual machines all have the
    same files: you are still required to download them all as a whole.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 容器的许多有用方面之一是它们可以由许多层组成，这些层可以在其他容器中使用或重复使用。这种分层工作流程防止了每个使用它的容器每次都需要下载一个 10 兆字节的基础层。实际操作中，你只需下载一次
    10 兆字节的层，并且多次重复使用。这与虚拟机非常不同，在虚拟机中，即使所有这些虚拟机都具有相同的文件，你仍然需要将它们全部下载为整体。
- en: Next, the `RUN` instruction runs a system command. This system command installs
    Python 3, which isn’t included in the base CentOS 8 image. Note how the `dnf`
    command uses the `-y` flag, which prevents a prompt for confirmation by the installer,
    triggered when building the container. It is crucial to avoid any prompts from
    running commands as it would halt the build.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，`RUN` 指令运行一个系统命令。该系统命令安装 Python 3，而基本的 CentOS 8 镜像中并不包含它。注意 `dnf` 命令如何使用
    `-y` 标志，这可以防止安装程序在构建容器时询问确认。避免运行命令时触发任何提示是至关重要的。
- en: 'Now build the container from the same directory where the *Dockerfile* is:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在从存放 *Dockerfile* 的同一目录构建容器：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The output reports that I already have the initial layer for CentOS 8, so there
    is no need to pull it again. Then, it installs Python 3.8 to complete image creation.
    Make sure you start a build pointing to where the *Dockerfile* is present. In
    this case, I’m in the same directory, so I use a dot to let the build know that
    the current directory is the one to build from.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 输出报告说我已经拥有 CentOS 8 的初始层，因此无需再次拉取它。然后，它安装 Python 3.8 完成镜像的创建。确保启动构建时指向存放 *Dockerfile*
    的位置。在这种情况下，我在同一目录中，因此使用点号让构建知道当前目录是构建的目录。
- en: 'This way of building images is not very robust and has a few problems. First,
    it is challenging to identify this image later. All we have is the sha256 digest
    to reference it and nothing else. To see some information about the image just
    built, rerun `docker`:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种构建镜像的方式不是很健壮，存在一些问题。首先，很难后续识别这个镜像。我们只有 sha256 摘要来引用它，没有其他信息。要查看刚刚构建的镜像的一些信息，重新运行
    `docker`：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'There is no repository or tag associated with it. The image ID is the digest,
    which gets reduced to only 12 characters. This image is going to be challenging
    to deal with if it doesn’t have additional metadata. It is a good practice to
    tag it when building the image. This is how you create the same image and tag
    it:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 没有与之关联的存储库或标签。镜像 ID 是摘要，缩短为仅 12 个字符。如果没有额外的元数据，处理这个镜像会很具挑战性。在构建镜像时给它打标签是一个好习惯。这是创建相同镜像并打标签的方法：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The critical difference is that now `localbuild` has a tag of `removeme` and
    it will show up when listing the images:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 关键区别在于现在 `localbuild` 有一个 `removeme` 的标签，并且在列出镜像时会显示出来：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Since the image didn’t change at all, the build process was speedy, and internally,
    the build system tagged the already built image. The naming and tagging of images
    helps when pushing the image to a registry. I would need to own the *localbuild*
    repository to push to it. Since I don’t, the push will get denied:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于镜像根本没有变化，构建过程非常迅速，内部构建系统已经为已构建的镜像打了标签。命名和标记镜像在推送镜像到注册表时很有帮助。我需要拥有 *localbuild*
    存储库才能推送到它。因为我没有，推送将被拒绝：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'However, if I re-tag the container to my repository in the registry, pushing
    will work. To re-tag, I first need to reference the original tag (`localbuild:removeme`)
    and then use my registry account and destination (`alfredodeza/removeme`):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果我将容器重新标记到注册表中的我的存储库，推送将会成功。要重新标记，我首先需要引用原始标签 (`localbuild:removeme`)，然后使用我的注册表账户和目的地
    (`alfredodeza/removeme`)：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Going to the [registry](https://hub.docker.com) (in this case, Docker Hub) now
    shows that the recently pushed image is available ([Figure 3-1](#Figure-3-1)).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在去 [注册表](https://hub.docker.com)（在本例中是 Docker Hub），可以看到最近推送的镜像已经可用（见 [图 3-1](#Figure-3-1)）。
- en: 'Since my account is open and the registry is not restricting access, anyone
    can “pull” the container image by running: `docker pull alfredodeza/removeme`.
    If you’ve not been exposed to containers or registries before, this should feel
    revolutionary. Like I mentioned at the beginning of this chapter, it is the foundation
    of why containers went viral in the developer community. The answer to *“How do
    I install your software?”* can now be *“just pull the container”* for almost anything.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我的账户是开放的，注册表没有限制访问，任何人都可以通过运行 `docker pull alfredodeza/removeme` 来“拉取”容器镜像。如果你之前没有接触过容器或注册表，这应该感觉革命性。正如我在本章开头提到的，这是容器在开发者社区迅速流行的基础。对于“如何安装你的软件？”的答案现在几乎可以是“只需拉取容器”。
- en: '![pmlo 0301](Images/pmlo_0301.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0301](Images/pmlo_0301.png)'
- en: Figure 3-1\. Docker Hub image
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. Docker Hub 镜像
- en: Running a Container
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行容器
- en: Now that the container builds with the *Dockerfile*, we can run it. When running
    virtual machines, it was common practice to enable the SSH (also known as the
    Secure Shell) daemon and expose a port for remote access, and perhaps even add
    default SSH keys to prevent getting password prompts. People who aren’t used to
    running a container will probably ask for SSH access to a running container instance.
    SSH access is not needed; even though you can enable it and make it work, it is
    not how to access a running container.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在*Dockerfile*构建了容器，我们可以运行它了。在运行虚拟机时，通常会启用SSH（也称为安全外壳）守护程序并公开一个端口进行远程访问，甚至可能添加默认的SSH密钥以防止密码提示。不习惯运行容器的人可能会要求SSH访问正在运行的容器实例。虽然可以启用SSH并使其工作，但这不是访问运行中容器的方法。
- en: 'Make sure that a container is running. In this example, I run CentOS 8:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 确保容器正在运行。在此示例中，我运行的是CentOS 8：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'There are several new flags in this command. It uses `-ti` to allocate a TTY
    (emulates a terminal) and attaches `stdin` to it to interact with it in the terminal
    later. Next, the `-d` flag makes the container run in the background to prevent
    taking control of the current terminal. I assign a name (`centos-test`) and then
    use `--rm` so that Docker removes this container after stopping it. After issuing
    the command, a digest returns, indicating that the container has started. Now,
    verify it is running:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令中有几个新标志。它使用`-ti`来分配一个TTY（模拟终端），并将`stdin`附加到其中，以便稍后在终端中与之交互。接下来，`-d`标志使容器在后台运行，以防止接管当前终端。我分配了一个名称（`centos-test`），然后使用`--rm`以便Docker在停止容器后移除它。执行命令后，会返回一个摘要，表示容器已启动。现在，验证它是否正在运行：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Some containers get created with an `ENTRYPOINT` (and optionally a `CMD`) instruction.
    These instructions are meant to get the container up and running for a specific
    task. In the example container we just built for CentOS, the `/bin/bash` executable
    had to be specified because otherwise the container would not stay running. These
    instructions mean that if you want a long-running container, you should create
    it with at least an `ENTRYPOINT` that executes a program. Update the *Dockerfile*
    so that it looks like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有些容器使用了`ENTRYPOINT`（可选使用`CMD`）指令创建。这些指令旨在使容器能够为特定任务启动和运行。在我们刚刚为CentOS构建的示例容器中，必须指定`/bin/bash`可执行文件，否则容器将无法保持运行状态。这些指令意味着，如果需要一个长时间运行的容器，至少应该创建一个执行程序的`ENTRYPOINT`。更新*Dockerfile*，使其看起来像这样：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now it is possible to run the container in the background without the need
    to specify the `/bin/bash` command:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以在后台运行容器，而无需指定`/bin/bash`命令：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'I mentioned before how it is common to use SSH to gain access to a virtual
    machine and that gaining access to a container is somewhat different. Although
    you could enable SSH for a container (in theory), I don’t recommend it. This is
    how you can get access to a running container using the container ID and the `exec`
    subcommand:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前提到过，通常使用SSH访问虚拟机，而访问容器有些不同。虽然理论上可以为容器启用SSH，但我不建议这样做。以下是使用容器ID和`exec`子命令访问运行中容器的方法：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In that case, I have to use the command I want to run. Since I want to interactively
    manipulate the container (as I would with a virtual machine), I call out the executable
    for the Bash (a ubiquitous Unix shell and command language) program.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在那种情况下，我必须使用我想要运行的命令。由于我想要与容器进行交互操作（就像我与虚拟机一样），我调用Bash程序的可执行文件。
- en: 'Alternatively, you may not want to gain access using an interactive shell environment,
    and all you want to do is run some command. The command must change to achieve
    this. Replace the shell executable used in the previous example with that of the
    command to use:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可能不想使用交互式Shell环境访问，并且您只想运行一些命令。必须更改命令才能实现此目的。将先前示例中使用的Shell可执行文件替换为要使用的命令：
- en: '[PRE12]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Since there is no interactive need (I’m not sending any input via a shell),
    I can omit the `-it` flag.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有交互需求（我不通过Shell发送任何输入），我可以省略`-it`标志。
- en: Note
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: One common aspect of container development is to keep its size as small as possible.
    That is why a CentOS container will have a lot fewer packages than that of a newly
    installed CentOS virtual machine. This leads to surprising experiences when you
    expect a package to be present (e.g., a text editor like Vim) and it isn’t.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 容器开发的一个常见方面是尽可能保持其大小尽可能小。这就是为什么CentOS容器会比新安装的CentOS虚拟机少得多的软件包。当您期望某个软件包存在时（例如像Vim这样的文本编辑器），但实际上不存在时，会带来惊讶的经历。
- en: Best Practices
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最佳实践
- en: 'The first thing I do (and highly recommend) when trying a new language or tool
    is to find a linter that can help navigate conventions and common usage that I
    may not be familiar with. There are a few linters for creating containers with
    a Dockerfile. One of these linters is `hadolint`. It is conveniently packaged
    as a container. Modify the last *Dockerfile* example, so it looks like this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 第一件事（也强烈推荐）在尝试新的语言或工具时，是找一个可以帮助导航约定和常见用法的代码检查工具。有几种用于使用 Dockerfile 创建容器的代码检查工具。其中一个是`hadolint`。它被方便地打包为一个容器。修改最后一个*Dockerfile*示例，使其看起来像这样：
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now run the linter to see if there are any good suggestions:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在运行代码检查工具，看看是否有好的建议：
- en: '[PRE14]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This is a good suggestion. Pinning packages is always a great idea because you
    are safe from an update in a dependency being incompatible with the code your
    application needs. Be aware that pinning dependencies and never going through
    the chore of updating them isn’t a great idea. Make sure you come back to pinned
    dependencies and see if it would be useful to update.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个好建议。固定软件包版本总是一个好主意，因为这样可以确保依赖项的更新不会与您的应用程序需要的代码不兼容。请注意，固定依赖项并永远不更新它们并不是一个好主意。确保回到固定的依赖项，并查看是否有必要进行更新。
- en: 'Since one of the goals of containerizing tools is to keep them as small as
    possible, you can accomplish a couple of things when creating a Dockerfile. Every
    time there is a `RUN` instruction, a new layer gets created with that execution.
    Containers consist of individual layers, so the fewer the number of layers, the
    smaller the container’s size. This means that it is preferable to use a single
    line to install many dependencies instead of one:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于容器化工具的一个目标是尽可能保持其小巧，您可以在创建 Dockerfile 时实现几件事情。每次有`RUN`指令时，都会创建一个包含该执行的新层。容器由个别层组成，因此层数越少，容器的大小就越小。这意味着最好使用一行命令安装多个依赖项，而不是一个依赖项一个命令：
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The use of `&&` at the end of each command chains everything together, creating
    a single layer. If the previous example had a separate `RUN` instruction for each
    install command, the container would end up being larger. Perhaps for this particular
    example, the size wouldn’t make that much of a difference; however, it would be
    significant in containers that require lots of dependencies.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个命令的末尾使用`&&`将所有内容链接在一起，创建一个单一的层。如果前面的示例为每个安装命令使用单独的`RUN`指令，那么容器的大小将更大。也许对于这个特定示例，大小不会有太大的区别；然而，在需要大量依赖项的容器中，这将是显著的。
- en: 'There is a useful option that linting can offer: the opportunity to automate
    the linting. Be on the lookout for chances to automate processes, removing any
    manual step and letting you concentrate on the essential pieces of the process
    of shipping models into production (writing a good Dockerfile in this case).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 代码检查提供了一个有用的选项：自动化代码检查的机会。留意自动化流程的机会，消除任何手动步骤，并让您集中精力在将模型部署到生产中的过程的核心部分（在这种情况下编写一个好的
    Dockerfile）。
- en: Another critical piece of building containers is making sure there aren’t vulnerabilities
    associated with the software installed. It is not uncommon to find engineers who
    think that the application is unlikely to have vulnerabilities because they write
    high-quality code. The problem is that a container comes with preinstalled libraries.
    It is a full operating system that, at build time, will pull extra dependencies
    to satisfy the application you are trying to deliver. If you are going to serve
    a trained model from the container using a web framework like Flask, you have
    to be well aware that there might be Common Vulnerabilities and Exposures (CVEs)
    associated with either Flask or one of its dependencies.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 构建容器的另一个关键部分是确保安装的软件没有与之相关的漏洞。发现认为应用程序不太可能有漏洞，因为他们编写高质量代码的工程师并不罕见。问题在于容器带有预安装的库。它是一个完整的操作系统，在构建时将拉取额外的依赖项以满足您尝试交付的应用程序。如果您要使用像
    Flask 这样的 Web 框架从容器中提供训练模型，您必须清楚地了解可能与 Flask 或其依赖项之一相关联的常见漏洞和曝光（CVEs）。
- en: 'These are the dependencies that Flask (at version `1.1.2`) brings:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是 Flask（版本为`1.1.2`）带来的依赖项：
- en: '[PRE16]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: CVEs can get reported at any given time, and software systems used to alert
    on vulnerabilities ensure they are updated several times during the day to report
    accurately when that happens. A critical piece of your application like Flask
    may not be vulnerable today for version 1.1.2, but it can undoubtedly be tomorrow
    morning when a new CVE is discovered and reported. Many different solutions specialize
    in scanning and reporting vulnerabilities in containers to mitigate these vulnerabilities.
    These security tools scan a library that your application installs and the operating
    system’s packages, providing a detailed and accurate vulnerability report.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: CVE可能随时报告，并且用于警报漏洞的软件系统确保在报告时准确更新多次。像Flask这样的应用程序的关键部分今天可能不会对版本1.1.2有漏洞，但是明天早上发现并报告新CVE时就肯定会有。许多不同的解决方案专门用于扫描和报告容器中的漏洞以减轻这些漏洞。这些安全工具扫描应用程序安装的库和操作系统的软件包，提供详细和准确的漏洞报告。
- en: 'One solution that is very fast and easy to install is Anchore’s `grype` command
    line tool. To install it on a Macintosh computer:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常快速且易于安装的解决方案是Anchore的`grype`命令行工具。要在Macintosh计算机上安装它：
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Or on any Linux machine:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 或在任何Linux机器上：
- en: '[PRE18]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Using `curl` in this way allows deploying `grype` into most any continuous
    integration system to scan for vulnerabilities. The `curl` installation method
    will place the executable in the current working path under a *bin/* directory.
    After installation is complete, run it against a container:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`curl`这种方式可以将`grype`部署到几乎任何持续集成系统中以扫描漏洞。`curl`安装方法会将可执行文件放置在当前工作路径下的*bin/*目录中。安装完成后，运行它对一个容器进行扫描：
- en: '[PRE19]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Over a thousand vulnerabilities look somewhat surprising. The output is too
    long to capture here, so filter the result to check for vulnerabilities with a
    severity of *High*:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一千多个漏洞看起来有些令人惊讶。输出太长无法在此捕获，因此过滤结果以检查*High*严重性的漏洞：
- en: '[PRE20]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: There were a few vulnerabilities reported, so I reduced the output to just one.
    The [CVE](https://oreil.ly/6Q1O2) is worrisome because it can potentially allow
    the system to crash if an attacker exploits the vulnerability. Since I know the
    application uses Python 3.8, then this container is not vulnerable because Python
    2.7 is unused. Although this is a Python 3.8 container, the image contains an
    older version for convenience. The critical difference is that now you know what
    is vulnerable and can make an executive decision for the eventual deployment of
    the service to production.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 报告了几个漏洞，因此我将输出减少到只有一个。[CVE](https://oreil.ly/6Q1O2)令人担忧，因为如果攻击者利用漏洞，可能会导致系统崩溃。由于我知道应用程序使用Python
    3.8，所以这个容器不会有漏洞，因为Python 2.7未使用。虽然这是一个Python 3.8容器，但是为了方便起见，镜像包含一个较旧的版本。关键的区别在于现在您知道什么是有漏洞的，并且可以就最终将服务部署到生产环境做出执行决策。
- en: 'A useful automation enhancement is to fail on a specific vulnerability level,
    such as `high`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有用的自动化增强功能是在特定漏洞级别（如`high`）上失败：
- en: '[PRE21]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This is another check that you can automate along with linting for robust container
    building. A well-written *Dockerfile* with constant reporting on vulnerabilities
    is an excellent way to enhance containerized models’ production delivery.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您可以与Linting一起自动化的另一个检查，用于构建强大的容器。一个写得很好的*Dockerfile*，并且始终报告漏洞是提升容器化模型生产交付的极好方式。
- en: Serving a Trained Model Over HTTP
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在HTTP上为训练模型提供服务
- en: 'Now that a few of the core concepts of creating a container are clear, let’s
    create a container that will serve a trained model over an HTTP API using the
    Flask web framework. As you already know, everything starts with the Dockerfile,
    so create one, assuming for now that a *requirements.txt* file is present in the
    current working directory:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在核心概念中有几个已经清晰，让我们创建一个容器，该容器将使用Flask Web框架通过HTTP API提供训练模型的服务。正如您已经了解的，一切都始于Dockerfile，所以现在创建一个，假设当前工作目录中有*requirements.txt*文件：
- en: '[PRE22]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: There are a few new things in this file that I have not covered before. First,
    we define an argument called `VERSION` that gets used as a variable for a `LABEL`.
    I’m using a [label schema convention](https://oreil.ly/PtOSK) that is useful to
    normalize how these labels are named. Using a version is a helpful way of adding
    informational metadata about the container itself. I will use this label later
    when I want to identify the version of the trained model. Imagine a situation
    where a container is not producing expected accuracy from a model; adding a label
    helps identify the problematic model’s version. Although this file uses one label,
    you can imagine that the more labels with descriptive data, the better.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件中有几个我以前没有涉及过的新东西。首先，我们定义了一个名为 `VERSION` 的参数，它作为 `LABEL` 的变量使用。我正在使用一个 [标签模式约定](https://oreil.ly/PtOSK)，有助于规范这些标签的命名。使用版本是一种有用的方式，用于添加有关容器本身的信息元数据。当容器未能从模型中产生预期的准确性时，添加标签有助于识别问题模型的版本。虽然此文件只使用一个标签，但可以想象使用更多带有描述性数据的标签会更好。
- en: Note
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There is a slight difference in the container image used. This build uses Python
    3.7 because at the time of writing, some of the dependencies do not work yet with
    Python 3.8\. Feel free to swap 3.7 for 3.8 and check if it now works.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此构建使用的容器镜像略有不同。这个构建使用 Python 3.7，因为在撰写本文时，一些依赖项尚不支持 Python 3.8\. 您可以随意将 3.7
    替换为 3.8 并检查它是否现在可以工作。
- en: 'Next, a *requirements.txt* file gets copied into the container. Create the
    requirements file with the following dependencies:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将 *requirements.txt* 文件复制到容器中。创建具有以下依赖项的 requirements 文件：
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, create a new directory called *webapp* so that the web files are contained
    in one place, and add the *app.py* file so that it looks like this:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建一个名为 *webapp* 的新目录，以便将 Web 文件放在一个地方，并添加 *app.py* 文件，使其看起来像这样：
- en: '[PRE24]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The last file needed is the trained model. If you are training the Boston Housing
    prediction dataset, make sure to place it within the *webapp* directory along
    with the *app.py* file and name it *boston_housing_prediction.joblib*. You can
    also find a trained version of the model in this [GitHub repository](https://oreil.ly/ibjG0).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 最后需要的文件是训练好的模型。如果正在训练波士顿房屋预测数据集，请确保将其放置在 *webapp* 目录中，与 *app.py* 文件一起，并将其命名为
    *boston_housing_prediction.joblib*。您也可以在这个 [GitHub 仓库](https://oreil.ly/ibjG0)
    中找到一个训练好的模型版本。
- en: 'The final structure of the project should look like this:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 项目的最终结构应如下所示：
- en: '[PRE25]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now build the container. In the example, I will use the run ID that Azure gave
    me when I trained the model as the version to make it easier to identify where
    the model came from. Feel free to use a different version (or no version at all
    if you don’t need one):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在构建容器。在示例中，我将使用 Azure 在我训练模型时给出的运行 ID 作为版本，以便更容易识别模型的来源。如果不需要版本，请随意使用不同的版本（或根本不使用版本）：
- en: '[PRE26]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Double-check that the image is now available after building:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 双重检查构建后镜像是否可用：
- en: '[PRE27]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now run the container in the background, exposing port `5000`, and verify it
    is running:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在后台运行容器，暴露端口 `5000`，并验证它是否在运行：
- en: '[PRE28]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'On your browser, open *http://localhost:5000* and the HTML from the `home()`
    function should welcome you to the Sklearn Prediction application. Another way
    to verify this is wired up correctly is using `curl`:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的浏览器中打开 *http://localhost:5000*，`home()` 函数返回的 HTML 应该欢迎您使用 Sklearn 预测应用程序。另一种验证方法是使用
    `curl`：
- en: '[PRE29]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You can use any tool that can send information over HTTP and process a response
    back. This example uses a few lines of Python with the `requests` library (make
    sure you install it before running it) to send a POST request with the sample
    JSON data:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用任何能够通过 HTTP 发送信息并处理返回响应的工具。本示例使用几行 Python 代码与 `requests` 库（确保在运行之前安装它）发送带有示例
    JSON 数据的 POST 请求：
- en: '[PRE30]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Write the Python code to a file and call it *predict.py*. Execute the script
    to get some predictions back on the terminal:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Python 代码写入文件并命名为 *predict.py*。在终端上执行该脚本以获取一些预测结果：
- en: '[PRE31]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Containerizing deployments is an excellent way to create portable data that
    can be tried by others. By sharing a container, the friction of setting up the
    environment is greatly reduced while ensuring a repeatable system to interact
    with. Now that you know how to create, run, debug, and deploy containers for ML,
    you can leverage this to start automating noncontainerized environments to speed
    up production deployments and enhance the whole process’s robustness. Aside from
    containers, there is a push to get services closer to the user, and that is what
    I will get into next with edge devices and deployments.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 容器化部署是创建可由他人尝试的便携数据的绝佳方式。通过共享容器，减少了设置环境的摩擦，同时确保了一个可重复使用的系统进行交互。现在你知道如何为机器学习创建、运行、调试和部署容器，可以利用这一点来开始自动化非容器化环境，加快生产部署并增强整个流程的稳健性。除了容器之外，还有一个推动力，即使服务更接近用户，这就是我接下来要讨论的边缘设备和部署。
- en: Edge Devices
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘设备
- en: 'The computational cost of (fast) inferencing was astronomical a few years ago.
    Some of the more advanced capabilities of machine learning that are available
    today were cost-prohibitive not long ago. Not only have costs gone down, but more
    powerful chips are getting produced. Some of these chips are explicitly tailored
    for ML tasks. The right combination of needed features for these chips allows
    inferencing in devices like mobile phones: fast, small, and made for ML tasks.
    When “deploying to the edge” is mentioned in technology, it refers to compute
    devices that are not within a data center along with thousands of other servers.
    Mobile phones, Raspberry PI, and smart home devices are some examples that fit
    the description of an “edge device.” In the last few years, large telecommunication
    companies have been pushing toward edge computing. Most of these edge deployments
    want to get faster feedback to users instead of routing expensive compute requests
    to a remote data center.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 几年前，（快速）推理的计算成本是天文数字。今天可用的一些更先进的机器学习功能在不久前是成本禁止的。成本不仅降低了，而且更强大的芯片正在生产中。其中一些芯片专门为机器学习任务量身定制。这些芯片的所需功能的正确组合允许在诸如手机之类的设备上进行推理：快速、小巧且专为机器学习任务而设计。当技术中提到“部署到边缘”时，指的是不在数据中心内的计算设备，以及成千上万的其他服务器。手机、树莓派和智能家居设备是符合“边缘设备”描述的一些例子。在过去几年中，大型电信公司一直在推动边缘计算。这些边缘部署中的大多数都希望向用户提供更快的反馈，而不是将昂贵的计算请求路由到远程数据中心。
- en: The general idea is that the closer the computational resources are to the user,
    the faster the user experience will be. There is a fine line that divides what
    may land at the edge versus what should go all the way to the data center and
    back. But, as I’ve mentioned, specialized chips are getting smaller, faster, and
    more effective; it makes sense to predict that the future means more ML at the
    edge. And the edge, in this case, will mean more and more devices that we previously
    didn’t think could handle ML tasks.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一般的想法是，计算资源距离用户越近，用户体验就会越快。有一条细微的界线，界定了什么可能在边缘落地，而不是完全回到数据中心。但正如我提到的，专用芯片变得更小、更快、更有效；可以预见未来意味着边缘计算中更多的机器学习。在这种情况下，边缘将意味着更多我们之前认为不能处理机器学习任务的设备。
- en: Most people living in countries with plenty of data centers hosting application
    data do not experience much lag at all. For those countries that do not, the problem
    is exacerbated. For example, Peru has several submarine cables that connect it
    to other countries in South America but no direct connectivity to the US. This
    means that if you are uploading a picture from Peru to a service that hosts its
    application in a data center in the US, it will take exponentially longer than
    a country like Panama with multiple cables going back to North America. This example
    of uploading a picture is trivial but gets even worse when computational operations
    like ML predictions are done on the sent data. This section explores a few different
    ways on how edge devices can help by performing fast inferencing done as close
    to the user as possible. If long distances are a problem, imagine what happens
    when there is no (or very limited) connectivity like a remote farm. If you need
    fast inferencing done in a remote location, the options are limited, and this
    is where the *deploying to the edge* has an advantage over any data center.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 居住在拥有大量数据中心托管应用数据的国家的大多数人几乎不会遇到延迟问题。对于那些不是这样的国家，问题会更加严重。例如，秘鲁有几条连接其与南美其他国家的海底电缆，但没有直接连接到美国的通路。这意味着，如果您从秘鲁上传图片到在美国数据中心托管应用的服务，速度将比像巴拿马这样的国家花费的时间长得多。这个上传图片的例子虽然微不足道，但在像
    ML 预测这样的计算操作上则会更糟。本节探讨了边缘设备如何通过尽可能接近用户执行快速推理来帮助解决长距离问题。如果长距离是一个问题，想象一下当像远程农场这样没有（或者连接非常有限）的地方会发生什么。如果您需要在远程位置进行快速推理，选项有限，这就是
    *部署到边缘* 比任何数据中心都有优势的地方。
- en: 'Remember, users don’t care that much about the spoon: they are interested in
    having a seamless way to try the delicious soup.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，用户并不太关心勺子：他们对于能顺利尝试美味汤的无缝方式更感兴趣。
- en: Coral
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Coral
- en: '[The Coral Project](https://coral.ai) is a platform that helps build local
    (on-device) inferencing that captures the essence of edge deployments: fast, close
    to the user, and offline. In this section, I’ll cover the [USB Accelerator](https://oreil.ly/id47e),
    which is an edge device that supports all major operating systems and works well
    with TensorFlow Lite models. You can compile most TensorFlow Lite models to run
    on this edge TPU (Tensor Processing Unit). Some aspects of operationalization
    of ML mean being aware of device support, installation methods, and compatibility.
    Those three aspects are true about the Coral Edge TPU: it works on most operating
    systems, with TensorFlow Lite models as long as they can get compiled to run on
    the TPU.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[珊瑚项目](https://coral.ai) 是一个平台，帮助构建本地（设备上的）推理，捕捉边缘部署的本质：快速、靠近用户和离线。在本节中，我将介绍
    [USB 加速器](https://oreil.ly/id47e)，这是一种支持所有主要操作系统并且与 TensorFlow Lite 模型兼容良好的边缘设备。您可以编译大多数
    TensorFlow Lite 模型以在这种边缘 TPU（张量处理单元）上运行。ML 的运营化的一些方面意味着需要了解设备支持、安装方法和兼容性。这三个方面对于珊瑚边缘
    TPU 是正确的：它适用于大多数操作系统，与 TensorFlow Lite 模型一起工作，只要能编译运行在 TPU 上即可。'
- en: 'If you are tasked to deploy a fast inferencing solution at the edge on a remote
    location, you must ensure that all the pieces necessary for such a deployment
    will work correctly. This core concept of DevOps is covered throughout this book:
    repeatable deployment methods that create reproducible environments are critical.
    To ensure that is the case, you must be aware of compatibility.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您被委派在边缘的远程位置部署快速推理解决方案，您必须确保所有部署所需的组件能正常工作。这本书贯穿了 DevOps 的核心概念：可重复部署的方法创建可重现的环境至关重要。为了确保这一点，您必须了解兼容性。
- en: 'First, start by installing the TPU runtime. For my machine, this means downloading
    and unzipping a file to run the installer script:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，开始安装 TPU 运行时。对于我的机器，这意味着下载并解压文件以运行安装脚本：
- en: '[PRE32]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: These setup examples use a Macintosh computer, so some of the installation methods
    and dependencies will vary from other operating systems. [Check the getting started
    guide](https://oreil.ly/B16Za) if you need support for a different computer.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这些设置示例使用的是 Macintosh 计算机，因此安装方法和依赖项会与其他操作系统有所不同。[查看入门指南](https://oreil.ly/B16Za)，如果您需要支持不同计算机。
- en: 'Now that the runtime dependencies are installed in the system, we are ready
    to try the edge TPU. The Coral team has a useful repository with Python3 code
    that helps run image classification with a single command. Create a directory
    to clone the contents of the repository to set up the workspace for image classification:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在系统中安装了运行时依赖项，我们准备尝试使用边缘TPU。Coral团队有一个有用的Python3代码仓库，可以通过一个命令来运行图像分类。创建一个目录来克隆该仓库的内容，以设置图像分类的工作空间：
- en: '[PRE33]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Note
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The `git` command uses a `--depth 1` flag, which performs a shallow clone. A
    shallow clone is desirable when the complete contents of the repository are not
    needed. Since this example is using the latest changes of the repository, there
    is no need to perform a full clone that contains a complete repository history.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`git`命令使用`--depth 1`标志执行浅克隆。当不需要完整的仓库内容时，浅克隆是可取的。由于这个例子使用了仓库的最新更改，因此不需要执行包含完整仓库历史记录的完整克隆。'
- en: 'For this example, do not run the *install_requirements.sh* script. First, make
    sure you have Python3 available and installed in your system and use it to create
    a new virtual environment; make sure that after activation, the Python interpreter
    points to the virtual environment and not the system Python:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在这个例子中，请不要运行*install_requirements.sh*脚本。首先确保你的系统中安装了Python3，并使用它创建一个新的虚拟环境；确保在激活后，Python解释器指向虚拟环境而不是系统Python：
- en: '[PRE34]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now that the *virtualenv* is active, install the two library dependencies and
    the TensorFlow Lite runtime support:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在虚拟环境*virtualenv*已经激活，请安装两个库依赖项和TensorFlow Lite运行支持：
- en: '[PRE35]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Both *numpy* and *Pillow* are straightforward to get installed in most systems.
    The outlier is the very long link that follows. This link is crucial to have,
    and it has to match your platform and architecture. Without that library, it is
    not possible to interact with the Coral device. [The Python installation guide
    for TensorFlow Lite](https://oreil.ly/VjFoS) is the right source to double-check
    what link you need to use for your platform.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*numpy*和*Pillow*在大多数系统中安装都很简单。唯一的异常是接下来的非常长的链接。这个链接非常重要，必须与您的平台和架构匹配。如果没有这个库，将无法与Coral设备进行交互。[TensorFlow
    Lite的Python安装指南](https://oreil.ly/VjFoS)是确认您需要使用哪个链接的正确来源。'
- en: 'Now that you have everything installed and ready to perform the image classification,
    run the *classify_image.py* script to get the help menu. Bringing back the help
    menu, in this case, is an excellent way to verify all dependencies were installed
    and that the script works correctly:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一切都安装好并准备好执行图像分类，运行*classify_image.py*脚本以获取帮助菜单。在这种情况下，重新显示帮助菜单是验证所有依赖项都已安装且脚本正常工作的好方法：
- en: '[PRE36]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Since I didn’t define any flags when I called the script, an error returned,
    mentioning that I do need to pass some flags. Before we start using the other
    flags, we need to retrieve a TensorFlow model to work with an image to test it.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 因为在调用脚本时我没有定义任何标志，返回了一个错误，提醒我需要传递一些标志。在开始使用其他标志之前，我们需要检索一个TensorFlow模型，用于处理要测试的图像。
- en: The [Coral AI site](https://oreil.ly/VZAun) has a models section where you can
    browse some of the specialized pretrained models it has for doing some image classification.
    Find the *iNat insects* one that recognizes over a thousand different types of
    insects. Download both the *tflite* model and the labels.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[Coral AI网站](https://oreil.ly/VZAun)有一个模型部分，您可以浏览一些专门预训练的模型，用于进行图像分类。找到识别一千多种不同昆虫的*iNat昆虫*模型。下载*tflite*模型和标签。'
- en: For this example, download a sample image of a common fly. [The original source
    of the image is on Pixabay](https://oreil.ly/UFfxq), but it is also conveniently
    accessible in the [GitHub repository for this book](https://oreil.ly/NHNIN).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在这个例子中，下载一个普通飞行图像的示例。[图像的原始来源在Pixabay上](https://oreil.ly/UFfxq)，但在[本书的GitHub存储库](https://oreil.ly/NHNIN)中也很方便地可以获取。
- en: Create directories for the model, labels, and image. Place the required files
    respectively in their directories. Having this order is not required, but it is
    useful to start adding more classification models, labels, and images later to
    play around more with the TPU device.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 创建模型、标签和图像的目录。分别将所需文件放置在它们的目录中。尽管不一定需要按照这个顺序，但以后添加更多分类模型、标签和图像以进一步使用TPU设备时会更方便。
- en: 'This is how the directory structure should look now:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 目录结构应该如下所示：
- en: '[PRE37]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Finally, we can try classification operations using the Coral device. Make
    sure that the device is plugged in with the USB cable, otherwise you will get
    a long traceback (which unfortunately doesn’t really explain what the problem
    is):'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以尝试使用Coral设备进行分类操作。确保设备已插入USB电缆，否则您将得到一长串的追溯信息（不幸的是，这并不真正解释问题所在）：
- en: '[PRE38]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'That error means that the device is unplugged. Plug it in and run the classification
    command:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 那个错误意味着设备未插入。请插入设备并运行分类命令：
- en: '[PRE39]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The image was classified correctly, and the common fly was detected! Find some
    other insect pictures and rerun the command to check how the model performs with
    different inputs.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图像被正确分类，普通苍蝇被检测到！找一些其他昆虫图片，并重新运行命令检查模型在不同输入下的表现。
- en: Azure Percept
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure Percept
- en: When this book was being written, Microsoft announced the release of a platform
    and hardware called Azure Percept. Although I didn’t have enough time to get hands-on
    practical examples on how to take advantage of its features, I feel it is worth
    mentioning some of its functionality.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在书写本书时，微软宣布发布一个名为Azure Percept的平台和硬件。虽然我没有足够的时间去实际操作如何利用其功能的实例，但我觉得值得提到一些它的功能。
- en: 'The same concepts that apply to the Coral device in the previous section and
    to the edge, in general, apply to the devices for Percept: they allow seamless
    machine learning operations at the edge.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一节中Coral设备以及边缘一般相同的概念适用于Percept设备：它们允许在边缘进行无缝机器学习操作。
- en: First, it is important to emphasize that although the Percept products are mostly
    advertised as pieces of hardware, Azure Percept is a whole platform for doing
    edge computing, from the devices themselves all the way to deployment, training,
    and management in Azure. There is also support for the major AI platforms like
    ONNX and TensorFlow, making it easier to try out with prebuilt models.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，重要的是要强调，尽管Percept产品大多作为硬件组件进行广告宣传，但Azure Percept是一个完整的边缘计算平台，从设备本身到在Azure中的部署、训练和管理。还支持主要的AI平台如ONNX和TensorFlow，使得试用预建模型变得更加简单。
- en: One downside of the Azure Percept hardware compared to the Coral devices is
    that it is much more expensive, making it harder to buy one of its bundles to
    try the new technology. As always, Microsoft has done a stellar job in [documenting
    and adding a good amount of context and examples](https://oreil.ly/MFIKf) that
    are worth exploring if you are interested.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 与Coral设备相比，Azure Percept硬件的一个缺点是价格昂贵，这使得很难购买其捆绑产品来尝试新技术。正如以往一样，微软在[文档化并添加大量上下文和示例](https://oreil.ly/MFIKf)方面做得非常出色，如果您感兴趣，值得探索。
- en: TFHub
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFHub
- en: A great resource to find TensorFlow models is the [TensorFlow Hub](https://tfhub.dev).
    The hub is a repository of thousands of pretrained models ready to be used. For
    the Coral Edge TPU, not all models will work, though. Since the TPU has separate
    instructions specific to the device, a model needs to be explicitly compiled for
    it.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 找到TensorFlow模型的一个很好的资源是[TensorFlow Hub](https://tfhub.dev)。该hub是一个存储库，其中包含数千个预训练模型可供使用。对于Coral
    Edge TPU，并非所有模型都能正常工作。由于TPU具有针对设备的单独说明，模型需要专门为其编译。
- en: Now that you can run classifications with the Coral USB device, you can use
    TFHub to find other pretrained models to work with. At the hub, a Coral model
    format is available; click on it to get to [the models ready to use for the TPU](https://oreil.ly/mJv9N)
    as shown in [Figure 3-2](#Figure-3-1_2).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以使用Coral USB设备运行分类操作，可以使用TFHub查找其他预训练模型进行工作。在hub上，有一个Coral模型格式；点击进入[用于TPU的可用模型](https://oreil.ly/mJv9N)，如[图 3-2](#Figure-3-1_2)所示。
- en: '![pmlo 0302](Images/pmlo_0302.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0302](Images/pmlo_0302.png)'
- en: Figure 3-2\. TFHub Coral models
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. TFHub Coral模型
- en: Select the *MobileNet Quantized V2* model for download. This model can detect
    over a thousand objects from images. The previous examples using Coral require
    the labels and the model, so make sure you download that as well.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 选择*MobileNet Quantized V2*模型进行下载。该模型可以从图像中检测超过一千个对象。之前使用Coral的示例需要标签和模型，因此请确保您也下载了这些。
- en: Note
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: When these models are presented in the TFHub website, multiple different formats
    are available. Ensure you double-check which model format you are getting, and
    that (in this case) it is compatible with the Coral device.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当这些模型在TFHub网站上展示时，有多种不同的格式可用。确保仔细检查您获取的模型格式，并且（在本例中）它与Coral设备兼容。
- en: Porting Over Non-TPU Models
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移植非TPU模型
- en: You might find that the model you need is available in some situations but not
    compiled for the TPU device you have. The Coral Edge TPU does have a compiler
    available, but it isn’t installable in every platform as the runtime dependencies
    are. When such situations come up, you have to get creative on the solutions and
    always attempt to find the automation within any workarounds possible. The compiler
    documentation requires a Debian or Ubuntu Linux distribution, and the instructions
    on how to get everything set up for the compiler are tied to that particular distro.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会发现你需要的模型在某些情况下可用，但没有为你所拥有的TPU设备编译。Coral Edge TPU确实有一个可用的编译器，但并非每个平台都可以安装运行时依赖项。当遇到这种情况时，你必须在解决方案上进行创意尝试，并始终尝试找到任何可能的解决方案中的自动化。编译器文档要求Debian或Ubuntu
    Linux发行版，并且设置编译器的说明与该特定发行版相关联。
- en: In my case, I’m working from an Apple computer, and I don’t have other computers
    running Linux. What I *do have* is a container runtime installed locally in which
    I can run any image from any distro with a few commands. We’ve already covered
    how to get started with containers, how to run them, and how to create them. And
    this is the perfect use case for creating a new Debian-based container with everything
    installed for the compiler to solve this problem.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的情况下，我是在一台Apple电脑上工作，并且没有其他运行Linux的计算机。我拥有的是本地安装的容器运行时，在这个运行时中，我可以用几个命令运行来自任何发行版的任何镜像。我们已经讨论过如何开始使用容器，如何运行它们以及如何创建它们。这是一个创建一个新的基于Debian的容器，并为编译器安装所有内容来解决这个问题的完美用例。
- en: 'Now that we understand the problem and have a solution in mind with containers,
    create a new *Dockerfile* to build a container image for the compiler:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了问题，并且有了一个使用容器的解决方案，我们可以创建一个新的*Dockerfile*来构建一个容器镜像以供编译器使用。
- en: '[PRE40]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'With the newly created *Dockerfile*, create a new image to run the compiler:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 利用新创建的*Dockerfile*，创建一个新的镜像来运行编译器：
- en: '[PRE41]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: I’ve identified [a model](https://oreil.ly/b7o64) that I want to use with the
    TPU compiler but doesn’t come compiled for it.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经找到了一个我想要与TPU编译器一起使用但没有为其编译的[模型](https://oreil.ly/b7o64)。
- en: Note
  id: totrans-169
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Only models that are precompiled for TensorFlow Lite and are quantized will
    work with the compiler. Ensure that models are both *tflite* and *quantized* before
    downloading them to convert them with the compiler.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 只有为TensorFlow Lite预编译且量化的模型才能与编译器一起工作。确保模型同时是*tflite*和*quantized*，然后再将其下载以便用编译器转换。
- en: 'Download the model locally. In this case, I use the command line to save it
    in the current working directory:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地下载模型。在这种情况下，我使用命令行将其保存在当前工作目录中：
- en: '[PRE42]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Although I’ve used the command line, you can also download the model by going
    [to the model on the website](https://oreil.ly/NeI87). Ensure you move the file
    to the current working directory for the next steps.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我已经使用了命令行，但你也可以通过访问[网站上的模型](https://oreil.ly/NeI87)来下载模型。确保将文件移动到当前工作目录以进行下一步操作。
- en: We need to get the downloaded model into the container and then copy back the
    files locally. Docker makes this task somewhat more manageable by using a *bind
    mount*. This mount operation will link a path from my machine into the container,
    effectively sharing anything I have into the container. This also works great
    for files created in the container, and I need them back on the local machine.
    Those files created in the container will appear automatically in my local environment.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将下载的模型放入容器中，然后将文件本地复制回来。通过*bind mount*，Docker可以使这个任务变得更加可管理。这种挂载操作将把我的机器上的路径链接到容器中，有效地共享我拥有的任何东西到容器中。这对于在容器中创建的文件也非常有效，因为我需要它们回到本地环境中。这些在容器中创建的文件将自动出现在我的本地环境中。
- en: 'Start the container with the bind mount:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 通过绑定挂载启动容器：
- en: '[PRE43]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: There are a couple of things happening with the previous command. First, I’m
    using `PWD` to indicate that the current working directory, where the *mobilenet_v1_50_160_quantized.tflite*
    file exists, is what I want in the container. The destination path within the
    container is */models*. And lastly, I’m using the container built with the tag
    `tpu-compiler` to specify the container I need. If you used a different tag when
    building the image, you would need to update that part of the command. After starting
    the container, I change directories into */models*, list the directory contents,
    and find the downloaded model in my local machine. The environment is now ready
    to use the compiler.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个命令中有几件事情在发生。首先，我使用`PWD`来指示当前工作目录，在这个目录中，*mobilenet_v1_50_160_quantized.tflite*文件存在于容器中的目标路径是*/models*。最后，我使用了带有标签`tpu-compiler`的构建容器来指定我需要的容器。如果你在构建镜像时使用了不同的标签，你需要更新命令中的这部分。启动容器后，我切换到*/models*目录，列出目录内容，并在本地机器上找到了下载的模型。环境现在已准备好使用编译器。
- en: 'Verify the compiler works by calling its help menu:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用其帮助菜单来验证编译器是否工作：
- en: '[PRE44]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Next, run the compiler against the quantized model:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，对量化模型运行编译器：
- en: '[PRE45]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The operation took less than a second to run and produced a few files, including
    the newly compiled model (*mobilenet_v1_50_160_quantized_edgetpu.tflite*) that
    you can now use with the edge device.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作少于一秒就运行完毕，并生成了一些文件，包括新编译的模型（*mobilenet_v1_50_160_quantized_edgetpu.tflite*），你现在可以用在边缘设备上。
- en: 'Finally, exit out of the container, go back to the local machine, and list
    the contents of the directory:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，退出容器，返回本地机器，并列出目录的内容：
- en: '[PRE46]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This is a handy workaround to requiring an operating system for a tool. Now
    that this container can compile models for the edge device, it can be automated
    further by porting over models you need with a few lines in a script. Remember
    that there are a few assumptions made in the process and that you must ensure
    these assumptions are all accurate at compile time. Otherwise, you will get errors
    from the compiler. This process is an example of trying to use a nonquantized
    model with the compiler:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这是绕过工具操作系统需求的一个方便的解决方法。现在这个容器可以为边缘设备编译模型，可以通过脚本中的几行代码进一步自动化移植你所需的模型。记住，在这个过程中做了一些假设，你必须确保这些假设在编译时都是准确的。否则，你将会从编译器那里得到错误。这个过程是试图使用非量化模型与编译器配合的一个示例：
- en: '[PRE47]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Containers for Managed ML Systems
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理型ML系统的容器
- en: At the heart of advanced next-generation MLOps workflows are managed ML systems
    like AWS SageMaker, Azure ML Studio, and Google’s Vertex AI. All of these systems
    build on top of containers. Containers are a secret ingredient for MLOps. Without
    containerization, it is much more challenging to develop and use technologies
    like AWS SageMaker. In [Figure 3-3](#Figure-3-1-2), notice that the EC2 Container
    Registry is the location where the inference code image and the training code
    live.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在高级下一代MLOps工作流的核心是像AWS SageMaker、Azure ML Studio和Google的Vertex AI这样的管理型ML系统。所有这些系统都基于容器构建。容器是MLOps的一个秘密武器。没有容器化，开发和使用AWS
    SageMaker等技术就会更具挑战性。在[图 3-3](#Figure-3-1-2)中，请注意EC2容器注册表是推断代码镜像和训练代码的位置。
- en: '![pmlo 0303](Images/pmlo_0303.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0303](Images/pmlo_0303.png)'
- en: Figure 3-3\. SageMaker containers
  id: totrans-190
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. SageMaker容器
- en: This process is critically important because it allows DevOps best practices
    to bake into creating these images—among these most importantly are continuous
    integrations and continuous delivery. Containers increase the entire ML architecture
    quality by reducing complexity since the images are already “baked.” Intellectual
    horsepower can shift to other problems like data drift, analyzing the feature
    store for suitable candidates for a newer model, or evaluating whether the new
    model solves customer needs.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程至关重要，因为它允许DevOps最佳实践融入到创建这些镜像中——其中最重要的是持续集成和持续交付。容器通过减少复杂性来提高整个ML架构的质量，因为镜像已经“烘焙”好了。智力资源可以转移到其他问题，比如数据漂移，分析特征存储以寻找适合新模型的候选人，或评估新模型是否解决了客户需求。
- en: Containers in Monetizing MLOps
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在商业化MLOps中的容器
- en: Monetizing MLOps is another crucial problem for both startups and large companies.
    Containers play a role yet again! In the case of SageMaker, use either an algorithm
    or a model sold in the AWS Marketplace, as shown in [Figure 3-4](#Figure-3-1-3).
    They are the mode of delivery for the product sold.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 对于初创公司和大公司来说，Monetizing MLOps是另一个关键问题。容器再次发挥了作用！在SageMaker的情况下，可以使用在AWS Marketplace中展示的算法或模型，如[图 3-4](#Figure-3-1-3)所示。它们是产品销售的交付方式。
- en: '![pmlo 0304](Images/pmlo_0304.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0304](Images/pmlo_0304.png)'
- en: Figure 3-4\. SageMaker seller workflow
  id: totrans-195
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. SageMaker卖家工作流程
- en: The advantage of a container as a product is that it is sold much like other
    products sold in a physical store, such as peanut butter, flour, or milk. In the
    scenario where a company decides to produce high-quality, organic peanut butter,
    it may want to focus strictly on making the peanut butter, not building out a
    network of stores to sell the peanut butter.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 作为产品，容器的优势在于其销售方式类似于在实体店销售的其他产品，比如花生酱、面粉或牛奶。在公司决定生产高质量有机花生酱的情况下，可能希望专注于生产花生酱，而不是建立销售花生酱的店铺网络。
- en: Likewise, in companies looking to monetize machine learning, the container is
    an ideal package for delivering both models and algorithms to customers. Next,
    let’s take a look at how you can build once and run many with containers.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，在希望从机器学习中获利的公司中，容器是向客户交付模型和算法的理想封装。接下来，让我们看看如何通过容器一次构建多次运行。
- en: Build Once, Run Many MLOps Workflow
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一次构建，多次运行的MLOps工作流程
- en: Ultimately a container process for MLOps culminates in many rich options for
    both product and engineering. In [Figure 3-5](#Figure-3-1-4), you see that a container
    is an ideal package to monetize intellectual property from a product perspective.
    Likewise, from an engineering perspective, a container can serve out predictions,
    do training, or deploy to an edge device like a Coral TPU or Apple iPhone.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，MLOps的容器化过程为产品和工程师提供了许多丰富的选择。在[图 3-5](#Figure-3-1-4)中，您可以看到从产品角度看，容器是实现知识产权商业化的理想封装。同样地，从工程角度看，容器可以用于提供预测结果、进行训练，或者部署到像Coral
    TPU或Apple iPhone这样的边缘设备上。
- en: '![pmlo 0305](Images/pmlo_0305.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0305](Images/pmlo_0305.png)'
- en: Figure 3-5\. Build Once, Run Many MLOps container
  id: totrans-201
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5\. 一次构建，多次运行的MLOps容器
- en: MLOps and container technology are complementary in that containers help you
    deliver business value. MLOps methodologies then build directly on top of this
    technology to streamline productivity and add value. Next, let’s wrap up the chapter
    and summarize the essential aspects of containers for MLOps.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps和容器技术是互补的，因为容器帮助您交付业务价值。然后，MLOps方法直接建立在这项技术之上，以优化生产效率并增加价值。接下来，让我们结束本章，总结容器在MLOps中的重要方面。
- en: Conclusion
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: When operationalizing ML models, you will often encounter many different possibilities
    for deployment. It is becoming fairly common to see models getting deployed on
    mobile phones and other (small) devices that you can plug into any computer with
    a USB port. The problems that edge inferencing provides (like offline, remote,
    and fast access) can be transformational, specifically for remote regions without
    access to a reliable source of power and network. Similar to edge devices, containerization
    enables faster and more reliable reproduction of environments. Reproducible machine
    environments were a challenging problem to solve just a few years ago. Containerization
    is exceptionally relevant in that case. Fast scaling of resources and transitioning
    deployment environments from cloud providers, or even moving workloads from on-premise
    (local) to the cloud is far easier to accomplish with containers.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在操作化ML模型时，您经常会遇到许多不同的部署可能性。越来越普遍地看到模型部署在手机和其他（小型）设备上，您可以将其插入任何带有USB端口的计算机。边缘推理提供的问题（如离线、远程和快速访问）可能会产生转型效应，特别是对于没有可靠电源和网络访问的偏远地区。与边缘设备类似，容器化使环境的再现更快速、更可靠。几年前，可再现的机器环境是一个具有挑战性的问题。在这种情况下，容器化尤为重要。通过容器，资源的快速扩展和从云提供商转换部署环境，甚至将工作负载从本地部署到云中，都变得更加容易。
- en: With that covered, our next chapter dives into the continuous delivery process
    for machine learning models.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们的下一章将深入探讨机器学习模型的持续交付流程。
- en: Exercises
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Recompile a model to work with the Coral Edge TPU from TFHub.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新编译模型以适应TFHub的Coral Edge TPU。
- en: Use the MobileNet V2 model to perform inference on other objects and get accurate
    results.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MobileNet V2模型对其他对象进行推理，获得准确的结果。
- en: Create a new container image, based on the Flask example, that serves a model
    and that provides examples on a `GET` request to interact with the model. Create
    another endpoint that provides useful metadata about the model.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新的容器镜像，基于 Flask 示例，用于服务一个模型，并在 `GET` 请求中提供与模型交互的示例。创建另一个端点，提供关于模型的有用元数据。
- en: Publish the newly created image to a container registry like [Docker Hub](https://hub.docker.com).
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将新创建的镜像发布到像 [Docker Hub](https://hub.docker.com) 这样的容器注册表。
- en: Critical Thinking Discussion Questions
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批判性思维讨论问题
- en: Would it be possible to use a container to perform online predictions with an
    edge TPU device like Coral? How? or Why not?
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否可以使用容器来使用类似 Coral 的边缘 TPU 设备进行在线预测？如何？或为什么不？
- en: What is a container runtime, and how does it relate to Docker?
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器运行时是什么，它与 Docker 有什么关系？
- en: Name three good practices when creating a Dockerfile.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 Dockerfile 时的三个良好实践方法是什么？
- en: What are two critical concepts of DevOps mentioned in this chapter? Why are
    they useful?
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章提到的 DevOps 的两个关键概念是什么？它们为什么有用？
- en: Create a definition, in your own words, of what the “edge” is. Give some ML
    examples that can be applied.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个定义，用你自己的话来描述“边缘”是什么。给出一些可以应用的机器学习示例。
