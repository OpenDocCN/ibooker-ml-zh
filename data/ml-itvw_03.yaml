- en: 'Chapter 3\. Technical Interview: Machine Learning Algorithms'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章。技术面试：机器学习算法
- en: In [Chapter 1](ch01.html#machine_learning_roles_and_the_interview), you learned
    about the various steps you will go through as part of your ML interviews. In
    [Chapter 2](ch02.html#machine_learning_job_application_and_res), you looked at
    how to tie your experiences to roles of interest as well as how to craft a relevant
    resume. The goal of the previous chapters was to get you invited to interviews.
    In this chapter, I’ll focus on ML algorithms. As you recall, the interview process
    is illustrated in [Figure 1-9](ch01.html#ml_interview_process), and the ML algorithms
    interview is only one portion of the technical interviews; the rest, such as ML
    training and evaluation, coding, and so on, will be covered in subsequent chapters.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Chapter 1](ch01.html#machine_learning_roles_and_the_interview)中，你了解了作为ML面试一部分将要经历的各个步骤。在[Chapter 2](ch02.html#machine_learning_job_application_and_res)中，你学习了如何将你的经验与感兴趣的角色联系起来，以及如何制作相关的简历。前几章的目标是让你受邀参加面试。在本章中，我将专注于ML算法。正如你记得的那样，面试流程如[Figure 1-9](ch01.html#ml_interview_process)所示，ML算法面试仅仅是技术面试的一部分；其余部分，如ML训练和评估、编码等，将在随后的章节中讨论。
- en: Overview of the Machine Learning Algorithms Technical Interview
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习算法技术面试概述
- en: 'You’re likely to be asked ML algorithm technical questions in an interview
    if you’re applying for any of the following jobs:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你申请以下任何工作，可能会被问及ML算法技术问题：
- en: Data scientist who builds ML models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建ML模型的数据科学家
- en: Machine learning engineer
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习工程师
- en: Applied scientist
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用科学家
- en: And similar roles
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及类似的角色
- en: Recall that within the common ML job titles ([Figure 1-8](ch01.html#common_ml_job_titles_and_how_they_corres)),
    there are some jobs that have the responsibility of training ML models in the
    ML lifecycle. This chapter focuses on assessing candidates for those skills; if
    the job you’re aiming for focuses less on training ML models, you might get a
    simplified version of this type of interview, or it might be skipped completely.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾常见的机器学习职位标题（[Figure 1-8](ch01.html#common_ml_job_titles_and_how_they_corres)），有一些职位的责任是在机器学习生命周期中训练ML模型。本章重点评估这些技能的候选人；如果你申请的职位不太侧重于训练ML模型，你可能会得到这种类型面试的简化版本，或者完全跳过。
- en: This interview is meant to assess your understanding of ML algorithms, especially
    on the theoretical side. As to how you implement the algorithms with code, I cover
    that in the model deployment questions in [Chapter 6](ch06.html#technical_interviewcolon_model_deploymen)
    and the coding/programming technical interview in [Chapter 5](ch05.html#technical_interviewcolon_coding).
    The goal for you as an interviewee is for the interviewers to confirm that you
    understand the underlying concepts behind ML algorithms. Roles do exist where
    all you have to know is how to import the library with Python, but for more advanced
    projects, an underlying understanding can help you customize various ML approaches
    and better debug and troubleshoot models. As covered in [Chapter 1](ch01.html#machine_learning_roles_and_the_interview),
    in the three pillars of ML roles, this is the pillar of ML algorithm and data
    intuition, which showcases your ability to adapt (refer to [Figure 1-6](ch01.html#three_pillars_of_machine_learning_jobs)).
    This skill is especially important in companies that have complex ML use cases
    and custom-made solutions, where you might modify or combine various off-the-shelf
    methods or create something from scratch.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这个面试旨在评估你对ML算法的理解，特别是理论方面。关于如何用代码实现算法的问题，我在[Chapter 6](ch06.html#technical_interviewcolon_model_deploymen)的模型部署问题和[Chapter 5](ch05.html#technical_interviewcolon_coding)的编程技术面试中进行了讨论。作为受访者，你的目标是让面试官确认你理解ML算法背后的概念。确实存在一些角色，你只需知道如何用Python导入库即可，但对于更高级的项目，理解其背后的原理可以帮助你定制各种ML方法，更好地调试和排查模型问题。正如在[Chapter 1](ch01.html#machine_learning_roles_and_the_interview)中所述，在机器学习角色的三个支柱中，这是ML算法和数据直觉的支柱，展示了你适应能力（参考[Figure 1-6](ch01.html#three_pillars_of_machine_learning_jobs)）。这种能力在有复杂ML用例和定制解决方案的公司尤为重要，在这些公司中，你可能需要修改或组合各种现成的方法，或者从头开始创建某些内容。
- en: Note
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: I try to mention as many common algorithms as space allows, but there are many
    more techniques under the sun. Be sure to check out the linked resources to extend
    your learning and interview preparation!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我尽量提到尽可能多的常见算法，但是世界上还有更多的技术。请务必查看链接的资源，以扩展你的学习和面试准备！
- en: It is also important to note that, in addition to understanding the ML algorithms’
    inner workings and underlying statistical methods, you need to successfully communicate
    that understanding to the interviewer. Yes, I know that communication skills have
    been brought up many times in this book, but they are what help set you apart
    as a successful candidate.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意的是，除了理解机器学习算法的内部工作原理和基础统计方法之外，你还需要成功地将这种理解传达给面试官。是的，我知道在这本书中已经多次提到沟通技巧，但这正是帮助你脱颖而出成为成功候选人的关键。
- en: 'As a rule of thumb, it’s important to be able to explain algorithms and ML
    concepts at two levels: on a simple “explain like I’m five years old” level and
    at a deeper, technical level, one more appropriate for a college course. A second
    rule of thumb is to be prepared to answer follow-up questions to these ML algorithm
    interview questions. This is so the interviewer knows that you didn’t just memorize
    and then regurgitate the answer, but that you can apply it to various real-life
    scenarios on the job.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经验法则是，重要的是能够以两个层次解释算法和机器学习概念：一个简单的“像我五岁时解释”的水平，以及更深入、更技术的水平，更适合大学课程。第二个经验法则是要准备好回答这些机器学习算法面试问题的跟进问题。这样面试官就知道你不仅仅是记住并复述答案，而是能够将其应用到工作中的各种实际场景中。
- en: 'In this chapter, I break down technical questions on the following topics so
    you can easily refer to a specific question if your interview focuses on that
    topic:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我详细讨论了以下技术问题，这样你就可以在面试集中讨论某个特定主题时轻松查阅：
- en: Statistical techniques
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计技术
- en: Supervised, unsupervised, and reinforcement learning
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习、无监督学习和强化学习
- en: Natural language processing (NLP)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）
- en: Recommender systems
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统
- en: Reinforcement learning
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习
- en: Computer vision
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: Note
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In technical interviews that are very structured, such as the Amazon data science
    initial phone screen, they will ask you clearly scoped questions, such as asking
    for a definition of a particular algorithm. After you answer, they will generally
    move on without additional follow-up questions. There are companies that mix structured
    questions with a free-form discussion, where the interviewer might dig deeper
    into your answer, and the conversation might branch out from there into your past
    experiences.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在非常结构化的技术面试中，比如亚马逊数据科学初步电话筛选中，他们会明确问你一些范围明确的问题，比如要求你定义特定的算法。在你回答后，他们通常会继续下一个问题而不会有额外的跟进问题。有些公司会混合结构化问题和自由讨论，面试官可能会深入探讨你的回答，对话也可能从你的过往经验扩展开来。
- en: Statistical and Foundational Techniques
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计和基础技术
- en: Statistical techniques are used in every data role, and these techniques are
    the foundations for ML projects. Hence, in ML interviews, you will most likely
    have questions that cover this topic.^([1](ch03.html#ch03fn1)) Statistical techniques
    help build baseline models to compare more costly models and algorithms against
    or help discover if there is enough meaningful data in the first place to build
    ML models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 统计技术在每一个数据角色中都被使用，并且这些技术是机器学习项目的基础。因此，在机器学习面试中，你很可能会被问及涵盖这个主题的问题^([1](ch03.html#ch03fn1))。统计技术帮助构建基准模型，用于与更昂贵的模型和算法进行比较，或者帮助发现首先是否有足够有意义的数据来构建机器学习模型。
- en: For the purposes of this book, I will be placing the foundational regression
    techniques in this section, as well as various techniques for training and improving
    ML models. In short, these are (1) foundational techniques and (2) methods used
    during model training, such as training splits, regularization, and so on. These
    concepts are foundational knowledge for any type of ML algorithms that will be
    mentioned later as well as foundations for ML interview questions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本书的目的，我将把基础回归技术放在本节，以及用于训练和改进机器学习模型的各种技术。简而言之，这些是（1）基础技术和（2）模型训练期间使用的方法，如训练集拆分、正则化等。这些概念是任何类型的机器学习算法的基础知识，后面提到的ML面试问题也是如此。
- en: This section covers the basics of statistical techniques for those who are unsure
    whether they have sufficient background knowledge in this area. Feel free to skip
    the subsections if you already have expertise in any of these areas. Regardless
    of your expertise, I’ve highlighted specific advice for ML interviews in the tip
    boxes to help you apply your knowledge of each ML area and excel in your interviews.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了统计技术的基础知识，特别是对于那些不确定是否具有足够背景知识的人。如果你已经在这些领域有专业知识，可以跳过子章节。无论你的专业水平如何，我都在提示框中强调了ML面试的具体建议，以帮助你应用你在每个ML领域的知识并在面试中表现出色。
- en: Now, let’s jump in.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始吧。
- en: Summarizing Independent and Dependent Variables
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结独立变量和因变量
- en: Here’s an overview of one of the foundations of ML algorithms—variables—and
    a simple example of fitting a model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是机器学习算法基础之一——变量的概述，以及拟合模型的一个简单示例。
- en: Let’s say that you have a dataset about apples, with the *weight* and *height*
    of each apple. You also have a list of *past sales prices* of each apple. With
    the list of apple weights, heights, and past sales prices, you want to guess the
    sales price of *new* apples, before they are sold. For the sake of this example,
    ignore big grocery chains automatically calculating a price, but let’s say you’re
    selling as a hobby to friends and family, or maybe you’re running a farm that
    a grandparent left you. So you are making use of the weight and height of each
    single new apple to predict its price. Weight and height are fixed observations
    at that point in time (an apple can’t be both 100 grams and 150 grams at the same
    time).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个关于苹果的数据集，包括每个苹果的*重量*和*高度*。你还有每个苹果的*过去销售价格*列表。有了苹果重量、高度和过去销售价格的列表，你想要在它们被卖出之前猜测新苹果的销售价格。为了这个例子，忽略大型连锁超市自动计算价格的情况，假设你是在向朋友和家人出售，或者你正在经营祖父留给你的农场。因此，你正在利用每个新苹果的重量和高度来预测其价格。在那一时刻，重量和高度是固定的观察结果（一个苹果不能同时既是100克又是150克）。
- en: Now, to connect all these concepts, let’s add in some terminology. *Variables*
    refer to everything that is being taken into account in your model of how apple
    prices are calculated. So the variables in this case include weight, height, and
    price. Within these variables, you know the weight and height of each new apple,
    and they are fixed at that point in time. So the weight and height are *independent*
    variables. Then, you have another variable, price, that you’d like to predict
    for new apples prior to knowing the correct answer before selling them. The predicted
    price *depends* on the height and weight of the new apple. For example, heavier
    and taller apples sell for more money. Thus, price is a *dependent* variable (shown
    in [Table 3-1](#examples_of_independent_and_dependent_va)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了连接所有这些概念，让我们加入一些术语。*变量*指的是在计算苹果价格模型中考虑的所有内容。因此，在这种情况下，变量包括重量、高度和价格。在这些变量中，你知道每个新苹果的重量和高度，并且它们在那个时刻是固定的。因此，重量和高度是*独立*变量。然后，你有另一个变量，价格，你希望在卖出之前预测新苹果的价格。预测的价格*依赖于*新苹果的高度和重量。例如，重量更重、高度更高的苹果卖得更贵。因此，价格是一个*因变*量（在[表 3-1](#examples_of_independent_and_dependent_va)中显示）。
- en: Table 3-1\. Examples of independent and dependent variables
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-1\. 独立变量和因变量示例
- en: '| Independent variables | Dependent variable |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 独立变量 | 因变量 |'
- en: '| --- | --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Apple weight Apple height'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '| 苹果重量 苹果高度'
- en: Apple color
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 苹果颜色
- en: Apple variety | Price |
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 苹果品种 | 价格 |
- en: Defining Models
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义模型
- en: 'Models are a way of using past data points to describe “the way the world works,”
    or, in other words, a way of finding patterns and connections with past information.
    The apples example from the previous section uses a *model* that describes the
    way pricing works. The model is something that knows the “truth”—even if it’s
    not the full truth but rather our best attempt to approximate the truth. Thus,
    the model can be used to predict our best approximation of future data points.
    This applies for all “models” in ML models. Recommender-system models seek to
    predict what a user will like or click on when visiting a website. Convolutional
    neural networks (CNNs) for image recognition “learn” a model of what various pixels
    represent: is this cluster and layout of pixels a cat or a dog?'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是使用过去的数据点来描述“世界运作方式”的一种方式，或者说是一种找出过去信息的模式和联系的方式。前面章节中的苹果示例使用了描述定价方式的*模型*。模型是一种了解“真相”的方式
    — 即使它不是完全的真相，而是我们对真相的最佳尝试的近似。因此，模型可以用来预测我们对未来数据点的最佳近似。这适用于所有的ML模型。“推荐系统”模型试图预测用户在访问网站时会喜欢或点击什么。“卷积神经网络”（CNN）用于图像识别，“学习”各种像素代表的模型：这个像素群和布局是猫还是狗？
- en: Just as for independent and dependent variables, it is important to have a shared
    definition for “model” to prevent miscommunication during an interview, such as
    confusing algorithms with models.^([2](ch03.html#ch03fn2)) The model is the outcome
    of having run and fit an ML algorithm.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于独立和依赖变量，就像在面试中有一个共享的“模型”定义是很重要的，以防止误解，比如混淆算法与模型。^([2](ch03.html#ch03fn2))
    模型是运行和拟合ML算法后的结果。
- en: Summarizing Linear Regression
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结线性回归
- en: I wanted to make sure I included regression models. I’m glad that I learned
    the detailed ins and outs of linear and logistic regression, even calculating
    them by hand (a requirement for the second-year statistics course I was taking
    as part of an economics major at university). This knowledge has compounded and
    helped me understand the new ML algorithms I’ve encountered as well as how to
    apply them in practice. All of my learning stemmed from understanding these entry-level
    concepts, so I highly recommend not shying away from learning the mathematics
    of regression models. Again, feel free to skip this section if you already have
    expertise in this area.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我想确保包括回归模型。我很高兴我学到了线性回归和逻辑回归的详细内部和外部，甚至手动计算它们（这是我在大学经济学专业第二年统计课程中的要求）。这些知识已经累积并帮助我理解我遇到的新ML算法以及如何在实践中应用它们。所有我的学习都源于理解这些入门级概念，所以我强烈建议不要在学习回归模型的数学方面退缩。如果你已经在这个领域有专业知识，可以随时跳过这一部分。
- en: Let’s use the apple example from an earlier section in a graph. For simplicity
    and to squeeze it onto a two-dimensional graph, let’s use just one independent
    variable, *weight*, to predict the dependent variable, *price*. Each dot on the
    graph in [Figure 3-1](#linear_regression) represents a data point from past sales,
    so you already know the sale prices for them. For example, the dot with a callout
    on the graph weighs 80 grams (its intersect on the x-axis) and sold for $1 (its
    intersect on the y-axis). Note that this is a simple example; most usage of linear
    regression will have multiple independent variables (“multivariable”) and if visualized,
    will be a line in an *N*-dimensional space, where *N* = number of variables +
    1 (when there is one output variable). In addition, this example has one dependent
    variable; when there are multiple dependent/output variables, the regression task
    is referred to as being *multivariate*. Note that *multivariate* is separate from
    the “multivariable” concept mentioned earlier.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在图表中使用前面章节的苹果示例。为了简化起见并将其压缩到二维图表中，我们只使用一个独立变量，*重量*，来预测依赖变量，*价格*。图中的每个点代表过去销售的数据点，因此你已经知道它们的销售价格。例如，图中带有标注的点重量为80克（在x轴上的交点），售价为$1（在y轴上的交点）。请注意，这只是一个简单的例子；大多数线性回归的使用会有多个独立变量（“多变量”），如果可视化，将会是在*N*维空间中的一条线，其中*N*
    = 变量数 + 1（当有一个输出变量时）。此外，此示例有一个依赖变量；当有多个依赖/输出变量时，回归任务被称为*多元*。请注意，*多元*是与前面提到的“多变量”概念分开的。
- en: '![Linear regression](assets/mlin_0301.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![线性回归](assets/mlin_0301.png)'
- en: Figure 3-1\. Data points to be used for linear regression.
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1\. 用于线性回归的数据点。
- en: 'The next step in linear regression is fitting the titular “line” to the data
    points. Behind the scenes, software tools like Python, Stata, IBM SPSS, SAS, MATLAB,
    and the like will calculate a “line of best fit.” According to the definition
    of a *model* given previously in this section, this line is the *model*, which
    is the best *approximation* of the *truth* with the data points that you have.
    Starting with an initial line, the software will calculate the *residual*: the
    y-axis distance between a data point and the line, as illustrated in [Figure 3-2](#fitting_the_line_of_best_fit_in_linear_r).
    Colloquially, the *residual* is also referred to as the *residual error*.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归的下一步是将“线”拟合到数据点。在幕后，像 Python、Stata、IBM SPSS、SAS、MATLAB 等软件工具将计算“最佳拟合线”。根据本节先前给出的*模型*定义，该线是*模型*，它是使用你拥有的数据点最好地*逼近*“真相”的最佳*近似*。从初始线开始，软件将计算*残差*：数据点与线之间的
    y 轴距离，如 [图 3-2](#fitting_the_line_of_best_fit_in_linear_r) 所示。在口语中，*残差*也称为*残差误差*。
- en: '![Fitting the line of best fit in linear regression; the line is iterated on
    until least squares is found](assets/mlin_0302.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![在线性回归中拟合最佳拟合线；直到找到最小二乘法为止迭代线条](assets/mlin_0302.png)'
- en: Figure 3-2\. Fitting the line of best fit in linear regression; the line is
    iterated on until the residuals are as small as possible.
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. 在线性回归中拟合最佳拟合线；直到残差尽可能小为止迭代线条。
- en: 'All the residuals are squared so that predictions above and the line don’t
    cancel each other out due to having opposite signs (positive, negative). The goal
    is that the sum of the residuals is as small as possible since if you have a line
    that is drastically far away from the data points, that means the line isn’t fitting
    well to as many data points as possible and as correctly as possible. Mathematically,
    a common technique to tell how well the line is fitting is the process called
    *least squares*. Achieving least squares means finding the line that results in
    the smallest sum of squared residuals, which in turn means you have the “line
    of best fit”: the line is fitting the data points with least distance from the
    data points overall, as shown in [Figure 3-3](#least_squares_and_terminologysemicolon_y).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 所有残差都是平方的，以便预测值和线不会因为具有相反符号（正、负）而互相抵消。目标是使残差的总和尽可能小，因为如果你有一条明显偏离数据点的线，这意味着该线与尽可能多的数据点的拟合不佳、不准确。从数学上讲，评估线条拟合程度的常见技术是称为*最小二乘法*的过程。实现最小二乘法意味着找到导致平方残差总和最小的线，这反过来意味着你有了“最佳拟合线”：该线以最小距离适合数据点，如
    [图 3-3](#least_squares_and_terminologysemicolon_y) 所示。
- en: '![Least squares and terminology; y represents observed data points, and ŷ (y-hat)
    represents the predicted/estimated values](assets/mlin_0303.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![最小二乘法和术语；y 表示观测数据点，而 ŷ（y-hat）表示预测/估计值](assets/mlin_0303.png)'
- en: Figure 3-3\. Least squares and terminology; y represents observed data points,
    and ŷ (y-hat) represents the predicted/estimated values.
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. 最小二乘法和术语；y 表示观测数据点，ŷ（y-hat）表示预测/估计值。
- en: The end result is a line that has the smallest sum of least squares to the data
    points, as illustrated in [Figure 3-4](#the_resulting_line_of_best_fit_with_leas).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的结果是一条线，它对数据点的最小二乘和最小，如 [图 3-4](#the_resulting_line_of_best_fit_with_leas)
    所示。
- en: '![The resulting line of best fit with least squares from the data in Figure
    3-2](assets/mlin_0304.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![从图 3-2 的数据得出的最小二乘法得到的最佳拟合线](assets/mlin_0304.png)'
- en: Figure 3-4\. The resulting line of best fit with least squares from the data
    in [Figure 3-1](#linear_regression).
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. 从 [图 3-1](#linear_regression) 的数据得到的最小二乘法得到的最佳拟合线。
- en: Going forward, you can use this “line of best fit” as a model to predict new
    apple prices! You can plug the apple weight into the line (in equation form) to
    get a numerical value for the predicted price. This is one of the most basic ways
    of calculating a model from data points, but it has the same pattern as more in-depth
    ML models and algorithms that are covered in the next chapter. Namely, you’ll
    initialize a line (you don’t know if this is the best model yet) and calculate
    the residuals, or how well it fits. Next, you’ll change the line by tilting it
    a little—mathematically, this is called *updating coefficients* or *weights—*and
    calculate the residuals again, as illustrated in [Figure 3-2](#fitting_the_line_of_best_fit_in_linear_r).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，您可以使用这个“最佳拟合线”作为预测新苹果价格的模型！您可以将苹果重量插入该线条（以方程形式），以获得预测价格的数值。这是从数据点计算模型的最基本方式之一，但与下一章涵盖的更深入的ML模型和算法具有相同的模式。换句话说，您将初始化一条线（您不知道这是否是最佳模型），并计算残差或其拟合程度。接下来，您将通过稍微倾斜线条来更改它—在数学上称为*更新系数*或*权重*—并再次计算残差，如[图3-2](#fitting_the_line_of_best_fit_in_linear_r)所示。
- en: This updating process is called *training*, which is where the commonly used
    phrase “training/to train an ML model” comes from. If the sum of the squared residuals
    is getting smaller, then you are on the right track. When you can’t make the squared
    residuals any smaller, you’ve achieved least squares, and that’s how you can say
    the line is your best approximation with this dataset (as illustrated in [Figure 3-4](#the_resulting_line_of_best_fit_with_leas)).
    It’s like that game where there’s an item hidden in the room, and as you walk
    around the room trying to find it, your friend says “hot” if you’re getting closer
    and “cold” when you’re walking farther away. You want to walk toward hotter and
    hotter areas in the room, until you reach the final position.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此更新过程称为*训练*，这也是常用短语“训练/训练ML模型”来自的地方。如果平方残差的总和变小，则您正走在正确的道路上。当您无法再缩小平方残差时，您已经达到了最小二乘法，这就是您可以说该线条是您在该数据集上的最佳近似的方式（如[图3-4](#the_resulting_line_of_best_fit_with_leas)所示）。这就像一个游戏，房间里有一个隐藏的物品，当你在房间里走动尝试找到它时，你的朋友会说“热”，如果你越来越接近，而在你走远时则说“冷”。您希望朝着房间里越来越热的地方走，直到达到最终位置。
- en: In [Chapter 4](ch04.html#technical_interviewcolon_model_training), I’ll walk
    through ways to evaluate models via error terms such as mean squared error (MSE),
    root mean square error (RMSE), and more, which are very similar concepts to residuals.
    The main difference here is that residuals are the difference between past observation
    data and model estimations while errors are the difference between model estimations
    and actual data previously unseen by the model. In other words, errors are the
    differences after applying the model to previously unseen data in order to evaluate
    model performance.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第四章](ch04.html#technical_interviewcolon_model_training)中，我将介绍通过诸如均方误差（MSE）、均方根误差（RMSE）等误差项来评估模型的方法，这些概念与残差非常相似。主要区别在于，残差是过去观察数据与模型估计值之间的差异，而误差是模型估计值与模型之前未见的实际数据之间的差异。换句话说，在将模型应用于先前未见数据以评估模型性能后，误差即为这些差异。
- en: Defining Training and Test Set Splits
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义训练集和测试集分割
- en: To sum up, when using supervised^([3](ch03.html#ch03fn3)) machine learning such
    as the simple linear regression example in the previous section, you’ll generally
    start with a dataset and want the ML algorithm to learn a model of how things
    work. You then will use the model to calculate the values of dependent variables,
    such as predicting how much apples will sell for before they are actually sold.
    In other words, you have a dataset of past data points and, of course, no future
    data points. When the ML model is being trained, it’s learning to “fit” the data
    that you currently have. There are some issues that could arise with model training
    when the model is used in the real world. For one, there will always be outliers
    or changing events in the real world.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，在使用监督机器学习^([3](ch03.html#ch03fn3))，例如前一节中简单线性回归示例时，通常会从数据集开始，希望ML算法能学习事物运作的模型。然后，您将使用模型计算因变量的值，例如预测苹果在实际销售前的售价。换句话说，您有过去数据点的数据集，当然没有未来数据点。在ML模型训练时，它正在学习“拟合”您当前拥有的数据。当模型在真实世界中使用时，可能会出现一些问题。首先，真实世界中总会有离群值或变化事件。
- en: 'One example is in financial predictions with ML: the market could swing suddenly
    to a bear (downturn) market, and the model we’ve trained with financial data in
    a bull (upswing) market will produce horrible and wildly inaccurate predictions.
    Another example is that the dataset you have isn’t representative enough of the
    behaviors of the real world. In the apples example from the previous section,
    you assume that with the weight and height data of the apples, you can predict
    the sell price of new apples. But what if the data you have on hand isn’t enough,
    and apple variants like Fuji or Honeycrisp (one of my favorites) sell for more?
    You didn’t have each apple’s variant name tracked in your dataset, so then your
    model may be incorrect once you put it to the test.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如在使用机器学习进行金融预测时：市场可能突然转向熊市（下跌市场），而我们在牛市（上涨市场）中用金融数据训练的模型会产生可怕且极不准确的预测。另一个例子是，你手上的数据集可能不足以代表现实世界的行为。在前一节中关于苹果的例子中，你假设凭借苹果的重量和高度数据可以预测新苹果的销售价格。但如果你手上的数据不够，像富士或者蜜脆（我最喜欢的之一）这样的苹果品种售价更高怎么办？你的数据集中并没有追踪每个苹果的品种名称，所以一旦投入使用，你的模型可能是错误的。
- en: 'But for now, you have only the current dataset. To make the most of it, you
    need to keep some of the data you have for testing purposes. What this means is
    that you can break out 80% of the apple data points to use for model training
    and then save 20% of the apple data points to run the trained model predictions
    on. The 80% the model is trained on is called the *training set* (sometimes referred
    to as the *train set*), and the 20% of data that is unseen by the model during
    the training phase is called the *test set*. This mimics the real-world scenario
    of running the model to predict new data points; the test set serves that purpose.
    In many cases, you might even split the data into three chunks: 80% as the training
    dataset, 10% as the validation (holdout) dataset, and another 10% as the test
    dataset ([Figure 3-5](#trainingcomma_validationcomma_and_test_s)).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 但目前，你只有当前的数据集。为了充分利用它，你需要保留一些数据用于测试目的。这意味着你可以拿出80%的苹果数据点用于模型训练，然后保留20%的苹果数据点用于运行训练后模型的预测。模型训练的80%数据称为*训练集*（有时称为*训练数据集*），在训练阶段模型未见过的20%数据称为*测试集*。这模拟了在真实世界中运行模型以预测新数据点的情景；测试集就是为此目的而存在的。在许多情况下，你甚至可能将数据分成三个部分：80%作为训练数据集，10%作为验证（保留）数据集，另外10%作为测试数据集（[图 3-5](#trainingcomma_validationcomma_and_test_s)）。
- en: The validation set allows you to monitor the model’s performance during the
    training process without “formally” evaluating it, and it enables you to diagnose
    weak spots of the model and tune its parameters. The test set, as previously mentioned,
    was unseen by the model during the training process and thus is used to formally
    evaluate the model performance, mimicking a real-world environment as much as
    possible. Of course, having a test and validation set isn’t infallible, which
    brings us to more robust techniques and the concepts of model overfitting and
    underfitting.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 验证集允许你在训练过程中监控模型的性能，而不是“正式”评估它，并且它能帮助你诊断模型的弱点并调整其参数。如前所述，测试集在训练过程中模型未见过，因此用于正式评估模型性能，尽可能模拟真实世界环境。当然，拥有测试集和验证集并非绝对可靠，这引出了更强大的技术以及模型过拟合和欠拟合的概念。
- en: '![Training, validation, and test set splits](assets/mlin_0305.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![训练、验证和测试集的划分](assets/mlin_0305.png)'
- en: Figure 3-5\. Training, validation, and test set splits.
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5\. 训练、验证和测试集的划分。
- en: Tip
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: For interview questions on training and test sets, make sure you can name common
    ways to augment the simpler splits, such as using [cross-validation](https://oreil.ly/miQ1N):^([4](ch03.html#ch03fn4))
    splitting up data into smaller chunks and rotating through them as training sets.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于关于训练和测试集的面试问题，请确保你能够命名简单分割的常见方式，例如使用[交叉验证](https://oreil.ly/miQ1N)：^([4](ch03.html#ch03fn4))将数据分成较小的块并依次作为训练集。
- en: Defining Model Underfitting and Overfitting
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义模型欠拟合和过拟合
- en: There are many reasons a model may not perform well on real-world data (or even
    the validation or test set). A common starting point is addressing overfitting
    or underfitting. *Underfitting* is when the model isn’t fitting well. This might
    mean that the model isn’t able to capture the relationship between the dataset’s
    independent variables (e.g., weight, height, etc.) and the dependent variables
    (e.g., price). Consequently, some ways to reduce underfitting are related to helping
    the model learn more nuances or patterns during the training process.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在真实数据（甚至验证或测试集）上表现不佳的原因有很多。解决过拟合或欠拟合是一个常见的起点。*欠拟合* 是指模型拟合得不好。这可能意味着模型无法捕捉数据集的自变量（例如重量、高度等）与因变量（例如价格）之间的关系。因此，减少欠拟合的一些方法与帮助模型在训练过程中学习更多微妙或模式有关。
- en: For example, adding more variables, or model features, such as apple variant
    or age of the apple, could help the model learn more patterns from the training
    data and potentially reduce underfitting. A second way to reduce underfitting
    is to increase the number of iterations the model trains for [before training
    is stopped](https://oreil.ly/ZFqyo).^([5](ch03.html#ch03fn5))
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，添加更多变量或模型特征，例如苹果变种或苹果的年龄，可能有助于模型从训练数据中学习更多模式，并潜在地减少欠拟合。减少欠拟合的第二种方法是增加模型训练的迭代次数[在停止训练之前](https://oreil.ly/ZFqyo)^([5](ch03.html#ch03fn5))。
- en: '*Overfitting* is when a model fits the training data too closely and very specifically,
    perhaps finding patterns that happen to be in the training set but not elsewhere.
    A simplified example is that the training data just so happens to have a lot of
    apples that are disproportionately expensive despite their weight (e.g., Sekai
    Ichi apples^([6](ch03.html#ch03fn6))). The model learned from that data and overfit
    to it, therefore making incorrect predictions that are overpriced for cheaper
    apple variants. Simply put, the model is overmemorizing the training data and
    unable to generalize to new data points. There are many techniques to make the
    model generalize better, such as adding more training data, data augmentation,
    or regularization.^([7](ch03.html#ch03fn7)) I’ll cover the details of regularization
    next.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*过拟合* 是指模型过于密切地适应训练数据，可能找到只存在于训练集中而不在其他地方的模式。一个简化的例子是，训练数据恰好包含许多尽管重量不同但价格昂贵的苹果（例如，Sekai
    Ichi苹果^([6](ch03.html#ch03fn6))）。模型从这些数据中学习并过拟合于此，因此导致不正确的预测，对便宜的苹果变体定价过高。简而言之，模型过于记忆训练数据，无法推广到新的数据点。有许多技术可以使模型更好地推广，例如添加更多训练数据，数据增强或正则化^([7](ch03.html#ch03fn7))。接下来我将详细介绍正则化。'
- en: Summarizing Regularization
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则化总结
- en: '*Regularization* is a technique used to reduce overfitting of ML models. Generally,
    regularization will create a damper on model weights/coefficient. By this point,
    you likely know what I’m going to do—which is to bring up the apples again! Apples
    are my favorite fruit, which is probably why I use the example so often. So let’s
    say the model has learned to weigh “weight of apple” more heavily (accidental
    pun, but model “weights” is legitimate terminology); then the weight of the apple
    is mathematically increasing the results of the ML model’s prediction of the price
    by a relatively high positive value. If you can dampen the amount by which the
    weight of the apple increases the model’s predictions of the price, via regularization,
    that can make the model generalize more and take other variables into account
    more evenly.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*正则化* 是减少机器学习模型过拟合的一种技术。一般来说，正则化会对模型的权重/系数施加一个阻尼作用。到这里，你可能已经知道我接下来要做什么了——那就是再次提到苹果！苹果是我最喜欢的水果，这可能是为什么我经常使用这个例子的原因。所以让我们假设模型已经学会更重视“苹果的重量”（不经意的双关语，但模型的“权重”是合法的术语）；然后苹果的重量在数学上会显著增加机器学习模型对价格的预测结果。如果通过正则化减少苹果重量增加模型对价格预测的影响量，那么可以使模型更具普遍性，并更均衡地考虑其他变量。'
- en: Sample Interview Questions on Foundational Techniques
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础技术的样本面试问题
- en: Now that I’ve covered various statistical and ML techniques at a higher level,
    let’s look at some sample questions. Here, I will dive into the details of common
    interview questions that stem from the concepts covered in this section. These
    details may not have been previously addressed, so my hope is that these sample
    questions also serve to explain the new concepts.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经在更高层次上涵盖了各种统计和机器学习技术，让我们来看一些样例问题。在这里，我将深入探讨由本节涵盖的概念引发的常见面试问题的细节。这些细节可能之前没有提到过，所以我希望这些样例问题也能帮助解释这些新概念。
- en: 'Interview question 3-1: What is L1 versus L2 regularization?'
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题3-1：L1正则化与L2正则化有何区别？
- en: Example answer
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: '*L1 regularization*, also known as [*lasso regularization*](https://oreil.ly/hoPuG),^([8](ch03.html#ch03fn8))
    is a type of regularization that shrinks model parameters toward zero. *L2 regularization*
    (also known as *ridge regularization*) adds a penalty term to the objective function
    that is proportional to the square of the coefficients of the model. This penalty
    term shrinks the coefficients toward zero, but unlike L1 (lasso) regularization,
    it does not make any of the coefficients exactly equal to zero.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*L1正则化*，也称为[*套索正则化*](https://oreil.ly/hoPuG)，是一种将模型参数收缩至零的正则化类型。*L2正则化*（也称为*岭正则化*）向目标函数添加一个与模型系数平方成比例的惩罚项。这个惩罚项将模型系数收缩至零，但与L1（套索）正则化不同，它不会使任何系数完全等于零。'
- en: L2 regularization can help reduce overfitting and improve the stability of the
    model by keeping coefficients from becoming too large. Both L1 and L2 regularization
    are commonly used to prevent overfitting and improve the generalization of ML
    models.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: L2正则化有助于减少过拟合并通过保持系数不会变得过大来改善模型的稳定性。L1和L2正则化都常用于防止过拟合并提高机器学习模型的泛化能力。
- en: Tip
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'Interview questions on model overfitting and underfitting may lead to follow-up
    questions. For example, if you bring up L1 and L2 regularization, the interviewer
    might ask, “What other types of regularization could work?” In that case, you
    could bring up *elastic net*, which is a combination of L1 and L2 techniques.
    Or for the overfitting case, ensemble techniques can also help (refer to [“Interview
    question 3-3: Explain boosting and bagging and what they can help with.”](#interview_question_threehyphenthreecolon)).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模型过拟合和欠拟合的面试问题可能会引发跟进问题。例如，如果你提到了L1和L2正则化，面试官可能会问：“还有哪些类型的正则化可以起作用？”在这种情况下，你可以提到*弹性网*，它是L1和L2技术的结合体。或者对于过拟合的情况，集成技术也可以帮助（参考[“面试问题3-3：解释提升和装袋以及它们可以帮助解决什么问题。”](#interview_question_threehyphenthreecolon)）。
- en: 'Interview question 3-2: How do you deal with the challenges that come with
    an imbalanced dataset?'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题3-2：如何处理不平衡数据集带来的挑战？
- en: Example answer
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: 'Imbalanced datasets in ML refer to datasets in which some classes or categories
    outweigh others.^([9](ch03.html#ch03fn9)) Techniques to deal with imbalanced datasets
    include data augmentation, oversampling, undersampling, ensemble methods, and
    so on:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，不平衡数据集指的是某些类别或类别比其他类别多。处理不平衡数据集的技术包括数据增强、过采样、欠采样、集成方法等：
- en: Data augmentation
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强
- en: Data augmentation involves generating more examples for the ML model to train
    on, such as rotating images so that the dataset includes images of humans turned
    upside down as well as the normal upright image orientation. Without data augmentation,
    the model might not be able to correctly recognize images of humans who are laying
    sideways or doing headstands since the data is imbalanced toward humans in an
    upright pose.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强涉及生成更多示例以供机器学习模型训练，例如旋转图像，使数据集包括正常直立的人类图像以及倒立的图像。没有数据增强，模型可能无法正确识别侧卧或做倒立头站的人类图像，因为数据向正常直立的人类倾斜。
- en: Oversampling
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 过采样
- en: Oversampling is a technique to increase the number of data points of a minority
    class via synthetic generation. As an example, SMOTE (synthetic minority oversampling
    technique)^([10](ch03.html#ch03fn10)) uses the feature vectors of the minority
    classes to generate synthetic data points that are located between real data points
    and their k-nearest neighbors. This could synthetically increase the size of the
    minority class(es) and improve the performance of the ML model trained on a dataset
    with oversampling treatment.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 过采样是通过合成生成技术增加少数类数据点数量的一种技术。例如，SMOTE（合成少数过采样技术）^([10](ch03.html#ch03fn10)) 使用少数类的特征向量生成位于真实数据点及其
    k 近邻之间的合成数据点。这可以通过合成增加少数类的大小，并提升在过采样处理后训练的机器学习模型的性能。
- en: Undersampling
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 下采样
- en: 'Undersampling does the opposite: it reduces examples from the majority class
    to balance the number of data points of the majority class and minority class(es).
    Oversampling is generally preferred in practice since undersampling may cause
    useful data to be discarded, which is exacerbated when the dataset is already
    small.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 下采样则相反：它减少了多数类的示例数量，以平衡多数类和少数类的数据点数量。在实践中通常更喜欢过采样，因为下采样可能导致有用的数据被丢弃，特别是当数据集已经很小时，这种情况会更加严重。
- en: Ensemble methods
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 集成方法
- en: Ensemble methods can also be used to increase model performance when dealing
    with an imbalanced dataset.^([11](ch03.html#ch03fn11)) Each model in the ensemble
    can be trained on a different subset of the data and can help learn the nuances
    of each class better.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 集成方法还可以在处理不平衡数据集时提升模型性能。^([11](ch03.html#ch03fn11)) 集成中的每个模型可以在数据的不同子集上训练，并有助于更好地学习每个类别的细微差别。
- en: 'Interview question 3-3: Explain boosting and bagging and what they can help
    with.'
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题3-3：解释 boosting 和 bagging，以及它们可以帮助解决的问题。
- en: Example answer
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 示例答案
- en: 'Bagging and boosting are ensemble techniques used to improve the performance
    of ML models:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging 和 boosting 是用于提升机器学习模型性能的集成技术：
- en: Bagging
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging
- en: Bagging trains multiple models on different subsets of the training data and
    combines their predictions to make a final prediction.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging 训练多个模型在训练数据的不同子集上，并组合它们的预测以进行最终预测。
- en: Boosting
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Boosting
- en: Boosting trains a series of models where each model tries to correct the mistakes
    made by the previous model. The final prediction is made by all the models. Ensemble
    techniques can help with a variety of issues encountered during ML training. For
    example, they can help with imbalanced data^([12](ch03.html#ch03fn12)) and reduce
    overfitting.^([13](ch03.html#ch03fn13))
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Boosting 训练一系列模型，其中每个模型试图纠正前一个模型的错误。最终的预测由所有模型共同完成。集成技术可以帮助解决机器学习训练过程中遇到的各种问题。例如，它们可以帮助处理不平衡数据^([12](ch03.html#ch03fn12))
    和减少过拟合^([13](ch03.html#ch03fn13))。
- en: Note
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: See [Chapter 4](ch04.html#technical_interviewcolon_model_training) for more
    in-depth questions concerning model evaluation.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于模型评估的深入问题，请参阅[第四章](ch04.html#technical_interviewcolon_model_training)。
- en: Supervised, Unsupervised, and Reinforcement Learning
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习、无监督学习和强化学习
- en: In ML roles, knowing when and what to pick from each family of techniques—including
    supervised, unsupervised, or reinforcement learning—is an essential skill. In
    my previous jobs, I’ve used supervised learning to prevent fraud and customer
    churn, but at other times, I used unsupervised learning like anomaly detection
    for the same problem, depending on the data and situation. Sometimes (more often,
    as you grow more senior in your ML career), you might even create an ML pipeline
    with both supervised and unsupervised learning. In your reinforcement learning
    pipeline, you might use supervised learning in a previous step to label features.
    Understanding the underlying mechanics can help you adapt to new situations when
    using different techniques might be more effective than sticking to what is convenient.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习角色中，了解何时以及从每个技术家族中选择什么是一项重要技能——包括监督、无监督或强化学习。在我的之前的工作中，我使用监督学习来防止欺诈和客户流失，但在其他时候，我根据数据和情况使用无监督学习如异常检测解决同样的问题。有时候（随着你在机器学习职业中的成长），你甚至可能创建一个包含监督和无监督学习的机器学习管道。在强化学习管道中，你可能会在前一步骤使用监督学习来标记特征。理解底层机制可以帮助你在使用不同技术可能比坚持便捷更有效时，适应新情况。
- en: Therefore, in interviews there are often questions about supervised versus unsupervised
    learning. Reinforcement learning (RL) is considered a somewhat advanced topic
    and may not be touched on in many interviews. However, I’ve been asked about it
    in a nontrivial number of interviews because of the growth of RL use for industry
    applications such as in conjunction with recommender systems—although my past
    work experience in RL may have prompted the interviewers to ask me about it. As
    I mentioned in [Chapter 2](ch02.html#machine_learning_job_application_and_res),
    if something’s on your resume, it’s fair game to discuss in the interview! For
    a more comprehensive overview of RL, see [“Reinforcement Learning Algorithms”](#reinforcement_learning_algorithms).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在面试中经常会有关于监督学习和非监督学习的问题。增强学习（RL）被认为是一个稍微高级的主题，在许多面试中可能不会被触及。然而，由于RL在行业应用中的增长，如与推荐系统结合使用，我曾在相当多的面试中被问及此问题。正如我在[第2章](ch02.html#machine_learning_job_application_and_res)中提到的，如果某事出现在您的简历中，那么在面试中讨论它是公平的！有关RL的更全面的概述，请参见[“增强学习算法”](#reinforcement_learning_algorithms)。
- en: Tip
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Regardless of what types of ML roles you’re interviewing for, knowledge about
    supervised and unsupervised learning is a must. Brush up on reinforcement learning
    concepts afterward, in terms of priority.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您面试的是哪种类型的机器学习职位，了解监督学习和非监督学习都是必备的知识。优先了解增强学习概念。
- en: This section covers the basics of labeled data, supervised learning, unsupervised
    learning, semi- and self-supervised learning, and reinforcement learning, those
    who are unsure whether they have the background knowledge in this area. Feel free
    to skip the subsections if you already have expertise in any of these areas. Regardless
    of your expertise, I’ve highlighted specific advice for ML interviews in the tip
    boxes to help you apply your knowledge of each ML area and excel in your interviews.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了标记数据、监督学习、非监督学习、半监督学习、自监督学习和增强学习的基础知识，对于那些不确定是否具有这一领域背景知识的人来说。如果您已经在任何这些领域具有专业知识，则可以跳过这些子部分。无论您的专业知识如何，我都在提示框中强调了ML面试的具体建议，帮助您应用每个ML领域的知识并在面试中表现出色。
- en: Defining Labeled Data
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义标记数据
- en: Returning to our apple dataset from “Summarizing Independent and Dependent Variables,”
    you have the data points for how much apples sold for in the past. The price is
    also the dependent variable in “Summarizing Linear Regression.” The fact that
    you do have labels for the dataset^([14](ch03.html#ch03fn14)) means that the ML
    tasks you were doing previously were with *labeled* data. An example of *unlabeled*
    data is when you have the prices and weights of the apples but not the apple variants,
    yet you try to deduce commonalities within different variants of apples. Because
    you don’t initially have the correct or expected “label”—in this case, the apple
    variant—you would be using unlabeled data and conducting unsupervised learning.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到我们的苹果数据集，从“总结独立和因变量”，您拥有过去苹果销售的数据点。在“总结线性回归”中，价格也是依赖变量。您确实拥有数据集的标签^[14](ch03.html#ch03fn14)，这意味着您之前进行的ML任务是使用*标记*数据。*非标记*数据的一个例子是当您有苹果的价格和重量但没有苹果品种时，您尝试推断不同苹果品种之间的共同点。因为您最初没有正确或预期的“标签”——在这种情况下是苹果品种——所以您将使用非标记数据进行无监督学习。
- en: Summarizing Supervised Learning
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习总结
- en: 'Building on the concept of labeled and unlabeled data, let’s move on to supervised
    learning. *Supervised learning* is the first type of machine learning as defined
    by its use of labeled data, illustrated in [Figure 3-6](#overview_of_machine_learning_families).
    Supervised learning uses correct or expected outcomes of the past to predict the
    dependent variables for new or future data points. The example of using apple
    weight, variant, and so on to predict sales prices for new apples is supervised
    learning. Supervised learning can be broken down into two main categories: regression
    and classification.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在标记和非标记数据的概念基础上，让我们进入监督学习。*监督学习*是机器学习的第一种类型，其定义是利用标记数据，如[图 3-6](#overview_of_machine_learning_families)所示。监督学习利用过去的正确或预期结果来预测新数据点的因变量。例如，利用苹果的重量、品种等来预测新苹果的销售价格就属于监督学习。监督学习可以分为两大类：回归和分类。
- en: '![Overview of machine learning families](assets/mlin_0306.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习家族概述](assets/mlin_0306.png)'
- en: Figure 3-6\. Overview of machine learning families (simplified for understanding).
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-6\. 机器学习家族概述（简化理解）。
- en: In *regression* tasks, the dependent/output variable is a continuous value.
    For example, predicting stock prices, housing prices, or weather (temperature)
    produces continuous values. *Classification* is a type of supervised learning
    in which the dependent/output variable is categorical—that is, it is put into
    a category, such as “it’s a dog” or “it’s a cat.” Classification examples include
    detecting whether something is or isn’t spam, using image recognition such as
    tagging animal types in a picture, and so on.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在*回归*任务中，依赖/输出变量是连续值。例如，预测股票价格、房价或天气（温度）都产生连续值。*分类*是一种监督学习类型，其中依赖/输出变量是分类的，即它被放入一个类别，比如“这是狗”或“这是猫”。分类的例子包括检测某物是否是垃圾邮件，使用图像识别如在图片中标记动物类型等。
- en: It is possible to mix categorical data with continuous data via techniques such
    as *one-hot encoding*. For example, if we’re trying to classify if there is a
    dog or a cat in an image, an image that has a dog will be encoded with 1 for the
    “dog” category and 0 for the “cat” category. Think of it like a Boolean (True/False)
    representation of the data for each category. Then you can mix these numerical
    encodings (0 or 1) with datasets with continuous values.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过诸如*独热编码*之类的技术混合分类数据和连续数据。例如，如果我们尝试分类图像中是否有狗或猫，有狗的图像将使用“狗”类别的1编码，以及“猫”类别的0编码。可以将这些数字编码（0或1）与具有连续值的数据集混合。这样您可以混合这些分类数据（0或1）与具有连续值的数据集。
- en: Defining Unsupervised Learning
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义无监督学习
- en: '*Unsupervised learning* is training a model with unlabeled data: when you do
    not have the “labels” available (the labels being the correct or expected values
    that you are looking for). You’d likely use unsupervised learning to find patterns,
    commonalities, or anomalies in the dataset without prior knowledge in the ML model
    of correct or expected result labels.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*无监督学习*是使用未标记数据来训练模型：当您没有“标签”可用时（标签是您正在寻找的正确或预期值）。您可能会使用无监督学习来查找数据集中的模式、共同点或异常，而无需先前知识的ML模型的正确或预期结果标签。'
- en: Common usage of unsupervised learning includes clustering and dimensionality
    reduction (see [Figure 3-6](#overview_of_machine_learning_families)). Many generative
    models are unsupervised, such as variational autoencoder (VAE), which is used
    with applications like Stable Diffusion for image generation.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习的常见用途包括聚类和降维（见[图3-6](#overview_of_machine_learning_families)）。许多生成模型是无监督的，例如用于图像生成的变分自编码器（VAE），例如与应用程序如稳定扩散。
- en: '*Clustering* is an ML task that groups similar data points together into clusters,
    as illustrated in [Figure 3-7](#example_of_unsupervised_learningcolon_cl), which
    allows you to see any emerging patterns. While you won’t be able to deduce any
    labels that you don’t have, you can still find outliers or clusters of interest
    to further investigate. Unsupervised learning can be used for customer segmentation
    because you can hypothesize that customers in the same clusters might have similar
    preferences or behaviors. You can use unsupervised learning for anomaly and outlier
    detection since you can find abnormal patterns in the data without prior knowledge
    of what an “anomaly” looks like.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*聚类*是一种将相似数据点组合到一起形成聚类的ML任务，如[图3-7](#example_of_unsupervised_learningcolon_cl)所示，这允许您看到任何新出现的模式。虽然您无法推断出您没有的任何标签，但仍然可以找到异常或感兴趣的聚类以进一步调查。无监督学习可用于客户细分，因为您可以假设同一聚类中的客户可能具有类似的偏好或行为。您可以使用无监督学习进行异常和异常检测，因为您可以在不了解“异常”外观的情况下发现数据中的异常模式。'
- en: '![Example of unsupervised learning: clustering](assets/mlin_0307.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![无监督学习示例：聚类](assets/mlin_0307.png)'
- en: 'Figure 3-7\. Example of unsupervised learning: clustering.'
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-7\. 无监督学习示例：聚类。
- en: '*Dimensionality reduction* is a common technique used to reduce the number
    of redundant input variables in training data. Reducing the number of features/input
    variables can help to reduce overfitting since models that learn from too many
    variables might also learn from the “noise” from those variables.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '*降维*是一种常见的技术，用于减少训练数据中冗余输入变量的数量。减少特征/输入变量的数量有助于减少过拟合，因为学习过多变量的模型可能还会从这些变量的“噪音”中学习。'
- en: Summarizing Semisupervised and Self-Supervised Learning
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结半监督和自监督学习
- en: Additional variations as extensions of supervised and unsupervised learning
    have become more popular in the industry, especially because of limitations on
    fully labeling large amounts of data. You might not encounter these concepts much
    during interviews, but you should be aware of them. If the team you’re interviewing
    with uses these techniques, it will be good to be prepared to discuss them.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 随着行业对完全标记大量数据的限制，监督学习和无监督学习的扩展变体变得越来越受欢迎。在面试中，你可能不经常遇到这些概念，但你应该意识到它们的存在。如果你正在面试的团队使用这些技术，最好准备好讨论它们。
- en: '*Semisupervised learning* uses a small amount of labeled data (usually manually
    labeled) to train a separate ML model specifically meant to help with machine
    labeling previously unlabeled data. The initial labeled dataset is then combined
    with the machine-generated labels with highest confidence to create a larger labeled
    dataset, as illustrated in [Figure 3-8](#semisupervised_learning_overview).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*半监督学习*使用少量标记数据（通常是手动标记的）来训练一个专门用于帮助机器标记先前未标记数据的ML模型。然后，初始标记数据集与具有最高置信度的机器生成标签结合，创建一个更大的标记数据集，如[图
    3-8](#semisupervised_learning_overview)所示。'
- en: '![Semisupervised learning overview](assets/mlin_0308.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![半监督学习概述](assets/mlin_0308.png)'
- en: Figure 3-8\. Semisupervised learning overview.
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-8\. 半监督学习概述。
- en: '*Self-supervised learning*^([15](ch03.html#ch03fn15)) relies on the dataset
    itself to learn latent representations, without labels. For example, in an image,
    if certain parts are removed, can we predict or generate those missing parts?
    Common usage of self-supervised learning includes filling in missing parts of
    images, audio, video,^([16](ch03.html#ch03fn16)) text, and so on.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*自监督学习*^([15](ch03.html#ch03fn15))依赖于数据集本身来学习潜在的表示，而不需要标签。例如，在图像中，如果删除了某些部分，我们能否预测或生成这些缺失的部分？自监督学习的常见用途包括填补图像、音频、视频^([16](ch03.html#ch03fn16))、文本等的缺失部分。'
- en: Tip
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Semisupervised and self-supervised learning can be brought up in interview answers
    to help with a lack of labeled data or cases where it’s not necessary to label
    all the data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 面试中可以提到半监督学习和自监督学习，以帮助解决标记数据不足或不必要为所有数据进行标记的情况。
- en: Summarizing Reinforcement Learning
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化学习总结
- en: The third major type of machine learning based on the dataset or the usage of
    labels is *reinforcement learning* (RL). In it’s simplest form, RL doesn’t necessarily
    require a prior dataset, although generally in industry, I’d still prefer to have
    some existing dataset or existing model so I can test the RL algorithms offline
    (not live) before deploying the RL agent into the real world or into the hands
    of customers.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 基于数据集或标签使用的第三种主要机器学习类型是*强化学习*（RL）。在其最简单的形式中，RL并不一定需要先前的数据集，尽管通常在行业中，我仍然更喜欢有一些现有的数据集或现有的模型，这样我可以在部署RL代理到真实世界或客户手中之前脱机测试RL算法。
- en: RL relies on an “agent,” which is not the same as the concept of an ML “model”
    that I introduced earlier, although they do have similarities in that they both
    improve and learn through iterations. RL learns through trial and error. The agent
    only needs to react to each new data point as it comes in, and the agent eventually
    learns enough from experience to figure out an optimal way of predicting the best
    action to carry out next.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习依赖于“代理”，这与我之前介绍的机器学习“模型”概念并不相同，尽管它们在改进和学习的迭代过程中有相似之处。强化学习通过试错学习。代理只需在每个新数据点到来时做出反应，通过经验最终学会预测执行下一步最佳动作的最优方式。
- en: A common RL example is a robot learning to navigate a maze that has rewards,
    traps, and an exit (for an example, see [Figure 3-14](#illustration_of_reinforcement_learningco)
    later in this chapter). The first time the robot moves through the maze, it has
    no knowledge of where the gold, traps, and exit are. But as it encounters those
    things in the environment, it also acquires knowledge, or data points, about the
    past, similar to constructing its own dataset via trial and error. After the robot
    has navigated the maze enough times, it learns the fastest and safest path to
    the exit. But based on how you design the RL agent, it can also optimize for various
    goals, such as collecting the most gold instead of reaching the exit as fast as
    possible.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的强化学习示例是机器人学习导航迷宫，迷宫中有奖励、陷阱和出口（例如，参见本章后面的[图 3-14](#illustration_of_reinforcement_learningco)）。机器人第一次穿越迷宫时，不知道金子、陷阱和出口的位置。但是随着它在环境中遇到这些事物，它也会获得知识或数据点，类似于通过试错构建自己的数据集。在机器人多次导航迷宫之后，它学会了最快和最安全的路径到达出口。但根据您设计的强化学习代理的方式，它还可以优化各种目标，例如收集最多的金子而不是尽快到达出口。
- en: There are various types of RL, some of which resemble supervised learning, but
    I will leave the in-depth discussion of those for the section [“Reinforcement
    Learning Algorithms”](#reinforcement_learning_algorithms). RL is commonly used
    in gaming, robotics, and self-driving cars, but RL can also be used for a growing
    number of applications that previously used supervised learning, such as a system
    that recommends videos on YouTube.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种类型的强化学习，其中一些类似于监督学习，但我将把这些深入讨论留在[“强化学习算法”](#reinforcement_learning_algorithms)部分。强化学习通常用于游戏、机器人和自动驾驶汽车，但强化学习也可以用于越来越多之前使用监督学习的应用，比如YouTube上推荐视频的系统。
- en: Sample Interview Questions on Supervised and Unsupervised Learning
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习和无监督学习的样例面试问题
- en: Now that I’ve covered supervised, unsupervised, and reinforcement learning at
    a higher level, let’s look at some common interview questions that stem from these
    concepts.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经在更高层次上覆盖了监督学习、无监督学习和强化学习，让我们看看一些与这些概念相关的常见面试问题。
- en: Note
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This section specifically covers interview questions on supervised and unsupervised
    learning; since RL has its own section, [“Reinforcement Learning Algorithms”](#reinforcement_learning_algorithms),
    the questions on RL can be found there.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 本节专门涵盖了监督学习和无监督学习的面试问题；由于强化学习有自己的部分，可以在[“强化学习算法”](#reinforcement_learning_algorithms)中找到关于强化学习的问题。
- en: 'Interview question 3-4: What are common algorithms in supervised learning?'
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-4：监督学习中常见的算法有哪些？
- en: Example answer
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 示例答案
- en: The *regression* family of algorithms includes linear regression and logistic
    regression, among other algorithms such as generalized linear models (GLMs) and
    various time-series regression models such as autoregressive integrated moving
    average (ARIMA).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '*回归*算法族包括线性回归和逻辑回归，以及其他算法如广义线性模型（GLMs）和各种时间序列回归模型如自回归移动平均（ARIMA）。'
- en: The *decision tree* family of algorithms can be used for both classification
    and regression tasks within supervised learning; these include XGBoost, LightGBM,
    CatBoost, and so on. Decision trees can be combined in random forest algorithms,
    which ensemble (combine) a multitude of decision trees. Like decision trees, random
    forests can be used for both classification and regression tasks under supervised
    learning.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*决策树*算法族可以在监督学习中用于分类和回归任务；这些包括XGBoost、LightGBM、CatBoost等。决策树可以在随机森林算法中组合（集成）多个决策树。像决策树一样，随机森林可以用于监督学习中的分类和回归任务。'
- en: '*Neural networks* can be used for supervised learning tasks as well as unsupervised
    learning. In terms of supervised learning, these include many tasks in this section,
    such as image classification, object detection, speech recognition, and natural
    language processing (NLP).'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*神经网络*不仅可以用于监督学习任务，还可以用于无监督学习。在监督学习方面，这些任务包括本节中的许多任务，如图像分类、目标检测、语音识别和自然语言处理（NLP）。'
- en: Other algorithms include naive Bayes,^([17](ch03.html#ch03fn17)) which is a
    supervised classification algorithm that uses [Bayes’ theorem](https://oreil.ly/OJqAX).^([18](ch03.html#ch03fn18))
    Applications of Bayes’ theorem in ML include Bayesian neural networks,^([19](ch03.html#ch03fn19))
    which predict a distribution of results (for example, a normal model might predict
    the price is $100, but the Bayesian model will predict the price is $100 with
    a standard deviation of 5).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 其他算法包括朴素贝叶斯，^([17](ch03.html#ch03fn17)) 这是一种使用[贝叶斯定理](https://oreil.ly/OJqAX)的监督分类算法。^([18](ch03.html#ch03fn18))
    贝叶斯定理在机器学习中的应用包括贝叶斯神经网络，^([19](ch03.html#ch03fn19)) 这些网络预测结果的分布（例如，标准模型可能预测价格为$100，但贝叶斯模型将预测价格为$100，标准差为5）。
- en: 'Interview question 3-5: What are some common algorithms used in unsupervised
    learning? How do they work?'
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '面试问题 3-5: 无监督学习中常用的一些算法是什么？它们是如何工作的？'
- en: Example answer
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 例子答案
- en: Unsupervised learning is commonly used for clustering, anomaly detection, and
    dimensionality reduction. I’ll group the algorithms by those categories. *Clustering*
    is often done with algorithms such as k-means clustering and density-based clustering
    (DBSCAN algorithm). *K-means clustering* groups the data into *k* clusters, and
    the algorithm iteratively labels each data point with the cluster’s centroid.
    The cluster centroid is then updated, and the algorithm continues until the cluster
    assignments have reached a stable state and no longer shift or change. *DBSCAN*
    is a popular algorithm that groups together data points that are close to one
    another (high density) and also separates those clusters from one another depending
    on their distance. Because unsupervised learning algorithms can handle large class
    imbalances, there are common unsupervised learning algorithms that address anomaly
    detections.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习通常用于聚类、异常检测和降维。我将根据这些类别对算法进行分组。*聚类* 通常使用k均值聚类和基于密度的聚类（DBSCAN算法）等算法。*K均值聚类*
    将数据分组到*k*个簇中，并迭代地使用聚类的质心标记每个数据点。然后更新簇的质心，并继续迭代，直到簇分配达到稳定状态，不再移动或改变。*DBSCAN* 是一个流行的算法，它将彼此靠近的数据点（高密度）分组在一起，并根据它们之间的距离将这些簇分离开来。因为无监督学习算法可以处理大的类别不平衡，所以有常见的无监督学习算法可以处理异常检测。
- en: There are many algorithms that can be used for dimensionality reduction. *Principal
    component analysis* (PCA) can “flatten” datasets into a lower-dimensional space.
    This is useful for data preprocessing since it can reduce the number of redundant
    features that are used while keeping the variance in the data so that enough signals
    and patterns are preserved in the data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多算法可以用于降维。*主成分分析*（PCA）可以将数据集“压缩”到一个更低维的空间中。这对于数据预处理非常有用，因为它可以减少使用的冗余特征数，同时保持数据中的方差，以便在数据中保留足够的信号和模式。
- en: '*Autoencoders* are a type of unsupervised learning with a broad range of applications,
    notably in NLP—but not limited to NLP. They can be used to encode a compressed
    representation of input text, which is also a form of dimensionality reduction,
    and then decode the compressed representation for the generation of the next chunk
    of text data. This is useful for text completion and text summarization tasks.
    As a subset of unsupervised learning, self-supervised learning is also a case
    where autoencoders can be used. Examples include self-supervised learning to fill
    in missing parts of images or [fix audio and video](https://oreil.ly/pn61B).^([20](ch03.html#ch03fn20))'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '*自编码器* 是一种无监督学习的类型，具有广泛的应用，特别是在自然语言处理领域，但不限于此。它们可以用于对输入文本进行压缩表示，这也是一种降维的形式，然后解码压缩表示以生成下一块文本数据。这对于文本完成和文本摘要任务非常有用。作为无监督学习的一个子集，自监督学习也是自编码器可以使用的情况之一。例如，自监督学习用于填补图像中缺失的部分或[修复音频和视频](https://oreil.ly/pn61B)。^([20](ch03.html#ch03fn20))'
- en: 'Interview question 3-6: What are the differences between supervised and unsupervised
    learning?'
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '面试问题 3-6: 监督学习和无监督学习之间有什么区别？'
- en: Example answer
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 例子答案
- en: The major difference between the two types of machine learning is related to
    the training data that is used. Supervised learning uses labeled data while unsupervised
    learning uses unlabeled data. *Labeled data* refers to the correct output or result
    from the ML model already being inside the training dataset.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种类型的机器学习之间的主要区别与使用的训练数据有关。监督学习使用带标签的数据，而无监督学习使用未标记的数据。*带标签的数据* 指的是训练数据集中已经包含ML模型的正确输出或结果。
- en: Supervised and unsupervised learning also differ in terms of the ML model outputs.
    In supervised learning, the ML model aims to predict what the label would be.
    Unsupervised learning doesn’t predict specific label(s) but rather tries to find
    latent patterns and groupings within the dataset, which can be used to cluster
    new data points.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习和无监督学习在 ML 模型输出方面也有所不同。在监督学习中，ML 模型旨在预测标签将是什么。无监督学习不预测特定的标签，而是试图在数据集中找到潜在的模式和分组，这可以用来聚类新数据点。
- en: In terms of evaluation, the two types of ML are assessed differently. Supervised
    learning is evaluated by comparing its outputs with the correct output (with the
    test/holdout/validation datasets). In unsupervised learning, the model is evaluated
    based on how well it groups or captures patterns within the data, via metrics
    such as the *Jaccard score* or *silhouette index* for clustering and receiver
    operating characteristic curves (ROC)/area under the curve (AUC) metrics for positive
    rate comparisons for anomaly detection.^([21](ch03.html#ch03fn21))
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估方面，这两种 ML 方法有不同的评估方法。监督学习通过将其输出与正确输出（使用测试/保留/验证数据集）进行比较来进行评估。在无监督学习中，模型根据其在数据中聚类或捕捉模式的效果进行评估，通过诸如聚类的
    Jaccard 分数或轮廓指数以及异常检测的 ROC 曲线/曲线下面积（AUC）等指标来进行正比率比较。^([21](ch03.html#ch03fn21))
- en: Finally, supervised learning and unsupervised learning are generally used for
    different types of tasks. Supervised learning is often used for classification
    (predicting the correct category) or regression (predicting the correct value)
    tasks while unsupervised learning is often used for clustering, anomaly detection,
    and dimensionality reduction tasks.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，监督学习和无监督学习通常用于不同类型的任务。监督学习通常用于分类（预测正确的类别）或回归（预测正确的值）任务，而无监督学习通常用于聚类、异常检测和降维任务。
- en: 'Interview question 3-7: What are scenarios where you would use supervised learning
    but not unsupervised learning, and vice versa? Please illustrate with some real-world
    examples.'
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-7：您在哪些情况下会使用监督学习而不使用无监督学习，反之亦然？请用一些现实世界的例子加以说明。
- en: Example answer
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 示例答案
- en: Unsupervised learning and supervised learning differ in the usage of results
    or labels. Hence, unsupervised learning is most suitable for cases where labeled
    data is not available or when the task isn’t to predict a “correct” output, but
    rather to find patterns or anomalies in the data.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习和监督学习在结果或标签的使用上存在差异。因此，无监督学习最适用于标记数据不可用或任务不是预测“正确”输出，而是在数据中找到模式或异常的情况。
- en: As a real-world example, supervised learning can be used for classification
    and object detection, such as in image recognition tasks. In the training dataset
    I’ll have the correct objects labeled, and the algorithms will then know if they’re
    learning to detect objects correctly based on comparing their predictions with
    the ground truth. In other words, if the algorithm isn’t correctly boxing faces
    in images, I’d know since I’ll have each image (with the faces correctly boxed)
    to compare to. Other scenarios for supervised learning could include predicting
    the price of a rare trading card based on its features, such as its age, its series
    name, and the condition of the card. Given that I have a dataset with fraudulent
    data already correctly labeled, fraud detection could also be an application of
    supervised learning. If I didn’t already have labeled data about fraudulent behavior,
    I might opt to use unsupervised learning instead, via detecting anomalous behaviors.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个现实世界的例子，监督学习可以用于分类和物体检测，例如图像识别任务。在训练数据集中，我将有正确标记的对象，并且算法将知道它们是否学会了根据与地面实况比较它们的预测来正确地检测对象。换句话说，如果算法没有正确地在图像中用框圈出脸部，我会知道，因为我将每个图像（脸部正确框出）与之比较。监督学习的其他场景可能包括基于其特征（如其年龄、系列名称和卡片的条件）预测罕见交易卡的价格。鉴于我已经有了正确标记的欺诈数据集，欺诈检测也可能是监督学习的应用。如果我没有关于欺诈行为的标记数据，我可能会选择使用无监督学习，通过检测异常行为来进行。
- en: Note
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In a real interview, you might not have to come up with so many examples, but
    as a reference answer, I’m including a few. It’s even better if you can come up
    with an example that’s a common concern for the industry of the company where
    you’re interviewing. For example, time-series examples are often relevant to finance
    and fintech industries, and fraud detection is relevant to online sales platforms,
    banking, and finance.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在真实的面试中，你可能不需要提供这么多例子，但作为参考答案，我会列举一些。如果你能提供一个在你面试的公司所属行业中普遍关注的例子，那就更好了。例如，时间序列的例子通常与金融和金融科技行业相关，而欺诈检测则与在线销售平台、银行和金融相关。
- en: Sometimes unsupervised learning is more suitable than supervised learning. For
    general warning signs of abnormal behavior, anomaly detection can be used to find
    an anomalous login location for a user’s online bank account. Clustering is an
    unsupervised learning task, and a real-world application could be to group customers
    into segments based on their features (e.g., behavior, preferences), something
    that businesses might use to identify how they can tailor products to users in
    a cluster or to target marketing campaigns. If I investigate a cluster and it
    shows that young professionals have similar behaviors via the clustering algorithm,
    then we might know that we can give them similar promotional materials in the
    company’s next digital ad campaign.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 有时无监督学习比监督学习更合适。对于异常行为的一般警告标志，可以使用异常检测来查找用户在线银行账户的异常登录位置。聚类是一种无监督学习任务，实际应用可以是根据客户的特征（例如行为、偏好）将客户分组，企业可以利用这些信息来确定如何为特定集群的用户量身定制产品或针对市场营销活动。如果我调查一个集群，并且通过聚类算法显示年轻专业人士有类似的行为，那么我们可能会知道在公司下一次数字广告活动中可以向他们提供类似的促销材料。
- en: 'Interview question 3-8: What is a common issue that you might run into while
    implementing supervised learning, and how would you address it?'
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-8：在实施监督学习时可能遇到的常见问题是什么，你会如何解决？
- en: Example answer
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 示例答案
- en: One common problem that can affect supervised learning is the lack of labeled
    data. For example, when I want to classify specific cartoon and anime characters
    in images with ML, I don’t have labeled data available on the internet to download
    and use. There are open source datasets such as CIFAR,^([22](ch03.html#ch03fn22))
    which are labeled for general objects and items, but when it comes to more specific
    use cases, I would have to acquire and label images myself (for personal usage).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会影响监督学习的一个常见问题是缺乏标记数据。例如，当我想要用机器学习分类图像中的特定卡通和动漫角色时，我找不到可用于下载和使用的互联网标记数据。有一些开源数据集，比如CIFAR，^([22](ch03.html#ch03fn22))用于一般对象和物品的标记，但是对于更具体的用例，我需要自己获取并标记图像（供个人使用）。
- en: 'I had to address the issue of not having enough labeled data; in this case,
    hand labeling a few examples worked as a starting point. However, there still
    weren’t *enough* labeled examples, which resulted in an imbalanced dataset. To
    artificially increase the amount of labeled data, I used data augmentation, creating
    synthetic data and variations on existing data to make the ML model more robust.
    An example of data augmentation in image recognition is to randomly flip or rotate
    images. To illustrate why this can increase samples, if I flip one upright anime
    character looking to the right, it becomes two data points for the model to learn
    from: one looking right and one looking left. Rotation can also help: can the
    ML algorithm correctly identify anime characters who are leaning sideways or who
    are even upside down, doing a headstand?'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾经处理过标记数据不足的问题；在这种情况下，手动标记一些例子作为起点是有效的。然而，仍然没有足够的*标记*例子，这导致了一个不平衡的数据集。为了人为增加标记数据的数量，我使用了数据增强技术，创建了合成数据和现有数据的变体，以使机器学习模型更加健壮。在图像识别中的数据增强的一个例子是随机翻转或旋转图像。为了说明为什么这可以增加样本，如果我翻转一个向右看的直立动漫角色，那么它就变成了两个模型学习的数据点：一个向右看和一个向左看。旋转也有助于：机器学习算法能够正确地识别侧身倾斜或者倒立做倒立头的动漫角色吗？
- en: Natural Language Processing Algorithms
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言处理算法
- en: NLP has gained traction in recent years, with the notable example of OpenAI’s
    ChatGPT. There are a lot of interview questions that build off the foundational
    techniques of transformers, and subsequently the BERT and GPT families of models,
    so I will cover those concepts in this section.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，自然语言处理领域取得了很大进展，OpenAI的ChatGPT就是一个显著的例子。有很多面试问题是基于变压器模型的基础技术，并且随后是BERT和GPT系列模型，所以我会在本节中涵盖这些概念。
- en: NLP is often applied in chatbots and sentiment analysis (for example, to see
    if the general attitude toward a product or company is positive or negative, based
    on Reddit or Twitter posts) as well as to generate written content. If you are
    interviewing for a company or team that is working on NLP, you will definitely
    be asked to demonstrate your understanding of these concepts in depth. Even if
    you’re not interviewing for an NLP team specifically, I’d still recommend having
    a general understanding of NLP applications, which will make you a more well-rounded
    candidate and ML professional. Not to mention, NLP techniques are no longer used
    to generate written content only; they are also being combined with computer vision,
    text-to-image models to generate images, video, audio, and so on. Even time-series
    prediction and recommender systems have started picking up NLP techniques. You’ll
    benefit from learning the basics of NLP because of how generalizable the techniques
    are.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: NLP通常应用于聊天机器人和情感分析（例如，基于Reddit或Twitter帖子查看产品或公司的一般态度是积极还是消极），以及生成书面内容。如果您正在为一个从事NLP工作的公司或团队面试，那么您肯定会被要求深入展示您对这些概念的理解。即使您不是专门面试NLP团队，我仍然建议您对NLP应用有一般了解，这将使您成为一个更全面的候选人和ML专业人员。更不用说，NLP技术不再仅用于生成书面内容；它们还与计算机视觉、文本到图像模型结合，用于生成图像、视频、音频等等。甚至时间序列预测和推荐系统也开始采用NLP技术。学习NLP的基础知识将会给您带来很多好处，因为这些技术的通用性有多大。
- en: This section covers the basics of NLP techniques for those who are unsure whether
    they have the background knowledge in this area. Feel free to skip the subsections
    if you already have expertise in any of these areas. Regardless of your expertise,
    I’ve highlighted specific advice for ML interviews in the tip boxes to help you
    apply your knowledge of each ML area and excel in your interviews.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了NLP技术的基础知识，适合那些对该领域的背景知识不确定的人。如果您已经精通其中任何领域，请随意跳过子部分。无论您的专业水平如何，我都在提示框中强调了ML面试的具体建议，以帮助您应用您对每个ML领域的知识，并在面试中表现出色。
- en: Summarizing NLP Underlying Concepts
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结NLP的基本概念
- en: Let’s break down the components that power NLP. First, you have a dataset, often
    called a *text corpus*.^([23](ch03.html#ch03fn23)) A text corpus can consist of
    many types of text, such as news, online forums, or anything with a lot of authentic
    and meaningful text that isn’t gibberish. Next, with this dataset you’ll need
    to preprocess the data much like you would for other ML jobs. Some common techniques
    that are quizzed about in interviews are tokenization, bag of words, or TF-IDF
    (term frequency–inverse document frequency).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解支持 NLP 的组件。首先，你有一个数据集，通常称为*文本语料库*。^([23](ch03.html#ch03fn23)) 文本语料库可以包含许多类型的文本，如新闻、在线论坛或任何具有大量真实和有意义文本的内容，而不是胡言乱语。接下来，使用这个数据集，你需要像处理其他机器学习任务一样对数据进行预处理。一些常见的在面试中会问到的技术包括分词、词袋模型或
    TF-IDF（词频-逆文档频率）。
- en: '*Tokenization* is the process of breaking down the text into individual words,
    phrases, or useful semantic units.^([24](ch03.html#ch03fn24)) For example, depending
    on the situation, the word “preprocess” could be left as its own token or separated
    into “pre” and “process.” “Aren’t” could be left as its own token but could also
    be separated into “are,” and “n’t.”'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '*分词*是将文本分解为单词、短语或有用的语义单元的过程。^([24](ch03.html#ch03fn24)) 例如，根据情况，“preprocess”
    这个词可以作为一个单独的标记保留，也可以分解为“pre”和“process”。而“aren’t”可以作为一个单独的标记保留，但也可以分解为“are”和“n’t”。'
- en: Once the dataset has been preprocessed, language modeling can be formulated
    to predict the next sequence of items, which could be the next word (as illustrated
    in [Figure 3-9](#next_word_or_phrase_predictioncomma_as_s)), the next sentence,
    the next paragraph, missing words, and so on.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据集经过预处理，语言建模就可以被制定出来，以预测下一个序列的项，这可能是下一个单词（如图 3-9](#next_word_or_phrase_predictioncomma_as_s)所示），下一个句子，下一个段落，缺失的单词等等。
- en: '![Next word or phrase prediction, as seen in autocomplete on phones or email25](assets/mlin_0309.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![如手机或电子邮件上的自动完成中看到的下一个单词或短语预测25](assets/mlin_0309.png)'
- en: Figure 3-9\. Next word or phrase prediction, as seen in [autocomplete](https://oreil.ly/MoMsz)
    on phones or email.^([25](ch03.html#ch03fn25))
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-9\. 如手机或电子邮件上的自动完成中看到的下一个单词或短语预测。^([25](ch03.html#ch03fn25))
- en: '*Bag of words* (*BoW*) is a way to map a sentence or phrase by mapping the
    words in it to a vector. The vector can consist of the words and other info, such
    as how many times the word has appeared (1 if once, 2 if twice, and so on). An
    example *.json* representation for the sentence “Syd likes to drink bubble tea
    and chamomile tea” would be:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '*词袋模型*（*BoW*）是一种将句子或短语映射到向量的方法。向量可以由单词和其他信息组成，例如单词出现的次数（如果出现一次为1，出现两次为2，依此类推）。对于句子“Syd
    likes to drink bubble tea and chamomile tea”的示例*.json*表示如下：'
- en: '[PRE0]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that the word “tea” appears twice, and thus the count is 2.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，“tea”这个词出现了两次，因此计数为2。
- en: '*TF-IDF* uses the frequency of the appearance of words in a passage or document
    to determine how relevant those words are.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '*TF-IDF*利用单词在段落或文档中出现的频率来确定这些单词的相关性。'
- en: Although it shares many foundational concepts with other types of ML, NLP comes
    with unique challenges. In cases where supervised learning is used, such as downstream
    fine-tuning, the data is hard to label. For example, if you are using supervised
    fine-tuning for sentiment analysis to quickly predict if a user review is positive
    or negative, it can be ambiguous at times. Another challenge is that there’s a
    large amount of variability, such as slang and regional syntax differences, which
    can also lead to data sparsity, where exact combinations of words might rarely
    appear in the text corpus but are still valid.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管NLP与其他类型的机器学习共享许多基础概念，但它也带来了独特的挑战。在使用监督学习（如下游微调）时，数据很难标记。例如，如果您正在使用监督微调进行情感分析，快速预测用户评论是积极的还是消极的，有时可能会存在歧义。另一个挑战是存在大量的变异性，例如俚语和地方语法差异，这也可能导致数据稀疏性，即文本语料库中确切的单词组合可能很少出现，但仍然是有效的。
- en: Common use cases of NLP include sentiment analysis, chatbots, text classification
    (e.g., spam versus not spam), text generation, text summarization, text-to-image
    generation, and many more.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: NLP的常见用例包括情感分析、聊天机器人、文本分类（例如，垃圾邮件与非垃圾邮件）、文本生成、文本摘要、文本到图像生成等等。
- en: Tip
  id: totrans-183
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: BoW and TF-IDF are useful underlying techniques that I’ve recently heard mentioned
    in interviews.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: BoW和TF-IDF是我最近在面试中听说的有用的基础技术。
- en: Summarizing Long Short-Term Memory Networks
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要长短期记忆网络
- en: Long short-term memory (LSTM) networks are a type of recurrent neural network
    designed to handle long sequences of data, which is useful in NLP applications.
    Like attention units in transformers, long-term dependencies and context of prior
    text are important for NLP to be effective. However, LSTMs have some limitations,
    such as when dealing with very long sequences of text—that is, understanding the
    context of text that came much earlier in a page or paragraph. To that end, transformers
    (covered in the next section) are able to handle long-term dependencies better.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 长短期记忆（LSTM）网络是一种递归神经网络，专门设计用于处理长数据序列，在自然语言处理（NLP）应用中非常有用。与转换器中的注意力单元类似，长期依赖性和先前文本的上下文对于NLP的有效性至关重要。然而，LSTMs也有一些局限性，比如处理非常长的文本序列时，即理解页面或段落中较早出现的文本背景。为此，转换器（在下一节中介绍）能够更好地处理长期依赖性。
- en: Tip
  id: totrans-187
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: LSTMs can be used for feature engineering and time series as well. I don’t include
    more explanation here because of space constraints, but I encourage you to read
    more. Christopher Olah’s blog [Understanding LSTM Networks](https://oreil.ly/C-jwG)
    offers a good series of illustrations for understanding how LSTMs are used.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: LSTMs不仅可以用于特征工程和时间序列。由于篇幅限制，我在这里不再详细解释，但我鼓励你阅读更多。Christopher Olah的博客[理解LSTM网络](https://oreil.ly/C-jwG)提供了一系列良好的插图，帮助理解LSTMs的应用。
- en: Summarizing Transformer Models
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要变压器模型
- en: The transformer model was introduced by Google in 2017,^([26](ch03.html#ch03fn27))
    which has enabled a larger scope of language models in recent years. Transformers
    are effective at NLP modeling because of their improvements in handling context
    and meaning over longer text strings compared to existing architectures like convolutional
    neural networks (CNNs) and recurrent neural networks (RNNs).^([27](ch03.html#ch03fn28))
    Transformers are also better suited to finding patterns within the dataset, as
    opposed to requiring large, labeled datasets like CNNs and RNNs do. Hence, there
    is a lower barrier to entry for what datasets are available. With transformers,
    large, free-form text corpora from the internet became available for use, without
    the need for costly labeling beforehand.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 模型由 Google 于 2017 年引入，^([26](ch03.html#ch03fn27)) 这使得近年来语言模型的范围得以扩大。相比于卷积神经网络（CNNs）和循环神经网络（RNNs）等现有架构，Transformers
    在处理长文本串的上下文和意义时表现出更好的改进。^([27](ch03.html#ch03fn28)) Transformers 也更适合在数据集中找到模式，而不像
    CNNs 和 RNNs 那样需要大规模标记的数据集。因此，现有数据集的准入门槛更低。有了 transformers，大型的、自由形式的互联网文本语料库可以直接用于分析，无需事先昂贵的标注工作。
- en: Attention units within the transformer network are part of transformers’ effectiveness
    and can find both short- and long-distance relationships between words, which
    helps the model correctly label the context. Take, for example, the sentences
    “Max went to the record store. Later, *he* bought a Jay Chou album.” Self-attention
    units can correctly identify that “*he*” is referring to “Max.” Combined with
    BERT’s encoder architecture and multihead attention mechanisms, this has resulted
    in significant improvements in the performance and capabilities of NLP tasks.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: transformer 网络内的注意力单元是其有效性的一部分，可以找到单词之间的短距离和长距离关系，这有助于模型正确标记上下文。例如，“Max went
    to the record store. Later, *he* bought a Jay Chou album.” 自注意力单元可以正确识别“*he*”指的是“Max”。结合
    BERT 的编码器架构和多头注意力机制，这显著提高了自然语言处理任务的性能和能力。
- en: Summarizing BERT Models
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BERT 模型总结
- en: 'Developed by Google, BERT (Bidirectional Encoder Representations from Transformers)
    models have been used to process queries on the Google search engine since 2019.^([28](ch03.html#ch03fn29))
    As hinted at in its full name, BERT makes use of the transformer neutral network
    discussed earlier. BERT is pretrained, meaning the initial training step done
    by Google generates the model that users can access^([29](ch03.html#ch03fn30))
    via “self-supervised” learning on a large corpus of text, such as Wikipedia and
    other text datasets. There are two tasks BERT is trained on during pretraining:
    masked language modeling (MLM) and next sentence prediction (NSP).'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Google 开发，BERT（Bidirectional Encoder Representations from Transformers）模型自
    2019 年起用于处理 Google 搜索引擎的查询。^([28](ch03.html#ch03fn29)) 正如其全名所示，BERT 利用了前述的 transformer
    神经网络。BERT 是预训练的，这意味着 Google 进行的初始训练步骤生成了用户可以访问的模型^([29](ch03.html#ch03fn30))，通过在大规模文本语料库（如维基百科和其他文本数据集）上进行“自监督”学习。在预训练期间，BERT
    接受了两个任务的训练：遮蔽语言建模（MLM）和下一个句子预测（NSP）。
- en: '*Masked language modeling* refers to randomly “masking,” or blocking/removing,
    several tokens in a sentence and letting the model learn to correctly predict
    those tokens—for example, “Lisa is singing a [MASK],” where [MASK] signifies the
    token for BERT to predict. This is illustrated in [Figure 3-10](#illustration_of_masked_language_modeling).
    If BERT can predict that “song” or “melody” or other words have a higher probability
    of being correct, then the model training is going well. If it’s predicting words
    or tokens like “dog,” then it is not being accurate at that point during model
    training.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '*遮蔽语言建模* 指的是随机“遮蔽”或阻止/删除句子中的几个标记，并让模型学习正确预测这些标记。例如，“Lisa is singing a [MASK]”，其中
    [MASK] 表示 BERT 预测的标记。这在 [Figure 3-10](#illustration_of_masked_language_modeling)
    中有所说明。如果 BERT 能够预测“歌曲”或“旋律”等词有更高的正确概率，那么模型训练就很顺利。如果它预测的词或标记像“狗”，那么在模型训练的这一点上就不准确。'
- en: '![Illustration of masked language modeling](assets/mlin_0310.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![Illustration of masked language modeling](assets/mlin_0310.png)'
- en: Figure 3-10\. Illustration of masked language modeling.
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-10\. 遮蔽语言建模示例。
- en: '*Next sentence prediction* is the second task that BERT is trained on. The
    goal is to accurately predict the next sentence in a text sequence. Since this
    training process can provide feedback to the model without external labeling,
    it is not “supervised” learning per se, but it is described as “self-supervised”
    since the feedback comes from the text corpus itself.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '*下一个句子预测* 是 BERT 训练的第二个任务。其目标是准确预测文本序列中的下一个句子。由于这一训练过程可以在没有外部标签的情况下向模型提供反馈，因此它并不是“监督”学习本身，但因为反馈来自文本语料库本身，所以被描述为“自监督”学习。'
- en: After model pretraining, users can then download the model or use an API^([30](ch03.html#ch03fn31))
    to “fine-tune” the model to their own use cases. This improves on the user’s copy
    of the BERT model and requires supervised learning. For example, the user may
    wish to use BERT for sentiment analysis; in that case, the user would need to
    provide examples and labels of text that have a positive sentiment, negative sentiment,
    or ambiguous sentiment (if the user wishes). If you want to use BERT to generate
    text with a specific tone—for example, a movie supervillain—you’d need to provide
    BERT-specific examples as part of fine-tuning. BERT saves the user a lot of time
    on tasks like these since it already has a general understanding of the target
    language (English, among pretrained models of other languages that have been created
    by various developers^([31](ch03.html#ch03fn32))).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 模型预训练之后，用户可以下载模型或使用 API^([30](ch03.html#ch03fn31))来“精细调整”模型以适应其自己的用例。这会改进用户的
    BERT 模型副本，并需要监督学习。例如，用户可能希望使用 BERT 进行情感分析；在这种情况下，用户需要提供具有积极情感、消极情感或模糊情感的文本示例和标签（如果用户愿意）。如果你想使用
    BERT 生成具有特定语气的文本，例如电影反派，你需要提供特定于 BERT 的示例作为精细调整的一部分。BERT 在这些任务上为用户节省了大量时间，因为它已经对目标语言（包括各种开发者创建的其他语言的预训练模型）有了一般性的理解^([31](ch03.html#ch03fn32))。
- en: Tip
  id: totrans-199
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Fine-tuning can be used for many other ML models, not just BERT. For example,
    you can fine-tune models such as [GPT-3.5](https://oreil.ly/5IMBU) (at the time
    of writing). However, I include fine-tuning under BERT since I have seen many
    interviews ask about fine-tuning in the context of BERT.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 精调可以用于许多其他的 ML 模型，而不仅仅是 BERT。例如，你可以精调像[GPT-3.5](https://oreil.ly/5IMBU)（在写作时）。然而，我将精调作为
    BERT 的一部分，因为我看到许多面试都在问关于 BERT 精调的问题。
- en: Summarizing GPT Models
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结 GPT 模型
- en: The GPT (Generative Pretrained Transformer) family of NLP models is known for
    powering the OpenAI tool, ChatGPT. The GPT family of models includes GPT-1, GPT-2,
    GPT-3, and GPT-4 at the time of writing.^([32](ch03.html#ch03fn33)) They are trained
    on large corpora of text,^([33](ch03.html#ch03fn34)) such as BookCorpus, WebText
    (Reddit), English Wikipedia, and more.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: GPT（生成式预训练变换器）系列的 NLP 模型以推动 OpenAI 工具 ChatGPT 而闻名。截至写作时，GPT 模型家族包括 GPT-1、GPT-2、GPT-3
    和 GPT-4^([32](ch03.html#ch03fn33))。它们在大型文本语料库上进行训练^([33](ch03.html#ch03fn34))，例如
    BookCorpus、WebText（Reddit）、英文维基百科等等。
- en: The GPT family leverages transformers and is pretrained on predicting the next
    word. Like other major NLP models, it can be fine-tuned^([34](ch03.html#ch03fn35))
    downstream to update the pretrained model’s parameters to parameters targeted
    toward more specific tasks, such as text generation. Notably, GPT-3 (with GPT-3.5
    and GPT-4 powering ChatGPT at the time of writing) also uses RL via user feedback
    to improve its model predictions. RL is covered in more detail in [“Reinforcement
    Learning Algorithms”](#reinforcement_learning_algorithms).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: GPT 家族利用变换器进行预训练，并且预测下一个单词。像其他主要的 NLP 模型一样，它可以通过精细调整^([34](ch03.html#ch03fn35))来更新预训练模型的参数，使其更适合特定任务，例如文本生成。值得注意的是，GPT-3（与在写作时推动
    ChatGPT 的 GPT-3.5 和 GPT-4）还利用用户反馈通过强化学习来改进其模型预测。强化学习在[“强化学习算法”](#reinforcement_learning_algorithms)中有更详细的介绍。
- en: Apart from GPT, several other large language models (LLMs), such as PaLM2 (which
    powers Google Bard), Llama/[Llama 2](https://oreil.ly/MkMeN) (Meta AI), and more^([35](ch03.html#ch03fn36))
    are trained on similar techniques.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 GPT，还有几个其他大型语言模型（LLMs），例如 PaLM2（驱动 Google Bard）、Llama/[Llama 2](https://oreil.ly/MkMeN)（Meta
    AI）等等^([35](ch03.html#ch03fn36))，都是基于类似技术进行训练的。
- en: Going Further
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更进一步
- en: NLP has been growing at a fast pace, with many well-known LLMs being released
    in recent years (as illustrated in [Figure 3-11](#evolutionary_tree_illustration_of_large)).
    I encourage candidates interested in the field to learn more about these models
    and techniques. I remember exploring Word2vec^([36](ch03.html#ch03fn37)) and GloVe^([37](ch03.html#ch03fn38))
    at work, and now there are so many other ways to develop NLP applications. Many
    foundational methods such as those two and models like BERT are still commonly
    used, and hiring managers I know still ask about them, so don’t neglect the foundations
    either!
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: NLP 近年来发展迅速，许多知名的 LLM 已经发布（如[图 3-11](#evolutionary_tree_illustration_of_large)所示）。我鼓励对该领域感兴趣的候选人更多地了解这些模型和技术。我记得在工作中探索了
    Word2vec^([36](ch03.html#ch03fn37)) 和 GloVe^([37](ch03.html#ch03fn38))，现在还有许多其他开发
    NLP 应用的方法。许多基础方法像这两个以及像 BERT 这样的模型仍然被广泛使用，我认识的招聘经理们仍然会询问它们，所以不要忽视基础！
- en: '![Evolutionary tree illustration of large language models; used with permission
    from “The Practical Guides for Large Language Models”](assets/mlin_0311.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![大型语言模型的进化树示意图；来源：“大型语言模型实用指南”](assets/mlin_0311.png)'
- en: Figure 3-11\. Evolutionary tree illustration of large language models; used
    with permission from [“The Practical Guides for Large Language Models”](https://oreil.ly/eVJEK).
  id: totrans-208
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-11\. 大型语言模型的进化树示意图；使用许可来自[“大型语言模型实用指南”](https://oreil.ly/eVJEK)。
- en: Sample Interview Questions on NLP
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NLP 面试样本问题
- en: Now that I’ve covered some foundational techniques used in NLP, it’s time to
    look at some interview questions. The NLP space and applications in generative
    AI have been moving very quickly, so we’ll see how things change! However, from
    speaking to hiring managers in my network, I know that all of them still expect
    knowledge on foundational topics and data preprocessing techniques for NLP use
    cases.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经介绍了一些在 NLP 中使用的基础技术，是时候看一些面试问题了。NLP 领域和生成 AI 中的应用发展非常迅速，因此我们将看到事情如何变化！然而，从我与网络中的招聘经理交流来看，我知道所有的招聘经理仍然期望候选人具备关于基础主题和用于
    NLP 应用案例的数据预处理技术的知识。
- en: 'Interview question 3-9: How would you leverage pretrained models like BERT
    for specific downstream tasks such as sentiment analysis, chatbots, or named entity
    recognition?'
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-9：你将如何利用像 BERT 这样的预训练模型来执行特定的下游任务，比如情感分析、聊天机器人或命名实体识别？
- en: Example answer
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: BERT and other NLP models that have been pretrained can be fine-tuned. A large
    source of pretrained NLP models is the Hugging Face model repository. Pretrained
    models may include user-uploaded fine-tuned models of original models by Google,
    OpenAI, and so on, but users can also download models fine-tuned on tasks like
    sentiment analysis.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: BERT 和其他预训练的 NLP 模型可以进行微调。一个大型的预训练 NLP 模型库是 Hugging Face 模型库。预训练模型可能包括用户上传的原始模型的微调模型，例如由
    Google、OpenAI 等公司提供的原始模型，但用户也可以下载针对情感分析等任务进行微调的模型。
- en: If I wanted to fine-tune one of the original models myself, I’d need to provide
    a labeled dataset for the NLP model. For example, for sentiment analysis, that
    would include examples of both positive and negative sentiment text; for chatbots,
    I might provide labeled data with the correct corresponding answer to a help desk
    question; and for named entity recognition, I’d provide examples of the named
    entities that I’d expect the NLP model to correctly output.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我想自己对其中一个原始模型进行微调，我需要为 NLP 模型提供一个带标签的数据集。例如，对于情感分析，这将包括正面和负面情感文本的示例；对于聊天机器人，我可能提供带有正确答案的帮助台问题的标记数据；对于命名实体识别，我将提供命名实体的示例，希望
    NLP 模型能正确输出。
- en: 'Interview question 3-10: How do you clean/process a raw text corpus for training
    an NLP model? Can you name one or two techniques and the reasons behind them?'
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-10：你如何清洗/处理原始文本语料库以训练 NLP 模型？你能列举一两种技术及其背后的原因吗？
- en: Example answer
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: 'When starting from a raw corpus, a quick first step is to use regex (regular
    expression) techniques to clean up unwanted characters. Some downstream tasks
    don’t rely much on punctuation, but tasks like sentiment analysis could benefit
    from keeping punctuation; we can see how “!” could be useful for sentiment analysis.
    Next, we can use tokenization to break the text down into meaningful units, which
    often happen to be words; for example, “Susan is writing a sentence” becomes the
    five tokens: “Susan, is, writing, a, sentence.”'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 从原始语料库开始，一个快速的第一步是使用正则表达式技术清除不需要的字符。某些下游任务并不依赖标点符号，但像情感分析这样的任务可能受益于保留标点符号；我们可以看到“！”在情感分析中可能是有用的。接下来，我们可以使用分词将文本分解为有意义的单元，通常是单词；例如，“Susan
    is writing a sentence”可以分解为五个标记：“Susan, is, writing, a, sentence.”
- en: Stemming and lemmatization both aim to reduce a word to its base form so that
    tense variations and derivations can still point to the same root word. *Stemming*
    is a rough heuristic that removes the ends of words (such as cars → car; history
    → histori and historical → histori).^([38](ch03.html#ch03fn39)) Stemming is a
    cruder technique than *lemmatization*, which makes use of the dictionary forms
    of a base word; for example, in lemmatization, “studying,” “studies,” and “study”
    will all be lemmatized as “study.” This is useful for the NLP model to recognize
    that these words mean the same at their root.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 词干提取（Stemming）和词形归并（Lemmatization）都旨在将词语还原为其基本形式，以便时态变化和衍生仍指向同一根词。*词干提取* 是一个粗略的启发式技术，去除单词的末尾（例如
    cars → car；history → histori 和 historical → histori）。[^38] 词干提取比*词形归并*更加粗糙，后者利用词典形式的基本词；例如，在词形归并中，“studying”，“studies”和“study”都会被还原为“study”。这对于NLP模型识别这些词在其根本意义上相同是有用的。
- en: 'Interview question 3-11: What are some common challenges of NLP models, and
    how would you address them?'
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-11：自然语言处理模型常见的挑战有哪些，你如何解决这些挑战？
- en: Example answer
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: Possible challenges with NLP, even with robust pretrained models, could be homonyms/synonyms,
    sarcasm, or domain-specific language such as that of financial or legal documents
    and the like. All of these can be improved upon with better downstream fine-tuning
    with more data that targets the specific case. For example, you can provide more
    examples of the usage of synonyms so that the NLP model can pick out more signals
    on when to use which word.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 即使使用了强大的预训练模型，自然语言处理（NLP）可能面临的挑战包括同义词/同形异义词、讽刺以及特定领域（如金融或法律文件等）的语言。这些问题可以通过更多针对特定情况的数据进行更好的下游微调来改善。例如，可以提供更多同义词用法的示例，这样NLP模型就能更好地判断何时使用哪个词。
- en: There are also inherent biases in many cases; pretraining corpora that are commonly
    used for LLM training, such as Wikipedia, have a disproportionate number of male
    volunteer editors. Reddit, being a forum with a large text dataset, is also commonly
    used as a base for a training dataset and has a disproportionate number of male
    users.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，存在固有的偏见；用于大规模语言模型（LLM）训练的预训练语料库，如维基百科，有大量男性志愿编辑者，这是不成比例的。Reddit作为一个具有大量文本数据集的论坛，也常用作训练数据集的基础，其用户性别偏差也很明显。
- en: 'Interview question 3-12: What is the difference between BERT-cased and BERT-uncased?
    What are the advantages and disadvantages of using one over the other?'
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-12：BERT-cased和BERT-uncased有什么区别？使用其中之一的优缺点是什么？
- en: Example answer
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: '*BERT-uncased* has a tokenizer that will lowercase text input, so regardless
    of passing in cased (including uppercase) or all lowercase (uncased) text, it
    will be the same for BERT-uncased. *BERT-cased*, however, has a separate entry
    for the same words with different cases; for example, “The” will be different
    from “the” in BERT-cased. Thus, BERT-cased has the ability to distinguish between
    different semantics based on case. In applications where the case information
    doesn’t matter much, then BERT-uncased may be suitable. However, for situations
    where cased information is important, such as where proper nouns are valuable
    for the NLP task, BERT-cased will be preferred.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '*BERT-uncased* 有一个分词器，会将输入文本转换为小写，因此不管是传入大小写（包括大写）还是全小写（uncased）文本，对于BERT-uncased来说都是相同的。*BERT-cased*
    则会为相同的单词不同大小写情况下分别处理；例如，“The”在BERT-cased中与“the”是不同的。因此，BERT-cased能够基于大小写区分不同的语义。在不太重视大小写信息的应用中，BERT-uncased可能更合适。然而，在需要考虑大小写信息的情境，例如专有名词对于NLP任务很重要的情况下，会更倾向选择BERT-cased。'
- en: Tip
  id: totrans-226
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'You can see a trend in these questions: regardless of the NLP application (even
    if it’s generative AI!) knowing how to adapt to situations is essential. Preprocessing
    will be different if proper nouns are useful (don’t lowercase everything), and
    while sometimes you might keep the punctuation (such as in sentiment analysis),
    sometimes you don’t. Deeply understanding NLP techniques can help you respond
    much better in interviews than if you only memorize and regurgitate.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到这些问题的趋势：无论是哪种NLP应用（即使是生成式AI！），了解如何适应情况至关重要。如果专有名词有用（不要全部小写），预处理将会不同，有时您可能会保留标点符号（如情感分析），有时则不会。深入理解NLP技术可以帮助您在面试中作出比仅仅记忆和复述更好的回答。
- en: Recommender System Algorithms
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统算法
- en: '*Recommender systems* (RecSys) are everywhere in our digital lives and are
    responsible for personalization of the web pages and apps you visit, such as Netflix,
    YouTube, Spotify, any social media site, and much more. One way to tell if a site
    has personalization is by comparing the order of items or products shown on its
    front page or search results when two different people are logged in. For example,
    what is shown on your YouTube front page is likely not the same as the front page
    of a sibling or friend.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统（RecSys）无处不在于我们的数字生活中，并负责个性化您访问的网页和应用，例如Netflix、YouTube、Spotify、任何社交媒体网站等。通过比较两个不同用户登录时显示在其首页或搜索结果中的项目或产品的顺序，可以判断网站是否具有个性化。例如，您的YouTube首页显示的内容可能与兄弟或朋友的不同。
- en: A recommender system recommends items or products that it thinks you might enjoy,
    interact with, or purchase based on your past behavior. For example, Netflix uses
    information on what shows and movies you’ve watched before as signals in its recommender
    systems to suggest new shows and movies for you.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统根据您以前的行为（例如观看过的节目和电影）提供新节目和电影的建议，认为您可能会喜欢、与之互动或购买。例如，Netflix使用您以前观看的节目和电影的信息作为其推荐系统中的信号，以向您建议新的节目和电影。
- en: Tip
  id: totrans-231
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Since so many tech products use recommender systems, this is a common “default”
    category that interviewers at big tech companies will ask about.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多技术产品使用推荐系统，这是大型科技公司面试官常问的“默认”类别。
- en: This section covers the basics of recommender systems techniques for those who
    are unsure whether they have the background knowledge in this area. Feel free
    to skip the subsections if you already have expertise in any of these areas. Regardless
    of your expertise, I’ve highlighted specific advice for ML interviews in the tip
    boxes to help you apply your knowledge of each ML area and excel in your interviews.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了推荐系统技术的基础知识，供那些不确定是否具备该领域背景知识的人参考。如果您已经在任何这些领域有专业知识，可以跳过子节。无论您的专业知识如何，我都在提示框中强调了ML面试的具体建议，以帮助您应用您在每个ML领域的知识，并在面试中表现出色。
- en: Summarizing Collaborative Filtering
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结协同过滤
- en: '*Collaborative filtering* is a common technique in recommender systems. The
    term comes from using data on preferences of many users and/or items (collaborative)
    to make recommendations for a singular user (filtering). This is based on an assumption
    that individuals with similar past preferences can share preferences for new,
    unseen products; hence, the algorithm will recommend new items liked by similar
    users.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '*协同过滤* 是推荐系统中常见的技术。该术语来源于使用许多用户和/或物品偏好的数据（协同）来为单个用户进行推荐（过滤）。这基于一个假设，即具有相似过去偏好的个体可能会对新的未见产品产生偏好，因此算法将推荐相似用户喜欢的新物品。'
- en: 'There are two main types of collaborative filtering techniques: user based
    and item based. *User-based* collaborative filtering identifies users with similar
    interests and preferences and then recommends products or items to each of those
    similar users that they haven’t seen before. “Similar” users are calculated by
    ML algorithms, such as matrix factorization, which will be covered later in this
    chapter. *Item-based* collaborative filtering identifies items that are similar
    to one another based on their user ratings or user interaction. Items are then
    recommended by the collaborative filtering algorithm if a user has previously
    enjoyed similar items.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤技术有两种主要类型：基于用户和基于物品。 *基于用户* 的协同过滤技术识别具有相似兴趣和偏好的用户，然后向这些相似用户推荐他们以前未见过的产品或物品。通过ML算法（如矩阵分解），计算“相似”用户，这将在本章后面介绍。
    *基于物品* 的协同过滤技术根据其用户评分或用户互动识别相似的物品。如果用户以前喜欢过类似的物品，则协同过滤算法将推荐这些物品。
- en: Summarizing Explicit and Implicit Ratings
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结显式和隐式评分
- en: 'In user-based and item-based collaborative filtering, you generally need to
    know users’ ratings and preferences. If a user has left a good rating and review,
    then you can *explicitly* know that they enjoy a product. But users simply don’t
    have enough time to provide explicit, detailed feedback on everything—think about
    the times you’ve left a review; you likely didn’t do so for every single item
    you’ve used in the past. However, you can still calculate *implicit* feedback,
    such as the time spent on a YouTube video: if someone watches to the end, it could
    mean the viewer liked it more than a video they closed after two seconds. Using
    implicit feedback within a recommender system can help alleviate some common biases
    as well; people are more likely to leave an explicit review if they either loved
    or hated the product (and you know people are more vocal if something went wrong).'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于用户和基于物品的协同过滤中，通常需要了解用户的评分和偏好。如果用户留下了一个好评和评论，那么你可以*明确地*知道他们喜欢这个产品。但是用户没有足够的时间对每件事情都提供明确的详细反馈——想想你自己留下评论的次数；你很可能并没有为过去使用的每件物品都留下评论。然而，你仍然可以计算*隐式*反馈，比如在YouTube视频上花费的时间：如果有人看到最后，这可能意味着观看者比在两秒后关闭视频时更喜欢它。在推荐系统中使用隐式反馈还可以帮助减轻一些常见的偏见；如果人们喜欢或讨厌产品，他们更有可能留下明确的评价（而且你知道如果出了什么问题，人们更有可能大声表达）。
- en: Tip
  id: totrans-239
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: In [Chapter 4](ch04.html#technical_interviewcolon_model_training), I’ll discuss
    model training and data preprocessing. For recommender systems applications, making
    sense of the available explicit and implicit ratings during exploratory data analysis,
    model training, data preprocessing, featuring engineering, evaluation, and monitoring
    is important to discuss in interviews.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第四章](ch04.html#technical_interviewcolon_model_training) 中，我将讨论模型训练和数据预处理。对于推荐系统的应用，在探索性数据分析、模型训练、数据预处理、特征工程、评估和监控过程中，理解可用的显式和隐式评分是面试中重要讨论的内容。
- en: Summarizing Content-Based Recommender Systems
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结基于内容的推荐系统
- en: Another common type of recommender system is the content-based system. In a
    *content-based* recommender system, you need detailed information about the products
    themselves. This information could include traits of text descriptions (book blurbs,
    movie genres and descriptions), images (product screenshots), audio/video (trailers,
    product videos), and so on to create an understanding of which items are similar
    to one another. In contrast, the user- and item-based collaborative filtering
    described earlier relies on user preferences of items or products but not the
    traits of the items themselves.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见的推荐系统类型是基于内容的系统。在基于内容的推荐系统中，你需要关于产品本身的详细信息。这些信息可能包括文本描述的特征（书籍简介、电影类型和描述）、图像（产品截图）、音频/视频（预告片、产品视频）等，以便了解哪些物品彼此相似。相比之下，之前描述的基于用户和基于物品的协同过滤依赖于用户对物品或产品的偏好，而不依赖于物品本身的特征。
- en: An example content-based movie recommender system could recommend movies based
    on the genre, director, or actors of movies that the user has previously watched
    and enjoyed, as measured by explicit and implicit feedback. Hence, a content-based
    recommender systems can be formulated as a ranking or classification problem,
    and algorithms like tree-based models are suitable.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，基于内容的电影推荐系统可以根据用户先前观看并喜欢的电影的类型、导演或演员推荐电影，通过明确和隐式反馈进行衡量。因此，基于内容的推荐系统可以被制定为一个排序或分类问题，像基于树的模型算法非常适合。
- en: User-Based/Item-Based Versus Content-Based Recommender Systems
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于用户/基于物品与基于内容的推荐系统比较
- en: There are some pros and cons to using user-based/item-based or content-based
    recommender systems. User-based systems don’t perform as well with new users;
    this is commonly referred to as the “cold-start” problem since there isn’t enough
    data on the users’ preferences because they may not have bought or rated any products
    yet. Content-based recommender systems might need less user-behavior data since
    they do not rely on other users’ preferences or ratings, which makes them suitable
    for newer users or niche items with less user feedback overall. But content-based
    systems might be limited to recommending items similar to what the user has interacted
    with before; therefore, new items are not introduced to the user, limiting the
    diversity of the products or items that the user might have enjoyed had they been
    recommended those products.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基于用户/基于物品或基于内容的推荐系统都有其优缺点。基于用户的系统在处理新用户时表现不佳；这通常被称为“冷启动”问题，因为用户的偏好数据不足，可能因为他们尚未购买或评价任何产品。基于内容的推荐系统可能需要较少的用户行为数据，因为它们不依赖其他用户的偏好或评分，这使得它们适合新用户或整体反馈较少的小众项目。但基于内容的系统可能仅限于推荐与用户之前互动过的物品类似的物品；因此，新物品不会被引入给用户，从而限制了用户可能享受到的产品或物品的多样性。
- en: Tip
  id: totrans-246
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Knowing the trade-offs between user-based, item-based, and content-based recommender
    systems can help you in interviews as well as on the job. In reality, explicit
    feedback can be hard to come by, and implicit feedback might not be perfect. Knowing
    how to mix and match all the data and RecSys algorithms at your disposal will
    help you stand out by a lot.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 知道基于用户、基于物品和基于内容的推荐系统之间的权衡可以帮助你在面试和工作中脱颖而出。在现实中，显式反馈可能难以获得，而隐式反馈可能并不完美。知道如何混合和匹配你掌握的所有数据和推荐系统算法将极大地帮助你脱颖而出。
- en: Summarizing Matrix Factorization
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结矩阵分解
- en: '*Matrix factorization* is a technique used in collaborative filtering. First,
    a matrix is constructed with users as the rows and items as the columns, with
    the ratings or preferences of a user on an item as the cell values. This is called
    the *user-item matrix*, as illustrated in [Figure 3-12](#illustration_of_matrix_factorizationsemi).
    Since not all users interact with all items, the original matrix will be very
    sparse. For example, a user might have interacted with only a handful of items,
    but the online platform has thousands or millions of products. The goal of matrix
    factorization is to predict those empty values in the matrix—that is, how much
    a user would rate the items they haven’t interacted with before—and recommend
    those that you estimate that the user would enjoy.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '*矩阵分解*是协同过滤中使用的一种技术。首先，构建一个矩阵，其中用户作为行，物品作为列，用户对物品的评分或偏好作为单元格的值。这被称为*用户-物品矩阵*，如图[3-12](#illustration_of_matrix_factorizationsemi)所示。由于并非所有用户都与所有物品互动，原始矩阵将非常稀疏。例如，一个用户可能只与少数几个物品互动过，但在线平台上有数千或数百万种产品。矩阵分解的目标是预测矩阵中那些空值——也就是用户在之前未与之互动的物品上可能会给出的评分，并推荐那些你估计用户会喜欢的物品。'
- en: '![Illustration of matrix factorization; source: Google](assets/mlin_0312.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵分解示例；来源：Google](assets/mlin_0312.png)'
- en: 'Figure 3-12\. Illustration of matrix factorization; source: [Google](https://oreil.ly/F7Tzg).'
  id: totrans-251
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-12\. 矩阵分解示例；来源：[Google](https://oreil.ly/F7Tzg)。
- en: A classic algorithm is singular value decomposition (SVD); however, I have never
    seen it used outside of practice datasets because of its expensive computational
    requirements.^([40](ch03.html#ch03fn41)) For industry applications, if as an ML
    practitioner you choose to use matrix factorization, the chosen algorithm needs
    to be able to handle very sparse and large matrices since many online platforms
    have a large number of products and users. Algorithms such as ALS help address
    this issue since they use approximation via least squares (covered in [“Summarizing
    Linear Regression”](#summarizing_linear_regression)) to calculate their best guesses
    for the missing matrix values (how much a user might enjoy an item) instead of
    the complex matrix manipulations that traditional SVD uses.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经典的算法是奇异值分解（SVD）；然而，除了实践数据集之外，我从未见过它被用于行业应用，因为其昂贵的计算需求。^([40](ch03.html#ch03fn41))
    对于行业应用，如果作为机器学习从业者选择使用矩阵分解，选择的算法需要能够处理非常稀疏和大型的矩阵，因为许多在线平台拥有大量的产品和用户。例如，ALS等算法通过最小二乘法的近似来计算它们对矩阵中缺失值的最佳猜测（用户可能会喜欢的物品），而不是传统SVD使用的复杂矩阵操作。
- en: Sample Interview Questions on Recommender Systems
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐系统面试常见问题样例
- en: Now that I’ve covered the basics of recommender systems, let’s go through some
    example interview questions.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经介绍了推荐系统的基础知识，让我们来看一些实际面试问题的例子。
- en: 'Interview question 3-13: What’s the difference between content-based recommender
    systems and collaborative filtering recommender systems? When would you use one
    over the other?'
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-13：内容推荐系统和协同过滤推荐系统有什么区别？在什么情况下会选择其中之一？
- en: Example answer
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 示例答案
- en: Content-based recommender systems require knowledge of categorization or traits
    of the products being recommended to determine product similarity. Collaborative
    filtering relies on user behavior and user preferences to recommend products that
    users with similar tastes enjoyed and thus can be more ignorant about the products
    themselves.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 内容推荐系统需要了解被推荐产品的分类或特征，以确定产品的相似性。协同过滤依赖用户行为和用户偏好来推荐用户喜欢的类似口味的产品，因此可能对产品本身知之甚少。
- en: Hence, content-based recommenders work well when there are not many users or
    items to construct the user-item matrix for collaborative filtering. In other
    words, content-based recommenders can still make recommendations when there is
    the “cold-start” problem, as long as there is information on the features of the
    items/products and some information on the traits or preferences of the users,
    without requiring more data on user behavior and interactions like collaborative
    filtering does.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在协同过滤推荐系统无法为用户-物品矩阵构建足够多用户或物品时，内容推荐系统可以很好地工作。换句话说，只要有关于物品/产品特征以及用户特征或偏好的信息，内容推荐系统就可以解决“冷启动”问题，而无需像协同过滤那样需要更多的用户行为和交互数据。
- en: On the other hand, collaborative filtering is suited for scenarios in which
    a lot of data on user behavior is available. At times, it can be hard to gather
    sufficient, meaningful features that describe the products, which makes content-based
    recommender systems ineffective. In these cases, collaborative filtering can be
    more suitable.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，协同过滤适用于用户行为数据丰富的情况。有时，很难收集足够的、有意义的描述产品的特征，这使得内容推荐系统失效。在这些情况下，协同过滤可能更合适。
- en: Tip
  id: totrans-260
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Anecdotally, I once worked on a project where a collaborative filtering algorithm
    (ALS) worked better for users who had used the web platform for a while but poorly
    for new users. Using content-based filtering with XGBoost worked better for new
    users, and we deployed different models depending on what type of user they were.
    Of course, this is only one example, and it may differ for your case.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 据我所知，我曾经参与过一个项目，其中协同过滤算法（ALS）对长期使用网络平台的用户效果更好，但对新用户效果较差。使用基于内容的过滤和XGBoost对新用户效果更好，我们根据用户类型部署了不同的模型。当然，这只是一个例子，对您的情况可能会有所不同。
- en: 'Interview question 3-14: What are some common problems encountered in recommender
    systems, and how would you resolve them?'
  id: totrans-262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-14：推荐系统中遇到的一些常见问题及其解决方法是什么？
- en: Example answer
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 示例答案
- en: 'The cold-start problem: this is when there aren’t a lot of past data points
    available for an ML model to train on. Therefore, the model won’t be able to learn
    enough patterns from the past to accurately predict the correct results for new
    data points. In recommender systems, content-based systems can be used, which
    require less user-behavior data but do still require sufficient product-feature
    data. This can help with the cold-start problem and still provide recommendations
    to newer website users.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 冷启动问题：这是指机器学习模型没有足够的过去数据点可供训练。因此，模型无法从过去学到足够的模式，以准确预测新数据点的正确结果。在推荐系统中，可以使用内容推荐系统，它需要较少的用户行为数据，但确实需要足够的产品特征数据。这可以帮助解决冷启动问题，并为新的网站用户提供推荐。
- en: Recommender systems can also encounter challenges with data quality, a problem
    that isn’t exclusive to recommender systems. This can include errors in the source
    data—for example, due to a bug while ingesting the data. This issue can be addressed
    by analyzing where the source data has issues and then fixing it with the teams
    that handle data quality (at times, data engineers or platform engineers, or the
    MLEs and data scientists themselves). However, identifying that there is a data
    quality issue is important in the first place, and some preventative measures
    include using data quality monitoring tools like Great Expectations to alert the
    team when there are shifts in the data distribution or many missing values, for
    example.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统在数据质量方面也可能遇到挑战，这个问题并不仅限于推荐系统。这可能包括源数据中的错误，例如在数据摄入过程中出现的错误。这个问题可以通过分析源数据存在问题的地方，并与负责数据质量的团队（有时是数据工程师或平台工程师，或者是MLE和数据科学家们）合作进行修复来解决。然而，首先要识别数据质量问题的存在是非常重要的，一些预防措施包括使用数据质量监控工具如Great
    Expectations，在数据分布发生变化或者有大量缺失值时提醒团队。
- en: When there are many missing values in an ML dataset, this is called *sparsity*.
    For example, users who sign up for a web platform with a questionnaire that asks
    for user preferences might not input several signup fields correctly or might
    skip them altogether. As an example, when someone signs up for a new Reddit account,
    there is a prompt that shows them common subreddits (subforums) that they may
    be interested in, but the user can skip this step. This is by design to make the
    web signup as frictionless as possible, but scenarios like this could cause data
    sparsity when you are trying to build a feature set for a RecSys. Possible solutions
    include imputation (e.g., filling in missing values with the mean or using a tree-based
    method to fill in the data), using collaborative filtering or matrix factorization
    techniques, feature engineering, and more.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 当ML数据集中有许多缺失值时，这被称为*稀疏性*。例如，注册网站平台的用户可能在问卷中要求用户偏好时没有正确填写或者完全跳过。例如，当有人注册新的Reddit账户时，会显示常见的子论坛，但用户可以跳过这一步。这是为了尽可能减少网站注册过程中的阻力，但是这样的情况可能导致在构建RecSys特征集时出现数据稀疏性。可能的解决方案包括插补（例如，用平均值填补缺失值或使用基于树的方法填补数据）、使用协同过滤或矩阵分解技术、特征工程等等。
- en: 'Interview question 3-15: What is the difference between explicit and implicit
    feedback in recommender systems? What are the trade-offs with using each type,
    respectively?'
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-15：推荐系统中显式反馈和隐式反馈的区别是什么？分别使用每种类型的权衡是什么？
- en: Example answer
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 示例答案
- en: Explicit feedback includes user ratings or reviews while implicit feedback has
    to be derived from available user behavior, such as the time spent on a web page
    or clickstream behavior. The benefits of explicit feedback include a clearly quantified
    rating to use in machine learning as well as clarity when compared to implicit
    feedback. However, explicit feedback can be harder to gather since not all users
    will leave a review after every interaction (most don’t).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 显式反馈包括用户评分或评价，而隐式反馈必须从可用的用户行为中派生，例如在网页上花费的时间或点击流行为。显式反馈的好处包括在机器学习中使用明确量化的评级以及与隐式反馈相比的明确性。然而，显式反馈可能更难收集，因为并不是所有用户每次互动后都会留下评价（大多数用户不会）。
- en: 'Thus, measuring the user’s engagement or enjoyment via implicit feedback, such
    as video watch time or time spent reading on a website, might be used. Of course,
    this can lead to imperfect measures: is the user spending a long time on the webpage
    because they enjoyed the content or because they were confused about the text
    on it? Overall, it is important to consider the trade-offs, but in practice, you
    can often combine both feedback signals in your ML models.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过隐式反馈（例如视频观看时间或在网站上阅读的时间）来衡量用户的参与度或享受程度可能会被使用。当然，这可能导致不完美的度量：用户在网页上花费很长时间是因为他们喜欢内容，还是因为他们对上面的文字感到困惑？总的来说，考虑到这些权衡是很重要的，但实际操作中，你可以经常在你的机器学习模型中结合这两种反馈信号。
- en: 'Interview question 3-16: How would you address imbalanced data in recommender
    systems?'
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-16：在推荐系统中如何解决数据不平衡问题？
- en: Example answer
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 示例答案
- en: 'This is a common problem facing ML scenarios: there are a few classes or categories
    that have many more observations or data points than others, and there are many
    classes/categories that have so few observations that they form a long tail.^([41](ch03.html#ch03fn42))'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这是ML场景中常见的一个问题：有一些类别或类别具有比其他类别更多的观测或数据点，而有许多类别/类别则观测较少，形成了长尾[^41]。
- en: To handle this issue, oversampling techniques may be helpful in simpler cases,
    such as creating more data points of categories that have fewer observations.
    However, when there are many classes/categories of observations, simple oversampling
    techniques won’t be able to alleviate this issue. Additional techniques such as
    feature engineering and ensemble methods can be used instead, or in conjunction
    with oversampling. An example of ensemble methods could be creating a separate
    recommender for popular items versus low-engagement items.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这个问题时，过采样技术可能在简单情况下有所帮助，比如创建更多的数据点来增加那些观测次数较少的类别。然而，当观测有许多类别时，简单的过采样技术就不能缓解这个问题了。可以使用其他技术，比如特征工程和集成方法，来替代或与过采样同时使用。集成方法的一个示例可以是为热门项目和低参与度项目分别创建推荐系统。
- en: In companies like Amazon and Spotify, combining RecSys with other families such
    as reinforcement learning helps ensure that long-tail products, artists, or items
    are shown to users at least some of the time.^([42](ch03.html#ch03fn43))
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在像亚马逊和Spotify这样的公司中，将RecSys与强化学习等家族结合起来，有助于确保长尾产品、艺术家或商品至少在某些时间向用户展示。[^42]
- en: Tip
  id: totrans-276
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: To loop back to the beginning of this section, recommender systems are a common
    default ML topic to ask about since many tech companies’ ML use cases can be formulated
    as a ranking or recommendation problem. In big tech, I’ve seen an increase of
    combining NLP techniques or RL with RecSys, so be sure to check out the papers
    in [“Resources for Learning About RecSys Algorithms”](#resources_for_learning_about_recsys_algo)
    for existing examples of well-known RecSys-focused products, such as social media
    (e.g., Facebook, Instagram), entertainment (e.g., Netflix, Spotify, YouTube),
    online shopping (e.g., Amazon), and more.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 回到本节开头，推荐系统是一个常见的默认ML话题，因为许多科技公司的ML用例可以被制定为排名或推荐问题。在大科技公司中，我看到NLP技术或RL与RecSys的结合增加了，因此请务必查看“[了解推荐系统算法的资源](#resources_for_learning_about_recsys_algo)”中的论文，例如社交媒体（如Facebook、Instagram）、娱乐（如Netflix、Spotify、YouTube）、在线购物（如Amazon）等已知的RecSys专注产品的现有示例。
- en: Reinforcement Learning Algorithms
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习算法
- en: In [“Supervised, Unsupervised, and Reinforcement Learning”](#supervisedcomma_unsupervisedcomma_and_re)
    I briefly introduced reinforcement learning (RL) algorithms. To recap, RL relies
    on learning through “trial and error,” and in the simplest of cases, it doesn’t
    need a preexisting dataset or known labels. RL will gather knowledge through a
    live environment, such as a robot navigating a maze multiple times, learning where
    the gold, traps, and exits are.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在“[监督学习、无监督学习和强化学习](#supervisedcomma_unsupervisedcomma_and_re)”中，我简要介绍了强化学习（RL）算法。简而言之，RL依赖于“试错”学习，在最简单的情况下，它不需要预先存在的数据集或已知标签。RL将通过实时环境（例如机器人多次导航迷宫）收集知识，学习金子、陷阱和出口的位置。
- en: Reinforcement learning has many applications in industry, such as autonomous
    vehicles, gaming,^([43](ch03.html#ch03fn44)) as part of large-scale recommender
    systems, improvements of LLMs (RLHF^([44](ch03.html#ch03fn45)) was a big part
    of improving [ChatGPT](https://oreil.ly/qoWME)), and more. Hence, an understanding
    of RL is required for interviewing for teams that use RL.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习在工业中有许多应用，比如自动驾驶车辆、游戏[^43]、作为大规模推荐系统的一部分、LLMs（RLHF[^44]对改进[ChatGPT](https://oreil.ly/qoWME)有很大帮助），等等。因此，了解强化学习对于希望加入使用RL的团队的面试者来说是必要的。
- en: Tip
  id: totrans-281
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: As mentioned earlier, RL is a somewhat more advanced family of techniques to
    use in production. So for new-graduate roles, you should focus on gaining a broader
    knowledge of ML first. Once you have that, knowing RL can help you stand out as
    a job candidate (based on my anecdotal experience).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，RL在生产中是一种较为先进的技术家族。因此，对于新毕业生角色，你应该首先专注于获得更广泛的ML知识。一旦掌握了这些，了解RL可以帮助你在求职过程中脱颖而出（根据我的经验来看）。
- en: This section covers the basics of RL techniques for those who are unsure whether
    they have the background knowledge in this area. Feel free to skip the subsections
    if you already have expertise in any of these areas. Regardless of your expertise,
    I’ve highlighted specific advice for ML interviews in the tip boxes to help you
    apply your knowledge of each ML area and excel in your interviews.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了强化学习技术的基础知识，供那些不确定自己在这一领域是否具备背景知识的人参考。如果您已经在任何这些领域中具有专业知识，请随意跳过子节。无论您的专业知识如何，我在提示框中强调了关于ML面试的具体建议，帮助您应用每个ML领域的知识，并在面试中表现出色。
- en: Summarizing Reinforcement Learning Agents
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结强化学习代理
- en: In RL, an *agent* is an autonomous entity that interacts with an environment
    with certain goals or objectives and learns to make optimal decisions through
    trial and error. An example is a self-driving car that doesn’t drive well but,
    while learning in a test environment, over time, learns which behaviors are good
    (following speed limits and road signs) and which are bad (such as bumping into
    trees and running red lights).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习中，*代理*是一个与环境交互的自主实体，具有特定的目标或目标，并通过试错学习做出最优决策。例如，一辆自动驾驶汽车在测试环境中学习，随着时间的推移，学会了哪些行为是好的（遵守速度限制和道路标志）和哪些是坏的（如撞到树木和闯红灯）。
- en: While the *model* is the focus of most ML algorithms mentioned in the previous
    sections, in RL the *agent* is being updated as the agent interacts with the environment.
    This does not mean there are no “models” in RL, but models are often used as supporting
    components that can be mixed and matched within the entire RL workflow.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在前面提到的大多数ML算法中，*模型*是焦点，但在RL中，*代理*随着其与环境的交互而更新。这并不意味着RL中没有“模型”，但模型通常被用作支持组件，可以在整个RL工作流程中混合和匹配。
- en: 'To illustrate RL, I’ll continue with the example of a self-driving car, simplified
    for understanding. Creating this basic RL agent requires the following building
    blocks: state, action, reward, and policy.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明强化学习，我将继续以自动驾驶汽车的示例简化理解。创建这个基本的强化学习代理需要以下构建块：状态、动作、奖励和策略。
- en: Tip
  id: totrans-288
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: There are many types of reinforcement learning, so the way the policy, state,
    action, or rewards interact in each type of algorithm may differ, and they may
    be mixed and matched with other concepts. Pay attention to which concepts you
    are being asked about in the interview.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多种类的强化学习，因此在每种算法类型中，策略、状态、动作或奖励之间的交互方式可能有所不同，并且它们可能与其他概念混合和匹配。请注意在面试中询问的概念。
- en: 'The RL agent is attempting to learn the best policy for how to react to the
    environment in order to drive safely. When the agent is initialized, it doesn’t
    know the policy to choose the best action in a given scenario yet, so you just
    let it drive around in the environment. The building blocks for this specific
    scenario are:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习代理正试图学习如何根据环境反应以安全驾驶的最佳策略。当代理被初始化时，它不知道在特定情景下选择最佳动作的策略，因此你只需让它在环境中四处行驶。这个特定场景的构建块包括：
- en: State
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 状态
- en: The *state* that the agent encounters is a representation of the environment,
    or the state of the environment. This could include updating information about
    the car’s surroundings; tracking if there is an object to the left, right, front,
    or behind the car; and special tags for drivable roads and traffic lights and
    their status.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 代理遇到的*状态*是环境的表示，或环境的状态。这可能包括更新汽车周围环境的信息；跟踪汽车左侧、右侧、前方或后方是否有物体；以及可行驶道路和交通灯及其状态的特殊标记。
- en: Action
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 动作
- en: 'The *actions* that the agent can choose in this example are: turn left, turn
    right, go forward, and brake. Note: this scenario is simplified to discrete actions,
    but complex scenarios might include how many degrees to turn the steering wheel.
    All the actions that the agent can carry out are collectively referred to as the
    *action set*, and the agent aims to carry out the best action at each decision
    point.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，代理可以选择的*动作*有：左转、右转、前进和刹车。注意：这种情况被简化为离散动作，但复杂的情景可能包括转动方向盘的角度。代理可以执行的所有动作统称为*动作集*，代理旨在在每个决策点执行最佳动作。
- en: Reward
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 奖励
- en: 'Each time the agent makes an action, given a state of the environment, the
    agent then gains feedback on how much benefit was gained or lost—this is called
    *reward* in RL. For example, during the state when there is a red light in front
    of the self-driving car RL agent, and the RL agent makes the action to brake,
    that can be rewarded with a positive reward. If the RL agent had chosen to go
    forward and run the red light, it would have gotten a penalty: a reward with a
    negative value, also referred to as a *negative reward*. The agent will remember
    that for the next time. The rewards are usually defined externally, and the agent
    doesn’t know about them beforehand, only learning about them during trial and
    error. Note that the wording “action made *given* a state” is deliberate; the
    same action in different states might yield different rewards. For example, turning
    right and crashing when there is a lamppost to the right and turning right when
    there is a right-turn lane will yield a negative and a positive reward, respectively.
    Hence, the *state* is essential to the decision and the learning of the RL agent,
    not just the *actions* and *rewards*.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 每次代理在环境的某个状态下采取行动后，代理将获得有关获得或损失的利益量的反馈，这在强化学习中称为*奖励*。例如，在自动驾驶汽车RL代理面前有红灯的状态下，RL代理采取制动行动，这可能会被奖励为正奖励。如果RL代理选择继续前进并闯红灯，则会受到惩罚：即获得一个负值的奖励，也称为*负奖励*。代理将记住这一点以便下次使用。奖励通常是外部定义的，代理事先不知道它们，只能在试验和错误中学习到。请注意，“在给定状态下进行的行动”这样的措辞是有意的；在不同状态下进行相同的行动可能会产生不同的奖励。例如，在右侧有灯柱时右转并发生碰撞，以及在右转道上右转将分别产生负和正奖励。因此，*状态*对于RL代理的决策和学习至关重要，不仅仅是*行动*和*奖励*。
- en: Policy
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 策略
- en: The *policy* is how the agent chooses the action. In most cases, it will choose
    the action that is known to yield the highest reward, but this simple policy causes
    the agent to stop exploring new scenarios and often yields strange behavior. For
    example, the agent might have learned early on that turning right at a red light
    doesn’t have a negative reward (allowed under traffic law in many places in North
    America). The agent might *exploit* the fact, always turning right at a red light,
    instead of trying something new and stopping at a red light instead.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '*策略*是代理如何选择行动的方式。在大多数情况下，它将选择已知能产生最高奖励的行动，但这种简单的策略会导致代理停止探索新的场景，并且经常产生奇怪的行为。例如，代理可能早就学会了在红灯时右转不会受到负奖励（在北美的许多地方根据交通法律是允许的）。代理可能会*利用*这个事实，总是在红灯时右转，而不是尝试新的事物，例如在红灯处停车。'
- en: So the policy can be defined as choosing the action given that state that is
    known to yield the highest reward, given that it balances additional factors such
    as *exploitation* of known rewards and *exploration* of the environment to learn
    new state-action-reward combinations. Commonly used policies include the [epsilon-greedy
    policy](https://oreil.ly/F1zE6),^([45](ch03.html#ch03fn46)) where the agent explores
    more in the beginning of the training process and then exploits more after it’s
    experienced more states, actions, and rewards. In some types of RL, its policy
    is a parametrized model that is then updated; I’ll cover that more in the later
    section about policy-based RL.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，策略可以定义为在已知产生最高奖励的状态下选择行动，同时平衡诸如*利用*已知奖励和*探索*环境以学习新的状态-动作-奖励组合等附加因素。常用的策略包括[epsilon-贪婪策略](https://oreil.ly/F1zE6)^([45](ch03.html#ch03fn46))，其中代理在训练过程的开始阶段更多地进行探索，然后在经历了更多状态、行动和奖励之后更多地进行利用。在某些类型的强化学习中，其策略是一个参数化模型，然后进行更新；我将在关于基于策略的强化学习的后续部分中详细介绍这一点。
- en: In summary, the agent uses the policy to choose an optimal action at a given
    state, after which it looks at the reward from the action and then updates the
    policy to improve for future states and actions, as illustrated in [Figure 3-13](#reinforcement_learning_policy_update).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，代理使用策略在给定状态下选择最优行动，然后查看行动带来的奖励，然后更新策略以改进未来的状态和行动，如[图 3-13](#reinforcement_learning_policy_update)所示。
- en: '![Reinforcement learning policy update](assets/mlin_0313.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![强化学习策略更新](assets/mlin_0313.png)'
- en: Figure 3-13\. Reinforcement learning policy update.
  id: totrans-302
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-13\. 强化学习策略更新。
- en: Tip
  id: totrans-303
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: In interviews, I’ve experienced more follow-up questions and drill-downs on
    why the reward is set up in such a way—for example, “Why did you choose to include
    a click-through as a positive reward but not the video watch time?”
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在面试中，我经历了更多关于为什么奖励设定如此的后续问题和深入追问，例如，“为什么你选择将点击率作为正面奖励，而不是视频观看时间？”
- en: Summarizing Q-Learning
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结 Q 学习
- en: I’ll continue to build on the concepts of state, action, reward, and policy
    as foundations for the following sections. The RL agent generally wants to maximize
    the highest rewards from choosing an action at a given state. However, without
    further nuances in the rewards, this can lead to short-term thinking, as you’ve
    seen when the agent only *exploits* and doesn’t *explore*. One way of addressing
    short-term thinking in RL is through adding more sophistication in the design
    of the reward beyond the immediate action. Thus, the long-term *expected* reward,
    which includes not only the reward from the immediate action but also possible
    rewards that are available to the agent in the future, is important.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我将继续在状态、动作、奖励和策略的概念上进行建设，作为接下来章节的基础。强化学习代理通常希望在给定状态下选择动作后获得最高的奖励。然而，在奖励中缺乏进一步的细化时，这可能导致短视行为，正如您在代理仅*利用*而不*探索*时看到的那样。解决强化学习中的短视行为的一种方法是通过在奖励设计中增加更多复杂性来处理。因此，长期的*预期*奖励非常重要，它不仅包括即时动作的奖励，还包括将来可能对代理可用的奖励。
- en: 'The expected total reward is calculated as part of the RL process as a weighted
    sum of the expected values of the future rewards that are available given the
    current step. I’ll illustrate this with the example of a robot that needs to find
    the way out of a maze, as illustrated in [Figure 3-14](#illustration_of_reinforcement_learningco):'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 预期的总奖励是作为强化学习过程的一部分计算的，它是当前步骤下可用的未来奖励的期望值的加权和。我将以需要寻找迷宫出口的机器人为例进行说明，如[图 3-14](#illustration_of_reinforcement_learningco)所示：
- en: In this maze, bombs are bad while gold/money is good.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个迷宫中，炸弹是坏的，而金钱/财富是好的。
- en: The exit is at the upper-right side of the maze, and there is a dead end in
    the middle of the maze, which the robot has learned about during previous exploration.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 出口位于迷宫的右上角，迷宫中间有一条死胡同，机器人在先前的探索中已经了解到。
- en: If the robot chooses to go toward the middle, then it has a higher probability
    of going to the dead end and a lesser probability of going to the exit, which
    is captured in the sum of expected values of future reward.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果机器人选择朝中间走，那么它去到死胡同的概率较高，去到出口的概率较低，这在未来奖励的期望值之和中得到了体现。
- en: Hence, all things held constant, the total expected reward (aka the expected
    cumulative reward) from heading to the upper-right will be higher than the total
    expected reward from heading toward the middle. Of course, the robot needs to
    have explored those places already; before it has, it will still calculate the
    expected reward, but it might not be as accurate.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，在其他条件保持不变的情况下，朝右上方向的总预期奖励（又称为预期累积奖励）将高于朝中间方向的总预期奖励。当然，机器人需要已经探索过那些地方；在探索之前，它仍会计算预期奖励，但可能不太准确。
- en: '![Illustration of reinforcement learning: robot navigating a maze](assets/mlin_0314.png)'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![强化学习示例：机器人在迷宫中导航](assets/mlin_0314.png)'
- en: 'Figure 3-14\. Illustration of reinforcement learning: robot navigating a maze.'
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-14\. 强化学习示例：机器人在迷宫中导航。
- en: Now let’s connect the concept of expected cumulative reward to the *Q-value*,
    which is the expected cumulative reward for taking an action in a particular state.
    The *Q-function* is a related concept; it takes the inputs of the state-action
    pairs and outputs the Q-values. The policy determines the action that the RL agent
    should take in a given state. To tie everything together, the optimal policy in
    Q-learning comes from selecting the action with the highest Q-value in each state.
    After each step, the policy is evaluated and the Q-values are updated using an
    optimization method called the Bellman equation.^([46](ch03.html#ch03fn47)) The
    process is repeated until the policy converges and selects the same action at
    a given state.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将预期的累积奖励概念与*Q值*联系起来，这是在特定状态下采取行动的预期累积奖励。*Q函数*是一个相关概念；它接受状态-动作对的输入并输出Q值。策略确定RL智能体应在给定状态下采取的行动。为了将所有内容联系起来，Q-learning中的最优策略来自于在每个状态中选择具有最高Q值的动作。在每一步之后，评估策略并使用称为Bellman方程的优化方法更新Q值。^([46](ch03.html#ch03fn47))
    重复此过程，直到策略收敛并在给定状态下选择相同的行动。
- en: It is also possible to use Q-learning without policy iteration, instead using
    the simpler epsilon-greedy policy, which was mentioned in the previous section.
    This simpler format is often more practical in situations where the policy is
    less likely to converge or is expensive to learn or when the state and/or action
    space is very large.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以使用Q-learning而不是策略迭代，而是使用更简单的ε-贪心策略，这在前面的部分中提到过。在策略不太可能收敛或学习代价高昂，或者状态和/或动作空间非常大的情况下，这种更简单的格式通常更为实际。
- en: Summarizing Model-Based Versus Model-Free Reinforcement Learning
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结基于模型与无模型的强化学习
- en: Because Q-learning doesn’t use a model to try to model the world—or in other
    words, the *relationship* between the states and the actions—it is a *model-free
    RL* technique. Model-free RL like Q-learning requires the representation of the
    state and the action, but then it only needs to observe the rewards to continue
    improving its Q-values and policy (if using policy iteration).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 因为Q-learning不使用模型来尝试模拟世界——或者换句话说，*状态*和*动作*之间的关系，因此它是一种*无模型强化学习*技术。像Q-learning这样的无模型强化学习需要表示状态和动作，但之后只需观察奖励即可持续改进其Q值和策略（如果使用策略迭代）。
- en: Tip
  id: totrans-318
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Common model-free RL algorithms include Q-learning, SARSA (state-action-reward-state-action),^([47](ch03.html#ch03fn48))
    and [proximal policy optimization (PPO)](https://oreil.ly/M-POc).^([48](ch03.html#ch03fn49))
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的无模型强化学习算法包括 Q-learning、SARSA（状态-动作-奖励-状态-动作）^([47](ch03.html#ch03fn48)) 和
    [近端策略优化（PPO）](https://oreil.ly/M-POc)^([48](ch03.html#ch03fn49))。
- en: In model-based RL, the agent learns a model of the environment, which includes
    the way the various possible states are related to one another, called *state
    transitions*. The agent uses this model to make decisions about the best action(s)
    to take in a given state. Therefore, model-based RL requires explicit knowledge
    of the environment. Examples include dynamic programming and [Monte Carlo tree
    search (MCTS)](https://oreil.ly/ZuF22).^([49](ch03.html#ch03fn50))
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于模型的强化学习中，智能体学习环境的模型，包括各种可能状态之间的关系，称为*状态转移*。智能体利用此模型在特定状态下做出最佳行动决策。因此，基于模型的强化学习需要对环境有明确的了解。例如动态规划和
    [蒙特卡洛树搜索（MCTS）](https://oreil.ly/ZuF22)^([49](ch03.html#ch03fn50))。
- en: Summarizing Value-Based Versus Policy-Based Reinforcement Learning
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结基于价值与基于策略的强化学习
- en: '*Value-based* RL is built on estimating the expected cumulative reward (aka
    the “value”) of being in a certain state and choosing to take a certain action,
    such as in Q-learning,^([50](ch03.html#ch03fn51)) SARSA,^([51](ch03.html#ch03fn52))
    and deep Q-networks (DQNs). The focus of these algorithms is on being able to
    predict the expected cumulative reward.'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '*基于价值*的强化学习建立在估计处于某个状态并选择采取某个动作时的预期累积奖励（即“价值”）的基础上，例如在Q-learning^([50](ch03.html#ch03fn51))、SARSA^([51](ch03.html#ch03fn52))和深度Q网络（DQNs）中。这些算法的重点在于能够预测预期的累积奖励。'
- en: On the other hand, *policy-based* RL learns the policy, the method or pattern
    that the agent uses to choose actions in a given state. Policy-based RL has a
    parametrized policy function that can be optimized with gradient ascent methods
    as it learns the mapping between states and actions. Gradient ascent is used because
    policy-based RL aims to maximize the expected cumulative reward, as opposed to
    gradient descent, which is used to minimize errors. Common policy-based algorithms
    include policy gradient algorithms such as REINFORCE and actor-critic methods
    (the “actor” learns a policy, and the “critic” learns the value). You can see
    an illustration of the various types of RL in [Figure 3-15](#overview_of_reinforcement_learning_metho).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*基于策略* 的强化学习学习策略，即代理程序在给定状态下选择行动的方法或模式。基于策略的强化学习具有可以使用梯度上升方法优化的参数化策略函数，因为它学习状态和行动之间的映射。使用梯度上升是因为基于策略的强化学习旨在最大化预期累积奖励，而梯度下降用于最小化错误。常见的基于策略的算法包括基于策略梯度的算法，如REINFORCE和演员-评论者方法（“演员”学习策略，“评论者”学习值）。您可以在[图 3-15](#overview_of_reinforcement_learning_metho)中看到各种类型的强化学习的示意图。
- en: '![Overview of reinforcement learning methods; source: “Introduction to Reinforcement
    Learning” by J. Zico Kolter](assets/mlin_0315.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![强化学习方法概述；来源：“Introduction to Reinforcement Learning” by J. Zico Kolter](assets/mlin_0315.png)'
- en: 'Figure 3-15\. Overview of reinforcement learning methods; source: [“Introduction
    to Reinforcement Learning” by J. Zico Kolter](https://oreil.ly/d0sua).'
  id: totrans-325
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-15\. 强化学习方法概述；来源：[“Introduction to Reinforcement Learning” by J. Zico Kolter](https://oreil.ly/d0sua)。
- en: Summarizing On-Policy Versus Off-Policy Reinforcement Learning
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结基于策略与离策略强化学习
- en: '*On-policy* RL updates its policy based on the data points collected while
    following the current iteration of the policy. Note that not all policy-based
    RL is necessarily on-policy.^([52](ch03.html#ch03fn53)) Let’s say that an RL algorithm
    takes an action (a1) with the current policy (p1), and with the observations from
    that action, it updates that policy with gradient ascent, notated as (p2): the
    latest learned policy. If the agent continues the next action (a2) with the new
    policy (p2), then it is considered on-policy. Policy iteration methods like SARSA^([53](ch03.html#ch03fn54))
    are on-policy RL. In other words, if the agent’s [behavior policy is its target
    policy](https://oreil.ly/Fgmck)^([54](ch03.html#ch03fn55)) (the policy being updated),
    then that is on-policy RL.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '*基于策略* 的强化学习根据在遵循当前策略迭代时收集的数据点更新其策略。请注意，并非所有基于策略的强化学习必须是基于策略的。^([52](ch03.html#ch03fn53))
    假设一个RL算法使用当前策略（p1）执行一个动作（a1），并使用该动作的观察结果使用梯度上升更新该策略，记为（p2）：最新学习的策略。如果代理程序使用新策略（p2）继续下一个动作（a2），那么它被认为是基于策略的。策略迭代方法如SARSA^([53](ch03.html#ch03fn54))是基于策略的RL。换句话说，如果代理的[行为策略是其目标策略](https://oreil.ly/Fgmck)^([54](ch03.html#ch03fn55))（正在更新的策略），那么这就是基于策略的RL。'
- en: An *off-policy* RL algorithm updates its policies based on data points or experiences
    collected from a different policy or a mixture of policies. This includes Q-learning
    and DQNs. Coincidentally, these are value-based RL algorithms. To prevent confusion,
    think of on-policy versus off-policy as pertaining to whether the agent is using
    the newest policy that is being updated while policy-based versus value-based
    refers to the types of algorithms used to derive the optimal behavior.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '*离策略* 的RL算法根据从不同策略或混合策略收集的数据点或经验更新其策略。这包括Q-learning和DQNs。巧合的是，这些都是基于值的RL算法。为了避免混淆，将基于策略与离策略视为代理程序是否使用正在更新的最新策略，而基于策略与基于值则指的是用于推导最佳行为的算法类型。'
- en: There are many additional algorithms to explore, such as temporal difference
    (TD), A3C (Asynchronous Advantage Actor-Critic), and PPO; if you’re interested
    in learning more, I encourage you to take a look at the reinforcement learning
    textbook by Richard Sutton and Andrew Barto, [available for free online](https://oreil.ly/MCgBK)
    and also included in the resources at the beginning of this section.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他算法可以探索，如时间差分（TD）、A3C（异步优势演员-评论者）和PPO；如果您有兴趣了解更多，请查阅Richard Sutton和Andrew
    Barto的强化学习教科书，[在线免费提供](https://oreil.ly/MCgBK)，也包括本节开头的资源。
- en: Sample Interview Questions on Reinforcement Learning
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化学习面试问题示例
- en: Now that you’re familiar with introductory RL concepts, let’s look at some example
    interview questions.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经熟悉了强化学习的基础概念，让我们看一些例子面试问题。
- en: 'Interview question 3-17: Explain the DQN (deep Q-network) algorithm in reinforcement
    learning.'
  id: totrans-332
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-17：解释强化学习中的 DQN（深度 Q 网络）算法。
- en: Example answer
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: 'DQN is an extension of Q-learning; DQN uses neural networks to approximate
    the Q-values, which represent the expected future reward from taking an action
    in a given state (the same definition as Q-learning). In DQN, you have two networks:
    a target network and the Q-network. The target network is responsible for predicting
    the best Q-value out of all actions that can be taken from a given state (the
    target Q-value). The Q-network takes the current state and action and predicts
    the Q-value for a particular action (the predicted Q-value). To improve the Q-network,
    the difference between the predicted Q-value, the target Q-value, and the observed
    reward is used as a loss function for the Q-network.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: DQN 是 Q-learning 的一个扩展；DQN 使用神经网络来逼近 Q 值，这些值表示在给定状态下采取行动后预期的未来奖励（与 Q-learning
    的定义相同）。在 DQN 中，您有两个网络：目标网络和 Q 网络。目标网络负责预测从给定状态下所有可能采取的行动中的最佳 Q 值（目标 Q 值）。Q 网络采用当前状态和动作，并预测特定动作的
    Q 值（预测的 Q 值）。为了改进 Q 网络，使用预测的 Q 值、目标 Q 值和观察到的奖励之间的差异作为 Q 网络的损失函数。
- en: The weights of the neural network are updated based on the difference between
    the predicted Q-learning and the actual Q-value obtained through experience. The
    reason for using the target network is to ensure that the training results are
    more stable since with reinforcement learning and updating the Q-network with
    each step, the variance of each action can be quite large. After sufficient steps,
    the target network is updated with the new weights of the Q-network, and training
    continues.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的权重是根据预测的 Q-learning 与通过经验获得的实际 Q 值之间的差异进行更新的。使用目标网络的原因是确保训练结果更稳定，因为在强化学习中，每一步都会更新
    Q 网络，每个动作的方差可能非常大。经过足够的步骤后，目标网络使用 Q 网络的新权重进行更新，然后继续训练。
- en: 'Interview question 3-18: As a follow-up question, could you explain the main
    modifications that DQN added on top of regular Q-learning?'
  id: totrans-336
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-18：作为跟进问题，您能解释一下 DQN 在常规 Q-learning 基础上添加的主要修改吗？
- en: Example answer
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: One of the main new advances that DQN uses is experience replay. Experience
    replay is a component before the Q-network and target networks that uses a simple
    epsilon-greedy method to take an action in the current state in the real environment
    and get a reward. It saves these actions, states, and rewards as experiences for
    the networks to use as training data. The reason for using experience replay is
    the sequential nature of reinforcement learning; the training dataset for the
    networks should have the sequence of rewards and new states that result from each
    action in the previous state.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: DQN 主要的新进展之一是使用经验回放。经验回放是在 Q 网络和目标网络之前的一个组件，使用简单的 epsilon-greedy 方法在当前状态下在真实环境中采取行动并获得奖励。它将这些行动、状态和奖励保存为网络用作训练数据的经验。使用经验回放的原因是强化学习的顺序性质；网络的训练数据集应包含每个动作在前一个状态下导致的奖励和新状态的顺序。
- en: 'Interview question 3-19: Explain exploration and exploitation in reinforcement
    learning with an example. What are the trade-offs of these two concepts? What
    are some ways you would balance exploration and exploitation?'
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-19：通过一个例子解释强化学习中的探索与利用。这两个概念的权衡是什么？您会如何平衡探索和利用？
- en: Example answer
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 示例回答
- en: 'I’ll use the example of an RL agent that is part of a simple self-driving car.
    During its exploration, it first finds that turning right at a red light isn’t
    penalized (going by rules in North America). The agent may continue to exploit
    this knowledge instead of trying something new and learning to stop at the red
    light, causing undesired behavior: never stopping at a red light. Therefore, it
    is important to encourage exploration as well so that the agent tries out new
    behaviors. As the agent has explored more iterations of the environment, then
    it is safer to continue to increase the exploitation parameter because at that
    point it may be more important for the agent to perform well and become an accurate
    self-driving car with the experience it has gathered so far. By allowing more
    exploration early on and then reducing exploration and increasing exploitation
    later, via techniques such as the epsilon-greedy policy, I can balance exploration
    and exploitation.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我将以一个简单的自动驾驶汽车的RL代理为例进行说明。在探索过程中，它首先发现在红灯处右转不会受到惩罚（按照北美的规则）。代理程序可能会继续利用这一知识，而不是尝试新的行为并学会在红灯前停下来，从而导致不良行为：永远不在红灯前停车。因此，鼓励探索同样重要，这样代理程序就可以尝试新的行为。随着代理程序对环境进行了更多次的探索，增加利用参数变得更安全，因为此时对代理程序表现良好并积累的经验来说更为重要。通过早期允许更多的探索，然后通过epsilon-greedy策略等技术减少探索并增加利用，我可以平衡探索和利用。
- en: In summary, to balance exploration and exploitation, I’d use an epsilon-greedy
    policy^([55](ch03.html#ch03fn56)) so that the RL agent can explore more of the
    environment. As the agent interacts and learns more from the environment, the
    epsilon value is reduced, which makes the agent start to increase exploitation.
    Eventually, once the agent has explored sufficiently, it can exploit the good
    decisions it’s seen in the past and reduce exploration.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，为了平衡探索和利用，我将使用epsilon-greedy策略^([55](ch03.html#ch03fn56))，以便RL代理可以更多地探索环境。随着代理程序与环境的互动和学习，epsilon值会减少，使得代理程序开始增加利用。最终，一旦代理程序进行了足够的探索，它就可以利用过去见过的良好决策并减少探索。
- en: 'Interview question 3-20: In the following scenario, you’ve found that the reinforcement
    learning algorithm keeps recommending an item that is incorrectly labeled as 10%
    of its sale price. What might have caused this, and what would you investigate,
    assuming that the data is all correct?'
  id: totrans-343
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题3-20：在以下情况下，您发现强化学习算法一直推荐将作为其销售价格的10%错误标记的项目。这可能是什么原因，并假设数据都是正确的，您将调查什么？
- en: Example answer
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 例子回答
- en: In the case that there is a reward function in our RL agent, I would investigate
    the reward/reward function and see if it’s rewarding perverse behavior of the
    RL agent. It could be that the agent is exploiting ways to increase users’ click-through
    rate artificially, for example, by recommending items that are highly discounted.
    The artificial increase in click-through rate in this case leads to a positive
    reward for the RL agent. If the reward takes into account the cost of the discounts
    in the reward function, then the agent will be less likely to only optimize click-through
    rate at the cost of losing money on the product.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的RL代理中有奖励函数的情况下，我将调查奖励/奖励函数，并查看是否在奖励RL代理的异常行为。例如，代理程序可能会利用方式来人为增加用户的点击率，例如推荐高度折扣的商品。在这种情况下，点击率的人为增加会给RL代理带来正面奖励。如果奖励函数考虑到了折扣在奖励中的成本，那么代理程序就不太可能只优化点击率而损失产品的利润。
- en: 'Interview question 3-21: Explain model-based or model-free reinforcement learning.
    What are some examples of each, and when would you choose one over the other?'
  id: totrans-346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题3-21：解释基于模型或无模型强化学习。各自的例子是什么？在何时选择其中一种？
- en: Example answer
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 例子回答
- en: 'Model-free RL is often preferred when a model of the environment is difficult
    to estimate or where the environment is constantly changing. This is because model-based
    algorithms try to build an accurate model of the full environment they are operating
    in. The “model” includes the transition probabilities from one state to another.
    Note: the use of the word “model” here does not mean other components of RL are
    not ML models. Specifically, “model-based” RL refers to the model of the environment,
    which is not exclusive to having other ML models in the workflow.'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 当环境模型难以估计或环境不断变化时，通常更倾向于无模型RL。这是因为基于模型的算法试图构建准确的完整环境模型。这里“模型”包括从一个状态到另一个状态的转移概率。注意：这里使用“模型”一词并不意味着RL的其他组件不是ML模型。具体来说，“基于模型的”RL指的是环境的模型，而不是在工作流中具有其他ML模型的独占性。
- en: Model-based RL is more feasible when you have a reasonable ground-truth representation
    of the entire environment, such as in a game environment like Atari or chess.
    These environments can be simulated many times, with (usually) deterministic results,
    so that the model that describes the environment and its state transition probabilities
    can be learned or built. In most real-world cases, it is less feasible to fully
    describe the environment, although with deep learning and a very, very large number
    of features that describe the environment, such as advanced sensors on a self-driving
    car, it might be possible. Generally in cases where the environment is not known,
    though, model-free RL can be used.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 当您有一个合理的地面真实表示整个环境时，比如在Atari或象棋等游戏环境中，模型基RL更为可行。这些环境可以模拟多次，通常具有确定性结果，因此可以学习或构建描述环境及其状态转移概率的模型。在大多数实际情况下，完全描述环境是不可行的，尽管通过深度学习和描述环境的非常非常多的特征，比如自动驾驶汽车上的先进传感器，这可能是可能的。总的来说，在环境未知的情况下，无模型RL可以使用。
- en: Computer Vision Algorithms
  id: totrans-350
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉算法
- en: '*Computer vision* is a common ML application that includes image classification,
    image recognition, and so on. Examples include applying computer vision to medical
    images, such as X-rays, to classify whether a patient has a certain disease, or
    checking waveform images to classify certain sounds. Self-driving cars represent
    a complex use of various computer vision techniques.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '*计算机视觉*是一个常见的ML应用程序，包括图像分类、图像识别等。例如，将计算机视觉应用于医学图像，如X光片，以分类患者是否患有某种疾病，或检查波形图像以分类特定声音。自动驾驶汽车代表了各种计算机视觉技术的复杂应用。'
- en: Some computer vision applications can be used across multiple industries. For
    example, optical character recognition (OCR) can be used to read checks for a
    bank’s online check-deposit system, detect logos in social media posts, or identify
    products in advertising images.^([56](ch03.html#ch03fn57)) Regardless of the industry,
    ML practitioners leveraging computer vision ML benefit from domain knowledge,
    especially for high-impact applications in health care or autonomous vehicles,
    for example.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 一些计算机视觉应用可以跨多个行业使用。例如，光学字符识别（OCR）可用于银行的在线支票存款系统中读取支票，检测社交媒体帖子中的标志，或者识别广告图像中的产品。^([56](ch03.html#ch03fn57))
    无论行业如何，利用计算机视觉ML的ML从业者受益于领域知识，特别是在健康护理或自动驾驶等高影响应用中。
- en: Tip
  id: totrans-353
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Interview questions about computer vision can rely heavily on domain knowledge,
    so beyond this book and resources on technical know-how, I encourage you to read
    about computer vision applications specific to your target field.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉面试问题可能严重依赖领域知识，因此除了本书和技术知识的资源外，我鼓励您阅读与您目标领域特定的计算机视觉应用相关的内容。
- en: This section covers the basics of computer vision techniques for those who are
    unsure whether they have the background knowledge in this area. Feel free to skip
    the subsections if you already have expertise in any of these areas. Regardless
    of your expertise, I’ve highlighted specific advice for ML interviews in the tip
    boxes to help you apply your knowledge of each ML area and excel in your interviews.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了计算机视觉技术的基础，适合那些对这个领域的背景知识不确定的人。如果您已经在任何这些领域有专业知识，可以跳过子节。无论您的专业知识如何，我在提示框中强调了关于ML面试的具体建议，帮助您应用每个ML领域的知识并在面试中表现出色。
- en: Summarizing Common Image Datasets
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 汇总常见图像数据集
- en: Because of their visual and relatively easy-to-understand nature, image datasets
    are commonly used as beginner tutorials for deep learning. For example, I remember
    using the dogs and cats dataset in a Coursera course on CNNs, along with hundreds
    of thousands of other learners. Using ML on images has captured the imagination
    of ML enthusiasts and is popular for self-learning and portfolio projects. In
    research, many of the same datasets have propelled major advances in ML. You might
    recall in [Chapter 1](ch01.html#machine_learning_roles_and_the_interview) I mentioned
    that the ImageNet dataset and challenge led to a development and explosion of
    accuracy in deep learning models that hadn’t been seen before.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们的视觉性和相对易于理解的特性，图像数据集通常被用作深度学习的初学者教程。例如，我记得在 Coursera 上一个关于 CNN 的课程中使用了狗和猫的数据集，以及其他数十万名学习者。在图像上使用机器学习引起了机器学习爱好者的想象，并且在自学和项目组合方面非常流行。在研究中，许多相同的数据集推动了机器学习的重大进展。您可能还记得在
    [第一章](ch01.html#machine_learning_roles_and_the_interview) 中我提到 ImageNet 数据集和挑战导致了深度学习模型准确率的发展和爆炸式增长，这是前所未有的。
- en: 'Here are some common public datasets that are used in computer vision:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些在计算机视觉中常用的公共数据集：
- en: '[ImageNet](https://oreil.ly/yQHl1/)'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ImageNet](https://oreil.ly/yQHl1/)'
- en: '[CIFAR-100](https://oreil.ly/regHX)'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CIFAR-100](https://oreil.ly/regHX)'
- en: '[MNIST](https://oreil.ly/4Yf5C) and related datasets, such as [Fashion-MNIST](https://oreil.ly/OeMdK)'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MNIST](https://oreil.ly/4Yf5C) 和相关数据集，如 [Fashion-MNIST](https://oreil.ly/OeMdK)'
- en: '[COCO](https://oreil.ly/FsK3V) (Common Objects in Context)'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[COCO](https://oreil.ly/FsK3V) (上下文中的常见对象)'
- en: '[LVIS](https://oreil.ly/2h6JQ) (annotated COCO)'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LVIS](https://oreil.ly/2h6JQ)（注释的 COCO 数据集）'
- en: 'I encourage you to give them a try. If it’s your first time, you can try the
    following Colab notebooks:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励您试试。如果这是您第一次尝试，您可以尝试以下 Colab 笔记本：
- en: '[Image Classification—Colaboratory tutorial (TensorFlow)](https://oreil.ly/XnUJz)'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像分类——Colaboratory 教程（TensorFlow）](https://oreil.ly/XnUJz)'
- en: '[Transfer Learning for Computer Vision tutorial (PyTorch)](https://oreil.ly/AgB50)'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机视觉的迁移学习教程（PyTorch）](https://oreil.ly/AgB50)'
- en: 'Once you’ve familiarized yourself with the basics, I encourage you to come
    up with a project yourself. You can find more image datasets here or even collect
    your own:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您熟悉了基础知识，我鼓励您自己动手做一个项目。您可以在这里找到更多的图像数据集，甚至可以收集您自己的数据：
- en: '[Machine Learning Datasets—Image Classification](https://oreil.ly/b_uhg) on
    *[paperswithcode.com](https://oreil.ly/o6CZ_)*'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习数据集——图像分类](https://oreil.ly/b_uhg) 在 *[paperswithcode.com](https://oreil.ly/o6CZ_)*
    上'
- en: '[Know Your Data Catalog](https://oreil.ly/Z2YS4) by Google'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[了解您的数据目录](https://oreil.ly/Z2YS4) by Google'
- en: '[Kaggle](https://oreil.ly/Fy-9E) datasets'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kaggle](https://oreil.ly/Fy-9E) 数据集'
- en: Tip
  id: totrans-371
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Many online tutorials start with a simple image dataset such as classifying
    cats and dogs, the [Iris dataset](https://oreil.ly/4Bhjc), MNIST, and so on. As
    such, they should be used for learning purposes, not for portfolio purposes. Candidates
    will find it hard to stand out with projects that only use these most common datasets^([57](ch03.html#ch03fn58))
    since we interviewers have seen thousands of applicants (not an exaggeration)
    with these projects. Try to find more unique datasets if you’re building a portfolio
    project.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 许多在线教程都从简单的图像数据集开始，例如分类猫和狗，鸢尾花数据集，MNIST 等等。因此，它们应该用于学习目的，而不是用于组合作品。候选人只使用这些最常见的数据集（这不是夸张），我们面试官已经看过成千上万的申请人，这些项目很难突出。如果您正在构建一个组合项目，请尝试找到更独特的数据集。
- en: Summarizing Convolutional Neural Networks (CNNs)
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结卷积神经网络（CNN）
- en: As discussed previously, examples of computer vision tasks include object detection,
    facial recognition, and medical classification. The data commonly used in computer
    vision algorithms are images, and often they are implemented with the CNN architecture,
    as illustrated in [Figure 3-16](#a_cnn_takes_in_a_cat_image_and_represent). CNNs
    are particularly effective for tasks like image recognition because they can intake
    the information encoding from images, where images are represented as matrices
    (input feature maps). The inputs are then “convoluted” via various convolutional
    layers in the network—a process that extracts information from the images’ matrix
    representation and creates new features that capture more nuanced information
    about the image. Convolution also allows information in the image to be flattened
    and compressed, which is effective for computation.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，计算机视觉任务的示例包括目标检测、人脸识别和医学分类。计算机视觉算法常用的数据是图像，并且通常使用CNN架构实现，如图3-16所示。CNN在图像识别等任务中特别有效，因为它们可以接收图像编码的信息，图像以矩阵形式表示（输入特征图）。然后，输入通过网络中的各种卷积层“卷积”——这个过程从图像的矩阵表示中提取信息，并创建捕捉图像更细微信息的新特征。卷积还允许将图像中的信息压平和压缩，这对计算是有效的。
- en: '![A CNN takes in a cat image and represents the image in matrix form, then
    two convolutional modules extract useful features, which are fed into the last
    two fully connected layers that predict if the image is a cat or not; source:
    “ML Practicum: Image Classification,” Google)](assets/mlin_0316.png)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
  zh: '![CNN接收一张猫的图像，并以矩阵形式表示图像，然后两个卷积模块提取有用的特征，这些特征被馈送到最后的两个全连接层，预测图像是否是猫；来源：“ML实习：图像分类”，Google](assets/mlin_0316.png)'
- en: 'Figure 3-16\. A CNN takes in a dog image and represents the image in matrix
    form, then two convolutional modules extract useful features, which are fed into
    the last two fully connected layers that predict if the image is a dog or not;
    based on an image from [“ML Practicum: Image Classification”](https://oreil.ly/I3yeL),
    Google.'
  id: totrans-376
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-16\. CNN接收一张狗的图像，并以矩阵形式表示图像，然后两个卷积模块提取有用的特征，这些特征被馈送到最后的两个全连接层，预测图像是否是狗；基于来自[“ML实习：图像分类”](https://oreil.ly/I3yeL)，Google的一张图像。
- en: Summarizing Transfer Learning
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结转移学习
- en: For computer vision tasks, you can find many pretrained models online. These
    pretrained models have already been tweaked and tuned on general tasks, such as
    image-classification tasks. It is time-consuming and resource heavy to train these
    models from scratch, so in practice, transfer learning is a common technique.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 对于计算机视觉任务，你可以在网上找到许多预训练模型。这些预训练模型已经在通用任务（如图像分类任务）上进行了调整和优化。从头开始训练这些模型耗时且资源密集，因此在实践中，转移学习是一种常见的技术。
- en: Transfer learning leverages a pretrained model and modifies the last layers’
    task to focus on the smaller task at hand. For example, the pretrained model might
    have been trained to classify one thousand items. At work, you have to classify
    only desktop computers and laptops for an inventory-tracking task. You can download
    the pretrained model, use its architecture and weights apart from the final layer,
    and train only the final layer(s) so that it can specialize in those two objects.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 转移学习利用预训练模型，并修改最后的层次任务以专注于手头的较小任务。例如，预训练模型可能已经训练好了对一千种物品进行分类。在工作中，你只需对台式电脑和笔记本电脑进行库存跟踪任务的分类。你可以下载预训练模型，使用其架构和权重，除了最后的层次，然后只训练最后的层次，使其专门用于这两种物体。
- en: The result is a model that already has a general understanding of classifying
    images as well as the specialized tasks you’ve fine-tuned the model to do. This
    process is called *transfer learning*.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个模型，它已经对图像分类有了一般的理解，以及你微调模型以执行的专门任务。这个过程被称为*转移学习*。
- en: 'Here are some tutorials:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些教程：
- en: '[Transfer Learning and Fine-Tuning (TensorFlow)](https://oreil.ly/qVisB)'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[转移学习与微调（TensorFlow）](https://oreil.ly/qVisB)'
- en: '[Transfer Learning for Computer Vision (PyTorch)](https://oreil.ly/zO3Af)'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机视觉的转移学习（PyTorch）](https://oreil.ly/zO3Af)'
- en: Tip
  id: totrans-384
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: In interviews, it is helpful to be aware of transfer learning. In many situations,
    it’s useful to identify pretrained models to use and build on top of for the specific
    task at hand. In industry, it’s rare for the first option to be training a whole
    new neural network, due to the costs. If you only mention training a model from
    scratch for computer vision, that might show that you haven’t thought about or
    been exposed to practical situations enough.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 在面试中，了解迁移学习是有帮助的。在许多情况下，识别预训练模型并在其基础上进行构建对于特定任务非常有用。在工业界，由于成本问题，很少会选择从头开始训练一个全新的神经网络。如果您只提到从头开始训练计算机视觉模型，这可能显示您还没有考虑或接触到足够的实际情况。
- en: Summarizing Generative Adversarial Networks
  id: totrans-386
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结生成对抗网络
- en: “Deepfakes” (fake images generated by deep learning) have been in the news for
    creating fake images of politicians and celebrities. Deepfakes are an example
    of how results of generative AI have already started to get very realistic. They
    are commonly generated by networks referred to as *generative adversarial networks*
    (GANs).
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: “Deepfakes”（通过深度学习生成的伪造图像）因创建政治家和名人的伪造图像而频登新闻头条。Deepfakes 是生成式 AI 结果已经变得非常逼真的一个例子。它们通常由称为*生成对抗网络*（GANs）的网络生成。
- en: 'The architecture of GANs^([58](ch03.html#ch03fn59)) focuses on two models:
    a generator and a discriminator. The *generator* learns and improves to generate
    good outputs. The *discriminator* learns and improves in order to evaluate whether
    the outputs that the generator created are real or fake.'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 的架构^([58](ch03.html#ch03fn59))侧重于两个模型：生成器和鉴别器。*生成器*学习和改进以生成良好的输出。*鉴别器*学习和改进以评估生成器创建的输出是真实还是伪造。
- en: 'For example, the process training to generate images of Labrador retrievers
    (or Labs, for short) is as follows (see [Figure 3-17](#illustration_of_gan_training)):'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，训练生成拉布拉多犬图像的过程如下（参见[图3-17](#illustration_of_gan_training)）：
- en: Training begins. The generator is bad at generating objects that look like Labs,
    while the discriminator is bad at distinguishing the images that the generator
    created from real pictures of Labs.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练开始。生成器在生成类似拉布拉多犬的对象方面表现不佳，而鉴别器在区分生成器创建的图像与真实拉布拉多犬图片方面表现不佳。
- en: As the generator is trained more, it learns to create images that look slightly
    more like Labs. As the discriminator is trained more, it’s better able to distinguish
    the generator’s fake Labs from the real ones. The goal of the generator is to
    create Labs that look real enough for the discriminator to mistake them for real
    Lab pictures from the real world.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着生成器的训练加深，它学会了创建看起来更像拉布拉多犬的图像。随着鉴别器的训练加深，它更能够区分生成器生成的伪造拉布拉多犬图像与真实图像的不同。生成器的目标是创建足够逼真的拉布拉多犬图像，以至于鉴别器会误以为它们来自真实世界中的真实拉布拉多犬图片。
- en: Finally, the generator gets so good at generating Lab images that the discriminator
    can no longer tell them apart.
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，生成器在生成拉布拉多犬（或简称拉布拉多犬）的图像方面变得非常擅长，鉴别器无法再将它们与真实图像区分开来。
- en: '![Illustration of GAN training](assets/mlin_0317.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![GAN 训练示例](assets/mlin_0317.png)'
- en: Figure 3-17\. Illustration of GAN training. Note that the GAN can generate passable
    images not in the training dataset that are good enough to fool the discriminator.
    (In this illustration we just have a flipped image for simplicity, but the real
    network can generate images even more different from the real training data.)
  id: totrans-394
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-17\. GAN 训练示例。请注意，GAN 可以生成足以欺骗鉴别器的训练数据集中没有的图像（在本示例中，我们只是简单地翻转了图像，但是真实的网络可以生成更与真实训练数据不同的图像）。
- en: Note
  id: totrans-395
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Diffusion models are now common for image-generation tasks. I won’t go into
    details in this book, but you can read the original paper^([59](ch03.html#ch03fn60))
    if you’re interested.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 扩散模型现在常用于图像生成任务。我不会在本书中详细介绍，但如果您感兴趣，可以阅读原始论文^([59](ch03.html#ch03fn60))。
- en: Summarizing Additional Computer Vision Use Cases
  id: totrans-397
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结额外的计算机视觉用例
- en: In addition to classification and image generation, there are many more use
    cases for computer vision, such as super resolution, semantic segmentation, and
    object detection. I will go through a few common industry use cases here, but
    as mentioned before, I highly recommend you read about examples relevant to the
    company or industry you’re interviewing for, to further enhance your answers during
    interviews.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 除了分类和图像生成，计算机视觉还有许多其他用例，例如超分辨率、语义分割和物体检测。我将在这里介绍一些常见的行业用例，但正如之前提到的，我强烈建议您阅读与您正在面试的公司或行业相关的示例，以进一步提升面试回答。
- en: Super resolution summary
  id: totrans-399
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 超分辨率摘要
- en: '*Super resolution* is the task of taking a low-resolution image and creating
    a high-resolution version of it. This task is also called *upscaling*. Common
    use cases are to upscale historical images, photos, films, and so on. In the health
    industry, this task can be used to increase the resolution of older medical equipment
    so that better diagnoses can be made if it’s difficult to upgrade the equipment.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '*超分辨率* 是将低分辨率图像转换成高分辨率版本的任务。这项任务也被称为*提升*。常见的用例包括提升历史图像、照片、电影等。在健康行业中，这项任务可以用于提高老旧医疗设备的分辨率，以便在难以升级设备的情况下做出更好的诊断。'
- en: 'GANs and diffusion models are commonly used for this task. For more examples,
    here are some resources:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 和扩散模型通常用于这项任务。更多示例，请参考以下资源：
- en: '[“High Fidelity Image Generation Using Diffusion Models”](https://oreil.ly/5b_5Y),
    by Jonathan Ho (Google Research Blog)'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“使用扩散模型生成高保真度图像”](https://oreil.ly/5b_5Y)，作者为 Jonathan Ho（Google Research
    Blog）。'
- en: '[“SUPERVEGAN: Super Resolution Video Enhancement Gan for Perceptually Improving
    Low Bitrate Streams”](https://oreil.ly/nw0e2), by Silviu S. Andrei et al. (Amazon
    Science)'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“SUPERVEGAN：用于感知提高低比特率流的超分辨率视频增强 GAN”](https://oreil.ly/nw0e2)，作者为 Silviu
    S. Andrei 等人（Amazon Science）。'
- en: Object detection summary
  id: totrans-404
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标检测摘要
- en: '*Object detection* is a task used to recognize and localize objects in an image.
    It is more advanced than image classification, which classifies the entire image;
    *localizing* tells us *where* in the image the object of interest is located.
    As an extension, by applying object detection to individual frames in a video,
    you can conduct object tracking and follow a subject’s or object’s location in
    a video feed, and even across multiple camera angles. Object detection and object
    tracking with ML can be used in sports matches to track a ball, for example.'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '*目标检测* 是用于识别和定位图像中物体的任务。它比图像分类更为先进，后者是对整个图像进行分类；*定位* 告诉我们感兴趣物体在图像中的位置。通过将目标检测应用于视频中的单个帧，可以进行物体跟踪，并跟随视频中的主体或物体位置，甚至跨多个摄像头角度。使用机器学习进行目标检测和物体跟踪可用于体育比赛中追踪球的运动轨迹，例如。'
- en: 'Relevant algorithms to object detection include:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 与目标检测相关的算法包括：
- en: '[YOLO](https://oreil.ly/2RAW5) (You Only Look Once) and its newer versions
    by Chien-Yao Wang et al.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLO](https://oreil.ly/2RAW5)（You Only Look Once）及其新版本，作者为 Chien-Yao Wang
    等人。'
- en: '[“Pix2Seq: A New Language Interface for Object Detection”](https://oreil.ly/n14_h),
    by Ting Chen and David Fleet (Google Research Blog)'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“Pix2Seq：用于目标检测的新语言接口”](https://oreil.ly/n14_h)，作者为 Google Research Blog 的
    Ting Chen 和 David Fleet。'
- en: Semantic image segmentation summary
  id: totrans-409
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语义图像分割摘要
- en: '*Semantic image segmentation* is the task of assigning a semantic label, such
    as “computer,” “phone,” “person,” or “dog,” to every pixel in an image. Examples
    include isolating categories in images, such as isolating humans in the foreground
    from buildings in the background. One common example is portrait mode in smartphone
    cameras. Read more about semantic segmentation applications in the Google Pixel
    mobile phone camera’s portrait mode^([60](ch03.html#ch03fn61)) as an example.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '*语义图像分割* 是将语义标签（如“计算机”、“手机”、“人物”或“狗”）分配给图像中每个像素的任务。示例包括在图像中隔离类别，例如将前景中的人类与背景中的建筑物分离。智能手机相机的人像模式是一个常见的示例。了解更多关于语义分割应用的信息，例如
    Google Pixel 手机相机的人像模式^([60](ch03.html#ch03fn61))。'
- en: 'You can learn more with these resources:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过这些资源了解更多信息：
- en: '[“Semantic Image Segmentation with DeepLab in TensorFlow”](https://oreil.ly/qDr94),
    by Liang-Chieh Chen and Yukun Zhu (Google Research Blog)'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“使用 TensorFlow 中的 DeepLab 进行语义图像分割”](https://oreil.ly/qDr94)，作者为 Google Research
    Blog 的 Liang-Chieh Chen 和 Yukun Zhu。'
- en: '[“Comparison of Object Detection and Semantic Segmentation”](https://oreil.ly/UmZhc)
    from *Practical Machine Learning for Computer Vision* by Valliappa Lakshmanan,
    Martin Görner, and Ryan Gillard (O’Reilly)'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“目标检测与语义分割的比较”](https://oreil.ly/UmZhc)，出自 Valliappa Lakshmanan、Martin Görner
    和 Ryan Gillard（O’Reilly）的《实用机器学习视觉》。'
- en: 'Here are some more industry examples (note that they usually combine multiple
    techniques):'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一些行业示例（请注意它们通常结合多种技术）：
- en: Amazon consistently experiments and researches computer vision to help customers
    shop online, for example, helping them find relevant products by describing variations
    of existing products.^([61](ch03.html#ch03fn62)) For instance, a customer could
    be searching for dresses and see one they like. However, the style is not available
    in the color they prefer. They can find dresses similar to the current product
    by typing, “I want a similar one, but change black to pink.”
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon一直在实验和研究计算机视觉，以帮助顾客在线购物，例如通过描述现有产品的变化来帮助他们找到相关产品。^([61](ch03.html#ch03fn62))
    例如，顾客可能在搜索连衣裙时看到一款喜欢的款式。然而，该款式的颜色不是他们偏爱的。他们可以通过输入“我想找一个类似的，但把黑色改成粉色”来找到类似当前产品的连衣裙。
- en: '[Meta AI](https://oreil.ly/yf9xL) often seeks to leverage computer vision to
    improve automation on its social media platforms. For example, it has improved
    the automatically generated text descriptions of images for people with visual
    impairments,^([62](ch03.html#ch03fn63)) provided better automatic categorization
    of Facebook Marketplace items, content moderation, and so on.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Meta AI](https://oreil.ly/yf9xL)经常利用计算机视觉来提高其社交媒体平台上的自动化。例如，它已经改进了为视力障碍人士自动生成的图像描述，^([62](ch03.html#ch03fn63))
    提供了更好的Facebook Marketplace商品的自动分类、内容审核等功能。'
- en: Netflix uses computer vision to experiment with and improve thumbnails for content,
    and other use cases, using its wealth of video, audio, and image data.^([63](ch03.html#ch03fn64))
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Netflix利用计算机视觉来实验和改进内容的缩略图，以及其他使用案例，利用其丰富的视频、音频和图像数据。^([63](ch03.html#ch03fn64))
- en: Sample Interview Questions on Image Recognition
  id: totrans-418
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像识别的样例面试问题
- en: Now that I’ve walked through an overview of computer vision, common datasets,
    algorithms, and use cases, here are some example interview questions.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经概述了计算机视觉、常见数据集、算法和使用案例，这里有一些例子面试问题。
- en: 'Interview question 3-22: What are some common techniques of preprocessing in
    image-recognition tasks?'
  id: totrans-420
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-22：图像识别任务中的一些常见预处理技术是什么？
- en: Example answer
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 样例回答
- en: Common preprocessing techniques in image-recognition tasks include data normalization,
    data augmentation, and image standardization. Data normalization converts the
    numerical representation of the pixels in an image to a predefined range—for example,
    (0, 1) or (-1, 1). This is so the algorithms being applied to different layers
    can follow the same range. Data augmentation can help reduce overfitting on the
    training dataset. For example, if the training data coincidentally only includes
    cats that are facing to the right, then the CNN might not learn that cats facing
    to the left are also cats. Using various data augmentation techniques such as
    flipping, rotating, cropping, and so on, we can add more representations of the
    same object into the dataset and help the CNN learn to generalize the detection
    of objects. Image standardization makes the dataset easier to work with by ensuring
    that images have heights and widths that are close to one another. During this
    preprocessing step, images are resized so that they are within a certain range
    of widths and heights.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 图像识别任务中常见的预处理技术包括数据归一化、数据增强和图像标准化。数据归一化将图像中像素的数值表示转换为预定义的范围，例如(0, 1)或(-1, 1)。这样，应用于不同层的算法可以遵循相同的数值范围。数据增强有助于减少在训练数据集上的过拟合。例如，如果训练数据偶然只包含向右转的猫，那么卷积神经网络可能不会学习到向左转的猫也是猫。通过使用翻转、旋转、裁剪等多种数据增强技术，我们可以向数据集中添加更多相同对象的表示，并帮助卷积神经网络学习泛化物体检测。图像标准化使数据集更易于处理，通过确保图像具有接近的高度和宽度来实现。在此预处理步骤中，图像被调整大小，使它们在某一范围内具有相似的宽度和高度。
- en: 'Interview question 3-23: How might you handle class imbalance in image-recognition
    tasks?'
  id: totrans-423
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题 3-23：在图像识别任务中，你如何处理类别不平衡？
- en: Example answer
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 样例回答
- en: There are several methods we can use to handle class imbalance in image-recognition
    tasks. A “class” in this case means a category or label; for example, an image
    may contain a “cat” or a “dog”. One way to handle class imbalance is to merge
    very similar categories, such as “orange” and “tangerine”. Of course, we’d have
    to determine the trade-off between the labels that are being merged. If the image-recognition
    model is responsible for labeling citrus fruits, then we should try another approach
    or merge other types of labels.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 处理图像识别任务中的类别不平衡有几种方法。在这里，“类别”指的是一个类别或标签；例如，一幅图像可能包含“猫”或“狗”。处理类别不平衡的一种方法是合并非常相似的类别，比如“橙子”和“柑橘”。当然，我们必须确定合并标签的权衡。如果图像识别模型负责标记柑橘水果，那么我们应该尝试另一种方法或合并其他类型的标签。
- en: A second option is resampling, which generates synthetic data or duplicates
    data points in the minority class. There are built-in tools in TensorFlow and
    PyTorch to do this for image-recognition tasks. Another method to handle class
    imbalance is to adjust the CNN’s loss function to weigh mistakes on minority or
    rare categories more than mistakes on common classes and labels. This is to help
    avoid underfitting on rare categories due to class imbalance.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个选项是重新采样，它生成合成数据或复制少数类别的数据点。在TensorFlow和PyTorch中有内置工具可以为图像识别任务执行此操作。处理类别不平衡的另一种方法是调整CNN的损失函数，使得对少数或稀有类别的错误赋予更高的权重，而不是常见类别和标签的错误。这有助于避免由于类别不平衡导致在稀有类别上的欠拟合。
- en: 'Interview question 3-24: How would you handle overfitting in image-recognition
    tasks?'
  id: totrans-427
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题3-24：如何处理图像识别任务中的过拟合？
- en: Example answer
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 示例答案
- en: Adding a dropout layer (a type of regularization) within the CNN will set random
    neurons’ activations to 0; this prevents the layer from overexploiting a certain
    feature. Another method is early stopping, where training stops when there isn’t
    meaningful reduction of the loss (which the CNN is aiming to minimize). Reducing
    layer complexity can also reduce overfitting because when the CNN layers are too
    complex, it may find more patterns in the images than are meaningful. For example,
    many images of singers involve them standing on a stage and holding a microphone,
    and the model might learn that the presence of a microphone in the image means
    the presence of a singer. Another technique for handling overfitting in image
    recognition is data augmentation, which can help add more diversity into the training
    dataset and reduce overfitting.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 在CNN中添加一个dropout层（一种正则化类型）将随机将神经元的激活设置为0；这可以防止层次过度利用某些特征。另一种方法是早停止，即在CNN无法显著减少损失时停止训练（CNN旨在最小化损失）。减少层次复杂性也可以减少过拟合，因为当CNN层次太复杂时，它可能在图像中找到更多无意义的模式。例如，许多歌手的图像都涉及站在舞台上并拿着麦克风，模型可能会学到图像中麦克风的存在意味着歌手的存在。处理图像识别中过拟合的另一种技术是数据增强，这可以帮助在训练数据集中增加更多多样性，减少过拟合。
- en: 'Interview question 3-25: How would you improve and optimize the architecture
    for a CNN used for image recognition?'
  id: totrans-430
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面试问题3-25：如何改进和优化用于图像识别的CNN架构？
- en: Example answer
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 示例答案
- en: If the existing network isn’t working well, for example, if it is underfitting
    and not classifying objects well, I might consider adding more layers of specific
    types—for example, adding a convolutional layer or rearranging the order of various
    layers. This is also how researchers optimize various algorithm architectures,
    such as creating variations of layers on ResNet.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 如果现有网络表现不佳，例如，出现欠拟合且无法良好分类对象的情况，我可能考虑增加更多特定类型的层次，例如添加卷积层或重新排列各种层次的顺序。这也是研究人员优化各种算法架构的方式，例如在ResNet上创建层次变化。
- en: Summary
  id: totrans-433
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'Congratulations on making it through some dense topics! First, you went through
    a summary of statistical techniques commonly mentioned in interviews, including
    common techniques for ML, like regularization, and topics such as overfitting
    and underfitting. We walked through supervised learning, unsupervised learning,
    and reinforcement learning. Then you dove into the various core ML areas: natural
    language processing, recommender systems, reinforcement learning, and computer
    vision.'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你已经通过了一些复杂的话题！首先，你浏览了一个总结常见的统计技术，包括机器学习中的常见技术，如正则化，以及过拟合和欠拟合等主题。我们详细介绍了监督学习，无监督学习和强化学习。然后，你深入研究了各种核心机器学习领域：自然语言处理，推荐系统，强化学习和计算机视觉。
- en: In this chapter, you were given some example interview questions as well as
    resources for each topic, which you can refer to when you’re preparing.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，您将得到一些示例面试问题以及每个主题的资源，当您准备时可以参考。
- en: Now that you’ve gotten an overview of the machine learning algorithms portion
    of technical interviews, let’s look at the training process of ML models and model
    evaluation.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了技术面试中机器学习算法部分的概述，让我们来看看ML模型的训练过程和模型评估。
- en: ^([1](ch03.html#ch03fn1-marker)) Depending on the types of responsibilities
    the job has in the ML lifecycle, this portion might be skipped—for example, for
    “applied machine learning engineer” or “software engineer, machine learning,”
    roles, especially at Google. Double-check with your recruiter or hiring manager
    when in doubt!
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.html#ch03fn1-marker)) 根据工作在机器学习生命周期中的责任类型，可能会跳过这部分内容，例如“应用机器学习工程师”或“软件工程师，机器学习”等职位，特别是在Google。如有疑问，请与您的招聘者或招聘经理确认！
- en: ^([2](ch03.html#ch03fn2-marker)) Jason Brownlee, “Difference Between Algorithm
    and Model in Machine Learning,” *Machine Learning Mastery* (blog), August 19,
    2020, [*https://oreil.ly/TrduX*](https://oreil.ly/TrduX).
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch03.html#ch03fn2-marker)) Jason Brownlee，《机器学习掌握》博客，“算法与模型在机器学习中的区别”，2020年8月19日，[*https://oreil.ly/TrduX*](https://oreil.ly/TrduX)。
- en: ^([3](ch03.html#ch03fn3-marker)) Details are in [“Supervised, Unsupervised,
    and Reinforcement Learning”](#supervisedcomma_unsupervisedcomma_and_re).
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch03.html#ch03fn3-marker)) 详细信息请参阅[“监督学习、无监督学习和强化学习”](#supervisedcomma_unsupervisedcomma_and_re)。
- en: '^([4](ch03.html#ch03fn4-marker)) “Cross-Validation: Evaluating Estimator Performance,”
    in *Scikit-learn: Machine Learning in Python User Guide*, accessed October 24,
    2023, [*https://oreil.ly/Spja4*](https://oreil.ly/Spja4).'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch03.html#ch03fn4-marker)) “交叉验证：评估估算器的性能”，在*Scikit-learn：Python中的机器学习用户指南*中，2023年10月24日访问，[*https://oreil.ly/Spja4*](https://oreil.ly/Spja4)。
- en: ^([5](ch03.html#ch03fn5-marker)) “What Is Underfitting?” IBM, accessed October
    21, 2023, [*https://oreil.ly/SSihF*](https://oreil.ly/SSihF).
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch03.html#ch03fn5-marker)) “什么是欠拟合？”IBM，2023年10月21日访问，[*https://oreil.ly/SSihF*](https://oreil.ly/SSihF)。
- en: '^([6](ch03.html#ch03fn6-marker)) Sekai Ichi apples could sell for between $20
    and $25 each (source: [Silver Creek Nursery](https://oreil.ly/U_54R)).'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch03.html#ch03fn6-marker)) Sekai Ichi苹果每个可以售价$20至$25（来源：[Silver Creek
    Nursery](https://oreil.ly/U_54R)）。
- en: ^([7](ch03.html#ch03fn7-marker)) “What Is Overfitting?” IBM, accessed October
    21, 2023\. [*https://oreil.ly/p9V_u*](https://oreil.ly/p9V_u).
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch03.html#ch03fn7-marker)) “什么是过拟合？”IBM，2023年10月21日访问，[*https://oreil.ly/p9V_u*](https://oreil.ly/p9V_u)。
- en: ^([8](ch03.html#ch03fn8-marker)) “Lasso and Elastic Net,” MathWorks, accessed
    October 21, 2023, [*https://oreil.ly/yOCEe*](https://oreil.ly/yOCEe).
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch03.html#ch03fn8-marker)) “Lasso和Elastic Net”，MathWorks，2023年10月21日访问，[*https://oreil.ly/yOCEe*](https://oreil.ly/yOCEe)。
- en: ^([9](ch03.html#ch03fn9-marker)) “Imbalanced Data,” Machine Learning, Google
    for Developers, accessed October 21, 2023, [*https://oreil.ly/sKP4h*](https://oreil.ly/sKP4h).
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch03.html#ch03fn9-marker)) “不平衡数据”，Machine Learning，Google for Developers，2023年10月21日访问，[*https://oreil.ly/sKP4h*](https://oreil.ly/sKP4h)。
- en: '^([10](ch03.html#ch03fn10-marker)) Nitesh V. Chawla, Kevin W. Bowyer, Lawrence
    O. Hall, and W. Philip Kegelmeyer, “SMOTE: Synthetic Minority Over-Sampling Technique,”
    *Journal of Artificial Intelligence Research* 16 (2002): 321–57, [doi:10.1613/jair.953](https://www.jair.org/index.php/jair/article/view/10302).'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch03.html#ch03fn10-marker)) Nitesh V. Chawla, Kevin W. Bowyer, Lawrence
    O. Hall, and W. Philip Kegelmeyer，《人工智能研究杂志》第16卷（2002年）：321–57，[doi:10.1613/jair.953](https://www.jair.org/index.php/jair/article/view/10302)。
- en: ^([11](ch03.html#ch03fn11-marker)) Chip Huyen, “Training Data,” Ch. 4 in [*Designing
    Machine Learning Systems*](https://oreil.ly/bsqEg) (O’Reilly).
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch03.html#ch03fn11-marker)) Chip Huyen，《设计机器学习系统》第4章“训练数据”（O’Reilly），[*https://oreil.ly/bsqEg*](https://oreil.ly/bsqEg)。
- en: ^([12](ch03.html#ch03fn12-marker)) Chip Huyen, “Model Development and Offline
    Evaluation,” Ch. 6 in *Designing Machine Learning Systems*.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch03.html#ch03fn12-marker)) Chip Huyen，《设计机器学习系统》第6章“模型开发与离线评估”。
- en: ^([13](ch03.html#ch03fn13-marker)) “What Is Overfitting?” IBM, accessed October
    21, 2023\. [*https://oreil.ly/p9V_u*](https://oreil.ly/p9V_u).
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch03.html#ch03fn13-marker)) “什么是过拟合？”IBM，2023年10月21日访问，[*https://oreil.ly/p9V_u*](https://oreil.ly/p9V_u)。
- en: ^([14](ch03.html#ch03fn14-marker)) As a reminder, the labels for this apple
    dataset are the past apple prices—in other words, the “correct” or expected outcomes
    of the past, in order for us to check how accurate the trained model is.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch03.html#ch03fn14-marker)) 作为提醒，此苹果数据集的标签是过去苹果价格，换句话说，过去的“正确”或预期结果，以便我们检查训练模型的准确性。
- en: ^([15](ch03.html#ch03fn15-marker)) See Randall Balestriero et al., *A Cookbook
    of Self-Supervised Learning*, June 28, 2023, [*https://oreil.ly/M20OU*](https://oreil.ly/M20OU),
    and the accompanying blog post “The Self-Supervised Learning Cookbook,” *Meta
    AI* (blog), April 25, 2023, [*https://oreil.ly/XT6wX*](https://oreil.ly/XT6wX).
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch03.html#ch03fn15-marker)) 参见 Randall Balestriero 等人, *自监督学习菜谱*, June
    28, 2023, [*https://oreil.ly/M20OU*](https://oreil.ly/M20OU), 以及附带的博客文章 “自监督学习菜谱,”
    *Meta AI* (blog), April 25, 2023, [*https://oreil.ly/XT6wX*](https://oreil.ly/XT6wX).
- en: ^([16](ch03.html#ch03fn16-marker)) To learn more, see Andrew Zisserman, “Self-Supervised
    Learning” (presentation, Google DeepMind), [*https://oreil.ly/wGQ98*](https://oreil.ly/wGQ98).
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch03.html#ch03fn16-marker)) 欲了解更多，请参阅 Andrew Zisserman, “自监督学习” (presentation,
    Google DeepMind), [*https://oreil.ly/wGQ98*](https://oreil.ly/wGQ98).
- en: ^([17](ch03.html#ch03fn17-marker)) Jake VanderPlas, [*Python Data Science Handbook*](https://oreil.ly/kyA6E)
    (O’Reilly, 2016).
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch03.html#ch03fn17-marker)) Jake VanderPlas, [*Python 数据科学手册*](https://oreil.ly/kyA6E)
    (O’Reilly, 2016).
- en: ^([18](ch03.html#ch03fn18-marker)) “An Intuitive (and Short) Explanation of
    Bayes’ Theorem,” Better Explained, accessed October 23, 2023, [*https://oreil.ly/I7ika*](https://oreil.ly/I7ika).
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch03.html#ch03fn18-marker)) “贝叶斯定理直观（及简短）解释,” Better Explained, accessed
    October 23, 2023, [*https://oreil.ly/I7ika*](https://oreil.ly/I7ika).
- en: ^([19](ch03.html#ch03fn19-marker)) “Bayesian Neural Network,” Machine Learning
    Glossary, accessed October 23, 2023, [*https://oreil.ly/BotI7*](https://oreil.ly/BotI7).
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch03.html#ch03fn19-marker)) “贝叶斯神经网络,” 机器学习词汇表, accessed October 23,
    2023, [*https://oreil.ly/BotI7*](https://oreil.ly/BotI7).
- en: ^([20](ch03.html#ch03fn20-marker)) Andrew Zisserman, “Self-Supervised Learning”
    (presentation, Google DeepMind), [*https://oreil.ly/o32MY*](https://oreil.ly/o32MY).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](ch03.html#ch03fn20-marker)) Andrew Zisserman, “自监督学习” (presentation,
    Google DeepMind), [*https://oreil.ly/o32MY*](https://oreil.ly/o32MY).
- en: ^([21](ch03.html#ch03fn21-marker)) ML model evaluation is covered in more detail
    in [Chapter 4](ch04.html#technical_interviewcolon_model_training).
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch03.html#ch03fn21-marker)) ML 模型评估在[第四章](ch04.html#technical_interviewcolon_model_training)中有更详细的涵盖。
- en: ^([22](ch03.html#ch03fn22-marker)) Alex Krizhevsky, “The CIFAR-10 Dataset,”
    Canadian Institute for Advanced Research, accessed October 23, 2023, [*https://oreil.ly/x1g7o*](https://oreil.ly/x1g7o).
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch03.html#ch03fn22-marker)) Alex Krizhevsky, “CIFAR-10 数据集,” Canadian
    Institute for Advanced Research, accessed October 23, 2023, [*https://oreil.ly/x1g7o*](https://oreil.ly/x1g7o).
- en: ^([23](ch03.html#ch03fn23-marker)) “Text Corpus,” Wikipedia, updated September
    17, 2023, [*https://oreil.ly/v2IbE*](https://oreil.ly/v2IbE).
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](ch03.html#ch03fn23-marker)) “文本语料库,” Wikipedia, updated September 17,
    2023, [*https://oreil.ly/v2IbE*](https://oreil.ly/v2IbE).
- en: ^([24](ch03.html#ch03fn24-marker)) Christopher D. Manning, Prabhakar Raghavan,
    and Hinrich Schütze, “Tokenization,” in *An Introduction to Information Retrieval*
    (Cambridge University Press, 2022), [*https://oreil.ly/0opkO*](https://oreil.ly/0opkO).
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](ch03.html#ch03fn24-marker)) Christopher D. Manning, Prabhakar Raghavan,
    and Hinrich Schütze, “Tokenization,” in *信息检索导论* (Cambridge University Press,
    2022), [*https://oreil.ly/0opkO*](https://oreil.ly/0opkO).
- en: '^([25](ch03.html#ch03fn25-marker)) Yonghui Wu, “Smart Compose: Using Neural
    Networks to Help Write Emails.” *Google Research* (blog), May 16, 2018, [*https://oreil.ly/gqnBt*](https://oreil.ly/gqnBt).'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: '^([25](ch03.html#ch03fn25-marker)) Yonghui Wu, “智能撰写: 使用神经网络帮助撰写电子邮件,” *Google
    Research* (blog), May 16, 2018, [*https://oreil.ly/gqnBt*](https://oreil.ly/gqnBt).'
- en: ^([26](ch03.html#ch03fn27-marker)) Ashish Vaswani et al., “Attention Is All
    You Need” (paper presented at the meeting of the Advances in Neural Information
    Processing Systems, 2017), [*https://arxiv.org/abs/1706.03762*](https://oreil.ly/0V-UR).
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: ^([26](ch03.html#ch03fn27-marker)) Ashish Vaswani 等人, “注意力机制就是你所需的一切” (paper
    presented at the meeting of the Advances in Neural Information Processing Systems,
    2017), [*https://arxiv.org/abs/1706.03762*](https://oreil.ly/0V-UR).
- en: ^([27](ch03.html#ch03fn28-marker)) Rick Merritt, “What Is a Transformer Model?”
    *Nvidia* (blog), March 25, 2022, [*https://oreil.ly/As2W6*](https://oreil.ly/As2W6).
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: ^([27](ch03.html#ch03fn28-marker)) Rick Merritt, “转换器模型是什么?” *Nvidia* (blog),
    March 25, 2022, [*https://oreil.ly/As2W6*](https://oreil.ly/As2W6).
- en: ^([28](ch03.html#ch03fn29-marker)) Pandu Nayak, “Understanding Searches Better
    than Ever Before,” *The Keyword* (blog), Google, October 25, 2019, [*https://oreil.ly/xONdR*](https://oreil.ly/xONdR).
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: ^([28](ch03.html#ch03fn29-marker)) Pandu Nayak, “比以往更好地理解搜索,” *The Keyword*
    (blog), Google, October 25, 2019, [*https://oreil.ly/xONdR*](https://oreil.ly/xONdR).
- en: ^([29](ch03.html#ch03fn30-marker)) See “Pre-trained Models,” BERT, on GitHub,
    [*https://oreil.ly/XkaY2*](https://oreil.ly/XkaY2).
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: ^([29](ch03.html#ch03fn30-marker)) 参见 “预训练模型,” BERT, on GitHub, [*https://oreil.ly/XkaY2*](https://oreil.ly/XkaY2).
- en: '^([30](ch03.html#ch03fn31-marker)) “Getting Started with the Built-in BERT
    Algorithm,” AI Platform Training: Documentation, Google Cloud, updated October
    20, 2023, [*https://oreil.ly/HeJax*](https://oreil.ly/HeJax).'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: ^([30](ch03.html#ch03fn31-marker)) “使用内置BERT算法入门”，AI Platform培训：文档，Google Cloud，更新于2023年10月20日，[*https://oreil.ly/HeJax*](https://oreil.ly/HeJax)。
- en: ^([31](ch03.html#ch03fn32-marker)) See “BERT Multilingual Base Model (Cased)”
    on Hugging Face, [*https://oreil.ly/tyO6D*](https://oreil.ly/tyO6D).
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: ^([31](ch03.html#ch03fn32-marker)) 参见Hugging Face上的“BERT多语言基础模型（带大小写区分）”，[*https://oreil.ly/tyO6D*](https://oreil.ly/tyO6D)。
- en: ^([32](ch03.html#ch03fn33-marker)) GPT-4 came out after I had written the first
    draft of this chapter, so I had to add it! By the time this book reaches your
    hands, I wonder what else will have been released.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: ^([32](ch03.html#ch03fn33-marker)) 我在撰写本章草稿后，GPT-4问世了，所以我不得不添加它！当这本书到达你手中时，我想知道还会发布什么新内容。
- en: ^([33](ch03.html#ch03fn34-marker)) “Generative Pre-trained Transformer,” Wikipedia,
    updated October 23, 2023, [*https://oreil.ly/Emp_M*](https://oreil.ly/Emp_M).
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: ^([33](ch03.html#ch03fn34-marker)) “生成式预训练变压器”，维基百科，更新于2023年10月23日，[*https://oreil.ly/Emp_M*](https://oreil.ly/Emp_M)。
- en: ^([34](ch03.html#ch03fn35-marker)) “Fine-tuning,” OpenAI Documentation, accessed
    October 23, 2023, [*https://oreil.ly/B19eG*](https://oreil.ly/B19eG).
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: ^([34](ch03.html#ch03fn35-marker)) “微调”，OpenAI文档，访问日期为2023年10月23日，[*https://oreil.ly/B19eG*](https://oreil.ly/B19eG)。
- en: ^([35](ch03.html#ch03fn36-marker)) This field is moving fast; by the time this
    book comes out, I wonder if these models will have been superseded.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: ^([35](ch03.html#ch03fn36-marker)) 这个领域发展迅速；当这本书出版时，我不知道这些模型是否已经被淘汰。
- en: ^([36](ch03.html#ch03fn37-marker)) “Word2vec,” Wikipedia, updated September
    5, 2023, [*https://oreil.ly/JyqBW*](https://oreil.ly/JyqBW).
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: ^([36](ch03.html#ch03fn37-marker)) “Word2vec”，维基百科，更新于2023年9月5日，[*https://oreil.ly/JyqBW*](https://oreil.ly/JyqBW)。
- en: '^([37](ch03.html#ch03fn38-marker)) Jeffrey Pennington, Richard Socher, and
    Christopher D. Manning, “GloVe: Global Vectors for Word Representation,” Stanford
    University, August 2014, [*https://oreil.ly/LdCcH*](https://oreil.ly/LdCcH).'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: ^([37](ch03.html#ch03fn38-marker)) Jeffrey Pennington，Richard Socher和Christopher
    D. Manning，“GloVe：全局词向量表示”，斯坦福大学，2014年8月，[*https://oreil.ly/LdCcH*](https://oreil.ly/LdCcH)。
- en: ^([38](ch03.html#ch03fn39-marker)) Christopher D. Manning, Prabhakar Raghavan,
    and Hinrich Schütze, “Stemming and Lemmatization,” in *Introduction to Information
    Retrieval* (Cambridge University Press, 2008), [*https://oreil.ly/JsXCj*](https://oreil.ly/JsXCj).
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: ^([38](ch03.html#ch03fn39-marker)) Christopher D. Manning，Prabhakar Raghavan和Hinrich
    Schütze，《信息检索导论》（剑桥大学出版社，2008年），[*https://oreil.ly/JsXCj*](https://oreil.ly/JsXCj)。
- en: ^([39](ch03.html#ch03fn40-marker)) Weidinger et al., *Ethical and Social Risks
    of Harm from Language Models*, Google DeepMind, December 8, 2021, [*https://oreil.ly/-ZFL7*](https://oreil.ly/-ZFL7).
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: ^([39](ch03.html#ch03fn40-marker)) Weidinger等人，《语言模型的道德和社会风险》（Google DeepMind，2021年12月8日），[*https://oreil.ly/-ZFL7*](https://oreil.ly/-ZFL7)。
- en: '^([40](ch03.html#ch03fn41-marker)) For those who are curious, the [time complexity
    of SVD](https://oreil.ly/z4_x0) of an *m* x *n* matrix, where *m* > *n*: *O*(*m*²
    × *n* + *n*³). In practice, it might depend on the implementation, as this [MathWorks
    discussion](https://oreil.ly/GFa4z) mentions.'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: ^([40](ch03.html#ch03fn41-marker)) 对于那些好奇的人，奇异值分解（SVD）的时间复杂度，对于一个*m* x *n*的矩阵，其中*m*
    > *n*：*O*(*m*² × *n* + *n*³)。实际上，这可能取决于实现，正如这个[MathWorks讨论](https://oreil.ly/GFa4z)所提到的。
- en: ^([41](ch03.html#ch03fn42-marker)) Sometimes, this problem is referred to as
    the [“long-tail” problem](https://oreil.ly/Zd1Yp) in RecSys.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: ^([41](ch03.html#ch03fn42-marker)) 有时，这个问题在RecSys中被称为[“长尾”问题](https://oreil.ly/Zd1Yp)。
- en: ^([42](ch03.html#ch03fn43-marker)) Rishabh Mehrotra, “Personalizing Explainable
    Recommendations with Multi-Objective Contextual Bandits” (video presentation for
    MLconf, YouTube, March 29, 2019), [*https://oreil.ly/v587X*](https://oreil.ly/v587X);
    Brent Rabowsky and Liam Morrison, “What’s New in Recommender Systems,” AWS for
    M&E (blog), Amazon Web Services, [*https://oreil.ly/Z0Qq2*](https://oreil.ly/Z0Qq2).
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: ^([42](ch03.html#ch03fn43-marker)) Rishabh Mehrotra，“个性化可解释推荐与多目标上下文赌博”（MLconf的视频演示，YouTube，2019年3月29日），[*https://oreil.ly/v587X*](https://oreil.ly/v587X)；Brent
    Rabowsky和Liam Morrison，“推荐系统的新动向”，AWS for M&E（博客），Amazon Web Services，[*https://oreil.ly/Z0Qq2*](https://oreil.ly/Z0Qq2)。
- en: ^([43](ch03.html#ch03fn44-marker)) I’ve spoken to someone at Ubisoft whose team
    trained RL agents to help optimize and test their games. [Here are more examples
    from Ubisoft](https://oreil.ly/1RP1h).
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: ^([43](ch03.html#ch03fn44-marker)) 我曾与育碧的一位团队成员交谈过，他们训练了RL代理以帮助优化和测试他们的游戏。[这里有更多来自育碧的例子](https://oreil.ly/1RP1h)。
- en: '^([44](ch03.html#ch03fn45-marker)) Chip Huyen, “RLHF: Reinforcement Learning
    from Human Feedback” (blog), May 2, 2023, [*https://oreil.ly/xE7tR*](https://oreil.ly/xE7tR).'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '^([44](ch03.html#ch03fn45-marker)) Chip Huyen，“RLHF: 人类反馈的强化学习”（博客），2023年5月2日，[*https://oreil.ly/xE7tR*](https://oreil.ly/xE7tR)。'
- en: '^([45](ch03.html#ch03fn46-marker)) “Epsilon Greedy Policy,” Machine Learning
    Glossary: Reinforcement Learning, accessed October 23, 2023, [*https://oreil.ly/ZYbkN*](https://oreil.ly/ZYbkN).'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: ^([45](ch03.html#ch03fn46-marker)) “ε贪婪策略”，机器学习词汇表：强化学习，访问于2023年10月23日，[*https://oreil.ly/ZYbkN*](https://oreil.ly/ZYbkN)。
- en: '^([46](ch03.html#ch03fn47-marker)) “Bellman Equation,” Machine Learning Glossary:
    Reinforcement Learning, accessed October 23, 2023, [*https://oreil.ly/KP8kh*](https://oreil.ly/KP8kh).'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: ^([46](ch03.html#ch03fn47-marker)) “贝尔曼方程”，机器学习词汇表：强化学习，访问于2023年10月23日，[*https://oreil.ly/KP8kh*](https://oreil.ly/KP8kh)。
- en: ^([47](ch03.html#ch03fn48-marker)) “SARSA Agents,” MathWorks, accessed October
    23, 2023, [*https://oreil.ly/KP8kh*](https://oreil.ly/KP8kh).
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: ^([47](ch03.html#ch03fn48-marker)) “SARSA代理”，MathWorks，访问于2023年10月23日，[*https://oreil.ly/KP8kh*](https://oreil.ly/KP8kh)。
- en: ^([48](ch03.html#ch03fn49-marker)) Yuewen Sun, Xin Yuan, Wenzhang Liu, and Changyin
    Sin, “Model-Based Reinforcement Learning via Proximal Policy Optimization,” *2019
    Chinese Automation Conference (CAC),* 2019, pp. 4736–40, [doi:10.1109/CAC48633.2019.8996875](https://oreil.ly/M-POc).
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: ^([48](ch03.html#ch03fn49-marker)) 孙月文、袁欣、刘文章和辛长银，“基于模型的强化学习：近端策略优化”，*2019年中国自动化大会
    (CAC)*，2019年，pp. 4736–40，[doi:10.1109/CAC48633.2019.8996875](https://oreil.ly/M-POc)。
- en: '^([49](ch03.html#ch03fn50-marker)) Michael Janner, “Model-Based Reinforcement
    Learning: Theory and Practice,” *Berkeley Artificial Intelligence Research*, December
    12, 2019, [*https://oreil.ly/ZuF22*](https://oreil.ly/ZuF22).'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: ^([49](ch03.html#ch03fn50-marker)) Michael Janner，“基于模型的强化学习：理论与实践”，*伯克利人工智能研究*，2019年12月12日，[*https://oreil.ly/ZuF22*](https://oreil.ly/ZuF22)。
- en: ^([50](ch03.html#ch03fn51-marker)) J. Zico Kolter, “Introduction to Reinforcement
    Learning” (presentation, 28th International Conference on Automated Planning and
    Scheduling, Delft, The Netherlands, June 24–29, 2018), [*https://oreil.ly/b_5nO*](https://oreil.ly/b_5nO).
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: ^([50](ch03.html#ch03fn51-marker)) J. Zico Kolter，“强化学习简介”（演示，第28届国际自动规划与调度会议，荷兰代尔夫特，2018年6月24–29日），[*https://oreil.ly/b_5nO*](https://oreil.ly/b_5nO)。
- en: ^([51](ch03.html#ch03fn52-marker)) “SARSA Agents,” MathWorks, accessed October
    2, 2023, [*https://oreil.ly/iZOG3*](https://oreil.ly/iZOG3).
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: ^([51](ch03.html#ch03fn52-marker)) “SARSA代理”，MathWorks，访问于2023年10月2日，[*https://oreil.ly/iZOG3*](https://oreil.ly/iZOG3)。
- en: ^([52](ch03.html#ch03fn53-marker)) Tingwu Wang, “Learning Reinforcement Learning
    by Learning REINFORCE” (presentation, University of Toronto Machine Learning Group),
    [*https://oreil.ly/Fgmck*](https://oreil.ly/Fgmck).
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: ^([52](ch03.html#ch03fn53-marker)) 王廷武，“通过学习REINFORCE学习强化学习”（演示，多伦多大学机器学习组），[*https://oreil.ly/Fgmck*](https://oreil.ly/Fgmck)。
- en: ^([53](ch03.html#ch03fn54-marker)) David L. Poole and Alan K. Mackworth, “On-Policy
    Learning,” in *Artificial Intelligence*, 2nd ed. (Cambridge University Press,
    2017), [*https://oreil.ly/KmgMu*](https://oreil.ly/KmgMu).
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: ^([53](ch03.html#ch03fn54-marker)) David L. Poole和Alan K. Mackworth，“关于策略学习”，《人工智能》第2版（剑桥大学出版社，2017年），[*https://oreil.ly/KmgMu*](https://oreil.ly/KmgMu)。
- en: ^([54](ch03.html#ch03fn55-marker)) Tingwu Wang, “Learning Reinforcement Learning
    by Learning REINFORCE” (presentation, University of Toronto Machine Learning Group),
    [*https://oreil.ly/Fgmck*](https://oreil.ly/Fgmck).
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: ^([54](ch03.html#ch03fn55-marker)) 王廷武，“通过学习REINFORCE学习强化学习”（演示，多伦多大学机器学习组），[*https://oreil.ly/Fgmck*](https://oreil.ly/Fgmck)。
- en: '^([55](ch03.html#ch03fn56-marker)) “Epsilon Greedy Policy,” Machine Learning
    Glossary: Reinforcement Learning, accessed October 23, 2023, [*https://oreil.ly/jHrup*](https://oreil.ly/i0A2J).'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: ^([55](ch03.html#ch03fn56-marker)) “ε贪婪策略”，机器学习词汇表：强化学习，访问于2023年10月23日，[*https://oreil.ly/jHrup*](https://oreil.ly/jHrup)。
- en: ^([56](ch03.html#ch03fn57-marker)) “What Is OCR (Optical Character Recognition)?”
    Amazon Web Services, accessed October 24, 2023, [*https://oreil.ly/0ms_Z*](https://oreil.ly/0ms_Z).
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: ^([56](ch03.html#ch03fn57-marker)) “什么是OCR（光学字符识别）？”亚马逊网络服务，访问于2023年10月24日，[*https://oreil.ly/0ms_Z*](https://oreil.ly/0ms_Z)。
- en: ^([57](ch03.html#ch03fn58-marker)) Unless you have some truly creative twist,
    but even so, you might have better ROI using a less-clichéd dataset.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: ^([57](ch03.html#ch03fn58-marker)) 除非你有一些真正有创意的转折，但即便如此，使用一个不那么陈词滥调的数据集可能会有更好的投资回报。
- en: ^([58](ch03.html#ch03fn59-marker)) “Overview of GAN Structure,” Machine Learning,
    Google for Developers, July 18, 2022, [*https://oreil.ly/EfpSR*](https://oreil.ly/EfpSR).
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: ^([58](ch03.html#ch03fn59-marker)) “GAN结构概述”，机器学习，Google开发者，2022年7月18日，[*https://oreil.ly/EfpSR*](https://oreil.ly/EfpSR)。
- en: ^([59](ch03.html#ch03fn60-marker)) Jascha Sohl-Dickstein et al., “Deep Unsupervised
    Learning Using Nonequilibrium Thermodynamics” (2015), [*https://oreil.ly/0Zp8Q*](https://oreil.ly/0Zp8Q).
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: ^([59](ch03.html#ch03fn60-marker)) Jascha Sohl-Dickstein 等，“利用非平衡热力学进行深度无监督学习”（2015），[*https://oreil.ly/0Zp8Q*](https://oreil.ly/0Zp8Q)。
- en: ^([60](ch03.html#ch03fn61-marker)) Marc Levoy and Yael Pritch, “Portrait Mode
    on the Pixel 2 and Pixel 2 XL Smartphones,” *Google Research* (blog), October
    17, 2017, [*https://oreil.ly/VdtgX*](https://oreil.ly/VdtgX).
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: ^([60](ch03.html#ch03fn61-marker)) Marc Levoy 和 Yael Pritch，“Pixel 2 和 Pixel
    2 XL 智能手机上的肖像模式”，*Google Research*（博客），2017年10月17日，[*https://oreil.ly/VdtgX*](https://oreil.ly/VdtgX)。
- en: ^([61](ch03.html#ch03fn62-marker)) Larry Hardesty, “How Computer Vision Will
    Help Amazon Customers Shop Online,” *Amazon Science* (blog), June 5, 2020, [*https://oreil.ly/xGyam*](https://oreil.ly/xGyam).
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: ^([61](ch03.html#ch03fn62-marker)) Larry Hardesty，“计算机视觉如何帮助亚马逊顾客在线购物”，*Amazon
    Science*（博客），2020年6月5日，[*https://oreil.ly/xGyam*](https://oreil.ly/xGyam)。
- en: ^([62](ch03.html#ch03fn63-marker)) “How Facebook Is Using AI to Improve Photo
    Descriptions for People Who Are Blind or Visually Impaired,” *AI at Meta* (blog),
    January 19, 2021, [*https://oreil.ly/_3YYj*](https://oreil.ly/_3YYj).
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: ^([62](ch03.html#ch03fn63-marker)) “Facebook 如何利用 AI 改善盲人或视觉障碍人士的照片描述”，*AI at
    Meta*（博客），2021年1月19日，[*https://oreil.ly/_3YYj*](https://oreil.ly/_3YYj)。
- en: '^([63](ch03.html#ch03fn64-marker)) “Ava: The Art and Science of Image Discovery
    at Netflix,” *Netflix Technology Blog*, Medium, February 7, 2018, [*https://oreil.ly/3S9NZ*](https://oreil.ly/3S9NZ).'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '^([63](ch03.html#ch03fn64-marker)) “Ava: 在 Netflix 上的图像发现的艺术与科学”，*Netflix Technology
    Blog*，Medium，2018年2月7日，[*https://oreil.ly/3S9NZ*](https://oreil.ly/3S9NZ)。'
- en: '[*OceanofPDF.com*](https://oceanofpdf.com)'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '[*OceanofPDF.com*](https://oceanofpdf.com)'
