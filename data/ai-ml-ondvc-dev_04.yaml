- en: Chapter 4\. Computer Vision Apps with ML Kit on Android
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章 计算机视觉应用程序与 ML Kit 在 Android 上
- en: '[Chapter 3](ch03.html#introduction_to_ml_kit) gave you an introduction to ML
    Kit and how it can be used for face detection in a mobile app. But ML Kit is far
    more than that—it gives you the ability to rapidly prototype common vision scenarios,
    host custom models, or implement other turnkey solution scenarios such as barcode
    detection also. In this chapter, we will explore some of the models that are available
    in ML Kit to provide computer vision scenarios, including image labeling and classification,
    and object detection in both still and moving images. We’ll do this on Android,
    using Kotlin as the programming language. [Chapter 6](ch06.html#computer_vision_apps_with_ml_kit_on_ios)
    will cover the equivalent content using Swift for iOS development.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '[第三章](ch03.html#introduction_to_ml_kit)向你介绍了 ML Kit 及其如何在移动应用程序中用于人脸检测。但是 ML
    Kit 不仅仅如此——它还能让你快速原型化常见的视觉场景、托管自定义模型或实施其他即插即用的解决方案场景，例如条形码检测。在这一章中，我们将探讨 ML Kit
    中提供的一些模型，以提供计算机视觉场景，包括图像标签化、分类以及静态和动态图像中的对象检测。我们将在 Android 上使用 Kotlin 作为编程语言进行这些操作。[第六章](ch06.html#computer_vision_apps_with_ml_kit_on_ios)将使用
    Swift 来实现 iOS 开发中的相应内容。'
- en: Image Labeling and Classification
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像标签化和分类
- en: The concept of image classification is a well-known one in machine learning
    circles, and the staple of computer vision. In its simplest sense, image classification
    happens when you show an image to a computer and it tells you what that image
    contains. For example, you show it a picture of a cat, like that in [Figure 4-1](#an_image_of_a_cat),
    and it will label it as a cat.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类的概念在机器学习领域是众所周知的，并且是计算机视觉的基石。简单来说，图像分类发生在你向计算机展示一幅图像时，它告诉你图像包含的内容。例如，你向它展示一张猫的图片，就像[图 4-1](#an_image_of_a_cat)中的那样，它会将其标记为猫。
- en: Image labeling in ML Kit takes this a little further and gives you a list of
    things seen in the image with levels of probability, so instead of [Figure 4-1](#an_image_of_a_cat)
    just showing a cat, it might say that it sees a cat, flowers, grass, daisies,
    and more.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ML Kit 中进行图像标签化会进一步扩展，并为你提供图像中看到的物体列表及其概率级别，因此，与[图 4-1](#an_image_of_a_cat)只显示一只猫不同，它可能会显示它看到了猫、花、草、雏菊等等。
- en: Let’s explore how to create a very simple Android app that can label this image!
    We’ll use Android Studio and Kotlin. If you don’t have them already, you can download
    them at [*https://developer.android.com/studio/*](https://developer.android.com/studio/).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来探索如何创建一个非常简单的 Android 应用程序来标记这张图片！我们将使用 Android Studio 和 Kotlin。如果你还没有它们，你可以在
    [*https://developer.android.com/studio/*](https://developer.android.com/studio/)
    下载它们。
- en: '![](assets/aiml_0401.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0401.png)'
- en: Figure 4-1\. An image of a cat
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1\. 一张猫的图片
- en: 'Step 1: Create the App and Configure ML Kit'
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步：创建应用程序并配置 ML Kit
- en: 'If you haven’t gone through [Chapter 3](ch03.html#introduction_to_ml_kit) yet,
    or if you aren’t familiar with getting up and running with an Android app, I’d
    recommend that you do! Once you’ve created the app, you’ll need to edit your build.gradle
    file as demonstrated in that chapter. However, in this case, instead of adding
    the face detection libraries, you’ll need to add the image labeling ones, like
    this:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有阅读过[第三章](ch03.html#introduction_to_ml_kit)，或者对于如何启动并运行 Android 应用程序不太熟悉，我建议你现在去看看！一旦你创建了应用程序，你需要像第三章中演示的那样编辑你的
    build.gradle 文件。但在这种情况下，你需要添加图像标签库，而不是添加人脸检测库，如下所示：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once you’ve done this, Android Studio will likely ask you to sync given that
    your Gradle files have changed. This will trigger a build with the new ML Kit
    dependencies included.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成这些步骤，Android Studio 可能会要求你同步，因为你的 Gradle 文件已更改。这将触发包含新的 ML Kit 依赖项的构建。
- en: 'Step 2: Create the User Interface'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二步：创建用户界面
- en: We’ll just create a super simple UI for this app to allow us to get straight
    down to using the image labeling. In your res->layout directories within Android
    View you’ll see a file called *activity_main.xml*. Refer back to [Chapter 3](ch03.html#introduction_to_ml_kit)
    if this isn’t familiar.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为这个应用程序创建一个非常简单的超级简单的用户界面，以便我们可以直接开始使用图像标签。在 Android View 中的 res->layout
    目录中，你会看到一个名为 *activity_main.xml* 的文件。如果这不熟悉，请参考[第三章](ch03.html#introduction_to_ml_kit)。
- en: 'Update the UI to contain a linear layout with an ImageView, a Button, and a
    TextView like this:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 更新 UI 以包含一个线性布局，其中包括一个 ImageView、一个 Button 和一个 TextView，就像这样：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: At runtime, the ImageView will load an image, and when the user presses the
    button, ML Kit will be invoked to get image label data back for the displayed
    image. The results will be rendered in the TextView. You can see this in [Figure 4-3](#running_the_app_with_an_image_loaded)
    a little later.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行时，ImageView 将加载一张图像，当用户按下按钮时，ML Kit 将被调用以获取显示图像的图像标签数据。结果将在 TextView 中呈现。稍后您可以在
    [图 4-3](#running_the_app_with_an_image_loaded) 中看到这一点。
- en: 'Step 3: Add the Images as Assets'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '步骤 3: 添加图片作为资源'
- en: Within your project, you’ll need an assets folder. Again, if you aren’t familiar
    with this step, check back to [Chapter 3](ch03.html#introduction_to_ml_kit), where
    you’ll be stepped through the process. Once you have an assets folder and have
    added some images to it, you’ll see them in Android Studio. See [Figure 4-2](#images_in_the_assets_folder).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的项目中，您需要一个资产文件夹。如果您对此步骤不熟悉，请返回第 [3章](ch03.html#introduction_to_ml_kit)，在那里您将逐步了解该过程。一旦您有了一个资产文件夹并添加了一些图像，您将在
    Android Studio 中看到它们。参见 [图 4-2](#images_in_the_assets_folder)。
- en: '![](assets/aiml_0402.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0402.png)'
- en: Figure 4-2\. Images in the assets folder
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. 资产文件夹中的图像
- en: 'Step 4: Load an Image to the ImageView'
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '步骤 4: 将图像加载到 ImageView 中'
- en: 'Now let’s write some code! We can go to the *MainActivity.kt* file, and within
    that add an extension that lets us load images from the assets folder as bitmaps:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来写一些代码吧！我们可以转到 *MainActivity.kt* 文件，并在其中添加一个扩展，使我们能够从资产文件夹加载图像作为位图：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, update the `onCreate` function that was made for you by Android Studio
    to find the ImageView control based on its ID, and load one of the images from
    the assets folder into it:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，更新由 Android Studio 为您创建的 `onCreate` 函数，以根据其 ID 查找 ImageView 控件，并将位于资产文件夹中的图像加载到其中：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can run your app now to test if it loads the image properly. If it does,
    you should see something like [Figure 4-3](#running_the_app_with_an_image_loaded).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以运行应用程序，测试它是否正确加载图像。如果正确，您应该会看到类似于 [图 4-3](#running_the_app_with_an_image_loaded)
    的内容。
- en: '![](assets/aiml_0403.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0403.png)'
- en: Figure 4-3\. Running the app with an image loaded
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-3\. 运行带有加载图像的应用程序
- en: Pressing the button won’t do anything yet because we haven’t coded it. Let’s
    do that next!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 按钮目前不会做任何事情，因为我们还没有编写代码。接下来让我们来做这件事吧！
- en: 'Step 5: Write the Button Handler Code'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '步骤 5: 编写按钮处理程序代码'
- en: 'Let’s start by writing code to give us variables that can represent the text
    view (for writing out the labels) as well as the button itself:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从编写代码开始，获取可以表示文本视图（用于输出标签）和按钮本身的变量：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now that we have the button, we can create a button handler for it. This will
    be achieved by typing `btn.setOnClickListener`; autocomplete will create a stub
    function for you. Then, you can update it for image labeling with this complete
    code. We’ll go through it piece by piece next:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了按钮，我们可以为它创建一个按钮处理程序。这可以通过键入 `btn.setOnClickListener` 来实现；自动完成将为您创建一个存根函数。然后，您可以使用以下完整代码来进行图像标签处理。接下来我们将逐步讲解它：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'When the user clicks the button, this code will create an image labeler from
    ML Kit with default options like this:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户点击按钮时，此代码将使用默认选项从 ML Kit 中创建一个图像标签处理器，如下所示：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once it has done this, it will then create an image object (which ML Kit can
    understand) from the bitmap (used to display the image) with this code:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成此操作，它将使用此代码从位图（用于显示图像）创建一个图像对象（可以由 ML Kit 理解）：
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The labeler will be called to process the image, with two listeners added to
    it. A *success* listener will fire if the processing was successful, and a *failure*
    listener if it wasn’t. When an image labeler succeeds, it will return a list of
    *labels*. These labels will have a text property with text describing the label,
    and a confidence property with a value from 0 to 1 containing the probability
    that the labeled item is present.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 标签处理器将被调用来处理图像，并添加了两个监听器。*成功* 监听器在处理成功时触发，*失败* 监听器在处理失败时触发。当图像标签处理器成功时，它将返回一个*标签*列表。这些标签将具有一个文本属性，其中包含描述标签的文本，以及一个置信度属性，其值从
    0 到 1，表示标签存在的概率。
- en: 'So, within the success listener, the code will parse through the full list
    of labels, and add the text and confidence to a variable called `outputText`.
    Once it has completed, it can then set the text property of the TextView (now
    called `txtOutput`) to the value of the `outputText` variable:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在成功监听器中，代码将遍历标签列表，并将文本和置信度添加到名为 `outputText` 的变量中。完成后，它可以将 TextView 的文本属性（现在称为
    `txtOutput`）设置为 `outputText` 变量的值：
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It’s really as simple as that. Running the app with the cat image from earlier
    in this chapter will then give you output like [Figure 4-4](#labeling_the_image_from_earlier_in_this).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这么简单。使用本章早些时候的猫图像运行应用程序，您将会得到类似于 [图 4-4](#labeling_the_image_from_earlier_in_this)
    的输出。
- en: '![](assets/aiml_0404.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0404.png)'
- en: Figure 4-4\. Labeling the image from earlier in this chapter
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-4\. 标记本章前面的图像
- en: Next Steps
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步
- en: The built-in image labeling model from ML Kit recognizes over 400 classes within
    an image. At the time of writing it was 447, but this may change. The full label
    map for ML Kit is published at [*https://developers.google.com/ml-kit/vision/image-labeling/label-map*](https://developers.google.com/ml-kit/vision/image-labeling/label-map)*.*
    Should you want to train a model to recognize *different* classes you’ll use TensorFlow,
    which we’ll explore in [Chapter 9](ch09.html#creating_custom_models).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit 内置的图像标记模型能够识别图像中的超过 400 个类别。在撰写本文时，共有 447 个类别，但这可能会改变。ML Kit 的完整标签映射发布在
    [*https://developers.google.com/ml-kit/vision/image-labeling/label-map*](https://developers.google.com/ml-kit/vision/image-labeling/label-map)*.*
    如果您想训练一个模型来识别*不同*的类别，您将使用 TensorFlow，在[第 9 章](ch09.html#creating_custom_models)中我们将探讨这一点。
- en: Object Detection
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 物体检测
- en: The previous section showed you how to do image classification and labeling
    where the computer was able to detect *what* was in an image, but not necessarily
    *where* the item was within the image. The concept of o*bject detection* is used
    here. In this case, when you pass an image to the object detector, you’ll get
    back a list of objects, including *bounding boxes* that may be used to determine
    where in the image the object may be. The ML Kit default model for object detection
    is excellent at picking out objects in an image, but the number of classes it
    can classify is limited to only five before you need to use a custom model. However,
    when combining it with image labeling (previous section), you can get a classification
    of the individual objects within the image to get labels for them! You can see
    an example of this in [Figure 4-5](#performing_object_detection).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节向您展示了如何进行图像分类和标记，在这种情况下，计算机能够检测图像中的*内容*，但不一定能确定物体在图像中的*位置*。这里使用了*对象检测*的概念。在这种情况下，当您将图像传递给对象检测器时，您将获得一个包含*边界框*的对象列表，这些边界框可用于确定物体可能在图像中的位置。ML
    Kit 的默认对象检测模型非常擅长在图像中检测物体，但它只能分类五种类别之后，您需要使用自定义模型。然而，当与图像标记（前一节）结合使用时，您可以获得图像中各个物体的分类标签！您可以在[图
    4-5](#performing_object_detection)中看到一个示例。
- en: '![](assets/aiml_0405.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0405.png)'
- en: Figure 4-5\. Performing object detection
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-5\. 执行物体检测
- en: Let’s look at this step by step.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步来看。
- en: 'Step 1: Create the App and Import ML Kit'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '步骤 1: 创建应用程序并导入 ML Kit'
- en: Create the app as before as a single view application. We’ll try to keep this
    as similar to the image labeling app you’ve already built so that things can be
    familiar.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 创建应用程序时要像之前一样创建一个单视图应用程序。我们将尽量保持与您已经构建的图像标记应用程序相似，以便事物看起来更加熟悉。
- en: 'When you’re done, edit your build.gradle file to use both object detection
    and image labeling, like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，请编辑您的 build.gradle 文件，以像这样同时使用物体检测和图像标记：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Your version numbers may be different, so check the latest at [*https://developers.google.com/ml-kit*](https://developers.google.com/ml-kit)*.*
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 您的版本号可能不同，请检查最新版本信息 [*https://developers.google.com/ml-kit*](https://developers.google.com/ml-kit)*.*
- en: 'Step 2: Create the Activity Layout XML'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '步骤 2: 创建活动布局 XML'
- en: The layout file for the activity is super simple and exactly the same as what
    we saw earlier. You’ll have a LinearLayout that lays out an ImageView, a Button,
    and a TextView. The ImageView will display the image, the Button will run the
    object detection and labeling code, and the TextView will render the results of
    the labeling. Instead of relisting the code here, just use the same layout code
    as the previous example.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 该活动的布局文件非常简单，与之前看到的完全相同。您将拥有一个 LinearLayout，用于布局 ImageView、Button 和 TextView。ImageView
    将显示图像，Button 将运行物体检测和标记代码，TextView 将呈现标签的结果。而不是在此重新列出代码，只需使用与前面示例相同的布局代码。
- en: 'Step 3: Load an Image into the ImageView'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '步骤 3: 将图像加载到 ImageView 中'
- en: 'As before, you’ll use an extension to load an image from the assets folder
    into the ImageView. For convenience, I’ve repeated the code to do that here:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，您将使用扩展来从资产文件夹加载图像到 ImageView 中。为方便起见，我在此重复了执行此操作的代码：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Create an assets folder like before, and put some images in it. For the screenshot
    in [Figure 4-5](#performing_object_detection), I used an image from [Pixabay](https://oreil.ly/TnCR6),
    which I renamed to *bird.jpg* for easier code.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 像之前一样创建一个资产文件夹，并在其中放置一些图像。对于图[4-5](#performing_object_detection)中的屏幕截图，我使用了来自[Pixabay](https://oreil.ly/TnCR6)的图像，并将其重命名为*bird.jpg*以便于代码处理。
- en: 'Then, within the `onCreate` function, you can get the image from the assets
    using the preceding extension function and load it into your bitmap like this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在`onCreate`函数中，你可以使用前面的扩展函数从资产中获取图像，并像这样加载到你的位图中：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You can also set up the Button and TextView controls like this:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以像这样设置按钮和TextView控件：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Step 4: Set Up the Object Detector Options'
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4步：设置对象检测选项
- en: 'You’ll use a number of ML Kit classes in this section. Here are the imports:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将使用多个ML Kit类。以下是导入：
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The ML Kit object detector gives you a variety of ways to do object detection,
    and these are controlled by an `ObjectDetectorOptions` object. We will use it
    in one of its simplest modes, which is to detect based on a single image and enable
    detecting multiple objects within that image:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit对象检测器提供了多种进行对象检测的方法，这些方法由`ObjectDetectorOptions`对象控制。我们将在其最简单的模式之一中使用它，即基于单个图像进行检测并启用在该图像中检测多个对象的功能。
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The object detector is a powerful API, which can also do things like tracking
    objects in a video stream—detecting them and maintaining them from frame to frame.
    That’s beyond the scope of what we’re doing in this book, but you can learn more
    about it in the [ML Kit documentation](https://oreil.ly/kluVJ).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对象检测器是一个强大的API，还可以执行诸如在视频流中跟踪对象等操作——从帧到帧检测和维护它们。这超出了我们在本书中所做的范围，但您可以在[ML Kit文档](https://oreil.ly/kluVJ)中了解更多信息。
- en: The mode option is used to determine this—you can learn more about the `SINGLE_IMAGE_MODE`
    used in this example at [*https://oreil.ly/WFSZD*](https://oreil.ly/WFSZD).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 模式选项用于确定此操作，你可以在此示例中了解更多关于`SINGLE_IMAGE_MODE`的信息[*https://oreil.ly/WFSZD*](https://oreil.ly/WFSZD)。
- en: Additionally, the object detector can be enabled to detect the most prominent
    object, or all objects within the scene. We’ve set it here to detect multiple
    objects (using `.enableMultipleObjects()` ), so we can see multiple items as demonstrated
    in [Figure 4-5](#performing_object_detection).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对象检测器可以启用以检测场景中最显著的对象或所有对象。我们在这里设置为检测多个对象（使用`.enableMultipleObjects()`），因此我们可以看到多个项目，如图[4-5](#performing_object_detection)所示。
- en: Another common option is to enable classification. As the default object detector
    can only detect five classes of object, and it gives them a very generic label,
    I haven’t turned it on here, and we will “roll our own” labeling of the objects
    using the image labeling APIs discussed earlier in the chapter. If you want to
    use more than the base five classes of object, you can do so with a custom TensorFlow
    model, and we’ll explore using custom models in Chapters [9](ch09.html#creating_custom_models)
    through [11](ch11.html#using_custom_models_in_ios).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见选项是启用分类。由于默认对象检测器只能检测五类对象，并为它们提供非常通用的标签，我在这里没有打开它，而是使用了本章前面讨论的图像标签API“自己动手”标记对象。如果您想使用超过五类基本对象，可以使用自定义TensorFlow模型，我们将在第[9](ch09.html#creating_custom_models)章到第[11](ch11.html#using_custom_models_in_ios)章中探讨使用自定义模型。
- en: 'Step 5: Handling the Button Interaction'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5步：处理按钮交互
- en: 'When the user touches the button, you’ll want to invoke the object detector,
    get its response, and from there get the bounding boxes for the objects within
    the image. Later we’ll also use those bounding boxes to crop the image into the
    subimage defined by the bounding box, so we can pass that to the labeler. But
    for now, let’s just implement the object detection handler. It should look something
    like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户触摸按钮时，您将希望调用对象检测器，获取其响应，并从中获取图像中对象的边界框。稍后我们还将使用这些边界框将图像裁剪为由边界框定义的子图像，以便传递给标签器。但现在，让我们先实现对象检测处理程序。它应该看起来像这样：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: So, similar to what you did earlier with image labeling, the pattern is to create
    an instance of the object detection API with the options. You’ll then convert
    the bitmap into an `InputImage`, and process this with the object detector.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，类似于您之前对图像标签化所做的操作，模式是使用选项创建对象检测API的实例。然后，您将位图转换为`InputImage`，并使用对象检测器处理它。
- en: This will return on success with a list of detected objects, or on failure with
    an exception object.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 成功时返回检测到的对象列表，或者失败时返回异常对象。
- en: The `detectedObjects` returned to the `onSuccessListener` will contain details
    about the object including its bounding boxes. So let’s next create a function
    to draw the bounding boxes on the image.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`onSuccessListener`返回的`detectedObjects`将包含关于对象的详细信息，包括其边界框。接下来，让我们创建一个函数在图像上绘制边界框。'
- en: 'Step 6: Draw the Bounding Boxes'
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 6：绘制边界框
- en: The easiest way is to extend the `Bitmap` object to draw rectangles on top of
    it using a `Canvas`. We’ll pass the detected object to this, so it can establish
    the bounding boxes, and from there draw them on top of the bitmap.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法是扩展`Bitmap`对象，使用`Canvas`在其上绘制矩形。我们将检测到的对象传递给它，以便它可以建立边界框，并从那里在位图的顶部绘制它们。
- en: 'Here’s the complete code:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这是完整的代码：
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The code will first create a copy of the bitmap, and a new `Canvas` based on
    it. It will then iterate through all of the detected objects.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将首先创建位图的副本，并基于它创建一个新的`Canvas`。然后，它将遍历所有检测到的对象。
- en: 'The bounding box returned by ML Kit for the object is in the `boundingBox`
    property, so you can get its details with:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit返回的对象的边界框位于`boundingBox`属性中，因此您可以使用以下代码获取其详细信息：
- en: '[PRE17]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This can then be used to draw a bounding box using a `Paint` object on the
    canvas like this:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以使用`Paint`对象在画布上绘制边界框，如下所示：
- en: '[PRE18]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The rest of the code just handles things like the color of the rectangle and
    the size and color of the text, which just contains a number, and as you saw in
    [Figure 4-5](#performing_object_detection), we write 1, 2, 3 on the boxes in the
    order in which they were detected.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的其余部分只处理诸如矩形的颜色、文本的大小和颜色等事务，文本只包含一个数字，如您在[图 4-5](#performing_object_detection)中看到的那样，我们按照检测顺序在框上写下
    1、2、3。
- en: 'You then call this function within the `onSuccessListener` like this:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以像这样在`onSuccessListener`中调用此函数：
- en: '[PRE19]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: So, upon a successful return from ML Kit, you’ll now have bounding boxes drawn
    on the images. Given the limitations of the object detector, you won’t get very
    useful labels for these boxes, so in the next step, you’ll see how to use image
    labeling calls to get the details for what is within the bounding box.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在ML Kit成功返回后，您现在会在图像上看到绘制的边界框。考虑到对象检测器的限制，您将不会为这些框获得非常有用的标签，因此在下一步中，您将看到如何使用图像标签调用来获取边界框内内容的详细信息。
- en: 'Step 7: Label the Objects'
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 7：标记对象
- en: The base model, for simplicity, only handles five very generic classes when
    it comes to labeling the contents of the image. You could use a custom model that
    is trained on more, or you could use a simple multistep solution. The process
    is simple—you already have the bounding boxes, so create a *new* temporary image
    with just what’s within a bounding box, pass that to the image labeler, and then
    get the results back. Repeat this for each bounding box (and thus each object),
    and you’ll get detailed labels for each detected object!
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 简单起见，基本模型仅处理五个非常通用的类别来标记图像内容。您可以使用训练更多类别的自定义模型，或者您可以使用简单的多步解决方案。该过程很简单——您已经有了边界框，所以创建一个*新*的临时图像，其中仅包含边界框内的内容，将其传递给图像标签器，然后获取结果。对于每个边界框（因此每个对象）重复此过程，您将获得每个检测到对象的详细标签！
- en: 'Here’s the complete code:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这是完整的代码：
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This code loops through each of the detected objects and uses the bounding box
    to create a new bitmap called `croppedBitmap`. It will then use an image labeler
    (called `labeler`) that is set up with default options to process that new image.
    On a successful return it will have a number of labels, which it will then write
    into a comma-separated string that will be rendered in `txtOutput`. I’ve noticed
    occasionally that even though it succeeds in labeling, it returns an empty labeled
    list, so I added code to only construct the string if there are labels within
    the return.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码循环遍历每个检测到的对象，并使用边界框创建一个名为`croppedBitmap`的新位图。然后，它将使用设置为默认选项的图像标签器（称为`labeler`）处理该新图像。在成功返回后，它将获得多个标签，然后将这些标签写入以逗号分隔的字符串中，该字符串将在`txtOutput`中呈现。我注意到，即使成功标记，有时也会返回一个空的标记列表，因此我添加了代码，仅在返回的标签中存在标签时才构造字符串。
- en: 'To call this function, just add this code to the `onSuccessListener` for the
    o*bject detection* call, immediately after where you called the code to set the
    rectangles on the bitmap:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要调用此函数，只需将此代码添加到`onSuccessListener`中，用于对象检测调用，在调用代码设置位图上的矩形之后立即添加：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: When running this code, you are making a number of asynchronous calls, first
    to the object detector, and later to the image labeler. As a result, you’ll likely
    see delayed behavior after pressing the button. You’ll likely see the bounding
    boxes drawn first, and then a few moments later the list of labels will be updated.
    Android and Kotlin offer a lot of asynchronous functionality to make the user
    experience here a bit better, but they’re beyond the scope of this book, as I
    wanted to keep the example simple and focused on what you can do with the functionality
    present in ML Kit.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码时，您正在进行多个异步调用，首先是对象检测器，然后是图像标签器。因此，按下按钮后，您可能会看到延迟行为。您可能会首先看到绘制的边界框，然后几分钟后更新标签列表。Android和Kotlin提供了许多异步功能，以使用户体验更好，但这超出了本书的范围，因为我想保持示例简单，并专注于ML
    Kit中现有功能的使用。
- en: Detecting and Tracking Objects in Video
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在视频中检测和跟踪对象
- en: The ML Kit object detector can also operate on video streams, giving you the
    ability to detect objects in a video *and* track that object in successive video
    frames. For example, see [Figure 4-6](#using_a_video_based_object_detector), where
    I moved the camera across a scene, and the Android figurine was not only detected,
    and a bounding box given, but a tracking ID was assigned. While the object stayed
    in the field of view, subsequent frames get different bounding boxes based on
    the new position, but the tracking ID is maintained—i.e., it was recognized as
    the *same* object despite looking different because of the placement within the
    frame and the different camera angle.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit对象检测器还可以在视频流上运行，使您能够在视频中检测对象并在连续视频帧中跟踪该对象。例如，请参阅[图4-6](#using_a_video_based_object_detector)，我在场景中移动相机，Android小人不仅被检测到，并给出了边界框，还分配了跟踪ID。虽然对象保持在视野中，但根据新位置，后续帧会获得不同的边界框，但跟踪ID保持不变——也就是说，尽管由于放置在帧内和不同的摄像头角度而看起来不同，但它被识别为*同一*对象。
- en: We’ll explore how an app like this can be built using ML Kit in this section.
    Note that to test this you should use a physical device—the nature of moving the
    camera around to track devices doesn’t translate well to using the emulator.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨如何使用ML Kit构建这样的应用程序。请注意，要测试此功能，您应该使用物理设备——将摄像头移动以跟踪设备的性质不适合使用模拟器。
- en: There are a lot of steps in building an app like this that aren’t ML-specific,
    like handling CameraX, using an overlay, and managing drawing of the boxes between
    frames, etc., that I won’t go into in depth in this chapter, but the book download
    has the complete code that you can dissect.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样构建应用程序还有很多步骤不是ML特定的，比如处理CameraX、使用覆盖层以及在帧之间管理绘制框等等，我在本章不会深入讨论，但书籍下载包含了您可以剖析的完整代码。
- en: '![](assets/aiml_0406.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![AIML_0406](assets/aiml_0406.png)'
- en: Figure 4-6\. Using a video-based object detector
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-6。使用基于视频的对象检测器
- en: Exploring the Layout
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索布局
- en: Naturally, the layout of an app like the preceding is a little more complex
    than what we’ve been seeing. It needs you to draw a camera preview, and then,
    on top of the preview, to draw bounding boxes that update in near real time as
    you move the camera around the frame to track the object. In this app I used CameraX,
    a support library in Android that is designed to make using the camera much easier—and
    it did! You can learn more about CameraX at [*https://developer.android.com/training/camerax*](https://developer.android.com/training/camerax).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，像前述应用程序这样的布局比我们看到的要复杂一些。它需要您绘制相机预览，然后在预览的顶部绘制边界框，这些边界框在您移动相机以跟踪对象时几乎实时更新。在此应用程序中，我使用了CameraX，这是Android中的一个支持库，旨在更轻松地使用相机——确实如此！您可以在[*https://developer.android.com/training/camerax*](https://developer.android.com/training/camerax)了解更多关于CameraX的信息。
- en: 'Repeat the earlier steps for creating a new Android app. When ready, open the
    layout file and edit it. For an app like this, you’ll need to use a FrameLayout,
    which is typically only used for a single item, to block out a particular area
    of the screen for it, but I like using it in a circumstance like this, where I
    have two items but one will completely overlay the other:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 重复前面创建新Android应用程序的步骤。准备就绪后，打开布局文件并进行编辑。对于这样的应用程序，您需要使用FrameLayout，通常只用于单个项目，以阻挡屏幕的特定区域，但我喜欢在像这样的情况下使用它，其中我有两个项目，但一个将完全覆盖另一个：
- en: '[PRE22]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Within the FrameLayout, the first control is the `androidx.camera.view.PreviewView`
    on which the stream of video from the camera will be rendered. On top of this
    is a custom control called a `GraphicOverlay`, which, as its name suggests, provides
    an overlay on top of the Preview on which graphics can be drawn. This overlay
    control has been adapted from the [open source ML Kit sample](https://oreil.ly/csyn9).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在FrameLayout内，第一个控件是`androidx.camera.view.PreviewView`，在此控件上将呈现来自相机的视频流。在其上方是一个名为`GraphicOverlay`的自定义控件，正如其名称所示，它在预览的顶部提供一个可以绘制图形的覆盖层。这个覆盖层控件已经从[开源ML
    Kit示例](https://oreil.ly/csyn9)中进行了适配。
- en: Note that in the listing I’m calling the `GraphicOverlay com.odmlbook.liveobjectdetector.GraphicOverlay`;
    this is because the `GraphicOverlay` from the preceding Google sample was added
    directly to my app, and I’m using my app’s namespace. You’ll likely have a different
    namespace, so be sure to use the correct naming for your `GraphicOverlay`.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在列表中我称呼了`GraphicOverlay com.odmlbook.liveobjectdetector.GraphicOverlay`；这是因为前面Google示例中的`GraphicOverlay`直接添加到了我的应用程序中，并且我正在使用我的应用程序命名空间。你可能会有不同的命名空间，因此请确保使用你的GraphicOverlay的正确命名。
- en: I’ve kept the layout as simple as possible so you can focus on the aspects of
    object detection—so that’s pretty much it—a preview for CameraX on top of which
    is a GraphicOverlay on which you can draw the bounding boxes. You’ll see more
    of this a little later.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我将布局保持尽可能简单，以便你可以专注于对象检测的各个方面——所以基本上就是这样——CameraX的预览，在其上是一个GraphicOverlay，你可以在这个GraphicOverlay上绘制边界框。稍后你会看到更多相关内容。
- en: The GraphicOverlay Class
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GraphicOverlay类
- en: 'In the layout you saw a custom `GraphicOverlay` class. It’s the job of this
    class to manage a collection of graphic objects—which will be made up of the bounding
    boxes and their labels—and draw them on a canvas. One thing to note is that often
    you’ll encounter differences between coordinates between the camera preview (at
    the camera’s resolution) and a canvas that’s placed on top of it (at the screen
    resolution) like in this case. Thus, a coordinate translation may also be necessary
    for you to draw on top of the preview in the appropriate place. You can find the
    code for that, as well as for managing performance of drawing graphics when operating
    frame by frame, in the `GraphicOverlay` class. The bounding boxes, represented
    as graphic objects, will simply be added in the `onDraw` event:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在布局中，你看到了一个自定义的`GraphicOverlay`类。这个类的作用是管理一组图形对象——包括边界框及其标签，并在画布上绘制它们。需要注意的一点是，通常情况下，你会在相机预览（以相机分辨率显示）和放置在其上方的画布（以屏幕分辨率显示）之间遇到坐标差异，就像在这种情况下一样。因此，可能还需要进行坐标转换，以便在预览上方的适当位置进行绘制。你可以在`GraphicOverlay`类中找到用于管理逐帧操作时绘制图形性能的代码。边界框，表示为图形对象，将简单地在`onDraw`事件中添加：
- en: '[PRE23]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Capturing the Camera
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 捕获相机
- en: When using CameraX, you access a camera provider, which will then allow you
    to set various subproviders on it, including a *surface* provider that lets you
    define where to put the preview, as well as an *analyzer* that lets you do stuff
    with the frames that come in from the camera. These are perfect for our needs—the
    surface provider can give us the preview window, and the analyzer can be used
    to call the ML Kit object detector. In the `MainActivity` for the app, you will
    find this code (in the `startCamera()` function).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CameraX时，你会访问一个相机提供者，该提供者允许你在其上设置各种子提供者，包括*surface*提供者，让你定义预览放置的位置，以及*analyzer*，让你对来自相机的帧进行处理。这些对我们的需求非常合适——surface提供者可以提供预览窗口，而analyzer可以用于调用ML
    Kit对象检测器。在应用程序的`MainActivity`中，你会在这段代码中找到这一点（在`startCamera()`函数中）。
- en: 'First, we set up the preview view (notice that the control in the layout listing
    was called `viewFinder`) to render the stream of frames from the camera:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们设置预览视图（注意，布局列表中的控件称为`viewFinder`），以渲染来自相机的帧流：
- en: '[PRE24]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next comes the image analyzer. CameraX calls this frame by frame, giving you
    the ability to do some kind of processing on the image. This is perfect for our
    needs. When you call `setAnalyzer`, you specify a class that will handle the analysis.
    Here I specified a class called `ObjectAnalyzer`, which, as its name suggests,
    will use the object detection APIs with the frame:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是图像分析器。CameraX会逐帧调用这个函数，让你能够对图像进行某种处理。这非常适合我们的需求。当你调用`setAnalyzer`时，你会指定一个处理分析的类。在这里，我指定了一个名为`ObjectAnalyzer`的类，正如其名称所示，它将使用对象检测API与帧一起使用：
- en: '[PRE25]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Then, once you have these, you can bind them to the life cycle of the camera
    so that CameraX knows to use them to render the preview and manage frame-by-frame
    processing respectively:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，一旦你拥有了这些，你可以将它们绑定到相机的生命周期中，以便CameraX知道要使用它们来渲染预览并管理逐帧处理：
- en: '[PRE26]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: You can learn more about the life cycle of camera applications using CameraX
    in the CameraX documentation. I just want to highlight the important parts when
    it comes to using object detection with it here.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在CameraX文档中了解有关使用CameraX的相机应用程序生命周期的更多信息。我只想在这里强调一下在使用它进行对象检测时的重要部分。
- en: The ObjectAnalyzer Class
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对象分析器类
- en: The full code for this class is in the [book’s repo](https://oreil.ly/WIQMR).
    I recommend you clone that and use it to understand how object analysis works
    for tracking objects in video. This section just shows the important parts of
    the code, and won’t really work for coding along!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类的完整代码在[书籍的代码库](https://oreil.ly/WIQMR)中。我建议你克隆它并使用它来理解如何在视频中跟踪对象的对象分析工作。本节只显示代码的重要部分，并不能真正用于编码！
- en: Earlier you saw that you could hook into CameraX’s analyzer ability to do the
    object detection, and we specified a class called `ObjectAnalyzer` to handle it.
    We also passed a reference to the graphic overlay to this class.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 之前你看到，你可以钩入CameraX的分析器能力来进行对象检测，并且我们指定了一个叫做`ObjectAnalyzer`的类来处理它。我们还将对这个类的图形叠加引用传递给了它。
- en: 'An analyzer class has to override `ImageAnalysis.Analyzer`, so the signature
    for this class should look something like:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一个分析器类必须重写`ImageAnalysis.Analyzer`，因此这个类的签名应该看起来像这样：
- en: '[PRE27]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'It’s the job of this class to do the object detection, so we’ll need to create
    our `ObjectDetector` instance as we did before:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类的工作是进行对象检测，所以我们需要像以前一样创建我们的`ObjectDetector`实例：
- en: '[PRE28]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note the difference in the detector mode setting though—`ObjectDetectorOptions.STREAM_MODE`—it’s
    now using *stream mode* because we’re going to be streaming images to it. This
    turns on the object tracking feature that we saw in [Figure 4-6](#using_a_video_based_object_detector)
    where it “remembers” the same object across different frames, even if it looks
    different because of camera placement.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意检测器模式设置的不同之处，虽然是`ObjectDetectorOptions.STREAM_MODE`——现在它正在使用*流模式*，因为我们将向其传送图像。这将启用我们在[图 4-6](#using_a_video_based_object_detector)中看到的对象跟踪功能，即使由于相机放置的不同而看起来不同，它也会“记住”相同的对象。
- en: 'When you create an analyzer class like this, you’ll need to override the function
    `analyze`, which takes an `ImageProxy` object representing the image. To use a
    CameraX image with the image proxy, there’s some processing you’ll need to do
    to manage the rotation, etc. I won’t go into the detail on that here, but the
    important thing to manage is if the camera is providing frames in landscape or
    portrait mode, in which case we need to inform the overlay about the appropriate
    height and width of the image, flipping them where necessary—so that the ML Kit
    API always receives images in the same orientation:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建一个像这样的分析器类时，你需要重写函数`analyze`，它接受一个代表图像的`ImageProxy`对象。为了使用CameraX图像与图像代理，你需要进行一些处理来管理旋转等问题。这里我不会详细说明，但需要重点管理的是，如果相机以横向或纵向模式提供帧，则我们需要通知叠加层有关图像的适当高度和宽度，并在必要时翻转它们——以便ML
    Kit API始终以相同的方向接收图像：
- en: '[PRE29]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, we can pass the frame to the object detector, and if we get success,
    the callback will have detected objects like before. At this point we should clear
    the overlay, and then add new graphic objects to the overlay for each of the detected
    objects. These graphic objects are a custom class within this app. You’ll see
    them in a moment. Once we’re done, we call `postInvalidate()` on the overlay,
    which will trigger a redraw of the overlay:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将帧传递给对象检测器，如果成功，回调将像以前一样检测到对象。在这一点上，我们应该清除叠加层，然后为每个检测到的对象向叠加层添加新的图形对象。这些图形对象是该应用程序中的自定义类。马上你会看到它们。完成后，我们在叠加层上调用`postInvalidate()`，这将触发叠加层的重绘：
- en: '[PRE30]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The ObjectGraphic Class
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对象图形类
- en: As the bounding boxes are composed of three elements—the box, the text of the
    label, and the background for the label—instead of just drawing each one of these
    individually, a single class is used to represent each. This class will be initialized
    using the `detectedObject` that is returned from ML Kit, so we can get the tracking
    ID and the coordinates of the bounding box. The `ObjectGraphic` class manages
    all of this—you can see it being used in the preceding code, where a new instance
    of it is created using the overlay and the `detectedObject`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 由于边界框由三个元素组成——框本身、标签的文本和标签的背景，所以不仅仅是单独绘制每一个，而是使用一个单一的类来表示每一个。这个类将使用从 ML Kit
    返回的 `detectedObject` 进行初始化，因此我们可以获取跟踪 ID 和边界框的坐标。`ObjectGraphic` 类管理所有这些——您可以在前面的代码中看到它的使用，其中使用覆盖层和
    `detectedObject` 创建了它的一个新实例。
- en: Putting It All Together
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将所有内容整合
- en: That’s generally how an app like this would work. Using CameraX, you specify
    a preview surface and an analyzer. The analyzer calls the ML Kit object detector
    with stream mode enabled. The detected objects that it returns are used to create
    objects that represent the bounding boxes, and these are added to the overlay.
    This uses the generic model in ML Kit, so there’s not much by way of classification—just
    that it detected an object and that object is assigned an ID. To further classify
    each object detected, you’ll need a custom model, and we’ll discuss that in [Chapter 9](ch09.html#creating_custom_models).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，这种应用的工作方式如下。使用 CameraX，您指定预览表面和分析器。分析器调用 ML Kit 对象检测器，并启用流模式。返回的检测到的对象用于创建表示边界框的对象，并将其添加到覆盖层上。这使用了
    ML Kit 中的通用模型，因此分类方面并不多，只是检测到一个对象，并为该对象分配了一个 ID。要进一步对每个检测到的对象进行分类，您需要一个自定义模型，在
    [第9章](ch09.html#creating_custom_models) 中我们将讨论这一点。
- en: Summary
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Building apps that use vision is very straightforward using ML Kit for Android.
    In this chapter, you explored several scenarios for this using the built-in generic
    models, including image classification and labeling, where a single image can
    have its contents determined by the computer, and then using object detection,
    where multiple images within an image can be detected and their location determined
    by a bounding box. You wrapped up the chapter with a brief exploration on how
    this could be extended to video—where not only would you *detect* an object, but
    you could also track it in real time. All these scenarios were based on the generic
    built-in models in ML Kit but could easily be extended with custom models. We’ll
    explore that more in [Chapter 9](ch09.html#creating_custom_models).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ML Kit 为 Android 构建使用视觉的应用非常简单。在本章中，您探索了几种使用内置通用模型的情景，包括图像分类和标记，其中计算机可以确定单个图像的内容，以及对象检测，其中可以检测到图像中的多个对象，并通过边界框确定它们的位置。您在本章中总结了一个简短的探讨，说明如何将此扩展到视频——不仅可以*检测*对象，还可以实时跟踪对象。所有这些情景都是基于
    ML Kit 中的通用内置模型，但可以轻松扩展为自定义模型。我们将在 [第9章](ch09.html#creating_custom_models) 中进一步探讨这一点。
