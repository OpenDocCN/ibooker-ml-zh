- en: Chapter 3\. Build Your First End-to-End Pipeline
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章\. 建立您的第一个端到端管道
- en: In [Part I](part01.html#section_1), we started by covering how to go from product
    requirements to candidate modeling approaches. Then, we moved on to the planning
    stage and described how to find relevant resources and leverage them to make an
    initial plan of what to build. Finally, we discussed how building an initial prototype
    of a functioning system was the best way to make progress. This is what we will
    cover in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第I部分](part01.html#section_1)中，我们首先介绍了如何从产品需求到候选建模方法。然后，我们进入了规划阶段，并描述了如何找到相关资源并利用它们来制定一个建设初步计划的初始计划。最后，我们讨论了建立一个功能系统的初步原型是取得进展的最佳途径。这是我们将在本章中涵盖的内容。
- en: 'This first iteration will be lackluster by design. Its goal is to allow us
    to have all the pieces of a pipeline in place so that we can prioritize which
    ones to improve next. Having a full prototype is the easiest way to identify the
    impact bottleneck that Monica Rogati described in [“Monica Rogati: How to Choose
    and Prioritize ML Projects”](ch01.html#monica_rogati).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这个第一次迭代设计的目的是有意缺乏亮点。它的目标是使我们能够将管道的所有部分放在一起，以便我们可以优先改进哪些部分。拥有一个完整的原型是识别Monica
    Rogati在[“Monica Rogati：如何选择和优先处理ML项目”](ch01.html#monica_rogati)中描述的影响瓶颈的最简单方法。
- en: Let’s start by building the simplest pipeline that could produce predictions
    from an input.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从构建最简单的管道开始，这个管道可以从输入产生预测。
- en: The Simplest Scaffolding
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最简单的脚手架
- en: In [“Start with a Simple Pipeline”](ch02.html#pipeline_description), we described
    how most ML models consist of two pipelines, training and inference. Training
    allows us to generate a high-quality model, and inference is about serving results
    to users. See [“Start with a Simple Pipeline”](ch02.html#pipeline_description)
    for more about the difference between training and inference.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“从简单管道开始”](ch02.html#pipeline_description)中，我们描述了大多数ML模型由两个管道组成，训练和推断。训练允许我们生成高质量的模型，而推断则是为用户提供结果。有关训练和推断之间区别的更多信息，请参见[“从简单管道开始”](ch02.html#pipeline_description)。
- en: For the first prototype of an application, we will focus on being able to deliver
    results to users. This means that out of the two pipelines we described in [Chapter 2](ch02.html#setting_expectations),
    we will start with the inference pipeline. This will allow us to quickly examine
    how users may interact with the output of a model, therefore gathering useful
    information to make training a model easier.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 对于应用程序的第一个原型，我们将专注于能够向用户提供结果。这意味着在我们描述的两个管道中的一个——[第2章](ch02.html#setting_expectations)中的推断管道，我们将从推断管道开始。这将使我们能够快速检查用户如何与模型输出交互，从而收集有用的信息，以便更轻松地训练模型。
- en: If we are only focusing on inference, we will ignore training for now. And since
    we are not training a model, we can instead write some simple rules. Writing such
    rules or heuristics is often a great way to get started. It is the quickest way
    to build a prototype and allows us to see a simplified version of the full application
    right away.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只专注于推断，我们将暂时忽略训练。既然我们不训练模型，我们可以写一些简单的规则。编写这些规则或启发式经常是一个很好的入门方式。这是快速构建原型的最快方式，使我们可以立即看到完整应用程序的简化版本。
- en: While this may seem superfluous if we are aiming to implement an ML solution
    anyway (as we will later in the book), it is a critical forcing function to make
    us confront our problem and devise an initial set of hypotheses about how best
    to solve it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如果我们打算在书中的后面实施ML解决方案，这可能看起来是多余的，但它是一个关键的推动因素，使我们直面问题并制定一个关于如何最好解决它的初始假设集。
- en: Building, validating, and updating hypotheses about the best way to model data
    are core parts of the iterative model building process, which starts before we
    even build our first model!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 建立、验证和更新关于如何对数据进行建模的最佳方式的假设是迭代模型构建过程的核心部分，这甚至在我们构建第一个模型之前就开始了！
- en: Note
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Here are a couple of examples of great heuristics from projects I have seen
    used by Fellows I mentored at Insight Data Science.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个我在指导Insight数据科学院学员时见过的项目中使用的优秀启发式的例子。
- en: '*Code quality estimation:* When building a model aiming to predict whether
    a coder performed well on HackerRank (a competitive coding website) from a sample
    of code, Daniel started by counting the number of open and closed parentheses,
    brackets, and curly braces.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*代码质量估计:* 当构建一个旨在预测编程者在HackerRank（一个竞争性编程网站）上表现良好的模型时，Daniel首先计算开放和关闭的括号、方括号和花括号的数量。'
- en: In the majority of proper working code, the counts of opening and closing brackets
    match, so this rule proved to be quite a strong baseline. Furthermore, it gave
    him the intuition to focus his modeling on using an [abstract syntax tree](https://oreil.ly/L0ZFk)
    to capture even more structural information about code.
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在大多数有效的工作代码中，开放和闭合括号的计数是匹配的，因此这一规则被证明是一个相当强大的基线。此外，这使他产生了使用[抽象语法树](https://oreil.ly/L0ZFk)捕获更多关于代码结构信息的直觉。
- en: '*Tree counting:* When trying to count trees in a city from satellite imagery,
    after looking at some data, Mike started by devising a rule estimating tree density
    based on counting the proportion of green pixels in a given image.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*树木计数：* 当试图从卫星图像中统计城市中的树木时，Mike在查看了一些数据后，首先制定了一个规则，根据给定图像中绿色像素的比例来估算树木密度。'
- en: It turns out that this approach worked for trees that were spread apart but
    failed when it came to groves of trees. Again, this helped define the next modeling
    steps, which focused on building a pipeline that can handle densely grouped trees.
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果表明，这种方法适用于分散的树木，但在树木林地时失败了。同样，这有助于定义接下来的建模步骤，重点是构建一个可以处理密集树木群的流水线。
- en: The vast majority of ML projects should start with a similar heuristic. The
    key is to remember to devise it based on expert knowledge and data exploration
    and to use it to confirm initial assumptions and speed up iteration.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数ML项目应该从类似的启发式方法开始。关键在于记住根据专家知识和数据探索设计它，并使用它来确认初始假设并加速迭代。
- en: Once you have a heuristic, it is time to create a pipeline that can gather input,
    pre-process it, apply your rules to it, and serve results. This could be as simple
    as a Python script you could call from the terminal or a web application that
    gathers a user’s camera feed to then serve live results.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了启发式方法，就是创建一个可以收集输入、预处理它、应用规则并提供结果的流水线的时候了。这可以简单到您可以从终端调用的Python脚本，也可以是收集用户摄像头输入然后提供实时结果的Web应用程序。
- en: The point here is to do for your product the same thing we did for your ML approach,
    simplify it as much as possible, and build it so you have a simple functional
    version. This is often referred to as an MVP (minimum viable product) and is a
    battle-tested method for getting useful results as fast as possible.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的重点是为您的产品做与您的ML方法相同的事情，尽可能简化它，并构建一个简单的功能版本。这通常被称为MVP（最小可行产品），是尽快获得有用结果的经过测试的方法。
- en: Prototype of an ML Editor
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML编辑器的原型
- en: For our ML editor, we will leverage common editing recommendations to craft
    a few rules about what makes for good or bad questions and display the results
    of those rules to users.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的ML编辑器，我们将利用常见的编辑建议来制定关于什么是好问题和坏问题的几条规则，并向用户显示这些规则的结果。
- en: 'For a minimal version of our project that takes user input from the command
    line and returns suggestions, we only need to write four functions, shown here:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于从命令行接收用户输入并返回建议的我们项目的最小版本，我们只需要编写四个函数，如下所示：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Let’s dive into each of them! We will keep the argument parser simple and start
    with taking a string of text from the user, with no options. You can find the
    source code for the example and all other code examples in this book’s [GitHub
    repository](https://oreil.ly/ml-powered-applications).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解每一个！我们将保持参数解析器简单，并从用户那里获取文本字符串，不带任何选项。您可以在本书的[GitHub代码库](https://oreil.ly/ml-powered-applications)中找到示例和所有其他代码示例的源代码。
- en: Parse and Clean Data
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解析和清理数据
- en: First, we simply parse incoming data coming from the command line. This is relatively
    straightforward to write in Python.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们简单地解析从命令行接收的数据。这在Python中相对简单地编写。
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Whenever a model runs on user input, you should start by validating and verifying
    it! In our case, users will type in data, so we will make sure that their input
    contains characters we can parse. To clean our input, we will remove non-ASCII
    characters. This shouldn’t restrict our users’ creativity too much and allow us
    to make reasonable assumptions about what is in the text.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 每当模型根据用户输入运行时，您都应该开始验证和验证它！在我们的情况下，用户将输入数据，因此我们将确保他们的输入包含我们可以解析的字符。为了清理我们的输入，我们将删除非ASCII字符。这不应过多限制我们用户的创造力，并且允许我们对文本中的内容做出合理的假设。
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we need to preprocess our input and provide recommendations. To get us
    started, we will lean on some of the existing research about classifying text
    we mentioned in [“The Simplest Approach: Being the Algorithm”](ch01.html#start_heuristic).
    This will involve counting words such as “told” and “said” and computing summary
    statistics of syllables, words, and sentences to estimate sentence complexity.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要对输入进行预处理并提供建议。为了开始工作，我们将依赖我们在[“最简单的方法：成为算法”](ch01.html#start_heuristic)中提到的一些关于文本分类的现有研究。这将涉及计算诸如“告诉”和“说”的词语频率，并计算音节、单词和句子的摘要统计数据，以估计句子的复杂性。
- en: To compute word-level statistics, we need to be able to identify words from
    sentences. In the world of natural language processing, this is known as *tokenization*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算词级别的统计数据，我们需要能够从句子中识别单词。在自然语言处理领域，这被称为*分词*。
- en: Tokenizing Text
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本分词
- en: 'Tokenization is not straightforward, and most simple methods you can think
    of, such as splitting our input into words based on spaces or periods, will fail
    on realistic text due to the diversity of ways words can be separated. Consider
    this sentence, provided as an example by Stanford’s [NLP class](https://oreil.ly/vdrZW),
    for example:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 分词并不简单，大多数你能想到的简单方法，比如根据空格或句号将输入拆分为单词，将在实际文本中失败，因为单词分隔方式多种多样。例如，考虑斯坦福大学的[NLP课程](https://oreil.ly/vdrZW)提供的这个例子：
- en: “Mr. O’Neill thinks that the boys’ stories about Chile’s capital aren’t amusing.”
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “奥尼尔先生认为男孩们关于智利首都的故事并不有趣。”
- en: 'Most simple methods will fail on this sentence due to the presence of periods
    and apostrophes that carry various meanings. Instead of building our own tokenizer,
    we will leverage [nltk](https://www.nltk.org/), a popular open source library,
    which allows us to do this in two easy steps, as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数简单的方法在处理这句话时会失败，因为其中包含具有不同含义的句点和撇号。我们不会自己构建分词器，而是会利用[nltk](https://www.nltk.org/)，这是一个流行的开源库，可以通过两个简单步骤来完成，如下所示：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Once our output is preprocessed, we can use it to generate features that will
    help judge the quality of a question.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的输出被预处理，我们可以用它来生成特征，以帮助评估问题的质量。
- en: Generating Features
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成特征
- en: 'The last step is to write a few rules we could use to give advice to our users.
    For this simple prototype, we will start by computing the frequency of a few common
    verbs and connectors and then count adverb usage and determine the [Flesch readability
    score](https://oreil.ly/iKhmk). We will then return a report of these metrics
    to our users:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是编写一些规则，可以用来向用户提供建议。对于这个简单的原型，我们将首先计算几个常见动词和连接词的频率，然后统计副词的使用情况，并计算[Flesch可读性分数](https://oreil.ly/iKhmk)。然后，我们将向用户返回这些指标的报告：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Voilà, we can now call our application from the command line and see its results
    live. It is not very useful yet, but we have a starting point we can test and
    iterate from, which we’ll do next.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以从命令行调用我们的应用程序并实时查看其结果。虽然现在还不是非常有用，但我们有了一个可以测试和迭代的起点，接下来我们将做这些工作。
- en: Test Your Workflow
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试您的工作流程
- en: Now that we’ve built this prototype, we can test our assumptions about the way
    we’ve framed our problem and how useful our proposed solution is. In this section,
    we will take a look both at the objective quality of our initial rules and examine
    whether we are presenting our output in a useful manner.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了这个原型，我们可以测试我们对问题框架的假设以及我们提出的解决方案的实用性。在本节中，我们将评估我们初始规则的客观质量，并检查我们是否以有用的方式呈现输出。
- en: As Monica Rogati shared earlier, “Frequently, your product is dead even if your
    model is successful.” If the method we have chosen excels at measuring question
    quality but our product does not provide any advice to users to improve their
    writing, our product will not be useful despite the quality of our method. Looking
    at our complete pipeline, let’s evaluate both the usefulness of the current user
    experience and the results of our handcrafted model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 正如Monica Rogati之前分享的，“即使你的模型成功了，你的产品也可能一无是处。”如果我们选择的方法在测量问题质量方面表现出色，但我们的产品没有为用户提供改善写作的建议，那么尽管我们的方法质量很高，产品也将毫无用处。在审视我们的完整流程时，让我们评估当前用户体验的实用性以及我们手工制作模型的结果。
- en: User Experience
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户体验
- en: Let’s first examine how satisfying our product is to use, independently of the
    quality of our model. In other words, if we imagine that we will eventually get
    a model that performs well enough, is this the most useful way to present results
    to our users?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们独立于我们模型的质量来检查我们的产品使用体验有多满意。换句话说，如果我们想象最终将获得一个表现足够好的模型，这是向用户展示结果最有用的方式吗？
- en: If we are building a tree census, for example, we may want to present our results
    as a summary of a long-running analysis of an entire city. We may want to include
    the number of reported trees, as well as broken-down statistics per neighborhood,
    and a measure of the error on a gold standard test set.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们正在进行树木普查，我们可能希望将我们的结果呈现为对整个城市长期分析的摘要。我们可能希望包括报告树木数量，以及按社区细分的统计数据，以及对黄金标准测试集误差的度量。
- en: In other words, we would want to make sure that the results we present are useful
    (or will be if we improve our model). On the flip side, of course, we’d also like
    our model to perform well. That is the next aspect we’ll evaluate.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们希望确保我们呈现的结果是有用的（或者如果我们改进我们的模型会变得更有用）。当然，反过来，我们也希望我们的模型表现良好。这是我们将评估的下一个方面。
- en: Modeling Results
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建模结果
- en: We mentioned the value of focusing on the right metric in [“Measuring Success”](ch02.html#minimal_viable_product).
    Having a working prototype early on will allow us to identify and iterate on our
    chosen metrics to make sure they represent product success.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到了在[“衡量成功”](ch02.html#minimal_viable_product)中集中精力选择正确的度量标准的价值。早期拥有一个可工作的原型将使我们能够识别和迭代我们选择的度量标准，以确保它们代表产品成功。
- en: As an example, if we were building a system to help users search for rental
    cars nearby, we may use a metric such as discounted cumulative gain (DCG). DCG
    measures ranking quality by outputting a score that is highest when the most relevant
    items are returned earlier than others (see [the Wikipedia article on DCG](https://oreil.ly/b_8Xq)
    for more information about ranking metrics). When initially building our tool,
    we may have assumed that we wanted at least one useful suggestion to appear in
    our first five results. We thus used DCG at 5 to score our model. However, when
    having users try the tool, we may notice that users only ever consider the first
    three results displayed. In that case, we should change our metric of success
    from DCG at 5 to 3.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们正在构建一个帮助用户搜索附近租车的系统，我们可能会使用像折扣累积增益（DCG）这样的度量标准。DCG通过输出一个评分来衡量排名质量，在最相关的项目早于其他项目时得分最高（详见[DCG的维基百科文章](https://oreil.ly/b_8Xq)了解更多关于排名指标的信息）。在最初构建我们的工具时，我们可能假设我们希望至少有一个有用的建议出现在前五个结果中。因此，我们使用DCG@5来评估我们的模型。然而，当用户试用这个工具时，我们可能注意到用户只考虑前三个显示的结果。在这种情况下，我们应该将我们的成功度量从DCG@5更改为DCG@3。
- en: The goal of considering both user experience and model performance is to make
    sure we are working on the most impactful aspect. If your user experience is poor,
    improving your model is not helpful. In fact, you may realize you would be better
    served with an entirely different model! Let’s look at two examples.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑用户体验和模型性能的目标在于确保我们处理最具影响力的方面。如果用户体验差，改进模型是没有帮助的。事实上，你可能会意识到最好采用完全不同的模型！让我们看两个例子。
- en: Finding the impact bottleneck
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 寻找影响瓶颈
- en: The goal of looking both at modeling results and at the current presentation
    of the product is to identify which challenge to tackle next. Most of the time,
    this will mean iterating on the way we present results to our users (which could
    mean changing the way we train our models) or improving model performance by identifying
    key failure points.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 同时查看建模结果和产品当前展示的目标是确定下一个解决挑战的方向。大多数情况下，这意味着在我们向用户展示结果的方式上进行迭代（这可能意味着改变我们训练模型的方式）或者通过识别关键失败点来改进模型性能。
- en: 'While we will dive into error analysis more in [Part III](part03.html#section_3),
    we should identify failure modes and appropriate ways to resolve them. It is important
    to determine whether the most impactful task to work on is in the modeling or
    product domain, as they each require different remediations. Let’s see an example
    of each:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们将在[第三部分](part03.html#section_3)更深入地进行错误分析，但我们应该确定失败模式和适当的解决方式。重要的是确定要解决的最具影响力的任务是在建模还是产品领域，因为它们各自需要不同的修复方法。让我们看一个每个方面的例子：
- en: On the product side
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在产品方面
- en: Let’s say you have built a model that looks at images of research papers and
    predicts whether they will be accepted to top conferences (see Jia-Bin Huang’s
    paper [“Deep Paper Gestalt,”](https://oreil.ly/RRfIN) which tackles this issue).
    However, you’ve noticed that returning only a probability of rejection to a user
    is not the most satisfying of outputs. In this case, improving your model would
    *not* be helpful. It would make sense to focus on extracting advice from the model
    so that we can help our users improve their papers and increase their chances
    of being accepted.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你建立了一个模型，该模型查看研究论文的图像，并预测它们是否会被顶级会议接受（参见贾斌黄的论文["Deep Paper Gestalt,"](https://oreil.ly/RRfIN)，该论文解决了这个问题）。然而，你注意到仅返回用户一个拒绝的概率并不是最令人满意的输出。在这种情况下，改进你的模型将*没有*帮助。专注于从模型中提取建议，以便我们可以帮助用户改进他们的论文并增加被接受的机会，这才是有意义的。
- en: On the model side
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型方面
- en: You’ve built a credit scoring model and are noticing that with all other factors
    being equal, it assigns higher risks of defaulting to a certain ethnic group.
    This is likely due to a bias in the training data you have been using, so you
    should gather more representative data and build a new cleaning and augmentation
    pipeline to attempt to address this. In this case, regardless of the manner in
    which you present results, *the model needs to be fixed*. Examples like this are
    common and a reason why you should always dive deeper than an aggregate metric
    and look at the impact of your model on different slices of your data. This is
    what we will do in [Chapter 5](ch05.html#first_model).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 你建立了一个信用评分模型，并注意到在其他因素相同的情况下，它会给某个特定种族群体分配更高的违约风险。这很可能是由于你使用的训练数据中存在偏见，因此你应该收集更具代表性的数据，并建立新的清理和增强流水线来尝试解决这个问题。在这种情况下，无论你如何呈现结果，*模型都需要修正*。类似这样的例子很常见，这也是为什么你应该总是深入探究聚合指标以及分析模型对数据不同切片影响的原因。这就是我们在[第五章](ch05.html#first_model)中将要做的事情。
- en: To illustrate this further, let’s go through this exercise for our ML Editor.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步说明这一点，让我们为我们的 ML 编辑器进行这个练习。
- en: ML Editor Prototype Evaluation
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML 编辑器原型评估
- en: Let’s see how our initial pipeline fares both in terms of user experience and
    model performance. Let’s start by throwing in a few inputs to our application.
    We will start by testing a simple question, a convoluted question, and a full
    paragraph.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的初始流水线在用户体验和模型性能方面的表现如何。让我们首先输入一些内容到我们的应用程序中。我们将开始测试一个简单问题，一个复杂问题和一个完整段落。
- en: Since we are using a reading ease score, we would ideally like our workflow
    to return a high score for the simple sentence, a low score for the convoluted
    one, and suggestions for improving our paragraph. Let’s actually run a few examples
    through our prototype.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用的是阅读易度分数，我们希望我们的工作流能为简单的句子返回高分，为复杂句子返回低分，并提出改进段落的建议。让我们实际运行几个示例通过我们的原型。
- en: 'Simple question:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 简单问题：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Convoluted question:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂问题：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Entire paragraph (that you’ll recognize from earlier):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 之前你已经认识到的整个段落：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let’s examine these results using both of the aspects we’ve just defined.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用我们刚刚定义的两个方面来检查这些结果。
- en: Model
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: It is unclear whether our results align well with what we would consider quality
    writing. The convoluted sentence and the entire paragraph receive a similar readability
    score. Now, I will be the first to admit that my prose can sometimes be difficult
    to read, but the earlier paragraph is more comprehensible than the convoluted
    sentence we tested before it.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 目前还不清楚我们的结果是否与我们认为的优质写作相符。复杂的句子和整个段落接受到了类似的可读性评分。现在，我将首先承认，我的散文有时可能很难阅读，但与之前测试的复杂句子相比，之前的段落更易理解。
- en: 'The attributes we are extracting from the text are not necessarily the most
    correlated with “good writing.” This is usually due to not having defined success
    clearly enough: given two questions, how can we say one is better than the other?
    When we build our dataset in the next chapter, we will define this more clearly.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从文本中提取的属性未必与“好写作”最相关。这通常是因为我们没有清晰地定义成功：在给定两个问题的情况下，我们如何说一个比另一个更好？在下一章中构建数据集时，我们将更清晰地定义这一点。
- en: As expected, we have some modeling work to do, but are we even presenting results
    in a useful manner?
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，我们还有一些建模工作要做，但我们是否正在以有用的方式呈现结果？
- en: User Experience
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户体验
- en: From the results shown earlier, two issues are immediately apparent. The information
    we return is both overwhelming and irrelevant. The goal of our product is to provide
    actionable recommendations to our users. The features and readability score are
    a quality metric but will not help a user decide how to improve their submission.
    We may want to boil down our recommendations to a single score, along with actionable
    recommendations to improve it.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 根据之前展示的结果，立即出现了两个问题。我们返回的信息既过于冗余又不相关。我们产品的目标是向用户提供可操作的建议。特征和可读性分数是质量指标，但不会帮助用户决定如何改进他们的提交。我们可能希望将我们的建议归纳为一个单一的分数，以及行动建议来改进它。
- en: For example, we could suggest general changes such as using fewer adverbs, or
    work at a more granular level by suggesting word- and sentence-level changes.
    Ideally, we could present results by highlighting or underlining the parts of
    the input that require users’ attention. I’ve added a mock-up of how this could
    look in [Figure 3-1](#mockup_image).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以建议一般性的更改，比如使用更少的副词，或者在更细粒度的级别上建议单词和句子级别的更改。理想情况下，我们可以通过突出或下划线显示需要用户注意的输入部分来呈现结果。我已经添加了一个如何在[图3-1](#mockup_image)中看起来的模拟。
- en: '![More actionable suggestions](assets/bmla_0301.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![更具操作性的建议](assets/bmla_0301.png)'
- en: Figure 3-1\. More actionable writing suggestions
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1\. 更具操作性的写作建议
- en: Even if we were not able to directly highlight recommendations in the input
    string, our product could benefit from providing recommendations similar to the
    ones on the right side of [Figure 3-1](#mockup_image), which are more actionable
    than a list of scores.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们不能直接在输入字符串中突出显示建议，我们的产品仍然可以从提供类似于[图3-1](#mockup_image)右侧的更具操作性建议中受益，这些建议比分数列表更具操作性。
- en: Conclusion
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We have built an initial inference prototype and used it to evaluate the quality
    of our heuristics and the workflow of our product. This allowed us to narrow down
    our performance criteria and iterate on the way we would like to present results
    to our users.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经建立了一个初始推理原型，并用它来评估我们的启发式和产品工作流的质量。这使我们能够缩小我们的绩效标准范围，并在向用户展示结果的方式上进行迭代。
- en: For the ML Editor, we’ve learned that we should both focus on providing a better
    user experience by providing actionable recommendations and improve our modeling
    approach by looking at data to more clearly define what makes for a good question.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对于ML编辑器，我们已经学到，通过提供具有操作性的建议来改善用户体验，并通过查看数据来更清晰地定义好问题的特征生成和建模方法，可以改进我们的建模方法。
- en: In the first three chapters, we’ve used our product goals to define which initial
    approach to take, explored existing resources to make a plan for our approach,
    and built an initial prototype to validate our plan and assumptions.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在前三章中，我们利用产品目标来定义初始方法，探索现有资源以制定我们的方法计划，并建立了一个初始原型来验证我们的计划和假设。
- en: Now, it is time to dive into what is often the most overlooked part of an ML
    project—exploring our dataset. In [Chapter 4](ch04.html#initial_dataset), we will
    see how to gather an initial dataset, assess its quality, and iteratively label
    subsets of it to help guide our feature generation and modeling decisions.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候深入研究ML项目中经常被忽视的部分了——探索我们的数据集。在[第四章](ch04.html#initial_dataset)中，我们将看到如何收集一个初始数据集，评估其质量，并逐步标记其子集，以帮助指导我们的特征生成和建模决策。
