- en: Chapter 4\. Using Azure Cognitive Services to Build Intelligent Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章。使用 Azure 认知服务构建智能应用程序
- en: In the previous chapter we looked at how a cloud service like Azure Machine
    Learning helps you focus on building and training machine learning models without
    needing to create an entire machine learning environment from scratch. But not
    every developer will want to build their own machine learning models, so in this
    chapter we’re going to show you how to use ready-made AI services that you can
    use out of the box or customize using your own training data and call like any
    other API.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们看过像 Azure 机器学习这样的云服务如何帮助你专注于构建和训练机器学习模型，而无需从头开始创建整个机器学习环境。但并非每个开发人员都希望构建自己的机器学习模型，因此在本章中，我们将向您展示如何使用现成的
    AI 服务，这些服务可以直接使用或使用您自己的训练数据进行定制，并像调用其他任何 API 一样使用。
- en: Using Prebuilt AI
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用预建 AI
- en: The term “AI” is used very broadly these days and covers many different approaches,
    but techniques for having computers perform tasks that we used to think only people
    could do, like understanding and learning from experience, are fundamental. They
    include “cognitive” tasks like recognizing speech and images to improve customer
    service, detecting faces in a photo or even using a selfie to authenticate to
    an app, understanding speech that’s full of the product names and technical terms
    used in your industry, or synthesizing speech from text.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当今，“AI”一词的使用非常广泛，涵盖了许多不同的方法，但让计算机执行我们曾经认为只有人类能够做到的任务的技术，例如理解和从经验中学习，是基础的。它们包括诸如识别语音和图像以改进客户服务，检测照片中的面孔，甚至使用自拍验证应用程序，理解充满产品名称和行业技术术语的语音，或从文本合成语音的“认知”任务。
- en: Want to let your users take a photograph of a menu, translate it into another
    language, and get photographs showing what their food might look like? How about
    creating a chatbot that can deliver text and voice chat for customer support but
    also recognize pictures of your products that customers send in, spot whether
    the item is broken, and kick off the return process? Those are all powerful AI-powered
    features that you could build into your existing apps and tools using APIs for
    these cognitive tasks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 想让你的用户拍摄菜单，将其翻译成另一种语言，并展示他们的食物可能的照片吗？创建一个聊天机器人，可以为客户支持提供文本和语音聊天，还可以识别客户发送的产品图片，判断物品是否损坏，并启动退货流程，这些都是你可以通过这些认知任务的
    API 将强大的 AI 功能集成到现有应用程序和工具中。
- en: This is a fast-moving area of AI, with new algorithms and techniques being developed
    all the time that are complex to implement. Using prebuilt but customizable APIs
    that deliver cognitive tasks as a cloud service gives developers a fast way to
    take advantage of the business value AI can bring and give their apps a human
    side, without having to become data scientists. You don’t have to build the model,
    manage the production environment for a machine learning system—or secure it.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 AI 领域的快速发展区域，不断开发出复杂的新算法和技术。使用预建但可定制的 API 作为云服务提供认知任务，为开发人员提供了快速利用 AI 带来的商业价值的方式，并使他们的应用程序具备人性化的一面，而无需成为数据科学家。你不需要构建模型，管理机器学习系统的生产环境——或者保障它。
- en: You don’t have to train the models used in Cognitive Services (although you
    can build custom models in some services). Microsoft delivers pretrained models
    as services and regularly updates them with improved training sets to ensure that
    they stay relevant and can work with as wide a range of source materials as possible.
    New and improved algorithms and models are regularly added to the different services;
    you may find your app gets more powerful without you needing to make any changes,
    or there will be new options to work with. In some cases, developers get access
    to new models as quickly as the teams inside Microsoft.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要训练认知服务中使用的模型（尽管你可以在某些服务中构建定制模型）。微软将预训练模型作为服务交付，并定期使用改进的训练集更新这些模型，以确保它们保持相关性，并能够处理尽可能广泛的源材料。不断向不同服务中添加新的改进算法和模型；你可能会发现你的应用程序变得更强大，而无需进行任何更改，或者会有新的选项可供使用。在某些情况下，开发人员可以像微软内部团队一样快速获得新模型的访问权限。
- en: The Bing Search app for iOS and Android can generate speech that sounds almost
    exactly like a person speaking; that’s important because research shows it’s much
    less tiring to listen to results, directions, or something longer like an audiobook
    with the natural intonations of a human voice and with all the words articulated
    clearly.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: iOS 和 Android 的 Bing 搜索应用程序可以生成听起来几乎像人说话的语音；这一点非常重要，因为研究表明，听自然语调和清晰发音的结果、方向或像有声书那样更长的内容，会减少很多疲劳感。
- en: 'Using deep neural networks to do voice synthesis and prosody (matching the
    patterns of stress and intonation in speech) together rather than as separate
    steps produces more natural and fluid speech. This is a relatively new development
    that was in research labs a couple of years ago, and new research papers are still
    coming out with refinements. But several months before the Bing team added neural
    voice synthesis to their mobile app, the Cognitive Services Speech API already
    included a preview of two neural text-to-speech voices in English, followed by
    Chinese, German, and Italian voices. Now companies like Progressive Insurance
    use custom neural voices: the Flo chatbot speaks with the voice of actor Stephanie
    Courtney, thanks to Cognitive Services.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度神经网络同时进行语音合成和韵律学（匹配语音中的重音和语调模式），而不是作为单独的步骤，可以产生更自然和流畅的语音。 这是几年前在研究实验室中的一个相对新的发展，新的研究论文仍在不断出现并进行改进。
    但在 Bing 团队将神经语音合成添加到他们的移动应用程序几个月前，认知服务的语音 API 已经包括预览英语的两个神经语音合成声音，然后是中文、德语和意大利语的声音。
    现在，像 Progressive Insurance 这样的公司使用定制的神经语音：Flo 聊天机器人使用演员 Stephanie Courtney 的声音，这要归功于认知服务。
- en: Even companies with deep expertise in AI turn to these services rather than
    creating their own implementations. When Uber wanted to ensure the person driving
    the car was the registered driver who was supposed to show up as your ride, even
    if they’d cut their hair or changed their glasses since they got their ID photo
    taken, they used the Face API in Azure Cognitive Services to have drivers take
    a selfie on their phone. The team at Uber uses machine learning extensively and
    even builds open source tools for machine learning development. But they chose
    Cognitive Services because they were able to deliver the new feature in a few
    lines of code rather the months of development it would have taken to build face
    detection into their own platform.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是在人工智能方面有深厚专业知识的公司，也会转向这些服务，而不是创建自己的实现。 当优步希望确保驾驶汽车的人是注册的司机时，即使他们已经剪了头发或换了眼镜，自他们拍摄
    ID 照片以来，他们使用 Azure 认知服务中的 Face API 要求司机在手机上自拍。 优步团队广泛使用机器学习，甚至为机器学习开发构建开源工具。 但他们选择认知服务是因为他们能够用几行代码交付新功能，而不是花费几个月时间将人脸检测集成到他们自己的平台中。
- en: 'The REST APIs and client SDKs (for languages including .NET, Python, Java,
    and Node.js) available through Azure Cognitive Services let developers use and
    customize the latest AI models for computer vision, text and video analytics,
    speech, and knowledge understanding without needing to implement, train, or host
    their own models. Cognitive Services can be called from Azure Functions and Azure
    App Service, or from within Apache Spark, Azure Databricks, Azure Synapse Analytics,
    and other data processing services if you need to enrich or annotate big data.
    (They’re also available inside the Power Platform and in Logic Apps for no-code
    and low-code developers: we’ll be covering how to use those in [Chapter 6](ch06.xhtml#machine_learning_for_everyoneem_dashlow).)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Azure 认知服务提供的 REST API 和客户端 SDK（包括 .NET、Python、Java 和 Node.js 等语言），开发人员可以使用和定制最新的
    AI 模型，用于计算机视觉、文本和视频分析、语音和知识理解，无需实现、训练或托管自己的模型。认知服务可从 Azure Functions 和 Azure 应用服务调用，或从
    Apache Spark、Azure Databricks、Azure Synapse Analytics 等数据处理服务中调用，以丰富或注释大数据。 （它们也适用于
    Power Platform 和 Logic Apps 中的无代码和低代码开发者：我们将在 [第六章](ch06.xhtml#machine_learning_for_everyoneem_dashlow)
    中介绍如何使用这些功能。）
- en: As cloud services, Cognitive Services work at scale, for thousands or millions
    of users, reaching 150 countries, from more than 30 Azure regions around the world,
    with data stored and retained in compliant ways to give users control over their
    data. (Check out [Chapter 9](ch09.xhtml#how_microsoft_runs_cognitive_services_f)
    for the details of what it takes to scale up machine learning services like this.)
    The APIs run with strict SLAs and are guaranteed to be available at least 99.9%
    of the time. Services are localized into multiple languages, with some services
    available in over 100 different languages and dialects. Speech-to-text, for example,
    is available in 197 and complies with ISO, SOC2, and HIPAA standards.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 作为云服务，认知服务可以规模化，适用于成千上万的用户，在全球超过 30 个 Azure 地区的 150 个国家，以符合合规方式存储和保留数据，以便用户控制其数据。API
    运行符合严格的 SLA，并保证至少 99.9% 的可用性。服务本地化支持多种语言，某些服务可提供超过 100 种不同的语言和方言。例如，语音转文字可提供 197
    种语言，并符合 ISO、SOC2 和 HIPAA 标准。
- en: But you can also take some of the most useful Cognitive Services and run them
    locally, by building the trained model right into a smartphone app that uses the
    AI offload hardware on the phone, or running them in a container inside an IoT
    device where they can work directly with sensor readings as they’re generated.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还可以将一些最有用的认知服务在本地运行，通过将训练模型直接构建到智能手机应用中，并利用手机上的 AI 卸载硬件运行，或将它们运行在 IoT 设备内部的容器中，这样它们可以直接处理生成的传感器读数。
- en: That’s ideal for the remote, demanding environments where IoT devices are the
    most useful, and connectivity is slow, expensive, or both. This also addresses
    questions of data governance; if you’re using image recognition to analyze medical
    documents for insurance, you don’t have to worry about compliance issues when
    taking them outside the hospital network to analyze them in the cloud.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于远程、苛刻的环境特别适用，那里物联网设备最有用，而连接速度慢、昂贵或两者兼而有之。这也解决了数据治理的问题；例如，如果您正在使用图像识别分析保险医疗文件，您在将其带出医院网络以在云中分析时无需担心合规问题。
- en: The core Cognitive Services provide skills in the areas of speech, vision, and
    language, including the Azure OpenAI Service, as well as services for making decisions
    and detecting anomalies (and you can call multiple services in the same app).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 核心认知服务涵盖语音、视觉和语言技能，包括 Azure OpenAI 服务，以及用于决策和检测异常的服务（您可以在同一应用程序中调用多个服务）。
- en: Azure Applied AI Services, which we cover in the next chapter, combine these
    core services into tools for common scenarios, like understanding video or processing
    paperwork and documents. Azure Form Recognizer uses vision and language Cognitive
    Services and business logic to automate dealing with forms, as you can see in
    [Figure 4-1](#rather_than_calling_multiple_cognitive).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 应用 AI 服务，我们将在下一章进行详细讲解，将这些核心服务组合成常见场景的工具，如理解视频或处理文件和文档。Azure 表单识别器利用视觉和语言认知服务以及业务逻辑来自动处理表单，正如您在[图 4-1](#rather_than_calling_multiple_cognitive)中所见。
- en: '![Rather than calling multiple Cognitive Services yourself to get information
    out of a form, you can use Azure Form Recognizer, which wraps multiple services
    with business logic and has pretrained models](Images/aasc_0401.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![不必自己调用多个认知服务来从表单中获取信息，您可以使用 Azure 表单识别器，它包装了多个服务和业务逻辑，并具有预训练模型](Images/aasc_0401.png)'
- en: Figure 4-1\. Rather than calling multiple Cognitive Services yourself to get
    information out of a form, you can use Azure Form Recognizer, which wraps multiple
    services with business logic and has pretrained models
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1\. 不必自己调用多个认知服务来从表单中获取信息，您可以使用 Azure 表单识别器，它包装了多个服务和业务逻辑，并具有预训练模型。
- en: 'Think of Cognitive Services as the building blocks that let any developer build
    an AI-powered solution: Applied AI Services add task-specific AI models and business
    logic for common problems like digital asset management, extracting information
    from documents, and analyzing and reacting to real-time data.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 认知服务可以看作是让任何开发人员构建基于人工智能解决方案的基础组件：应用 AI 服务添加了针对特定任务的 AI 模型和业务逻辑，用于解决诸如数字资产管理、从文档中提取信息以及分析和实时数据的反应等常见问题。
- en: The Core Azure Cognitive Services
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 核心 Azure 认知服务
- en: 'There are dozens of different Cognitive Services grouped into the key areas
    shown in [Figure 4-2](#the_core_cognitive_services_are_grouped): speech, text,
    vision, and decision making, plus OpenAI. We don’t have space to cover them all
    in detail here;^([1](ch04.xhtml#ch01fn5)) instead, we’re going to show you how
    to use some of the most popular services—but you should find working with any
    of the APIs and SDKs a similar experience.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 有几十种不同的认知服务，分为以下主要领域，如[图 4-2](#the_core_cognitive_services_are_grouped)所示：语音、文本、视觉和决策制定，以及
    OpenAI。我们在这里没有足够的空间详细介绍它们所有；^([1](ch04.xhtml#ch01fn5)) 相反，我们将向您展示如何使用一些最流行的服务，但您应该发现与任何
    API 和 SDK 一起工作的体验类似。
- en: '![The core Cognitive Services are grouped into five pillars](Images/aasc_0402.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![核心认知服务分为五大支柱](Images/aasc_0402.png)'
- en: Figure 4-2\. The core Cognitive Services are grouped into five pillars
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. 核心认知服务分为五大支柱
- en: Language
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言
- en: Analyze, understand, and translate text with the language APIs (or use them
    together with the speech services we previously mentioned).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 使用语言 API 分析、理解和翻译文本（或者与我们之前提到的语音服务一起使用）。
- en: You can turn your FAQ into an interactive chatbot with the Question Answering
    service, extract not just keywords but the intent of what users are saying or
    typing with Language Understanding, or translate in near-real time, using the
    terms that matter in your own business and industry. That includes full document
    translation, even of complex PDF files, preserving the layout and format.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用问答服务将您的常见问题解答转换为交互式聊天机器人，不仅提取关键词汇，还可以了解用户说或者输入的意图，使用语言理解实现几乎实时的翻译，使用您所在业务和行业中重要的术语。这包括对复杂
    PDF 文件的全文档翻译，保留其布局和格式。
- en: Tip
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Which Cognitive Services language models can you customize?
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以自定义哪些认知服务语言模型？
- en: '[Language Understanding (LUIS)](https://www.luis.ai)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语言理解（LUIS）](https://www.luis.ai)'
- en: '[Question Answering](https://www.qnamaker.ai)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[问答服务](https://www.qnamaker.ai)'
- en: '[Translator and Custom Translator](https://portal.customtranslator.azure.ai)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[翻译器和自定义翻译器](https://portal.customtranslator.azure.ai)'
- en: The Text Analytics API takes raw text and extracts the sentiment behind the
    text, the key phrases it uses, the language it’s written in, and the entities
    it refers to. A sentence refers to “Rover”; is it a dog or a car? Is “Mars” the
    planet or the British candy bar? Entity recognition can find time zones, temperatures,
    numbers and percentages, places, people, quantities, businesses, dates and times,
    URLs, and email addresses. There’s a healthcare-specific entity recognition service
    that can extract medical information from unstructured documents like doctor’s
    notes and electronic health records, detecting terms that might be a diagnosis,
    a condition or symptom, the name of a medicine, part of the body, and other important
    medical concepts.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分析 API 可以处理原始文本并提取其背后的情感、关键短语、语言以及它所指的实体。一句话提到“Rover”；它是一只狗还是一辆车？“Mars”是行星还是英国的糖果棒？实体识别可以找到时区、温度、数字和百分比、地点、人物、数量、企业、日期和时间、URL
    和电子邮件地址。还有一种专门针对医疗领域的实体识别服务，可以从医生的笔记和电子健康记录等非结构化文档中提取医疗信息，检测可能是诊断、病症或症状、药物名称、身体部位及其他重要的医疗概念。
- en: Tip
  id: totrans-32
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Use sentiment analysis to filter comments and reviews from customers to feature
    on your site, or take the results and feed them into Power BI to generate actionable
    data. Use the opinion mining option to pull out subjects and opinions to get more
    details. If a message appears to be a complaint, you can see not only the negative
    sentiment rating, but also terms like “room” or “handle” and phrases like “was
    cold” or “broke off in my hand,” allowing you to respond quickly to customer problems.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 使用情感分析来筛选客户评论和评价，并在您的网站上展示，或将结果输入 Power BI 以生成可操作的数据。使用观点挖掘选项来提取主题和观点，以获取更多细节。如果一条消息看起来是投诉，您不仅可以看到负面情感评分，还可以看到像“房间”或“把手”这样的术语，以及像“很冷”或“断在我手上”这样的短语，使您能够迅速回应客户的问题。
- en: Key phrases and entities aren’t enough to give you the intent of every phrase
    or sentence. We all have different ways of talking and typing, using different
    words to mean the same thing. When someone ordering a pizza through a chat interface
    asks for it to be delivered to their digs, what do they mean? Could they really
    want their pizza in a hole?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 关键短语和实体并不能完全表达每个短语或句子的意图。我们都有不同的说话和打字方式，使用不同的词来表示相同的意思。当有人通过聊天界面订购披萨，并要求将其送到他们的住所时，他们到底是什么意思？他们真的想要披萨放在一个洞里吗？
- en: LUIS maps keywords to a list of things you expect your users to be asking for
    and turns a conversation into a list of ways an app or chatbot can respond.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LUIS将关键字映射到您期望用户询问的事物列表，并将对话转换为应用程序或聊天机器人可以响应的方式列表。
- en: Adding LUIS to a travel agency chatbot, for example, can narrow the information
    needed to help a customer. A statement like “I need a flight to Heathrow” will
    be parsed with the intent “BookTravel” and entities “flight” and “London.” Prefilling
    those entities into a booking engine starts the booking process, while the chatbot
    prompts the user for additional information, like dates, class of travel, and
    the departure airport. You can see how LUIS extracts intent from a text string
    in [Figure 4-3](#luis_can_extract_both_entities_and_inte).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，将LUIS添加到旅行社聊天机器人中可以缩小帮助客户所需的信息范围。像“我需要去希斯罗的航班”这样的声明将被解析为意图“BookTravel”和实体“flight”和“London”。将这些实体预填充到预订引擎中启动预订过程，同时聊天机器人提示用户输入其他信息，例如日期、旅行等级和出发机场。您可以看到LUIS如何从文本字符串中提取意图，在[图4-3](#luis_can_extract_both_entities_and_inte)中。
- en: '![LUIS can extract both entities and intent from what someone says](Images/aasc_0403.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![LUIS可以从某人说的话中提取实体和意图](Images/aasc_0403.png)'
- en: Figure 4-3\. LUIS can extract both entities and intent from what someone says
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-3\. LUIS可以从某人说的话中提取实体和意图
- en: LUIS is not a general-purpose machine learning model; to get the most out of
    it, you have to train it with domain-specific data for your industry, location,
    and scenarios. A set of prebuilt models for specific domains can help you get
    started, but they’ll need additional training if you want the best results.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: LUIS不是通用的机器学习模型；要充分利用它，您必须使用行业、地点和场景特定的数据对其进行训练。特定领域的预构建模型可以帮助您入门，但如果您想要最佳结果，它们还需要额外的训练。
- en: Translator
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 翻译器
- en: 'Microsoft Translator is a cloud-based machine translation service with multilanguage
    support for translation, transliteration, language detection, and dictionaries:
    it handles more than 100 languages and dialects. The core service is the Translator
    Text API, which is used in multiple Microsoft products as well as being available
    through Cognitive Services. The same API also powers speech translation, and we’ll
    talk about that next.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft Translator是一种基于云的机器翻译服务，支持多语言翻译、转写、语言检测和字典功能：它处理超过100种语言和方言。核心服务是Translator
    Text API，该API在多个Microsoft产品中使用，并可通过认知服务获得。同一API还驱动语音翻译，接下来我们将讨论这一点。
- en: The Translator Text API uses deep learning-powered neural machine translation,
    the technique that has revolutionized machine translation in the last decade,
    with more accurate translations that sound more natural and fluent because it
    translates words as part of a full sentence, rather than only looking at a few
    words around each target word to explain it. The translation engine also makes
    multiple attempts at a translation, learning from previous translation to refine
    the result. The result is a more human-sounding translation, particularly with
    non-Western languages. Check the current [list of supported languages](https://go.microsoft.com/fwlink/?linkid=2190159).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Translator Text API使用深度学习驱动的神经机器翻译技术，这种技术在过去十年中彻底改变了机器翻译，通过将单词作为完整句子的一部分进行翻译，而不仅仅是查看每个目标词周围的几个词来解释它，从而实现更准确、更自然、更流畅的翻译。翻译引擎还会多次尝试翻译，通过以前的翻译学习来优化结果。结果是一种更具人类声音的翻译，尤其适用于非西方语言。查看当前[支持的语言列表](https://go.microsoft.com/fwlink/?linkid=2190159)。
- en: 'You access the models through a REST API. While you can force operation through
    a specific region, Microsoft recommends using the Global option, which dynamically
    directs calls to any available endpoint, usually the one closest to the request
    location. The following Python code snippet calls a translation from English to
    Dutch and Brazilian Portuguese:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过REST API访问这些模型。虽然您可以强制通过特定地区进行操作，但Microsoft建议使用全局选项，动态将调用重定向到任何可用的端点，通常是最接近请求位置的端点。以下Python代码片段调用了从英语到荷兰语和巴西葡萄牙语的翻译：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can have more than one target language in your translation request, with
    each translation in the same JSON return. The response contents indicate the detected
    source language and include a translation block with text and a language identifier
    for each selected target language:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在翻译请求中有多个目标语言，每个翻译都在同一个JSON返回中。响应内容指示检测到的源语言，并包括一个翻译块，其中包含每个选择的目标语言的文本和语言标识符：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The returned data can be parsed by your choice of JSON library.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的数据可以由您选择的JSON库解析。
- en: For additional translations you can use the [Dictionary Lookup API](https://go.microsoft.com/fwlink/?linkid=2190157),
    which will return alternates for the phrase you submit. The JSON data returned
    will have both the source and translated text, with a back translation to help
    you check that the translation is correct. The response will also give you details
    about the word or phrase you’re translating.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用[字典查找 API](https://go.microsoft.com/fwlink/?linkid=2190157)获取额外的翻译，该 API
    将返回您提交的短语的替代翻译。返回的 JSON 数据将包含源文本和已翻译的文本，还有一个反向翻译，以帮助您检查翻译是否正确。响应还将提供有关您正在翻译的单词或短语的详细信息。
- en: You may also want to identify the language that’s being used, so you don’t waste
    API calls on the wrong language pairing or content that can’t be translated.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还希望识别正在使用的语言，这样您就不会在错误的语言配对或无法翻译的内容上浪费 API 调用。
- en: Transliterating text is a useful tool for, say, converting Japanese or Chinese
    pictographs or Cyrillic text to a Western transliteration. In the REST request,
    set a from script and a to script, with the text you wish to transliterate in
    the JSON body. When run, the returned JSON will contain the transliterated text.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 文本转写是一个有用的工具，比如，将日文或中文象形文字或西里尔文字转写为西方转写。在 REST 请求中，设置一个源脚本和一个目标脚本，在 JSON 主体中包含您希望转写的文本。运行后，返回的
    JSON 将包含转写的文本。
- en: Combine the different capabilities to create your own translation service—for
    example, detecting Japanese text, transliterating it to Western script at the
    same time as translating it, while displaying any alternate translations that
    might be available.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 将不同的功能组合起来，创建您自己的翻译服务——例如，检测日文文本，同时将其转写为西方文字，并进行翻译，同时显示可能可用的备选翻译。
- en: The Translator Text APIs are extensible; if you need to tag only a few product
    names, you can apply markup to those phrases to supply the way they should be
    translated. But if you need translations to cover industry-specific terms, or
    language that’s essential to your business, Custom Translator lets you extend
    the default translation neural network models.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Translator Text API 可扩展；如果您只需标记几个产品名称，可以对这些短语应用标记，以提供它们应该被翻译的方式。但如果您需要覆盖行业特定术语或对您业务至关重要的语言，Custom
    Translator 可让您扩展默认的翻译神经网络模型。
- en: Tip
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'The main metric for machine translation is Bilingual Evaluation Understudy
    (BLEU) score: a number from 0 (the worst score) to 1 (the best); this is calculated
    by comparing a translation done by your model to existing reference translations
    done by human translators.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 机器翻译的主要度量标准是双语评估替代（BLEU）分数：从0（最差分数）到1（最佳）的数字；这是通过将您的模型翻译与人类翻译人员已有的参考翻译进行比较来计算的。
- en: 'Custom Translator supports more than three dozen languages and lets you add
    words and phrases that are specific to your business, industry, or region. You
    can build a new translation model using “parallel” documents: pairs of documents
    that have already been translated so they have the same content in two languages
    in common formats. The service can also match sentences that are the same content
    in separate documents; either way, you need at least 10,000 parallel sentences.
    You can also supply a dictionary of specific words, phrases, and sentences that
    you always want translated the same way; that’s useful for product names, technical
    terms that need to match the region, or legal boilerplate.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Custom Translator 支持三十多种语言，并允许您添加特定于您的业务、行业或地区的单词和短语。您可以使用“平行”文档构建新的翻译模型：已经被翻译的文档对，使它们在两种语言中具有相同内容和常见格式。该服务还可以匹配在不同文档中具有相同内容的句子；无论哪种方式，您都需要至少有一万个平行句子。您还可以提供一个特定单词、短语和句子的字典，您始终希望以相同方式翻译；这对于产品名称、需要匹配地区的技术术语或法律底稿非常有用。
- en: Training is relatively quick, on the order of a few hours, and can result in
    a significant improvement in both text and voice translations.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 训练相对较快，大约几个小时，并且可以显著改善文本和语音翻译。
- en: Upload dictionaries, training, tuning, and test documents for each language
    pair you want to use in the [Custom Translator portal](https://portal.customtranslator.azure.ai),
    where you can also share access with colleagues working on the same translation
    project. Or you can upload training data (as shown in [Figure 4-4](#upload_the_datasets_to_the_custom_trans))
    and leave Custom Translator to build the tuning and test sets when you click “Create
    model.”
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为每种语言对上传字典、训练、调整和测试文档至[自定义翻译器门户](https://portal.customtranslator.azure.ai)，您还可以与同一翻译项目上工作的同事共享访问权限。或者，您可以上传训练数据（如[图4-4](#upload_the_datasets_to_the_custom_trans)所示），并在点击“创建模型”时，由自定义翻译器构建调整和测试集。
- en: '![Upload the datasets to the Custom Translator portal, and click “Create model”
    to start training; once trained, you can see various metrics to understand the
    accuracy of your model](Images/aasc_0404.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![将数据集上传到自定义翻译器门户，并点击“创建模型”开始训练；一旦训练完成，您可以查看各种指标以了解模型的准确性](Images/aasc_0404.png)'
- en: Figure 4-4\. Upload the datasets to the Custom Translator portal, and click
    “Create model” to start training; once trained, you can see various metrics to
    understand the accuracy of your model
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-4\. 将数据集上传到自定义翻译器门户，并点击“创建模型”开始训练；一旦训练完成，您可以查看各种指标以了解模型的准确性。
- en: You can also add training data via an API and even use that API to build your
    own interfaces to the service, either adding it to your own document portal or
    making submission an automatic step in a document translation workflow.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过 API 添加训练数据，甚至使用该 API 构建自己的服务界面，将其添加到您自己的文档门户或将提交作为文档翻译工作流程中的自动步骤。
- en: 'As well as translating snippets of text, you can translate entire documents
    and keep the text formatting. Document translation works on PDF, Word, PowerPoint,
    CSV/Excel, Outlook messages, OpenDocument, HTML, Markdown, RTF, tab separate,
    and plain-text files. They can be up to 40 MB in size, in batches of up to 250
    MB, but they can’t be secured with a password or information protection. Store
    the documents in containers in Azure Blob storage (we show a suggested cloud architecture
    for this workflow in [Figure 4-5](#a_typical_azure_architecture_for_buildi)):
    you can translate individual documents or the entire container.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 除了翻译文本片段外，您还可以翻译整个文档并保留文本格式。文档翻译适用于 PDF、Word、PowerPoint、CSV/Excel、Outlook 消息、OpenDocument、HTML、Markdown、RTF、以及分隔符和纯文本文件。它们的大小可达40
    MB，每批次最多250 MB，但不能使用密码或信息保护进行安全。将文档存储在 Azure Blob 存储容器中（我们在[图4-5](#a_typical_azure_architecture_for_buildi)中展示了建议的云架构工作流程）：您可以翻译单个文档或整个容器。
- en: '![A typical Azure architecture for building a document translation workflow
    with Translator](Images/aasc_0405.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Translator 构建文档翻译工作流的典型 Azure 架构](Images/aasc_0405.png)'
- en: Figure 4-5\. A typical Azure architecture for building a document translation
    workflow with Translator
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-5\. 使用 Translator 构建文档翻译工作流的典型 Azure 架构
- en: Warning
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: All API requests to the Document Translation service need a read-only key for
    authenticating access and a custom domain endpoint with your resource name, hostname,
    and Translator subdirectories (*https://<NAME-OF-YOUR-RESOURCE>.cognitive⁠​services.azure.com/translator/text/batch/v1.0*).
    This isn’t the same as the global translator endpoint (`api.cognitive.microsofttranslator.com`)
    or the endpoint listed on the Keys and Endpoint page in your Azure portal.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 所有对文档翻译服务的 API 请求都需要一个只读密钥用于认证访问，并且使用带有您资源名称、主机名和 Translator 子目录的自定义域终结点（*https://<NAME-OF-YOUR-RESOURCE>.cognitive⁠​services.azure.com/translator/text/batch/v1.0*）。这不同于全球翻译器终结点（`api.cognitive.microsofttranslator.com`）或
    Azure 门户中的密钥和终结点页面上列出的终结点。
- en: The translations are high quality, but you may want to use them as a first step
    and have a native speaker improve on them before you use them. If you do use them
    directly, whether it’s a custom or standard translation, it’s important to let
    your users know that the content they’re reading used machine translation (and
    to give them a way to let you know if there are problems with the translation).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译质量很高，但您可能希望将其作为第一步使用，并在使用之前让母语人士对其进行改进。如果您直接使用它们，无论是自定义还是标准翻译，都重要告知用户他们阅读的内容是使用机器翻译（并提供方法让用户告知翻译问题）。
- en: Azure OpenAI Service
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure OpenAI 服务
- en: If you’ve used the GitHub Copilot extension to generate code suggestions or
    had your grammar corrected while learning a language with Duolingo, you’ve seen
    OpenAI’s GPT-3 large language model in action. Several Microsoft products already
    have features based on OpenAI. Dynamics 365 marketing uses it to suggest content
    to include in marketing messages. Power BI uses it to let less experienced users
    say in natural language what they want to do with their data and get complex DAX
    queries written for them (a task with a steep learning curve).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您曾使用GitHub Copilot扩展程序生成代码建议或在Duolingo学习语言时纠正语法，您就已经见识过OpenAI的GPT-3大语言模型的运行情况。微软的几款产品已经基于OpenAI推出了相关功能。Dynamics
    365营销使用它来建议包含在营销信息中的内容。Power BI让经验较少的用户能够用自然语言表达他们想要对其数据做什么，并为他们编写复杂的DAX查询（这是一个学习曲线陡峭的任务）。
- en: The OpenAI API lets you apply GPT-3 to a wide range of language and code tasks
    including extraction, classification, and translation by sending a few free text
    examples of what you want to see (called the prompt), which it analyses and uses
    for pattern matching, predicting the best text to include in the response, which
    is also delivered as free text. This technique is known as “in-context” learning.
    Context can be easily preserved by including prior responses in the text sent
    for each API call, so if the interface in your app allows it, users will be able
    to ask questions of their data iteratively.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API允许你将GPT-3应用于广泛的语言和代码任务，包括提取、分类和翻译，只需发送几个自由文本示例（称为提示），它会分析并用于模式匹配，预测最佳文本包含在响应中，也以自由文本形式交付。这种技术被称为“上下文”学习。通过在每个API调用中包含先前的响应，可以轻松保留上下文，因此如果您的应用界面允许，用户将能够迭代地询问他们的数据问题。
- en: Tip
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'If you want a much deeper understanding of GPT-3, check out another O’Reilly
    book, *GPT-3: Building Innovative NLP Products Using Large Language Models* by
    Sandra Kublik and Shubham Saboo.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想更深入地了解GPT-3，请查看另一本O'Reilly的书籍，*GPT-3：利用大语言模型构建创新的NLP产品*，作者是Sandra Kublik和Shubham
    Saboo。
- en: 'It’s useful for content generation to help a user who needs some help with
    creative writing or generating summaries of articles or conversations, perhaps
    extracting the gist of a customer support call and creating action items or triaging
    top issues for human review. It can search through documents to find answers to
    user questions, matching user query intent to how the documents are semantically
    related and extracting keywords or generating summaries, either to condense long
    text generally or to extract key points. You could create an “I don’t understand
    this” button for education and training scenarios where OpenAI can rephrase the
    content in different words to help explain it. Simple ranking and answer extraction
    doesn’t need the power of OpenAI: use it when you have more generative, open-ended
    questions that need the flexibility and power.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 它对于内容生成非常有用，可以帮助需要创意写作或生成文章或对话摘要的用户，也许可以从客服电话中提取要点并创建行动项或分类需要人工审查的重要问题。它可以通过文档搜索找到用户问题的答案，将用户查询意图与文档的语义关系匹配，并提取关键词或生成摘要，通常是为了概括长文本或提取关键要点。你可以为教育和培训场景创建一个“我不理解这个”的按钮，OpenAI可以用不同的措辞重新表达内容来帮助解释。简单的排名和答案提取不需要OpenAI的强大功能：当你需要更具生成性和开放性的问题时，使用它可以获得更大的灵活性和力量。
- en: Tip
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The GPT-3 models offer the best performance with English, although they have
    some knowledge of French, German, Russian, and other languages. Although Codex
    models are most capable in Python, they can generate code in over a dozen languages
    including JavaScript, Go, Ruby, and SQL. New iterations of the model are regularly
    being released, so be sure to check the documentation for the latest guidance.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然GPT-3模型在英语方面表现最佳，但它们也有一定的法语、德语、俄语和其他语言的知识。尽管Codex模型在Python方面最有能力，但它们可以在包括JavaScript、Go、Ruby和SQL在内的十几种语言中生成代码。模型的新迭代版本定期发布，因此务必查看最新指南文档。
- en: 'You can choose from four base GPT-3 models (Ada, Babbage, Curie, and Davinci)
    that can understand and generate natural language, as well as the Codex series
    of models that can understand and generate code, turning natural language prompts
    into code or explaining code in natural language. Use Codex for suggesting code
    that developers will review and refine, or to make your internal APIs and services
    more accessible to less-proficient developers by explaining how they work and
    offering on-demand code examples:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择四种基本的 GPT-3 模型（Ada、Babbage、Curie 和 Davinci），它们可以理解和生成自然语言，以及 Codex 系列的模型，它们可以理解和生成代码，将自然语言提示转换为代码或用自然语言解释代码。使用
    Codex 提示开发人员审查和完善建议的代码，或通过解释其工作方式并提供按需代码示例，使内部 API 和服务对技能较低的开发人员更易访问：
- en: 'Ada is the fastest GPT-3 model and is a good fit for tasks that don’t require
    too much nuance, like parsing text and correcting addresses: you could use it
    to extract patterns like airport codes.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ada 是最快的 GPT-3 模型，非常适合不需要太多细微差别的任务，例如解析文本和更正地址：您可以使用它提取诸如机场代码之类的模式。
- en: 'Davinci is the most capable model. It can perform all the tasks the other models
    can, often with fewer prompts, and delivers the best results on tasks that require
    more understanding of the content, like taking bullet points and generating different
    lengths of content like suggested headlines or marketing messages, or summarizing
    content in the right tone for specific audiences: you could choose a summary for
    schoolchildren or ask for a more business or professional tone. But it’s also
    the largest model and requires a lot more compute power.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Davinci 是最强大的模型。它可以执行其他模型能够完成的所有任务，通常需要更少的提示，并在需要更深入理解内容的任务上提供最佳结果，例如提取要点并生成不同长度的内容，如建议的标题或营销信息，或者以特定受众的正确语调总结内容：你可以选择适合学生的摘要，或者要求更商业或专业的语调摘要。但它也是最大的模型，需要更多的计算资源。
- en: You can experiment with different models to see which gives you the best trade-off
    between speed and capability. You can also choose between different prompt approaches
    as you move from quick prototyping to creating a customized model that you can
    scale for production.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以尝试不同的模型，以找到在速度和能力之间的最佳权衡。在从快速原型设计到创建可扩展到生产环境的定制模型时，您还可以选择不同的提示方法。
- en: To use the service, create an Azure OpenAI resource using the same procedure
    as any other Azure Cognitive Service. Once the resource has been created, Azure
    will generate access keys and an endpoint for use from your own code.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用该服务，请按照与任何其他 Azure 认知服务相同的步骤创建 Azure OpenAI 资源。一旦资源创建完成，Azure 将生成访问密钥和终结点，供您自己的代码使用。
- en: To process text, the service first breaks the text down into chunks called tokens.
    One token is roughly equal to a short word or a punctuation mark.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理文本，服务首先将文本分解为称为标记的块。一个标记大致相当于一个短词或标点符号。
- en: For example, a word like “doggerel” would be tokenized as “dog,” “ger,” and
    “el,” while “cat” would be a single token. The number of tokens used in a call
    will determine the cost and response speed of an operation. The API calls are
    limited by the number of tokens, which depend on the length of the input, output,
    and parameters. Use [this OpenAI tool](https://beta.openai.com/tokenizer) to see
    how text is broken up into tokens.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，像“doggerel”这样的词将被标记为“dog”、“ger” 和 “el”，而“cat”将是一个单一的标记。调用中使用的标记数量将决定操作的成本和响应速度。API
    调用受标记数量限制，这取决于输入、输出和参数的长度。使用 [此 OpenAI 工具](https://beta.openai.com/tokenizer)
    查看文本如何被分解为标记。
- en: Unlike other Cognitive Services, the OpenAI models use free text for input and
    output, using the natural language instructions and examples you provide as a
    prompt to set the context and predict probable next text.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他认知服务不同，OpenAI 模型使用自由文本作为输入和输出，使用您提供的自然语言指令和示例作为提示来设置上下文并预测可能的下一个文本。
- en: 'This code will generate text using the Davinci natural language model, and
    the prompt you include will determine which of the three in-context learning techniques
    are used: zero-shot, few-shot, or one-shot learning.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将使用 Davinci 自然语言模型生成文本，您包含的提示将决定使用哪种三种上下文学习技术：零-shot、少-shot 或一-shot 学习。
- en: 'Don’t think of this as retraining the model in the usual machine learning sense—you’re
    providing prompts at generation time, not updating the weights in a model. Instead,
    the models generate predictions about what the best text to return is, based on
    the context you include in the prompt, so providing different prompts as examples
    will give you different results:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 不要把这当作通常机器学习意义上的重新训练模型——你是在生成时提供提示，而不是更新模型中的权重。相反，模型根据你在提示中包含的上下文生成关于返回最佳文本的预测，因此提供不同的提示示例将会给出不同的结果：
- en: '[PRE2]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Zero-shot
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 零射击
- en: You don’t have to give an example in the prompt. For quick prototyping, just
    state the objective and the model will generate a response. Accuracy and repeatability
    will depend heavily on your scenario. Models fine-tuned with your own data will
    let you use zero-shot prompts with greater accuracy.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你不必在提示中给出一个例子。对于快速原型设计，只需说明目标，模型就会生成响应。准确性和重复性将严重依赖于你的场景。使用自己的数据进行微调的模型将允许您更准确地使用零射击提示。
- en: Few-shot
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 少射击
- en: You’ll typically need a few more examples in the prompt to demonstrate the format
    and the level of detail you want in the response, to make the text generated for
    you more relevant and reliable. There’s a maximum input length, but depending
    on how long examples are, you can include up to around a hundred of them (though
    you may not need that many).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您需要在提示中添加几个例子，以展示您希望响应中的格式和详细级别，以使为您生成的文本更相关和可靠。输入长度有最大限制，但根据示例的长度，您可以包含大约一百个（尽管您可能不需要那么多）。
- en: One-shot
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一射击
- en: Where you want to show the format for the response, but you don’t expect the
    service to need multiple examples, you can provide just one example.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望显示响应的格式，但不希望服务需要多个示例，可以提供一个示例。
- en: 'The OpenAI Service is stochastic: even with the same prompts, you won’t necessarily
    get the same results every time (so if you use this in a chatbot or interface,
    it should feel fresh rather than predictable). If you ask for multiple results
    when you send the prompt, you can control the amount of variation in those results
    with the temperature parameter: the higher the value, the more variation you’ll
    see.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 服务是随机的：即使使用相同的提示，您也不一定每次都会得到相同的结果（因此，如果在聊天机器人或接口中使用，应该感觉新鲜而不是可预测的）。如果在发送提示时要求多个结果，您可以通过温度参数控制这些结果的变化程度：数值越高，您将看到的变化越大。
- en: Warning
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: 'You’re not guaranteed to get as many responses as you request: sometimes the
    response returned may be blank, so you need to check for that and handle it in
    your code.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 没有保证会得到与您请求的响应数量一样多的响应：有时返回的响应可能为空白，因此您需要检查并在代码中处理它。
- en: Experiment with zero-, one-, and few-shot prompts from different models to see
    what gets you the best result, and then use the API to submit a fine-tuning job
    with your prompt and completion examples to get a customized model you can deploy
    for testing and production.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用来自不同模型的零、一和少射击提示，看看哪个可以为您带来最佳结果，然后使用 API 提交一个带有您的提示和完成示例的微调作业，以获取一个您可以用于测试和生产的定制模型。
- en: Warning
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Because the OpenAI Service produces text that sounds like a human wrote it,
    it’s important both to ensure that the content generated is appropriate for the
    way you’re going to use it and to make sure it can’t be misused. Learn how to
    create a responsible AI strategy for this in [Chapter 7](ch07.xhtml#responsible_ai_development_and_use).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 OpenAI 服务生成的文本听起来像是人类写的，所以确保生成的内容适合您使用的方式并确保它不会被滥用是非常重要的。了解如何为此创建负责任的 AI
    策略，请参阅[第 7 章](ch07.xhtml#responsible_ai_development_and_use)。
- en: Speech
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 演讲
- en: Speech recognition was one of the earliest areas of applied AI research, but
    it’s only in recent years that deep learning has made it powerful enough to use
    widely. The very first successful implementation of deep learning instead of the
    traditional speech recognition algorithms was funded by Microsoft Research, helping
    to transform the industry. [In 2017](https://go.microsoft.com/fwlink/?linkid=2190158),
    a system built by Microsoft researchers outperformed not just individuals but
    a team of humans, accurately transcribing the recorded phone conversations of
    the industry standard Switchboard dataset.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 语音识别是应用AI研究最早的领域之一，但直到近年来深度学习使其强大到足以广泛应用。微软研究的首个成功实现深度学习而非传统语音识别算法的案例，帮助转变了整个行业。[2017年](https://go.microsoft.com/fwlink/?linkid=2190158)，由微软研究人员构建的系统不仅超越了个人，还超越了团队，准确地转录了行业标准Switchboard数据集中的录音电话对话。
- en: The Azure Speech Services cover speech-to-text, text-to-speech, and real-time
    translation of speech in multiple languages. You can customize speech models for
    specific acoustic environments, like a factory floor or background road noise,
    and to recognize and pronounce jargon; we’ll look at how to do that in the next
    chapter. Or you can recognize specific speakers or even use voice authentication
    for access and security with speaker identification and speaker verification.
    Speech services are available through the Speech SDK, the Speech Devices SDK,
    or REST APIs.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Azure语音服务涵盖了语音转文字、文字转语音以及多语言实时语音翻译。您可以根据特定的声学环境（如工厂车间或背景道路噪音）定制语音模型，以识别和发音专业术语；我们将在下一章节讨论如何实现这一点。或者，您可以识别特定的讲话者，甚至使用语音认证来进行访问和安全验证，具体操作包括讲话者识别和验证。语音服务可通过语音
    SDK、语音设备 SDK 或 REST API 使用。
- en: 'Using the Azure speech recognition tools requires working with the Cognitive
    Services Speech SDK. The following snippet of code loads a speech recognizer,
    looking for user intent in their utterances, using LUIS as a backend to the recognition
    process. Here we’re controlling a basic home automation application, looking to
    turn a service on and off. The app will take the first submission from the user
    and use this to drive our hypothetical backend service. Finally, we check if an
    intent is recognized, or if valid speech is detected, before failing or cancelling
    operations:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Azure语音识别工具需要使用认知服务语音 SDK。以下代码片段加载了一个语音识别器，用于检测用户话语中的意图，并使用LUIS作为后端进行识别过程。在这里，我们正在控制一个基本的家庭自动化应用程序，试图打开和关闭某项服务。该应用程序将使用用户的首次提交来驱动我们的假设后端服务。最后，在操作失败或取消之前，我们会检查是否识别出了意图或检测到有效的语音：
- en: '[PRE3]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Speech-to-text
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语音转文字
- en: Transcription used to require hours of time and specialized equipment for a
    trained human to turn speech into text, using a system that’s more like drawing
    gestures than normal typing. It was expensive, and even commercial services don’t
    always reach the 95% accuracy of the best human transcription.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，转录需要经过训练的人员花费数小时的时间，并使用专门的设备将语音转换为文本，这一过程更像是绘制手势而非常规打字。这种方法昂贵，即使商业服务也不能总是达到最佳人工转录的95%准确率。
- en: Azure’s speech-to-text tools work with real-time streamed audio data or prerecorded
    audio files. A single subscription covers all the Cognitive Services speech services,
    so you get access to translation and text-to-speech alongside the speech-to-text
    services.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Azure的语音转文字工具支持实时流式音频数据或预先录制的音频文件。一个订阅即可覆盖所有认知服务的语音服务，因此您可以访问语音转文字服务以及翻译和文字转语音服务。
- en: The core speech-to-text service delivers real-time transcriptions using the
    same technology as Teams and Word, so it’s been proven in a wide range of conditions
    with many accents and in multiple languages. Turn to [Chapter 11](ch11.xhtml#translating_multiple_languages_at_scale)
    to see how it’s used alongside speech translation in some very large organizations.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 核心语音转文字服务使用与Teams和Word相同的技术提供实时转录，因此在多种语音和多种语言的条件下得到了验证。请参阅[第11章](ch11.xhtml#translating_multiple_languages_at_scale)，了解它如何在一些非常大的组织中与语音翻译一起使用。
- en: While you can specify the language to use, which may give more accurate recognition,
    the service default is a universal model with automatic language detection that
    works well in most situations. The list of supported languages is long and continues
    to grow, covering most European languages, Arabic, Thai, Chinese, and Japanese.
    Not all languages have the same level of available customization, but even without
    customizing the language model you’re using, you should be able to get acceptable
    results in office or home applications.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以指定要使用的语言，这可能会提供更准确的识别，但服务的默认设置是使用具有自动语言检测功能的通用模型，适用于大多数情况。支持的语言列表很长，并且在不断增长，涵盖大多数欧洲语言、阿拉伯语、泰语、中文和日语。并非所有语言都具有相同级别的可用定制功能，但即使不定制您正在使用的语言模型，您也应该能够在办公室或家庭应用程序中获得可接受的结果。
- en: Speech-to-text is available through a set of SDKs and REST APIs. As the service
    is primarily intended to be used with streamed data, it’s easiest to use the SDKs,
    as these give you direct access to audio streams, including device microphones
    and local audio recording files. The REST APIs are useful for quick speech commands,
    adding speech controls to mobile apps or the web. If you’ve built custom language
    understanding models in LUIS, you can use these in conjunction with Speech Services
    to extract the speaker intent, making it easier to deliver what your user is asking
    for.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 语音转文本可通过一组 SDK 和 REST API 使用。由于该服务主要用于流式数据，最简单的方法是使用 SDK，因为这些SDK允许您直接访问音频流，包括设备麦克风和本地音频录制文件。REST
    API 适用于快速语音命令，将语音控件添加到移动应用程序或 Web 上。如果您在 LUIS 中构建了自定义语言理解模型，您可以与语音服务一起使用这些模型来提取说话者的意图，从而更容易传达用户所要求的内容。
- en: Calls to the SpeechRecognizer are run using asynchronous connections to Azure,
    handling connections to device microphones in the SDK and recognizing data until
    a set amount of silence is found. Calls can send either short speech or long utterances
    for recognition, and the transcribed text is delivered once the asynchronous process
    is complete. The SDK returns recognized speech as a string, with error handling
    for failed recognitions.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 SpeechRecognizer 时使用与 Azure 的异步连接，SDK 中处理与设备麦克风的连接并识别数据，直到发现一定量的静音。调用可以发送短语音或长话语进行识别，一旦异步过程完成，转录文本将被传送。SDK
    将识别的语音返回为字符串，并包含对识别失败的错误处理。
- en: Text-to-speech
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本转语音
- en: Speech synthesis is useful for industrial settings where users might not be
    able to look at a device screen—or might be wearing a HoloLens. It’s also important
    for accessibility. Increasingly, it’s also used to give products and services
    a recognizable voice for chatbots and other ways consumers interact with brands.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 语音合成对于工业环境非常有用，因为用户可能无法查看设备屏幕，或者可能正在佩戴 HoloLens。这对于无障碍功能也非常重要。越来越多地，它也用于为聊天机器人和其他消费者与品牌互动的方式赋予产品和服务一个可识别的声音。
- en: The text-to-speech services convert text into synthesized speech that’s natural
    and sounds near human. You can pick from a set of standard and higher-quality
    “neural” voices, or if you want to express your brand’s personality you can create
    your own voices.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 文本转语音服务将文本转换为自然且听起来接近人类的合成语音。您可以从一组标准和高质量的“神经”语音中进行选择，或者如果您希望表达您品牌的个性，您可以创建您自己的语音。
- en: Currently, more than 75 standard voices are available, in over 45 languages
    and locales. If you want to experiment with the new neural synthesized voices,
    you can choose between five options in four languages and locales.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 目前提供超过 75 种标准语音，覆盖超过 45 种语言和地区设置。如果您想尝试新的神经合成语音，您可以在四种语言和地区设置中选择五个选项。
- en: Neural text-to-speech is a powerful new improvement over standard speech synthesis,
    offering human-sounding inflection and articulation and making computer-generated
    speech less tiring to listen to. It’s ideal if you’re using speech to deliver
    long-form content—for example, narrating scenes for the visually impaired or when
    generating audiobooks from web content. It’s also a useful tool when you’re expecting
    a lot of human interaction, for high-end chatbots or for virtual assistants. Built
    using deep neural networks, neural voices synthesize speech and apply patterns
    of stress and intonation to that speech in a single step, which makes the generated
    speech sound much more fluent and natural.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 神经文本转语音是对标准语音合成的强大改进，提供人类感的语调和表达，使计算机生成的语音听起来不那么令人疲倦。如果您正在使用语音来传递长篇内容，例如为视觉障碍者叙述场景或从网络内容生成有声书，这是理想的选择。它还是在预期有大量人类互动时的有用工具，适用于高端聊天机器人或虚拟助手。神经音色使用深度神经网络合成语音，并对该语音应用重音和语调模式，从而使生成的语音听起来更加流畅和自然。
- en: Standard speech synthesis supports many more languages, but it’s clearly artificial.
    You can experiment to find the right set of parameters to give it the feel you
    want, tuning speed, pitch, and other settings—including adding pauses to give
    a more natural feel.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 标准语音合成支持更多语言，但显然是人工的。您可以进行实验，找到合适的参数集，使其具有您想要的感觉，调整速度、音调和其他设置，包括添加停顿以增加更自然的感觉。
- en: 'To get the most out of text-to-speech, you’ll probably be using it in an app
    that calls multiple Cognitive Services: perhaps using speech recognition to extract
    requests from a user, passing them through LUIS to generate intents that can be
    used in an application, and then delivering responses using neural voices or your
    own custom voice. If you offer that to people as a chatbot, consider using the
    Azure Bot Service, which offers an integrated experience for working with those
    services together.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要充分利用文本转语音功能，您可能会在调用多个认知服务的应用程序中使用它：例如使用语音识别从用户中提取请求，通过LUIS传递请求以生成可用于应用程序中的意图，然后使用神经音色或您自己的自定义音色进行响应。如果将其提供给用户作为聊天机器人，请考虑使用Azure
    Bot Service，该服务提供了与这些服务集成的综合体验。
- en: Use the Speech SDK from C# (using the .NET Standard-based SDK that works on
    Windows, Linux, macOS, Mono, Xamarin, UWP, and Unity), C++, Java, Go, Python,
    Objective-C/Swift, or JavaScript to give your applications access to speech-to-text,
    text-to-speech, speech translation, and intent recognition. Some versions of the
    SDK support different features, and you may find that more complex operations
    require using direct access to the Speech Service APIs.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 使用来自C#的语音SDK（使用基于.NET标准的SDK，适用于Windows、Linux、macOS、Mono、Xamarin、UWP和Unity）、C++、Java、Go、Python、Objective-C/Swift或JavaScript，使您的应用程序能够访问语音识别、文本转语音、语音翻译和意图识别。SDK的某些版本支持不同的功能，您可能会发现更复杂的操作需要直接访问语音服务API。
- en: Translation and unified speech
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 翻译和统一语音
- en: One of the first deep learning services that Microsoft demonstrated, when today’s
    Cognitive Services were still just projects inside Microsoft Research, was the
    real-time speech translation tools. Using a modified version of Skype, an English
    speaker could communicate with a Chinese speaker in real time, using subtitles
    to translate the conversation.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当今的认知服务仍然只是微软研究项目时，微软展示的第一个深度学习服务之一是实时语音翻译工具。使用修改版的Skype，英语说话者可以实时与中文说话者交流，使用字幕来翻译对话。
- en: Now those translation services have gone from research to product to service—for
    example, in the Microsoft Translator app as shown in [Figure 4-6](#the_microsoft_translate_mobile_app_can)—and
    speech translation SDKs in Speech Services let you add real-time translation services
    to your C#, C++, and Java applications. Using neural machine translation techniques
    rather than the traditional statistical approach, this delivers much higher-quality
    translations using a large training set of millions of translated sentences.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这些翻译服务已经从研究阶段发展成为产品和服务，例如在Microsoft Translator应用程序中展示的[图4-6](#the_microsoft_translate_mobile_app_can)中，并且语音翻译SDK在语音服务中可以让您为C#、C++和Java应用程序添加实时翻译服务。使用神经机器翻译技术而不是传统的统计方法，这种方法利用数百万句子的大型训练集，提供更高质量的翻译。
- en: The speech translation tool uses a four-step process, starting with speech recognition
    to convert spoken words into text. The transcribed text is then passed through
    a TrueText engine to normalize the speech and make it more suitable for translation.
    Next, the text is passed through the machine translation tools using conversation-optimized
    models, before being delivered as text or processed into voice through the Speech
    Services text-to-speech tools. The actual translation is done by the Translator
    Text API, which we covered in detail in [“Translator”](#translator).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 语音翻译工具采用四步流程，从语音识别开始，将口语转换为文本。然后，通过TrueText引擎将转录的文本规范化，使其更适合翻译。接下来，文本通过使用面向对话优化的模型的机器翻译工具处理，然后作为文本传送或通过语音服务的文本到语音工具转换成语音。实际的翻译由Translator
    Text API完成，我们在[“Translator”](#translator)中详细介绍过。
- en: '![The Microsoft Translate mobile app can translate spoken language or text
    in a photograph](Images/aasc_0406.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![Microsoft Translate移动应用可以翻译口语或照片中的文本](Images/aasc_0406.png)'
- en: Figure 4-6\. The Microsoft Translate mobile app can translate spoken language
    or text in a photograph
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-6\. Microsoft Translate移动应用可以翻译口语或照片中的文本
- en: The speech translation tools work in a similar fashion to the standard speech
    recognition tools, using a TranslationRecognizer object to work with audio data.
    By default, it uses the local microphone, though you can configure it to use alternative
    audio sources. To make a translation, you set both source and target languages,
    using the standard Windows language types (even if your app doesn’t run on Windows).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 语音翻译工具与标准语音识别工具类似，使用TranslationRecognizer对象处理音频数据。默认情况下，它使用本地麦克风，但您可以配置它使用替代音频源。要进行翻译，您需要设置源语言和目标语言，使用标准的Windows语言类型（即使您的应用程序不运行在Windows上）。
- en: 'You’ll need to install the Azure Speech Services SDK to work with the translation
    tools, storing your key and region details as environment variables. For Python,
    use:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要安装Azure Speech Services SDK来使用翻译工具，并将您的密钥和区域详细信息存储为环境变量。对于Python，使用：
- en: '[PRE4]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'With that in place, set to and from languages, before running a speech recognizer
    and converting speech to translated text. The sample code here uses your PC’s
    microphone to translate from French to Brazilian Portuguese. You can choose multiple
    target languages, especially if you’re serving a diverse group of users. The translated
    text can be delivered to a speech synthesizer if necessary:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这些设置后，设定语言，然后运行语音识别器并将语音转换为翻译文本。此处的示例代码使用您PC上的麦克风将法语翻译为巴西葡萄牙语。您可以选择多种目标语言，尤其是如果您服务的用户群体多样化的话。如果需要，翻译文本可以传送到语音合成器：
- en: '[PRE5]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Translations are delivered as events, so your code needs to subscribe to the
    response stream. The streamed data can either be displayed as text in real time,
    or you can use it to produce a synthesized translation, using neural speech if
    available. By working with APIs, you can produce in a few lines of code what would
    have been a large project if implemented from scratch. Similarly, Azure’s cloud
    pricing model means it’s economical to add speech to applications where you wouldn’t
    have considered expensive client-side translation services.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译作为事件交付，因此您的代码需要订阅响应流。流数据可以实时显示为文本，或者您可以使用它来生成合成翻译，如果有的话，可以使用神经语音。通过使用API，您可以在几行代码内生成从头开始实施将成为大型项目的内容。同样，Azure的云定价模型意味着，在您未考虑昂贵的客户端翻译服务的应用程序中添加语音是经济实惠的。
- en: The custom translation models we looked at as part of the language APIs are
    also available for translating speech.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 作为语言API的一部分，我们查看的自定义翻译模型也可用于语音翻译。
- en: Vision
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视觉
- en: Want to know what’s in an image or a video? The different vision APIs and services
    can recognize faces, emotions and expressions, objects and famous landmarks, scenes
    and activities, or text and handwriting. You can get all the power of a fully
    trained image recognition deep learning network, and then you can customize it
    to recognize the specific objects you need with only a few dozen examples. Use
    that to find patterns that can help diagnose plant disease, or classify the world
    and narrate it to the blind, or generate metadata summaries that can automate
    image archiving and retrieval.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 想知道图像或视频中有什么？不同的视觉 API 和服务可以识别人脸、情绪和表情、物体和著名地标、场景和活动，或者文本和手写。您可以获得完全训练的图像识别深度学习网络的所有功能，然后可以根据仅有几十个示例自定义它，以识别您需要的特定对象。用它来发现可以帮助诊断植物疾病的模式，或者对盲人分类世界并进行叙述，或者生成可以自动化图像归档和检索的元数据摘要。
- en: The vision APIs and technologies in Cognitive Services are the same as those
    that power Bing’s image search and OCR text from images in OneNote and index video
    in Azure Streams. They provide endpoints that take image data and return labeled
    content you can use in your app, whether that’s the text in a menu, the expression
    on someone’s face, or a description of what’s going on in a video.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Cognitive Services 中的视觉 API 和技术与 Bing 的图像搜索、OneNote 中的图像 OCR 文本以及 Azure Streams
    中的视频索引相同。它们提供端点，接收图像数据并返回标记的内容，您可以在应用程序中使用，无论是菜单中的文本、某人脸上的表情，还是视频中正在发生的事情的描述。
- en: As well as the APIs, there are also SDKs for many popular platforms. If you’re
    using custom machine learning tools and analytical frameworks like Anaconda or
    Jupyter Notebooks, there’s support for Python. Windows developers can access the
    Computer Vision service from .NET, JavaScript via Node.js, Android with Java,
    and iOS using Swift, and there’s Go support for systems programming.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 API 外，许多流行平台还提供 SDK。如果您正在使用自定义的机器学习工具和分析框架，如 Anaconda 或 Jupyter Notebooks，Python
    有相应的支持。Windows 开发人员可以通过 .NET 访问计算机视觉服务，通过 Node.js 访问 JavaScript，通过 Java 访问 Android，通过
    Swift 访问 iOS，还有针对系统编程的 Go 支持。
- en: Behind the APIs are a set of deep neural networks trained to perform functions
    like image classification, scene and activity recognition, celebrity and landmark
    recognition, OCR, and handwriting recognition.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些 API 的背后是一组深度神经网络，经过训练执行图像分类、场景和活动识别、名人和地标识别、OCR 和手写识别等功能。
- en: Many of the computer vision tasks are provided by a single API namespace, Analyze
    Image, which supports the most common image recognition scenarios. When you make
    a call to the different endpoints in the API namespace, the appropriate neural
    network is used to classify your image. In some cases, this may mean the image
    passes through more than one model, first to recognize an object and then to extract
    additional information. That way you can use a picture of the shelves in a supermarket
    to identify not only the packaging types on display but also the brands being
    sold and even whether the specific products are laid out in the right order on
    the shelf (something that’s time-consuming and expensive to audit manually).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 许多计算机视觉任务由单个 API 命名空间 Analyze Image 提供，支持最常见的图像识别场景。当您调用 API 命名空间中不同的端点时，将使用适当的神经网络对您的图像进行分类。在某些情况下，这可能意味着图像会经过多个模型，首先识别对象，然后提取附加信息。这样一来，您可以使用超市货架上的图片，不仅识别展示的包装类型，还可以识别销售的品牌，甚至检查特定产品是否按正确顺序摆放（这在手动审核时既耗时又昂贵）。
- en: 'The Analyze Image API attempts to detect and tag various visual features, marking
    detected objects with a bounding box. Use the Vision API in the sample Cognitive
    Services kiosk to experiment with the API, as in [Figure 4-7](#use_the_vision_api_explorer_to_see_what).
    Those features include:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Analyze Image API 试图检测和标记各种视觉特征，并使用边界框标记检测到的对象。在示例 Cognitive Services 亭中使用 Vision
    API 进行实验，如 [图 4-7](#use_the_vision_api_explorer_to_see_what) 中所示。这些功能包括：
- en: Tagging visual features
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记视觉特征
- en: Detecting objects
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测物体
- en: Detecting brands
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测品牌
- en: Categorizing images
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像分类
- en: Describing images
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像描述
- en: Detecting faces
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测人脸
- en: Detecting image types
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测图像类型
- en: Detecting domain-specific content
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测领域特定内容
- en: Detecting color schemes
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测色彩方案
- en: Generating thumbnails
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成缩略图
- en: Detecting areas of interest
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测感兴趣的区域
- en: You can call the Analyze Image endpoint to group many of these tasks together—for
    example, extracting tags, detecting objects and faces—or you can call those features
    individually by using their specific endpoints. Other operations, like generating
    thumbnails, require calling the task-specific endpoint.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以调用Analyze Image端点将许多这些任务组合在一起——例如，提取标签、检测物体和面部——或者你可以通过使用其特定端点单独调用这些功能。其他操作，如生成缩略图，需要调用特定任务的端点。
- en: '![Use the Vision API Explorer to see what information Analyze Image returns
    for an image](Images/aasc_0407.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![使用Vision API Explorer查看Analyze Image返回图像的信息](Images/aasc_0407.png)'
- en: Figure 4-7\. Use the Vision API Explorer to see what information Analyze Image
    returns for an image
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-7。使用Vision API Explorer查看Analyze Image返回图像的信息
- en: For more advanced requirements than simple face recognition in the Computer
    Vision API, use the separate Face API to compare two faces, to search by face
    for images of the same person in an archive, or to compare a selfie to a set of
    stored images to identify someone by their face instead of a password. When you
    want to understand movements and presence in a physical space, the Spatial Analysis
    APIs ingest video from CCTV or industrial cameras, detect and track people in
    the video as they move around, and generate events as they interact with the regions
    of interest you set in the space. You can use this to count the number of people
    entering a space, see how quickly they move through an area, or track compliance
    with guidelines for social distancing and mask wearing.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于比简单面部识别更高级的计算机视觉API需求，使用独立的面部API来比较两张面孔，通过面部搜索在存档中查找相同人物的图像，或者将自拍与存储的图像集进行比较，以通过面部识别而不是密码来识别某人。当你想要了解物理空间中的运动和存在时，空间分析API会从CCTV或工业摄像头摄取视频，检测并跟踪视频中的人物在空间中的移动，并在他们与你在空间中设置的感兴趣区域互动时生成事件。你可以使用这些功能来统计进入空间的人数，观察他们通过某个区域的速度，或跟踪遵守社交距离和戴口罩指南的情况。
- en: Warning
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: 'It’s particularly important to use face recognition, spatial analysis, and
    video analysis services responsibly: check out the guidance in [Chapter 7](ch07.xhtml#responsible_ai_development_and_use)
    for how to approach this.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用面部识别、空间分析和视频分析服务时，特别需要负责任地使用：请查看[第7章](ch07.xhtml#responsible_ai_development_and_use)的指导，了解如何处理此类问题。
- en: To get started with Computer Vision, download the SDK, using pip. You’ll also
    need the pillow image processing library.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用计算机视觉，使用pip下载SDK。你还需要pillow图像处理库。
- en: '[PRE6]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'With the SDK and required components in place, you can start to write code.
    First import libraries, and then add your key and endpoint URL, before authenticating
    with the service:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用了   在SDK和所需组件就绪后，你可以开始编写代码。首先导入库，然后添加你的密钥和终端URL，最后进行服务验证：
- en: '[PRE7]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'With this in place, you’re now ready to analyze an image. We’ll use an image
    URL as a start:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 设置好后，你现在可以开始分析图像了。我们将使用一个图像URL作为起点：
- en: '[PRE8]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Our application will use the object detection feature of the Computer Vision
    API. Once the image has been processed, it will display details of what has been
    detected and where. You could use this data to quickly add overlay boxes and captions
    to an image:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的应用程序将使用计算机视觉API的物体检测功能。一旦图像处理完成，它将显示已检测到的内容及其位置。你可以使用这些数据快速在图像上添加叠加框和字幕：
- en: '[PRE9]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Tip
  id: totrans-163
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Most of the computer vision tools return machine-readable information, but sometimes
    you need text that can be used as a caption or readout in an audio description.
    Call this capability either with the */analyze* endpoint or the standalone */describe*
    endpoint. Descriptions are returned as a JSON document in an ordered list in terms
    of confidence, along with associated tags that can be used for extra context.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数计算机视觉工具返回机器可读的信息，但有时你需要文本，这些文本可以用作字幕或音频描述的读出。通过调用*/analyze*端点或独立的*/describe*端点来使用此功能。描述作为JSON文档返回，以信心水平的有序列表形式，同时附带可用于额外上下文的标签。
- en: When you request tags for an image using Image Analysis, the data returned is
    a word list you can use to classify images, like making a gallery of all the images
    in a set that contain car parts, or are taken outdoors. By providing multiple
    tags for an image, you can create complex indexes for your image sets that can
    then be used to describe the scene depicted, or find images of specific people,
    objects, or logos in an archive.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用图像分析请求图像的标记时，返回的数据是一个单词列表，您可以使用它来分类图像，例如创建一个包含所有包含汽车零件或在室外拍摄的图像集的画廊。通过为图像提供多个标记，您可以为图像集创建复杂的索引，然后用于描述所描绘的场景，或在存档中查找特定人物、物体或标志的图像。
- en: 'We can add the following snippet to our object recognition code to generate
    a list of object tags along with their confidence level:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将以下代码片段添加到我们的对象识别代码中，以生成带有其置信水平的对象标记列表：
- en: '[PRE10]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To use this API, you need to upload a still image or provide a link to an image
    URL. The API returns a JSON document that contains recognized objects, along with
    a confidence value you can use as a cutoff to define when to apply a tag (or when
    to show the tag to your users). Pick a high threshold to avoid false positives
    and poor matches cluttering up tags and search results.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用此 API，您需要上传静态图像或提供图像 URL 链接。API 将返回包含识别对象的 JSON 文档，以及您可以用作截止值的置信度值，用于定义何时应用标记（或何时向用户显示标记）。选择一个较高的阈值以避免虚假阳性和匹配不良干扰标签和搜索结果。
- en: 'Object detection also takes an image or URL; it returns the bounding box coordinates
    for objects and the relationship between them: whether a “tree” is next to a “house”
    or a “car” is in front of a “truck.” The brand detection API is a specialized
    version for product logos. If you want to improve recognition for specific classes
    of images, you can train a custom vision model: we cover the steps for doing that
    in the next chapter.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 对象检测还可以获取图像或 URL；它返回对象的边界框坐标及其之间的关系：例如“树”是否在“房子”旁边，或“汽车”是否在“卡车”的前面。品牌检测 API
    是产品标志的专业版本。如果您想为特定类别的图像改进识别，可以训练定制视觉模型：我们将在下一章节介绍如何执行这些步骤。
- en: 'Image categorization is a much higher-level approach than the other image classification
    tools: it’s useful for filtering a large image set to see if a picture is even
    relevant and whether you should be using more complex algorithms. Similarly, the
    Analyze Image API can tell you if an image is a photo, clip art, or line art.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类是比其他图像分类工具更高级的方法：它有助于过滤大量图像集，以查看图像是否相关，以及是否应使用更复杂的算法。类似地，分析图像 API 可以告诉您图像是否是照片、剪贴画还是线条艺术。
- en: Decision Making
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 决策制定
- en: Need to detect problems and get warnings when something starts to go wrong?
    You can use the Anomaly Detector API for spotting fraud, telling when the sensor
    in an IoT device is failing, catching changing patterns in services or user activity,
    detecting an outage as it starts, or even looking for unusual patterns in financial
    markets. This is the anomaly detection Microsoft uses to monitor dozens of its
    own cloud services, so it can handle very large-scale data.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 需要在某些事情开始出问题时检测问题并获得警告吗？您可以使用异常检测 API 来发现欺诈、检测 IoT 设备中传感器故障、捕捉服务或用户活动中的变化模式、在故障开始时检测中断，甚至在金融市场中寻找异常模式。这是微软用来监控其自有云服务的异常检测，因此它可以处理非常大规模的数据。
- en: Designed to work with real-time or historical time series data, using individual
    or groups of metrics from multiple sensors, the API determines whether a data
    point is an anomaly and whether it needs to be delivered as an alert, without
    you needing to provide labeled data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 设计用于实时或历史时间序列数据，使用单个或多个传感器的多个指标，该 API 确定数据点是否异常，并确定是否需要将其作为警报传递，而无需提供标记数据。
- en: If you’re using Python with the anomaly detector, you’ll also need to install
    the Pandas data analysis library. Use pip to install it and the Azure anomaly
    SDK. The code snippet here also uses local environment variables to store your
    keys and endpoint data. Please create these before running the application. You’ll
    also need a CSV file with time series data, giving your code a path to the data.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在使用异常检测的 Python，你还需要安装 Pandas 数据分析库。使用 pip 安装它和 Azure 异常 SDK。这里的代码片段还使用本地环境变量来存储你的密钥和端点数据。在运行应用程序之前，请先创建这些变量。你还需要一个包含时间序列数据的
    CSV 文件，并将其路径传递给你的代码。
- en: 'This code will analyze a set of time series data with a daily granularity,
    looking for anomalies in the data. It will then indicate where in the file an
    anomaly was found, allowing you to pass the data on for further analysis, alerting
    those responsible for the equipment or service generating the data:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将分析一组具有每日粒度的时间序列数据，查找数据中的异常。然后它将指示在文件中发现异常的位置，使您可以将数据传递给进一步的分析，并警告负责生成数据的设备或服务的相关人员：
- en: '[PRE11]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The Personalizer service uses reinforcement learning to pick what product to
    recommend to online shoppers, what content to prioritize for a specific visitor,
    or where to place an ad. It can work with text, images, URLs, emails, chatbot
    responses, or anything where there’s a short list of actions or items to choose
    from, enough contextual information about the content to use for ranking, and
    enough traffic for the service to keep learning from. Every time a Personalizer
    pick is shown, the service gets a reward score between 0 and 1, based on how the
    shopper or reader reacted—did they click the link, scroll to the end or buy the
    product, pick something different or look around and then chose what was offered—that’s
    used to improve the already-trained model. We’ll see the Personalizer service
    in action in [Chapter 12](ch12.xhtml#bringing_reinforcement_learning_from_th),
    where it powers recommendations in an online marketplace.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: Personalizer 服务利用强化学习来选择向在线购物者推荐哪种产品，优先显示哪些内容给特定访客，或者在哪里放置广告。它可以处理文本、图像、网址、电子邮件、聊天机器人回复或任何有一个较短的行动或选择列表的地方，内容足够提供排名使用的上下文信息，服务有足够的流量可以继续学习。每次
    Personalizer 服务进行选择时，基于购物者或读者的反应（他们是否点击了链接、滚动到底部或购买了产品，选择了不同的东西或四处查看然后选择了所提供的东西），服务会获得一个介于
    0 和 1 之间的奖励分数，用于改进已经训练好的模型。我们将在[第12章](ch12.xhtml#bringing_reinforcement_learning_from_th)中看到
    Personalizer 服务的实际应用，它为在线市场推荐提供支持。
- en: Content moderation
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内容审核
- en: Whether you want to keep a chat room family friendly or make sure your ecommerce
    site doesn’t offer products with unfortunate or offensive phrases printed on them,
    content moderation services can help. The Image and Video Indexer APIs can detect
    adult or “racy” content that might not be suitable for your audience. There’s
    also an image moderation tool that can spot images that might be offensive or
    unpleasant, including using OCR to look for offensive language.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是想保持聊天室的家庭友好性，还是确保您的电子商务网站不提供印有不幸或冒犯性短语的产品，内容审核服务都能提供帮助。图像和视频索引器 API 可以检测到成人或“性感”内容，这可能不适合您的受众。还有一个图像审核工具，可以识别可能具有冒犯性或不愉快的图像，包括使用
    OCR 查找冒犯性语言。
- en: 'Images and video are uploaded to the service and passed to the Analyze Image
    API. Two Booleans are returned: isAdultContent and isRacyContent, along with confidence
    scores.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图像和视频上传到服务并传递到分析图像 API。将返回两个布尔值：isAdultContent 和 isRacyContent，以及置信度分数。
- en: 'Start by installing the content moderator library via pip:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 首先通过 pip 安装内容审核库：
- en: '[PRE12]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can now start to build a service that works with Azure to moderate content
    on your site. Here we’re providing a list of images to check for identifiable
    faces:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以开始构建一个与 Azure 协作以审核您站点上内容的服务。在这里，我们提供了一个要检查可识别面孔的图像列表：
- en: '[PRE13]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Content moderation isn’t only for images; it can also work with text content.
    This can find more than adult or racy content; as well as offensive language,
    including looking for terms that are misspelled (maybe on purpose to evade moderation),
    it scans for personally identifiable information (PII) that’s subject to regulation
    in many jurisdictions. You can add custom terms—for example, if you don’t want
    to include posts that mention competing brands. You create the API wrapper in
    the same way as for images. The more comprehensive Azure Content Moderator service
    includes custom lists for content that’s often submitted that you don’t need to
    classify every time and can reject straight away.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 内容审核不仅适用于图像；它还可以处理文本内容。这可以找到更多不只是成人或性感内容的内容；除了寻找含有冒犯性语言的内容（包括有意拼写错误以逃避审核的术语），它还扫描个人可识别信息（PII），这在许多司法管辖区受到规定的管制。您可以添加自定义术语
    - 例如，如果您不希望包括提到竞争品牌的帖子。您可以像处理图像一样创建 API 封装器。更全面的 Azure 内容审核服务包括用于经常提交的内容的自定义列表，您无需每次分类即可直接拒绝。
- en: Tip
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Which Cognitive Services decision models can you customize?
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以自定义哪些认知服务决策模型？
- en: '[Metrics Advisor](https://oreil.ly/sR2td) (you must be logged in to an Azure
    account to open this URL)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Metrics Advisor](https://oreil.ly/sR2td)（您必须登录 Azure 账户才能打开此网址）'
- en: 'Personalizer: customize your model in the Azure portal under Personalizer.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Personalizer: 在Azure门户下个性化你的模型。'
- en: Wrapping It Up
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结语
- en: In this chapter, we’ve looked at what you can achieve with the Azure Cognitive
    Services with prebuilt or customized models that you call through APIs or SDKs—but
    we’ve looked at them as separate options, and that may not be what you’ll want
    to do in a real application. Individual Cognitive Services are powerful, but often
    you will want to combine multiple Cognitive Services to handle broader scenarios.
    You can do that yourself in code, but there are some services that developers
    use together so commonly that Microsoft has bundled them into Applied AI Services.
    Read on to learn what you can do with them.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看了看使用Azure认知服务可以实现的内容，包括预构建或定制模型，通过API或SDK调用，但我们将它们视为独立的选项，这可能不是你在实际应用中想要的。单个认知服务很强大，但通常你会想要结合多个认知服务来处理更广泛的场景。你可以在代码中自行实现这一点，但有些服务开发人员使用得如此普遍，以至于Microsoft已将它们捆绑成应用AI服务。继续阅读以了解你可以用它们做些什么。
- en: ^([1](ch04.xhtml#ch01fn5-marker)) If you want to more details about the different
    Cognitive Services and how you use them, see the [online documentation](https://go.microsoft.com/fwlink/?linkid=2190271)
    or check out our previous book, *Building Intelligent Apps with Cognitive APIs*.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch04.xhtml#ch01fn5-marker)) 如果你想了解更多关于不同认知服务及其如何使用的细节，请查阅[在线文档](https://go.microsoft.com/fwlink/?linkid=2190271)或查看我们之前的书籍，*使用认知API构建智能应用*。
