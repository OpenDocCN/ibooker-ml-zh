- en: Chapter 8\. Model Quality and Continuous Evaluation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章\. 模型质量和持续评估
- en: So far in this book, we have covered the design and implementation of vision
    models. In this chapter, we will dive into the important topic of monitoring and
    evaluation. In addition to beginning with a high-quality model, we also want to
    maintain that quality. In order to ensure optimal operation, it is important to
    obtain insights through monitoring, calculate metrics, understand the quality
    of the model, and continuously evaluate its performance.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本书涵盖了视觉模型的设计和实现。在本章中，我们将深入讨论监控和评估这一重要主题。除了从高质量模型开始，我们还希望保持该质量。为了确保最佳运行，通过监控获得洞察力、计算指标、理解模型的质量以及持续评估其性能非常重要。
- en: Monitoring
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: So, we’ve trained our model on perhaps millions of images, and we are very happy
    with its quality. We’ve deployed it to the cloud, and now we can sit back and
    relax while it makes great predictions forever into the future… Right? Wrong!
    Just as we wouldn’t leave a small child alone to manage him or herself, we also
    don’t want to leave our models alone out in the wild. It’s important that we constantly
    monitor their quality (using metrics like accuracy) and computational performance
    (queries per second, latency, etc.). This is especially true when we’re constantly
    retraining models on new data that may contain distribution changes, errors, and
    other issues that we’ll want to be aware of.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可能已经在数百万图像上训练了我们的模型，并且对其质量非常满意。我们已经将其部署到了云端，现在我们可以坐下来放松，让它永远为未来做出优秀的预测……
    对吗？错！正如我们不会让小孩子独自管理自己一样，我们也不希望把我们的模型单独留在野外。重要的是，我们要不断监控其质量（使用准确性等指标）和计算性能（每秒查询、延迟等）。特别是当我们不断使用新数据对模型进行重新训练时，可能会出现分布变化、错误和其他问题，我们需要注意这些问题。
- en: TensorBoard
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorBoard
- en: Often ML practitioners train their models without fully considering all the
    details. They submit a training job and check it every now and then until the
    job is finished. Then they make predictions using the trained model to see how
    it’s performing. This may not seem like a big deal if the training jobs take a
    few minutes. However, many computer vision projects, especially with datasets
    that contain millions of images, have training jobs that take days or weeks. It
    would be terrible if something went wrong with the training early on and we didn’t
    notice until training was complete, or until we tried to use the model to make
    some predictions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，机器学习从业者在训练模型时并未充分考虑所有细节。他们提交一个训练任务，然后不时检查，直到任务完成。然后，他们使用训练好的模型进行预测，查看其性能如何。如果训练任务只需几分钟，这可能看起来无关紧要。然而，许多计算机视觉项目，特别是包含数百万图像的数据集，其训练任务需要花费数天甚至数周的时间。如果在训练早期出现问题而我们没有注意到，或者直到训练完成或尝试使用模型进行预测时才注意到，那将是非常糟糕的。
- en: There is a great monitoring tool called TensorBoard that is distributed with
    TensorFlow that we can use to avoid just this scenario. TensorBoard is an interactive
    dashboard (see [Figure 8-1](#the_tensorboard_scalar_summary_uidot)) that displays
    summaries saved during model training and evaluation. You can use it as a historical
    record of experiments run, for comparing different versions of your model or code,
    and for analyzing training jobs.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个名为 TensorBoard 的优秀监控工具，它与 TensorFlow 一起分发，可以用来避免这种情况。TensorBoard 是一个交互式仪表板（参见[图
    8-1](#the_tensorboard_scalar_summary_uidot)），显示了模型训练和评估期间保存的摘要信息。您可以将其用作实验运行的历史记录，用于比较您模型或代码的不同版本，并用于分析训练任务。
- en: '![](Images/pmlc_0801.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0801.png)'
- en: Figure 8-1\. The TensorBoard scalar summary UI.
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-1\. TensorBoard 标量摘要 UI。
- en: TensorBoard allows us to monitor loss curves to make sure that the model training
    is still progressing, and it hasn’t stopped improving. We can also display and
    interact with any other evaluation metrics we have in our model, such as accuracy,
    precision, or AUC—for example, we can perform filtering across multiple series,
    smoothing, and outlier removal, and we’re able to zoom in and out.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 允许我们监控损失曲线，以确保模型训练仍在进行中，并且没有停止改进。我们还可以显示和与模型中的任何其他评估指标交互，例如准确性、精度或AUC——例如，我们可以跨多个系列执行过滤、平滑和异常值移除，并且能够放大和缩小。
- en: Weight Histograms
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 权重直方图
- en: We can also explore histograms in TensorBoard, as shown in [Figure 8-2](#the_tensorboard_histogram_uidot_model_we).
    We can use these to monitor weights, gradients, and other scalar quantities that
    have too many values to inspect individually.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在TensorBoard中探索直方图，如[图 8-2](#the_tensorboard_histogram_uidot_model_we)所示。我们可以用它们来监视权重、梯度和其他数量过多的标量。
- en: '![](Images/pmlc_0802.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0802.png)'
- en: Figure 8-2\. The TensorBoard histogram UI. Model weights are on the horizontal
    axis and the training step number is on the vertical axis.
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-2\. TensorBoard直方图用户界面。模型权重位于水平轴上，训练步骤编号位于垂直轴上。
- en: Device Placement
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设备放置
- en: We can output the TensorFlow model graph to TensorBoard for visualization and
    exploration, as shown in [Figure 8-3](#tensorboard_model_graph_visualizationsco).
    .
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将TensorFlow模型图输出到TensorBoard以进行可视化和探索，如[图 8-3](#tensorboard_model_graph_visualizationsco)所示。
- en: '![](Images/pmlc_0803.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0803.png)'
- en: 'Figure 8-3\. TensorBoard model graph visualizations: structure view (left)
    and device view (right).'
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-3\. TensorBoard模型图可视化：结构视图（左）和设备视图（右）。
- en: The default structure view shows which nodes share the same structure, and the
    device view shows which nodes are on which device(s), with a color per device.
    We can also see TPU compatibility and more. This can allow us to ensure that our
    model code is being accelerated properly.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的结构视图显示哪些节点共享相同的结构，设备视图显示哪些节点位于哪些设备上，每个设备用不同的颜色表示。我们还可以看到TPU的兼容性等信息。这可以帮助我们确保我们的模型代码得到适当的加速。
- en: Data Visualization
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据可视化
- en: TensorBoard can display examples of specific types of data, such as images (on
    the Images tab, shown on the left in [Figure 8-4](Images/#the_tensorboard_images_tab_allows_you_to))
    or audio (on the Audio tab). This way, we can get feedback as training is progressing;
    for example, with image generation, we can see live how our generated images are
    looking. For classification problems, TensorBoard also has the ability to display
    confusion matrices, as seen on the right in [Figure 8-4](Images/#the_tensorboard_images_tab_allows_you_to),
    so we can monitor metrics per class throughout a training job (more on this in
    [“Metrics for Classification”](#metrics_for_classification)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard可以显示特定类型的数据示例，例如图像（在图像选项卡上，如[图 8-4](Images/#the_tensorboard_images_tab_allows_you_to)所示在左侧）或音频（在音频选项卡上）。这样，我们可以在训练过程中得到反馈；例如，在图像生成方面，我们可以实时查看生成图像的外观。对于分类问题，TensorBoard还可以显示混淆矩阵，如[图 8-4](Images/#the_tensorboard_images_tab_allows_you_to)右侧所示，这样我们可以监控每个类别在整个训练过程中的指标（更多详细信息请参见[“分类的度量”](#metrics_for_classification)）。
- en: '![](Images/pmlc_0804.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0804.png)'
- en: Figure 8-4\. The TensorBoard Images tab allows you to visualize training images
    (left) and view a confusion matrix (right) to see where the classifier is making
    most of its mistakes.
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-4\. TensorBoard图像选项卡允许您可视化训练图像（左）并查看混淆矩阵（右），以了解分类器大部分错误发生的位置。
- en: Training Events
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练事件
- en: 'We can add a TensorBoard callback to our model using code like the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码为我们的模型添加TensorBoard回调：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We specify the directory path where the TensorBoard event logs will get written
    to disk using the `log_dir` argument. `histogram_freq` and `embeddings_freq` control
    how often (in epochs) those two types of summaries are written; if you specify
    a value of zero they are not computed or displayed. Note that validation data,
    or at least a split, needs to be specified when fitting the model for histograms
    to show. Furthermore, for embeddings, we can pass a dictionary to the argument
    `embeddings_metadata` that maps layer names to a filename where the embedding
    metadata will be saved.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过`log_dir`参数指定TensorBoard事件日志将写入磁盘的目录路径。`histogram_freq`和`embeddings_freq`控制两种摘要类型在多少个epochs后写入一次；如果指定为零，则不会计算或显示。请注意，当拟合模型以显示直方图时，需要指定验证数据，或者至少需要拆分。此外，对于嵌入，我们可以通过`embeddings_metadata`参数传递一个映射层名称到嵌入元数据将保存的文件名的字典。
- en: If we want to see the graph in TensorBoard, we can set the `write_graph` argument
    to `True`; however, the event log files can get quite sizable if our model is
    large. The update frequency is specified through the `update_freq` argument. Here
    it is set to update every epoch or batch, but we can set it to an integer value
    to have it update after that number of batches. We can visualize model weights
    as images in TensorBoard using the Boolean argument `write_images`. Lastly, if
    we want to profile the performance of our compute characteristics, such as the
    contributions to the step time, we can set `profile_batch` to an integer or tuple
    of integers and it will profile that batch or range of batches. Setting the value
    to zero disables profiling.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想在 TensorBoard 中查看图表，我们可以将`write_graph`参数设置为`True`；然而，如果我们的模型很大，事件日志文件可能会非常大。更新频率通过`update_freq`参数指定。在这里，它被设置为每个
    epoch 或批次更新一次，但我们可以将其设置为整数值，以便在那些批次数之后更新。我们可以使用布尔参数`write_images`在 TensorBoard
    中将模型权重可视化为图像。最后，如果我们想分析计算特性的性能，例如对步骤时间的贡献，我们可以将`profile_batch`设置为整数或整数元组，并将分析应用于那个批次或一系列批次。将该值设置为零将禁用分析。
- en: 'Once defined, we can add the TensorBoard callback to `model.fit()`’s callbacks
    list as shown here:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义，我们可以将 TensorBoard 回调添加到`model.fit()`的回调列表中，如下所示：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The simplest way to run TensorBoard is to open a terminal and run the following
    bash command:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 TensorBoard 的最简单方法是打开终端并运行以下 bash 命令：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can provide other arguments, for example to change the default port TensorBoard
    uses, but to quickly get it up and running you simply need to specify the `logdir`.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以提供其他参数，例如更改 TensorBoard 使用的默认端口，但要快速启动它，您只需指定`logdir`即可。
- en: The summaries typically include loss and evaluation metric curves. However,
    we can use callbacks to emit other potentially useful summaries, like images and
    weight histograms, depending on our use case. We can also print out and/or log
    the loss and eval metrics while training is taking place, as well as have periodic
    evaluations of generated images or other model outputs that we can then inspect
    for diminishing returns in improvement. Lastly, if training locally with `model.fit()`,
    we can inspect the history output and look at the loss and eval metrics and how
    they change over time.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要通常包括损失和评估指标曲线。然而，根据我们的用例，我们可以使用回调来生成其他潜在有用的摘要，比如图像和权重直方图。我们还可以在训练过程中打印和/或记录损失和评估指标，以及定期评估生成的图像或其他模型输出，然后检查改进的递减回报。最后，如果使用`model.fit()`在本地训练，我们可以检查历史输出，并查看损失和评估指标随时间的变化。
- en: Model Quality Metrics
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型质量指标
- en: Even if you are using a validation set, looking at the validation loss doesn’t
    really give a clear picture of how well the model is performing. Enter the evaluation
    metrics! These are metrics that are calculated based on the model’s predictions
    on unseen data that allow us to evaluate how the model is doing in terms that
    are related to the use case.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您正在使用验证集，查看验证损失并不能真正清楚地展示模型的表现如何。进入评估指标！这些指标是基于模型对未见数据的预测计算的，它们允许我们评估模型在与用例相关的方面的表现。
- en: Metrics for Classification
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类指标
- en: 'As you learned in previous chapters, image classification involves assigning
    labels to images that indicate which class they belong to. Labels can be mutually
    exclusive, with only a single label applying to any given image, or it may be
    possible for multiple labels to describe an image. In both the single-label and
    multilabel cases, we typically predict a probability across each of the classes
    for an image. Since our predictions are probabilities and our labels are usually
    binary (0 if the image is not that class and 1 if it is), we need some way to
    convert predictions into a binary representation so we can compare them with the
    actual labels. To do that, we typically set a threshold: any predicted probabilities
    below the threshold become a 0, and any predicted probabilities above it become
    a 1\. In binary classification the default threshold is normally 0.5, giving an
    equal chance for both choices.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在前几章学到的那样，图像分类涉及将标签分配给指示它们所属类别的图像。标签可以是相互排斥的，每个图像只适用一个标签，或者可能有多个标签描述一个图像。在单标签和多标签的情况下，我们通常对图像的每个类别预测一个概率。由于我们的预测是概率，而我们的标签通常是二进制的（如果图像不是该类，则为0，如果是，则为1），因此我们需要一些方法将预测转换为二进制表示，以便与实际标签进行比较。为此，我们通常设置一个阈值：任何低于阈值的预测概率变为0，而任何高于阈值的预测概率变为1。在二元分类中，默认阈值通常为0.5，使两种选择有平等的机会。
- en: Binary classification
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 二元分类
- en: There are many metrics for single-label classification that are used in practice,
    but the best choice depends on our use case. In particular, different evaluation
    metrics are appropriate for binary and multiclass classification. Let’s begin
    with binary classification.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，有许多用于单标签分类的指标，但最佳选择取决于我们的用例。特别是，不同的评估指标适用于二元分类和多类分类。让我们从二元分类开始。
- en: 'The most common evaluation metric is accuracy. This is a measure of how many
    predictions our model got right. To figure that out, it’s also useful to calculate
    four other metrics: true positives, true negatives, false positives, and false
    negatives. True positives are when the label is 1, indicating that the example
    belongs to a certain class, and the prediction is also 1\. Similarly, true negatives
    are when the label is 0, indicating that the example does not belong to that class,
    and the prediction is also 0\. Conversely, a false positive is when the label
    is 0 but the prediction is 1, and a false negative is when the label is 1 but
    the prediction is 0\. Taken together, these create something called a *confusion
    matrix* for the set of predictions, which is a 2x2 grid that counts the number
    of each of these four metrics, as can be seen in [Figure 8-5](#a_binary_classification_confusion_matrix).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的评估指标是准确率。这是衡量模型正确预测的百分比的指标。为了弄清楚这一点，计算四个其他指标也很有用：真正例、真反例、假正例和假反例。真正例是标签为1，表示示例属于某个类别，并且预测也为1。类似地，真反例是标签为0，表示示例不属于该类别，并且预测也为0。相反，假正例是标签为0但预测为1，假反例是标签为1但预测为0。总之，这些指标构成了一种称为*混淆矩阵*的预测集合，这是一个2x2的网格，统计了这四个指标的数量，如[图 8-5](#a_binary_classification_confusion_matrix)所示。
- en: '![](Images/pmlc_0805.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0805.png)'
- en: Figure 8-5\. A binary classification confusion matrix.
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-5. 一个二元分类混淆矩阵。
- en: 'We can add these four metrics to our Keras model as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这四个指标添加到我们的Keras模型中，如下所示：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Classification accuracy is the percentage of correct predictions, so it’s calculated
    by dividing the number of predictions the model got right by the total number
    of predictions it made. Using the four confusion matrix metrics, this can be expressed
    as:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 分类准确率是正确预测的百分比，因此通过将模型正确预测的数量除以其总预测数量来计算。使用四个混淆矩阵指标，可以表示为：
- en: <math><mrow><mrow><mi>a</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>a</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: 'In TensorFlow, we can add an accuracy metric to our Keras model like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow中，我们可以像这样向Keras模型添加一个准确率指标：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This counts the number of predictions that matched the labels and then divides
    by the total number of predictions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这会计算与标签匹配的预测数量，然后除以总预测数量。
- en: 'If our predictions and labels are all either 0 or 1, as in the case of binary
    classification, then we could instead add the following TensorFlow code:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的预测和标签都是0或1，例如在二分类的情况下，我们可以添加以下 TensorFlow 代码：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this case the predictions are most likely probabilities that are thresholded
    to 0 or 1 and then compared with the actual labels to see what percentage of them
    match.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，预测通常是经过阈值化为0或1的概率，然后与实际标签比较，以确定匹配的百分比。
- en: 'If our labels are categorical, one-hot encoded, then we could instead add the
    following TensorFlow code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的标签是分类的、独热编码的，那么我们可以添加以下 TensorFlow 代码：
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is more common for the multiclass case and usually involves comparing a
    vector of predicted probabilities for each class to a one-hot-encoded vector of
    labels for each example.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于多类情况更为常见，通常涉及将每个样本的预测概率向量与每个类别的独热编码标签向量进行比较。
- en: A problem with accuracy, however, is that it works well only when the classes
    are balanced. For example, suppose our use case is to predict whether a retinal
    image depicts eye disease. Let’s say we have screened one thousand patients, and
    only two of them actually have eye disease. A biased model that predicts that
    every image shows a healthy eye would be correct 998 times and wrong only twice,
    thus achieving 99.8% accuracy. While that might sound impressive, this model is
    actually useless to us because it will completely fail to detect the cases we’re
    actually looking for. For this specific problem, accuracy is not a useful evaluation
    metric. Thankfully, there are other combinations of the confusion matrix values
    that can be more meaningful for imbalanced datasets (and also for balanced ones).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，准确率的一个问题是它仅在类别平衡时表现良好。例如，假设我们的用例是预测视网膜图像是否显示眼部疾病。假设我们已经筛选了一千名患者，只有两名患者实际患有眼部疾病。一个有偏向的模型，预测每张图像都显示健康眼睛，将会在998次中正确，仅错过两次，因此达到99.8%的准确率。虽然听起来令人印象深刻，但这个模型对我们来说实际上是无用的，因为它完全无法检测到我们实际寻找的病例。对于这个特定问题，准确率并不是一个有用的评估指标。幸运的是，混淆矩阵值的其他组合对于不平衡数据集（以及平衡数据集）可能更有意义。
- en: 'If, instead, we were interested in the percentage of positive predictions that
    our model got right, then we would be measuring the *prediction precision*. In
    other words, how many patients really have eye disease out of all the ones the
    model predicted to have eye disease? Precision is calculated as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，如果我们对模型正确预测的正预测百分比感兴趣，那么我们将测量*预测精度*。换句话说，在所有模型预测为患有眼部疾病的人中，真正患有眼部疾病的有多少？精度计算如下：
- en: <math><mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: 'Similarly, if we wanted to know the percentage of positive examples that our
    model was able to correctly identify, then we would be measuring the *prediction
    recall*. In other words, of the patients who really had the eye disease, how many
    did the model find? Recall is calculated as:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，如果我们想知道我们的模型能够正确识别的正样本百分比，那么我们将测量*预测召回率*。换句话说，实际患有眼部疾病的患者中，模型能找到多少人？召回率计算如下：
- en: <math><mrow><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: 'In TensorFlow, we can add these two metrics to our Keras model using:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中，我们可以通过以下方式将这两个指标添加到我们的 Keras 模型中：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We could also add a `thresholds` argument either as a float in the range [0,
    1] or a list or tuple of float values if we want the metrics calculated at thresholds
    other than 0.5.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望在0.5以外的阈值处计算指标，我们还可以添加`thresholds`参数，可以是范围为[0, 1]的浮点数，或者是浮点数值的列表或元组。
- en: 'As you can see, with precision and recall the numerators are identical and
    the denominators only differ in whether they include false positives or false
    negatives. Therefore, typically when one goes up, the other goes down. So how
    do we find a good balance point between the two? We can add another metric, the
    F1 score:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，精确率和召回率的分子相同，只有在包括假阳性或假阴性时分母有所不同。因此，通常当一个增加时，另一个减少。那么我们如何找到两者之间的一个良好平衡点呢？我们可以引入另一个度量标准，即
    F1 分数：
- en: <math><mrow><mrow><msub><mrow><mi>F</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>=</mo><mn>2</mn><mo>*</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>*</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><msub><mrow><mi>F</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>=</mo><mn>2</mn><mo>*</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>*</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: The F1 score is simply the harmonic mean between precision and recall. Like
    accuracy, precision, and recall, it has a range between 0 and 1\. An F1 score
    of 1 indicates a model with perfect precision and recall and thus perfect accuracy.
    An F1 score of 0 means either the precision or the recall is 0, which means that
    there are no true positives. This indicates either that we have a terrible model
    or that our evaluation dataset contains no positive examples at all, denying our
    model the chance to learn how to predict positive examples well.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数简单地是精确率和召回率之间的调和平均数。与准确率、精确率和召回率一样，它的范围在 0 到 1 之间。F1 分数为 1 表示模型具有完美的精确率和召回率，因此准确率也是完美的。F1
    分数为 0 意味着精确率或召回率中的一个为 0，这意味着没有真正的正例。这表明我们要么有一个糟糕的模型，要么我们的评估数据集根本没有正例，导致我们的模型无法学习如何有效预测正例。
- en: 'A more general metric known as the F[β] score adds a real-valued constant between
    0 and 1, β, which allows us to scale the importance of precision or recall in
    the F-score equation:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更一般的度量标准称为 F[β] 分数，其中添加一个实值常数 β（在 0 到 1 之间），允许我们在 F-分数方程中缩放精确率或召回率的重要性：
- en: <math><mrow><mrow><msub><mrow><mi>F</mi></mrow><mrow><mi>β</mi></mrow></msub><mo>=</mo><mrow><mrow><mo>(</mo><mn>1</mn><mo>+</mo><msup><mrow><mi>β</mi></mrow><mrow><mn>2</mn></mrow></msup><mo>)</mo></mrow></mrow><mo>*</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>*</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><msup><mrow><mi>β</mi></mrow><mrow><mn>2</mn></mrow></msup><mo>*</mo><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><msub><mrow><mi>F</mi></mrow><mrow><mi>β</mi></mrow></msub><mo>=</mo><mrow><mrow><mo>(</mo><mn>1</mn><mo>+</mo><msup><mrow><mi>β</mi></mrow><mrow><mn>2</mn></mrow></msup><mo>)</mo></mrow></mrow><mo>*</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>*</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><msup><mrow><mi>β</mi></mrow><mrow><mn>2</mn></mrow></msup><mo>*</mo><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: This is useful if we want to use a more aggregate measure than precision or
    recall alone, but the costs associated with false positives and false negatives
    are different; it allows us to optimize for the one we care about the most.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要使用比单独的精确率或召回率更综合的度量，但与假阳性和假阴性相关的成本不同，这将允许我们优化我们最关心的一个方面。
- en: All the evaluation metrics we’ve looked at so far require us to choose a classification
    threshold which determines whether the probabilities are high enough to become
    positive class predictions or not. But how do we know where to set the threshold?
    Of course, we could try many possible threshold values and then choose the one
    that optimizes the metric we care most about.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们看过的所有评估指标都要求我们选择一个分类阈值，以确定概率是否足够高，使其成为正类预测还是不是。但是我们如何知道在哪里设置阈值呢？当然，我们可以尝试许多可能的阈值值，然后选择优化我们最关心的指标的那个值。
- en: 'However, if we’re using multiple thresholds, there is another way to compare
    models across all thresholds at once. This first involves building curves out
    of metrics across a grid of thresholds. The two most popular curves are the *receiver
    operating characteristic* (ROC) and *precision-recall* curves. ROC curves have
    the true positive rate, also known as the sensitivity or recall, on the y-axis;
    and the false positive rate, also known as 1-specificity (the true negative rate)
    or fallout, along the x-axis. The false positive rate is defined as:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们使用多个阈值，还有另一种比较模型的方法。首先，通过在阈值网格上构建度量的曲线来进行比较。最流行的两种曲线是*接收者操作特征*（ROC）曲线和*精确率-召回率*曲线。ROC曲线将真阳性率（也称为灵敏度或召回率）放在y轴上，将假阳性率（也称为1-特异性或真阴性率）放在x轴上。假阳性率定义为：
- en: <math><mrow><mrow><mi>F</mi><mi>P</mi><mi>R</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>F</mi><mi>P</mi><mi>R</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: Precision-recall curves have precision on the y-axis and recall on the x-axis.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 精确率-召回率曲线的精确率在y轴上，召回率在x轴上。
- en: Suppose we’ve chosen a grid of two hundred equally spaced thresholds, and calculated
    the thresholded evaluation metrics for both the horizontal and vertical axes for
    either type of curve. Of course, plotting these points will create a line that
    extends across all two hundred thresholds.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们选择了两百个等间距阈值的网格，并计算了水平和垂直轴的阈值评估度量。当然，绘制这些点将创建一条延伸至所有两百个阈值的线。
- en: Generating curves like these can help us with threshold selection. We want to
    choose a threshold that optimizes the metric of interest. It could be one of these
    statistical metrics, or, better yet, a metric relevant to the business or use
    case at hand, such as the economic cost of missing a patient who has eye disease
    versus carrying out additional unnecessary screening of a patient who doesn’t
    have eye disease.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 生成这样的曲线可以帮助我们进行阈值选择。我们希望选择一个优化感兴趣度量的阈值。它可以是这些统计度量之一，或者更好的是与当前业务或用例相关的度量，比如错过有眼病患者的经济成本与对没有眼病患者进行额外不必要的筛查。
- en: We can summarize this information into a single number by calculating the *area
    under the curve* (AUC). As we can see on the left side of [Figure 8-6](#leftcolon_roc_curvedot_rightcolon_precis),
    a perfect classifier would have an AUC of 1 because there would be a 100% true
    positive rate and a 0% false positive rate. A random classifier would have an
    AUC of 0.5 because the ROC curve would fall along the y = x-axis, which shows
    that the numbers of true positives and false positives grow at equal rates. If
    we calculate an AUC less than 0.5, then that means our model is performing *worse*
    than a random classifier; an AUC of 0 means the model was perfectly wrong about
    every prediction. All else being equal, a higher AUC is usually better, with the
    possible range being between 0 and 1.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过计算*曲线下面积*（AUC）来总结这些信息。正如我们在[图 8-6](#leftcolon_roc_curvedot_rightcolon_precis)左侧看到的，完美的分类器AUC为1，因为会有100%的真阳性率和0%的假阳性率。随机分类器的AUC为0.5，因为ROC曲线将沿y
    = x轴下降，显示真阳性和假阳性以相等速率增长。如果计算出的AUC小于0.5，则意味着我们的模型表现比随机分类器*更差*；AUC为0表示模型在每个预测上都完全错误。其他条件相同，较高的AUC通常更好，可能的范围在0到1之间。
- en: The precision-recall (PR) curve is similar, as we can see on the right of [Figure 8-6](#leftcolon_roc_curvedot_rightcolon_precis);
    however, not every point in PR space may be obtained, and thus the range is less
    than [0, 1]. The actual range depends on how skewed the data’s class distributions
    are.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 精确率-召回率（PR）曲线与我们在[图 8-6](#leftcolon_roc_curvedot_rightcolon_precis)右侧看到的类似；然而，并非每个PR空间的点都可以获取，因此范围小于[0,
    1]。实际范围取决于数据类分布的偏斜程度。
- en: '![](Images/pmlc_0806.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0806.png)'
- en: 'Figure 8-6\. Left: ROC curve. Right: precision-recall curve.'
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-6\. 左侧：ROC曲线。右侧：精确率-召回率曲线。
- en: 'So, which curve should we use when comparing classification models?  If the
    classes are well sampled and balanced, then calculating the AUC-ROC is recommended.
    Otherwise, if the classes are imbalanced or skewed, then AUC-PR is the recommended
    choice. Here is the TensorFlow code to add the AUC evaluation metric:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，在比较分类模型时，我们应该使用哪种曲线？如果类别被很好地抽样和平衡，那么推荐计算AUC-ROC。否则，如果类别不平衡或倾斜，那么推荐使用AUC-PR。以下是用于添加AUC评估指标的TensorFlow代码：
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can set the number of thresholds to calculate the four confusion metrics
    via the `num_thresholds` argument, which will create that number of equally spaced
    thresholds between 0 and 1\. Alternatively, we can provide a list of float thresholds
    within the range [0, 1] that `tf.keras.metrics.AUC()` will use instead to calculate
    the AUC.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过`num_thresholds`参数设置要计算四个混淆度量的阈值数，它将在0到1之间创建那些数量的均匀间隔的阈值。或者，我们可以提供一个浮点阈值列表，该列表在范围[0,
    1]内，`tf.keras.metrics.AUC()`将使用它来计算AUC。
- en: We can also set the type of curve via the `curve` argument to either `"ROC"`
    or `"PR"` to use an ROC or precision-recall curve, respectively.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过`curve`参数将曲线类型设置为`"ROC"`或`"PR"`，分别使用ROC曲线或精确率-召回率曲线。
- en: Lastly, since we are performing binary classification, we set `multi_label`
    to `False`. Otherwise, it would calculate the AUC for each class and then average.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于我们正在进行二元分类，我们将`multi_label`设为`False`。否则，它会计算每个类别的AUC，然后求平均值。
- en: Multiclass, single-label classification
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多类别，单标签分类
- en: If we instead have a multiclass classification problem, let’s say with three
    classes (dog, cat, and bird), then the confusion matrix will look like [Figure 8-7](#a_multiclass_confusion_matrix_with_three).
    Notice that instead of a 2x2 matrix we now have a 3x3 matrix; thus, in general,
    it will be an *n*x*n* matrix where *n* is the number of classes. A key difference
    between the binary classification problem and the multiclass classification problem
    is that we don’t have true negatives anymore, because those are now the “true
    positives” of the other classes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个多类别分类问题，比如三个类别（狗、猫和鸟），那么混淆矩阵将看起来像[Figure 8-7](#a_multiclass_confusion_matrix_with_three)。请注意，现在我们不再有一个2x2的矩阵，而是一个3x3的矩阵；因此，一般来说，它将是一个*n*x*n*的矩阵，其中*n*是类别数。二元分类问题和多类别分类问题之间的一个关键区别是，我们不再有真负例，因为那些现在是其他类别的“真正例”。
- en: '![](Images/pmlc_0807.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0807.png)'
- en: Figure 8-7\. A multiclass confusion matrix with three classes.
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-7\. 一个具有三个类别的多类别混淆矩阵。
- en: Remember, for multiclass, single-label classification, even though we have multiple
    classes, each instance still belongs to one and only one class. The labels are
    mutually exclusive. It is either a picture of a dog, a cat, or a bird, not more
    than one of these things.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，对于多类别、单标签分类，即使我们有多个类别，每个实例仍然属于一个且仅一个类别。标签是互斥的。它可以是一张狗的图片、一张猫的图片或一张鸟的图片，不会同时是这些中的多个。
- en: How can we fit our binary classification confusion matrix metrics into our multiclass
    version? Let’s walk through an example. If we have an image that is labeled a
    dog and we predict correctly that it is a dog, then the count in the dog-dog cell
    of the matrix gets incremented by one. This is what we called a true positive
    in the binary classification version. But what if instead our model predicted
    “cat”? It’s obviously a false something, but it doesn’t really fit into the false
    positive or false negative camps. It’s just…false, wrong.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将我们的二元分类混淆矩阵指标适配到我们的多类别版本？让我们通过一个例子来详细说明。如果我们有一张被标记为狗的图片，并且我们预测它是狗，那么矩阵中狗-狗单元格的计数将增加一。这就是我们在二元分类版本中称之为真正例的情况。但是如果我们的模型预测“猫”呢？显然是一个假的某种东西，但它并不真正适合于假阳性或假阴性的阵营。它只是…错误。
- en: Thankfully, we don’t have to leap too far to get our multiclass confusion matrix
    to work for us. Let’s look at the confusion matrix again, with values filled in
    this time ([Figure 8-8](#a_dogcomma_catcomma_bird_multiclass_clas)).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们不必跨越太远来使我们的多类别混淆矩阵为我们工作。让我们再次看一下填入值的混淆矩阵（[Figure 8-8](#a_dogcomma_catcomma_bird_multiclass_clas)）。
- en: '![](Images/pmlc_0808.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0808.png)'
- en: Figure 8-8\. A dog, cat, bird multiclass classification confusion matrix example.
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-8\. 一个狗、猫、鸟多类别分类混淆矩阵示例。
- en: We can see that this is a balanced dataset, because each class has two hundred
    examples. However, it is not a perfect model since it is not a purely diagonal
    matrix; it has gotten many examples wrong, as evidenced by the off-diagonal counts.
    If we want to be able to calculate the precision, recall, and other metrics, then
    we must look at each class individually.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这是一个平衡的数据集，因为每个类别都有两百个例子。然而，这不是一个完美的模型，因为它不是一个纯对角矩阵；它在许多例子中犯了错误，正如非对角线计数所示。如果我们想要计算精确率、召回率和其他指标，那么我们必须逐个类别地查看。
- en: 'Looking only at the dog class, our confusion matrix contracts to what we see
    in [Figure 8-9](#the_dog_classification_confusion_matrixd). We can see in this
    figure that our true positives are where the image was actually a dog and we predicted
    a dog, which was the case for 150 examples. The false positives are where we predicted
    the image was a dog but it was not (i.e., it was a cat or a bird). Therefore,
    to get this count we add together the 50 examples from the dog-cat cell and the
    50 examples from the dog-bird cell. To find the count of false negatives, we do
    the opposite: these are cases where we should have predicted a dog but didn’t,
    so to get their total we add together the 30 examples from the cat-dog cell and
    the 20 examples from the bird-dog cell. Lastly, the true negative count is the
    sum of the rest of the cells, where we correctly said that those images were not
    pictures of dogs. Remember, even though the model might have gotten cats and birds
    mixed up with each other in some cases, because for now we are only looking at
    the dog class those values all get lumped together in the true negative count.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅看狗类别，我们的混淆矩阵缩小到我们在[图8-9](#the_dog_classification_confusion_matrixd)中看到的情况。我们可以在这个图中看到，我们的真正例子是那些实际上是狗并且我们预测为狗的图像，这种情况发生了150次。假正例是我们预测图像是狗但实际上不是的情况（例如猫或鸟）。因此，为了得到这个计数，我们将狗-猫单元格中的50个示例和狗-鸟单元格中的50个示例相加。为了找到假负例的数量，我们做相反的操作：这些是我们应该预测为狗但没有预测的情况，所以我们将猫-狗单元格中的30个示例和鸟-狗单元格中的20个示例相加。最后，真负例的计数是其余单元格的总和，这些单元格中我们正确地说这些图像不是狗。请记住，即使模型在某些情况下可能将猫和鸟混淆在一起，因为我们现在只看狗类别，这些值都会被合并到真负例计数中。
- en: '![](Images/pmlc_0809.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0809.png)'
- en: Figure 8-9\. The dog classification confusion matrix.
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-9\. 狗类别分类混淆矩阵。
- en: Once we’ve done this for every class, we can calculate the composite metrics
    (precision, recall, F1 score, etc.) for each class. We can then take the unweighted
    average of each of these to get the macro versions of these metrics—for example,
    averaging the precisions across all classes would give the macro-precision. There
    is also a micro version, where instead we add up all of the true positives from
    each of the individual class confusion matrices into a global true positive count
    and do the same for the other three confusion metrics. However, since this was
    done globally, the micro-precision, micro-recall, and micro-F1 score will all
    be the same. Lastly, instead of using an unweighted average as we did in the macro
    versions, we could weight each class’s individual metric by the total number of
    samples of that class. This would then give us the weighted precision, weighted
    recall, and so on. This can be useful if we have imbalanced classes.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们对每个类别都完成了这个过程，我们可以计算每个类别的复合指标（精确率、召回率、F1分数等）。然后，我们可以取这些指标的未加权平均值来获得这些指标的宏版本，例如，对所有类别的精确率进行平均会得到宏精确率。还有一个微观版本，其中我们将每个单独类别混淆矩阵中的所有真正例子相加到一个全局真正例子计数中，并对其他三个混淆指标做同样处理。然而，由于这是全局完成的，微观精确率、微观召回率和微观F1分数将都是相同的。最后，与我们在宏版本中所做的未加权平均值不同，我们可以通过每个类别的样本总数加权每个类别的个别指标。这将为我们提供加权精确率、加权召回率等。如果我们有不平衡的类别，这可能是有用的。
- en: Since these all still used thresholds to convert the predicted class probabilities
    into a 1 or 0 for the winning class, we can use these combined metrics for various
    thresholds to make ROC or precision-recall curves to find the AUC for comparing
    threshold-agnostic model performance.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些仍然使用阈值将预测的类别概率转换为获胜类别的1或0，我们可以使用这些组合指标来生成不同阈值的ROC曲线或精确率-召回率曲线，以找到比较无阈值模型性能的AUC。
- en: Multiclass, multilabel classification
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多类别、多标签分类
- en: In binary (single-class, single-label) classification, the probabilities are
    mutually exclusive and each example either is the positive class or is not. In
    multiclass single-label classification the probabilities are again mutually exclusive,
    so each example can belong to one and only one class, but there are no positive
    and negative classes. The third type of classification problem is multiclass multilabel
    classification, where the probabilities are no longer mutually exclusive. An image
    doesn’t necessarily have to be of just a dog or just a cat. If both are in the
    image, then the labels for both dog and cat can be 1, and therefore a good model
    should predict a value close to 1 for each of those classes, and a value close
    to 0 for any other classes.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在二进制（单类别，单标签）分类中，概率是互斥的，每个示例要么是正类要么不是。在多类别单标签分类中，概率再次是互斥的，因此每个示例只能属于一个类别，但没有正面和负面类别。第三种分类问题是多类别多标签分类，其中概率不再是互斥的。一幅图像不一定只能是狗或只能是猫。如果图像中同时存在狗和猫，那么狗和猫的标签可以都是1，因此一个好的模型应该为每个类别预测一个接近1的值，对于其他类别则预测接近0的值。
- en: What evaluation metrics can we use for the multilabel case? We have several
    options, but first let’s define some notation. We’ll define *Y* to be the set
    of actual labels, *Z* to be the set of predicted labels, and the function *I*
    to be the indicator function.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 用于多标签情况的评估指标有哪些？我们有几个选项，但首先让我们定义一些符号。我们将定义*Y*为实际标签集，*Z*为预测标签集，并定义函数*I*为指示函数。
- en: 'A harsh and challenging metric to maximize is the *exact match ratio* (EMR),
    also known as the *subset accuracy*:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一个严格且具有挑战性的最大化指标是*精确匹配比*（EMR），也称为*子集精度*：
- en: <math><mrow><mrow><mi>E</mi><mi>M</mi><mi>R</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mi>I</mi><mrow><mo>(</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>=</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>)</mo></mrow></mrow></mrow></math>
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>E</mi><mi>M</mi><mi>R</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mi>I</mi><mrow><mo>(</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>=</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>)</mo></mrow></mrow></mrow></math>
- en: This measures the percentage of examples where we got *all* of the labels exactly
    right. Note that this does not give partial credit. If we were supposed to predict
    that one hundred classes are in an image but we only predict 99 of them, then
    that example isn’t counted as an exact match. The better the model, the higher
    the EMR should be.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指标衡量了我们完全正确预测所有标签的例子的百分比。请注意，这不会给予部分分。如果我们应该预测一幅图像中有一百个类别，但我们只预测了其中的99个，则这个示例不会被视为精确匹配。模型越好，EMR
    应该越高。
- en: 'A less strict metric we could use is the *Hamming score*, which is effectively
    the multilabel accuracy:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 一个较少严格的指标是*Hamming分数*，它实际上是多标签精度的衡量：
- en: <math><mrow><mrow><mi>H</mi><mi>S</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∩</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∪</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>H</mi><mi>S</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∩</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∪</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: Here we are measuring the ratio of predicted correct labels to the total number
    of labels, predicted and actual, for each example, averaged across all examples.
    We want to maximize this quantity. This is similar to the Jaccard index or intersection
    over union (IOU), which we looked at in [Chapter 4](ch04.xhtml#object_detection_and_image_segmentation).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在测量每个示例预测正确标签与总标签数之比，包括预测和实际标签，然后对所有示例进行平均。我们希望最大化这个量。这类似于Jaccard指数或交并比（IOU），我们在[第4章](ch04.xhtml#object_detection_and_image_segmentation)中已经看过了。
- en: 'There is also a *Hamming loss* that can be used, which has a range of [0, 1]:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个*汉明损失*可以使用，其范围为[0, 1]：
- en: <math><mrow><mrow><mrow><mi>H</mi><mi>L</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>k</mi><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>k</mi></mrow></munderover></mrow><mrow><mo>[</mo><mi>I</mi><mrow><mo>(</mo><mi>l</mi><mo>∈</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∧</mo><mi>l</mi><mo>∉</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>)</mo><mo>+</mo><mi>I</mi><mrow><mo>(</mo><mi>l</mi><mo>∉</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∧</mo><mi>l</mi><mo>∈</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow></math>
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mrow><mi>H</mi><mi>L</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>k</mi><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>k</mi></mrow></munderover></mrow><mrow><mo>[</mo><mi>I</mi><mrow><mo>(</mo><mi>l</mi><mo>∈</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∧</mo><mi>l</mi><mo>∉</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>)</mo><mo>+</mo><mi>I</mi><mrow><mo>(</mo><mi>l</mi><mo>∉</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∧</mo><mi>l</mi><mo>∈</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow></math>
- en: 'Different from the Hamming score, the Hamming loss measures the relevance of
    an example to a class label that is incorrectly predicted and then averages that
    measure. Therefore, we are able to capture two kinds of errors: in the first term
    of the sum we are measuring the prediction error where we predicted an incorrect
    label, and for the second term we are measuring the missing error where a relevant
    label was not predicted. This is similar to an exclusive or (XOR) operation. We
    sum over the number of examples *n* and the number of classes *k* and normalize
    the double sum by those two numbers. If we only had one class, this would simplify
    to essentially 1 – accuracy for binary classification. Since this is a loss, the
    smaller the value, the better.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 不同于汉明分数，汉明损失度量了一个示例与错误预测的类标签的相关性，然后对该度量进行平均。因此，我们能够捕捉两种类型的错误：在和的第一项中，我们测量了预测错误的标签，而对于第二项，我们测量了未能预测到的相关标签的错误。这类似于排他或（XOR）操作。我们对示例数
    *n* 和类数 *k* 进行求和，并通过这两个数字对双重求和进行归一化。如果我们只有一个类，这将简化为二元分类中的 1 - 精度。由于这是一种损失函数，数值越小越好。
- en: We also have multilabel forms of precision, recall, and F1 score. For precision,
    we average the ratio of predicted correct labels to the total number of actual
    labels.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有精确度、召回率和F1分数的多标签形式。对于精确度，我们平均预测正确标签与实际标签总数的比率。
- en: <math><mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∩</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∩</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: 'Similarly for recall, where instead we average the ratio of predicted correct
    labels to the total number of predicted labels:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，对于召回率，我们平均预测正确标签与预测标签总数的比率：
- en: <math><mrow><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∩</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∩</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: 'For F1 score, it is similar to before as the harmonic mean of precision and
    recall:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于F1分数，与以往类似，它是精确率和召回率的调和平均：
- en: <math><mrow><mrow><msub><mrow><mi>F</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>2</mn><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∩</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo><mo>+</mo></mrow><mrow><mo>|</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><msub><mrow><mi>F</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>2</mn><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∩</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo><mo>+</mo></mrow><mrow><mo>|</mo><msub><mrow><mi>Z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: Of course we can also calculate the AUC of a ROC curve or precision-recall curve
    using the macro version, where we calculate the AUCs per class and then average
    them.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们也可以使用宏版本计算ROC曲线或精确率-召回率曲线的AUC，其中我们按类计算AUC，然后求平均。
- en: Metrics for Regression
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归指标
- en: For image regression problems, there are also evaluation metrics that we can
    use to see how well our model is performing on data outside of training. For all
    of the following regression metrics, our goal is to minimize them as much as possible.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像回归问题，还有一些评估指标可用于查看我们的模型在训练之外的数据上表现如何。对于以下所有回归指标，我们的目标是尽量将它们最小化。
- en: 'The most well-known and standard metric is *mean squared error* (MSE):'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名和标准的度量方法是*均方误差*（MSE）：
- en: <math><mrow><mrow><mi>M</mi><mi>S</mi><mi>E</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mrow><mo>(</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><msup><mrow><mo>)</mo></mrow><mrow><mn>2</mn></mrow></msup></mrow></mrow></mstyle></mrow></mrow></math>
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>M</mi><mi>S</mi><mi>E</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mrow><mo>(</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><msup><mrow><mo>)</mo></mrow><mrow><mn>2</mn></mrow></msup></mrow></mrow></mstyle></mrow></mrow></math>
- en: MSE, as its name suggests, is the mean of the squared error between the predicted
    and actual continuous labels. This is a mean-unbiased estimator which has great
    sensitivity due to the quadratic term, but this sensitivity means a few outliers
    can unduly influence it.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 均方误差（MSE）顾名思义，是预测值与实际连续标签之间的平方误差的平均值。这是一个均值无偏估计量，由于二次项的存在，具有很高的敏感性，但这种敏感性意味着少数离群值可能会对其产生不适当的影响。
- en: 'The *root mean squared error* (RMSE), which is just the square root of the
    mean squared error, is also used:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*均方根误差*（RMSE），它只是均方误差的平方根，也被广泛使用：'
- en: <math><mrow><mrow><mi>R</mi><mi>M</mi><mi>S</mi><mi>E</mi><mo>=</mo><msqrt><mrow><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover></mrow></msqrt><mrow><mo>(</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><msup><mrow><mo>)</mo></mrow><mrow><mn>2</mn></mrow></msup></mrow></mrow></mrow></math>
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>R</mi><mi>M</mi><mi>S</mi><mi>E</mi><mo>=</mo><msqrt><mrow><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover></mrow></msqrt><mrow><mo>(</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><msup><mrow><mo>)</mo></mrow><mrow><mn>2</mn></mrow></msup></mrow></mrow></mrow></math>
- en: 'A slightly simpler and more interpretable metric is the *mean absolute error*
    (MAE):'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 更简单和更易解释的度量方法是*平均绝对误差*（MAE）：
- en: <math><mrow><mrow><mi>M</mi><mi>A</mi><mi>E</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow></mrow></mrow></math>
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>M</mi><mi>A</mi><mi>E</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mrow><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow></mrow></mrow></mrow></math>
- en: The MAE is just the absolute difference between continuous predictions and labels.
    Compared to the MSE/RMSE with their squared exponents, the MAE is not as prone
    to being skewed by a few outliers. Also, unlike MSE, which is a mean-unbiased
    estimator, where the estimator’s sample mean is the same as the distributional
    mean, MAE is instead a median-unbiased estimator, where the estimator overestimates
    as frequently as it underestimates.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: MAE只是连续预测和标签之间的绝对差异。与MSE/RMSE使用的平方指数相比，MAE不太容易因为少数离群值而偏斜。此外，与MSE不同，后者是均值无偏估计，其中估计量的样本均值与分布均值相同，而MAE是中位数无偏估计，估计量高估和低估的频率相同。
- en: 'In an effort to make regression more robust, we can also try the Huber loss
    metric. This is also less sensitive to outliers than having a squared error loss:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使回归更加稳健，我们也可以尝试使用Huber损失度量。这比使用平方误差损失更不容易受到离群值的影响：
- en: <math><mrow><mrow><mi>H</mi><msub><mrow><mi>L</mi></mrow><mrow><mi>δ</mi></mrow></msub><mrow><mrow><mo>(</mo><mi>Y</mi><mo>,</mo><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover><mo>)</mo></mrow><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mrow><mo>{</mo><mtable
    columnalign="left"><mtr><mtd><mfrac><mrow><mn>1</mn></mrow><mrow><mn>2</mn></mrow></mfrac><mrow><mo>(</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><msup><mrow><mo>)</mo></mrow><mrow><mn>2</mn></mrow></msup></mrow></mtd><mtd><mi>f</mi><mi>o</mi><mi>r</mi><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo><mo>≤</mo><mi>δ</mi></mrow></mtd></mtr><mtr><mtd><mi>δ</mi><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow><mo>−</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mn>2</mn></mrow></mfrac></mrow></mstyle><msup><mrow><mi>δ</mi></mrow><mrow><mn>2</mn></mrow></msup></mtd><mtd><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>w</mi><mi>i</mi><mi>s</mi><mi>e</mi></mtd></mtr></mtable></mrow></mrow></mrow></mrow></math>
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>H</mi><msub><mrow><mi>L</mi></mrow><mrow><mi>δ</mi></mrow></msub><mrow><mrow><mo>(</mo><mi>Y</mi><mo>,</mo><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover><mo>)</mo></mrow><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mrow><mo>{</mo><mtable
    columnalign="left"><mtr><mtd><mfrac><mrow><mn>1</mn></mrow><mrow><mn>2</mn></mrow></mfrac><mrow><mo>(</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><msup><mrow><mo>)</mo></mrow><mrow><mn>2</mn></mrow></msup></mrow></mtd><mtd><mi>f</mi><mi>o</mi><mi>r</mi><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo><mo>≤</mo><mi>δ</mi></mrow></mtd></mtr><mtr><mtd><mi>δ</mi><mrow><mo>|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover><mrow><mi>Y</mi></mrow><mrow><mo>^</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><mo>|</mo></mrow><mo>−</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mn>2</mn></mrow></mfrac></mrow></mstyle><msup><mrow><mi>δ</mi></mrow><mrow><mn>2</mn></mrow></msup></mtd><mtd><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>w</mi><mi>i</mi><mi>s</mi><mi>e</mi></mtd></mtr></mtable></mrow></mrow></mrow></mrow></math>
- en: As you can see, we get the best of both worlds with this metric. We declare
    a constant threshold, *δ*; if the absolute residual is less than this value we
    use the squared term, and otherwise we use the linear term. This way we can benefit
    from the sensitivity of the squared mean–unbiased estimator of the quadratic term
    for values close to zero and the robustness of the median-unbiased estimator of
    the linear term for values further from zero.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这个度量标准集两全其美。我们声明一个常数阈值，*δ*；如果绝对残差小于该值，我们使用平方项，否则使用线性项。这样，我们既可以从靠近零的值的平方均值无偏估计的敏感性中获益，也可以从远离零的值的线性项的中位数无偏估计的稳健性中获益。
- en: Metrics for Object Detection
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 物体检测度量标准
- en: Essentially, most of the usual object detection evaluation metrics are the same
    as the classification metrics. However, instead of comparing predicted and actual
    labels for an entire image, we are comparing the objects detected versus the objects
    that are actually there using bounding boxes, as we saw in [Chapter 4](ch04.xhtml#object_detection_and_image_segmentation).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，大多数常见的物体检测评估度量与分类度量相同。但是，我们不是比较整个图像的预测和实际标签，而是使用边界框比较检测到的对象与实际存在的对象，正如我们在[第4章](ch04.xhtml#object_detection_and_image_segmentation)中所看到的。
- en: 'One of the most common object detection metrics is the intersection over union:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的物体检测度量标准之一是交并比：
- en: <math><mrow><mrow><mi>I</mi><mi>O</mi><mi>U</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mi>a</mi><mi>r</mi><mi>e</mi><mi>a</mi><mrow><mo>(</mo><mover><mrow><mi>B</mi></mrow><mrow><mo>^</mo></mrow></mover><mo>∩</mo><mi>B</mi><mo>)</mo></mrow></mrow><mrow><mi>a</mi><mi>r</mi><mi>e</mi><mi>a</mi><mrow><mo>(</mo><mover><mrow><mi>B</mi></mrow><mrow><mo>^</mo></mrow></mover><mo>∪</mo><mi>B</mi><mo>)</mo></mrow></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>I</mi><mi>O</mi><mi>U</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mi>a</mi><mi>r</mi><mi>e</mi><mi>a</mi><mrow><mo>(</mo><mover><mrow><mi>B</mi></mrow><mrow><mo>^</mo></mrow></mover><mo>∩</mo><mi>B</mi><mo>)</mo></mrow></mrow><mrow><mi>a</mi><mi>r</mi><mi>e</mi><mi>a</mi><mrow><mo>(</mo><mover><mrow><mi>B</mi></mrow><mrow><mo>^</mo></mrow></mover><mo>∪</mo><mi>B</mi><mo>)</mo></mrow></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: The numerator is the area of the intersection of our predicted bounding box
    and the actual bounding box. The denominator is the union of our predicted bounding
    box and the actual bounding box. We can see this graphically in [Figure 8-10](#intersection_over_union_is_the_area_of_o).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 分子是我们预测的边界框和实际边界框的交集面积。分母是我们预测的边界框和实际边界框的并集面积。我们可以在图8-10中以图形方式看到这一点。
- en: '![](Images/pmlc_0810.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0810.png)'
- en: Figure 8-10\. Intersection over union is the area of overlap divided by the
    area of union.
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-10。交并比是重叠区域与并集区域的比值。
- en: With perfect overlap, the two areas will be equal and thus the IOU will be 1\.
    With no overlap, there will be 0 in the numerator and therefore the IOU will be
    0\. Thus, the bounds of IOU are [0, 1].
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在完美重叠的情况下，两个区域将相等，因此IOU将为1。在没有重叠的情况下，分子中将为0，因此IOU将为0。因此，IOU的界限为[0, 1]。
- en: We can also use a form of the classification confusion metrics, such as true
    positives. As with classification, calculating these requires a threshold, but
    instead of thresholding a predicted probability, we threshold the IOU. In other
    words, if a bounding box’s IOU is over a certain value, then we declare that that
    object has been detected. Threshold values are typically 50, 75, or 95%.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用一种形式的分类混淆指标，例如真正例。与分类一样，计算这些需要一个阈值，但我们不是对预测概率进行阈值处理，而是对IOU进行阈值处理。换句话说，如果边界框的IOU超过某个值，则声明检测到了该对象。阈值通常为50%，75%或95%。
- en: A true positive in this case would be considered a correct detection. This occurs
    when the predicted and actual bounding boxes have an IOU greater than or equal
    to the threshold. A false positive, on the other hand, would be considered a wrong
    detection. This occurs when the predicted and actual bounding boxes have an IOU
    less than the threshold. A false negative would be considered a missed detection,
    where an actual bounding box was not detected at all.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，真正例被视为正确的检测。当预测的边界框和实际边界框的IOU大于或等于阈值时发生。另一方面，假正例被视为错误的检测。当预测的边界框和实际边界框的IOU小于阈值时发生。假负例被视为漏检，即根本没有检测到实际边界框。
- en: Lastly, true negatives don’t apply for object detection. A true negative is
    a correct missed detection. If we remember our per-class multiclass confusion
    matrices, the true negative was the sum of all of the other cells not used in
    the other three confusion metrics. Here, the true negatives would be all of the
    bounding boxes that we could have placed on the image and not triggered one of
    the other three confusion metrics. Even for small images the number of permutations
    of these kinds of not-placed bounding boxes would be enormous, so it doesn’t make
    sense to use this confusion metric.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，真负例不适用于物体检测。真负例是正确的未检测到。如果我们记得我们的每类多类混淆矩阵，真负例是其他三个混淆指标中未使用的所有其他单元格的总和。在这里，真负例将是我们可以放置在图像上并且未触发其他三个混淆指标之一的所有边界框。即使对于小图像，这种未放置边界框的排列方式的数量也会非常庞大，因此使用这种混淆指标是没有意义的。
- en: 'Precision in this case equals the number of true positives divided by the number
    of all detections. This measures the model’s ability to identify only the relevant
    objects within the image:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，精度等于真正例数除以所有检测数。这衡量了模型识别图像中相关对象的能力：
- en: <math><mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>a</mi><mi>l</mi><mi>l</mi><mi
    mathvariant="italic">det</mi><mi mathvariant="italic">e</mi><mi mathvariant="italic">c</mi><mi
    mathvariant="italic">t</mi><mi mathvariant="italic">i</mi><mi mathvariant="italic">o</mi><mi
    mathvariant="italic">n</mi><mi mathvariant="italic">s</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>a</mi><mi>l</mi><mi>l</mi><mi
    mathvariant="italic">d</mi><mi>e</mi><mi>t</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: 'In object detection, recall measures the model’s ability to find all of the
    relevant objects within the image. Therefore, it equals the number of true positives
    divided by the number of all actual bounding boxes:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在目标检测中，召回率衡量了模型在图像中查找所有相关对象的能力。因此，它等于真正例的数量除以所有实际边界框的数量：
- en: <math><mrow><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>a</mi><mi>l</mi><mi>l</mi><mi>a</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi><mi>b</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>b</mi><mi>o</mi><mi>x</mi><mi>e</mi><mi>s</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mstyle
    displaystyle="true" scriptlevel="0"><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>a</mi><mi>l</mi><mi>l</mi><mi>a</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi><mi>b</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>b</mi><mi>o</mi><mi>x</mi><mi>e</mi><mi>s</mi></mrow></mfrac></mrow></mstyle></mrow></mrow></math>
- en: Just like with classification, these composite metrics can be used to create
    curves using different threshold values. Some of the most common are precision-recall
    curves (like the ones we’ve seen before) and recall-IOU curves, which typically
    plot IOU in the range [0.5, 1.0].
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 就像分类一样，这些复合度量可以用来使用不同的阈值创建曲线。其中一些最常见的是精确率-召回率曲线（就像我们之前见过的那些）和召回-IOU曲线，通常绘制IOU在范围[0.5,
    1.0]之间。
- en: We can also calculate the average precision and average recall using the precision-recall
    and recall-IOU curves. In order to smooth out any perturbations in the curve,
    we typically interpolate the precision at multiple recall levels before performing
    the actual average precision calculation, as shown in [Figure 8-11](#an_interpolated_precision-recall_curvedo).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用精确率-召回率和召回-IOU曲线来计算平均精确率和平均召回率。为了平滑曲线中的任何波动，在执行实际平均精确率计算之前，我们通常在多个召回水平处插值精确率，如在[图8-11](#an_interpolated_precision-recall_curvedo)中所示。
- en: '![](Images/pmlc_0811.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0811.png)'
- en: Figure 8-11\. An interpolated precision-recall curve.
  id: totrans-150
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-11\. 一个插值精确率-召回率曲线。
- en: 'We do something similar for average recall. In the formula, the interpolated
    precision at a chosen recall level *r* is the maximum of the precision *p* found
    for any recall level *r’* that is greater than or equal to *r*:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对平均召回率也采取类似的方法。在公式中，选择的召回水平*r*处的插值精确率是找到的任何大于或等于*r*的召回水平*r'*的精确率*p*的最大值：
- en: <math><mrow><mrow><mi mathvariant="italic">p</mi><mo mathvariant="italic">⁢</mo><mi
    mathvariant="italic">int</mi><mi mathvariant="italic">e</mi><mi mathvariant="italic">r</mi><mi
    mathvariant="italic">p</mi><mi mathvariant="italic">o</mi><mi mathvariant="italic">l</mi><mi
    mathvariant="italic">a</mi><mi mathvariant="italic">t</mi><mi mathvariant="italic">e</mi><mi
    mathvariant="italic">d</mi><mo>=</mo><msub><mrow><mi mathvariant="italic">max</mi></mrow><mrow><msup><mrow><mi>r</mi></mrow><mrow><mo>′</mo></mrow></msup><mo>≥</mo><mi>r</mi></mrow></msub><mrow><mrow><mo>[</mo><mi>p</mi><mrow><mrow><mo>(</mo><msup><mrow><mi>r</mi></mrow><mrow><mo>′</mo></mrow></msup><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow></mrow></math>
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi mathvariant="italic">p</mi><mo mathvariant="italic">⁢</mo><mi
    mathvariant="italic">i</mi><mi mathvariant="italic">n</mi><mi mathvariant="italic">t</mi><mi
    mathvariant="italic">e</mi><mi mathvariant="italic">r</mi><mi mathvariant="italic">p</mi><mi
    mathvariant="italic">o</mi><mi mathvariant="italic">l</mi><mi mathvariant="italic">a</mi><mi
    mathvariant="italic">t</mi><mi mathvariant="italic">e</mi><mi mathvariant="italic">d</mi><mo>=</mo><msub><mrow><mi
    mathvariant="italic">m</mi><mi mathvariant="italic">a</mi><mi mathvariant="italic">x</mi></mrow><mrow><msup><mrow><mi>r</mi></mrow><mrow><mo>′</mo></mrow></msup><mo>≥</mo><mi>r</mi></mrow></msub><mrow><mrow><mo>[</mo><mi>p</mi><mo>(</mo><msup><mrow><mi>r</mi></mrow><mrow><mo>′</mo></mrow></msup><mo>)</mo><mo>]</mo></mrow></mrow></mrow></mrow></math>
- en: 'The traditional interpolation method is to choose 11 equally spaced recall
    levels; however, more recently practitioners have been experimenting with choosing
    all unique recall levels for interpolation. The average precision is thus the
    area under the interpolated precision-recall curve:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的插值方法是选择 11 个等间距的召回水平；然而，最近的实践者们开始尝试选择所有唯一的召回水平进行插值。因此，平均精度就是插值精度-召回曲线下的面积：
- en: <math><mrow><mrow><mi>A</mi><mi>P</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></munderover><mrow><mo>(</mo><msub><mrow><mi>r</mi></mrow><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mrow><mi>r</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>)</mo><mi
    mathvariant="italic">p</mi><mo mathvariant="italic">⁢</mo><mi mathvariant="italic">int</mi><mi
    mathvariant="italic">e</mi><mi mathvariant="italic">r</mi><mi mathvariant="italic">p</mi><mi
    mathvariant="italic">o</mi><mi mathvariant="italic">l</mi><mi mathvariant="italic">a</mi><mi
    mathvariant="italic">t</mi><mi mathvariant="italic">e</mi><mi mathvariant="italic">d</mi><mrow><mo>(</mo><msub><mrow><mi>r</mi></mrow><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>)</mo></mrow></mrow></mrow></mrow></math>
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>A</mi><mi>P</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></munderover><mrow><mo>(</mo><msub><mrow><mi>r</mi></mrow><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mrow><mi>r</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>)</mo><mi
    mathvariant="italic">p</mi><mo mathvariant="italic">⁢</mo><mi mathvariant="italic">int</mi><mi
    mathvariant="italic">e</mi><mi mathvariant="italic">r</mi><mi mathvariant="italic">p</mi><mi
    mathvariant="italic">o</mi><mi mathvariant="italic">l</mi><mi mathvariant="italic">a</mi><mi
    mathvariant="italic">t</mi><mi mathvariant="italic">e</mi><mi mathvariant="italic">d</mi><mrow><mo>(</mo><msub><mrow><mi>r</mi></mrow><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>)</mo></mrow></mrow></mrow></mrow></math>
- en: 'This is the end of the story for precision if we only have one class, but often
    in object detection we have many classes, all of which have different detection
    performances. Therefore, it can be useful to calculate the *mean average precision*
    (mAP), which is just the mean of each class’s average precision:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只有一个类别，这就是精度的结尾，但通常在目标检测中，我们有许多不同的类别，它们都有不同的检测性能。因此，计算*平均平均精度*（mAP）可能很有用，这只是每个类别平均精度的平均值：
- en: <math><mrow><mrow><mi>m</mi><mi>A</mi><mi>P</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>k</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>k</mi></mrow></munderover><mi>A</mi><msub><mrow><mi>P</mi></mrow><mrow><mi>l</mi></mrow></msub></mrow></mrow></math>
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>m</mi><mi>A</mi><mi>P</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>k</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>k</mi></mrow></munderover><mi>A</mi><msub><mrow><mi>P</mi></mrow><mrow><mi>l</mi></mrow></msub></mrow></mrow></math>
- en: 'To calculate average recall, as mentioned previously, we use the recall-IOU
    curve instead of the precision-recall curve used for average precision. It is
    essentially the recall averaged over all IOUs (specifically, IOUs that are at
    least 50%) and thus becomes two times the area under the recall-IOU curve:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，为了计算平均召回率，我们使用召回-IOU 曲线而不是用于平均精度的精度-召回曲线。它实质上是所有 IOU（特别是至少为 50% 的 IOU）上的平均召回率，因此成为召回-IOU
    曲线下的两倍面积：
- en: <math><mrow><mrow><mi>A</mi><mi>R</mi><mo>=</mo><mn>2</mn><mrow><msubsup><mo>∫</mo><mrow><mn>0.5</mn></mrow><mrow><mn>1</mn></mrow></msubsup><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow><mi>d</mi><mi>u</mi></mrow></mrow></mrow></math>
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>A</mi><mi>R</mi><mo>=</mo><mn>2</mn><mrow><msubsup><mo>∫</mo><mrow><mn>0.5</mn></mrow><mrow><mn>1</mn></mrow></msubsup><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow><mi>d</mi><mi>u</mi></mrow></mrow></mrow></math>
- en: 'As we did for the multiclass objection detection case for average precision,
    we can find the *mean average recall* (mAR) by averaging the average recalls across
    all classes:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们对于多类别目标检测情况的平均精度所做的，我们可以通过对所有类别的平均召回率进行平均来找到*平均平均召回率*（mAR）：
- en: <math><mrow><mrow><mi>m</mi><mi>A</mi><mi>R</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>k</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>k</mi></mrow></munderover><mi>A</mi><msub><mrow><mi>R</mi></mrow><mrow><mi>l</mi></mrow></msub></mrow></mrow></math>
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mrow><mi>m</mi><mi>A</mi><mi>R</mi><mo>=</mo><mstyle displaystyle="true"
    scriptlevel="0"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>k</mi></mrow></mfrac></mrow></mstyle><munderover><mrow><mi
    mathvariant="normal">Σ</mi></mrow><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>k</mi></mrow></munderover><mi>A</mi><msub><mrow><mi>R</mi></mrow><mrow><mi>l</mi></mrow></msub></mrow></mrow></math>
- en: For instance segmentation tasks, the metrics are exactly the same as for detection.
    IOU can equally well be defined for boxes or masks.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，分割任务中的指标与检测任务完全相同。IOU同样适用于框或掩码。
- en: Now that we have explored the available evaluation metrics for models, let’s
    look at how we use them for understanding model bias and for continuous evaluation.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了模型的可用评估指标，让我们看看如何使用它们来理解模型偏差和进行持续评估。
- en: Quality Evaluation
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 质量评估
- en: The evaluation metrics computed on the validation dataset during training are
    computed in aggregate. Such aggregate metrics miss a number of subtleties that
    are needed to truly gauge a model’s quality. Let’s take a look at sliced evaluations,
    a technique to catch these subtleties, and how to use sliced evaluations to identify
    bias in a model.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练期间验证数据集上计算的评估指标是聚合计算的。这样的聚合指标忽略了一些需要真正衡量模型质量的微妙之处。让我们看看切片评估，一种捕捉这些微妙之处的技术，以及如何使用切片评估来识别模型中的偏见。
- en: Sliced Evaluations
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 切片评估
- en: Evaluation metrics are usually calculated based on a holdout dataset that is
    similar to the training dataset in distribution. This typically gives us a good
    overall view of model health and quality. However, the model may perform much
    worse on some slices of the data than others, and these deficiencies can be lost
    in the ocean of calculating on the entire dataset.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标通常基于类似于训练数据集分布的保留数据集进行计算。这通常给我们一个关于模型健康和质量的总体良好视角。然而，模型在某些数据片段上的表现可能比其他片段要差得多，这些缺陷可能会在整个数据集计算的海洋中被忽视。
- en: Therefore, it can often be a good idea to analyze model quality on a more granular
    level. We can do this by taking slices of the data based on classes or other separating
    characteristics and calculating the usual evaluation metrics on each one of those
    subsets. Of course, we should still calculate the evaluation metrics using all
    of the data so that we can see how individual subsets vary from the superset.
    You can see an example of these sliced evaluation metrics in [Figure 8-12](#a_sliced_roc_curve_for_two_different_dat).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通常建议更细粒度地分析模型质量可能是一个好主意。我们可以通过基于类别或其他分离特征的数据切片，并在每个子集上计算常规评估指标来实现这一点。当然，我们仍然应该使用所有数据计算评估指标，以便看到各个子集与超集的差异。您可以在[图 8-12](#a_sliced_roc_curve_for_two_different_dat)中看到这些切片评估指标的示例。
- en: '![](Images/pmlc_0812.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/pmlc_0812.png)'
- en: Figure 8-12\. A sliced ROC curve for two different data segments compared to
    the overall ROC curve.
  id: totrans-169
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-12\. 两个不同数据段的切片ROC曲线与总体ROC曲线进行比较。
- en: Some use cases place special importance on certain segments of the data, so
    these are prime targets to apply sliced evaluation metrics to in order to keep
    a close eye on them.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一些用例对数据的某些段位特别重视，因此这些是应用切片评估指标以密切关注的主要目标。
- en: This doesn’t just have to be a passive monitoring exercise, though! Once we
    know the sliced evaluation metrics, we can then make adjustments to our data or
    model to bring each of the sliced metrics in line with our expectations. This
    could be as simple as augmenting the data more for a particular class or adding
    some more complexity to the model to be able to understand those problematic slices
    better.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这不仅仅是一种被动的监控练习！一旦我们知道了切片评估指标，我们可以对我们的数据或模型进行调整，使每个切片的指标符合我们的预期。这可能只需为特定类别增加数据或为了更好地理解这些问题片段而增加模型的复杂性。
- en: Next, we’ll look at a specific example of a segment that we may need to do sliced
    evaluations on.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看一个可能需要进行切片评估的特定段的具体示例。
- en: Fairness Monitoring
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 公平性监控
- en: Image ML models have been shown to perform poorly on some segments of the population.
    For example, a [2018 study](https://oreil.ly/CnSW8) showed that commercially available
    facial analysis programs had dramatically higher error rates at identifying the
    gender of darker-skinned women as compared to lighter-skinned men. In 2020, many
    [Twitter users reported](https://oreil.ly/oVOZR) that Twitter’s photo preview
    feature appears to favor white faces over Black faces. Meanwhile, Zoom’s facial
    recognition appeared to [remove Black faces](https://oreil.ly/9v8op) when using
    a virtual background. And in 2015, Google Photos [mistakenly labeled](https://oreil.ly/Mw5LC)
    a selfie of a Black couple as being an image of gorillas.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图像ML模型在某些人群中表现不佳。例如，2018年的一项研究显示，商用面部分析程序在识别深肤色女性的性别时错误率显著高于较浅肤色的男性。2020年，许多Twitter用户报告称，Twitter的照片预览功能似乎更偏向白种人面孔而不是黑种人面孔。与此同时，Zoom的面部识别在使用虚拟背景时似乎会删除黑种人面孔。而2015年，Google
    Photos错误地将一对黑人夫妇的自拍标记为猩猩的图像。
- en: Considering these high-profile and distressing mistakes by highly capable engineering
    teams, it is clear that if our computer vision problems involve human subjects,
    we should attempt to safeguard against such errors by carrying out sliced evaluations
    where the segments consist of individuals belonging to different races and genders.
    This will allow us to diagnose whether there is a problem.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些由高效工程团队发生的高调和令人不安的错误，很明显，如果我们的计算机视觉问题涉及到人类主体，我们应该尝试通过进行切片评估来防范这些错误，其中各个段落包括属于不同种族和性别的个体。这将帮助我们诊断是否存在问题。
- en: Poor model performance on subjects of different genders and races cannot be
    addressed simply by ensuring that all races and genders are present in the training
    and evaluation datasets. There may be deeper problems. Photographic filters and
    processing techniques were [historically optimized](https://oreil.ly/JFpNx) to
    best represent lighter skin tones, and this causes problems with lighting effects
    on darker-toned individuals. Therefore, preprocessing and data augmentation methods
    may have to be incorporated into our model-training pipelines in order to correct
    for this effect. Also, ML model training focuses initially on common cases, and
    only later on rarer examples. This means that techniques such as early stopping,
    pruning, and quantization might [amplify biases](https://arxiv.org/abs/1911.05248)
    against minorities. It is not, in other words, “just” a data problem. Addressing
    fairness issues requires examination of the entire machine learning pipeline.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同性别和种族主题上模型表现不佳，不能简单通过确保所有种族和性别在训练和评估数据集中都有代表来解决。可能存在更深层次的问题。摄影滤镜和处理技术过去是针对更轻肤色最佳化的，这导致在较深色调的个体上会出现照明效果问题。因此，我们的模型训练流程中可能需要包含预处理和数据增强方法来纠正这种影响。此外，ML模型训练最初侧重于常见情况，后来才转向更罕见的例子。这意味着技术如早停止、修剪和量化可能会对少数群体产生偏见。换句话说，这不仅仅是一个数据问题。解决公平性问题需要审视整个机器学习流程。
- en: Sliced evaluations are an invaluable tool to diagnose whether such biases exist
    in the models that have been trained. This means that we should perform these
    evaluations for any segment of the population that we are concerned might be treated
    unfairly.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 切片评估是诊断我们训练的模型中是否存在这些偏见的宝贵工具。这意味着我们应该针对我们担心可能会被不公平对待的人群段进行这些评估。
- en: Continuous Evaluation
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连续评估
- en: How often should we carry out sliced evaluations? It’s important to constantly
    be evaluating our models even after we deploy them. This can help us catch things
    that could be going wrong early. For instance, we might have prediction drift
    because the inference input distribution is slowly shifting over time. There also
    could be a sudden event that causes a major change in the data, which in turn
    causes the model’s behavior to change.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该多久进行一次切片评估？即使在部署后，不断评估我们的模型也很重要。这可以帮助我们早期发现可能出现问题的情况。例如，我们可能会因为推理输入分布随时间缓慢变化而出现预测漂移。还可能会有突发事件导致数据发生重大变化，从而导致模型行为改变。
- en: 'Continuous evaluation typically consists of seven steps:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 连续评估通常包括七个步骤：
- en: Randomly sample and save the data being sent for model predictions. For example,
    we might choose to save 1% of all the images sent to the deployed model.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机采样并保存发送到模型预测的数据。例如，我们可能选择保存所有发送到部署模型的图像中的1%。
- en: Carry out predictions with the model as usual and send them back to the client—but
    make sure to also save the model’s prediction for each of the sampled images.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像往常一样使用模型进行预测并将其发送回客户端，但务必保存每个采样图像的模型预测结果。
- en: Send the samples for labeling. We can use the same labeling approach as was
    used for the training data—for example, we can use a labeling service, or label
    the data a few days later based on the eventual outcome.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送样本进行标记。我们可以使用与训练数据相同的标记方法，例如可以使用标记服务，或者根据最终结果几天后标记数据。
- en: Compute evaluation metrics over the sampled data, including sliced evaluation
    metrics.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算采样数据上的评估指标，包括切片评估指标。
- en: Plot moving averages of the evaluation metrics. For example, we might plot the
    average Hubert loss over the past seven days.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制评估指标的移动平均线。例如，我们可以绘制过去七天的平均Hubert损失。
- en: Look for changes in the averaged evaluation metrics over time, or specific thresholds
    that are exceeded. We might choose to send out an alert, for example, if the accuracy
    for any monitored segment drops below 95% or if the accuracy this week is more
    than 1% lower than the accuracy the previous week.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索随时间变化的平均评估指标或超过特定阈值的情况。例如，如果任何监测段的准确率低于95%，或者本周的准确率比上周低1%以上，我们可能会选择发送警报。
- en: We might also choose to periodically retrain or fine-tune the model after adding
    the sampled and subsequently labeled data to the training dataset.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以选择在添加采样并随后标记的数据到训练数据集后，定期重新训练或微调模型。
- en: When to retrain is a decision that we need to make. Some common choices include
    retraining whenever the evaluation metric falls below a certain threshold, retraining
    every *X* days, or retraining once we have *X* new labeled examples.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 何时重新训练是我们需要做出的决定。一些常见选择包括当评估指标低于某个阈值时重新训练，每隔*X*天重新训练，或者一旦有*X*个新的标记样本时重新训练。
- en: Whether to train from scratch or just fine tune is another decision that we
    need to make. The typical choice is to fine tune the model if the new samples
    are a small fraction of the original training data and to train from scratch once
    the sampled data starts to approach about 10% of the number of examples in the
    original dataset.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 是否从头开始训练还是仅进行微调是我们需要做出的另一个决定。如果新样本只是原始训练数据的一小部分，通常的选择是微调模型；一旦采样数据接近原始数据集的大约10%，则选择从头开始训练。
- en: Summary
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the importance of monitoring our models during
    training. We can use the amazing graphical UI of TensorBoard to watch our loss
    and other metrics throughout training, and to verify that the model is converging
    and getting better over time. Additionally, since we don’t want to overtrain our
    models, by creating checkpoints and enabling early stopping we can halt training
    at the best moment.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了在训练过程中监控模型的重要性。我们可以使用TensorBoard的出色图形用户界面来观察我们的损失和其他指标的变化，并验证模型是否随着时间的推移收敛并变得更好。此外，由于我们不希望过度训练我们的模型，通过创建检查点并启用早期停止，我们可以在最佳时机停止训练。
- en: We also discussed many quality metrics that we can use to evaluate our models
    on unseen data to get a better measure of how well they’re doing. There are different
    metrics for image classification, image regression, and object detection, although
    some of them resurface in slightly different forms among the various problem types.
    In fact, image classification has three different subfamilies of classification
    metrics, depending on both the number of classes and the number of labels per
    image.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了许多质量评估指标，可用于在未知数据上评估我们的模型，以更好地衡量它们的表现。对于图像分类、图像回归和目标检测，有不同的指标，尽管其中一些在各种问题类型中以稍有不同的形式重新出现。事实上，图像分类有三种不同的分类指标子系列，这取决于类别数量和每张图像的标签数量。
- en: Finally, we looked at performing sliced evaluations on subsets of our data to
    not only be aware of our model’s gaps but also to help us brainstorm fixes to
    close those gaps. This practice can help us monitor for bias, to make sure that
    we are being as fair as possible and understand the inherent risks of using our
    model.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们研究了对数据子集进行切片评估，不仅了解我们模型的缺陷，还帮助我们构思修复这些缺陷的方法。这种做法可以帮助我们监控偏见，确保我们尽可能公平，并了解使用我们模型的固有风险。
