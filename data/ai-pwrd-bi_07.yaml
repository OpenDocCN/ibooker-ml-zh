- en: Chapter 7\. AI-Powered Predictive Analytics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章：AI驱动的预测性分析
- en: Get ready for takeoff! We are entering the space of AI-powered predictive analytics.
    And we will do that by stepping into the role of a BI analyst at American Airlines.
    In this chapter, we will look at three use cases from a real-world dataset. First,
    we will try to classify flights as to whether they will land on time or not. Second,
    we want to detect bottlenecks in our flight schedule by forecasting actual flight
    times in contrast to the scheduled flight duration. And finally, we will analyze
    airports’ ability to keep up with the flight schedule by using automatic anomaly
    detection.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 做好起飞的准备！我们正在进入AI驱动的预测性分析领域。我们将通过扮演美国航空公司的BI分析师的角色来实现这一点。在本章中，我们将从真实数据集中探讨三个使用案例。首先，我们将尝试将航班分类为准时或不准时。其次，我们希望通过预测实际飞行时间与计划飞行持续时间的对比来检测我们航班时间表中的瓶颈。最后，我们将使用自动异常检测分析机场跟得上飞行时间表的能力。
- en: Our goal is to build a prototype of an AI-powered BI solution that proves to
    solve a specific problem depending on the use case. We want to evaluate how well
    the AI model works with our data, show it around, and gain support for the new
    approach in our organization by demonstrating the business value (build fast,
    show fast, learn fast), as outlined in [Chapter 4](ch04.xhtml#prototyping). To
    that end, we will start by abstracting away things like setting up data pipelines,
    handling ETL jobs, and integrating AI services into our enterprise data warehouse.
    But rest assured—all of these things will be possible, as you will learn in [Chapter 11](ch11.xhtml#taking_the_next_steps_from_prototype_to).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是构建一个AI驱动的BI解决方案的原型，证明它能够根据使用案例解决特定问题。我们希望评估AI模型在我们的数据中的表现，展示出来，并通过展示业务价值（快速构建，快速展示，快速学习）来获得组织内对新方法的支持，正如[第4章](ch04.xhtml#prototyping)中所述。为此，我们将首先摆脱设置数据管道、处理ETL作业以及将AI服务集成到企业数据仓库等事务。但请放心，所有这些事情都是可能的，正如你将在[第11章](ch11.xhtml#taking_the_next_steps_from_prototype_to)中学到的那样。
- en: What will most likely be the same in the prototyping and production phases is
    the AI model we will build. Already in our prototype, we will use enterprise-grade
    AI services from Microsoft Azure that will stand up to production workloads. The
    only thing that will change later is the way we integrate these services into
    our overarching system architecture. Once we can prove the business value and
    build a solid business case for our solution, we can afford the effort to move
    the prototype into production and build it “properly” there.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在原型和生产阶段最有可能相同的是我们将构建的AI模型。在我们的原型中，我们将使用来自Microsoft Azure的企业级AI服务，这些服务将应对生产工作负载。稍后唯一会改变的是我们将这些服务集成到我们的整体系统架构的方式。一旦我们能够证明业务价值并为我们的解决方案建立一个坚实的业务案例，我们就能够承担将原型移入生产并在那里“正确”构建的工作。
- en: Prerequisites
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 先决条件
- en: 'To follow along with the use cases in this chapter, I recommend downloading
    the following files from the [book’s website](https://oreil.ly/X9jmJ):'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随本章中的使用案例，建议您从[书籍网站](https://oreil.ly/X9jmJ)下载以下文件：
- en: Datasets
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集
- en: '*AA_Flights_2021.xlsx*'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AA_Flights_2021.xlsx*'
- en: '*AA_Flights_2021_01.csv*'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AA_Flights_2021_01.csv*'
- en: 'Use Case: Automating Classification Tasks'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 用例：自动化分类任务
- en: '*Arrival_Delay.pbix*'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Arrival_Delay.pbix*'
- en: '*AA_Hourly_Batches_2021-02-07_0800-0859.csv*'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AA_Hourly_Batches_2021-02-07_0800-0859.csv*'
- en: '*azure-ml-inference-arrdel15.R* or'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*azure-ml-inference-arrdel15.R*或'
- en: '*azure-ml-inference-arrdel15.py*'
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*azure-ml-inference-arrdel15.py*'
- en: 'Use Case: Improving KPI Prediction'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 用例：改进KPI预测
- en: '*Elapsed_Time.pbix*'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Elapsed_Time.pbix*'
- en: '*azure-ml-inference-elapsedtime.R* or'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*azure-ml-inference-elapsedtime.R*或'
- en: '*azure-ml-inference-elapsedtime.py*'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*azure-ml-inference-elapsedtime.py*'
- en: 'Use Case: Automating Anomaly Detection'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 用例：自动化异常检测
- en: '*Airports_Anomaly.pbix*'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Airports_Anomaly.pbix*'
- en: '*azure-anomaly-detection-airports.R* or'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*azure-anomaly-detection-airports.R*或'
- en: '*azure-anomaly-detection-airports.py*'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*azure-anomaly-detection-airports.py*'
- en: In addition, you will need an account on Microsoft Azure to train and host the
    AI model as demonstrated in [Chapter 4](ch04.xhtml#prototyping), some basic knowledge
    in Python or R to get predictions from the model, and a BI tool capable of executing
    Python or R scripts to integrate the model predictions into your dashboard.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，您将需要一个Microsoft Azure账户来训练和托管AI模型，如[第4章](ch04.xhtml#prototyping)中所示，一些基本的Python或R知识来从模型获取预测，并且需要一个能够执行Python或R脚本并将模型预测集成到您的仪表板中的BI工具。
- en: Although we are using Microsoft Azure to train the model, the same functionality
    is more or less also available on other cloud platform providers such as GCP or
    AWS. Once you get a feel for how things work on Azure, getting up and running
    on the other platforms should be relatively easy and quick.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们使用Microsoft Azure来训练模型，但类似的功能也大致可在其他云平台提供商（如GCP或AWS）上使用。一旦您对Azure的工作方式有所了解，就可以相对轻松快速地在其他平台上运行和运行。
- en: To build our dashboard, we will use Power BI to achieve consistency with the
    previous use cases (and because Azure works nicely with Power BI). However, this
    book is not limited to Power BI users. That is why I will show you how to get
    inference from your model by using a popular programming language like Python
    or R. You can integrate Python or R code into Power BI or any other BI tool. Alternatively,
    you could run the predictions directly on the database (batch predictions) and
    just display the results in any BI tool such a Tableau or Looker. [Chapter 10](ch10.xhtml#bringing_it_all_together_building_an_ai)
    offers more details.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建我们的仪表板，我们将使用Power BI以保持与先前使用案例的一致性（以及Azure与Power BI的良好兼容性）。然而，本书并不局限于Power
    BI用户。因此，我将向您展示如何通过使用像Python或R这样的流行编程语言，从您的模型中获取推断。您可以将Python或R代码集成到Power BI或任何其他BI工具中。或者，您可以直接在数据库上运行预测（批量预测），并在Tableau或Looker等任何BI工具中显示结果。[第10章](ch10.xhtml#bringing_it_all_together_building_an_ai)提供了更多详细信息。
- en: About the Dataset
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于数据集
- en: 'Beware: we will be working on a real-world dataset. This dataset hasn’t been
    tweaked or tuned for ML exercises. So don’t expect any jaw-dropping insights or
    nice-looking charts. But instead, you will get a feel for what a real-world scenario
    looks like, which gains you can expect from ML, and how you can use this technology
    to beat your own baselines and automate predictions. The process might get messy,
    but it’s closer to real life than any academic exercise you will find.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们将处理一个真实世界的数据集。此数据集未经过调整或调优用于ML练习。因此，请不要期望有令人瞠目结舌的洞察力或漂亮的图表。但是，您将了解到真实场景是什么样子的，从ML中可以获得哪些收益，以及如何使用这项技术来击败自己的基线并自动化预测。这个过程可能会有些混乱，但它比您在任何学术练习中找到的更接近现实生活。
- en: 'The public dataset for this use case has been acquired through the TranStats
    service of the [US Bureau of Transportation Statistics](https://oreil.ly/y7C8W).
    This data source maintains updated information about flight details for flights
    in the US. Throughout the whole chapter, we will use flight data from January
    2021 and February 2021, which I provide as an Excel file through the [book’s website](https://oreil.ly/X9jmJ)
    for your convenience. The file includes the following processing steps to make
    it match our case study:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此使用案例的公共数据集已通过[美国运输统计局](https://oreil.ly/y7C8W)的TranStats服务获得。此数据源保持了有关美国航班详细信息的更新信息。在整个章节中，我们将使用2021年1月和2021年2月的航班数据，我已将其作为Excel文件通过[书籍的网站](https://oreil.ly/X9jmJ)提供给您以便查阅。该文件包括以下处理步骤以使其匹配我们的案例研究：
- en: The dataset has been filtered for American Airlines flights only.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该数据集已经仅针对美国航空公司的航班进行了筛选。
- en: Canceled flights have been deleted from the dataset.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已从数据集中删除了取消的航班。
- en: Flights without any information on the arrival delay have been removed (< 1%).
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已删除没有任何到达延误信息的航班（< 1%）。
- en: If you want to get more data or explore different airlines, feel free to do
    so by downloading the original files yourself from the TranStats website. If you
    do, make sure you select the Prezipped File option, as shown in [Figure 7-1](#airline_on_time_performance_dataset_dow),
    before downloading the data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想获取更多数据或探索不同的航空公司，请随时从TranStats网站下载原始文件。如果您这样做，请确保在下载数据之前选择Prezipped File选项，如[图 7-1](#airline_on_time_performance_dataset_dow)所示。
- en: '![Airline On-Time Performance dataset download](Images/apbi_0701.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![航空公司准点表现数据集下载](Images/apbi_0701.png)'
- en: Figure 7-1\. Airline On-Time Performance dataset download
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-1\. 航空公司准点表现数据集下载
- en: 'Use Case: Automating Classification Tasks'
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用案例：自动化分类任务
- en: For our first use case, we are tackling a classification problem of predicting
    whether a given flight will be delayed on arrival. Even if you are not an expert
    in the aviation industry, you should be familiar with the overall challenge.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的第一个使用案例，我们正在处理一个分类问题，预测给定航班是否会延误到达。即使您不是航空业的专家，您也应该熟悉整体挑战。
- en: Problem Statement
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题陈述
- en: As a member of the BI team of American Airlines, you have been given the task
    of building a reporting dashboard on a business-critical metric. The metric is
    the percentage of American Airlines flights that are currently in the air and
    are expected to be delayed for more than 15 minutes. This metric is important
    for quality control reasons and for keeping customer satisfaction high, as well
    as for maintaining the overall flight schedule.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 作为美国航空公司商业智能团队的一员，您被要求构建一个关键业务指标的报告仪表板。该指标是目前在空中并预计延误超过 15 分钟的美国航空公司航班的百分比。这一指标对于质量控制和保持客户满意度以及保持总体航班时间表的重要性不言而喻。
- en: In our example, let’s imagine that we receive data every hour containing all
    flights that departed within the last 60 minutes. These hourly batches contain
    information as to the flight details (origin, destination, flight number, etc.)
    and the flight delay upon departure. So, for example, when we look at a batch
    of data anytime between 9:00 a.m. and 9:59 a.m., the information in this dataset
    will contain flights that took off between 8:00 a.m. and 8:59 a.m. To make this
    example less complicated, we’re ignoring time zones for now and are assuming that
    all timestamps are provided in Coordinated Universal Time (UTC).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，假设我们每小时收到一次数据，其中包含过去 60 分钟内起飞的所有航班。这些每小时批次包含航班详情（起点、目的地、航班号等）以及起飞时的航班延误信息。因此，例如，当我们在上午
    9:00 到 9:59 之间查看数据批次时，此数据集中将包含在上午 8:00 到 8:59 之间起飞的航班信息。为了简化这个例子，我们暂时忽略时区，假设所有时间戳都以协调世界时（UTC）提供。
- en: The metric Proportion of Delayed Flights is currently reported through a BI
    dashboard, shown in [Figure 7-2](#reporting_dashboard_on_proportion_of_de).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 延误航班比例这一指标目前通过一个商业智能仪表板报告，如[图 7-2](#reporting_dashboard_on_proportion_of_de)所示。
- en: '![Reporting dashboard on Proportion of Delayed Flights metric](Images/apbi_0702.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![关于延误航班比例的报告仪表板](Images/apbi_0702.png)'
- en: Figure 7-2\. Reporting dashboard on Proportion of Delayed Flights metric
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-2\. 关于延误航班比例的报告仪表板
- en: The dashboard shows the total number of flights (107) in the current batch scheduled
    for the departure time block 8:00 a.m. to 8:59 a.m. for a given day. Most of these
    flights will be still in the air before the next data batch comes in.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板显示当前批次计划在给定日的 8:00 a.m. 到 8:59 a.m. 起飞时间段内的航班总数为 107 架。大多数这些航班在下一个数据批次到来之前仍将在空中。
- en: To estimate whether an arrival delay will occur, we are currently using the
    departure delay information as a proxy. Up to now, the BI team has used the variable
    DepDel15, which indicates whether the flight was delayed at least 15 minutes upon
    departure, to approximate whether the flight will also be late more than 15 minutes
    upon arrival.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了估算是否会发生到达延误，我们目前使用起飞延误信息作为一个近似。到目前为止，商业智能团队一直使用变量 DepDel15，该变量指示航班是否在起飞时延误至少
    15 分钟，来近似航班是否在到达时也会晚于 15 分钟。
- en: This estimate has been a good first shot, but it is far from perfect. Let’s
    open the Excel workbook *AA_Flights_2021.xlsx* and select the first sheet, AA_Flights_01,
    as shown in [Figure 7-3](#american_airlines_flight_data_from_janu), to find out
    how this estimate has performed historically.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此估算是一个很好的初步尝试，但还远非完美。让我们打开 Excel 工作簿 *AA_Flights_2021.xlsx* 并选择第一个表 AA_Flights_01，如[图
    7-3](#american_airlines_flight_data_from_janu)所示，以了解此估算的历史表现。
- en: '![American Airlines flight data from January 2021](Images/apbi_0703.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![2021 年 1 月的美国航空公司航班数据](Images/apbi_0703.png)'
- en: Figure 7-3\. American Airlines flight data from January 2021
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-3\. 2021 年 1 月的美国航空公司航班数据
- en: The sheet AA_Flights_01 contains all American Airlines flights from January
    2021—almost 38,000 rows of data. Each row is an American Airlines flight that
    happened during January 2021.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 表 AA_Flights_01 包含了 2021 年 1 月的所有美国航空公司航班数据，几乎有 38,000 行数据。每一行都是 2021 年 1 月期间发生的一次美国航空公司航班。
- en: 'Since this is a historical dataset, we can see the actual arrival delay that
    happened. Take the first row, for example. The flight Number AA1 from John F.
    Kennedy International Airport (JFK) to Los Angeles International Airport (LAX)
    took off on January 1, 2021\. The flight didn’t have a delay on departure of 15
    minutes or more and thus the column DepDelay15 is set to 0\. Since the plane landed
    even ahead of schedule without any delay, the ArrDelay15 column is also set to
    0\. The first flight that had a departure delay of more than 15 minutes happened
    in row 21: it is again flight AA1 from JFK to LAX, but this time on January 20,
    2021\. The DepDelay15 attribute is 1 since the departure delay was 75 minutes,
    as you can see in [Figure 7-4](#flight_delay_of_sevenfive_minutes_on_de).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个历史数据集，我们可以看到实际发生的到达延误情况。例如，我们来看第一行。从约翰·肯尼迪国际机场（JFK）到洛杉矶国际机场（LAX）的AA1航班起飞于2021年1月1日。该航班没有15分钟或更长时间的延误，因此DepDelay15列设置为0。由于飞机甚至提前降落而没有任何延误，ArrDelay15列也设置为0。第一个出发延误超过15分钟的航班发生在第21行：再次是从JFK到LAX的AA1航班，但这次是在2021年1月20日。DepDelay15属性为1，因为出发延误为75分钟，正如您可以在[图7-4](#flight_delay_of_sevenfive_minutes_on_de)中看到的那样。
- en: '![Flight delay of 75 minutes on departure](Images/apbi_0704.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![出发延误75分钟的航班](Images/apbi_0704.png)'
- en: Figure 7-4\. Flight delay of 75 minutes on departure
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-4. 出发延误75分钟的航班
- en: So in this case, the attribute DepDelay15 was a good indicator of whether a
    flight was actually also delayed on arrival. Now, how good would our prediction
    have been if we relied only on the DepDelay15 information? Head over to the third
    worksheet of the Excel file, Confusion_Table, to see the confusion table ([Figure 7-5](#evaluating_the_baseline_classifier)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这种情况下，DepDelay15属性是一个很好的指标，用于判断航班是否实际上也延误到达。现在，如果我们只依赖于DepDelay15信息，我们的预测会有多好呢？转到Excel文件的第三个工作表Confusion_Table，看看混淆矩阵（[图7-5](#evaluating_the_baseline_classifier)）。
- en: '![Evaluating the baseline classifier](Images/apbi_0705.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![评估基线分类器](Images/apbi_0705.png)'
- en: Figure 7-5\. Evaluating the baseline classifier
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-5. 评估基线分类器
- en: Before we dive into the details, look at the last two rows, which read, ArrDel15
    True = 10.4% and False = 89.6%. This summary tells us that we are dealing with
    an *imbalanced classification* problem as explained previously in [Chapter 3](ch03.xhtml#machine_learning_fundamentals).
    Only 10% of all flights are actually flagged with the ArrDelay15 attribute and
    are thus more than 15 minutes late on arrival.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入细节之前，看看最后两行，即ArrDel15 True = 10.4%和False = 89.6%。这一摘要告诉我们，我们正在处理一个*不平衡分类*问题，正如之前在[第3章](ch03.xhtml#machine_learning_fundamentals)中所解释的那样。只有10%的航班实际上标记为ArrDelay15属性，因此到达延误超过15分钟。
- en: Why should this imbalance be important to us? Because it affects our evaluation
    metric. Imagine that if we predicted that all flights will be on time with less
    than 15 minutes’ delay, this would give us an astonishing accuracy score of 90%.
    Would this prediction be useful? No. That is why we have to come up with a smarter
    evaluation metric.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这种不平衡对我们很重要呢？因为它影响我们的评估指标。想象一下，如果我们预测所有航班都将准时到达，延误不超过15分钟，这将给我们带来惊人的90%的准确性分数。这种预测有用吗？不。这就是为什么我们必须提出更智能的评估指标。
- en: 'Look at the confusion table in [Figure 7-5](#evaluating_the_baseline_classifier).
    This shows us how our baseline prediction (the DepDelay15 label) performed. If
    we used the Departure Delay heuristic in the past, we would have misclassified
    2,166 observations: 1,178 flights were actually delayed, although we predicted
    they would be on time. And 988 flights were actually on time, even though we predicted
    there would be a delay.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 看看[图7-5](#evaluating_the_baseline_classifier)中的混淆矩阵。这显示了我们基线预测（DepDelay15标签）的表现。如果过去我们使用出发延误启发式，我们会误分类2,166个观察结果：1,178个航班实际上延误了，尽管我们预测它们将准时到达。而988个航班实际上准时到达，尽管我们预测会延误。
- en: 'As you learned in [Chapter 3](ch03.xhtml#machine_learning_fundamentals), *precision*
    is a measure that captures a classifier’s exactness; higher precision indicates
    fewer false positives. If we manage to improve this metric, the 988 flights that
    have been predicted as delayed, but were actually on time, would be reduced. The
    precision is calculated by dividing the true-positive values (TP: 2,749) by the
    sum of the true positives and false positives (FP: 988).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[第 3 章](ch03.xhtml#machine_learning_fundamentals)学到的，*精确率*是衡量分类器准确性的指标；较高的精确率表示假阳性较少。如果我们能改善这个指标，那么预测为延误的
    988 航班实际上准时的情况将会减少。精确率的计算方法是将真正例（TP：2,749）除以真正例加假阳性（FP：988）的总和。
- en: '*Recall* measures a classifier’s completeness; higher recall indicates fewer
    false negatives (FN: 1,178 flights that were delayed, although predicted on time).
    Recall is calculated by dividing the true positives by the true positives plus
    the false negatives.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*召回率*衡量分类器的完整性；较高的召回率表示假阴性较少（FN：1,178 航班延误，尽管预测为准时）。召回率的计算方法是将真正例除以真正例加假阴性的总和。'
- en: 'To compress both bits of information into a single metric that is easier to
    track, we will use the *F1-score*, which is the harmonic mean of precision and
    recall and is calculated as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将这两个信息压缩成一个更易于跟踪的单一指标，我们将使用*F1 分数*，它是精确率和召回率的调和平均值，计算方法如下：
- en: F1 = 2 × (*precision* × *recall*) / (*precision* + *recall*) = 2TP / (2TP +
    FP + FN)
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F1 = 2 × （*精确率* × *召回率*）/（*精确率* + *召回率*）= 2TP / （2TP + FP + FN）
- en: As you can see in [Figure 7-6](#fone_score_for_the_baseline_classifier), the
    F1-score for our baseline classifier is 0.72.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[图 7-6](#fone_score_for_the_baseline_classifier)中所看到的，我们基线分类器的 F1 分数为 0.72。
- en: '![F1-score for the baseline classifier](Images/apbi_0706.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![基线分类器的 F1 分数](Images/apbi_0706.png)'
- en: Figure 7-6\. F1-score for the baseline classifier
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-6\. 基线分类器的 F1 分数
- en: Our goal is to come up with a new classifier that manages to beat this 0.72
    F1-score baseline, so we can make even more accurate predictions about flight
    delays.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是开发出一个新的分类器，能够超过这个 0.72 的 F1 分数基线，这样我们可以更准确地预测航班延误。
- en: Solution Overview
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案概述
- en: To improve the prediction for a late arrival, we will use an AI classifier trained
    on historical data. [Figure 7-7](#automated_classification_use_case_archi) shows
    a conceptual overview of the architecture for this use case. As you can see, this
    use case is getting slightly more advanced than the use cases from previous chapters.
    That is mainly because we are now looking beyond the capabilities of Power BI
    and adding more functionalities in the analysis layer.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改善对航班延误预测的准确性，我们将使用一个基于历史数据训练的 AI 分类器。[图 7-7](#automated_classification_use_case_archi)
    展示了这个用例架构的概念概述。正如你所见，这个用例比之前章节的用例略为复杂。这主要是因为我们现在超越了 Power BI 的能力，并在分析层中添加了更多功能。
- en: '![Automated classification use case architecture](Images/apbi_0707.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![自动分类用例架构](Images/apbi_0707.png)'
- en: Figure 7-7\. Automated classification use case architecture
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-7\. 自动分类用例架构
- en: We have two data sources in this architecture. On the bottom left of the figure
    is a set of historical flight data provided as a CSV file. And on the bottom right,
    we have the hourly batches of data being consumed by our BI system (in this case,
    Power BI).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个架构中我们有两个数据源。图的左下角是提供的历史航班数据，保存为 CSV 文件。而右下角是我们的 BI 系统（在这种情况下是 Power BI）每小时消费的数据批次。
- en: In this example, we are using an AI service that will learn patterns from historical
    flight data and use this information to classify new data points (hourly flight
    batches), whether these flights will be likely delayed or not.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们使用一个 AI 服务，它将从历史航班数据中学习模式，并使用这些信息对新的数据点（每小时航班批次）进行分类，判断这些航班是否可能会延误。
- en: We could use many approaches to tackle these classification problems. Since
    we don’t want to bring in rare and expensive AI/ML experts at this stage, we will
    use AutoML to train an ML model for us. I’m demonstrating the workflow on the
    example of Microsoft Azure Machine Learning Studio as the AutoML platform, but
    it could really be anything; they all work more or less the same. We will first
    build and evaluate the model on Azure ML Studio and then deploy it as an online
    HTTP endpoint—all without writing a single line of code!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用多种方法来解决这些分类问题。由于我们目前不希望引入稀有且昂贵的AI/ML专家，所以我们将使用AutoML来为我们训练一个ML模型。我将演示Microsoft
    Azure机器学习工作室作为AutoML平台的工作流程示例，但实际上它可以是任何平台；它们的工作原理都差不多。我们将首先在Azure ML Studio上构建和评估模型，然后将其部署为在线HTTP端点——所有这些都不需要编写一行代码！
- en: The actual predictions will be made directly from the user layer within Power
    BI. Here, we will send a prediction request to an online API so we can fetch the
    new data and integrate it into our data model using Power Query. For this part,
    we will rely on a small R or Python script that handles the API request. Once
    we have the predictions in our BI, we will present the results in a Power BI report.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的预测将直接从用户层面在Power BI中进行。在这里，我们将向在线API发送一个预测请求，以便获取新数据，并使用Power Query将其集成到我们的数据模型中。对于此部分，我们将依赖于一个处理API请求的小型R或Python脚本。一旦我们在BI中获得了预测结果，我们将在Power
    BI报告中呈现结果。
- en: Model Training with Microsoft Azure Walk-Through
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Microsoft Azure进行模型训练演示
- en: Visit [Azure ML Studio](https://ml.azure.com), which you set up in [Chapter 4](ch04.xhtml#prototyping).
    Since we want to train an AI model by using AutoML, select Start Now in the Automated
    ML pane and choose “New Automated ML job” to fill up the blank rows.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 访问[Azure ML Studio](https://ml.azure.com)，您已在[第四章](ch04.xhtml#prototyping)中进行了设置。由于我们想要通过AutoML训练一个AI模型，请在自动化ML窗格中选择立即开始，并选择“新的自动化ML作业”来填充空白行。
- en: An *AutoML job* is the process that takes you all the way from providing a dataset
    up to getting a validated ML model as a result. We will go through this process
    step by step.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*AutoML作业*是一个过程，从提供数据集到获得验证的ML模型结果。我们将逐步完成这个过程。'
- en: First, you need some data. On Azure, data is organized in datasets that are
    linked to your workspace. Datasets will ensure that your data is correctly formatted
    and can be consumed by ML jobs. As shown in [Figure 7-8](#creating_a_dataset_from_the_local_file),
    select “Create.”
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要一些数据。在Azure上，数据以数据集的形式组织，这些数据集与您的工作区关联。数据集将确保您的数据格式正确，并可以被ML作业消费。如[图 7-8](#creating_a_dataset_from_the_local_file)所示，选择“创建”。
- en: '![Creating a dataset from the local file](Images/apbi_0708.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![从本地文件创建数据集](Images/apbi_0708.png)'
- en: Figure 7-8\. Creating a dataset from the local file
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-8\. 从本地文件创建数据集
- en: You can import data from various sources. In this case, we will upload a local
    file, so go ahead and select “From local files,” as shown in [Figure 7-8](#creating_a_dataset_from_the_local_file).
    In the “Basic info” form shown in [Figure 7-9](#adding_basic_info), give your
    dataset a telling name and add a description if you like. In this example, I named
    the dataset `**aa_flights_ontime**`. The version will default to 1, and the dataset
    type will be Tabular, as AutoML currently supports only tabular data.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从各种来源导入数据。在这种情况下，我们将上传一个本地文件，所以请继续选择“从本地文件”，如[图 7-8](#creating_a_dataset_from_the_local_file)所示。在[图 7-9](#adding_basic_info)中显示的“基本信息”表单中，为您的数据集取一个能说明问题的名称，并添加一个描述（如果需要）。在这个例子中，我将数据集命名为`**aa_flights_ontime**`。版本将默认为1，并且数据集类型将是表格，因为AutoML当前仅支持表格数据。
- en: '![Adding basic info](Images/apbi_0709.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![添加基本信息](Images/apbi_0709.png)'
- en: Figure 7-9\. Adding basic info
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-9\. 添加基本信息
- en: Click Next to head over to the next section. You need to provide information
    as shown in [Figure 7-10](#selecting_files_to_upload). You’ll choose where the
    data should be stored and from where it should be uploaded. Select the default
    datastore that was automatically set up during your workspace creation (in this
    example, mine is called *workspaceblobstore*). This is where you’ll physically
    upload your data file to make it available to your current workspace.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“下一步”进入下一部分。您需要提供如[图 7-10](#selecting_files_to_upload)所示的信息。您将选择数据存储的位置以及应从何处上传数据。选择在工作区创建期间自动设置的默认数据存储（在此示例中，我的称为*workspaceblobstore*）。这是您将物理上传数据文件以使其可供当前工作区使用的地方。
- en: We can’t upload the Excel file here. Azure ML Studio supports CSV, TSV, Parquet,
    and JSON files for tabular datasets. That’s why we need to convert the Excel file
    to CSV first. For your convenience, I’ve done that already and created the file
    *AA_Flights_2021_01.csv*, which contains all flight data from January and is the
    first sheet of the Excel workbook *AA_Flights_2021.xlsx*. Click Next at the bottom
    of your screen to upload the file.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法在此处上传Excel文件。Azure ML Studio支持CSV、TSV、Parquet和JSON文件作为表格数据集。这就是为什么我们需要先将Excel文件转换为CSV。为了您的方便，我已经完成了这一步，并创建了名为*AA_Flights_2021_01.csv*的文件，其中包含了2021年1月的所有航班数据，并且是Excel工作簿*AA_Flights_2021.xlsx*的第一个工作表。在屏幕底部点击“下一步”上传文件。
- en: '![Selecting files to upload](Images/apbi_0710.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![选择要上传的文件](Images/apbi_0710.png)'
- en: Figure 7-10\. Selecting files to upload
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-10\. 选择要上传的文件
- en: After the file is successfully uploaded, you should see the “Settings and preview”
    form with some pre-populated information based on the uploaded file. Double-check
    that the settings are set as shown in [Figure 7-11](#settings_and_preview) and
    that the data preview at the bottom is displaying the first couple of rows correctly.
    If everything looks good, click Next.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 文件成功上传后，您应该看到“设置和预览”表单，其中包含一些基于上传文件预填的信息。请仔细检查设置是否与[图 7-11](#settings_and_preview)中显示的设置相同，并确保底部的数据预览正确显示前几行。如果一切正常，请点击“下一步”。
- en: '![Settings and preview](Images/apbi_0711.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![设置和预览](Images/apbi_0711.png)'
- en: Figure 7-11\. Settings and preview
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-11\. 设置和预览
- en: The following form ([Figure 7-12](#defining_the_schema)) will define the schema
    of your dataset. This schema is important for two reasons. First, the schema will
    allow you to define which columns in your dataset should be considered by the
    AutoML algorithm. And second, the schema will allow you to define the data type
    of the respective columns.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的表单（[图 7-12](#defining_the_schema)）将定义数据集的模式。该模式对两个原因至关重要。首先，模式将允许您定义哪些列应由AutoML算法考虑。其次，模式将允许您定义各列的数据类型。
- en: 'This step is important because both the columns you want to use and their respective
    data types are very hard for Azure ML Studio to guess automatically. For example,
    the column DayOfWeek looks numerical, but it’s in fact categorical data: weekday
    7 + 1 is not weekday 8, but weekday 1\. Therefore, the column DayOfWeek should
    be interpreted as containing string values and not numeric ones.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步骤非常重要，因为您想要使用的列以及它们的数据类型对于Azure ML Studio来说非常难以自动猜测。例如，列DayOfWeek看起来是数字，但实际上是分类数据：工作日7
    + 1不是工作日8，而是工作日1\. 因此，DayOfWeek列应被解释为包含字符串值而不是数值。
- en: '![Defining the schema](Images/apbi_0712.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![定义模式](Images/apbi_0712.png)'
- en: Figure 7-12\. Defining the schema
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-12\. 定义模式
- en: Data types also define which AutoML tasks are possible for your data. For example,
    if we left the data type of the ArrDel15 variable to Decimal, we would not be
    able to select a Classification later. Similarly, if we want to predict a numeric
    value, we have to make sure it is correctly being set in the schema to enable
    a regression task. There is no way AutoML could reliably guess the data type on
    its own. That is something we have to define manually, and providing this information
    up front requires your expert knowledge.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 数据类型还定义了数据的AutoML任务可能性。例如，如果我们将ArrDel15变量的数据类型留在Decimal上，我们将无法在后续选择分类任务。同样地，如果我们要预测数值，我们必须确保在模式中正确设置它以启用回归任务。AutoML无法可靠地猜测数据类型，这是我们必须手动定义的内容，提前提供这些信息需要您的专业知识。
- en: In our example, we don’t need all the data provided in the dataset. Some values
    don’t provide any meaningful insight at all and would only increase the complexity
    of the project (such as Year, which has all the same values). And we don’t want
    to include some other values in our prediction because it contains *target leakage*
    in the context of ML, which means that one feature includes the actual target
    in itself. For example, ArrivalDelay does tell us perfectly whether ArrDel15 is
    true or false.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们不需要数据集中提供的所有数据。某些值根本不提供有意义的见解，并且只会增加项目的复杂性（例如，Year具有完全相同的值）。我们不希望在我们的预测中包含一些其他值，因为它在ML的上下文中包含*目标泄漏*，这意味着一个特征本身包含了实际目标。例如，ArrivalDelay确实可以完美地告诉我们ArrDel15是否为真。
- en: 'Here’s a list of all the columns we need for our use case. Make sure to include
    *only* these variables and that you set their data type correctly as shown in
    [Figure 7-12](#defining_the_schema):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们用例所需的所有列的列表。确保仅包括这些变量，并正确设置它们的数据类型，如[图 7-12](#defining_the_schema)所示：
- en: 'DayofWeek: String'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DayofWeek：String
- en: 'Origin: String'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Origin：String
- en: 'Dest: String'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dest：String
- en: 'DepDelay: Dec/Comma'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DepDelay：Dec/Comma
- en: 'DepDelayMinutes: Dec/Comma'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DepDelayMinutes：Dec/Comma
- en: 'DepDel15: String'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DepDel15：String
- en: 'DepartureDelayGroups: String'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DepartureDelayGroups：String
- en: 'DepTimeBlk: String'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DepTimeBlk：String
- en: 'TaxiOut: Dec/Comma'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TaxiOut：Dec/Comma
- en: 'ArrDel15: String'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ArrDel15：String
- en: 'ArrTimeBlk: String'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ArrTimeBlk：String
- en: 'Distance: Dec/Comma'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Distance：Dec/Comma
- en: 'DistanceGroup: String'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DistanceGroup：String
- en: Click Next. On the “Confirm details” page, double-check the information you
    provided and click Create to finish the creation of your dataset. You can select
    your dataset from the list that appears (click Refresh if necessary).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“下一步”。在“确认详细信息”页面上，仔细检查您提供的信息，然后点击“创建”完成数据集的创建。您可以从显示的列表中选择您的数据集（如果需要，点击刷新）。
- en: Process by clicking Next. You will see the “Configure job” screen, shown in
    [Figure 7-13](#creating_a_new_automl_run), which lets you specify how your AutoML
    job should work.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 通过点击“下一步”进行处理。您将看到“配置作业”屏幕，如[图 7-13](#creating_a_new_automl_run)所示，该屏幕允许您指定您的
    AutoML 作业应该如何工作。
- en: '![Creating a new AutoML job](Images/apbi_0713.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![创建一个新的 AutoML 作业](Images/apbi_0713.png)'
- en: Figure 7-13\. Creating a new AutoML job
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 7-13\. 创建一个新的 AutoML 作业
- en: What Is an AutoML Job?
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 AutoML 作业？
- en: Now that we have defined our dataset, we have to define which computation resources
    should be used for the AutoML training. In Azure, one AutoML training on a specific
    dataset is called an *AutoML job*. Jobs are organized in experiments. An *experiment*
    holds the information, such as the size of your compute environment, and specifies
    which column you want to predict.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了我们的数据集，我们必须定义哪些计算资源应该用于 AutoML 训练。在 Azure 中，一个特定数据集上的 AutoML 训练称为 *AutoML
    作业*。作业组织在实验中。一个 *实验* 包含信息，如您的计算环境的大小，并指定您想要预测的列。
- en: 'Since we have not set up an experiment yet, select the “Create new” radio button.
    Enter a custom experiment name. In this case, I chose `**aa-automl-arrdel15**`.
    Specify ArrDel15 (String) as the target column. Finally, we have to specify which
    computing resources should be used for this training job. Select “Compute instance”
    as the compute type and then select the computing resource we initially created
    in [Chapter 4](ch04.xhtml#prototyping). If the compute instance is stopped, you
    need to start it first. To do that, choose Compute from the Azure Machine Learning
    Studio main menu, select your instance from the list, and click Start. Tip: Open
    the compute instance menu in a new tab, so you don’t interrupt the setup of your
    AutoML job.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们还没有设置实验，请选择“创建新”单选按钮。输入一个自定义实验名称。在这种情况下，我选择了`**aa-automl-arrdel15**`。将 ArrDel15（String）指定为目标列。最后，我们必须指定用于此训练作业的计算资源。选择“计算实例”作为计算类型，然后选择我们最初在[第
    4 章](ch04.xhtml#prototyping)中创建的计算资源。如果计算实例已停止，您需要首先启动它。为此，请从 Azure 机器学习工作室主菜单中选择计算，从列表中选择您的实例，然后单击“启动”。提示：在新标签页中打开计算实例菜单，以免中断
    AutoML 作业的设置过程。
- en: Note
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: While there are no additional fees for using Azure Machine Learning, you will
    be charged for the underlying Azure services, such as Azure compute power or Azure
    Blob Storage. While greater compute power can improve AutoML speed (and thus lower
    the cost of the AutoML job), it is usually more cost-effective to choose cheaper
    compute resources and accept a slightly longer AutoML training time. Auto ML training
    in this use case should be more than covered by your free trial budget, even if
    you do it several times. To learn more about managing budgets, costs, and quotas
    for Azure Machine Learning, I recommend the Microsoft resource [“Manage Budgets,
    Costs, and Quota for Azure Machine Learning at Organizational Scale”](https://oreil.ly/LQo6K).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 Azure 机器学习时，并没有额外费用，但是你会为底层的 Azure 服务（如 Azure 计算能力或 Azure Blob 存储）付费。虽然更大的计算能力可以提高
    AutoML 的速度（从而降低 AutoML 作业的成本），但通常选择更便宜的计算资源并接受稍长的 AutoML 训练时间更加成本效益。在这种使用情况下，即使你多次进行
    AutoML 训练，也应该完全由你的免费试用预算覆盖。要了解有关管理 Azure 机器学习的预算、成本和配额的更多信息，我建议参考微软资源[“管理 Azure
    机器学习的组织规模预算、成本和配额”](https://oreil.ly/LQo6K)。
- en: Now it is time to specify what the AutoML task should do ([Figure 7-14](#select_a_machine_learning_task)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是指定 AutoML 任务应该执行什么操作的时候了（参见[图 7-14](#select_a_machine_learning_task)）。
- en: '![Select a machine learning task](Images/apbi_0714.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![选择一个机器学习任务](Images/apbi_0714.png)'
- en: Figure 7-14\. Select a machine learning task
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-14\. 选择机器学习任务
- en: 'We can choose from three task types here:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这里选择三种任务类型：
- en: Classification
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 分类
- en: Predicting a categorical variable
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 预测分类变量
- en: Regression
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 回归
- en: Predicting a continuous numeric variable
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 预测连续数值变量
- en: Time-series forecasting
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列预测
- en: Regression for time-series data
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 针对时间序列数据的回归
- en: Before you choose Next, click “View additional configuration settings.” You
    will see the “Additional configurations” pane ([Figure 7-15](#additional_configuration_for_a_machine)).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择“下一步”之前，请单击“查看附加配置设置”。您将看到“附加配置”窗格（参见图 7-15）。
- en: '![Additional configuration for a machine learning task](Images/apbi_0715.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习任务的附加配置](Images/apbi_0715.png)'
- en: Figure 7-15\. Additional configuration for a machine learning task
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-15\. 机器学习任务的附加配置
- en: We want to customize some options here. First, we want to change the “Primary
    metric.” Per default, this is set to Accuracy. As you have seen previously, accuracy
    isn’t a good measure for imbalanced classification problems. We can’t choose “F1-score”
    here. Instead, choose “Precision score weighted.” This will also consider recall
    and therefore result in a better F1-score. Also, make sure that “Explain best
    model” is ticked.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要在这里自定义一些选项。首先，我们要更改“主要指标”。默认情况下，这设置为准确度。正如您之前所见，准确度并不适合不平衡分类问题的衡量。我们无法在这里选择“F1
    分数”。而是选择“加权精度分数”。这也将考虑召回率，因此会产生更好的 F1 分数。此外，请确保选中“解释最佳模型”。
- en: Note
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Choosing the correct evaluation metric is a vital step in your AutoML process
    and can significantly affect the results. At the same time, it is hard for the
    AutoML service to guess which metric you need, since this depends on the problem
    at hand. For example, do you prioritize more false-positive over false-negative
    results, such as in clinical tests? Feel free to revisit [Chapter 3](ch03.xhtml#machine_learning_fundamentals)
    and become more familiar with various metrics as you need to. Experiment with
    them in multiple AutoML jobs. Visit [“Evaluate Automated Machine Learning Experiment
    Results”](https://oreil.ly/hNs4e) in Azure ML Studio to compare your AutoML jobs
    according to different metrics.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AutoML 过程中选择正确的评估指标是至关重要的一步，可以显著影响结果。与此同时，对于 AutoML 服务来说，很难猜测您需要哪种指标，因为这取决于手头的问题。例如，在临床测试中，您更看重假阳性还是假阴性结果？请随时返回第
    3 章，更加熟悉各种指标，根据需要在多个 AutoML 作业中进行实验。访问 [“评估自动化机器学习实验结果”](https://oreil.ly/hNs4e)
    在 Azure ML Studio 中根据不同的指标比较您的 AutoML 作业。
- en: Another setting we want to customize is the “Exit criterion.” This will tell
    our AutoML algorithm when the model is “good enough.” If a criteria is met, the
    training job is stopped. Typically, you can take two approaches here. You can
    end the training by time limit or by a minimum acceptance criteria for the metric.
    In this example, choose 1 hour as the maximum time limit. In fact, chances are
    that the training might even end before, if the algorithm can’t get any more significant
    gains on training an even better model.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要自定义的另一个设置是“退出标准”。这将告诉我们的 AutoML 算法模型何时“足够好”。如果满足某一标准，则训练作业将停止。通常，您可以采用两种方法。您可以通过时间限制或者通过指标的最小接受标准来结束训练。在这个例子中，选择
    1 小时作为最大时间限制。实际上，如果算法无法在训练中获得更大的增益，训练可能会提前结束。
- en: Confirm the additional settings with Save. Click Next and Finish to start your
    AutoML job. This will initialize your AutoML job and bring you to the “Run details”
    screen ([Figure 7-16](#automl_run_details)).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 确认附加设置并保存。单击“下一步”和“完成”以启动您的 AutoML 作业。这将初始化您的 AutoML 作业，并将您带到“运行详细信息”屏幕（参见图
    7-16）。
- en: '![AutoML job details](Images/apbi_0716.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![AutoML 作业详细信息](Images/apbi_0716.png)'
- en: Figure 7-16\. AutoML job details
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-16\. AutoML 作业详细信息
- en: This status updates as the experiment progresses. After a couple of minutes,
    the Status should change from “Not started” to “Running.”
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 随着实验的进行，此状态会更新。几分钟后，状态应从“未开始”变为“运行”。
- en: It will probably take 10 minutes or so before the first model is being trained.
    Some internal setups and checks occur on Azure first. One of these preparations
    is a service called *data guardrails*. Click the “Data guardrails” tab to find
    out more. After a few minutes, the screen should look like [Figure 7-17](#data_guardrails).
    If this area is still empty, check back after a few minutes and refresh the page.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个模型开始训练可能需要大约10分钟左右。Azure 首先进行一些内部设置和检查。其中一个准备工作是名为“数据守则”的服务。点击“数据守则”选项卡以获取更多信息。几分钟后，屏幕应该看起来像[图 7-17](#data_guardrails)。如果此区域仍然为空，请稍后再检查并刷新页面。
- en: '![Data guardrails](Images/apbi_0717.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![数据守则](Images/apbi_0717.png)'
- en: Figure 7-17\. Data guardrails
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-17\. 数据守则
- en: '*Data guardrails* on Azure AutoML are a series of automated checks over the
    training data to increase the chances of a high-quality training outcome. These
    checks include splitting the data into training and validation sets automatically,
    or checking for missing values in the training columns. Azure AutoML also checks
    for some assumptions related to the training task at hand—for example, it recognizes
    the imbalanced classes in the label and flags them as a potential problem area.
    If you click the “View additional details” button, you will see the underlying
    distribution of the class labels.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure AutoML 中，*数据守则* 是一系列自动检查，用于增加高质量训练结果的可能性。这些检查包括自动将数据拆分为训练集和验证集，或检查训练列中是否存在缺失值。Azure
    AutoML 还会检查与当前训练任务相关的一些假设，例如识别标签中的不平衡类，并标记它们作为潜在问题区域。如果你点击“查看附加详细信息”按钮，你将看到类标签的基础分布。
- en: To find out how to tackle this problem, read the Azure documentation [“Identify
    Models with Imbalanced Data”](https://oreil.ly/dapAa). Besides some built-in features
    that help tackle imbalanced classes, such as adding a weight column, one major
    point suggested is to pick an evaluation metric that is robust against class imbalances.
    It’s a good thing that we chose precision over accuracy as our leading metric
    before.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何解决这个问题，请阅读 Azure 文档 [“识别具有不平衡数据的模型”](https://oreil.ly/dapAa)。除了一些内置功能帮助解决不平衡类的问题，例如添加权重列，建议的一个主要点是选择一个针对类不平衡具有鲁棒性的评估指标。我们之前选择精度而不是准确度作为我们的主要评估指标，这是个好主意。
- en: While the overall training process is still running, head over to the Models
    tab. Here you will see a list of all the models and the preliminary evaluation
    metrics that the AutoML algorithm has come up with so far. After 15 to 20 minutes,
    you should already see a preliminary model with the respective evaluation metric.
    Consider that the model can only become better from here. If the AutoML algorithm
    finds an even better model, it will appear on top of this list. You can explore
    each model here and look further into the respective details. But the idea of
    AutoML is that we don’t worry too much about what’s going on during training.
    Let the algorithms do their job, grab a coffee, and check back in 30 minutes or
    so.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管整个训练过程仍在进行中，但请前往“模型”选项卡。在这里，你将看到所有模型的列表以及自动机器学习算法到目前为止提出的初步评估指标。15到20分钟后，你应该已经看到一个带有相应评估指标的初步模型。请记住，模型从这里只会变得更好。如果自动机器学习算法找到了更好的模型，它将出现在列表的顶部。你可以在这里探索每个模型并进一步查看各自的详细信息。但是自动机器学习的理念是，在训练过程中我们不必过于担心发生了什么。让算法自行处理，喝杯咖啡，大约30分钟后再回来查看。
- en: Has the training been finished? If so, you should see a screen like [Figure 7-18](#completed_automl_run),
    where the status indicates Completed.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成了吗？如果完成了，你应该看到一个类似于[图 7-18](#completed_automl_run)的屏幕，状态显示为已完成。
- en: '![Completed AutoML job](Images/apbi_0718.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![已完成的 AutoML 作业](Images/apbi_0718.png)'
- en: Figure 7-18\. Completed AutoML job
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-18\. 已完成的 AutoML 作业
- en: Evaluating the AutoML Outputs
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估 AutoML 输出
- en: Now it’s time to look at the best model the algorithm has found and explore
    it in a bit more detail. Head over to the models by clicking the Models tab. You
    should see a list similar to [Figure 7-19](#automl_models). From this overview,
    we can see that the top five models are close together, with Precision scores
    ranging from 0.96340 to 0.96690 for the best model.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候查看算法找到的最佳模型，并稍微详细地探索一下。点击“模型”选项卡进入模型页面。你应该看到一个类似于[图 7-19](#automl_models)的列表。从这个概览中，我们可以看到前五名模型非常接近，最佳模型的精度分数在0.96340到0.96690之间。
- en: The best model in this case is a voting ensemble with a final Precision score
    of 0.96690\. The actual results depend on the computing resources and the training
    time spent. They might look a little different if you chose different settings
    for the run configuration.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，最佳模型是一个投票集成模型，最终精度得分为0.96690。实际结果取决于计算资源和所花费的训练时间。如果选择了不同的运行配置，结果可能会有所不同。
- en: '![AutoML models](Images/apbi_0719.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![AutoML模型](Images/apbi_0719.png)'
- en: Figure 7-19\. AutoML models
  id: totrans-152
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-19\. AutoML模型
- en: Note
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The actual results for your AutoML job might slightly differ from the results
    in this book. While the AutoML process is deterministic, you might see different
    results due to stochastic procedures on the data preparation process (e.g., automated
    data sampling for training and testing). The big picture, however, should be similar.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 您的AutoML作业的实际结果可能会略有不同于本书中的结果。虽然AutoML过程是确定性的，但由于数据准备过程中的随机过程（例如，用于训练和测试的自动化数据抽样），您可能会看到不同的结果。然而，总体趋势应该是相似的。
- en: Since we checked “Explain best model” in the advanced configurations before,
    the best model automatically shows the link “View explanation.” We will come back
    to this in a bit. But first, click the algorithm name “VotingEnsemble” to see
    the model’s detail page ([Figure 7-20](#details_for_best_model)).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们之前在高级配置中勾选了“解释最佳模型”，最佳模型自动显示了“查看解释”链接。稍后我们会回到这一点。但首先，点击算法名称“VotingEnsemble”以查看模型的详细页面（[图7-20](#details_for_best_model)）。
- en: '![Details for best model](Images/apbi_0720.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![最佳模型详情](Images/apbi_0720.png)'
- en: Figure 7-20\. Details for best model
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-20\. 最佳模型详情
- en: 'Most importantly, we want to find out how this model performs on our data.
    To find out more, click the Metrics tab. On this section, enable the following
    evaluation metrics and keep all other ones disabled for now:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，我们要了解这个模型在我们的数据上的表现如何。要了解更多信息，请单击“指标”选项卡。在此部分，启用以下评估指标，并暂时保持所有其他指标禁用状态：
- en: average_precision_score_macro
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: average_precision_score_macro
- en: average_precision_score_micro
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: average_precision_score_micro
- en: average_precision_score_weighted
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: average_precision_score_weighted
- en: confusion_matrix
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: confusion_matrix
- en: f1_score_macro
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: f1_score_macro
- en: f1_score_micro
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: f1_score_micro
- en: f1_score_weighted
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: f1_score_weighted
- en: Your screen should look similar to the one in [Figure 7-21](#model_metrics).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 您的屏幕应该看起来与[图7-21](#model_metrics)中的屏幕类似。
- en: '![Model metrics](Images/apbi_0721.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![模型指标](Images/apbi_0721.png)'
- en: Figure 7-21\. Model metrics
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-21\. 模型指标
- en: Before we worry too much about what micro, macro, and average metrics mean,
    let’s take a look at the confusion matrix that the model evaluation has provided
    for us. This confusion table contains exactly the same information as our Excel
    table ([Figure 7-5](#evaluating_the_baseline_classifier)) in the problem statement—just
    the layout is a bit different.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入研究微观、宏观和平均指标意味着什么之前，让我们先看一下模型评估为我们提供的混淆矩阵。这个混淆表格包含的信息与我们问题陈述中的Excel表格（[图7-5](#evaluating_the_baseline_classifier)）完全相同，只是布局有些不同。
- en: The table contrasts the true data labels with the model’s predicted labels.
    For example, for 3,374 observations, the actual label was `0` (no arrival delay
    > 15 minutes), and the model’s predicted value was also `0`. By contrast, 98 observations
    were predicted to be on time (predicted label = `0`), but were in fact delayed
    by more than 15 minutes (actual label = `1`). Note that this table does not contain
    all observations from the dataset, but only the sample data points from the validation
    set.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表格对比了真实数据标签与模型预测标签。例如，对于3,374个观测值，实际标签为`0`（到达延误超过15分钟），而模型预测值也为`0`。相比之下，有98个观测被预测准时到达（预测标签=`0`），但实际上延误超过15分钟（实际标签=`1`）。请注意，此表格未包含数据集中的所有观测，而仅包括验证集中的样本数据点。
- en: To make this screen more comparable to the Excel spreadsheet from our problem
    set, switch the drop-down menu at the top left from Raw to Normalized to show
    you the respective percentages ([Figure 7-22](#normalized_confusion_matrix_in_azure_ve)).
    This makes it easier to compare the results to our Excel table from [Figure 7-5](#evaluating_the_baseline_classifier).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使此屏幕与我们问题集中的Excel电子表格更可比较，将左上角的下拉菜单从原始切换到归一化，以显示相应的百分比（[图7-22](#normalized_confusion_matrix_in_azure_ve)）。这样可以更轻松地将结果与我们来自[图7-5](#evaluating_the_baseline_classifier)的Excel表格进行比较。
- en: '![Normalized confusion matrix in Azure versus the Excel confusion matrix](Images/apbi_0722.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![在Azure中的归一化混淆矩阵与Excel混淆矩阵的对比](Images/apbi_0722.png)'
- en: Figure 7-22\. Normalized confusion matrix in Azure versus the Excel confusion
    matrix
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-22\. 在Azure中的归一化混淆矩阵与Excel混淆矩阵的对比
- en: Let’s compare the model against our baseline model, which based its prediction
    solely on whether the plane was delayed more than 15 minutes upon departure. As
    you can see, our model makes significant gains compared to the baseline when it
    comes to flights predicted to be delayed (`1`) but were actually on time (`0`).
    The AI model misclassified only 0.71% of these observations incorrectly, whereas
    our baseline had an error of 2.9% in this category. Likewise, for flights that
    were predicted to be on time (`0`) but actually landed with more than a 15-minutes
    delay (`1`), we could reduce the error from the baseline from 30.0% to 24.94%.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来比较该模型与我们的基线模型，后者仅基于飞机起飞后是否延误超过 15 分钟来进行预测。如您所见，我们的模型在预测将延误的航班（`1`）实际上按时抵达的情况下，相较于基线模型取得了显著的进展。AI
    模型仅在这些观测中误分类了 0.71%，而我们的基线在该类别中的误差为 2.9%。同样地，对于预测将按时抵达的航班（`0`），实际上抵达延误超过 15 分钟的情况，我们将基线模型的误差从
    30.0% 降低到了 24.94%。
- en: 'Let’s take a look at what this means for our acceptance criteria, the precision,
    recall, and F1-score. The metrics for the baseline model are as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这对于我们的接受标准，精确率、召回率和 F1-score 意味着什么。基线模型的指标如下：
- en: 'Precision: 0.74'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确率：0.74
- en: 'Recall: 0.70'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率：0.70
- en: 'F1-score: **0.72**'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'F1-score: **0.72**'
- en: 'We can calculate the same metrics for our AI model by hand:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以手动计算我们的 AI 模型相同的指标：
- en: Precision = TP / (TP + FP) = 295 / (295 + 24) = 0.92
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确率 = TP / (TP + FP) = 295 / (295 + 24) = 0.92
- en: Recall = TP / (TP + FN) = 295 / (295 + 98) = 0.75
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率 = TP / (TP + FN) = 295 / (295 + 98) = 0.75
- en: 'F1-score: 2TP / (2TP + FP + FN) = 2 × 295 / (2 × 295 + 24 + 98) = **0.83**'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'F1-score: 2TP / (2TP + FP + FN) = 2 × 295 / (2 × 295 + 24 + 98) = **0.83**'
- en: As you can see, we could improve our baseline prediction by 11 percentage points,
    thanks to the approach of AutoML.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，由于 AutoML 方法的采用，我们成功地将基线预测提高了 11 个百分点。
- en: 'Let’s come back to the Precision and F1-score metrics in the model Metrics
    tab. Why do we see much higher values here? That is because we are provided with
    the micro, macro, and weighted scores for our classification algorithm:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到模型指标选项卡中的精确率和 F1-score 指标。为什么我们在这里看到的值要高得多？那是因为我们为我们的分类算法提供了微观、宏观和加权得分：
- en: Micro
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 微观
- en: Calculates metrics globally by counting the total true positives, false negatives,
    and false positives.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 计算全局指标，通过计算总的真正例、假负例和假正例来实现。
- en: Macro
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 宏观
- en: Calculates metrics for each label and finds their unweighted mean. This does
    not take label imbalance into account.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个标签计算指标并找到它们的非加权平均值。这不考虑标签的不平衡性。
- en: Weighted
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 加权
- en: Calculates metrics for each label and finds their average weighted by support
    (the number of true instances for each label).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 计算每个标签的指标并根据它们的支持度（每个标签的真实实例数）进行加权平均。
- en: For imbalanced classification problems, it is more informative to use a macro
    average with minority classes given equal weighting to majority classes.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不平衡的分类问题，使用宏观平均值更具信息量，其中少数类与多数类具有相同的权重。
- en: 'In the case of a binary (two classes) classification problem, the macro F1-score
    is simply the average of the F1-score of the positive class and the negative class:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二分类问题，宏观 F1-score 简单地是正类和负类的 F1-score 的平均值：
- en: '*macro F1-score* = (*F1-score of positive class* + *F1-score of negative class*)
    / 2 = (0.83 × 0.98) / 2 = **0.905**'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*宏观 F1-score* = (*正类的 F1-score* + *负类的 F1-score*) / 2 = (0.83 × 0.98) / 2 =
    **0.905**'
- en: As you see, that is exactly what the evaluation metric for the macro F1-score
    in Azure is showing us in [Figure 7-23](#fone_score_macro_comparison).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这正是 Azure 中宏观 F1-score 评估指标在 [图 7-23](#fone_score_macro_comparison) 中展示的内容。
- en: '![F1-Score macro comparison](Images/apbi_0723.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![F1-Score 宏观比较](Images/apbi_0723.png)'
- en: Figure 7-23\. F1-score macro comparison
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-23\. F1-score 宏观比较
- en: Be careful when you compare these aggregated evaluation metrics. Looking at
    things at a granular level (for example, in the confusion table) gives you a better
    picture of what is going on overall.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在比较这些聚合评估指标时要小心。从粒度层面来看（例如，混淆矩阵），可以更好地理解整体情况。
- en: Note
  id: totrans-198
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Sometimes the best model is not the best model for your purpose. Especially
    when the evaluation metrics are close together, you might want to check the first
    three models or so and explore the details—for example, in the confusion table
    as we did before. Depending on your preference, using the second- or third-best
    model may make sense if it better suits your problem at hand. Maybe you’ll find
    a model that offers a better recall while sacrificing some precision?
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，最好的模型并不适合您的目的。 特别是当评估指标接近时，您可能希望检查前三个模型，并探索详细信息，例如我们之前做过的混淆矩阵。 根据您的偏好，如果更适合解决手头的问题，使用第二或第三优秀的模型可能是有意义的。
    也许您会发现一个模型在牺牲一些精度的情况下提供了更好的召回率？
- en: Now that we have the confirmation that our model is working better than our
    non-AI baseline, let’s understand why exactly this is the case. Head over to the
    Explanations tab of our best model. Select “raw” from the table in [Figure 7-24](#model_explanations)
    and shrink the list pane by clicking the double arrow.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确认我们的模型比非AI基线效果更好，让我们明白为什么会这样。 前往我们最佳模型的解释选项卡。 从[Figure 7-24](#model_explanations)表格中选择“原始数据”，然后通过点击双箭头来收缩列表窗格。
- en: '![Model explanations](Images/apbi_0724.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![模型解释](Images/apbi_0724.png)'
- en: Figure 7-24\. Model explanations
  id: totrans-202
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 7-24\. 模型解释
- en: Next, click the “Aggregate feature importance” tab. This should result in a
    screen similar to [Figure 7-25](#aggregate_feature_importance).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，点击“聚合特征重要性”选项卡。 这应该会显示与[Figure 7-25](#aggregate_feature_importance)类似的屏幕。
- en: This visual briefly shows you the overall most important variables (features)
    that influence the outcome of a certain prediction. As we can see from the chart,
    the DepDelay (departure delay) attribute is unsurprisingly the most important
    influence factor by far.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 此视觉简要显示了影响特定预测结果的最重要的变量（特征）。 正如我们从图表中看到的那样，DepDelay（出发延误）属性显然是远远最重要的影响因素。
- en: But interestingly, three more variables are influencing the predictions by a
    good bit. The first is the TaxiOut attribute, which is nearly half as important
    as DepDelay. This should be no surprise since taxi-out is closely linked to the
    departure delay. But surprisingly, we also see that the variables Dest (destination)
    and Origin play a role when it comes to predicting arrival delays. Depending on
    the place a plane takes off and the airport it is scheduled to arrive at, the
    probability for an on-time arrival increases or decreases. These features are
    not as important as departure delay and taxi-out, but they do play a role in making
    better predictions.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 但有趣的是，还有三个变量对预测有显著影响。 第一个是TaxiOut属性，其重要性几乎与DepDelay相当。 这并不奇怪，因为出租车等待时间与出发延误密切相关。
    但令人惊讶的是，我们还看到目的地（Dest）和起飞地（Origin）在预测到达延误时起了作用。 根据飞机起飞和计划到达的机场位置，及时到达的概率会增加或减少。
    这些特征并不像出发延误和出租车等待时间那样重要，但确实在提高预测精度方面发挥了作用。
- en: '![Aggregate feature importance](Images/apbi_0725.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![聚合特征重要性](Images/apbi_0725.png)'
- en: Figure 7-25\. Aggregate feature importance
  id: totrans-207
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 7-25\. 聚合特征重要性
- en: With more than four hundred unique combinations of departure and arrival airports
    in our dataset, this is an area where AutoML can play out its strengths, since
    it would be cumbersome for us to come up with handcrafted rules for these combinations,
    just to increase the overall quality of our predictions by a certain percent.
    Now that we have a rough idea of why the AutoML model works better than our baseline,
    let’s move ahead and deploy our model for making predictions on new, unseen datasets.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的数据集中，有四百多个唯一的出发和到达机场组合，这是AutoML可以发挥其优势的领域，因为对于这些组合，手工制定规则会很麻烦，仅仅为了通过一定的百分比提高我们的预测质量。
    现在我们已经大致了解为什么AutoML模型比我们的基线效果更好，让我们继续前进，为新的、未见过的数据集部署我们的模型。
- en: Model Deployment with Microsoft Azure Walk-Through
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Microsoft Azure进行模型部署的实例
- en: Now that we’ve trained, validated, and understood our ML model, it is time to
    deploy it so we can use it to make predictions for new data. In Azure ML Studio,
    choose the model you want to make available and click “Deploy → Deploy to web
    service.” The “Deploy a model” pane will pop up on the right side ([Figure 7-26](#deploying_a_model)).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练、验证并理解了我们的ML模型，是时候部署它了，这样我们就可以用它来预测新数据。 在Azure ML Studio中，选择您想要提供的模型，然后点击“部署
    → 部署到Web服务”。 “部署模型”面板将在右侧弹出（参见[Figure 7-26](#deploying_a_model)）。
- en: '![Deploying a model](Images/apbi_0726.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![模型部署](Images/apbi_0726.png)'
- en: Figure 7-26\. Deploying a model
  id: totrans-212
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 7-26\. 模型部署
- en: Give your model deployment a name. I suggest using a combination of the model
    purpose (predicted variable) and the algorithm you are using. In our case, a good
    model name could be `**arrdel-votingensemble**`. Next, select the compute type.
    Here you can choose between Azure Kubernetes Services and Azure Container Instance.
    Both resources are typically used for real-time inference. The Kubernetes service
    is typically used for large-scale production deployments that require fast response
    time and autoscaling. This is exactly the opposite of our prototyping requirements.
    We’re happy with the Azure Container Service, which is used for smaller CPU-based
    workloads that require less than 48 GB RAM. Make sure authentication is disabled
    for now and click Deploy.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 为您的模型部署命名。我建议使用模型目的（预测变量）和您正在使用的算法的组合。在我们的情况下，一个好的模型名称可能是`**arrdel-votingensemble**`。接下来，选择计算类型。在这里，您可以选择Azure
    Kubernetes服务和Azure容器实例。这两种资源通常用于实时推断。Kubernetes服务通常用于需要快速响应时间和自动缩放的大规模生产部署，这与我们的原型要求完全相反。我们满意Azure容器服务，用于小型基于CPU的工作负载，需要少于48
    GB的RAM。确保目前已禁用身份验证，然后点击“部署”。
- en: After you click Deploy, you should see a notification telling you that the deployment
    is in progress ([Figure 7-27](#model_deployment_in_progress)).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 点击部署后，您应该会看到一个通知，告诉您部署正在进行中（[图 7-27](#model_deployment_in_progress)）。
- en: '![Model deployment in progress](Images/apbi_0727.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![模型部署中](Images/apbi_0727.png)'
- en: Figure 7-27\. Model deployment in progress
  id: totrans-216
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-27\. 模型部署中
- en: After a few minutes, you should see another notification that the deployment
    is complete. From the main menu on the left, click Endpoints and select your deployed
    model. You should see a screen similar to [Figure 7-28](#deployed_model_endpoint).
    The deployment state of your model should be Healthy, and you should see a REST
    endpoint URL. That’s one of the most important parameters from this whole page.
    We will use the REST endpoint later to make predictions (inference).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，您应该会看到另一个通知，告诉您部署已完成。从左侧的主菜单中，点击“端点”，然后选择您部署的模型。您应该会看到类似于[图 7-28](#deployed_model_endpoint)的屏幕。您的模型部署状态应为正常，并且您应该看到一个REST端点URL。这是整个页面中最重要的参数之一。我们稍后将使用REST端点进行预测（推理）。
- en: '![Deployed model endpoint](Images/apbi_0728.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![部署的模型端点](Images/apbi_0728.png)'
- en: Figure 7-28\. Deployed model endpoint
  id: totrans-219
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-28\. 部署的模型端点
- en: Congratulations, your first ML model is now ready for use! But before we integrate
    this model into our BI reports, let’s quickly test it by using the built-in testing
    features in Azure ML Studio.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，您的第一个机器学习模型现在已经准备好使用了！但在将此模型集成到我们的BI报告之前，让我们通过使用Azure ML Studio中的内置测试功能快速测试它。
- en: From the tab menu of the deployed model, choose Test. Here, you can quickly
    get online predictions for some sample data points. You can either input these
    values manually using the provided form, or you can toggle the small CSV icon
    to paste tabular data, as shown in [Figure 7-29](#testing_the_model_using_a_real_time_end).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署模型的选项菜单中，选择“测试”。在这里，您可以快速获取一些样本数据点的在线预测结果。您可以使用提供的表单手动输入这些值，或者您可以切换小的CSV图标以粘贴表格数据，如[图 7-29](#testing_the_model_using_a_real_time_end)所示。
- en: '![Testing the model using a real-time endpoint](Images/apbi_0729.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![使用实时端点测试模型](Images/apbi_0729.png)'
- en: Figure 7-29\. Testing the model using a real-time endpoint
  id: totrans-223
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-29\. 使用实时端点测试模型
- en: Open the *AA_Hourly_Batches_2021-02-07_0800-0859.csv* file in a plain-text editor
    of your choice (not in Excel!). This file contains one batch of hourly flight
    data, which we want to use to make predictions about the expected arrival delay.
    In the text editor, select all, and then copy and paste the contents into the
    text area on the testing page. Click the Test button, and you should immediately
    see the results on the right ([Figure 7-30](#testing_model_predictions)).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在您选择的纯文本编辑器中打开*AA_Hourly_Batches_2021-02-07_0800-0859.csv*文件（请勿在Excel中打开！）。此文件包含一个小时航班数据的一个批次，我们希望用它来预测预期到达延迟。在文本编辑器中，选择所有内容，然后复制并粘贴到测试页面的文本区域中。点击“测试”按钮，您应该立即在右侧看到结果（[图 7-30](#testing_model_predictions)）。
- en: '![Testing model predictions](Images/apbi_0730.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![测试模型预测](Images/apbi_0730.png)'
- en: Figure 7-30\. Testing model predictions
  id: totrans-226
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-30\. 测试模型预测
- en: Now that our model is up and running, we are going to use R or Python to start
    getting inferences inside our BI dashboard. To call online predictions from our
    BI report, we need to run a small script that takes data from (in our case) Power
    BI, sends it to the HTTP API, retrieves the results, and feeds them back into
    the report.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的模型已经启动运行，我们将使用R或Python开始在我们的BI仪表板内获取推断。要从我们的BI报告中调用在线预测，我们需要运行一个小脚本，该脚本从（在我们的情况下）Power
    BI获取数据，将其发送到HTTP API，检索结果，并将其反馈到报告中。
- en: Warning
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: We are leaving Azure ML Studio for now and will come back to it only for the
    next use case. To avoid costs, I recommend you stop the compute resource you used
    for the Auto ML training by choosing Azure Machine Learning Studio → Compute →
    Stop.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在离开Azure ML Studio，并且只会在下一个用例中回到它。为了避免费用，我建议您通过选择Azure Machine Learning Studio
    → 计算 → 停止来停止用于Auto ML训练的计算资源。
- en: Getting Model Predictions with Python or R
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Python或R获取模型预测
- en: Depending on your preferred programming language, you can continue this section
    by using either Python or R. I demonstrate the examples with R, but the same steps
    apply to Python as well.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您喜欢的编程语言，您可以继续使用Python或R来完成本节。我用R演示了示例，但同样的步骤也适用于Python。
- en: 'Visit Azure ML Studio. Select Endpoints and choose the model you want to use
    for requesting inference. On the following screen, select Consume and then choose
    R (or Python) from the tab menu. You will see two important things here, as shown
    in [Figure 7-31](#r_script_for_model_inference): the public REST endpoint URL
    you need to use and a pre-written script to submit the request.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 访问Azure ML Studio。选择“端点”并选择您要用于请求推断的模型。在接下来的屏幕上，选择“消耗”，然后从选项卡菜单中选择R（或Python）。您将在这里看到两个重要的事项，如图[7-31](#r_script_for_model_inference)所示：您需要使用的公共REST端点URL以及提交请求的预写脚本。
- en: '![R script for model inference](Images/apbi_0731.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![用于模型推断的R脚本](Images/apbi_0731.png)'
- en: Figure 7-31\. R script for model inference
  id: totrans-234
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-31\. 用于模型推断的R脚本
- en: The pre-written script is good enough if you want to process a single request
    for a single observation. If you want to process a whole table with multiple data
    points, you would need to rewrite the script in a way that multiple records are
    sent to the API, and not only one.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只想处理单个观察请求，则预写脚本已经足够好了。如果要处理包含多个数据点的整个表格，则需要以一种使多条记录发送到API的方式重写脚本，而不仅仅是一条记录。
- en: On the [book’s website](https://oreil.ly/X9jmJ), you can find two files, *azure-ml-inference-arrdel15.R*
    and *azure-ml-inference-arrdel15.py*. Both scripts share the same structure, sections,
    variable names, and code logic. I’ll walk you through the code examples in R,
    but the same applies to the Python version as well.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在[书籍的网站](https://oreil.ly/X9jmJ)上，您可以找到两个文件，*azure-ml-inference-arrdel15.R*和*azure-ml-inference-arrdel15.py*。这两个脚本共享相同的结构、部分、变量名称和代码逻辑。我将为您演示R中的代码示例，但同样适用于Python版本。
- en: 'Let’s go through the script *azure-ml-inference-arrdel15.R* piece by piece.
    Section 0 of the script does some setup and housekeeping. First, the script loads
    all required packages. In the case of R, these are the following:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步查看脚本*azure-ml-inference-arrdel15.R*。脚本的第0部分进行了一些设置和日常维护。首先，脚本加载了所有必需的包。在R的情况下，这些包括以下内容：
- en: '*httr* (for making HTTP requests)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*httr*（用于发出HTTP请求）'
- en: '*rjson* (for handling the API response)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*rjson*（用于处理API响应）'
- en: '*dplyr* (for data preparation)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*dplyr*（用于数据准备）'
- en: Make sure you have them installed for the R engine that Power BI is using, as
    described in [Chapter 4](ch04.xhtml#prototyping).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您已安装了用于Power BI使用的R引擎，如第4章中描述的那样。
- en: Next, you need to customize two variables. For the variable `API_URL`, replace
    the dummy URL with the REST endpoint one from the Consume tab in your Azure portal.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要自定义两个变量。对于变量`API_URL`，请使用Azure门户中“消耗”选项卡中的REST端点URL替换虚拟URL。
- en: 'The variable `API_KEY` is empty since we deployed our model without authentication.
    If you enable authentication, you would need to include your authentication key
    here:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`API_KEY`为空，因为我们在不进行身份验证的情况下部署了我们的模型。如果启用身份验证，您需要在此处包括您的身份验证密钥：
- en: '[PRE0]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Warning
  id: totrans-245
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: While we store our Azure credentials in plain text here within the code, please
    be aware that this is generally not good coding practice. We are doing this to
    keep things simple. If you want to learn best practices around handling authentication
    mechanisms, I recommend checking out the Microsoft resource [“About Azure Key
    Vault”](https://oreil.ly/cD2o6).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们在这里将我们的 Azure 凭证以明文形式存储在代码中，但请注意，这通常不是良好的编程实践。我们之所以这样做是为了简化事务。如果您想了解有关处理身份验证机制的最佳实践，请查阅微软资源
    [“关于 Azure 密钥保管库”](https://oreil.ly/cD2o6)。
- en: Section 1 of the code contains the function for the actual API request, similar
    to the example script in Azure. The main difference is that you can pass a whole
    set of records to this function rather than just a single observation, which speeds
    up the overall process considerably.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的第 1 节包含了实际 API 请求的函数，类似于 Azure 中的示例脚本。主要区别在于，您可以将整套记录传递给此函数，而不仅仅是单个观察结果，这极大地加快了整个处理过程。
- en: 'As you can see from the code, the column names have a static reference. So
    if you have made changes to the dataset or chosen different columns for predictions,
    you will need to update them in the script as well:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 从代码中可以看出，列名称具有静态引用。因此，如果您已对数据集进行了更改或选择了不同的列进行预测，您也需要在脚本中更新它们：
- en: '[PRE1]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Section 2 contains the data processing part, which is simple in this case.
    This script is later embedded in a Power Query workflow, and Power Query passes
    the data from the previous step to the script as a table called `dataset`. As
    you can see from the script, we are assigning this source data to a new variable
    `df` to stay organized and keep the processed data separate from the original
    data:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 第 2 节包含了这种情况下的数据处理部分。此脚本稍后将嵌入到 Power Query 工作流中，Power Query 将前一步骤的数据作为名为 `dataset`
    的表传递给脚本。正如您从脚本中看到的那样，我们将此源数据分配给一个新变量 `df`，以保持组织结构，并将处理后的数据与原始数据分开：
- en: '[PRE2]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Section 3 extracts the relevant columns for our prediction from the given dataset
    and actually calls the API, which is our hosted model:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 第 3 节从给定数据集中提取了我们预测所需的相关列，并实际调用了 API，这是我们托管的模型：
- en: '[PRE3]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Section 4 takes the result from the API and formats it in a way that it can
    be added to our original dataset as a new column called `ArrDel15_Prediction`:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 第 4 节从 API 中获取结果，并将其格式化为可以添加到我们的原始数据集作为名为 `ArrDel15_Prediction` 的新列的形式：
- en: '[PRE4]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, section 5 provides the output in a form that Power BI can take over
    from here again:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，第 5 节以 Power BI 可以继续处理的形式提供输出：
- en: '[PRE5]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-258
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Our dataset contains just a little more than 100 observations. If you need many
    more predictions than that (10,000+ rows), consider limiting the number of data
    points per API call or choosing a batch prediction instead of an online prediction.
    You will learn more about batch predictions in [Chapter 10](ch10.xhtml#bringing_it_all_together_building_an_ai).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集仅包含略多于 100 个观察结果。如果您需要的预测量比这多得多（10,000+ 行），请考虑限制每个 API 调用的数据点数量，或选择批量预测而不是在线预测。您将在
    [第 10 章](ch10.xhtml#bringing_it_all_together_building_an_ai) 中了解更多关于批量预测的信息。
- en: Model Inference with Power BI Walk-Through
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Power BI 演示模型推理
- en: Now that you know how to get predictions from your model programmatically, it
    is finally time to put your knowledge into action in Power BI. Note that although
    we are using Power BI here, you could use any BI tool that is able to process
    R or Python code.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您知道如何以编程方式从模型中获取预测结果，终于可以在 Power BI 中将您的知识付诸实践了。请注意，尽管我们在这里使用的是 Power BI，但您可以使用任何能够处理
    R 或 Python 代码的 BI 工具。
- en: 'Our goal is to enhance the arrival delay predictions for the dashboard we have
    seen in the problem statement (shown previously in [Figure 7-2](#reporting_dashboard_on_proportion_of_de)).
    To recap: the dashboard reads hourly batches of flight data and shows the expected
    proportion of delayed flights on arrival. We will now take this data, send it
    to our hosted model, get the predictions, and display the aggregated score for
    further use and improved decision making.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是增强对我们在问题说明中看到的仪表板的到达延迟预测（如 [图 7-2](#reporting_dashboard_on_proportion_of_de)
    所示）。回顾一下：仪表板每小时读取一批航班数据，并显示到达时延迟航班的预期比例。现在，我们将获取这些数据，发送到我们托管的模型中，获取预测结果，并显示聚合分数以供进一步使用和改进决策。
- en: To follow along in Power BI, open the *Arrival_Delay.pbix* file. You should
    see the dashboard shown in [Figure 7-32](#power_bi_report_for_on_time_arrivals).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Power BI 中进行操作，请打开 *Arrival_Delay.pbix* 文件。您应该看到 [图 7-32](#power_bi_report_for_on_time_arrivals)
    中显示的仪表板。
- en: '![Power BI report for on-time arrivals](Images/apbi_0732.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![准时到达的 Power BI 报告](Images/apbi_0732.png)'
- en: Figure 7-32\. Power BI report for on-time arrivals
  id: totrans-265
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-32\. Power BI 按时到达报告
- en: To add our AI predictions, we have to apply some data transformations. Click
    the Transform Data icon to launch Power Query from the toolbar, as shown in [Figure 7-33](#transform_data_icon).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加我们的 AI 预测，我们必须应用一些数据转换。点击工具栏中的“转换数据”图标以启动 Power Query，如[图 7-33](#transform_data_icon)所示。
- en: '![Transform Data icon](Images/apbi_0733.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![数据转换图标](Images/apbi_0733.png)'
- en: Figure 7-33\. Transform Data icon
  id: totrans-268
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-33\. 数据转换图标
- en: This opens the Power Query Editor. This tool allows you to manipulate your data,
    apply calculations, perform transformations, and execute Python and R scripts!
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打开 Power Query 编辑器。该工具允许您操作数据，应用计算，执行转换，并执行 Python 和 R 脚本！
- en: From the toolbar, click the Transform tab and then “Run R script” or “Run Python
    script,” depending on which you prefer (see [Figure 7-34](#power_query_edito)).
    For this tutorial, I will continue with the example of R.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 从工具栏中选择“转换”选项卡，然后根据您的偏好选择“运行 R 脚本”或“运行 Python 脚本”（参见[图 7-34](#power_query_edito)）。在本教程中，我将继续使用
    R 的示例。
- en: '![Power Query Editor](Images/apbi_0734.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![Power Query 编辑器](Images/apbi_0734.png)'
- en: Figure 7-34\. Power Query Editor
  id: totrans-272
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-34\. Power Query 编辑器
- en: In the code editor, paste the code from the script file (*azure-ml-inference-arrdel15.R*),
    as shown in [Figure 7-35](#running_rsoliduspython_scripts_inside_p). Double-check
    that you have replaced the endpoint URL with the one from your model in code section
    0.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码编辑器中，粘贴来自脚本文件（*azure-ml-inference-arrdel15.R*）的代码，如[图 7-35](#running_rsoliduspython_scripts_inside_p)所示。请确保已将代码段
    0 中的终端 URL 替换为您模型的 URL。
- en: '![Running R/Python scripts inside Power Query](Images/apbi_0735.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![在 Power Query 中运行 R/Python 脚本](Images/apbi_0735.png)'
- en: Figure 7-35\. Running R/Python scripts inside Power Query
  id: totrans-275
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-35\. 在 Power Query 中运行 R/Python 脚本
- en: Click OK, and Power BI will evaluate the script. If you get a warning on data
    privacy, select “Ignore Privacy Levels checks for this file.” The script should
    take a moment, depending on the number of rows you send to the API endpoint. Remember,
    we are still in the phase of prototyping here. In a production setting, you would
    apply these AI predictions on a database level and just consume them from your
    Power BI or reporting system. Check out [Chapter 11](ch11.xhtml#taking_the_next_steps_from_prototype_to)
    for more details.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“确定”，Power BI 将评估脚本。如果您收到有关数据隐私的警告，请选择“忽略此文件的隐私级别检查”。脚本的执行时间会根据发送到 API 终端的行数而有所不同。请记住，我们仍处于原型阶段。在生产环境中，您将在数据库级别应用这些
    AI 预测，并且只需从 Power BI 或报告系统中使用它们。详细信息请参阅[第 11 章](ch11.xhtml#taking_the_next_steps_from_prototype_to)。
- en: Once the script is finished, you should see a prompt with two tables in Power
    Query. Select the “output” table. You will notice two things in the editor. First,
    another step is added under the Applied Steps pane on the right. And second, you
    will see a new column, ArrDel15_Prediction, if you scroll to the right ([Figure 7-36](#prediction_column_in_power_query)).
    Double-check that the data type of this column is recognized as numeric. If it
    isn’t, right-click the column and choose Change Type → Whole Number.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本执行完成后，在 Power Query 中您应该会看到一个提示，其中包含两个表格。选择“输出”表。如果您向右滚动，您将注意到编辑器中的两件事。首先，在右侧的“应用步骤”窗格下添加了另一个步骤。其次，您将看到一个新的列，“ArrDel15_Prediction”，如果您滚动到右侧的话（参见[图
    7-36](#prediction_column_in_power_query)）。请务必检查此列的数据类型是否被识别为数字。如果没有，请右键单击列，然后选择“更改类型”→“整数”。
- en: '![Prediction column in Power Query](Images/apbi_0736.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![Power Query 中的预测列](Images/apbi_0736.png)'
- en: Figure 7-36\. Prediction column in Power Query
  id: totrans-279
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-36\. Power Query 中的预测列
- en: In the Power Query Editor, select Home and then Close & Apply. Your data model
    is being updated and populated with the new additional information. You can see
    the new column in the updated model. Whenever you want to update the data or the
    predictions, you need to refresh the data model, as shown in [Figure 7-37](#refreshing_data).
    This will reload the data from the file or an external source and rerun the steps
    in the Power Query Editor.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Power Query 编辑器中，选择“主页”，然后选择“关闭并应用”。您的数据模型正在更新，并添加了新的附加信息。您可以在更新的模型中看到新的列。每当您希望更新数据或预测时，您需要刷新数据模型，如[图
    7-37](#refreshing_data)所示。这将重新加载来自文件或外部源的数据，并重新运行 Power Query 编辑器中的步骤。
- en: '![Refreshing data](Images/apbi_0737.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![刷新数据](Images/apbi_0737.png)'
- en: Figure 7-37\. Refreshing data
  id: totrans-282
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-37\. 刷新数据
- en: Building the AI-Powered Dashboard in Power BI
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Power BI 中构建 AI 强化的仪表板
- en: We are now ready to populate our dashboard with the new information. Go back
    to Report and select the Card visual with the Proportion of Delayed Flights. Drag
    and drop the new dimension ArrDel15_Prediction from the Fields pane to the value
    field of the card visual, replacing the old metric DepDel15\. Right-click the
    updated field and select Average. The Settings pane should now look like [Figure 7-38](#updated_dashboard_with_ai_predictions),
    and the metric should update to 0.1495.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好用新信息填充我们的仪表板了。返回报告，选择Card视觉，使用延误航班比例的Proportion of Delayed Flights。从字段窗格中拖放新的维度ArrDel15_Prediction到卡片视觉的值字段，替换旧的度量DepDel15。右键单击更新后的字段，选择平均值。设置窗格现在应该看起来像[Figure 7-38](#updated_dashboard_with_ai_predictions)，度量应该更新为0.1495。
- en: '![Updated dashboard with AI predictions](Images/apbi_0738.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![带有AI预测的更新仪表板](Images/apbi_0738.png)'
- en: Figure 7-38\. Updated dashboard with AI predictions
  id: totrans-286
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 7-38\. 带有AI预测的更新仪表板
- en: Go ahead and replace the DepDel15 field with the new ArrDel15_Predicted dimension
    for the rest of the visuals in the dashboard. This includes the filter value for
    the card visual Expected Delay on Arrival as well as the filter on the flights
    table.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 继续使用新的ArrDel15_Predicted维度替换仪表板中其余视觉的DepDel15字段。这包括Card视觉上预期到达延迟的过滤值以及航班表上的过滤器。
- en: Alternatively, you can open the file *Arrival_Delay_AI-Powered.pbix* and follow
    along from there. Your final dashboard should look like [Figure 7-39](#final_ai_powered_dashboard_with_online).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以打开文件*Arrival_Delay_AI-Powered.pbix*，并从那里跟随。您的最终仪表板应该像[Figure 7-39](#final_ai_powered_dashboard_with_online)那样。
- en: '![Final AI-powered dashboard with online predictions for flight delays](Images/apbi_0739.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![带有在线预测航班延误的最终AI驱动仪表板](Images/apbi_0739.png)'
- en: Figure 7-39\. Final AI-powered dashboard with online predictions for flight
    delays
  id: totrans-290
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 7-39\. 带有在线航班延误预测的最终AI驱动仪表板
- en: From the count of delayed flights alone, we might intuitively assume that the
    predictions from our baseline and the AI model are not that different. But don’t
    fall for that trap! Just because the AI predicts one more flight in total to be
    delayed, the actual flights that are expected to be delayed are quite different.
    Have a look at the flights table. In the AI-powered dashboard, we can see flagged
    flights that did not have a departure delay of 15 minutes. Examples include flights
    AA2378 from IAH to DFW, flight AA2776 from OKC to DFW, and flight AA2828 from
    AUS to DFW that even started ahead of time.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 仅从延误航班的计数来看，我们可能直觉地认为我们的基线和AI模型的预测并没有太大差异。但不要陷入这个陷阱！仅仅因为AI预测总体上会有更多的延误航班，实际上预计会延误的航班是完全不同的。看一下航班表格。在AI驱动的仪表板上，我们可以看到标记的航班，并没有15分钟的出发延误。例如从IAH到DFW的AA2378航班，从OKC到DFW的AA2776航班，以及从AUS到DFW的AA2828航班，甚至提前起飞。
- en: As we know from the real dataset shown in [Figure 7-40](#actual_delay_of_flights_aatwothreeseven),
    we can confirm that flights AA2378 and flights AA2828 were in fact delayed by
    more than 15 minutes. Flight AA2776 did not have the ArrivalDelay15 flag, but
    the plane landed 12 minutes late, despite having a head start of 10 minutes. While
    technically the AI prediction here was wrong, it was definitely a good guess.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们从[Figure 7-40](#actual_delay_of_flights_aatwothreeseven)所示的真实数据集中所知，我们可以确认AA2378航班和AA2828航班确实延误了超过15分钟。尽管AA2776航班没有到达延误15标志，但飞机降落晚了12分钟，尽管起飞时间领先10分钟。从技术上讲，这里AI的预测是错误的，但这绝对是一个不错的猜测。
- en: '![Actual delay of flights AA2378 and AA2776 on 7/2/21](Images/apbi_0740.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![AA2378和AA2776航班在7/2/21的实际延误情况](Images/apbi_0740.png)'
- en: Figure 7-40\. Actual delay of flights AA2378 and AA2776 on 7/2/21
  id: totrans-294
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 7-40\. AA2378和AA2776航班在7/2/21的实际延误情况
- en: I hope you enjoyed building this dashboard and found out how AI can help you
    to make better predictions for your dataset. Keep track of a baseline and see
    if and how well AI can possibly outperform this.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您喜欢制作这个仪表板，并了解AI如何帮助您对数据集进行更好的预测。跟踪一个基线，并查看AI可能如何超越它。
- en: 'Use Case: Improving KPI Prediction'
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用案例：改进KPI预测
- en: For this use case, we will continue with the previous scenario. We are on the
    BI team of American Airlines. Only this time, we don’t want to improve our live
    reporting, but rather our planning even ahead of time.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个用例，我们将继续之前的情景。我们是美国航空的商业智能团队。这一次，我们不想改善我们的实时报告，而是提前进行规划。
- en: For that purpose, we will need to deal with the Elapsed Time metric, which measures
    the difference between actual departure time and actual arrival time of a given
    flight. The elapsed time is planned well ahead and called the Computer Reservation
    System (CRS) Elapsed Time. In contrast to the preceding use case, this is not
    a categorical, but a continuous numerical variable.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要处理经过时间指标，该指标衡量了给定航班实际起飞时间与实际到达时间之间的差异。经过时间计划得很早，称为计算机预订系统（CRS）经过时间。与之前的用例不同，这不是一个分类变量，而是一个连续的数值变量。
- en: Welcome to the world of regression problems! Let’s find out more about the problem
    by introducing the problem statement as follows.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到回归问题的世界！让我们通过以下问题陈述进一步了解问题。
- en: Problem Statement
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题陈述
- en: We want to identify bottlenecks in the flight schedule for the next month and
    flag those flights that have a high chance of being delayed, meaning the actual
    elapsed time was higher than the planned elapsed time. The BI team has built a
    dashboard that analyzes historical data and shows a key performance indicator
    (KPI) that compares CRS (scheduled) Elapsed Time to Actual Elapsed Time. You can
    see this dashboard in [Figure 7-41](#flight_analysis_dashboard) or open it yourself
    in Power BI with the file *Elapsed_Time.pbix*.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望识别下个月航班时间表中的瓶颈，并标记那些可能延误的航班，即实际经过时间高于计划经过时间。BI团队已建立一个仪表板，分析历史数据并展示一个关键绩效指标（KPI），比较了CRS（计划）经过时间与实际经过时间。您可以在[图7-41](#flight_analysis_dashboard)中看到这个仪表板，或者在Power
    BI中使用文件*Elapsed_Time.pbix*自行打开。
- en: '![Flight analysis dashboard](Images/apbi_0741.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![航班分析仪表板](Images/apbi_0741.png)'
- en: Figure 7-41\. Flight analysis dashboard
  id: totrans-303
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-41\. 航班分析仪表板
- en: From the dashboard, we find out that, on average, flights need 9.30 minutes
    less than actually planned. This intuitively makes sense, as we know that the
    schedule is optimized to minimize delays. At the same time, we can see from the
    scatterplot on the left that some flights exceed the planned elapsed time. The
    scatterplot shows CRS Elapsed Time versus Actual Elapsed Time. Each point is a
    flight. Points in the upper dark area of the plot needed more time than originally
    scheduled. The key question is, are we able to create a model that will flag these
    flights at times when the flight schedule is generated?
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 从仪表板中，我们发现，平均而言，航班需要比计划的时间少9.30分钟。这在直觉上是有道理的，因为我们知道航班时间表被优化以最小化延误。同时，我们可以从左侧的散点图中看到，一些航班超过了计划的经过时间。散点图显示了CRS经过时间与实际经过时间。每个点代表一个航班。在图的上部暗区域的点需要比原定计划的时间更多。关键问题是，我们能否创建一个模型，在生成航班时间表时标记这些航班？
- en: Based on the historical data, the analysts have built a simple regression model
    that is also shown as a trend line in the dashboard. The model takes the scheduled
    CRS Elapsed Time and calculates a prediction for the Actual Elapsed Time based
    on the historical data. The analysts have told us that the regression model has
    a Standard Error (RMSE) of 14.30, as shown in [Figure 7-42](#baseline_regression_model).
    If you struggle with the interpretation of these metrics, revisit [Chapter 3](ch03.xhtml#machine_learning_fundamentals)
    briefly. While the model seems to be good on paper, it turns out to be quite useless
    for predicting the actual elapsed time.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 基于历史数据，分析师们建立了一个简单的回归模型，也显示为仪表板上的趋势线。该模型以计划的CRS经过时间为基础，根据历史数据计算实际经过时间的预测。分析师告诉我们，回归模型的标准误差（RMSE）为14.30，如[图7-42](#baseline_regression_model)所示。如果您对这些指标的解释感到困惑，请简要回顾[第3章](ch03.xhtml#machine_learning_fundamentals)。尽管在文件上模型看起来不错，但它实际上对于预测实际经过时间几乎没什么用处。
- en: '![Baseline regression model](Images/apbi_0742.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![基准回归模型](Images/apbi_0742.png)'
- en: Figure 7-42\. Baseline regression model
  id: totrans-307
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-42\. 基准回归模型
- en: Open the Future Schedule report in the file *Elapsed_Time.pbix* ([Figure 7-43](#crs_elapsed_time_versus_predicted_elaps)).
    As we can see from this report, applying the model to the flight schedule for
    February 2021 will flag 114 flight numbers for which the actual elapsed time will
    probably exceed the scheduled elapsed time by five minutes or more. However, by
    looking at the bar chart on the right, we can see that the biggest difference
    between the scheduled elapsed and actual predicted elapsed time is only marginal,
    with 6.50 minutes more than planned. That is the highest difference the regression
    model is able to predict. Look at the scatterplot on the left. It shows the average
    expected delay by flight number. You can see that all of these flights are close
    to the threshold of being exactly in line with the scheduled elapsed time. This
    makes it hard for us to identify those flights that are likely to encounter a
    long delay.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在文件*Elapsed_Time.pbix*的“未来时间表”报告中打开（图 7-43）CRS 预计时间与预测经过时间。从这份报告中我们可以看到，应用模型到2021年2月的航班时间表将标记114个航班号，其实际经过时间可能比计划经过时间多五分钟或更多。然而，通过右侧的条形图我们可以看到，计划经过时间与实际预测经过时间之间的最大差异仅微小，比计划多了6.50分钟。这是回归模型能够预测到的最大差异。看一下左侧的散点图，它显示了按航班号排序的平均预期延误。你可以看到所有这些航班都接近准时的阈值，这使我们难以确定可能会遇到长时间延误的航班。
- en: '![CRS Elapsed Time versus Predicted Elapsed Time baseline](Images/apbi_0743.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![CRS Elapsed Time versus Predicted Elapsed Time baseline](Images/apbi_0743.png)'
- en: Figure 7-43\. CRS Elapsed Time versus Predicted Elapsed Time baseline
  id: totrans-310
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-43\. CRS 预计经过时间与预测经过时间基准
- en: The regression model that has been built is just not flexible enough to capture
    variations in the elapsed time that are caused by variables other than the scheduled
    CRS time. But what are these influencing variables, anyway? The BI team has further
    conducted an analysis and identified key drivers that cause the difference between
    the scheduled elapsed time and the actual elapsed time to increase. You can find
    a screenshot of this analysis in [Figure 7-44](#key_influencers_analysis_for_predicted)
    or in the “Key influencers” report page in the Power BI file *Elapsed_Time.pbix*.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 建立的回归模型并不能灵活地捕捉由于除计划CRS时间以外的变量引起的经过时间的变化。但究竟是哪些影响变量呢？BI团队进一步进行了分析，并确定了导致预定经过时间与实际经过时间差异增加的关键驱动因素。你可以在[图
    7-44](#key_influencers_analysis_for_predicted)中找到这次分析的截图，或者在Power BI文件*Elapsed_Time.pbix*的“关键影响因素”报告页面中查看。
- en: '![Key influencers analysis for predicted flight delays](Images/apbi_0744.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![预测飞行延误的关键影响因素分析](Images/apbi_0744.png)'
- en: Figure 7-44\. Key influencers analysis for predicted flight delays
  id: totrans-313
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-44\. 预测飞行延误的关键影响因素分析
- en: From the analysis, we find out that a variety of factors drive the discrepancy
    between scheduled and elapsed time. Among them are the origin airport, flight
    distance, planned flight duration, and the arrival time block. So, you probably
    don’t want to schedule a meeting shortly after arrival if you take a short-distance
    flight from Austin that is expected to land sometime between 9:00 a.m. and 9:59
    a.m.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 从分析中，我们发现多种因素导致预定时间与实际时间之间的差异。其中包括出发机场、飞行距离、计划飞行持续时间和到达时间段。因此，如果你从奥斯汀乘坐短途航班，预计在上午9:00至9:59之间降落，你可能不希望安排在抵达后不久的会议。
- en: But how can we as an airline turn these insights into actionable information
    for our customers? How can we flag those critical bottlenecks in a flight schedule
    and surface them automatically without having to run through the key influencers
    analysis over and over again? Let’s find out how by proceeding to the solution
    overview.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 但作为航空公司，我们如何将这些洞见转化为可操作的信息呢？如何在不反复运行关键影响因素分析的情况下自动标识航班时间表中的关键瓶颈？我们通过解决方案概述来找出答案。
- en: Solution Overview
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案概述
- en: To identify bottlenecks in the flight schedule, we will take all information
    available to us when the schedule is created and train an ML model on historical
    data to predict the actual elapsed time using this information. The information
    includes attributes such as origin airport, destination airport, arrival and departure
    time blocks, and more. All these attributes are known before the flight even happens,
    so we don’t run into a training-serving skew and can react to the model outputs
    well ahead of time.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别航班时间表中的瓶颈，我们将在创建时间表时利用所有可用信息，并使用历史数据训练 ML 模型来预测实际经过时间。这些信息包括起始机场、目的地机场、到达和离开时间段等属性。所有这些属性在航班发生之前都是已知的，因此我们不会遇到训练-服务偏差，并且可以提前很好地响应模型输出。
- en: '[Figure 7-45](#use_case_architecture_for_improving_kpi) shows the high-level
    architecture of this use case. It’s similar to what we did previously in [“Use
    Case: Automating Classification Tasks”](#use_case_automating_classification_task).
    We will train an ML model on historical data and deploy it using Azure ML Studio,
    so we can get predictions from an online endpoint from within Power BI. The only
    major difference is that this time we are not training a classification model,
    but a regression model. Again, we are using Power BI to make the request, but
    we could use other BI tools as well.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [7-45](#use_case_architecture_for_improving_kpi) 展示了此用例的高层架构。这与我们之前在 [“用例：自动化分类任务”](#use_case_automating_classification_task)
    中所做的类似。我们将在历史数据上训练 ML 模型，并使用 Azure ML Studio 部署它，以便我们可以从 Power BI 内部获取在线端点的预测。唯一的主要区别是，这次我们不是训练分类模型，而是回归模型。同样，我们使用
    Power BI 发出请求，但我们也可以使用其他 BI 工具。
- en: '![Use case architecture for improving KPI prediction](Images/apbi_0745.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![用例架构用于改进 KPI 预测](Images/apbi_0745.png)'
- en: Figure 7-45\. Use case architecture for improving KPI prediction
  id: totrans-320
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-45\. 用例架构用于改进 KPI 预测
- en: Model Training with Microsoft Azure Walk-Through
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Microsoft Azure 演练模型训练
- en: Head over to Azure ML Studio by navigating to *[ml.azure.com](http://ml.azure.com)*.
    From the home screen, choose Create new → Automated ML job, as shown in [Figure 7-46](#creating_a_new_automated_ml_run).
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 前往 Azure ML Studio，通过导航至 *[ml.azure.com](http://ml.azure.com)*。从主屏幕选择创建新 → 自动化
    ML 作业，如图 [7-46](#creating_a_new_automated_ml_run) 所示。
- en: '![Creating a new automated ML job](Images/apbi_0746.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![创建新的自动化 ML 作业](Images/apbi_0746.png)'
- en: Figure 7-46\. Creating a new automated ML job
  id: totrans-324
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-46\. 创建新的自动化 ML 作业
- en: Choose Create Dataset → From local file. You will see the form for providing
    basic information about your dataset ([Figure 7-47](#creating_a_dataset_from_local_files)).
    Give your dataset a name that you can relate to the AutoML training job. In this
    example, I chose `**aa-flights-elapsedtime**`. Proceed with Next.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 选择创建数据集 → 从本地文件。您将看到有关数据集基本信息的表单（见图 [7-47](#creating_a_dataset_from_local_files)）。为您的数据集取一个可以与
    AutoML 训练作业相关联的名称。在本示例中，我选择了 `**aa-flights-elapsedtime**`。继续点击下一步。
- en: '![Creating a dataset from local files](Images/apbi_0747.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![从本地文件创建数据集](Images/apbi_0747.png)'
- en: Figure 7-47\. Creating a dataset from local files
  id: totrans-327
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-47\. 从本地文件创建数据集
- en: Click the Upload button and select the *AA_Flights_2021_01.csv* file. Once the
    upload is complete, the Next button should appear at the bottom of the screen.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 点击上传按钮并选择 *AA_Flights_2021_01.csv* 文件。一旦上传完成，屏幕底部应出现下一步按钮。
- en: Note
  id: totrans-329
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Although we are technically using the same data source as in the previous use
    case, it is still a good idea to re-upload the file as a separate dataset in Microsoft
    Azure in order to keep organized. The training dataset we are using now has a
    different schema than the training dataset from the first use case. For example,
    this time we are predicting the Actual Elapsed Time attribute. You can also update
    the schema in Azure for a dataset by adding a new version, but this will be complicated
    to track if you want to retrain your ArrDel15 classifier from the use case before.
    A good rule of thumb: keep a separate dataset for each AutoML task, meaning that
    the target column should stay fixed. Use the schema update function and version
    control to add or remove features or tweak the data types of your input data,
    but don’t touch the target column.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在技术上使用的是与之前用例相同的数据源，但重新将文件作为 Microsoft Azure 中的单独数据集重新上传仍然是一个好主意，以保持组织有序。我们现在使用的训练数据集与第一个用例的训练数据集具有不同的模式。例如，这次我们预测实际经过时间属性。你还可以通过添加新版本在
    Azure 中更新数据集的模式，但如果你想重新训练之前的 ArrDel15 分类器，这将会很复杂。一个好的经验法则是：为每个 AutoML 任务保留单独的数据集，这意味着目标列应保持固定。使用模式更新功能和版本控制来添加或删除特征或调整输入数据的数据类型，但不要触及目标列。
- en: Continue to the “Settings and preview” form. Double-check that the file format
    is set to Delimited, the delimiter is set to Semicolon, and the encoding is set
    to UTF-8\. You should see a properly formatted preview of the data, as shown in
    [Figure 7-48](#dataset_settings_and_preview).
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 继续到“设置和预览”表单。确保文件格式设置为分隔符，分隔符设置为分号，并且编码设置为UTF-8。你应该看到数据的正确格式预览，如[图 7-48](#dataset_settings_and_preview)所示。
- en: '![Dataset settings and preview](Images/apbi_0748.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![数据集设置和预览](Images/apbi_0748.png)'
- en: Figure 7-48\. Dataset settings and preview
  id: totrans-333
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-48\. 数据集设置和预览
- en: 'Click Next to proceed to the schema settings. Include *only* the following
    attributes with their respective data types:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 点击下一步进入模式设置。仅包括以下带有其相应数据类型的属性：
- en: 'DayOfWeek: String'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'DayOfWeek: String'
- en: 'Origin: String'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Origin: String'
- en: 'Dest: String'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dest: String'
- en: 'DepTimeBlk: String'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'DepTimeBlk: String'
- en: 'ArrTimeBlk: String'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ArrTimeBlk: String'
- en: 'CRSElapsedTime: Decimal (Comma)'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'CRSElapsedTime: Decimal (Comma)'
- en: 'ActualElapsedTime: Decimal (Comma)'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ActualElapsedTime: Decimal (Comma)'
- en: 'Distance: Decimal (Comma)'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Distance: Decimal (Comma)'
- en: 'DistanceGroup: String'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'DistanceGroup: String'
- en: Click Next, confirm the details, and you should see the new dataset appear in
    the list of available datasets ([Figure 7-49](#list_of_available_datasets)).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 点击下一步，确认细节，你应该看到新数据集出现在可用数据集列表中（[图 7-49](#list_of_available_datasets)）。
- en: '![List of available datasets](Images/apbi_0749.png)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![可用数据集列表](Images/apbi_0749.png)'
- en: Figure 7-49\. List of available datasets
  id: totrans-346
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-49\. 可用数据集列表
- en: Select the new dataset and click Next. On the following screen, I suggest creating
    a new experiment to keep the models and results from the classification and regression
    tasks separated. Choose an experiment name that will differentiate well from the
    previous experiment, such as `**aa-automl-time**`. Choose ActualElapsedTime (Decimal)
    as the target column. For the compute resource, you can use the same “automl”
    resource that we have used in the previous use case. Proceed with Next.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 选择新数据集并点击下一步。在接下来的屏幕上，我建议创建一个新的实验，以便将分类和回归任务的模型和结果分开保存。选择一个能够很好区分前一个实验的实验名称，例如`**aa-automl-time**`。选择ActualElapsedTime
    (Decimal)作为目标列。对于计算资源，你可以使用之前用过的“automl”资源。继续进行下一步。
- en: On the following screen, AutoML will guess that you are trying to solve a regression
    problem, as you specified a continuous numeric target variable. In our case, this
    is absolutely correct! Before we finish the setup process, open the advanced settings
    shown in [Figure 7-50](#additional_configurations_for_automl) by clicking “View
    additional configuration settings.”
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的屏幕上，AutoML 将猜测你试图解决一个回归问题，因为你指定了一个连续的数值目标变量。在我们的案例中，这是完全正确的！在完成设置过程之前，通过点击“查看附加配置设置”，打开[图
    7-50](#additional_configurations_for_automl)中显示的高级设置。
- en: '![Additional configurations for AutoML](Images/apbi_0750.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![AutoML 的附加配置](Images/apbi_0750.png)'
- en: Figure 7-50\. Additional configurations for AutoML
  id: totrans-350
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-50\. AutoML 的附加配置
- en: In the additional configurations, make sure that “Primary metric” is set to
    “Normalized root mean squared error.” This way, we can compare the AutoML model
    pretty well with the existing baseline from the regression model we already have.
    Also double-check that the option “Explain best model” is checked. Under “Exit
    criterion,” set the training job to a maximum of 1 hour. In fact, we probably
    don’t even need that much time, and the algorithm should converge after roughly
    30 minutes. Confirm the settings with Save, and submit the AutoML job by clicking
    Finish.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 在附加配置中，确保“主要指标”设置为“归一化的均方根误差”。这样，我们可以与我们已有的回归模型基线相当好地比较AutoML模型。还要再次确认选项“解释最佳模型”已被选中。在“退出标准”下，将训练作业设置为最多1小时。实际上，我们可能甚至不需要那么多时间，算法大约在30分钟后应该会收敛。确认设置后点击保存，并通过点击完成提交AutoML作业。
- en: The run can take a while, so take a break and come back after a few minutes.
    You can check the status of your run by choosing Experiments → aa-automl-time
    (or whichever name you gave to it) and examining the status of your current run.
    Once the status changes to Completed, the run details should look similar to [Figure 7-51](#completed_run_details_for_the_lapsed_ti).
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 这个运行可能需要一些时间，所以休息一下，几分钟后再回来。你可以通过选择实验 → aa-automl-time（或者你给它起的任何名字）来检查运行的状态，并检查当前运行的状态。一旦状态变为已完成，运行的详细信息应该类似于[图7-51](#completed_run_details_for_the_lapsed_ti)。
- en: '![Completed job details for the lapsed time prediction](Images/apbi_0751.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![已完成的任务详细信息用于过去时间预测](Images/apbi_0751.png)'
- en: Figure 7-51\. Completed job details for the lapsed time prediction
  id: totrans-354
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-51\. 已完成的任务详细信息用于过去时间预测
- en: As you can see, in this case, the overall run took about 38 minutes and resulted
    in a model that uses VotingEnsemble as an algorithm—again! In fact, AutoML often
    comes up with a VotingEnsemble or Stacked Ensemble as the final model. Both techniques
    combine the results of numerous models that either “vote” for the final result
    or are “stacked” on top of each other to come up with the final decision (if you
    want to know more, revisit [Chapter 3](ch03.xhtml#machine_learning_fundamentals)
    for more details). It is common for AutoML algorithms to end up with ensemble
    models.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，在这种情况下，整体运行大约需要38分钟，并且生成了一个使用VotingEnsemble作为算法的模型——再次是这样！事实上，AutoML经常会产生VotingEnsemble或Stacked
    Ensemble作为最终模型。这两种技术都将众多模型的结果结合起来，这些模型要么为最终结果“投票”，要么“叠加”在一起以得出最终决策（如果你想了解更多，请回顾[第3章](ch03.xhtml#machine_learning_fundamentals)）。AutoML算法最终生成集成模型是很常见的。
- en: In our case, the model achieved a normalized RMSE of 0.2403\. How can we compare
    that to the RMSE baseline of 14.30 from our simple regression model?
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，该模型实现了0.2403的归一化RMSE。我们如何将其与我们简单回归模型的RMSE基线14.30进行比较？
- en: Click the VotingEnsemble link and choose Metrics. Uncheck all boxes except for
    r2-score, the residuals, and root_mean_squared_error, as shown in [Figure 7-52](#regression_evaluation_metrics).
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 点击VotingEnsemble链接，选择指标。取消除r2-score、残差和root_mean_squared_error之外的所有框，如[图7-52](#regression_evaluation_metrics)所示。
- en: '![Regression evaluation metrics](Images/apbi_0752.png)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![回归评估指标](Images/apbi_0752.png)'
- en: Figure 7-52\. Regression evaluation metrics
  id: totrans-359
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-52\. 回归评估指标
- en: From the metrics, you can see that the RMSE of our AutoML regression model is
    12.57\. That is less (and therefore better) than the simple regression model,
    but actually not that much, considering the amount of computing power we threw
    at this problem. But as you learned from the previous use case in this chapter,
    we should be skeptical about aggregated quality metrics and look at the results
    in a bit more detail.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 从指标来看，我们的AutoML回归模型的RMSE为12.57。这比简单回归模型要好（因此更好），但实际上并不太多，考虑到我们投入这个问题的计算能力。但正如你从本章的前一个用例中学到的那样，我们应该对聚合质量指标持怀疑态度，并且更详细地查看结果。
- en: Take a look back at the Residuals histogram in [Figure 7-52](#regression_evaluation_metrics).
    A *residual* is the error a regression model makes, the difference between the
    actual and the predicted outcome. For our simple regression model, the regression
    almost always predicted less than what was actually the real value. In our AutoML
    scenario here, we can see that the residuals are centered around the 0 value,
    with some predictions being a little bit on top of the actual metric and other
    predictions below that. This type of variance is a good sign, because we need
    this variation to identify flights that have a high probability of exceeding the
    scheduled elapsed time. So with some good faith in our AutoML model and the confirmation
    that at least on paper it is better than our regression baseline, head over to
    the Explanations tab to find out which factors are influencing our predictions.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下[图 7-52](#regression_evaluation_metrics)中的残差直方图。*残差*是回归模型的误差，即实际值与预测值之间的差异。对于我们的简单回归模型，预测值几乎总是低于实际值。在我们这里的AutoML场景中，我们可以看到残差集中在0值附近，有些预测值略高于实际度量值，而其他预测值则略低于实际度量值。这种变化的类型是一个好迹象，因为我们需要这种变化来识别那些有可能超出计划经过时间的航班。因此，对我们的AutoML模型抱有一些信心，并确认至少在理论上它比我们的回归基线更好后，前往“解释”选项卡查找影响我们预测的因素。
- en: In the Explanations tab, select the first list item with the raw features. Then
    select the “Aggregate feature importance” tab from the submenu. Select the Top
    5 features and you should see a screen similar to [Figure 7-53](#aggregate_feature_importance_for_the_re).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 在“解释”选项卡中，选择原始特征的第一个列表项。然后从子菜单中选择“聚合特征重要性”选项卡。选择前5个特征，您应该看到一个类似于[图 7-53](#aggregate_feature_importance_for_the_re)的屏幕。
- en: '![Aggregate feature importance for the regression model](Images/apbi_0753.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![回归模型的聚合特征重要性](Images/apbi_0753.png)'
- en: Figure 7-53\. Aggregate feature importance for the regression model
  id: totrans-364
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-53\. 回归模型的聚合特征重要性
- en: In this case, the top five features are CRSElapsedTime (no surprise, by far)
    and Distance, Dest, Origin, and ArrTimeBlk. This selection makes sense from a
    logical standpoint. Bigger airports are busier than smaller ones, so there should
    be a higher probability that a delay happens. Also, ArrTimeBlk confirms what we
    have seen from the key influencers tool previously. At certain arrival times,
    especially in morning hours, airports are typically busier, and delays are more
    likely to happen.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，排名前五的特征是CRSElapsedTime（毫不奇怪，远远超过其他）以及Distance、Dest、Origin和ArrTimeBlk。从逻辑角度来看，这种选择是有意义的。较大的机场比较繁忙，因此延误的可能性更高。此外，ArrTimeBlk从关键影响因素工具中确认了我们之前观察到的内容。在特定的到达时间，特别是在早晨，机场通常比较繁忙，延误的可能性更高。
- en: The actual results in your case might look a little different, as some random
    elements are involved in the AutoML process (for example, the way the data is
    split into training, testing, and validation sets). Unfortunately, we can’t set
    the seed for these random procedures fixed in Azure so we have 100% reproducible
    results. However, the overall big picture should be the same when you conduct
    the analysis on your own.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的情况下，实际结果可能会有所不同，因为在AutoML过程中涉及一些随机元素（例如，数据分为训练、测试和验证集的方式）。不幸的是，我们无法在Azure中固定这些随机过程的种子，因此无法100%复现结果。然而，当您自行进行分析时，总体大局应该是相同的。
- en: Let’s take a minute to understand our model even a little better and see what
    is going on. Click the “Individual feature importance” tab, shown in [Figure 7-54](#individual_feature_importance).
    You will find a scatterplot there. In the scatterplot, click the title of the
    y-axis and choose Predicted Y. Do the same for the x-axis and choose True Y. This
    will give an overview of all data points (flights) and their corresponding true
    and predicted values for the Elapsed Time attribute.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花一分钟时间更好地理解我们的模型，看看发生了什么。点击“个体特征重要性”选项卡，如[图 7-54](#individual_feature_importance)所示。在散点图中，点击y轴的标题，选择“预测Y”。对于x轴，选择“真实Y”。这将为所有数据点（航班）及其相应的真实和预测值提供一个概述，针对“Elapsed
    Time”属性。
- en: 'The great thing about this visualization is that we can individually select
    single data points and inspect the concrete feature importance that led to the
    individual predicted result. Choose three data points from this chart:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 这种可视化的绝妙之处在于，我们可以单独选择单个数据点并检查导致个别预测结果的具体特征重要性。从此图中选择三个数据点：
- en: One point with a predicted value that’s higher than the actual value
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个预测值高于实际值的点
- en: One point with a predicted value that almost matches the actual value
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个预测值几乎与实际值匹配的点
- en: One point with a predicted value that’s much lower than the actual value
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个预测值远低于实际值的点
- en: '[Figure 7-54](#individual_feature_importance) shows how this looks for my selection.'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 7-54](#individual_feature_importance)展示了我所选内容的情况。'
- en: '![Individual feature importance](Images/apbi_0754.png)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![个体特征重要性](Images/apbi_0754.png)'
- en: Figure 7-54\. Individual feature importance
  id: totrans-374
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-54\. 个体特征重要性
- en: To provide a little more context, you can also open the menu pane on the right
    to reveal more details about the data points. For example, data point Row 662
    is a flight from Honolulu Airport to Dallas Fort Worth, departing on a Saturday
    evening and landing in the morning, as you can see in [Figure 7-55](#data_point_feature_importance).
    The prediction for this point was pretty accurate, with a predicted elapsed time
    of 454.2 minutes and an actual time of 446 minutes.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供更多背景信息，您也可以打开右侧的菜单窗格，以查看有关数据点更多的细节。例如，第662行数据点是从檀香山机场到达达拉斯-沃斯堡的航班，周六晚上起飞，早晨降落，正如您在[图
    7-55](#data_point_feature_importance)中所看到的。这个点的预测时间是454.2分钟，实际时间是446分钟，预测非常准确。
- en: '![Data point feature importance](Images/apbi_0755.png)'
  id: totrans-376
  prefs: []
  type: TYPE_IMG
  zh: '![数据点特征重要性](Images/apbi_0755.png)'
- en: Figure 7-55\. Data point feature importance
  id: totrans-377
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-55\. 数据点特征重要性
- en: Likewise, I chose a point with a prediction value that was much higher than
    actual (426 minutes versus 395 minutes for Row 2395) and one point with a prediction
    value that fell short (84 versus 140 minutes in the case of Row 1523).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我选择了一个预测值远高于实际值的点（例如第2395行，预测426分钟，实际395分钟），以及一个预测值偏低的点（例如第1523行，预测84分钟，实际140分钟）。
- en: Now, with three points selected, scroll down to see a graphic similar to the
    one in [Figure 7-56](#local_feature_importance_of_selected_da).
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，选择了三个点后，向下滚动以查看类似于[图 7-56](#local_feature_importance_of_selected_da)的图形。
- en: '![Local feature importance of selected data points](Images/apbi_0756.png)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![所选数据点的本地特征重要性](Images/apbi_0756.png)'
- en: Figure 7-56\. Local feature importance of selected data points
  id: totrans-381
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-56\. 所选数据点的本地特征重要性
- en: This graphic shows what led to the individual prediction for the selected data
    points. For example, we can see that for Row 1523 (the bar in the middle), at
    the point where the prediction was too low, the feature CRSElapsedTime was actually
    weighed down by the model. For some reason, the model decided that in this special
    case, the original scheduled time should not be considered as much. As it turns
    out, in this case, this was a bad decision. In contrast, for Row 662 (the bar
    on the right), where the prediction was almost exactly like the true outcome,
    the scheduled departure time had a high influence factor. The model did not consider
    any other factors here as important in potentially causing a delay.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图展示了导致所选数据点个体预测结果的原因。例如，我们可以看到第1523行（中间的柱状图）预测值过低时，特征CRSElapsedTime实际上被模型所削弱。由于某种原因，模型决定在这种特殊情况下不应过多考虑原计划时间。事实证明，在这种情况下，这是一个错误的决定。相比之下，对于第662行（右侧的柱状图），预测值几乎与实际结果相同，预定起飞时间具有很高的影响因素。在这里，模型并未认为其他任何因素对可能导致延误有重要影响。
- en: Looking at single predictions and understanding which factors have an influence
    on them will help you feel more comfortable in applying as well as explaining
    your ML model, instead of just accepting it as a “closed box.” This process is
    also a good tool for debugging. In this example, we can see that the model is
    working pretty much as expected.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 分析单个预测并理解哪些因素对它们有影响，将帮助您更加自信地应用和解释您的机器学习模型，而不仅仅把它当作一个“黑盒子”接受。这个过程也是调试的一个好工具。在这个例子中，我们可以看到模型基本按照预期工作。
- en: Let’s go deploy this model to production so we can get some inference from it.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们部署这个模型到生产环境，这样我们就可以从中得到一些推断结果。
- en: Model Deployment with Microsoft Azure Walk-Through
  id: totrans-385
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Microsoft Azure 进行模型部署步骤
- en: The deployment steps will be identical to the previous use case, so I will keep
    it short here. Select the model you want to deploy and click “Deploy → Deploy
    to web service” from the menu bar as shown in [Figure 7-57](#deploying_the_model_from_azure_ml_studi).
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 部署步骤与前一个用例相同，所以我在这里会简要说明一下。选择要部署的模型，然后从菜单栏中点击“部署 → 部署到 Web 服务”，如图[7-57](#deploying_the_model_from_azure_ml_studi)所示。
- en: '![Deploying the model from Azure ML Studio](Images/apbi_0757.png)'
  id: totrans-387
  prefs: []
  type: TYPE_IMG
  zh: '![从 Azure ML Studio 部署模型](Images/apbi_0757.png)'
- en: Figure 7-57\. Deploying the model from Azure ML Studio
  id: totrans-388
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-57\. 从 Azure ML Studio 部署模型
- en: In this pane that pops up, give your model a name, such as `**elapsedtime-votingensemble**`.
    Choose Azure Container Instance as the Compute Type. Click Deploy.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 在弹出的窗格中，给您的模型取一个名字，比如 `**elapsedtime-votingensemble**`。选择 Azure 容器实例作为计算类型。点击部署。
- en: The deployment is complete when your model is listed under Endpoints and has
    the status Healthy ([Figure 7-58](#deployed_model_details)). Select the model
    to see the REST endpoint URL, which you will need in the further steps.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的模型在端点下列出并且状态为健康时（[图 7-58](#deployed_model_details)），部署完成。选择模型以查看 REST 端点
    URL，在接下来的步骤中您将需要这个 URL。
- en: '![Deployed model details](Images/apbi_0758.png)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
  zh: '![部署模型详细信息](Images/apbi_0758.png)'
- en: Figure 7-58\. Deployed model details
  id: totrans-392
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-58\. 部署模型详细信息
- en: Feel free to test your model online by choosing Test from the navigation menu.
    You can explore how to make requests against your model programmatically by using
    the Consume tab. Let’s go ahead and get some predictions from our online endpoint.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 随时通过选择导航菜单中的测试来在线测试您的模型。您可以使用消耗选项卡编程地探索如何对您的模型发出请求。让我们继续从我们的在线端点获取一些预测。
- en: Getting Model Predictions with Python or R
  id: totrans-394
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 或 R 获取模型预测
- en: To send data to our hosted model endpoint and get predictions back, we’ll use
    the same approach as in the previous use case (“Automating Classification Tasks”).
    This means that you can find two script files named *azure-ml-inference-elapsedtime.R*
    and *azure-ml-inference-elapsedtime.py* on the [book’s website](https://oreil.ly/X9jmJ).
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 要将数据发送到我们托管的模型端点并获取预测结果，我们将使用与前一个用例（“自动化分类任务”）相同的方法。这意味着您可以在 [书籍网站](https://oreil.ly/X9jmJ)
    上找到名为 *azure-ml-inference-elapsedtime.R* 和 *azure-ml-inference-elapsedtime.py*
    的两个脚本文件。
- en: You can continue in your preferred programming language. I will walk you through
    the example using R code, but all sections, variable names, and the overall code
    logic will be the same in the Python file. The script contains six sections that
    serve different purposes.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以继续使用您偏好的编程语言。我将通过 R 代码示例引导您，但所有部分、变量名和整体代码逻辑在 Python 文件中都是相同的。该脚本包含六个服务不同目的的部分。
- en: 'Section 0 again contains the setup, where you can review the required packages
    and update your API parameters. Make sure you replace the `API_URL` with your
    custom endpoint from the previous deployment:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: Section 0 再次包含设置部分，您可以查看所需的软件包并更新您的 API 参数。确保用您之前部署的自定义端点 `API_URL` 替换：
- en: '[PRE6]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Section 1 again contains the API request function. The main difference compared
    to the previous example is that we are now passing different columns to the function,
    because this endpoint expects different data. Also, `GlobalParameters` must be
    set to `0.0` as specified by the Azure endpoint example. Otherwise, the function
    works just the same:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: Section 1 再次包含 API 请求函数。与前面的示例相比，主要区别在于我们现在向函数传递了不同的列，因为此端点期望不同的数据。此外，`GlobalParameters`
    必须设置为 Azure 端点示例指定的 `0.0`。否则，函数的工作方式完全相同：
- en: '[PRE7]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Section 2 contains the preprocessing steps with a new detail. While in the previous
    use case we were looking at only a one-hour batch of data (about 100 rows), in
    this case we are dealing with an entire month of data—more than 32,000 rows in
    total for February 2021! While this would likely work given the size of the query,
    we are pushing the limits of online inference here; the processing time for this
    request would be nearly a minute.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: Section 2 包含预处理步骤的新细节。在以前的用例中，我们只查看了一个小时批处理数据（大约 100 行），而在这种情况下，我们处理了整个月的数据——2021
    年 2 月共超过 32,000 行！尽管这可能会因为查询大小而有效，但我们在此处推动了在线推断的极限；此请求的处理时间将接近一分钟。
- en: 'Also, this data contains a lot of redundant information for the inference API.
    Keep in mind that we trained on weekdays. Some flights in the schedule occur daily,
    which means that each day of the week is in the dataset four or more times. It
    would be inefficient not only computationally but also financially to send a data
    point with the same information to the API multiple times. Therefore, the code
    includes a `distinct` statement that deletes redundant rows based on the columns
    we use for AI predictions:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，此数据包含推理 API 的大量冗余信息。请记住，我们在工作日进行了训练。时间表中的某些航班每天都发生，这意味着每周的每一天在数据集中重复了四次或更多次。因此，代码包括一个
    `distinct` 语句，根据我们用于 AI 预测的列删除冗余行：
- en: '[PRE8]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `distinct` operation will shrink our dataframe from 32,048 rows to only
    13,826 rows that contain unique information for inference. That is a reduction
    of our data workload by more than 50%!
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '`distinct` 操作将我们的数据框架从 32,048 行缩减到仅包含 13,826 行，这些行包含推断所需的唯一信息。这将我们的数据工作量减少了超过
    50%！'
- en: 'Section 3 finally makes the actual call to the API by using the reduced dataset:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 第 3 节最终通过使用缩减的数据集来实际调用 API：
- en: '[PRE9]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Eventually, however, we want to report on all flights, not only the distinct
    combination that we sent to our model. We are solving that in section 4:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，最终，我们希望报告所有航班，而不仅仅是发送到我们的模型的不同组合。我们在第 4 节中解决了这个问题：
- en: '[PRE10]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In section 4, we will join the prediction results back to the original dataframe
    so that we get a prediction for each row in the original dataset. As a result,
    the dataframe `df` contains all of the 32,048 original observations with their
    respective prediction results, but we send only 13,826 rows from that to our model.
    Isn’t that beautiful?
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 4 节中，我们将预测结果与原始数据框架进行连接，以便为原始数据集中的每一行获取一个预测结果。因此，数据框架 `df` 包含所有 32,048 个原始观察结果及其相应的预测结果，但我们只发送其中的
    13,826 行给我们的模型。这不是很美吗？
- en: 'Section 5 cleans up the environment and provides the output for further downstream
    processing in Power BI (or any other BI tool):'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 第 5 节清理环境并提供输出，以供在 Power BI（或任何其他 BI 工具）中进行进一步的下游处理：
- en: '[PRE11]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now it’s time to put our script to work and see our model in action within our
    BI tool!
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候让我们的脚本开始工作，并在我们的 BI 工具中看到我们的模型在操作中的表现！
- en: Model Inference with Power BI Walk-Through
  id: totrans-413
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Power BI 演示模型推断步骤
- en: Open *Elapsed_Time.pbix* in Power BI Desktop. Select the Model icon on the left
    navigation pane to open the Modeling view. You will see two data sources here
    ([Figure 7-59](#data_model_in_power_bi-id000001)).
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Power BI Desktop 中打开 *Elapsed_Time.pbix*。选择左侧导航窗格中的模型图标以打开建模视图。您将在这里看到两个数据源（[图
    7-59](#data_model_in_power_bi-id000001)）。
- en: '![Data model in Power BI](Images/apbi_0759.png)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![Power BI 中的数据模型](Images/apbi_0759.png)'
- en: Figure 7-59\. Data model in Power BI
  id: totrans-416
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-59\. Power BI 中的数据模型
- en: The data source *AA_Flights_2021_1* contains all the historical flights from
    January 2021\. This is the data we used to train our model on. We don’t need to
    modify this data. The second source, *AA_Flight_Schedule_2021_2*, contains the
    flight schedule data we are interested in. For this data model, we want to run
    predictions for the Elapsed Time attribute.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 数据源 *AA_Flights_2021_1* 包含了 2021 年 1 月的所有历史航班。这是我们用来训练模型的数据。我们不需要修改这些数据。第二个数据源
    *AA_Flight_Schedule_2021_2* 包含了我们感兴趣的航班时间表数据。对于这个数据模型，我们希望对 Elapsed Time 属性运行预测。
- en: We will do this by applying the R or Python script we have written before to
    create a new column in the model. Open the Power Query Editor and make sure you
    choose the AA_Flight_Schedule_2021_2 table on the left, as shown in [Figure 7-60](#power_query_edit).
    In the menu pane, select the Transform tab and then choose “Run Python script”
    or “Run R script,” depending on your preference.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过应用之前编写的 R 或 Python 脚本，在模型中创建一个新列来实现这一点。打开 Power Query 编辑器，并确保您在左侧选择了 AA_Flight_Schedule_2021_2
    表，如 [图 7-60](#power_query_edit) 所示。在菜单窗格中，选择“转换”选项卡，然后选择“运行 Python 脚本”或“运行 R 脚本”，具体取决于您的偏好。
- en: '![](Images/apbi_0760.png)'
  id: totrans-419
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/apbi_0760.png)'
- en: Figure 7-60\. Power Query Editor
  id: totrans-420
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-60\. Power Query 编辑器
- en: Copy and paste the contents from the file of the R or Python script and paste
    it into the code window in Power BI. Double-check that the URL provided in the
    script is the one of your healthy REST endpoints. Also make sure that you have
    all the required packages (*httr*, *rjson*, and *dplyr* for R, or *requests*,
    *json*, and *pandas* for Python) installed in the code environment used by Power
    BI, as explained in [Chapter 4](ch04.xhtml#prototyping).
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 复制并粘贴来自 R 或 Python 脚本文件的内容，并将其粘贴到 Power BI 中的代码窗口中。双检查脚本中提供的 URL 是否为您健康的 REST
    终端之一。还要确保您在 Power BI 使用的代码环境中安装了所有所需的包（*httr*、*rjson* 和 *dplyr* 适用于 R，或 *requests*、*json*
    和 *pandas* 适用于 Python），如 [第 4 章](ch04.xhtml#prototyping) 所述。
- en: Click OK, and Power BI will run your script. Select “Ignore Privacy Levels checks
    for this file” if Power BI gives you a warning message. Depending on your machine,
    the inference process might take some time. Remember that we are doing calculations
    here for more than 32,000 rows of data. And while we reduced the data amount sent
    to the API, that’s still over 13,000 rows. If you want to see what your computer
    is doing, feel free to open the Windows Task Manager, click the Performance tab,
    and see your computer at work.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“确定”，Power BI 将运行您的脚本。如果 Power BI 给出警告消息，请选择“忽略此文件的隐私级别检查”。根据您的计算机性能，推理过程可能需要一些时间。请记住，我们在这里为超过
    32,000 行数据进行计算。虽然我们减少了发送到 API 的数据量，但仍然超过 13,000 行。如果您想查看计算机在做什么，请打开 Windows 任务管理器，点击“性能”选项卡，看看您的计算机在工作。
- en: After the process has been completed, you should see a prompt for showing you
    the two result tables from the script, called “df” and “output.” Select the “output”
    table and you should see that one step was added on the right under Applied Steps
    and that your dataset now contains an additional column called ELAPSED_TIME_PREDICTED,
    as shown in [Figure 7-61](#elapsed_time_predicted_column_in_power).
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 过程完成后，您应该看到一个提示，显示脚本生成的两个结果表“df”和“output”。选择“output”表，您将看到右侧的“已应用步骤”下新增了一个步骤，并且您的数据集现在包含一个名为
    ELAPSED_TIME_PREDICTED 的额外列，如 [图 7-61](#elapsed_time_predicted_column_in_power)
    所示。
- en: '![ELAPSED_TIME_PREDICTED column in Power BI](Images/apbi_0761.png)'
  id: totrans-424
  prefs: []
  type: TYPE_IMG
  zh: '![Power BI 中的 ELAPSED_TIME_PREDICTED 列](Images/apbi_0761.png)'
- en: Figure 7-61\. ELAPSED_TIME_PREDICTED column in Power BI
  id: totrans-425
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-61\. Power BI 中的 ELAPSED_TIME_PREDICTED 列
- en: Before we close the Power Query Editor, let’s quickly create a new column that
    creates the difference between the AI predictions and the CRS scheduled time,
    so we can later filter for flights that are likely to be delayed.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 在关闭 Power Query 编辑器之前，让我们快速创建一个新列，计算 AI 预测与 CRS 计划时间之间的差异，以便稍后过滤可能延误的航班。
- en: To insert a new column in Power Query, choose Add Column → Custom Column and
    enter the custom column formula shown in [Figure 7-62](#adding_a_new_custom_column_in_power_que).
    Confirm with OK.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Power Query 中插入新列，请选择“添加列” → “自定义列”，并输入如 [图 7-62](#adding_a_new_custom_column_in_power_que)
    所示的自定义列公式。点击“确定”确认。
- en: '![Adding a new custom column in Power Query](Images/apbi_0762.png)'
  id: totrans-428
  prefs: []
  type: TYPE_IMG
  zh: '![在 Power Query 中添加新的自定义列](Images/apbi_0762.png)'
- en: Figure 7-62\. Adding a new custom column in Power Query
  id: totrans-429
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-62\. 在 Power Query 中添加新的自定义列
- en: To double-check that this new column is formatted correctly as a numeric value,
    right-click the column PREDICTED_DIFF_AI and choose Change Type → Decimal. Now
    choose File → Close & Apply to exit the Power Query Editor and apply your transformations.
    Power BI will update the data model accordingly, which again can take a couple
    of minutes. The waiting time in this case should not bother us too much, since
    this process will be done only once for each monthly flight schedule.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 要确认这个新列被正确格式化为数值型值，请右键单击列 PREDICTED_DIFF_AI 并选择“更改类型” → “十进制数”。现在选择“文件” → “关闭并应用”以退出
    Power Query 编辑器并应用您的转换。Power BI 将相应地更新数据模型，这可能需要几分钟的时间。在这种情况下的等待时间不应该让我们感到困扰，因为这个过程每月的航班时间表只需执行一次。
- en: Building the AI-Powered Dashboard in Power BI
  id: totrans-431
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Power BI 中构建 AI 驱动的仪表板
- en: After the data model has been successfully updated, head over to Reports in
    Power BI. We want to put our new predictions to work. Select the report Future
    Schedule, where you can see the baseline regression predictions. Time to tune
    them up.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 数据模型成功更新后，转到 Power BI 的报告页面。我们想要把新的预测应用起来。选择“未来时间表”报告，您可以查看基线回归预测。现在是时候调整它们了。
- en: Select the scatterplot on the left. Replace the value for the y-axis. Instead
    of ELAPSED_REGRESSION, put the new measure ELAPSED_TIME_PREDICTED here. Update
    the other two visuals on the page accordingly. In addition, replace the filter
    on the KPI visual at the top right by deleting PREDICTED_DIFF and adding “PREDICTED_DIFF_AI
    is greater than 5” to consider your AI predictions instead. [Figure 7-63](#updated_dashboard_with_ai_powered_predi)
    shows the updated dashboard.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 选择左侧的散点图。替换 y 轴的值。将 ELAPSED_REGRESSION 替换为新的度量 ELAPSED_TIME_PREDICTED。相应地更新页面上的另外两个可视化图表。此外，通过删除
    PREDICTED_DIFF 并添加“PREDICTED_DIFF_AI 大于 5”来替换右上角 KPI 可视化图表上的过滤器，以考虑您的 AI 预测。[图 7-63](#updated_dashboard_with_ai_powered_predi)
    显示了更新后的仪表板。
- en: '![Updated dashboard with AI-powered predictions](Images/apbi_0763.png)'
  id: totrans-434
  prefs: []
  type: TYPE_IMG
  zh: '![带有 AI 预测的更新仪表板](Images/apbi_0763.png)'
- en: Figure 7-63\. Updated dashboard with AI-powered predictions
  id: totrans-435
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-63\. 带有 AI 预测的更新仪表板
- en: What have we achieved so far?
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们取得了什么成就？
- en: First, by applying our AI model, we have reduced the number of flights that
    are predicted to need at least five minutes longer than scheduled, from 114 to
    34 observations.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过应用我们的 AI 模型，我们已将预测需要比计划时间长至少五分钟的航班数量从 114 减少到 34 个观察结果。
- en: Second, if we look at the scatterplot on the left, we can see more variation;
    the points do not form a single straight line as in the simple regression model.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，如果我们看左侧的散点图，我们可以看到更多的变化；点不像简单回归模型中形成单一直线。
- en: And third, if we look at the bar chart on the right, we can see that we have
    identified two flights that are predicted to take 15 minutes longer than planned.
    If we compare that to the previous regression model, where the highest difference
    was only about 6.5 minutes, this is a significantly bigger amount.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，如果我们看右侧的条形图，我们可以看到我们已经确定了两次预测的航班，比计划的时间长了 15 分钟。如果我们将其与之前的回归模型进行比较，那里最大的差异只有大约
    6.5 分钟，这是一个显著更大的数值。
- en: Let’s see if we can tweak this report even a little bit more to make it more
    interactive and actionable. Right-click on the Future Schedule tab and click Duplicate
    Page to create a copy of the current report. Rename the copy from Duplicate of
    Future Schedule to `**Interactive Schedule**`.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看是否可以稍微调整这份报告，使其更具互动性和可操作性。右键单击“未来时间表”选项卡，然后单击“复制页面”以创建当前报告的副本。将副本从“未来时间表的副本”重命名为`**互动时间表**`。
- en: In the Interactive Schedule report, select the bar chart on the right and add
    the field DistanceGroup to the legend, as shown in [Figure 7-64](#highlighted_distance_groups_in_the_bar).
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 在“互动时间表”报告中，选择右侧的条形图，并将 DistanceGroup 字段添加到图例中，如 [图 7-64](#highlighted_distance_groups_in_the_bar)
    所示。
- en: '![Highlighted distance groups in the bar chart](Images/apbi_0764.png)'
  id: totrans-442
  prefs: []
  type: TYPE_IMG
  zh: '![条形图中突出显示的距离组](Images/apbi_0764.png)'
- en: Figure 7-64\. Highlighted distance groups in the bar chart
  id: totrans-443
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-64\. 条形图中突出显示的距离组
- en: From this additional information, we can see that the flights that have the
    highest discrepancy between predicted and scheduled elapsed time are long-distance
    flights (distance group 11). The majority of flights on the chart, however, are
    short-distance flights.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些额外信息中，我们可以看到预测与计划飞行时间之间差异最大的航班是长途航班（距离组 11）。然而，图表上大多数航班是短途航班。
- en: 'Also, let’s get rid of the scatterplot. It has provided a good overview of
    how the model is working, but it is not so interactive. Select the scatterplot
    and replace it with a treemap visual. Adjust the settings for the treemap as follows
    (see [Figure 7-65](#treemap_visual_and_settings)):'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，让我们去掉散点图。它提供了模型运行情况的良好概述，但不太互动。选择散点图，并用树状图视觉替换它。按照以下设置调整树状图（见 [图 7-65](#treemap_visual_and_settings)）：
- en: Add the fields Origin and Dest to Group.
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Origin 和 Dest 字段添加到 Group 中。
- en: Put the field PREDICTED_DIFF_AI into Values.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将字段 PREDICTED_DIFF_AI 放入 Values 中。
- en: Aggregate PREDICTED_DIFF_AI by Average.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过平均值聚合 PREDICTED_DIFF_AI。
- en: Filter this visual to “PREDICTED_DIFF_AI is greater than 0.”
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将这个可视化过滤到“PREDICTED_DIFF_AI 大于 0”。
- en: Delete any field from Details.
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从详细信息中删除任何字段。
- en: '![Treemap visual and settings](Images/apbi_0765.png)'
  id: totrans-451
  prefs: []
  type: TYPE_IMG
  zh: '![树状图视觉和设置](Images/apbi_0765.png)'
- en: Figure 7-65\. Treemap visual and settings
  id: totrans-452
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-65\. 树状图视觉和设置
- en: As a result, you should see an updated visual, as shown in [Figure 7-66](#treemap_visual_with_drill_down_function).
    Enable the drill-down function at the top.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，您应该看到一个更新的可视化，如 [图 7-66](#treemap_visual_with_drill_down_function) 所示。在顶部启用钻取功能。
- en: '![Treemap visual with drill-down function](Images/apbi_0766.png)'
  id: totrans-454
  prefs: []
  type: TYPE_IMG
  zh: '![带有钻取功能的树状图](Images/apbi_0766.png)'
- en: Figure 7-66\. Treemap visual with drill-down function
  id: totrans-455
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-66\. 带有钻取功能的树状图
- en: The treemap shows origin airports for which the field size is the average of
    the difference between the predicted and scheduled elapsed time for flights from
    this airport. Every time we interact with this tree, the bar chart on the right
    will change and we can drill down. For example, click the origin airport Honolulu.
    You will see that the treemap updates, and the bar chart as well, as shown in
    [Figure 7-67](#drilling_down_for_honolulu_left_parenth).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 树状图显示了起始机场的情况，其字段大小为该机场航班预测与计划飞行时间之间差异的平均值。每次与这棵树互动时，右侧的条形图都会改变，我们可以进行钻取。例如，单击起始机场檀香山。您会看到树状图和条形图如
    [图 7-67](#drilling_down_for_honolulu_left_parenth) 所示更新。
- en: '![Drilling down for Honolulu (Flight AA693 selected)](Images/apbi_0767.png)'
  id: totrans-457
  prefs: []
  type: TYPE_IMG
  zh: '![钻取至檀香山 (航班 AA693 已选择)](Images/apbi_0767.png)'
- en: Figure 7-67\. Drilling down for Honolulu (Flight AA693 selected)
  id: totrans-458
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-67\. 钻取至檀香山 (航班 AA693 已选择)
- en: From this drill-down, we can see that there are four flight numbers, two of
    which have more than five minutes’ predicted delay.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这次深入分析，我们可以看到有四个航班号，其中两个预测延误超过五分钟。
- en: This provides us with a great interactive resource to locate the bottlenecks
    in our flight planning. We can clearly see that flights scheduled to depart from
    Honolulu are on a tough schedule and that the connection from Honolulu to Phoenix,
    Arizona has the highest chance of exceeding the scheduled time, at least according
    to the best knowledge we have so far.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了一个很好的互动资源，用来定位我们飞行计划中的瓶颈。我们可以清楚地看到，计划从檀香山出发的航班时间安排紧张，并且檀香山到亚利桑那州凤凰城的连接有最高的超时可能性，至少根据我们目前的最佳知识。
- en: Similarly, we can search vice versa and select a bar from the bar chart to show
    us which airports are associated with the probably delayed flight numbers, as
    shown in [Figure 7-68](#drilling_down_by_flight_number_left_par).
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们可以反向搜索并从条形图中选择一根条形来显示与可能延误的航班号相关的机场，如图7-68所示。
- en: '![Drilling down by flight number (Flight AA301 selected)](Images/apbi_0768.png)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
  zh: '![按航班号（选择航班AA301）深入挖掘](Images/apbi_0768.png)'
- en: Figure 7-68\. Drilling down by flight number (Flight AA301 selected)
  id: totrans-463
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-68。按航班号（选择航班AA301）深入挖掘
- en: While the model is not perfect, we have improved our baseline, and who knows—maybe
    we can think of even more criteria that can make the model more accurate. At least
    now we have a good showcase to demonstrate how a better AI model could be beneficial
    for improving our schedule ahead of time.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然模型并不完美，但我们已经改进了我们的基线，也许我们可以考虑更多的标准，使模型更加准确。至少现在我们有一个很好的案例展示，展示如何通过改进我们的时间表提前获益于更好的AI模型。
- en: You can download the final Power BI file (*Elapsed_Time_AI-Powered.pbix*) from
    the [book’s website](https://oreil.ly/X9jmJ).
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[书籍网站](https://oreil.ly/X9jmJ)下载最终的Power BI文件（*Elapsed_Time_AI-Powered.pbix*）。
- en: 'Use Case: Automating Anomaly Detection'
  id: totrans-466
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例：自动化异常检测
- en: In the previous use cases, you learned how to leverage AI to predict categorical
    and numeric variables and how to use that skill to create business value. In the
    following use case, we are not so interested in whether a value is categorical
    or numeric, but we want to know if a certain value is abnormal. To identify whether
    a value is an anomaly, the algorithm will consider the points to be a series of
    events in time, also known as a *time series*. Let’s head over to the problem
    statement of our use case.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的用例中，您学习了如何利用AI来预测分类和数值变量，并如何利用这一技能创造业务价值。在接下来的用例中，我们对于一个值是分类还是数值并不是那么感兴趣，但我们想知道某个值是否异常。为了确定一个值是否异常，算法将考虑这些点作为时间上的一系列事件，也称为*时间序列*。让我们进入我们用例的问题陈述。
- en: Problem Statement
  id: totrans-468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题陈述
- en: We are analysts working with the operations team of American Airlines, and our
    job is to maintain a service level. This includes observing what is happening
    at the airports where American Airlines takes off, especially the ones used most
    frequently. The most important airports that counted more than 1,000 flight departures
    in January 2021 were Dallas Fort Worth (DFW), Charlotte Douglas Airport (CLT),
    Phoenix Sky Harbor (PHX), Miami International Airport (MIA), Chicago O’Hare (ORD),
    Philadelphia International (PHL), and Los Angeles International Airport (LAX).
    Among other metrics, we have to closely monitor the taxi-out time that is occurring
    at these airports.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是美国航空公司运营团队的分析师，我们的工作是保持服务水平。这包括观察美国航空公司起飞的机场的情况，特别是那些最常用的机场。2021年1月，起飞超过1000次的最重要机场包括达拉斯沃思堡国际机场（DFW）、夏洛特道格拉斯国际机场（CLT）、凤凰城天港国际机场（PHX）、迈阿密国际机场（MIA）、芝加哥奥黑尔国际机场（ORD）、费城国际机场（PHL）和洛杉矶国际机场（LAX）。除其他指标外，我们还必须密切监控这些机场发生的滑行离开时间。
- en: '*Taxi-out time* is defined as the time between the plane leaving the gates
    and actually taking off. A high taxi-out time is a proxy for busy or overcrowded
    airports and can lead to unexpected flight delays (as you have seen in the previous
    use case).'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '*滑行离开时间*被定义为飞机离开登机门到实际起飞之间的时间。高滑行离开时间是繁忙或过度拥挤的机场的代表，并可能导致意外的航班延误（正如您在前面的用例中看到的）。'
- en: While a natural fluctuation of the taxi-out time is normal and considered by
    the flight schedule, too many peaks in long taxi-out times can lead to recurring
    delays. A stable taxi-out time is an important precondition for guaranteeing a
    smooth departure process at an airport. Also, long taxi-out times increase congestion
    and excessive emission of greenhouse gases.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然出租车滑出时间的自然波动是正常的，并由航班时间表考虑，但是长时间的出租车滑出峰值会导致延误的频繁发生。稳定的出租车滑出时间是保证机场顺利出发流程的重要前提条件。此外，长时间的出租车滑出时间增加了拥堵和过多的温室气体排放。
- en: Monitoring the taxi-out status and flagging unwanted spikes to airport operators
    are effective approaches to eliminating delays and improving the utilization of
    resources. The way this process is currently handled is through a BI dashboard,
    which shows an overview of the daily average taxi-out time for the high-traffic
    airports previously mentioned. The dashboard is shown in [Figure 7-69](#taxi_out_baseline_dashboard).
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 监控出租车滑出状态并标记给机场操作者不希望的峰值是消除延误和提高资源利用率的有效方法。目前处理此过程的方式是通过BI仪表板，显示先前提到的高流量机场每日平均出租车滑出时间的概述。该仪表板显示在[图7-69](#taxi_out_baseline_dashboard)中。
- en: Our primary goal, as analysts looking at this dashboard, is to identify those
    peaks that are abnormal for an airport in order to raise these issues for further
    investigation to the operations team. The main problem is, what is an abnormal
    point?
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 我们作为分析师查看此仪表板的主要目标是识别对机场来说异常的高峰，以便将这些问题提升给运营团队进行进一步调查。主要问题是，什么是异常点？
- en: The line chart in the graphs shows the average daily taxi-out time for the month
    of January for the seven airports mentioned. The dashed horizontal line displays
    the average taxi-out time for each of these airports in January. As we can see
    from the dashboard, the value of these averages varies depending on the airport.
    The average taxi-out range is between 15.3 minutes for LAX and almost 20 minutes
    for DFW. That is why it is hard to judge abnormal taxi-out time generally, but
    instead they must be considered by the airport.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 折线图显示了一月份七个机场的平均每日出租车滑出时间。这些机场的一月平均出租车滑出时间用虚线水平线显示。从仪表板可以看出，这些平均值因机场而异。LAX的平均出租车滑出时间为15.3分钟，DFW几乎为20分钟。因此，通常很难判断出租车滑出时间是否异常，而是必须根据各机场情况进行考虑。
- en: '![Taxi-out baseline dashboard](Images/apbi_0769.png)'
  id: totrans-475
  prefs: []
  type: TYPE_IMG
  zh: '![出租车滑出基线仪表板](Images/apbi_0769.png)'
- en: Figure 7-69\. Taxi-out baseline dashboard
  id: totrans-476
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-69。出租车滑出基线仪表板
- en: Flagging all above-average taxi-out times, however, is not practical because
    the time has too many fluctuations. Instead, the team has decided to set a 90-percentile
    threshold for each airport, which is indicated by the solid horizontal line in
    the graphs. This threshold covers 90% of all taxi-out averages for a specific
    airport. All daily taxi-out averages that exceed this threshold will be flagged
    and considered anomalies. For example, the average taxi-out values for DFW on
    January 4 and January 10 have been flagged.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，标记所有高于平均值的出租车滑出时间并不实际，因为时间波动太大。相反，团队决定为每个机场设定90百分位数阈值，该阈值在图表中由实线水平线表示。该阈值涵盖了特定机场所有出租车滑出时间平均数的90%。超过此阈值的所有每日出租车滑出平均值将被标记为异常。例如，DFW在1月4日和1月10日的平均出租车滑出时间已被标记。
- en: 'However, this approach does have limits:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法确实存在一些限制：
- en: The 90-percentile mark is static and does not consider any trends that are happening
    in the data.
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 90百分位数标记是静态的，不考虑数据中正在发生的任何趋势。
- en: It is sensitive to extreme values, meaning one day of high average taxi-out
    values can raise the bar to unnecessary heights.
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它对极端值非常敏感，这意味着一天的高平均出租车滑出值可以将标准提高到不必要的高度。
- en: It is tedious and time-consuming to look at these charts manually and flag problematic
    events on a case-by-case basis.
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动查看这些图表并逐案标记问题事件是单调乏味且耗时的。
- en: The team is looking for an overall improved approach of identifying peak values
    for taxi-out times for these airports.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 团队正在寻求一种更全面的方法来识别这些机场出租车滑出时间的高峰值。
- en: Solution Overview
  id: totrans-483
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案概述
- en: Our goal is to make the prediction of abnormal data points more dynamic and
    more responsive to the overall development of the timeline. [Figure 7-70](#anomaly_detection_use_case_architecture)
    shows the overall architecture for this use case from a high level.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是使异常数据点的预测更加动态，更能响应时间轴的整体发展。[图7-70](#anomaly_detection_use_case_architecture)展示了此用例的整体架构高层次概述。
- en: '![Anomaly detection use case architecture](Images/apbi_0770.png)'
  id: totrans-485
  prefs: []
  type: TYPE_IMG
  zh: '![异常检测用例架构](Images/apbi_0770.png)'
- en: Figure 7-70\. Anomaly detection use case architecture
  id: totrans-486
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-70\. 异常检测用例架构
- en: This time, we are not going to train our own AI model. Instead, we will use
    an off-the-shelf AI service for the first time in this book. This means we will
    consume an AI model that has been pretrained before on the task that we want to
    achieve. That’s why we don’t need any training process here, but we can directly
    skip to inference.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，我们不打算训练自己的AI模型。相反，我们将在本书中首次使用现成的AI服务。这意味着我们将使用一个在我们想要达到的任务上预先训练过的AI模型。这就是为什么我们在这里不需要任何训练过程，而可以直接跳到推理过程。
- en: The approach we take for this is an AI-powered anomaly detection that analyzes
    a series of events (value) over a certain period of time (timestamp). The anomaly
    detection will calculate dynamic upper and lower margins for the expected value
    and flag all values that exceed these boundaries as positive (above upper boundary)
    or negative (below lower boundary) anomalies.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里采取的方法是通过AI驱动的异常检测，分析一段时间内一系列事件（值）的情况（时间戳）。异常检测将计算预期值的动态上限和下限，并标记所有超出这些边界的值为正（超过上限边界）或负（低于下限边界）的异常。
- en: In this example, we are using the Anomaly Detector by Azure Cognitive Services.
    To do this, we will enable the endpoint through our Azure portal, learn how to
    prepare our data, get predictions from this endpoint by using Python or R, and
    finally apply these predictions in Power BI to build an enhanced version of the
    taxi-out anomaly detection report.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用Azure认知服务的异常检测器。为此，我们将通过Azure门户启用端点，学习如何准备我们的数据，使用Python或R从这个端点获取预测，并最终在Power
    BI中应用这些预测，以构建增强版的出租车出站异常检测报告。
- en: Note that the anomaly detection service can be used for both batch and real-time
    prediction. *Real-time prediction* in this case means that we send any points
    we observe directly to the API and will get the prediction back of whether this
    point is an anomaly based on the points we sent previously. For our use case,
    however, we are taking the *batch* approach, meaning we upload all available data
    at once to the API.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，异常检测服务可以用于批处理和实时预测。在本例中，*实时预测* 意味着我们直接将我们观察到的任何点发送到API，并将根据我们先前发送的点来获取此点是否为异常的预测。然而，对于我们的用例，我们采取的是*批处理*方法，这意味着我们一次性上传所有可用数据到API。
- en: Without further ado, let’s head over to the Azure portal.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不拖延，让我们转向Azure门户。
- en: Note
  id: totrans-492
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Anomaly detection can be considered a tool for both predictive and diagnostic
    analytics, depending on how and for what purpose it is used. If the focus is more
    on analyzing historical data, anomaly detection can be considered a tool for diagnostic
    analytics. However, as soon as we analyze new data points in real time, it has
    more of the characteristics of a tool for predictive analysis.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测可以被认为是预测性和诊断性分析的工具，这取决于它如何以及用于何种目的。如果重点更多地放在分析历史数据上，异常检测可以被视为诊断性分析的工具。然而，一旦我们实时分析新数据点时，它就具有更多预测分析工具的特征。
- en: Enabling AI Service on Microsoft Azure Walk-Through
  id: totrans-494
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Microsoft Azure上启用AI服务演示
- en: 'Our first task is to enable the Cognitive Services Anomaly Detector API in
    Azure by creating a resource for it. To do that, you can either visit the [Create
    Anomaly Detector](https://oreil.ly/D38ul) page or navigate there manually: visit
    *[portal.azure.com](http://portal.azure.com)*, search for `**Cognitive Services**`,
    and in the Decision section you will find the card “Anomaly detector,” where you
    can click Create ([Figure 7-71](#cognitive_services_overview)).'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个任务是通过创建资源来在Azure中启用认知服务的异常检测器API。要做到这一点，您可以访问[创建异常检测器](https://oreil.ly/D38ul)页面或手动导航至：访问*[portal.azure.com](http://portal.azure.com)*，搜索`**认知服务**`，在决策部分您将找到“异常检测器”卡片，您可以单击“创建”（[图7-71](#cognitive_services_overview)）。
- en: '![Cognitive Services overview](Images/apbi_0771.png)'
  id: totrans-496
  prefs: []
  type: TYPE_IMG
  zh: '![认知服务概述](Images/apbi_0771.png)'
- en: Figure 7-71\. Cognitive Services overview
  id: totrans-497
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-71\. 认知服务概述
- en: The Create Anomaly Detector form requires you to specify more details. Choose
    your Azure subscription and select the same resource group you have created for
    the previous use cases. In addition, you need to specify the geographic region
    where the service should be running. Choose your preferred region and give your
    service a descriptive name. Note that this name is globally unique; think of it
    as a subdomain for the final endpoint.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 创建异常检测器表单需要您填写更多细节。选择您的 Azure 订阅，并选择您之前为先前用例创建的同一资源组。此外，您需要指定服务应运行的地理区域。选择您偏好的区域，并为您的服务取一个描述性名称。请注意，此名称在全球范围内必须唯一；将其视为最终端点的子域。
- en: Finally, you will need to choose the pricing tier. Different pricing tiers affect
    the performance and pricing model of the AI service. For our purposes, the Free
    tier should be enough; it allows 10 calls per second and 20,000 transactions per
    month. See [Figure 7-72](#creating_the_anomaly_detector_in_azure) for an example
    of the filled-out form. Proceed by selecting “Review + create.” Review your settings
    on the subsequent page and confirm by clicking Create.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您需要选择定价层。不同的定价层会影响 AI 服务的性能和定价模型。对于我们的目的，免费层应该足够了；它允许每秒 10 次调用和每月 20,000
    次交易。参见 [图 7-72](#creating_the_anomaly_detector_in_azure) 以查看填写表单的示例。选择“Review
    + create”继续。在随后的页面上检查您的设置，并通过单击“Create”确认。
- en: '![Creating the anomaly detector in Azure](Images/apbi_0772.png)'
  id: totrans-500
  prefs: []
  type: TYPE_IMG
  zh: '![在 Azure 中创建异常检测器](Images/apbi_0772.png)'
- en: Figure 7-72\. Creating the anomaly detector in Azure
  id: totrans-501
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-72\. 在 Azure 中创建异常检测器
- en: The deployment of the service might take a few minutes. After it is completed,
    you should see a notification in Azure and a success message ([Figure 7-73](#cognitive_services_deployment_complete)).
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 服务部署可能需要几分钟时间。完成后，在 Azure 中应该会看到通知和成功消息（[图 7-73](#cognitive_services_deployment_complete)）。
- en: '![Cognitive Services deployment complete](Images/apbi_0773.png)'
  id: totrans-503
  prefs: []
  type: TYPE_IMG
  zh: '![认知服务部署完成](Images/apbi_0773.png)'
- en: Figure 7-73\. Cognitive Services deployment complete
  id: totrans-504
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-73\. 认知服务部署完成
- en: Navigate to the newly created resource by clicking “Go to resource.” Alternatively,
    you could navigate from the Azure portal home page to Cognitive Services, choose
    “Anomaly detector” from the menu on the left, and click the name of the endpoint
    from the list, as shown in [Figure 7-74](#cognitive_services_list_view).
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“转到资源”导航到新创建的资源。或者，您可以从 Azure 门户主页导航到“认知服务”，从左侧菜单选择“异常检测器”，并从列表中点击端点的名称，如
    [图 7-74](#cognitive_services_list_view) 所示。
- en: '![Cognitive Services list view](Images/apbi_0774.png)'
  id: totrans-506
  prefs: []
  type: TYPE_IMG
  zh: '![认知服务列表视图](Images/apbi_0774.png)'
- en: Figure 7-74\. Cognitive Services list view
  id: totrans-507
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-74\. 认知服务列表视图
- en: When you have selected the anomaly detector resource, you will be prompted with
    the quick start guide. This is a good place to come back to if you want to integrate
    the endpoint into further applications. The most important page we will need is
    Keys and Endpoint, which you can find in the menu on the left ([Figure 7-75](#access_keys_for_cognitive_services)).
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 选择异常检测器资源后，您将收到快速入门指南。如果您希望将端点集成到更多应用程序中，这是一个很好的返回点。我们将需要的最重要页面是左侧菜单中的“Keys
    and Endpoint”（[图 7-75](#access_keys_for_cognitive_services)）。
- en: '![Access keys for Cognitive Services](Images/apbi_0775.png)'
  id: totrans-509
  prefs: []
  type: TYPE_IMG
  zh: '![认知服务的访问密钥](Images/apbi_0775.png)'
- en: Figure 7-75\. Access keys for Cognitive Services
  id: totrans-510
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-75\. 认知服务的访问密钥
- en: On this page, you will find three essential components. The first two are your
    secret credentials, which you will need to access the AI service. Think of them
    as something like a password that authorizes you to make requests against the
    service. As it goes for passwords, you should not save these keys somewhere in
    plain text and you should not share them publicly anywhere. If you did, either
    accidentally or on purpose (like printing them in a book), click the Regenerate
    Key 1 or Regenerate Key 2 button to generate a new pair of keys. This will void
    the previous key and create a new one for you.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 在此页面上，您将找到三个重要组件。前两个是您的秘密凭据，您需要这些凭据来访问 AI 服务。将它们视为授权您对服务发出请求的密码。就像处理密码一样，您不应将这些密钥明文保存在任何地方，也不应公开分享它们。如果您不小心或故意（如在书中打印它们），请点击“重新生成
    Key 1”或“重新生成 Key 2”按钮生成新的密钥对。这将使先前的密钥失效，并为您创建新的密钥。
- en: Why do we need two keys, you might ask? Think about it as having a guest key
    for your home. You have a second key that you can share and distribute to colleagues
    for quick prototyping purposes, so there is no harm when the key is regenerated
    often. The first key should be safely integrated in your running applications,
    and you don’t want to replace this key that much (most likely, never).
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，为什么我们需要两个密钥？把它想象成你家里的客人钥匙。你有一把可以分享和分发给同事进行快速原型设计的备用钥匙，所以当密钥经常重生成时也无妨。第一把钥匙应该安全地集成到你的运行应用中，你不需要频繁更换这把钥匙（很可能，永远不用更换）。
- en: 'And finally, the third component on this page is the API endpoint. Be careful,
    however: this is not the complete endpoint you can use to make inference requests,
    as we did in our previous examples. Instead, you need to add the path to the actual
    service, the service version, and the service settings to it. To find out how
    to construct the final REST endpoint, you can refer to the [API documentation](https://oreil.ly/iWMNi)
    or the quick start you visited before.'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，页面上的第三个组件是 API 端点。然而，请注意：这不是你可以用来进行推理请求的完整端点，就像我们在之前的示例中所做的那样。相反，你需要将实际服务的路径、服务版本和服务设置添加到其中。要了解如何构建最终的
    REST 端点，你可以参考 [API 文档](https://oreil.ly/iWMNi) 或之前访问的快速入门。
- en: 'For example, the final REST endpoint for the anomaly batch inference looks
    like the following (replace `*ai-powered-bi-anomaly*` with your own service name):'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 例如   例如，异常批量推理的最终 REST 端点如下所示（将 `*ai-powered-bi-anomaly*` 替换为你自己的服务名称）：
- en: '[PRE12]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: That’s it. Now we’re all set to start making prediction requests from our newly
    set-up AI service. Let’s find out how to do it in either Python or R, depending
    on your preference.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。现在我们已经准备好从新设置的 AI 服务开始进行预测请求了。让我们来看看如何在 Python 或 R 中进行，具体取决于你的偏好。
- en: Getting Model Predictions with Python or R
  id: totrans-517
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 或 R 获取模型预测
- en: On the [book’s website](https://oreil.ly/X9jmJ), you will find the files *azure-anomaly-detection-flights.r*
    and *azure-anomaly-detection-flights.py*. You can use either to follow along in
    your preferred code language. I’ll demonstrate the example in R, but all code
    sections, variable names, and intermediate steps will also appear in the equivalent
    Python version.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 在[书籍的官方网站](https://oreil.ly/X9jmJ)上，你会找到文件 *azure-anomaly-detection-flights.r*
    和 *azure-anomaly-detection-flights.py*。你可以使用其中任何一个来根据你喜欢的编程语言进行跟进。我将在 R 中演示示例，但所有代码段、变量名和中间步骤也会出现在相应的
    Python 版本中。
- en: The structure of the code is similar to what you have seen previously in the
    AutoML example. The script has a total of six sections, and each section handles
    a different part. Let’s go through them piece by piece.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的结构类似于你之前在 AutoML 示例中看到的。脚本总共有六个部分，每个部分处理不同的内容。让我们逐个了解它们。
- en: 'Section 0 is again the place where the script loads all required packages such
    as *httr*, *rjson*, and *dplyr* in the case of R. Furthermore, you need to specify
    your custom `API_Key` and `API_URL` for the Azure Cognitive Service from the Azure
    portal, as described previously. Make sure to replace the `*xxxxxxxx*` values
    with your custom parameters. Also, double-check that the `REGION` is set accordingly,
    as shown under the access keys:'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 第 0 节同样是脚本加载所有必需的包，如 R 中的 *httr*、*rjson* 和 *dplyr*。此外，你需要从 Azure 门户中指定你的自定义
    `API_Key` 和 `API_URL`，如前所述。确保用你自己的参数替换 `*xxxxxxxx*` 值。同时，仔细检查 `REGION` 是否已设置为相应的值，如访问密钥下所示：
- en: '[PRE13]'
  id: totrans-521
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In section 0, we are also defining the `MIN_FLIGHTS` threshold for the airport
    selection. Remember that we don’t want to check for anomalies for all airports,
    but just for the busiest ones, defined as airports with a minimum of 1,000 departing
    flights.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 0 节中，我们还定义了机场选择的 `MIN_FLIGHTS` 阈值。记住，我们不希望对所有机场进行异常检测，只对最繁忙的机场进行检测，定义为每周起飞航班数量不少于
    1000 个的机场。
- en: Section 1 contains the `inference_request` function. It is similar to the request
    function we used before but contains some variations. The biggest change is that
    the request body has been structured differently to fit the requirements of the
    Azure Anomaly Detector API. The API expects a JSON object that contains information
    about the time-series granularity first (in our case, that is daily), and secondly
    the actual time series with the corresponding timestamps and values. The function
    takes two vectors (R) or lists (Python) as inputs (timestamps and values). Within
    the function, these two lists will be brought into a format that can be consumed
    by the API
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 第 1 节包含 `inference_request` 函数。它类似于我们之前使用的请求函数，但包含一些变化。最大的变化是请求主体已按照 Azure 异常检测器
    API 的要求进行了不同结构的排列。API 预期一个包含有关时间序列粒度（在我们的情况下是每日）和实际时间序列及其相应时间戳和值的 JSON 对象。该函数接受两个向量（R）或列表（Python）作为输入（时间戳和值）。在函数内部，这两个列表将被格式化为可以被
    API 使用的格式。
- en: '[PRE14]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Section 2 is handling the data preprocessing steps needed before we actually
    send data to the API. First, we are reassigning the variable `dataset`, which
    is the default placeholder for data flowing in from the Power Query workflow.
    Assigning a different variable name will make it clear to us which variable refers
    to the original source data (`dataset`) and which one to the preprocessed data
    (`df`):'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 第 2 节正在处理实际将数据发送到 API 之前所需的数据预处理步骤。首先，我们重新分配变量 `dataset`，这是从 Power Query 工作流中流入的数据的默认占位符。分配不同的变量名称将清楚地显示哪个变量是指向原始源数据（`dataset`），哪个是指向预处理数据（`df`）：
- en: '[PRE15]'
  id: totrans-526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Second, we are applying our threshold value to filter for airports that cater
    to at least 1,000 American Airlines flights:'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们将我们的阈值应用于筛选至少服务于 1,000 次美国航空公司航班的机场：
- en: '[PRE16]'
  id: totrans-528
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Section 3 handles the code that applies the function `inference_request` to
    the daily average taxi-out times for the airports individually. We do that by
    running a preprocessing script inside a `for` loop that iterates through the list
    of the airports selected by the threshold criteria. All results will be collected
    in a dataframe called `df_inference_all`:'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 第 3 节处理将函数 `inference_request` 应用于各个机场每日平均出租车离港时间的代码。我们通过在 `for` 循环中运行预处理脚本来处理此操作，该循环迭代通过阈值条件选择的机场列表。所有结果将收集在名为
    `df_inference_all` 的数据框中：
- en: '[PRE17]'
  id: totrans-530
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Finally, in section 4, we join the information back to the original dataframe
    so we can make use of the new columns in our BI tool, just as we did previously.
    This process is handled by the following code:'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在第 4 节中，我们将信息与原始数据框架重新联接，以便我们可以在 BI 工具中利用新列，就像之前一样。这个过程由以下代码处理：
- en: '[PRE18]'
  id: totrans-532
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'And last but not least, section 5 returns the output, so Power Query can use
    our transformed dataset for further processing:'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但并非最不重要的，第 5 节返回输出，因此 Power Query 可以使用我们转换后的数据集进行进一步处理：
- en: '[PRE19]'
  id: totrans-534
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Don’t worry if the code looks too overwhelming or too complicated at first glance.
    You can always go back and revisit it step by step if you need to. Otherwise,
    feel free to copy and paste everything while replacing your custom variables in
    section 0.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 如果代码一开始看起来过于复杂或令人不知所措，请不要担心。如果需要的话，您可以随时回过头一步一步地重新审视它。否则，可以在替换自定义变量的同时，随意复制和粘贴所有内容到第
    0 节。
- en: Model Inference with Power BI Walk-Through
  id: totrans-536
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Power BI 详细说明模型推理
- en: Our goal is to utilize the anomaly detector to create a better report and more
    actionable insights. We want to make the overall report more accurate and interactive,
    and to free it up from manual efforts.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是利用异常检测器创建更好的报告和更具操作性的见解。我们希望使整体报告更加准确和交互式，并摆脱手动工作的束缚。
- en: First, let’s plug the AI into our data model. Open *Anomaly_Detection.pbix*
    in Power BI Desktop and navigate to the data model. Open Power Query Editor, as
    shown in [Figure 7-76](#power_query_edi).
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们将 AI 插入到我们的数据模型中。在 Power BI Desktop 中打开 *Anomaly_Detection.pbix*，并导航到数据模型。打开
    Power Query Editor，如图 [7-76](#power_query_edi) 所示。
- en: '![](Images/apbi_0776.png)'
  id: totrans-539
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/apbi_0776.png)'
- en: Figure 7-76\. Power Query Editor
  id: totrans-540
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-76\. Power Query Editor
- en: Before we can plug in our R or Python script, we need to include a small preprocessing
    step. Our script expects the flight date in a specific format (YYYY-MM-DD). However,
    Power BI converted the FlightDate column from String to a proprietary Datetime
    format, which is difficult for us to process in Python or R. But we don’t want
    to delete this type conversion, because it will allow a better reporting experience.
    Therefore, we will generate the YYYY-MM-DD string manually and use a simple Power
    Query formula to store the string in a separate column. From the ribbon menu,
    choose Add Column → Custom Column. Enter the new column name `**FlightDateTxt**`
    (pay attention to the correct spelling and letter case!) and include the custom
    formula shown in [Figure 7-77](#power_query_new_custom_column).
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以插入 R 或 Python 脚本之前，我们需要包括一个小的预处理步骤。我们的脚本期望以特定格式（YYYY-MM-DD）接收飞行日期。然而，Power
    BI 将 FlightDate 列从字符串转换为专有的日期时间格式，这在 Python 或 R 中处理起来很困难。但我们不想删除此类型转换，因为它将提供更好的报告体验。因此，我们将手动生成
    YYYY-MM-DD 字符串，并使用简单的 Power Query 公式将该字符串存储在单独的列中。从功能区菜单中，选择 添加列 → 自定义列。输入新列名
    `**FlightDateTxt**`（注意正确的拼写和大小写！），并包含 [图 7-77](#power_query_new_custom_column)
    中显示的自定义公式。
- en: '![Power Query new custom column](Images/apbi_0777.png)'
  id: totrans-542
  prefs: []
  type: TYPE_IMG
  zh: '![Power Query 新自定义列](Images/apbi_0777.png)'
- en: Figure 7-77\. Power Query new custom column
  id: totrans-543
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-77\. Power Query 新自定义列
- en: As a result, you should see a new column called FlightDateTxt in the preview.
    Finally, convert the original column to text by right-clicking the column name
    and choosing FlightDate → Change Type → Text. We are now ready to integrate our
    R or Python script.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将在预览中看到一个名为 FlightDateTxt 的新列。最后，通过右键单击列名并选择 FlightDate → 更改类型 → 文本，将原始列转换为文本。现在，我们已经准备好集成我们的
    R 或 Python 脚本了。
- en: From the ribbon menu, select Transform and then choose either “Run R script”
    or “Run Python script” as per your preference. I’ll continue the example with
    R, but the same steps apply to Python as well.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 从功能区菜单中，选择 转换，然后根据您的偏好选择“运行 R 脚本”或“运行 Python 脚本”。我将继续使用 R 作为示例，但这些步骤同样适用于 Python。
- en: When the script editor opens, paste the code from either *azure-anomaly-detection-flights.r*
    or *azure-anomaly-detection-flights.py* and replace the `*xxxxxxxxx*` values with
    your personal API key and URL from the Keys and Endpoint page of your Azure portal
    ([Figure 7-78](#power_bi_code_editor_left_parenthesisr)).
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 当脚本编辑器打开时，粘贴 *azure-anomaly-detection-flights.r* 或 *azure-anomaly-detection-flights.py*
    中的代码，并替换来自 Azure 门户“密钥和终结点”页面的个人 API 密钥和 URL 的 `*xxxxxxxxx*` 值（见 [图 7-78](#power_bi_code_editor_left_parenthesisr)）。
- en: '![Power BI code editor (R example)](Images/apbi_0778.png)'
  id: totrans-547
  prefs: []
  type: TYPE_IMG
  zh: '![Power BI 代码编辑器（R 示例）](Images/apbi_0778.png)'
- en: Figure 7-78\. Power BI code editor (R example)
  id: totrans-548
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-78\. Power BI 代码编辑器（R 示例）
- en: Click OK and wait for the script to be executed. Select “Ignore Privacy Levels
    checks for this file” when prompted. The script could take a few minutes, depending
    on the performance of your computer. If the script is completed, select the “output”
    table that appears as a result.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 单击 确定 并等待脚本执行。在提示时选择“为此文件忽略隐私级别检查”。脚本的执行时间取决于您计算机的性能。如果脚本已完成，请选择作为结果出现的“输出”表。
- en: You should eventually see the new columns expectedValues, isAnomaly, isPositiveAnomaly,
    and upperMargins in your preview table. It is OK if the first rows show null values,
    since we did not do inference for the whole dataset but for just some airports.
    If you scroll down, you should see results popping up from line 32 onward.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 您最终应该在预览表中看到新列 expectedValues、isAnomaly、isPositiveAnomaly 和 upperMargins。如果前几行显示空值，这是可以接受的，因为我们仅对一些机场进行推断而非整个数据集。如果向下滚动，您应该会看到从第
    32 行开始出现的结果。
- en: Before we close Power Query, transform the column FlightDate back to the original
    format (right-click and choose FlightDate → Change Type → Date). Your final preview
    and Power Query steps should look like [Figure 7-79](#anomaly_columns_in_power_query).
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 在关闭 Power Query 之前，将列 FlightDate 转换回原始格式（右键单击，选择 FlightDate → 更改类型 → 日期）。您的最终预览和
    Power Query 步骤应该如 [图 7-79](#anomaly_columns_in_power_query) 所示。
- en: '![Anomaly columns in Power Query](Images/apbi_0779.png)'
  id: totrans-552
  prefs: []
  type: TYPE_IMG
  zh: '![Power Query 中的异常列](Images/apbi_0779.png)'
- en: Figure 7-79\. Anomaly columns in Power Query
  id: totrans-553
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-79\. Power Query 中的异常列
- en: Choose File → Close & Apply to exit the Power Query Editor. Back in the data
    model menu, you should see the new list of columns in your model.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 文件 → 关闭并应用 以退出 Power Query Editor。返回到数据模型菜单，您应该看到模型中新列的列表。
- en: The heavy lifting is done. Now, we can proceed to the dashboard and make our
    predictions visible for report users.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 繁重的工作已经完成。现在，我们可以继续到仪表板，使我们的预测对报告用户可见。
- en: Building the AI-Powered Dashboard in Power BI
  id: totrans-556
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Power BI 中构建 AI 动力仪表板
- en: In the Report section, add another report page by clicking the plus icon next
    to the first report page. We don’t want to update the existing visuals, but come
    up with an approach that better fits the information we have.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 在报告部分，通过点击第一个报告页旁边的加号图标来添加另一个报告页。我们不想更新现有的可视化内容，而是想出一个更适合我们拥有信息的方法。
- en: Our goal is to build a line chart showing not only the actual average taxi-out
    time, but also the predicted upper boundaries for the time series. Also, we want
    to highlight those data points that exceeded the upper boundaries and therefore
    mark them as anomalies. And finally, we want to provide the user an interactive
    way to switch airports easily.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是构建一条折线图，不仅显示实际的平均出租车推出时间，还预测时间序列的上限边界。此外，我们希望突出显示超过上限边界的数据点，并将它们标记为异常。最后，我们希望为用户提供一种交互方式，方便地切换机场。
- en: 'Before we add any visuals, open the Filters pane and add a page filter to this
    report page, as shown in [Figure 7-80](#page_filter_options). Remember that we
    want to analyze only a selected group of airports so it is convenient to filter
    them out for all charts. Add the data field `**Origin**` to the “Filters on this
    page” area and select the following airports: CLT, DFW, LAX, MIA, ORD, PHL, and
    PHX.'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们添加任何可视化内容之前，打开筛选器面板并为此报告页面添加页面过滤器，如 [图 7-80](#page_filter_options) 所示。记住，我们只想分析所选机场组，因此过滤出这些机场对于所有图表来说很方便。将数据字段
    `**Origin**` 添加到“此页面上的筛选器”区域，并选择以下机场：CLT、DFW、LAX、MIA、ORD、PHL 和 PHX。
- en: '![Page filter options](Images/apbi_0780.png)'
  id: totrans-560
  prefs: []
  type: TYPE_IMG
  zh: '![页面过滤选项](Images/apbi_0780.png)'
- en: Figure 7-80\. Page filter options
  id: totrans-561
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-80\. 页面过滤选项
- en: 'Let’s continue by adding the line chart visual. Double-click the line chart
    icon from the Visualizations pane. Drag the line chart so that it covers roughly
    half of the report page. Add the following fields to the axis and value areas,
    as shown in [Figure 7-81](#field_settings_for_line_chart): FlightDate (Axis),
    TaxiOut, upperMargins (Values).'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续添加折线图可视化。从可视化面板中双击折线图图标。将折线图拖动到报告页面的大约一半位置。按照如下字段添加到轴和数值区域，如 [图 7-81](#field_settings_for_line_chart)
    所示：FlightDate（轴）、TaxiOut、upperMargins（数值）。
- en: '![Field settings for line chart](Images/apbi_0781.png)'
  id: totrans-563
  prefs: []
  type: TYPE_IMG
  zh: '![折线图的字段设置](Images/apbi_0781.png)'
- en: Figure 7-81\. Field settings for line chart
  id: totrans-564
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-81\. 折线图的字段设置
- en: Below FlightDate, delete the Year, Quarter, and Month hierarchy by clicking
    the small x icon so that only Day is left ([Figure 7-82](#field_settings_with_calculated_fields)).
    Also, right-click TaxiOut and upperMargins and choose Average as the aggregation
    function instead of Sum. The field labels should now read “Average of TaxiOut”
    and “Average of upperMargins.”
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 在 FlightDate 下方，通过点击小 x 图标删除年、季度和月的层次结构，以便只剩下天（[图 7-82](#field_settings_with_calculated_fields)）。另外，右键点击
    TaxiOut 和 upperMargins，并选择平均作为聚合函数，而不是求和。字段标签现在应该显示为“平均出租车推出时间”和“平均上限边界”。
- en: '![Field settings with calculated fields](Images/apbi_0782.png)'
  id: totrans-566
  prefs: []
  type: TYPE_IMG
  zh: '![带计算字段的字段设置](Images/apbi_0782.png)'
- en: Figure 7-82\. Field settings with aggregation method
  id: totrans-567
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-82\. 带聚合方法的字段设置
- en: You should see two lines ([Figure 7-83](#line_chart_with_average_of_taxiout_and)).
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到两条线（[图 7-83](#line_chart_with_average_of_taxiout_and)）。
- en: '![Line chart with Average of TaxiOut and Average of upperMargins](Images/apbi_0783.png)'
  id: totrans-569
  prefs: []
  type: TYPE_IMG
  zh: '![平均出租车推出时间和上限边界的折线图](Images/apbi_0783.png)'
- en: Figure 7-83\. Line chart with Average of TaxiOut and Average of upperMargins
  id: totrans-570
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-83\. 平均出租车推出时间和上限边界的折线图
- en: The chart shows the average taxi-out and the average upper margins for the airports
    we specified on the page filter. But we want to analyze the airports individually.
    Therefore, open the Filters pane once again and set a filter just for this visual,
    which is “Origin” is “DFW,” as shown in [Figure 7-84](#airport_filter_on_line_visual).
    We will add the interactivity later so that users can choose the airport they
    want to analyze.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表显示了我们在页面过滤器上指定的机场的平均出租车推出时间和平均上限边界。但是，我们想要逐个分析机场。因此，再次打开筛选器面板，并为此可视化设置一个筛选器，“Origin”
    是 “DFW”，如 [图 7-84](#airport_filter_on_line_visual) 所示。稍后我们将添加交互性，使用户可以选择他们想要分析的机场。
- en: '![Airport filter on line visual](Images/apbi_0784.png)'
  id: totrans-572
  prefs: []
  type: TYPE_IMG
  zh: '![折线视觉上的机场过滤器](Images/apbi_0784.png)'
- en: Figure 7-84\. Airport filter on line visual
  id: totrans-573
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-84\. 折线视觉上的机场过滤器
- en: 'You’ve set two filters now: one filter on the page for seven airports, and
    one filter on the visual for DFW airport. Also, we have two lines already on the
    chart: one line showing the daily average taxi-out and one line showing the predicted
    upper boundary. What’s missing is the highlight of outliers. We’re getting there!'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经设置了两个过滤器：页面上的七个机场的一个过滤器，以及视觉上的 DFW 机场的一个过滤器。此外，我们已经在图表上有了两条线：一条线显示每日平均出租车出站时间，另一条线显示预测的上限边界。缺少的是异常值的突出显示。我们快要完成了！
- en: 'Add the field isPositiveAnomaly to the values as the third line. Right-click
    and choose New Quick Measure. In the window that pops up, set the settings as
    shown in [Figure 7-85](#adding_a_quick_measure): select the Calculation option
    to “Filtered value,” set “Base value” to Average of TaxiOut, and set Filter to
    isPositiveAnomaly equals True. Confirm the settings by clicking OK. Delete Count
    of isPositiveAnomaly from the values area if it still appears here. You should
    see three values now: Average of TaxiOut, Average of upperMargins, and Average
    of TaxiOut for True. Right-click Average of TaxiOut for True and choose “Rename
    for this visual.” Rename this field to `**Anomaly**`. Likewise, change the name
    of “Average of upperMargins” to `**Upper Margin**` for this visual.'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 将字段 isPositiveAnomaly 添加到值中作为第三行。右键单击并选择“新建快速测量”。在弹出的窗口中，按照[图 7-85](#adding_a_quick_measure)中显示的设置进行设置：选择“计算”选项为“过滤值”，将“基础值”设置为
    TaxiOut 的平均值，并将过滤器设置为 isPositiveAnomaly 等于 True。通过单击“确定”来确认设置。如果这里仍然显示 isPositiveAnomaly
    的计数，请从值区域中删除它。现在应该看到三个值：TaxiOut 的平均值，upperMargins 的平均值以及 True 的 TaxiOut 的平均值。右键单击
    True 的 TaxiOut 的平均值并选择“为此视觉重命名”。将此字段重命名为`**异常**`。同样地，将“upperMargins 的平均值”更改为`**上限边界**`以供此视觉使用。
- en: '![Adding a quick measure](Images/apbi_0785.png)'
  id: totrans-576
  prefs: []
  type: TYPE_IMG
  zh: '![添加快速测量](Images/apbi_0785.png)'
- en: Figure 7-85\. Adding a quick measure
  id: totrans-577
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-85\. 添加快速测量
- en: With these three values, we have all the information we need on the plot. The
    rest is “just” formatting. So head over to the Format settings ([Figure 7-86](#formatting_pane)).
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这三个值，我们已经得到了图表所需的所有信息。剩下的只是“仅仅”格式化。所以前往格式设置（[图 7-86](#formatting_pane)）。
- en: '![Formatting pane](Images/apbi_0786.png)'
  id: totrans-579
  prefs: []
  type: TYPE_IMG
  zh: '![格式化窗格](Images/apbi_0786.png)'
- en: Figure 7-86\. Formatting pane
  id: totrans-580
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-86\. 格式化窗格
- en: Choose “X axis” and change the type from Continuous to Categorical, as shown
    in [Figure 7-87](#changing_the_formatting_type).
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 选择“X 轴”并将类型从连续更改为分类，如[图 7-87](#changing_the_formatting_type)所示。
- en: '![Changing the formatting type](Images/apbi_0787.png)'
  id: totrans-582
  prefs: []
  type: TYPE_IMG
  zh: '![更改格式类型](Images/apbi_0787.png)'
- en: Figure 7-87\. Changing the formatting type
  id: totrans-583
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-87\. 更改格式类型
- en: Head over to “Data colors” and change the color for both Upper Margin and Anomaly
    to Red.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 前往“数据颜色”并将上限边界和异常的颜色都更改为红色。
- en: Next, select Shape and set the stroke width to 6\. From the drop-down menu shown
    in [Figure 7-88](#formatting_shapes), select Upper Margin.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，选择形状并将描边宽度设置为 6\. 从[图 7-88](#formatting_shapes)所示的下拉菜单中选择“上限边界”。
- en: '![Formatting shapes](Images/apbi_0788.png)'
  id: totrans-586
  prefs: []
  type: TYPE_IMG
  zh: '![格式化形状](Images/apbi_0788.png)'
- en: Figure 7-88\. Formatting shapes
  id: totrans-587
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-88\. 格式化形状
- en: We want to give this upper band a different style to make clear that this is
    a boundary, not an actual data value. So set the line style to Dotted and then
    toggle Stepped to On. Next, select Anomaly from the drop-down menu in Shape and
    set the stroke width to 0\. Then scroll down to Markers and switch them to “on.”
    Select Anomaly from the drop-down menu. Switch the marker shape from circle to
    square, and increase the marker size to 10, as shown in [Figure 7-89](#marker_shape_format).
    Switch off markers for the other two series.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望给这个上限带上一个不同的样式，以明确这是一个边界，而不是实际的数据值。所以将线条样式设置为点状，然后切换到“步进”模式。接下来，在形状的下拉菜单中选择“异常”，并将描边宽度设置为
    0\. 然后滚动到标记并打开它们。从下拉菜单中选择“异常”。将标记形状从圆形切换为正方形，并将标记大小增加到 10，如[图 7-89](#marker_shape_format)所示。关闭其他两个系列的标记。
- en: '![Marker shape format](Images/apbi_0789.png)'
  id: totrans-589
  prefs: []
  type: TYPE_IMG
  zh: '![标记形状格式](Images/apbi_0789.png)'
- en: Figure 7-89\. Marker shape format
  id: totrans-590
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-89\. 标记形状格式
- en: Your line chart should look like [Figure 7-90](#final_line_chart_with_anomaly_highlight),
    and we are almost ready! The only thing missing now is for users to be able to
    choose the airport they want to examine. We will use the cross-filter feature
    in Power BI to make this process more convenient for the user.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 你的折线图应该看起来像[图 7-90](#final_line_chart_with_anomaly_highlight)，我们几乎准备好了！现在唯一缺少的是用户能够选择他们想要检查的机场。我们将使用
    Power BI 中的交叉筛选功能，使这个过程对用户更加方便。
- en: '![Final line chart with anomaly highlights](Images/apbi_0790.png)'
  id: totrans-592
  prefs: []
  type: TYPE_IMG
  zh: '![带有异常突出显示的最终折线图](Images/apbi_0790.png)'
- en: Figure 7-90\. Final line chart with anomaly highlights
  id: totrans-593
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-90. 具有异常突出显示的最终线形图
- en: Add a stacked bar chart from the Visualizations pane to the report page with
    a double-click. Make sure that your line chart is not selected; otherwise, it
    will replace this visual. The bar chart should automatically fill the empty space
    right next to the line chart. Add Origin to the axis and TaxiOut to the values.
    Right-click TaxiOut and choose Average as the aggregation measure. Under Format,
    choose “Y axis” and increase the inner padding to 50%.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 从可视化面板向报告页面添加堆叠条形图，双击即可。确保未选择线形图；否则，它将替换此可视化效果。条形图应自动填充紧挨线形图旁的空白区域。添加"Origin"到轴上，"TaxiOut"到数值上。右键点击"TaxiOut"，选择平均值作为聚合度量。在格式中，选择“Y轴”，将内部填充增加到50%。
- en: The cross-filter functionality in Power BI will have the effect that once a
    user selects a bar from the bar chart, the other visuals on the same page will
    be filtered accordingly. To allow the dynamic filtering for our line chart, select
    the line chart, open the Filters pane, and remove the visual filter “Origin is
    DFW” that we set for the purpose of designing the chart. Leave the page filter
    untouched.
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: Power BI中的交叉过滤功能会导致用户从条形图中选择一条后，同一页上的其他可视化效果会相应过滤。为了允许我们线形图的动态过滤，选择线形图，打开过滤器面板，移除我们为设计图表设置的可视化过滤器“Origin
    is DFW”。保留页面过滤器不变。
- en: Now, whenever we select a bar on the right side, the left side will show the
    daily average taxi-out time with the anomaly values highlighted; see [Figure 7-91](#report_interactivity).
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每当我们在右侧选择一个条形图时，左侧将显示具有突出显示异常值的每日平均出租车出场时间；参见[图7-91](#report_interactivity)。
- en: '![Report interactivity](Images/apbi_0791.png)'
  id: totrans-597
  prefs: []
  type: TYPE_IMG
  zh: '![Report interactivity](Images/apbi_0791.png)'
- en: Figure 7-91\. Report interactivity
  id: totrans-598
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-91. 报告互动性
- en: To finish off our report, let’s add a headline and the current month to the
    top by copying those elements from the first report page. [Figure 7-92](#final_ai_powered_dashboard)
    shows our final dashboard in action. You can find the final state in the *Anomaly-Detection_AI-Powered.pbix*
    file on the [book’s website](https://oreil.ly/X9jmJ).
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成我们的报告，让我们在顶部添加一个标题和当前月份，通过从第一个报告页面复制这些元素来实现。[图7-92](#final_ai_powered_dashboard)展示了我们最终的仪表板效果。您可以在[书的网站](https://oreil.ly/X9jmJ)的*Anomaly-Detection_AI-Powered.pbix*文件中找到最终状态。
- en: '![Final AI-powered dashboard](Images/apbi_0792.png)'
  id: totrans-600
  prefs: []
  type: TYPE_IMG
  zh: '![Final AI-powered dashboard](Images/apbi_0792.png)'
- en: Figure 7-92\. Final AI-powered dashboard
  id: totrans-601
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-92. 最终AI驱动的仪表板
- en: Since we now have the attribute isAnomaly in our dataset, we can easily run
    further analysis or automated reports for this metric. To find out more about
    how the anomaly detection is working in detail, how to run inference results in
    real time, and general best practices around this API, I recommend [“Best Practices
    for Using the Anomaly Detector Univariate API”](https://oreil.ly/9RHAY) by Microsoft.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们现在在数据集中具有isAnomaly属性，我们可以轻松运行进一步的分析或此指标的自动报告。要详细了解异常检测的工作原理、如何实时运行推断结果以及围绕此API的一般最佳实践，我建议阅读Microsoft的[“使用异常检测器单变量API的最佳实践”](https://oreil.ly/9RHAY)。
- en: With our AI-powered approach, we have helped the operations team identify anomalies
    quicker and without adhering to a fixed rule set. Thanks to the AI prediction,
    the data label isAnomaly is now also available in the data model, which allows
    further analysis or automated reporting of this metric, thus supporting the data
    teams by removing a lot of manual workload.
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 通过我们的AI驱动方法，我们帮助运营团队更快速地识别异常，而无需遵循固定的规则集。由于AI预测，数据模型中现在还可用数据标签isAnomaly，这允许进一步分析或自动报告此指标，从而通过减少大量手动工作量来支持数据团队。
- en: Cleaning Up Resources
  id: totrans-604
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清理资源
- en: 'Consider stopping or deleting the following resources we have used in this
    chapter to avoid any ongoing charges:'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑停止或删除本章中使用的以下资源，以避免持续收费：
- en: Stop the compute instance.
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止计算实例。
- en: Delete model endpoints for regression and classification.
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除回归和分类模型端点。
- en: Delete the Azure Cognitive Services Anomaly detector resource.
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除Azure认知服务异常检测器资源。
- en: We will still use some of these resources for the other chapters. If you don’t
    plan to do the use cases in the following chapters, you can delete all resources
    at once. Select “Resource groups” in your Azure portal, select the resource group
    that you created, and choose “Delete resource group.” Confirm the resource group
    name. Then click Delete.
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍将在其他章节中使用这些资源的一部分。如果您不打算在接下来的章节中进行使用案例，可以一次性删除所有资源。在 Azure 门户中选择“资源组”，选择您创建的资源组，然后选择“删除资源组”。确认资源组名称，然后单击“删除”。
- en: Summary
  id: totrans-610
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: Congratulations! Give yourself a pat on the back because what you just did was
    nothing less than applying state-of-the-art AI tools to real-world data and building
    actionable BI dashboards for predictive analytics. You have not only learned how
    to use historical information in a dataset to predict future categorical or numeric
    variables, but also touched on AI services that provide automated estimations
    (in this case, for anomaly detection).
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你刚刚做的事情不亚于应用先进的AI工具处理实际数据，并构建可操作的BI仪表板进行预测分析。你不仅学会了如何利用数据集中的历史信息预测未来的分类或数值变量，还涉及到了提供自动估算的AI服务（在本例中，用于异常检测）。
- en: It does not matter whether you are a Power BI or Tableau user, or whether you
    prefer AWS, Azure, or GCP. The fundamental building blocks that you learned and
    applied in this chapter will help you to get up to speed quickly on any of those
    platforms. Try out what you’ve learned on your own dataset to get more hands-on
    experience. In the next chapter, we will touch on the realms of prescriptive analytics,
    making intelligent recommendations for decisions on a microlevel.
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是Power BI还是Tableau用户，或者您更喜欢AWS、Azure还是GCP，本章中学到并应用的基本构建块将帮助您快速上手任何这些平台。尝试将所学内容应用于您自己的数据集，以获得更多的实际经验。在下一章中，我们将涉及处方分析的领域，为微观层面的决策提供智能推荐。
