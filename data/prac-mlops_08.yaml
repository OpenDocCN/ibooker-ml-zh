- en: Chapter 8\. MLOps for Azure
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 MLOps for Azure
- en: By Alfredo Deza
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 阿尔弗雷多·德萨
- en: A third reason for our family to move was that we had never had a proper home
    since 1933 when, in the midst of the Great Depression, we were dispossessed. It
    was only years later that I understood how the rural paradise I loved at age 6
    disappeared. My parents could not make the payments. My mother abandoned her struggling
    practice and found a job as receiving physician in a state hospital that provided
    a few dollars and an apartment too cramped for us all, so my brother and I were
    sent into what we later called “The Exile.”
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们一家搬迁的第三个原因是，自从1933年大萧条期间我们被剥夺家园以来，我们从未有过一个合适的家。直到多年以后，我才明白我6岁时所喜爱的乡村天堂是如何消失的。我的父母无法偿还贷款。我的母亲放弃了她苦苦挣扎的诊所工作，找到了一份作为接待医生的工作，提供了一些钱和一个对我们所有人来说都太拥挤的公寓，所以我和我哥哥被送进了后来我们称之为“流亡”的地方。
- en: ''
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Dr. Joseph Bogen
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 约瑟夫·博根博士
- en: Microsoft’s continuous investments in Azure for machine learning are paying
    off. The number of features offered today makes the platform as a whole a great
    offering. A few years ago, it wasn’t even clear that Azure would get such an influx
    of top-level engineering and a growing interest in its services.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft在Azure中为机器学习持续投资正在取得成效。今天提供的功能数量使整个平台成为一个很好的选择。几年前，甚至还不清楚Azure是否会获得如此多高级工程和对其服务日益增长的兴趣。
- en: If you haven’t tried Azure at all or haven’t seen anything related to machine
    learning within Microsoft’s cloud offering, I highly recommend you give it a chance.
    Like most cloud providers, a trial period is available with enough credits to
    try it out and judge for yourself.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有尝试过Azure，或者在Microsoft的云服务中还没有看到与机器学习相关的内容，我强烈建议你给它一个机会。像大多数云服务提供商一样，提供了试用期，具有足够的信用额度，可以自行尝试并作出判断。
- en: One of the examples I usually tend to bring up is that of using Kubernetes.
    Installing, configuring, and deploying a Kubernetes cluster is not a straightforward
    task *at all*. It is even more complicated if you factor in associating a machine
    learning model and scaling its interactions with potential consumers. This is
    a challenging problem to solve correctly. If you get a chance to go through the
    deployment settings for a trained model, using a Kubernetes cluster as a target
    for the model, it boils down to selecting the cluster from a drop-down menu.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常提到的一个例子是使用Kubernetes。安装、配置和部署Kubernetes集群根本*不是一件简单的任务*。如果考虑将机器学习模型与潜在消费者的互动进行关联和扩展，情况会更加复杂。这是一个需要正确解决的具有挑战性的问题。如果你有机会查看一个训练模型的部署设置，将Kubernetes集群作为模型的目标，最终可以通过从下拉菜单中选择集群来完成。
- en: Aside from all the features and abstractions of complex problems like deploying
    models in production, it is *very refreshing* to see an enormous amount of detailed
    documentation. Although this chapter concentrates on doing operations in machine
    learning in Azure, it can’t possibly capture all of the exciting details. The
    [main documentation resource](https://oreil.ly/EV9wX) is an excellent place to
    bookmark to dive deeper into more information not covered here.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 除了像将模型部署到生产环境这样的复杂问题的所有功能和抽象之外，看到大量详细的文档是*非常令人耳目一新*的。尽管这一章集中讨论在Azure中进行机器学习操作，但它不可能涵盖所有令人兴奋的细节。[主要文档资源](https://oreil.ly/EV9wX)是一个很好的地方，可以加为书签，深入了解这里未涵盖的更多信息。
- en: In this chapter, I go through some of the interesting options in Azure, from
    training a model to deploying it in containers or a Kubernetes cluster. As they
    are becoming commonplace in machine learning offerings, I will dive into pipelines.
    Pipelines can enhance the automation further, even when the automation originates
    outside of the Azure cloud.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我介绍了Azure中一些有趣的选项，从训练模型到将其部署在容器或Kubernetes集群中。随着它们在机器学习服务中变得越来越普遍，我将深入研究管道。管道可以进一步增强自动化，即使自动化起源于Azure云之外。
- en: 'There are many ways to perform machine learning tasks within the platform:
    Azure ML Studio Designer, Jupyter Notebooks, and AutoML, where you can upload
    a CSV and start training models right away. Finally, most (if not all) features
    have corresponding support in the SDK (covered in the next section). That flexibility
    is vital because it allows you to choose the solution that works best for you.
    So there is no need to follow an opinionated way to operationalize models.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在平台内执行机器学习任务有许多方法：Azure ML Studio 设计器、Jupyter Notebooks 和 AutoML，您可以上传 CSV 并立即开始训练模型。最后，大多数（如果不是全部）功能在
    SDK 中都有相应的支持（在下一节中讨论）。这种灵活性非常重要，因为它允许您选择最适合您的解决方案。因此，没有必要遵循一种偏见的方式来使模型运作。
- en: Finally, I will cover practical recommendations on applying some of the core
    principles of DevOps, such as monitoring and logging using features of Azure Machine
    Learning.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我将涵盖一些实用建议，如使用 Azure 机器学习的核心原则，例如监控和日志记录。
- en: Note
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Although this chapter is about Azure Machine Learning, it will not cover basics
    like creating and setting up a new account. If you haven’t tried the service yet,
    [you can start here](https://oreil.ly/LcSb2).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本章讨论的是 Azure 机器学习，但不涉及创建和设置新帐户等基础知识。如果您尚未尝试过该服务，[可以从这里开始](https://oreil.ly/LcSb2)。
- en: Azure CLI and Python SDK
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure CLI 和 Python SDK
- en: 'The various examples and code snippets in this chapter assume that you have
    the Azure command line tool and Python SDK (Software Development Kit) installed
    and available in your environment. Make sure [you install the latest version of
    the CLI](https://oreil.ly/EPTdV), and that the machine learning extension is available
    after installation:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的各种示例和代码片段假定您已经安装并在环境中可用 Azure 命令行工具和 Python SDK（软件开发工具包）。请确保[安装 CLI 的最新版本](https://oreil.ly/EPTdV)，并在安装后确保机器学习扩展可用：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Most of the time, you will need to authenticate from your local system back
    to Azure. This workflow is similar to other cloud providers. To associate your
    Azure account with the current environment, run the following command:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，您需要从本地系统返回到 Azure 进行身份验证。此工作流程类似于其他云提供商。要将 Azure 帐户与当前环境关联起来，请运行以下命令：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Most of the Python examples using Azure’s Python SDK will require an account
    with Azure and the *config.json* file associated with your workspace downloaded
    locally. This file has all the information necessary to associate the Python code
    with the workspace. All interactions with the Python SDK should use this to configure
    the runtime:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Azure 的 Python SDK 的大多数 Python 示例都需要一个 Azure 帐户以及本地下载的与您的工作区关联的 *config.json*
    文件。此文件包含将 Python 代码与工作区关联所需的所有信息。所有与 Python SDK 的交互应使用此文件配置运行时：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To retrieve the *config.json* file, [log in to Azure’s ML studio](https://ml.azure.com)
    and click the top-right menu (labeled Change Subscription). The submenu will have
    a link to download the *config.json* file (see [Figure 8-1](#Figure-8-1)) .
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要检索 *config.json* 文件，请[登录 Azure 的 ML Studio](https://ml.azure.com) 并点击右上角的菜单（标记为更改订阅）。子菜单中将包含一个链接以下载
    *config.json* 文件（参见[图 8-1](#Figure-8-1)）。
- en: '![pmlo 0801](Images/pmlo_0801.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0801](Images/pmlo_0801.png)'
- en: Figure 8-1\. Azure JSON config
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-1\. Azure JSON 配置
- en: 'If *config.json* is not present in the current working directory, using the
    SDK fails with a traceback:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果当前工作目录中不存在 *config.json* 文件，则使用 SDK 将导致回溯：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now that I’ve covered some of the basics of using the Azure CLI and the SDK,
    I will get into more authentication details and some variants you can use in Azure.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经介绍了使用 Azure CLI 和 SDK 的一些基础知识，接下来将深入探讨更多身份验证细节以及您在 Azure 中可以使用的一些变体。
- en: Authentication
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 身份验证
- en: 'Authentication should be one of the core pieces of automation when dealing
    with services. Azure has a *service principal* for access (and access control)
    to resources. When automating services and workflows, people tend to overlook
    or even attempt to simplify authenticating in general. It is *very* common to
    hear recommendations like: *“just use the root user,”* or *“just change file permissions
    so anyone can write and execute.”* A seasoned engineer will know best, but only
    because they have experienced the pain after accepting these suggestions of lax
    security and deployment constraints. I very much understand the problem of trying
    to fix a situation like this one.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理服务时，身份验证应该是自动化的核心部分之一。Azure具有用于资源访问（和访问控制）的*服务主体*。在自动化服务和工作流程时，人们往往忽视甚至尝试简化一般的身份验证。很常见听到建议像：“只需使用root用户”或“只需更改文件权限以便任何人都能写入和执行”。经验丰富的工程师会最了解，但这是因为他们在接受这些松散的安全性和部署约束建议后经历了痛苦。我非常理解试图解决类似这种情况的问题。
- en: When working as a Systems Administrator in a media agency, the Engineering Lead
    logged directly into the production environment to make a file readable to anyone
    (needed by the PHP application where it ran). We eventually found out about it.
    The result of the change meant any HTTP request (and anyone on the internet) had
    read, write, and execute permissions for that file. Sometimes, a simple fix may
    be tempting and feel like the best way forward, but this is not always the case.
    Particularly with security (and authentication in this case), you have to be very
    skeptical of simple fixes that remove a security constraint.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在媒体机构担任系统管理员时，工程主管直接登录生产环境以使文件对任何人可读（PHP应用程序所需）。最终我们发现了这一点。更改的结果意味着任何HTTP请求（以及任何互联网上的任何人）都可以读取、写入和执行该文件。有时，简单的修复可能很诱人，感觉是前进的最佳方式，但并非总是如此。特别是在安全性（以及身份验证在这种情况下）方面，您必须对移除安全约束的简单修复方法持怀疑态度。
- en: Always ensure that authentication is done correctly, and do not try to skip
    or work around these restrictions, even when it is an option.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 始终确保正确进行身份验证，不要试图跳过或绕过这些限制，即使这是一种选择。
- en: Service Principal
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务主体
- en: 'In Azure, creating a service principal involves several steps. Depending on
    the constraints you need for the account and resource access, it will vary from
    one example to another. Adapt the following to fit a specific scenario. First,
    after logging in with the CLI, run the following command:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure中，创建服务主体涉及多个步骤。根据您需要的帐户和资源访问约束，这将因示例而异。适应以下内容以适应特定场景。首先，在使用CLI登录后，运行以下命令：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'That command creates the service principal with the `ml-auth` name. You are
    free to choose any name you want, but it is always good to have some convention
    to remember what these names are associated with. Next, take note of the output,
    and check the `"clientId"` value, which the next steps require:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令使用`ml-auth`名称创建服务主体。您可以选择任何名称，但最好有一些约定来记住这些名称所关联的内容。接下来，注意输出并检查`"clientId"`值，后续步骤将需要它：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now use the `"clientId"` to retrieve metadata from the newly created service
    principal:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用`"clientId"`从新创建的服务主体中检索元数据：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To allow the service principal access to your Azure Machine Learning workspace,
    you need to associate it with the workspace and resource group:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 要允许服务主体访问您的Azure机器学习工作区，您需要将其与工作区和资源组关联：
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: That command is the last one required to complete the process of creating a
    service principal and associating it with the machine learning account using the
    `owner` role. The `example-workspace` is the name of the workspace I used in Azure,
    and `alfredodeza_rg_linux_centralus` is the resource group within that workspace.
    It is rather unfortunate that there is no output from running that command after
    a successful call.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令是完成创建服务主体并将其与使用`owner`角色的机器学习帐户关联的最后一个命令。`example-workspace`是我在Azure中使用的工作区的名称，`alfredodeza_rg_linux_centralus`是该工作区中的资源组。非常不幸的是，在成功调用后运行该命令不会有任何输出。
- en: Once this account created, you can use it to enable automation with authentication,
    which prevents prompts and constant authenticating. Make sure to restrict the
    access and role to the least number of permissions needed.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建此帐户，您可以使用它启用具有身份验证的自动化，从而避免提示和持续验证。请确保将访问权限和角色限制为所需权限的最少数量。
- en: Note
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: These examples use the role value of `"owner"` for the service principal, which
    has widespread permissions. The default value for the `--role` flag is `"contributor,"`
    which is more restricted. Adapt this value to what suits your environment (and
    usage) better.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例使用了服务主体的角色值 `"owner"`，其权限广泛。`--role` 标志的默认值是 `"contributor,"`，权限较为受限。根据你的环境（和使用情况），调整此值以适应更合适的设置。
- en: Authenticating API Services
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: API 服务的认证
- en: Other environments might not benefit from a service principal account, depending
    on the workflow at hand. These services can be exposed to the internet, providing
    interaction with deployed models via HTTP requests. In those cases, you need to
    decide the type of authentication to be enabled.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 根据手头的工作流程，其他环境可能不会从服务主体账户中受益。这些服务可以通过 HTTP 请求与部署的模型进行交互并向其提供服务。在这些情况下，你需要决定启用何种类型的认证。
- en: Before deploying a model or even configuring any settings for getting a model
    into production, you need to have a good idea about the different security features
    available to you.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署模型或甚至配置任何生产模型所需的设置之前，你需要对可用的不同安全功能有一个清晰的了解。
- en: 'Azure offers different ways to authenticate, depending on the service you need
    to interact with. The defaults for these services change, too, depending on the
    deployment type. Essentially, two types are supported: keys and tokens. Azure
    Kubernetes Service (AKS) and Azure Container Instances (ACI) have varying support
    for these authentication types.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 提供了与你需要交互的服务相关的不同认证方式。这些服务的默认设置也会根据部署类型而改变。基本上支持两种类型：密钥和令牌。Azure Kubernetes
    服务（AKS）和 Azure 容器实例（ACI）对这些认证类型的支持有所不同。
- en: 'Key-based authentication:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 基于密钥的认证：
- en: AKS has key-based auth enabled by default.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AKS 默认启用基于密钥的认证。
- en: ACI has key-based auth disabled by default (but can be enabled). No authentication
    is enabled by default.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACI 默认禁用基于密钥的认证（但可以启用）。默认情况下未启用任何认证。
- en: 'Token-based authentication:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 基于令牌的认证：
- en: AKS has token-based auth disabled by default.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AKS 默认禁用基于令牌的认证。
- en: ACI does not support token-based auth.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACI 不支持基于令牌的认证。
- en: These types of clusters for deployments are significant enough to grasp before
    deploying the model to production. Even for test environments, always enable authentication
    to prevent a mismatch between development and production.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型部署到生产环境之前，了解这些部署类型对于测试环境来说非常重要。即使是测试环境，也始终要启用认证以防止开发和生产之间的不匹配。
- en: Compute Instances
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算实例
- en: Azure has a definition for compute instances that describes them as a *managed
    cloud-based workstation for scientists*. Essentially, it allows you to get started
    *very quickly* with everything you might need for performing machine learning
    operations in the cloud. When developing proof of concepts or trying something
    new from a tutorial, you can leverage the excellent support for [Jupyter Notebooks](https://jupyter.org)
    with an enormous amount of dependencies preinstalled and ready to go. Although
    you can upload your own notebooks, I recommend starting by browsing the thorough
    samples that exist, as shown in [Figure 8-2](#Figure-8-2).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 对计算实例有一个定义，将其描述为科学家的 *托管云工作站*。基本上，它允许你快速启动所有在云中进行机器学习操作所需的内容。在开发概念验证或从教程尝试新事物时，你可以利用对
    [Jupyter 笔记本](https://jupyter.org) 的出色支持，预先安装并准备好大量依赖项。虽然你可以上传自己的笔记本，但我建议首先浏览现有的详尽示例，如
    [图 8-2](#Figure-8-2) 所示。
- en: '![pmlo 0802](Images/pmlo_0802.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0802](Images/pmlo_0802.png)'
- en: Figure 8-2\. Azure notebook samples
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-2\. Azure 笔记本示例
- en: One of the most annoying problems to solve when trying to get started running
    notebooks and tinkering with models is setting up an environment. By offering
    something ready-to-use and preconfigured specifically for ML, you are enabled
    to achieve your tasks quickly, moving from ideas in a notebook to production.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当你试图启动笔记本并尝试调整模型时，最让人头疼的问题之一是设置环境。通过提供一些现成且专门为机器学习预配置的东西，你可以快速完成任务，从笔记本中的想法转向生产。
- en: Once you are ready to deploy a trained model from a compute instance, you can
    use the compute instance as a training cluster since it supports a job queue,
    multiple jobs in parallel, and multi-GPU distributed training. This is a perfect
    combination for debugging and testing because the environment is reproducible.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你准备好从计算实例部署训练好的模型，你可以将计算实例用作训练集群，因为它支持作业队列、并行多个作业和多 GPU 分布式训练。这是调试和测试的理想组合，因为环境是可复制的。
- en: Have you ever heard *“But it works on my machine!”* before? I surely have! Even
    if testing or exploring new ideas, reproducible environments are a great way to
    normalize development so that there are fewer surprises and collaboration between
    other engineers is more streamlined. Using reproducible environments is an instrumental
    part of DevOps that applies to ML. Consistency alongside normalization takes a
    lot of effort to get right, and whenever you find tools or services that are immediately
    available, you should take advantage of them right away.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你以前听过*“但在我的机器上可以运行！”*这样的说法吗？我肯定听过！即使是在测试或探索新想法时，可重现的环境也是规范开发的一种重要方式，可以减少意外情况，使其他工程师之间的协作更加顺畅。使用可重现的环境是DevOps中不可或缺的一部分，也适用于ML。一致性和规范化需要大量的努力来正确实施，每当你发现有立即可用的工具或服务时，应立即利用它们。
- en: As a Systems Administrator, I’ve put tremendous effort in normalizing production
    environments for development, and it is a hard problem to solve. Use Azure compute
    instances as much as possible!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 作为系统管理员，我在规范化开发的生产环境方面投入了大量精力，这是一个难题。尽可能使用Azure计算实例！
- en: You can create a compute instance within Azure ML Studio from the various workflows
    that require one, like when creating a Jupyter Notebook. It is easier to find
    the Compute link in the Manage section and create one there. Once it loads, multiple
    choices are presented (see [Figure 8-3](#Figure-8-3)). A good rule of thumb is
    to pick a low-cost virtual machine to get started, which avoids higher costs down
    the road for something that might not be needed just to run a notebook.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过Azure ML Studio中的各种工作流之一创建计算实例，例如创建Jupyter Notebook时。在“管理”部分中更容易找到“计算”链接并在那里创建一个计算实例。加载后，会呈现多个选择（参见[图8-3](#Figure-8-3)）。一个经验法则是选择一个低成本的虚拟机来开始使用，这样可以避免因为可能不需要仅仅为了运行笔记本而产生的更高成本。
- en: '![pmlo 0803](Images/pmlo_0803.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0803](Images/pmlo_0803.png)'
- en: Figure 8-3\. Azure Create compute instance
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-3\. Azure 创建计算实例
- en: In this example, I’m choosing a `Standard_D2_v3`. Since the names of the various
    machines offered keep changing, the choices you get might be different.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我选择了一个`Standard_D2_v3`。由于提供的各种机器名称经常变化，你得到的选择可能会有所不同。
- en: Deploying
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: There are several ways of deploying in Azure to interact with a model. If you
    are dealing with massive amounts of data beyond what is reasonable to deal with
    in-memory, batch inferencing is a better fit. Azure does provide a lot of useful
    tooling (general availability for this service was announced in 2020), helping
    users deal with terabytes of both structured and unstructured data and get inferences
    from it.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure中有几种与模型交互的部署方式。如果你处理的数据量非常大，超出内存处理的合理范围，批量推断是更合适的选择。Azure确实提供了大量有用的工具（此服务的普遍可用性在2020年宣布），帮助用户处理结构化和非结构化的TB级数据，并从中获取推断结果。
- en: Another way of deploying is for online (sometimes referred to as *instant*)
    inference. When dealing with smaller datasets (not in the order of terabytes!),
    it is useful to have a model deployed quickly, accessed over an HTTP API that
    Azure can create for you programmatically. An HTTP API that gets created for you
    automatically for a trained model is another one of these features that you should
    leverage.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种部署方式是在线推断（有时称为*即时*推断）。当处理较小的数据集（而不是几TB的数据！）时，快速部署模型并通过Azure为你编程创建的HTTP API进行访问是非常有用的。为训练模型自动创建的HTTP
    API是你应该利用的另一项功能。
- en: Crafting HTTP APIs is not that much work, but offloading that work to a service
    means you (and your team) have more time to work on more substantial pieces like
    the quality of your data or the robustness of the deployment process.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 手工创建HTTP API并不麻烦，但是将这项工作外包给一个服务意味着你（以及你的团队）有更多时间处理数据质量或部署流程的稳健性等更重要的部分。
- en: Registering Models
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注册模型
- en: The Azure documentation describes registration as something optional. It is
    indeed optional in that you don’t need it to get a model deployed. But as you
    get used to the process of deploying models and releasing them into production
    environments, it will become apparent that skimping on features and constraints
    like authentication (or, in this case, model registration) makes things go easier
    at first but can create problems later.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Azure文档将注册描述为可选项。的确，在部署模型时你并不需要它。但是随着你习惯于部署模型并将其发布到生产环境中，你会意识到省略诸如认证（或者在这种情况下是模型注册）等功能和约束会使事情起初更加容易，但后续可能会引发问题。
- en: I *highly* recommend you register your models and follow a process to do so,
    even better if this process is fully automated. Granted, you may not need to register
    every single model you work with, but you most definitely should for select models
    that get into production. If you are familiar with [Git (the version control system)](https://oreil.ly/Ttyl0),
    then versioning models will feel like a very natural way to reason about changes
    and modification for production-level models.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我*强烈*建议您注册您的模型并遵循相应的流程，如果这个过程是完全自动化的话会更好。当然，您可能不需要为每一个您使用的模型都进行注册，但是对于进入生产环境的选择模型，您绝对应该这样做。如果您熟悉[Git（版本控制系统）](https://oreil.ly/Ttyl0)，那么对模型进行版本控制会感觉像是一种自然的方式来理解生产级模型的变更和修改。
- en: 'These are a few key aspects of model versioning that makes it a compelling
    feature to use:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 模型版本控制的几个关键方面使其成为一个引人注目的功能：
- en: You can identify which model version you are using
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以识别您正在使用的模型版本
- en: You can quickly select from the various versions, with clarity from descriptions
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以快速从各种版本中进行选择，并从描述中清晰了解。
- en: You can roll back and select a different model without effort
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以轻松进行回滚并选择不同的模型
- en: 'There are a few ways to register a model. If you are training the model within
    Azure, then you can use the [Python SDK](https://oreil.ly/6CN0h) with the result
    object of a `Run` class:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种注册模型的方法。如果您在Azure内训练模型，那么您可以使用[Python SDK](https://oreil.ly/6CN0h)与`Run`类的结果对象：
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'But you aren’t required to use Azure to train the model. Perhaps you already
    have several models trained, and you are considering moving to Azure to get them
    into production. The Python SDK allows you to register these models as well. Here
    is an example of how to do this with an [ONNX](https://onnx.ai) model that is
    locally available in your system:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 但是您并非必须使用Azure来训练模型。也许您已经训练了几个模型，并且正在考虑迁移到Azure以将它们投入生产。Python SDK还允许您注册这些模型。以下是如何使用在您系统中本地可用的[ONNX](https://onnx.ai)模型的示例：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'One of the refreshing things about Azure is its flexibility. The Python SDK
    is not the only way to register models. This is how to do it with the Azure CLI:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Azure令人振奋的一点是其灵活性。Python SDK并非注册模型的唯一方式。以下是使用Azure CLI的方法：
- en: '[PRE10]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You can iterate over several models and get them registered into Azure quickly
    with some modifications to the previous examples. If you have models available
    via HTTP, you could potentially download them programmatically and send them over.
    Use extra metadata to fill out the tags and descriptions; good descriptions make
    it easier to identify it later. The more automated the process, the better! In
    [Figure 8-4](#Figure-8-4), I’m using the Azure ML Studio to directly upload and
    register an ONNX model, which is also useful for handling a single model.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过对前面示例进行一些修改，快速迭代并将多个模型注册到Azure。如果您的模型通过HTTP可用，您可以通过编程方式下载它们并发送过去。使用额外的元数据填写标签和描述；良好的描述使得以后更容易识别。过程自动化程度越高，效果越好！在[图8-4](#Figure-8-4)中，我使用Azure
    ML Studio直接上传和注册ONNX模型，这对处理单个模型也非常有用。
- en: '![pmlo 0804](Images/pmlo_0804.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0804](Images/pmlo_0804.png)'
- en: Figure 8-4\. Registering a model in Azure
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-4\. 在Azure中注册模型
- en: Versioning Datasets
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集版本控制
- en: 'Similar to registering models, the ability to version a dataset solves one
    of the biggest problems in ML today: enormous datasets that differ slightly are
    hard (and until recently, impossible) to version nicely. Version control systems
    like Git are not a good fit for this task, even though version control systems
    are supposed to help. This mismatch of version control systems that target source
    code changes and enormous datasets has been a thorn when producing reliable and
    reproducible production models.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 与注册模型类似，版本化数据集的能力解决了当今ML中最大的问题之一：稍有不同的巨大数据集很难（甚至直到最近都是不可能的）进行良好的版本控制。像Git这样的版本控制系统不适合这项任务，尽管版本控制系统应该帮助解决问题。版本控制系统专注于源代码变更，而在处理巨大数据集时存在不匹配问题，这一直是生产可靠和可重现的模型的一个障碍。
- en: This is another example of how cloud providers like Azure improve workflows
    with features like dataset versioning. Data is one of the most important pieces
    when crafting an ML pipeline, and since data can go through many rounds of transformations
    and cleaning, it is instrumental to version throughout the steps from raw to clean.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 云提供商如Azure通过功能（例如数据集版本控制）改进工作流程的另一个示例。数据是构建ML流水线时最重要的组成部分之一，因为数据可能经历多轮转换和清理，从原始数据到干净数据的每一步都至关重要。
- en: 'Retrieve the dataset first. In this example, the dataset is hosted over HTTP:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 首先检索数据集。在这个例子中，数据集是通过 HTTP 托管的：
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, register it using the `dataset` object:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用 `dataset` 对象进行注册：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `create_new_version` will incrementally set a newer version of the data,
    even if there is no previous version (versions start at `1`). After registering
    and creating a new version of the dataset, retrieve it by the name and version:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`create_new_version` 将增量设置一个较新的数据版本，即使没有之前的版本（版本从 `1` 开始）。注册并创建数据集的新版本后，按名称和版本检索它：'
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Although it may seem like it, creating a new dataset version *does not mean*
    Azure makes a copy of the whole dataset with the workspace. Datasets use references
    to the data in the storage service.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管看起来似乎是这样，但创建新的数据集版本 *并不意味着* Azure 在工作区中复制整个数据集。数据集使用存储服务中数据的引用。
- en: Deploying Models to a Compute Cluster
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将模型部署到计算集群
- en: In this section, you will configure and deploy a model to a compute cluster.
    Although there are a few steps involved, it is useful to repeat the process a
    few times to get used to them.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将配置并部署模型到一个计算集群。虽然涉及几个步骤，但反复执行这个过程几次会很有用。
- en: Head over to the [Azure ML Studio](https://ml.azure.com) and create a new automated
    ML run by clicking on “New Automated ML run” in the Automated ML section, or directly
    from the main (home) page by clicking the Create New box with the drop-down. For
    this part of the process, you will need a dataset available. If you haven’t registered
    a dataset, you can download one and then select From Local File to register it.
    Follow the steps to upload it and make it available in Azure.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 转到 [Azure ML Studio](https://ml.azure.com) 并通过在自动 ML 部分点击“新自动化 ML 运行”或者直接从主页点击“创建新”框并选择下拉菜单中的选项来创建一个新的自动化
    ML 运行。在此过程的这一部分中，您将需要一个可用的数据集。如果您尚未注册数据集，可以下载一个，然后选择“从本地文件”注册它。按照步骤上传并在 Azure
    中使其可用。
- en: Configuring a Cluster
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置集群
- en: Back on the “Automated ML run” section, select the available dataset to configure
    a new run. Part of configuring requires a meaningful name and description. Until
    this point, all you have configured and made available is the dataset and how
    it should be used and stored. But one of the critical components of a robust deployment
    strategy is to ensure that the cluster is solid enough to train the model (see
    [Figure 8-5](#Figure-8-5)).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 回到“自动化 ML 运行”部分，选择可用的数据集来配置一个新的运行。配置的一部分需要一个有意义的名称和描述。到此时为止，您已经配置并使数据集可用，并确定了它应该如何使用和存储。但是，强大部署策略的关键组成部分之一是确保集群足够稳固以训练模型（参见
    [图 8-5](#Figure-8-5)）。
- en: '![pmlo 0805](Images/pmlo_0805.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0805](Images/pmlo_0805.png)'
- en: Figure 8-5\. Configure an AutoML run
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-5\. 配置自动 ML 运行
- en: At this point, no cluster should be available in the account. Select “Create
    a new compute” from the bottom of the form. Creating a new cluster can be done
    while configuring a run to train a model, or it can be made directly on the Manage
    section under the Compute link. The end goal is to create a robust cluster to
    train your model.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，帐户中不应该有任何集群可用。从表单底部选择“创建新的计算”。可以在配置运行以训练模型时创建新的集群，或者直接在“管理”部分的“计算”链接下进行。最终目标是创建一个强大的集群来训练您的模型。
- en: 'It is worth emphasizing to use meaningful names and descriptions whenever possible
    throughout the many features and products in Azure ML. The addition of these informational
    pieces is critical to capture (and later identify) what the underlying feature
    is about. A useful way to solve this is thinking about these as fields, like when
    writing an email: the *email subject* should capture the general idea about what
    will be in the body. Descriptions are incredibly powerful when you are dealing
    with hundreds of models (or more!). Being organized and clear in naming conventions
    and descriptions goes a long way.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 值得强调的是，在 Azure ML 中的许多功能和产品中尽可能使用有意义的名称和描述。添加这些信息片段对于捕获（以及后来识别）底层特征非常关键。解决这个问题的一个有用方法是将这些视为字段，就像写电子邮件时一样：*电子邮件主题*应该捕捉有关主体将包含什么的一般想法。当您处理数百个模型（或更多）时，描述非常强大。在命名约定和描述中组织和清晰地表达非常重要。
- en: 'There are two significant cluster types: the *Inference Cluster* and the *Compute
    Cluster*. It is easy to feel confused until the underlying systems are known:
    inference clusters use [Kubernetes](https://kubernetes.io) behind the scenes and
    Compute Clusters uses virtual machines. Creating both in Azure ML Studio is straightforward.
    All you need to do is fill out a form, and you get a cluster up and running, ready
    to train some models. After creation, all of them (regardless of the type) are
    available as an option to train your model.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种重要的集群类型：*推断集群*和*计算集群*。在了解底层系统之前，易于感到困惑：推断集群在幕后使用 [Kubernetes](https://kubernetes.io)
    并使用虚拟机的计算集群。在 Azure ML Studio 中创建两者都是直接的。您所需要做的就是填写一个表单，然后就可以运行一个集群，准备训练一些模型。创建完成后，无论类型如何，它们都可用作训练模型的选项。
- en: Although the Kubernetes cluster (Inference) can be used for testing purposes,
    I tend to use a Compute Cluster to try different strategies. Regardless of the
    chosen backend, it is *crucial* to match the workload to the size (and quantity)
    of machines doing the work. For example, in a Compute Cluster you *must* determine
    the minimum number of nodes as well as the maximum number of nodes. When parallelizing
    a model’s training, the number of parallel runs cannot be higher than the maximum
    number of nodes. Correctly determining the number of nodes, how much RAM, and
    how many CPU cores are adequate is more of a trial-and-error workflow. For the
    test run, it is best to start with less, and create clusters with more power as
    needed (see [Figure 8-6](#Figure-8-6)).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Kubernetes 集群（推断）可以用于测试目的，我倾向于使用计算集群来尝试不同的策略。无论选择的后端如何，将工作量匹配到执行工作的机器的大小（和数量）是*至关重要*的。例如，在计算集群中，您*必须*确定节点的最小数量以及节点的最大数量。在并行化模型的训练时，平行运行的数量不能超过节点的最大数量。正确确定节点数量、RAM
    大小和足够数量的 CPU 核心更多地是一个反复试验的工作流程。对于测试运行，最好从少量开始，并根据需要创建更强大的集群（参见 [图 8-6](#Figure-8-6)）。
- en: '![pmlo 0806](Images/pmlo_0806.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0806](Images/pmlo_0806.png)'
- en: Figure 8-6\. Create a Compute Cluster
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-6\. 创建计算集群
- en: I choose `0` as the minimum number of nodes in this figure because it prevents
    getting charged for idle nodes. This will allow the system to scale down to `0`
    when the cluster is unused. The machine type I’ve selected is not very performant,
    but since I’m testing the run, it doesn’t matter that much; I can always go back
    and create a newer cluster.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图中，我选择将节点的最小数量设为`0`，因为这样可以避免因空闲节点而产生费用。这将允许系统在集群闲置时缩减到`0`。我选择的机器类型性能并不是很好，但由于我正在测试运行，这并不是很重要；我随时可以回去创建一个更新的集群。
- en: Note
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The clusters for *training* a model are not the same ones you will use to deploy
    a model for live (or batch) inferencing. It can be confusing because both strategies
    (training and inferencing) use the “cluster” term to refer to the group of nodes
    doing the work.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 用于*训练*模型的集群并非用于部署实时（或批量）推断的集群。这可能会让人感到困惑，因为训练和推断两种策略都使用“集群”术语来指代执行工作的节点组。
- en: Deploying a Model
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署模型
- en: 'Very much like training a model, when the time comes to deploy a model into
    production, you have to be aware of the cluster choices available. Although there
    are a few ways to get this done, there are two key ways to deploy. Depending on
    the type of deployment use case (production or testing), you have to choose one
    that fits the best. Following is an excellent way to think about these resources
    and where they work best:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 与训练模型非常类似，当部署模型到生产环境时，您必须了解可用的集群选择。虽然有几种方法可以完成此操作，但部署的两种关键方法是必须的。根据部署使用情况（生产或测试），您必须选择最合适的方法。以下是关于这些资源及其最佳工作方式的一个很好的思路：
- en: Azure Container Instance (ACI)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 容器实例（ACI）
- en: Best for testing and test environments in general, especially if the models
    are small (under 1 GB in size).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 最适合测试和一般测试环境，特别是模型较小（大小不超过 1 GB）的情况。
- en: Azure Kubernetes Service (AKS)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Kubernetes 服务（AKS）
- en: All the benefits of Kubernetes (scaling in particular) and for models that are
    larger than 1 GB in size.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 Kubernetes 的优点（特别是扩展性），适用于大于 1 GB 大小的模型。
- en: Both of these choices are relatively straightforward to configure for a deployment.
    In Azure ML Studio, go to Models within the Assets section and select a previously
    trained model. In [Figure 8-7](#Figure-8-7), I chose an ONNX model that I’ve registered.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种选择对于部署而言都相对直接。在 Azure ML Studio 中，转到资产部分内的模型，并选择先前训练过的模型。在 [图 8-7](#Figure-8-7)
    中，我选择了一个已注册的 ONNX 模型。
- en: There are a couple of essential parts in the form; I chose *ACS* as the compute
    type, and enabled authentication. This is crucial because once the deployment
    completes, it will not be possible to interact with the container unless you use
    keys to authenticate the HTTP request. Enabling authentication is not required
    but is highly recommended to keep parity between production and testing environments.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在表单中有几个关键部分；我选择了*ACS*作为计算类型，并启用了身份验证。这一点非常重要，因为一旦部署完成，如果不使用密钥进行身份验证的HTTP请求，将无法与容器进行交互。虽然启用身份验证不是必需的，但强烈建议以保持生产和测试环境之间的一致性。
- en: After completing the form and submitting it, the process of deploying the model
    starts. In my example case, I enabled authentication and used ACS. These options
    don’t affect the interaction with the model much, so once the deployment completes,
    I can start interacting with the model over HTTP, ensuring that requests are using
    the keys.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成表单并提交后，模型部署的过程开始。在我的示例中，我启用了身份验证并使用了ACS。这些选项并不会对与模型的交互产生太大影响，因此一旦部署完成，我就可以通过HTTP与模型进行交互，确保请求使用了密钥。
- en: '![pmlo 0807](Images/pmlo_0807.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0807](Images/pmlo_0807.png)'
- en: Figure 8-7\. Deploy a model
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-7\. 部署模型
- en: 'You can find all the details about the deployed model in the Endpoints section.
    The name used for the deployment is listed, which links to a dashboard of the
    deployment details. Three tabs are part of this dashboard: Details, Consume, and
    Deployment Logs. All of these are full of useful information. If the deployment
    completes succesfuly, then the logs will probably not be that interesting. In
    the Details tab, a section will show the HTTP API (displayed as “REST endpoint”).
    Since I enabled authentication, the page will show the value of “Key-based authentication”
    as `true` as shown in [Figure 8-8](#Figure-8-8).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在Endpoints部分可以找到部署模型的所有详细信息。列出了用于部署的名称，该名称链接到部署详细信息的仪表板。该仪表板包含三个选项卡：详细信息、消耗和部署日志。所有这些都充满了有用的信息。如果部署成功完成，那么日志可能不会那么有趣。在详细信息选项卡中，一个部分将显示HTTP
    API（显示为“REST端点”）。由于我启用了身份验证，页面将显示“基于密钥的身份验证”的值为`true`，如[图8-8](#Figure-8-8)所示。
- en: '![pmlo 0808](Images/pmlo_0808.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0808](Images/pmlo_0808.png)'
- en: Figure 8-8\. REST endpoint
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-8\. REST端点
- en: 'Anything that can talk to an HTTP service with authentication enabled will
    work. This is an example using Python (no Azure SDK needed for this); the input
    is using [JSON](https://oreil.ly/Ugp7i) (JavaScript Object Notation), and the
    input for this particular model follows a strict schema that will vary depending
    on the model you are interacting with. This example uses the [Requests](https://oreil.ly/k3YqL)
    Python library:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 任何可以与启用身份验证的HTTP服务进行通信的东西都可以使用。这是一个使用Python的示例（不需要Azure SDK）；输入是使用[JSON](https://oreil.ly/Ugp7i)（JavaScript对象表示），而针对此特定模型的输入遵循一个严格的模式，这将取决于您要交互的模型。这个示例使用了[Requests](https://oreil.ly/k3YqL)
    Python库：
- en: '[PRE14]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Because the service is exposed with HTTP, it allows me to interact with the
    API in any way I choose (like using Python in the previous example). Interacting
    with an HTTP API to interact with the model is compelling because it offers excellent
    flexibility and gets you immediate results since it is a live inferencing service.
    In my case, it didn’t take long to create the deployment to get responses from
    the API. This means I’m leveraging the cloud infrastructure and services to quickly
    try a proof of concept that may end up in production. Trying out models with sample
    data and interacting with them in environments similar to production is key to
    paving the way for robust automation later.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 因为服务使用HTTP公开，这使得我可以以任何我选择的方式与API进行交互（就像在前面的Python示例中使用Python一样）。通过与模型交互的HTTP
    API是非常吸引人的，因为它提供了极大的灵活性，并且由于它是实时推理服务，所以可以立即得到结果。在我的情况下，创建部署并从API获取响应并不需要太长时间。这意味着我正在利用云基础设施和服务快速尝试一个可能最终进入生产的概念验证。使用样本数据尝试模型并在类似生产环境的环境中与其交互，是为后续稳健自动化铺平道路的关键。
- en: 'When all goes well, a JSON response will get back with useful data from the
    prediction. But what happens when things break? It is useful to be aware of the
    different ways this can break and what they mean. In this example, I use input
    that is unexpected for the ONNX model:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 一切顺利时，将返回一个JSON响应，其中包含来自预测的有用数据。但是当事情出错时会发生什么呢？了解可能出现问题的不同方式及其含义非常有用。在这个例子中，我使用了ONNX模型意外的输入：
- en: '[PRE15]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'An HTTP status code of 500 indicates that the service had an error caused by
    invalid input. Make sure that you use the correct keys and authentication methods.
    Most of the errors from Azure will be easy to grasp and fix; here are a few examples
    of how those look:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 状态码 500 表示服务由于无效输入而发生错误。确保使用正确的密钥和身份验证方法。大多数来自 Azure 的错误都很容易理解和修复；这里列举了几个示例：
- en: '`Missing or unknown *Content-Type* header field in the request`'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`请求中缺少或未知的 *Content-Type* 头字段`'
- en: Make sure that the right content type (e.g., JSON) is used and declared in the
    request.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 确保请求中使用和声明了正确的内容类型（例如 JSON）。
- en: '`Method Not Allowed. For HTTP method: GET and request path: /score`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`Method Not Allowed. 对于 HTTP 方法：GET 和请求路径：/score`'
- en: You are trying to make a `GET` request when you probably need a `POST` request
    that sends data.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 当您尝试进行 `GET` 请求时，可能需要发送数据的 `POST` 请求。
- en: '`Authorization header is malformed. Header should be in the form: "Authorization:
    Bearer <token>"`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`Authorization` 头部格式错误。头部应该是这种形式：“Authorization: Bearer <token>”'
- en: Ensure that the header is properly constructed and that it has a valid token.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 确保头部正确构造并包含有效的令牌。
- en: Troubleshooting Deployment Issues
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 故障排除部署问题
- en: One of the many crucial factors for effective MLOps (of course inherited from
    DevOps best practices, covered in [“DevOps and MLOps”](ch01.xhtml#Section-devops-and-mlops))
    is good troubleshooting skills. Debugging or troubleshooting is not a skill that
    you are born with; it takes practice and perseverance. One way I explain this
    skill is by comparing it to walking in a new city and finding your way around.
    Some will say that if I find my bearings with (apparent) ease, then I must have
    some natural ability. But not really. Pay attention to the details, review those
    mental details regularly, and question everything. Never assume.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的 MLOps 的众多关键因素之一（当然继承自 DevOps 最佳实践，详见[“DevOps 和 MLOps”](ch01.xhtml#Section-devops-and-mlops)）是良好的故障排除技能。调试或故障排除并非天生的技能，需要练习和坚持。我解释这种技能的一种方式是将其比作在新城市中四处走动并找到自己的路。有些人会说，如果我能轻松找到自己的方向，那么我一定具备某种天赋。但实际上并非如此。注意细节，定期复习这些心理细节，并质疑一切。不要假设。
- en: 'When finding my bearings, I immediately identify the sun’s position or the
    sea (is that East? Or West?), and take mental notes of landmarks or remarkable
    buildings. Then, I go from beginning to end, reviewing each step mentally: I went
    left at the hotel until the big church where I turned right, across the beautiful
    park, and now I’m at the square. Night settles in, and then there isn’t a sun
    position, and I can’t remember where to go. Was it left here? Or right? I ask
    questions, my friends all tell me left, and I don’t assume they are right. Trust
    but validate. *“If they tell me left, that means I wouldn’t have gotten to the
    park, I’ll go their way, wait for a few blocks, and if there is no park, I will
    backtrack and turn the other way.”*'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在找到自己的方向时，我立即确定太阳的位置或者大海（这是东边？还是西边？），并在心里记下地标或显著建筑物。然后，我从头到尾地回顾每一步：我在酒店左转，直到大教堂右转，穿过美丽的公园，现在我在广场上。夜幕降临，那时太阳不再存在，我记不清该去哪里了。是在这里左转？还是右转？我询问朋友，他们都告诉我左转，但我不敢肯定他们是对的。信任，但要验证。*“如果他们告诉我左转，那意味着我不会到达公园，我会走他们的路，走几个街区，如果没有公园，我会掉头走另一条路。”*
- en: Do not ever assume things. Question everything. Pay attention to details. Trust,
    but verify. If you practice this advice, your debugging will seem like a natural
    skill to your peers. In this section, I get into a few details related to containers
    and containerized deployment in Azure and some of the things you might see come
    up when they are problems. But you can apply the core concepts anywhere.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 绝不要假设事情。质疑一切。注意细节。信任，但要验证。如果您遵循这些建议，您的调试技能将在同行中显得自然。在本节中，我将深入探讨 Azure 中容器及容器化部署的若干细节，并介绍一些可能出现问题时会遇到的情况。但是，这些核心概念可以应用到任何地方。
- en: Retrieving Logs
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检索日志
- en: 'Once you deploy a container, you have a few ways of retrieving logs. These
    are available in Azure ML Studio as well as the command line and the Python SDK.
    Using the Python SDK means only a few lines after initializing the workspace:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 部署容器后，您有几种方法可以检索日志。这些方法在 Azure ML Studio 中以及命令行和 Python SDK 中都是可用的。使用 Python
    SDK 仅需几行代码初始化工作区后：
- en: '[PRE16]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Run that example code with the name of a service you’ve previously deployed,
    and output gets generated with lots of information. Sometimes logs aren’t that
    good and are mostly repetitive. You have to see through the noise and pick up
    the highlights with useful information. In a successful deployment, most of the
    output will not mean much.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 运行该示例代码，使用先前部署的服务名称，会生成大量信息。有时日志并不那么有用，大部分都是重复的。您必须摆脱噪声并捕捉有用信息的亮点。在成功部署中，大多数输出并不会有太多意义。
- en: 'These are some of the logs from deploying an ONNX model (timestamps removed
    for brevity):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是部署ONNX模型时的一些日志（为简洁起见删除了时间戳）：
- en: '[PRE17]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Application Insights
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用洞察
- en: Another aspect of retrieving logs and debugging that is valuable to explore
    is using observability tooling. Observability refers to the means of capturing
    the state of the system (or systems) at any given point in time. That sounds like
    a mouthful, but in short, it means that you rely on tooling like dashboards, log
    aggregation, graphs, and alerting mechanisms to visualize systems as a whole.
    Because the whole theme of observability is filled with tooling and processes,
    it is often complicated to get such a thing into production.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个检索日志和调试的方面是有价值的是使用可观察性工具。可观察性指的是在任何给定时间点捕获系统（或系统）的状态的手段。听起来有些复杂，但简而言之，这意味着您依赖像仪表板、日志聚合、图形和警报机制这样的工具来整体可视化系统。因为可观察性的整体主题充满了工具和流程，通常很难将这样的东西投入到生产中。
- en: Observability is crucial because it isn’t about application logs; it is about
    telling a story about applications when problems arise. Sure, you found a Python
    traceback in a log, but that doesn’t necessarily mean that the Python code needs
    fixing. What if the input expected was a JSON payload from another system, but
    instead, the external system sent an empty file? Why would that happen? Observability
    brings clarity to seemingly chaotic systems. The problems get exponentially more
    complicated when dealing with distributed systems.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 可观察性至关重要，因为它不仅仅关乎应用程序日志；它是在问题出现时讲述应用程序故事的关键。当然，在日志中找到了Python的回溯，但这并不一定意味着Python代码需要修复。如果预期的输入是来自另一个系统的JSON负载，但外部系统却发送了一个空文件，怎么会发生这种情况？可观察性为看似混乱的系统带来了清晰度。在处理分布式系统时，问题变得非常复杂。
- en: It is not uncommon to define a pipeline system for ingesting data into models
    that involve several different steps. Source the data, clean it, remove garbage
    columns, normalize it, and version this new dataset. Suppose all of these are
    being done with the Python SDK and leveraging triggers from Azure. For example,
    new data gets into the storage system, which triggers an [Azure Function](https://oreil.ly/zxv74)
    that executes some Python. In this chain of events, it is difficult to tell a
    story without tooling.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为将数据输入到涉及多个不同步骤的模型的管道系统并不少见。获取数据源，清理数据，删除垃圾列，归一化数据，并对这些新数据集进行版本控制。假设所有这些都是使用Python
    SDK进行，并利用Azure的触发器。例如，新数据进入存储系统，触发一个[Azure Function](https://oreil.ly/zxv74)执行一些Python代码。在这一系列事件中，如果没有工具支持，讲述一个故事将变得困难。
- en: Azure offers the right tooling out-of-the-box with the simplest of calls in
    the SDK. It is called [Application Insights](https://oreil.ly/CnZxv), and it is
    packed with all the graphs and dashboards useful right after enabling it. However,
    it is not only logs or nice graphs that it has to offer. A whole suite of crucial
    data with a highly visual interface is readily available. Response times, failure
    rates, and exceptions—they all get aggregated, timestamped, and graphed.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Azure在SDK中提供了最简单的调用即可提供所需的工具支持。它被称为[应用洞察](https://oreil.ly/CnZxv)，并在启用后立即提供所有有用的图形和仪表板。然而，它不仅仅是日志或漂亮的图形。一个高度可视化界面下提供了一整套关键数据。响应时间、失败率和异常情况——所有这些都会被聚合、时间戳记录和绘制。
- en: 'This is how you enable Application Insights in a previously deployed service:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何在先前部署的服务中启用应用洞察的：
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: When Application Insights is enabled, the API endpoint section in ML Studio
    will display it as shown in [Figure 8-9](#Figure-8-9).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 当启用应用洞察时，ML Studio中的API端点部分将显示如[图8-9](#Figure-8-9)所示。
- en: '![pmlo 0809](Images/pmlo_0809.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0809](Images/pmlo_0809.png)'
- en: Figure 8-9\. Application Insights enabled
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-9\. 已启用应用洞察
- en: Follow the link provided into the dashboard for the service. A plethora of various
    charts and informational sources are available. This image captures a small portion
    of the graphs available for requests made to the deployed model in a container,
    as shown in [Figure 8-10](#Figure-8-10).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 点击提供的链接进入服务仪表板。提供了大量各种图表和信息来源。此图像捕捉了部署模型在容器中接收的请求的一小部分图表，如[图 8-10](#Figure-8-10)所示。
- en: '![pmlo 0810](Images/pmlo_0810.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0810](Images/pmlo_0810.png)'
- en: Figure 8-10\. Application Insights
  id: totrans-162
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-10\. 应用洞察
- en: Debugging Locally
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本地调试
- en: Following the advice of DevOps principles when debugging, you must question
    everything and never assume anything. One technique that is useful to debug problems
    is to run a production service, or in this case, a trained model, in different
    environments. Containerized deployments and containers in general offer that flexibility,
    where something that runs in production in Azure can run locally. When running
    a container locally, which is the same container that runs in production with
    problems, you can do many more things aside from looking at logs. Debugging locally
    (potentially on your machine) is a tremendous asset to grasp and take advantage
    of, while avoiding service disruptions or catastrophic service interruptions.
    I’ve been in several situations where the only option was to “log in to the production
    web server to see what is going on.” This is dangerous and highly problematic.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在调试时遵循 DevOps 原则，您必须质疑一切，绝不能假设任何事情。一种有用于调试问题的技术是在不同环境中运行生产服务，或者在本例中，是在不同环境中运行训练好的模型。容器化部署及容器一般都提供了这种灵活性，可以在本地运行在
    Azure 生产环境中运行的东西。在本地运行容器时，可以做很多事情，除了查看日志外。本地调试（可能在您的计算机上）是一种非常有价值的资产，可以利用，同时避免服务中断或灾难性服务中断。我曾经遇到过几种情况，唯一的选择是“登录到生产
    Web 服务器查看发生了什么”。这是危险且极其棘手的。
- en: 'By being skeptical of issues and problems, it is crucial to attempt to replicate
    the problem. Reproducing the issue is the golden ticket to solving problems. Sometimes,
    to reproduce customer-facing products, I’ve reinstalled operating systems from
    scratch and done deployments in separate environments. Developers jokingly use
    the phrase *“it works on my machine,”* and I bet you that it almost always holds
    true—but in reality, it doesn’t mean anything. The advice to *“question everything”*
    can be applied here: deploy multiple times, in different environments, including
    locally, and try to replicate.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对问题和困难持怀疑态度，尝试复制问题至关重要。复制问题是解决问题的关键。有时，为了复制客户面向的产品，我会从头开始重新安装操作系统，并在不同的环境中进行部署。开发人员开玩笑地使用“它在我的机器上运行”的说法，我敢打赌，几乎总是正确的——但实际上，这并不意味着什么。在这里可以应用“质疑一切”的建议：多次部署，在不同的环境中，包括本地环境，并尝试复制。
- en: 'Although it is unreasonable to expect you have to run Azure’s Kubernetes offering
    locally, the Python SDK does offer facilities to expose a (local) web service
    where you can deploy the same production-grade model, in a container, locally.
    There are a few advantages to this approach that I’ve mentioned already. Still,
    there is another crucial one: most of the Python SDK APIs will work against this
    local deployment *in addition to* all the container tooling commands you can run
    to poke the container at runtime. Operations like retrieving the container logs,
    or getting inside the container to inspect the environment, are all possible and
    seamless.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管希望你在本地运行 Azure 的 Kubernetes 提供的服务是不合理的，Python SDK 提供了一些功能，可以在本地暴露一个（本地）Web
    服务，您可以在其中部署相同的生产级别模型，作为容器运行。这种方法有几个优点我已经提到过。但还有另一个至关重要的优点：大多数 Python SDK API 不仅可用于这种本地部署，*而且*还可以运行针对容器的所有工具命令来在运行时操作容器。诸如检索容器日志或进入容器检查环境等操作都是可能且无缝的。
- en: Note
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Since these operations are dealing with containerized deployments, it is required
    to have [Docker](https://docker.com) installed and running in your environment.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些操作涉及容器化部署，因此需要在您的环境中安装并运行[Docker](https://docker.com)。
- en: 'There are a few steps required to run a service locally. First, you must register
    the model into the current directory:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地运行服务需要几个步骤。首先，您必须将模型注册到当前目录中：
- en: '[PRE19]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next, create an environment, which installs all required dependencies for the
    model to operate within the container. For example, if the ONNX runtime is required,
    you must define it:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个环境，安装所有必需的依赖项，使模型能够在容器内运行。例如，如果需要 ONNX 运行时，必须定义它：
- en: '[PRE20]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'A scoring file (usually named *score.py*) is required to deploy the model.
    This script is responsible for loading the model, defining the inputs for that
    model, and scoring data. Scoring scripts are always specific to the model, and
    there isn’t a generic way to write one for any model. The script does require
    two functions: `init()` and `run()`. Now, create an *Inference Configuration*,
    which brings together the scoring script and the environment:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 部署模型需要一个评分文件（通常命名为 *score.py*）。这个脚本负责加载模型，为该模型定义输入并对数据进行评分。评分脚本始终特定于模型，并且没有通用的方法为任何模型编写评分脚本。该脚本需要两个函数：`init()`
    和 `run()`。现在，创建一个 *推理配置*，它将评分脚本和环境组合在一起：
- en: '[PRE21]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Putting it all together now requires using the `LocalWebservice` class from
    the Python SDK to launch the model into a local container:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将所有内容放在一起需要使用 Python SDK 中的 `LocalWebservice` 类来将模型部署到本地容器：
- en: '[PRE22]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Launching the model will use a container behind the scenes that will run the
    HTTP API exposed at port `9000`. Not only can you send HTTP requests directly
    to `localhost:9000`, but it is also possible to access the container at runtime.
    My container runtime didn’t have the container ready in my system, but running
    the code to deploy locally pulled everything from Azure:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 启动模型将使用后台的容器，该容器将在端口 `9000` 上运行公开的 HTTP API。您不仅可以直接向 `localhost:9000` 发送 HTTP
    请求，还可以在运行时访问容器。我的容器运行时在系统中没有准备好容器，但运行代码在本地部署时从 Azure 拉取了所有内容。
- en: '[PRE23]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now that the deployment finished, I can verify it by running `docker`:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在部署完成了，我可以通过运行 `docker` 来验证它：
- en: '[PRE24]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'I get in the container and can verify that my *score.py* script is there, alongside
    the model:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 进入容器后，我可以确认我的 *score.py* 脚本和模型都在那里：
- en: '[PRE25]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'When trying to deploy, I had some issues with the *score.py* script. The deployment
    process immediately raised errors and had some suggestions:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试部署时，我在 *score.py* 脚本上遇到了一些问题。部署过程立即引发了错误，并提出了一些建议：
- en: '[PRE26]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `init()` function, in this case, needs to accept one argument, and my example
    was not requiring it. Debugging locally and tinkering with a locally deployed
    container with a model is very useful and an excellent way to quickly iterate
    over different settings and changes to the model before trying it out in Azure
    itself.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`init()` 函数需要接受一个参数，而我的示例不需要它。在本地调试并与部署在本地容器中的模型进行调试是非常有用的，也是在尝试在 Azure
    中实施之前快速迭代不同设置和模型更改的绝佳方式。
- en: Azure ML Pipelines
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure ML 管道
- en: 'Pipelines are nothing more than various steps to achieve the desired goal.
    If you have ever worked with a continuous integration (CI) or continuous delivery
    (CD) platform like [Jenkins](https://jenkins.io), then any “pipeline” workflow
    will feel familiar. Azure describes its ML pipelines as a good fit for three distinct
    scenarios: machine learning, data preparation, and application orchestration.
    These have similar setups and configurations while working with different sources
    of information and targets for their completion.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 管道只不过是为实现所需目标而采取的各种步骤。如果您曾经使用过像 [Jenkins](https://jenkins.io) 这样的持续集成（CI）或持续交付（CD）平台，那么“管道”工作流将会很熟悉。Azure
    将其 ML 管道描述为适合三种不同场景：机器学习、数据准备和应用编排。它们具有类似的设置和配置，同时处理不同的信息来源和目标以完成任务。
- en: 'As with most Azure offerings, you can use the Python SDK or Azure ML Studio
    to create pipelines. As I’ve mentioned already, pipelines are *steps* toward achieving
    an objective, and it is up to you how to order those steps for the end result.
    For example, a pipeline may have to deal with data; we’ve covered datasets in
    this chapter already, so retrieve an existing dataset so that a pipeline step
    can get created. In this example, the dataset becomes the input of a Python script,
    forming a distinct *pipeline step*:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数 Azure 提供的服务一样，您可以使用 Python SDK 或 Azure ML Studio 创建管道。如我之前提到的，管道是实现目标的
    *步骤*，您可以决定如何为最终结果排序这些步骤。例如，一个管道可能需要处理数据；我们在本章中已经涵盖了数据集，所以检索现有数据集以便管道步骤可以被创建。在这个例子中，数据集成为
    Python 脚本的输入，形成一个独立的 *管道步骤*：
- en: '[PRE27]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note
  id: totrans-190
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The Azure SDK can change frequently, so be sure to check out the official [Microsoft
    AzureML documentation](https://oreil.ly/28JXz).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Azure SDK 可能会经常更改，因此请务必查看官方的 [Microsoft AzureML 文档](https://oreil.ly/28JXz)。
- en: 'The example uses the `PythonScriptStep`, one of the many different steps available
    as a pipeline step. Remember: pipelines are all about steps working toward an
    objective, and Azure provides different steps for different types of work within
    the SDK and Azure ML Studio. This step is missing a key part, however: the compute
    target. But it is already packed with almost everything needed to do data preparation.
    First, it uses the dataset object and calls `as_named_input`, which the `PythonScriptStep`
    uses as an argument. The script step is a Python class, but it tries to represent
    a command line tool, so the arguments use dashes, and the values to those arguments
    get passed in as items in a list. This is how you retrieve a previously created
    compute target with the SDK:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 示例使用的是`PythonScriptStep`，这是作为管道步骤可用的众多不同步骤之一。请记住：管道是为实现目标而工作的步骤，Azure 在 SDK
    和 Azure ML Studio 中提供了不同的步骤来支持不同类型的工作。然而，这一步骤缺少一个关键部分：计算目标。但它已经包含了几乎完成数据准备所需的所有内容。首先，它使用数据集对象并调用`as_named_input`，这是`PythonScriptStep`用作参数的方法。脚本步骤是一个
    Python 类，但它试图表示一个命令行工具，因此参数使用破折号，这些参数的值作为列表中的项目传递。这是如何使用 SDK 检索之前创建的计算目标的方法：
- en: '[PRE28]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Aside from the compute target, which we’ve already covered in this chapter,
    you can optionally provide a *runtime configuration*, which allows setting environment
    variables to tell Azure how to manage the environment. For example, if you want
    to manage your dependencies instead of having Azure handle it for you, then the
    runtime configuration would be the way to do that. Here is a simplified way to
    set that particular option:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们在本章已经介绍过的计算目标外，您还可以选择提供一个*运行时配置*，允许设置环境变量来告诉 Azure 如何管理环境。例如，如果您想自己管理依赖项而不是让
    Azure 来处理，那么运行时配置将是实现这一目标的方式。以下是设置特定选项的简化方法：
- en: '[PRE29]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Publishing Pipelines
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发布管道
- en: 'I’ve previously made the comparison of continuous integration systems like
    Jenkins to pipelines: many steps working in a coordinated way to accomplish an
    objective. But although other CI/CD systems like Jenkins have this capability,
    one thing that is very tricky to accomplish is to expose these jobs outside of
    the environment. Azure has a straightforward way to achieve this, both via Azure
    ML Studio and with the SDK. Essentially, what happens with the pipeline is that
    it becomes available over HTTP so that any system anywhere in the world can reach
    the pipeline and trigger it.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前曾将像 Jenkins 这样的持续集成系统与管道进行比较：许多步骤协调工作以完成一个目标。但尽管其他 CI/CD 系统像 Jenkins 有这个能力，有一件非常棘手的事情很难实现，那就是将这些作业暴露在环境之外。Azure
    有一种简单的方法来实现这一点，无论是通过 Azure ML Studio 还是使用 SDK。本质上，管道变得通过 HTTP 可用，以便世界上任何地方的任何系统都可以访问管道并触发它。
- en: 'The possibilities then are endless. You are no longer tied to using services,
    pipelines, and triggers from within Azure. Still, your pipeline steps can start
    elsewhere, perhaps in a closed on-premise environment at your company or a public
    source code service like GitHub. This is an interesting flexibility because it
    offers more options, and the constraints of the cloud provider go away. You don’t
    need to create a new pipeline every time you want to publish it. You can encounter
    this in the documentation while trying to find out how to publish a pipeline.
    In this example, a previous experiment and run gets retrieved to publish the pipeline:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 随后的可能性是无限的。您不再局限于在 Azure 中使用服务、管道和触发器。您的管道步骤可以从其他地方开始，也许是在公司的内部环境或像 GitHub 这样的公共源代码服务中。这是一个有趣的灵活性，因为它提供了更多的选择，云提供商的约束消失了。您不需要每次想要发布它时都创建新的管道。在尝试找出如何发布管道的过程中，您可能会在文档中遇到这种情况。在这个例子中，之前的实验和运行被检索出来以发布管道：
- en: '[PRE30]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now that you know how to publish it, you can interact with it over HTTP. These
    API endpoints require authentication, but the SDK has everything you need to get
    the authentication headers needed to make requests:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您知道如何发布它，可以通过 HTTP 与其交互。这些 API 端点需要身份验证，但 SDK 提供了您需要获取身份验证标头以进行请求的一切内容：
- en: '[PRE31]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Azure Machine Learning Designer
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure Machine Learning 设计师
- en: 'For the graphically inclined, the Azure Machine Learning designer is a good
    choice for abstracting away the complexity of building machine learning projects
    on Azure. The process to train a model is as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图形化倾向的人来说，Azure Machine Learning 设计师是在 Azure 上构建机器学习项目时抽象化复杂性的好选择。训练模型的过程如下所示：
- en: Sign in to Azure ML Studio.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录 Azure ML Studio。
- en: Select the Designer interface as shown in [Figure 8-11](#Figure-8-10-2).
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如 [Figure 8-11](#Figure-8-10-2) 所示，选择设计师界面。
- en: '![pmlo 0811](Images/pmlo_0811.png)'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![pmlo 0811](Images/pmlo_0811.png)'
- en: Figure 8-11\. Azure ML designer
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 8-11\. Azure ML 设计师
- en: Select a sample project to explore, like the Automobile Regression project in
    [Figure 8-12](#Figure-8-10-3). Note there are many sample projects to explore,
    or you can build your ML project from scratch. An excellent resource to investigate
    ML Designer sample projects is the official [Microsoft Azure Machine Learning
    designer documentation](https://oreil.ly/NJrfK).
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个样本项目进行探索，比如 [Figure 8-12](#Figure-8-10-3) 中的汽车回归项目。请注意，有许多样本项目可供探索，或者您可以从头开始构建自己的
    ML 项目。研究 ML 设计师样本项目的绝佳资源是官方的 [Microsoft Azure 机器学习设计师文档](https://oreil.ly/NJrfK)。
- en: '![pmlo 0812](Images/pmlo_0812.png)'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![pmlo 0812](Images/pmlo_0812.png)'
- en: Figure 8-12\. Azure ML Designer Automobile Regression project
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 8-12\. Azure ML 设计师汽车回归项目
- en: To run the project, submit a pipeline job as shown in [Figure 8-13](#Figure-8-10-4).
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要运行项目，请提交一个如 [Figure 8-13](#Figure-8-10-4) 所示的管道作业。
- en: '![pmlo 0813](Images/pmlo_0813.png)'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![pmlo 0813](Images/pmlo_0813.png)'
- en: Figure 8-13\. Azure ML designer submission
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 8-13\. Azure ML 设计师提交
- en: The Azure ML designer may seem a bit fancy, but it can play an essential role
    in understanding how the Azure ML Studio ecosystem works. By “kicking the tires”
    on a sample project, you get exposed to all of the essential aspects of Azure
    ML Studio, including AutoML, storage, compute clusters, and reporting. Next, let’s
    talk about how all of this relates to the ML lifecycle on Azure.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Azure ML 设计师可能看起来有点花哨，但在理解 Azure ML Studio 生态系统如何运作方面，它可以发挥关键作用。通过对样本项目进行“试水”，您将接触到
    Azure ML Studio 的所有关键方面，包括 AutoML、存储、计算集群和报告。接下来，让我们讨论所有这些与 Azure 上的 ML 生命周期的关系。
- en: ML Lifecycle
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML 生命周期
- en: In the end, all tooling and services in Azure are there to help with the model
    lifecycle. This methodology is not entirely particular to Azure, but it is useful
    to grasp how these services help you get your models into production. As [Figure 8-14](#Figure-8-11)
    shows, you start with training, which can happen in a Notebook, AutoML, or with
    the SDK. Then you can move on to validation with Azure Designer or Azure ML Studio
    itself. Production deployments can then leverage scaling with Kubernetes while
    keeping attention to problems with Application Insights.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Azure 中的所有工具和服务都旨在帮助模型生命周期。这种方法论并非完全特定于 Azure，但理解这些服务如何帮助您将模型投入生产是很有用的，正如
    [Figure 8-14](#Figure-8-11) 所示，您可以从笔记本、AutoML 或 SDK 进行训练。然后，您可以使用 Azure Designer
    或 Azure ML Studio 进行验证。在生产部署中，可以利用 Kubernetes 进行扩展，同时注意应用洞察中的问题。
- en: '[Figure 8-14](#Figure-8-11) tries to make it clear that this is not a linear
    process, and the constant feedback loop throughout the process of shipping to
    production can require going back to previous steps to address data issues and
    other common problems observed in models. However, the feedback loop and constant
    adjusting is essential for a healthy environment; it is not enough to click a
    checkbox that enables monitoring or that Kubernetes is handling scaling. Without
    consistent evaluation, success is impossible, regardless of the cloud provider.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[Figure 8-14](#Figure-8-11) 试图清楚地表明这不是一个线性过程，并且在整个生产过程中的持续反馈循环可能需要返回到先前的步骤来解决模型中观察到的数据问题和其他常见问题。然而，反馈循环和持续调整对于健康的环境至关重要；仅仅勾选一个启用监控或者
    Kubernetes 处理扩展的复选框是不够的。没有持续的评估，无论云提供商如何，成功都是不可能的。'
- en: '![pmlo 0814](Images/pmlo_0814.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![pmlo 0814](Images/pmlo_0814.png)'
- en: Figure 8-14\. ML lifecycle
  id: totrans-219
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 8-14\. ML 生命周期
- en: Conclusion
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: No doubt Azure is already solving challenging problems related to operationalizing
    machine learning, from registering and versioning datasets to facilitating monitoring
    and deploying live inferencing models on scalable clusters. It all feels relatively
    new, and Azure as a whole is still catching up in functionality to other cloud
    providers—but this shouldn’t matter. The platform of choice (even if it isn’t
    Azure) has to enable workflows with ease; you must leverage what is available.
    You will see repetition and emphasis on some ideas throughout the book about leveraging
    technology and avoiding solving challenges with half-baked solutions. Technology
    reuse will propel any venture. Remember that the most important thing to achieve
    as an MLOps engineer is to ship models to production, not reinvent cloud features.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，Azure已经在解决与操作机器学习相关的复杂问题，从注册和版本化数据集到促进监视和在可扩展集群上部署实时推断模型。这一切都感觉相对较新，整个Azure平台在功能上仍在努力赶超其他云服务提供商，但这并不重要。选择的平台（即使不是Azure）必须能够轻松地支持工作流程；你必须利用现有资源。在本书中，关于利用技术和避免用不成熟的解决方案解决挑战的想法会反复强调。技术的复用将推动任何事业。记住，作为MLOps工程师最重要的是将模型部署到生产环境中，而不是重新发明云功能。
- en: The next chapter will dig into the Google Cloud Platform.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将深入讨论Google Cloud Platform。
- en: Exercises
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Retrieve an ONNX model from a public source and register it in Azure with the
    Python SDK.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从公共来源检索一个ONNX模型，并使用Python SDK在Azure中注册它。
- en: Deploy a model to ACI and create a Python script that returns the model’s response,
    as it comes back from the HTTP API.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署模型到ACI，并创建一个Python脚本，从HTTP API返回模型的响应。
- en: Deploy a container locally, using Azure’s Python SDK, and produce some HTTP
    requests for live inferencing.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Azure的Python SDK在本地部署一个容器，并为实时推理生成一些HTTP请求。
- en: Publish a new pipeline, and then trigger it. The trigger should show the output
    of the `run_id` after a successful request.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布一个新的流水线，然后触发它。触发应该在成功请求后显示`run_id`的输出。
- en: Train a model using Azure AutoML from the Python SDK by grabbing a dataset from
    Kaggle.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Azure Python SDK从Kaggle获取数据集，并使用Azure AutoML训练模型。
- en: Critical Thinking Discussion Questions
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批判性思维讨论问题
- en: 'There are many ways to train models on the Azure platform: Azure ML Studio
    Designer, Azure Python SDK, Azure Notebooks, and Azure AutoML. What are the advantages
    and disadvantages of each?'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Azure平台上有许多训练模型的方式：Azure ML Studio Designer、Azure Python SDK、Azure Notebooks和Azure
    AutoML。各自的优缺点是什么？
- en: Why is it a good idea to enable authentication?
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么启用认证是个好主意？
- en: How can reproducible environments help deliver models?
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可复现的环境如何帮助交付模型？
- en: Describe two aspects of good debugging techniques and why they are useful.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述两个好的调试技术方面及其有用之处。
- en: What are some benefits of versioning models?
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型版本控制的一些好处是什么？
- en: Why is versioning datasets important?
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么数据集的版本控制很重要？
