- en: Chapter 6\. Using BigQuery ML to Train a Linear Regression Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。使用BigQuery ML训练线性回归模型
- en: In this chapter you learn how to build a linear regression model and a neural
    network model from scratch to forecast power plant production. You perform this
    task using SQL for data analysis, Jupyter Notebook for data exploration, and BigQuery
    Machine Learning (BigQuery ML) for training the ML model. Along the way, you learn
    new techniques for understanding your data in preparation for ML and how to apply
    this knowledge in improving your model performance.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习如何从头开始构建线性回归模型和神经网络模型，以预测电厂的生产。您将使用SQL进行数据分析，使用Jupyter Notebook进行数据探索，并使用BigQuery
    Machine Learning（BigQuery ML）来训练ML模型。在此过程中，您将学习准备ML所需的新技术，以及如何将这些知识应用于改善模型性能。
- en: 'The Business Use Case: Power Plant Production'
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 业务用例：电厂生产
- en: Your goal in this project will be to predict the net hourly electrical energy
    output for a combined cycle power plant (CCPP) given the weather conditions near
    the plant at the time.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，您的目标将是根据电厂附近的天气条件预测联合循环发电厂（CCPP）的净每小时电能输出。
- en: A CCPP is composed of gas turbines, steam turbines, and heat recovery steam
    generators. The electricity is generated by gas and steam turbines, which are
    combined in one cycle, and is transferred from one turbine to another. While the
    vacuum is collected from the steam turbine, the other three ambient variables
    (temperature, ambient pressure, and relative humidity) affect the gas turbine
    performance.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: CCPP由燃气轮机、汽轮机和热回收蒸汽发生器组成。电力是由燃气轮机和汽轮机生成的，它们在一个循环中结合，并且从一个涡轮机传递到另一个涡轮机。虽然真空是从汽轮机收集的，但其他三个环境变量（温度、环境压力和相对湿度）影响燃气轮机的性能。
- en: The dataset in this section contains data points collected from a CCPP over
    a six-year period (2006–2011) when the power plant was set to work with a full
    load. The data is aggregated per hour, though the exact hour for the recorded
    weather conditions and energy production is not supplied in the dataset. From
    a practical viewpoint, this means that you will not be able to treat the data
    as sequence or time-series data, where you use information from previous records
    to predict future records.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的数据集包含从CCPP收集的数据点，时间跨度为六年（2006年至2011年），当时发电厂设置为全负荷运行。尽管数据按小时聚合，但未提供记录天气条件和能源生产的确切时间。从实际的角度来看，这意味着您将无法将数据视为序列或时间序列数据，即您无法使用先前记录的信息来预测未来的记录。
- en: The data is initially supplied in a CSV file,^([1](ch06.html#ch01fn2)) so you
    will need to spend some time loading the data into BigQuery before you can explore
    it and ultimately use it to create the ML model. As you will see momentarily,
    there are five columns in our dataset, as shown in [Table 6-1](#the_five_columns_in_the_dataset_the_tar),
    and 9,590 rows.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据最初以CSV文件的形式提供，^([1](ch06.html#ch01fn2))因此，在您能够探索它并最终用它创建ML模型之前，您需要花一些时间将数据加载到BigQuery中。正如您马上会看到的，我们的数据集中有五列，如[表6-1](#the_five_columns_in_the_dataset_the_tar)所示，以及9,590行。
- en: 'Table 6-1\. The five columns in the dataset: the target variable, Energy Production,
    is shown in bold'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 表6-1。数据集中的五列：目标变量“能量生产”以粗体显示
- en: '| Column name | Minimum value | Maximum value |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 列名 | 最小值 | 最大值 |'
- en: '| --- | --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Temperature | 1.81°C | 37.11°C |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 温度 | 1.81°C | 37.11°C |'
- en: '| Ambient pressure | 992.89 millibar | 1,033.30 millibar |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 环境压力 | 992.89 毫巴 | 1,033.30 毫巴 |'
- en: '| Relative humidity | 25.56% | 100.16% |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 相对湿度 | 25.56% | 100.16% |'
- en: '| Exhaust vacuum | 25.36 cm Hg | 81.56 cm Hg |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 排气真空 | 25.36 厘米汞柱 | 81.56 厘米汞柱 |'
- en: '| **Energy production** | 420.26 MW | 495.76 MW |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| **能量生产** | 420.26 MW | 495.76 MW |'
- en: These expected value ranges are well documented by the power plant engineers
    and have been shared with you (say, via a technical report). This will be helpful
    when exploring the data to ensure that there are no issues, such as null values
    or magic numbers, as discussed in [Chapter 4](ch04.html#use_automl_to_predict_advertising_media).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些期望的数值范围已经被电厂工程师充分记录，并且通过技术报告与您分享过（比如通过技术报告）。在探索数据时，这将非常有帮助，以确保没有空值或魔数等问题，正如[第四章](ch04.html#use_automl_to_predict_advertising_media)中所讨论的那样。
- en: Cleaning the Dataset Using SQL in BigQuery
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SQL在BigQuery中清洗数据集
- en: As discussed before, it is important that you understand your dataset before
    beginning the processing of building ML models. Recall that the quality of any
    ML model you train will rely heavily on the quality of the dataset being used
    to train the model. If the dataset is filled with erroneous data or missing values,
    then the ML model will not be able to learn the proper insights.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前讨论的那样，在开始构建机器学习模型的处理过程之前，了解数据集的重要性至关重要。请记住，您训练的任何机器学习模型的质量将严重依赖于用于训练模型的数据集质量。如果数据集中充满错误数据或缺失值，那么机器学习模型将无法学习到正确的见解。
- en: In this section, you will use SQL as the tool of choice and BigQuery as the
    platform. All of the SQL code from this chapter is also available in the [low-code-ai
    repository](https://oreil.ly/supp-lcai). BigQuery is Google Cloud’s solution for
    a serverless data warehouse. Here, *serverless* will mean that you can quickly
    load the data into BigQuery and begin SQL data analysis without having to provision
    any servers. If you are not familiar with SQL, then the [“Prepare Data for Exploration”
    course](https://oreil.ly/zWLKA) by Google on Coursera is a great free starting
    point. [*Learning SQL*](https://learning.oreilly.com/library/view/learning-sql-3rd/9781492057604/)
    (3rd edition) by Alan Beaulieu (O’Reilly, 2020) is a good resource for those wanting
    to dive deeper into using SQL.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将使用 SQL 作为工具，并选择 BigQuery 作为平台。本章中的所有 SQL 代码也可以在 [low-code-ai 代码库](https://oreil.ly/supp-lcai)
    中找到。BigQuery 是 Google Cloud 的无服务器数据仓库解决方案。在这里，“无服务器”意味着您可以快速将数据加载到 BigQuery，并在不需要配置任何服务器的情况下开始
    SQL 数据分析。如果您对 SQL 不熟悉，那么 Google 在 Coursera 上提供的 [“准备探索数据”课程](https://oreil.ly/zWLKA)
    是一个很好的免费起点。Alan Beaulieu 的 [*学习 SQL*](https://learning.oreilly.com/library/view/learning-sql-3rd/9781492057604/)（第三版，O’Reilly，2020）是希望深入使用
    SQL 的人的良好资源。
- en: If you’re not already using BigQuery, it has a free tier that will cover the
    activities within this chapter for linear regression. The first 1 TB of data processed
    by SQL queries per month and 10 GB of storage each month are free. Additionally,
    the first 10 GB of data processed for creating certain types of ML models, such
    as linear regression, are free. If you are interested in doing ML on your data
    stored in BigQuery, then you can use BigQuery ML. BigQuery ML uses resources in
    Vertex AI for training neural network models. If you wish to follow this section
    to train a neural network model in BigQuery ML, you will incur charges against
    a free trial or billing account.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有使用 BigQuery，它有一个免费层，可以覆盖本章中线性回归的活动。每个月通过 SQL 查询处理的前 1 TB 数据和每月的 10 GB
    存储是免费的。此外，用于创建某些类型的机器学习模型（例如线性回归）的前 10 GB 数据处理也是免费的。如果您有兴趣在存储在 BigQuery 中的数据上进行机器学习，则可以使用
    BigQuery ML。BigQuery ML 使用 Vertex AI 中的资源来训练神经网络模型。如果您希望按照本节的指导在 BigQuery ML 中训练神经网络模型，则会针对免费试用或计费账户产生费用。
- en: Loading a Dataset into BigQuery
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据集到 BigQuery
- en: The CCPP dataset is not already available in BigQuery. The first thing that
    you will need to do is load the data into BigQuery. For your convenience, we have
    placed the data into a public Google Cloud Storage bucket (download at *https://oreil.ly/zY85-*).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: CCPP 数据集尚未在 BigQuery 中可用。您需要做的第一件事是将数据加载到 BigQuery 中。为了您的方便，我们已将数据放入了公共 Google
    Cloud Storage 存储桶中（在 *https://oreil.ly/zY85-* 下载）。
- en: To load the data into BigQuery, first open the Google Cloud Console and return
    to the BigQuery SQL workspace. On the left side of the UI, select your project
    name and then click the “View actions” button, the three vertical dots, to the
    right of the project name. Select “Create dataset” as shown in [Figure 6-1](#the_quotation_markcreate_datasetquotati).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要将数据加载到 BigQuery 中，首先打开 Google Cloud 控制台，并返回 BigQuery SQL 工作空间。在 UI 的左侧，选择您的项目名称，然后单击项目名称右侧的“查看操作”按钮（三个垂直点）。选择如
    [图 6-1](#the_quotation_markcreate_datasetquotati) 所示的“创建数据集”选项。
- en: '![The “Create dataset” button in the BigQuery console](assets/lcai_0601.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![BigQuery 控制台中的“创建数据集”按钮](assets/lcai_0601.png)'
- en: Figure 6-1\. The “Create dataset” button in the BigQuery console.
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-1\. BigQuery 控制台中的“创建数据集”按钮。
- en: Ensure that your project is selected under Project ID. For Dataset ID, type
    **`data_driven_ml`** into the box. Select US as the data location. We make this
    choice since the data we will be loading into BigQuery is located in a US-based
    Cloud Storage bucket. Now click Create Dataset. Enter the data into the fields
    as shown in [Figure 6-2](#creating_a_new_dataset_in_the_bigquery).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在“项目 ID”下选择你的项目。对于“数据集 ID”，请在框中键入**`data_driven_ml`**。选择数据位置为美国。我们选择这个选项是因为要加载到
    BigQuery 的数据存储在一个美国云存储桶中。现在点击“创建数据集”。按照 [图 6-2](#creating_a_new_dataset_in_the_bigquery)
    中显示的字段输入数据。
- en: '![Creating a new dataset in the BigQuery console](assets/lcai_0602.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![在 BigQuery 控制台中创建新数据集](assets/lcai_0602.png)'
- en: Figure 6-2\. Creating a new dataset in the BigQuery console.
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-2\. 在 BigQuery 控制台中创建新数据集。
- en: Once the dataset is created, you can use the “View actions” button, as shown
    in [Figure 6-3](#the_quotation_markview_actionsquotation), to create a BigQuery
    table. Select the dataset, click “View actions,” then select “Create table.”
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集创建后，你可以使用“查看操作”按钮（如 [图 6-3](#the_quotation_markview_actionsquotation) 所示）创建
    BigQuery 表。选择数据集，点击“查看操作”，然后选择“创建表”。
- en: '![The “View actions” and “Create table” buttons](assets/lcai_0603.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![“查看操作”和“创建表”按钮](assets/lcai_0603.png)'
- en: Figure 6-3\. The “View actions” and “Create table” buttons.
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-3\. “查看操作”和“创建表”按钮。
- en: You will need to specify where you will load the data from, the file format,
    and the name of the table to be created. These choices are summarized in [Table 6-2](#summary_of_choices_for_creating_a_table).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要指定数据加载的位置、文件格式以及要创建的表的名称。这些选择在 [表 6-2](#summary_of_choices_for_creating_a_table)
    中有总结。
- en: Table 6-2\. Summary of choices for creating a table
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-2\. 创建表选项总结
- en: '| Field | Value |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 字段 | 值 |'
- en: '| --- | --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Create table from | Google Cloud Storage |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 从哪里创建表 | Google Cloud Storage |'
- en: '| Select file from GCS bucket or use a URI pattern | low-code-ai-book/ccpp.csv
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 从 GCS 存储桶选择文件或使用 URI 模式 | low-code-ai-book/ccpp.csv |'
- en: '| File format | CSV |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 文件格式 | CSV |'
- en: '| Table | ccpp_raw |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 表 | ccpp_raw |'
- en: '| Schema | Auto detect |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 模式 | 自动检测 |'
- en: '[Figure 6-4](#the_quotation_markcreate_tablequotation) shows the completed
    “Create table” window with all the required values completed. In your case, the
    CSV has a header and all of the values are floating-point numbers, so you can
    have BigQuery detect the schema from this information.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 6-4](#the_quotation_markcreate_tablequotation) 显示已填写所有必填值的“创建表”窗口。在你的情况下，CSV
    文件具有标题，并且所有值都是浮点数，因此你可以让 BigQuery 根据此信息检测模式。'
- en: '![The “Create table” window with specified values](assets/lcai_0604.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![填写了指定值的“创建表”窗口](assets/lcai_0604.png)'
- en: Figure 6-4\. The “Create table” window with specified values.
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-4\. 填写了指定值的“创建表”窗口。
- en: Leave the default values for “Table type,” “Table partitioning,” and “Clustering.”
    Click the Create Table button to start the load job and create the table for your
    raw data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 保留“表类型”、“表分区”和“聚类”的默认值。点击“创建表”按钮开始加载作业并创建原始数据的表。
- en: Note
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Table partitioning is a method to break larger tables into “smaller tables,”
    or *partitions*, that can be accessed separately via filters. Any partitions that
    are not referenced in a query will not be read, lowering the cost of the query
    and improving the performance. Likewise, clustered tables in BigQuery are tables
    that have a user-defined column sort order using clustered columns. Clustered
    tables can improve query performance and reduce query costs by storing data close
    in the sort order in the same physical location.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 表分区是一种将较大的表拆分为“较小的表”或*分区*的方法，可以通过筛选器分别访问。未在查询中引用的任何分区都不会被读取，从而降低查询成本并提高性能。同样，BigQuery
    中的聚集表是使用聚集列定义的用户定义列排序顺序的表。聚集表通过将数据按排序顺序存储在同一物理位置中来提高查询性能和降低查询成本。
- en: After the table is created, you can see the schema for the table by selecting
    the table and selecting the Schema tab. You can also preview the data in the table
    by selecting the Preview tab. Figures [6-5](#schema_for_the_newly_created_ccpp_raw_t)
    and [6-6](#preview_of_the_ccpp_raw_table) show what you should see in the BigQuery
    console for these steps.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 表创建后，你可以通过选择表并选择“模式”选项卡来查看表的模式。你也可以通过选择“预览”选项卡预览表中的数据。 [图 6-5](#schema_for_the_newly_created_ccpp_raw_t)
    和 [图 6-6](#preview_of_the_ccpp_raw_table) 显示了这些步骤在 BigQuery 控制台中的展示效果。
- en: '![Schema for the newly created ccpp_raw table](assets/lcai_0605.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![新创建的 ccpp_raw 表的模式](assets/lcai_0605.png)'
- en: Figure 6-5\. Schema for the newly created `ccpp_raw` table.
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-5\. 新创建的 `ccpp_raw` 表的模式。
- en: '![Preview of the ccpp_raw table](assets/lcai_0606.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![ccpp_raw表的预览](assets/lcai_0606.png)'
- en: Figure 6-6\. Preview of the `ccpp_raw` table.
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-6\. `ccpp_raw`表的预览。
- en: Exploring Data in BigQuery Using SQL
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SQL在BigQuery中探索数据
- en: Now that the data is loaded into BigQuery, it is time to start exploring the
    data. First check to see if there are any null values. The easiest way to do this
    is using the `IF` function in BigQuery. The `IF` statement, `IF(expr, true_result,
    else_result)`, takes three arguments. The `expr` statement returns a Boolean value
    that determines if it is the `true_result` or the `else_result`. As you may expect,
    if `expr` returns `TRUE` then the `true_result` is returned, else the `else_result`
    is returned.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已加载到BigQuery中，是时候开始探索数据了。首先检查是否有空值的最简单方法是使用BigQuery中的`IF`函数。`IF`语句，`IF(expr,
    true_result, else_result)`，接受三个参数。`expr`语句返回一个布尔值，确定是返回`true_result`还是`else_result`。正如您可能期望的那样，如果`expr`返回`TRUE`，则返回`true_result`，否则返回`else_result`。
- en: Using the Null function to check for null values
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用空值函数检查空值
- en: 'What if you wanted to see if the `Temp` column had any null values? You could
    use the following statement: `IF(Temp IS NULL, 1, 0)`. This will return 1 if `Temp`
    is `NULL` and 0 if `Temp` is not `NULL`. Run the following query, replacing `your-project-id`
    with your Google Cloud project ID, and look at the results:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要查看`Temp`列是否有空值，您可以使用以下语句：`IF(Temp IS NULL, 1, 0)`。如果`Temp`为`NULL`，则返回1，如果`Temp`不为`NULL`，则返回0。运行以下查询，将其中的`your-project-id`替换为您的Google
    Cloud项目ID，并查看结果：
- en: '[PRE0]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you scroll through the results, you will find two 1s in our column of over
    9,000 values. This approach works, but it’s not too efficient, is it ([Figure 6-7](#it_is_inefficient_to_scroll_through_the))?
    Instead, let’s take advantage of the fact that the choice of the `true_result`
    and `else_result` is 1 and 0 respectively.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您浏览结果，您会在超过9,000个值的列中找到两个1。这种方法可行，但效率不高，对吧（[图6-7](#it_is_inefficient_to_scroll_through_the)）？相反，让我们利用`true_result`和`else_result`选择分别为1和0的事实。
- en: '![It is inefficient to scroll through the results to find two 1s in our column
    of over 9,000 values](assets/lcai_0607.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![在超过9,000个值的列中查找两个1的结果效率低下](assets/lcai_0607.png)'
- en: Figure 6-7\. It is inefficient to scroll through the results to find two 1s
    in our column of over 9,000 values.
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-7\. 在超过9,000个值的列中查找两个1的结果效率低下。
- en: 'You can easily compute the number of null values by simply using the `SUM()`
    function instead of scrolling through the list. Run the following query, replacing
    `your-project-id` with your Google Cloud project ID, to compute the number of
    nulls for every column:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`SUM()`函数而不是浏览列表，可以轻松计算空值的数量。运行以下查询，在其中将`your-project-id`替换为您的Google Cloud项目ID，以计算每列的空值数量：
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After running this query, you should see that all columns except `Ambient_Pressure`
    have null values. Compare your results to the results in [Figure 6-8](#results_from_query_counting_null_values).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此查询后，您应该会看到除了`Ambient_Pressure`列外，所有列都有空值。将您的结果与[图6-8](#results_from_query_counting_null_values)中的结果进行比较。
- en: '![Results from query counting null values. All columns except for Ambient_Pressure
    have null values](assets/lcai_0608.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![查询计算空值的结果。除了Ambient_Pressure列外，所有列都有空值](assets/lcai_0608.png)'
- en: Figure 6-8\. Results from query counting null values. All columns except for
    `Ambient_Pressure` have null values.
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-8\. 查询计算空值的结果。除了`Ambient_Pressure`列外，所有列都有空值。
- en: What should be done with the rows containing null values? The easiest approach
    is to simply omit these rows. Another option, explored in [Chapter 7](ch07.html#training_custom_ml_models_in_python),
    is to follow an imputation strategy. *Imputation* is the process of replacing
    missing data with substituted values, often done in such a way that the substituted
    values are realistic within the specific context. In this case, you may not be
    an expert on CCPPs. In the worst-case scenario, the rows containing null values
    will make up around 0.1% of the data. For this reason, simply omitting those rows
    is a very reasonable strategy.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 那些包含空值的行应该如何处理？最简单的方法是简单地省略这些行。另一个选项，在[第7章](ch07.html#training_custom_ml_models_in_python)中探讨，是遵循插补策略。*插补*是将缺失数据替换为替代值的过程，通常以这样的方式进行，使得替代值在特定的上下文中是现实的。在这种情况下，您可能不是CCPP的专家。最坏的情况下，包含空值的行将占数据的大约0.1%。因此，简单地省略这些行是一个非常合理的策略。
- en: When would you want to impute instead of throwing out data? If you have a small
    dataset or if the rows with missing values are a significant percentage of your
    dataset, then throwing out the rows in question could greatly affect your model
    performance. Another issue with removing data that is more subtle is around *bias.*
    Statistical bias refers to a systematic difference in the distribution of your
    data versus the real distribution of the data. If the null values show up for
    a specific subset of examples (say, certain demographics in a marketing dataset),
    then removing the rows with missing values will keep the model from learning important
    information.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在什么情况下您希望填补而不是丢弃数据？如果您的数据集很小，或者缺失值的行在数据集中占据了重要的百分比，那么丢弃这些行可能会严重影响您的模型性能。另一个删除数据的更微妙问题涉及到*偏差*。统计偏差是指您的数据分布与实际数据分布之间的系统性差异。如果空值出现在特定示例的子集中（例如，市场数据集中的某些人口统计学信息），那么删除具有缺失值的行将导致模型无法学习重要信息。
- en: Using the Min and Max functions to determine acceptable data ranges
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Min和Max函数确定可接受的数据范围
- en: 'Next, check to be sure that all of the values are within the expected ranges.
    The easiest way to do this quickly is by using the `MIN` and `MAX` functions.
    Like the `SUM` function, `MIN` and `MAX` are examples of aggregate functions.
    An *aggregate* function is a function that takes in a column, or subset of a column,
    and returns a single value. The `MIN` and `MAX` functions return the minimum and
    maximum values respectively for the column they are applied to. Go ahead and apply
    these functions to the `Temp` column by running the following SQL query, once
    again replacing `your-project-id` with your Google Cloud project ID:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，请确保所有值都在预期范围内。最快速地完成此操作的方法是使用`MIN`和`MAX`函数。与`SUM`函数一样，`MIN`和`MAX`是聚合函数的示例。*聚合*函数是指接受列或列的子集，并返回单个值的函数。`MIN`和`MAX`函数分别返回其应用于的列的最小值和最大值。请继续通过以下SQL查询将这些函数应用于`Temp`列，再次用您的Google
    Cloud项目ID替换`your-project-id`：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You should see that the minimum temperature is 1.81°C, and the maximum temperature
    is 37.11°C (see [Figure 6-9](#the_results_of_the_previous_query_compu)). The good
    news is that this range of values corresponds to the range of values for temperature
    specified earlier. Go ahead and use the same logic to check the range for the
    other columns. Try to write the query yourself this time around, but the query
    is included below the figure in case you get stuck.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到最低温度为1.81°C，最高温度为37.11°C（参见[图 6-9](#the_results_of_the_previous_query_compu)）。好消息是，这一数值范围与先前指定的温度数值范围相符。继续使用相同的逻辑检查其他列的范围。如果这次你遇到困难，可以尝试自己编写查询，但是查询已包含在图像下方。
- en: '![The results of the previous query computing the minimum and maximum values
    of temperature in our dataset](assets/lcai_0609.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![计算数据集中温度的最小值和最大值的上一个查询结果](assets/lcai_0609.png)'
- en: Figure 6-9\. The results of the previous query computing the minimum and maximum
    values of temperature in our dataset.
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-9\. 计算数据集中温度的最小值和最大值的上一个查询结果。
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You can present the results in BigQuery in the JavaScript Object Notation, or
    JSON, format. JSON is a programming language–independent data format that is used
    in many different web applications and products, including BigQuery, for exchanging
    information. An advantage of the JSON format is that it is human-readable and
    stored in text format, so it is easy to work with. An example is shown in [Figure 6-10](#the_minimum_and_maximum_values_of_all_c).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在BigQuery中以JavaScript对象表示法或JSON格式显示结果。JSON是一种与编程语言无关的数据格式，用于许多不同的Web应用程序和产品，包括BigQuery，用于交换信息。JSON格式的优点是它易于阅读，并以文本格式存储，因此易于处理。例如在[图 6-10](#the_minimum_and_maximum_values_of_all_c)中展示了一个示例。
- en: '![The minimum and maximum values of all columns in the ccpp_raw table presented
    in JSON format. Note the anomalous values.](assets/lcai_0610.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![在JSON格式中显示的ccpp_raw表中所有列的最小和最大值。请注意异常值。](assets/lcai_0610.png)'
- en: Figure 6-10\. The minimum and maximum values of all columns in the `ccpp_raw`
    table presented in JSON format. Note the anomalous values.
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-10\. 在JSON格式中显示的`ccpp_raw`表中所有列的最小和最大值。请注意异常值。
- en: If you look carefully, you will see a couple of suspicious values. The minimum
    ambient pressure is 0.0, and the minimum energy production is –1.0\. Based on
    the communicated range of values, and likely common sense, we know that neither
    of these two values make sense. Likely, the –1.0 value is an example of a magic
    number. *Magic numbers* are distinctive unique values that are meant to represent
    something different than a standard meaning. Since –1.0 does not make sense as
    an energy production value, this is likely a magic number to represent missing
    data. Likewise, the value of 0.0 for the minimum ambient pressure is likely an
    example of a default value. *Default values* are often present in applications
    as a way to record a value when none are reported. This is used to avoid some
    issues that can arise with `NULL` values.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仔细查看，您会发现几个可疑的值。最小环境压力是0.0，最小能量产生是-1.0。基于传达的数值范围，以及可能的常识，我们知道这两个值都是不合理的。很可能，-1.0值是一个魔数的例子。*魔数*是用来表示与标准含义不同的独特值。由于-1.0不作为能量产生值而存在，这很可能是一个魔数，用于表示缺失的数据。同样，最小环境压力为0.0很可能是一个默认值的例子。*默认值*通常在应用程序中存在，用于在未报告值时记录一个值。这用于避免一些与`NULL`值相关的问题。
- en: Knowing the ranges of expected values from the technical report, the easiest
    way to ensure that you are avoiding these unrealistic values is to filter based
    on the expected ranges. Note that this will also eliminate the `NULL` values that
    you detected earlier, since those values will also not be inside of the ranges.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 了解技术报告中预期值的范围后，确保避免这些不切实际的值的最简单方法是基于预期范围进行过滤。请注意，这也将消除您之前检测到的`NULL`值，因为这些值也不在这些范围内。
- en: Saving query results using a DDL statement in BigQuery
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用BigQuery中的DDL语句保存查询结果
- en: 'Before writing the query to filter out `NULL` and other unwanted values, it
    is important to think through how the results of that query will be stored for
    use in training an ML model. This can be done by executing a DDL statement in
    BigQuery. DDL stands for *data definition language * and is a syntax for creating
    and modifying objects in datasets such as tables. You will use the `CREATE TABLE`
    statement to create a new table. The basic syntax for the `CREATE TABLE` statement
    in BigQuery is as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写用于过滤`NULL`和其他不需要的值的查询之前，重要的是要考虑如何存储该查询结果以供训练ML模型使用。这可以通过在BigQuery中执行DDL语句来完成。DDL代表*数据定义语言*，是用于在数据集中创建和修改对象（如表）的语法。您将使用`CREATE
    TABLE`语句来创建一个新表。在BigQuery中，`CREATE TABLE`语句的基本语法如下：
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This query will create a new table with the name `table_name` and save the results
    of the `query_statement` as this table. Note that with this statement, if the
    table already exists, it will not be overwritten. If you want to do that, you
    would replace `CREATE TABLE` with `CREATE OR REPLACE TABLE`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此查询将创建一个名为`table_name`的新表，并将`query_statement`的结果保存为此表。请注意，使用此语句时，如果表已经存在，将不会被覆盖。如果您希望这样做，可以将`CREATE
    TABLE`替换为`CREATE OR REPLACE TABLE`。
- en: Now that you know how to save the results of a query using a `CREATE TABLE`
    statement, you can write the query to clean your raw power plant data and save
    the data into a new table—say, `ccpp_cleaned`—for the purpose of training an ML
    model.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经知道如何使用`CREATE TABLE`语句保存查询结果，可以编写查询来清理原始发电厂数据，并将数据保存到一个新表中，比如`ccpp_cleaned`，以便训练ML模型。
- en: 'The query is straightforward, but it can be fairly verbose if written in terms
    of inequalities. However, the operator `BETWEEN` can be leveraged to simplify
    the query. To use `BETWEEN`, you specify a minimum and maximum value by writing
    the following:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 查询很简单，但如果用不等式来写，可能会相当冗长。然而，操作符`BETWEEN`可以简化查询。要使用`BETWEEN`，您需要按以下方式指定最小和最大值：
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If the value you are checking is in the range between `min_value` and `max_value`,
    the statement will return `TRUE`; otherwise, the statement will return `FALSE`.
    For example, here you are looking for `Energy_Production` values between 420.26
    and 495.76\. The value of –1.0 that was discussed earlier is not in this range,
    so it will be filtered out. In particular, we want to only keep values that match
    the ranges shared with us in the technical report.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在检查的值在`min_value`和`max_value`之间的范围内，则语句将返回`TRUE`；否则，语句将返回`FALSE`。例如，在这里，您正在查找`Energy_Production`值在420.26到495.76之间的范围。前面讨论的-1.0值不在此范围内，因此将被过滤掉。特别是，我们希望仅保留与技术报告中共享的范围匹配的值。
- en: 'As before, try to write the query yourself and run it in BigQuery, but if you
    need help, here it is:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，尝试自己编写查询并在 BigQuery 中运行它，但如果需要帮助，这里是：
- en: '[PRE6]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: After executing the query, you can view the metadata for the new table we created
    by going to your project name in the pane on the left side of the BigQuery UI,
    then clicking on the dataset name (`data_driven_ml`), and finally selecting the
    table `ccpp_cleaned`. After opening a tab corresponding to the table, click on
    the Details tab to see the table metadata (see [Figure 6-11](#metadata_for_the_newly_created_ccpp_cle)).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 执行查询后，可以通过在 BigQuery UI 左侧面板中选择项目名称，然后点击数据集名称 (`data_driven_ml`)，最后选择表 `ccpp_cleaned`
    来查看我们创建的新表的元数据。在打开与表对应的选项卡后，点击“详细信息”选项卡查看表的元数据（见 [图 6-11](#metadata_for_the_newly_created_ccpp_cle)）。
- en: '![Metadata for the newly created ccpp_cleaned table. Compare the number of
    rows in this table to the number of rows in ccpp_raw to see how many rows were
    removed.](assets/lcai_0611.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![新创建的 ccpp_cleaned 表的元数据。比较此表中的行数与 ccpp_raw 表中的行数，以查看删除了多少行。](assets/lcai_0611.png)'
- en: Figure 6-11\. Metadata for the newly created `ccpp_cleaned` table. Compare the
    number of rows in this table to the number of rows in `ccpp_raw` to see how many
    rows were removed.
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-11\. 新创建的 `ccpp_cleaned` 表的元数据。比较此表中的行数与 `ccpp_raw` 表中的行数，以查看删除了多少行。
- en: The newly created `ccpp_cleaned` table has 9,576 rows. If you follow the same
    process for the original `ccpp_raw` table, you can see that it has 9,590 rows.
    So that means you filtered out 14 rows from our dataset, or about 0.15% of all
    data. Very little data was lost due to cleaning here! However, a few incorrect
    values, especially if they lead to extreme outliers, can greatly harm model performance.
    So it is a good thing to go through this process.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 新创建的 `ccpp_cleaned` 表有 9,576 行。如果按照相同过程处理原始 `ccpp_raw` 表，可以看到它有 9,590 行。这意味着我们从数据集中过滤掉了
    14 行，约占所有数据的 0.15%。由于清理导致的数据损失很少！然而，一些不正确的值，特别是如果它们导致极端离群值，可能会严重影响模型性能。因此，经过这个过程是件好事。
- en: Note
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注：
- en: In the preceding example, you knew in advance that you wanted to save the results
    of the query and used a DDL statement to create the table immediately. What if
    the decision to save the results was made after running a query? Do you need to
    rerun the query just for the sake of saving the results into a table?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述示例中，你事先知道想要保存查询结果，并使用 DDL 语句立即创建表。如果在运行查询后才决定保存结果怎么办？难道需要重新运行查询只是为了将结果保存到表中吗？
- en: Fortunately, the answer is no. After a query is executed, you can go to Save
    Results on the web console above the result, select BigQuery Table, and then fill
    in the dataset and table names for the table you want to create from these results.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，答案是否定的。在执行查询后，你可以转到 Web 控制台上的“保存结果”，选择 BigQuery 表，然后填写数据集和表名称，以创建这些结果所需的表。
- en: What if you realize later on that you should have saved the results—are you
    out of luck? When you execute a query in BigQuery, the results are stored in a
    temporary table. This table will be retained for 24 hours after the query has
    completed. To access the temporary table, go to the Personal History tab on the
    bottom of the console, click the job corresponding to the query you wish to retrieve
    the results for, and then click “Temporary table.” This table can be queried like
    any other table, and the results can be saved as mentioned.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当你事后意识到应该保存结果时，你会陷入困境吗？在 BigQuery 中执行查询时，结果会存储在临时表中。此表将在查询完成后保留 24 小时。要访问临时表，转到控制台底部的个人历史选项卡，点击与要检索结果的查询对应的作业，然后点击“临时表”。此表可以像其他表一样查询，并且可以保存结果如前所述。
- en: Linear Regression Models
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归模型
- en: Now that you have cleaned the data, you are ready to start training the model,
    right? Not quite. In earlier chapters you have relied on tools like AutoML that
    handled a lot of the feature-selection process for you behind the scenes. Now
    it is up to you in BigQuery ML. You will dive deeper into feature selection and
    engineering in the next project, but for now you will focus on the model type
    you will use for this problem and what criteria you will use for feature selection.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经清理好了，你准备好开始训练模型了吗？还不完全。在早期章节中，你依赖像 AutoML 这样的工具在幕后处理了许多特征选择过程。现在在 BigQuery
    ML 中由你来选择更深入的特征选择和工程化过程，但现在你将专注于为这个问题选择模型类型以及选择特征的标准。
- en: Before you go any further, take a step back and think a little bit more about
    the problem at hand. The goal is to predict the energy production of a CCPP based
    on the temperature, ambient pressure, relative humidity, and exhaust vacuum pressure,
    as you can see in [Figure 6-12](#the_goal_is_to_predict_energy_productio).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步进行之前，请退后一步，更深入地思考手头的问题。目标是根据温度、环境压力、相对湿度和排气真空压力预测CCPP的能源产量，如图[6-12](#the_goal_is_to_predict_energy_productio)所示。
- en: '![The goal is to predict energy production based on temperature, ambient pressure,
    relative humidity, and exhaust vacuum pressure](assets/lcai_0612.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![目标是基于温度、环境压力、相对湿度和排气真空压力预测能源产量](assets/lcai_0612.png)'
- en: Figure 6-12\. The goal is to predict energy production based on temperature,
    ambient pressure, relative humidity, and exhaust vacuum pressure.
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-12\. 目标是基于温度、环境压力、相对湿度和排气真空压力预测能源产量。
- en: 'This is an example of a *regression* problem, since the goal is to predict
    a real number: the energy production of the power plant in megawatts (MW). Though
    BigQuery ML supports many different model types, often the best starting point
    is the simplest one, a linear regression model, where you seek to find the line
    of best fit.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个*回归*问题的示例，因为目标是预测一个实数：以兆瓦（MW）为单位的发电厂能源产量。尽管BigQuery ML支持许多不同的模型类型，通常最好的起点是最简单的一个，即线性回归模型，您寻求找到最佳拟合线。
- en: In [Chapter 4](ch04.html#use_automl_to_predict_advertising_media), you saw a
    simplified example of linear regression. In this chapter, the discussion will
    go a little deeper so that you better understand how the model works (see [Figure 6-13](#a_simple_example_of_linear_regressiondo)).
    This way, you will be better informed when selecting which of our features we
    want to use in training an ML model later in the chapter.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第四章](ch04.html#use_automl_to_predict_advertising_media)中，您看到了线性回归的简化示例。在本章中，讨论将更深入，以便更好地理解模型的工作原理（见图[6-13](#a_simple_example_of_linear_regressiondo)）。这样，当您在本章后面的训练ML模型时，您将能够更明智地选择要使用的特征。
- en: '![A simple example of linear regression. The dots correspond to examples with
    the x value being a feature and the y value being the label. The dotted line represents
    the line of best fit.](assets/lcai_0613.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![线性回归的简单示例。点对应于具有x值作为特征和y值作为标签的示例。虚线代表最佳拟合线。](assets/lcai_0613.png)'
- en: Figure 6-13\. A simple example of linear regression. The dots correspond to
    examples with the x value being a feature and the y value being the label. The
    dotted line represents the line of best fit.
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-13\. 线性回归的简单示例。点对应于具有x值作为特征和y值作为标签的示例。虚线表示最佳拟合线。
- en: 'Suppose you have some number of numeric features, <math><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>x</mi>
    <mi>n</mi></msub></mrow></math> , and you want to predict some real number <math><mi>y</mi></math>
    based on the feature values. Often, <math><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    is used as a shorthand notation to represent the list of features <math><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>x</mi>
    <mi>n</mi></msub></mrow></math> . A *linear regression* model is a function of
    the form:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您有一些数值特征<math><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <mo>.</mo>
    <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>x</mi> <mi>n</mi></msub></mrow></math>，并且您想基于特征值预测一些实数<math><mi>y</mi></math>。通常，<math><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></math>被用作缩写符号来表示特征列表<math><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>x</mi>
    <mi>n</mi></msub></mrow></math>。*线性回归*模型是以下形式的函数：
- en: <math><mrow><mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <msub><mi>w</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>w</mi>
    <mn>1</mn></msub> <mo>×</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mo>.</mo>
    <mo>.</mo> <mo>.</mo> <mo>+</mo> <msub><mi>w</mi> <mi>n</mi></msub> <mo>×</mo>
    <msub><mi>x</mi> <mi>n</mi></msub></mrow></math>
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <msub><mi>w</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>w</mi>
    <mn>1</mn></msub> <mo>×</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mo>.</mo>
    <mo>.</mo> <mo>.</mo> <mo>+</mo> <msub><mi>w</mi> <mi>n</mi></msub> <mo>×</mo>
    <msub><mi>x</mi> <mi>n</mi></msub></mrow></math>
- en: Where <math><mrow><msub><mi>w</mi> <mn>0</mn></msub> <mo>,</mo> <msub><mi>w</mi>
    <mn>1</mn></msub> <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>w</mi>
    <mi>n</mi></msub></mrow></math> are also real numbers, they are called *weights*;
    <math><msub><mi>w</mi> <mn>0</mn></msub></math> is often called the *bias* of
    the model. Of course, you could choose any random weights you want and get a function,
    but how good of a model would that be?
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '-   其中<math><mrow><msub><mi>w</mi> <mn>0</mn></msub> <mo>,</mo> <msub><mi>w</mi>
    <mn>1</mn></msub> <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>w</mi>
    <mi>n</mi></msub></mrow></math>也是实数，称为*权重*；<math><msub><mi>w</mi> <mn>0</mn></msub></math>通常称为模型的*偏置*。当然，你可以选择任意随机的权重并得到一个函数，但这样的模型有多好呢？'
- en: Recall that you used *root mean squared error* (RMSE) in [Chapter 4](ch04.html#use_automl_to_predict_advertising_media)
    to evaluate your regression models, and you can do the same here. Recall the definition
    of RMSE before moving forward. Suppose your dataset <math><mi>D</mi></math> has
    <math><mi>N</mi></math> examples <math><mrow><mo>(</mo> <msup><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup> <mo>,</mo>
    <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup> <mo>)</mo></mrow></math>
    , that is, for feature values <math><msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math> , the corresponding
    label is <math><msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math>
    . The superscript <math><msup><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math>
    denotes that we are looking at the <math><mi>i</mi></math> th example in your
    dataset.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '-   请回忆你在[第四章](ch04.html#use_automl_to_predict_advertising_media)中使用了*均方根误差*（RMSE）来评估你的回归模型，你可以在这里做同样的事情。在继续之前，请回忆RMSE的定义。假设你的数据集<math><mi>D</mi></math>有<math><mi>N</mi></math>个示例<math><mrow><mo>(</mo>
    <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>,</mo> <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>)</mo></mrow></math>，即对于特征值<math><msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math>，相应的标签是<math><msup><mi>y</mi>
    <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math>。上标<math><msup><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math>表示我们正在查看你的数据集中的第<math><mi>i</mi></math>个示例。'
- en: 'Given a model <math><mrow><mi>f</mi> <mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> , the RMSE of the model is the expression:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '-   给定一个模型<math><mrow><mi>f</mi> <mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math>，模型的RMSE表达式是：'
- en: <math><mrow><mi>L</mi> <mrow><mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>D</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mn>1</mn> <mi>N</mi></mfrac> <msqrt><mrow><msub><mo>∑</mo>
    <mi>i</mi></msub> <msup><mrow><mo>(</mo><mi>f</mi><mrow><mo>(</mo><msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>)</mo></mrow><mo>-</mo><msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>)</mo></mrow> <mn>2</mn></msup></mrow></msqrt></mrow></math>
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mi>L</mi> <mrow><mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>D</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mn>1</mn> <mi>N</mi></mfrac> <msqrt><mrow><msub><mo>∑</mo>
    <mi>i</mi></msub> <msup><mrow><mo>(</mo><mi>f</mi><mrow><mo>(</mo><msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>)</mo></mrow><mo>-</mo><msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>)</mo></mrow> <mn>2</mn></msup></mrow></msqrt></mrow></math>
- en: where the sum is over all examples in the dataset <math><mi>D</mi></math> .
    The argument <math><mi>D</mi></math> is included here as a reminder that the RMSE
    depends on the dataset that is being used to compute it, just as much as the model
    that we are evaluating.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '-   这里求和是在数据集<math><mi>D</mi></math>中的所有示例上进行的。包含参数<math><mi>D</mi></math>在此作为提醒，RMSE取决于用于计算它的数据集，就像我们评估的模型一样。'
- en: If you just choose some weights <math><mrow><msub><mi>w</mi> <mn>0</mn></msub>
    <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>w</mi> <mi>n</mi></msub></mrow></math>
    , then how do you know you have the weights that give you the best model? Another
    way to phrase this question is that you want to make the *loss function,* the
    RMSE <math><mrow><mi>L</mi> <mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>D</mi> <mo>)</mo></mrow></math>
    , as small as possible.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '-   如果你只是选择一些权重<math><mrow><msub><mi>w</mi> <mn>0</mn></msub> <mo>,</mo> <mo>.</mo>
    <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>w</mi> <mi>n</mi></msub></mrow></math>，那么你如何知道你拥有给出最佳模型的权重？换句话说，你希望使*损失函数*，RMSE<math><mrow><mi>L</mi>
    <mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>D</mi> <mo>)</mo></mrow></math>尽可能小。'
- en: Note
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '-   注'
- en: Recall that the goal of loss functions is to measure how well your algorithm
    performs on your dataset. In other words, a loss function is a method of evaluating
    how well your [algorithm](https://oreil.ly/CJqzM) models your dataset. If your
    predictions are totally off, your loss function will output a higher number. If
    the predictions are pretty good, it will output a lower number.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，损失函数的目标是衡量你的算法在数据集上表现如何。换句话说，损失函数是评估你的[算法](https://oreil.ly/CJqzM)模型数据集的一种方法。如果你的预测完全不准确，损失函数会输出一个较高的数字。如果预测相当不错，它会输出一个较低的数字。
- en: See [Chapter 4](ch04.html#use_automl_to_predict_advertising_media) for a visual
    explanation of the loss function.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[第四章](ch04.html#use_automl_to_predict_advertising_media)以了解损失函数的可视化解释。
- en: There are two commonly used approaches to determine the appropriate weights
    for a linear regression model. The first is called the *normal equation*. Using
    a dataset and the corresponding labels, solving the normal equation gives an exact
    analytical solution to which weights give the best model for the features that
    have been selected. Many analytics packages and products (including BigQuery)
    include this approach in their toolkits.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种常用方法来确定线性回归模型的适当权重。第一种被称为*正规方程*。使用数据集和相应的标签，解正规方程可以给出最佳模型权重的精确分析解。许多分析包和产品（包括BigQuery）在其工具包中包含此方法。
- en: If there is a nice method to always find the best weights, why is it not always
    used? Well, there are a few reasons. The first is *computational complexity*,
    or how much effort it is to compute. Technically speaking, we say that the computational
    complexity of solving the normal equation is slightly less than <math><mrow><mi>O</mi>
    <mo>(</mo> <msup><mi>n</mi> <mn>3</mn></msup> <mo>)</mo></mrow></math> . What
    does that actually mean? Suppose a dataset is increased from 1,000 to 10,000 examples,
    or tenfold. The amount of work that would need to be done to solve the normal
    equation would increase by roughly a factor of <math><mrow><msup><mn>10</mn> <mn>3</mn></msup>
    <mo>=</mo> <mn>1</mn> <mo>,</mo> <mn>000</mn></mrow></math> ! You can see with
    larger and larger datasets this quickly gets out of hand.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果总有一种好方法可以找到最佳权重，为什么不总是使用呢？好吧，原因有几个。首先是*计算复杂度*，即计算所需的工作量。从技术上讲，我们说解决正规方程的计算复杂度略低于<math><mrow><mi>O</mi>
    <mo>(</mo> <msup><mi>n</mi> <mn>3</mn></msup> <mo>)</mo></mrow></math>。这究竟意味着什么？假设数据集从1,000个例子增加到10,000个例子，即增加十倍。解决正规方程所需的工作量将大约增加一个因子<math><mrow><msup><mn>10</mn>
    <mn>3</mn></msup> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mn>000</mn></mrow></math>！可以看出，随着数据集变得越来越大，这个问题会迅速失控。
- en: Another reason that is a little bit more mathematically subtle is that the computation
    could involve very large numbers. Due to how arithmetic is handled on computers
    (floating-point arithmetic), these large numbers could create an issue in solving
    the normal equation. The technical term for this situation is that the system
    is *ill-conditioned*.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个更加数学上微妙的原因是计算可能涉及非常大的数值。由于计算机处理算术的方式（浮点运算），这些大数值可能在解决正常方程时造成问题。这种情况的技术术语是*病态条件*。
- en: Regardless of the situation, if you have a large number of examples or run into
    issues solving the normal equation, there’s a second approach you can take called
    *gradient descent*. We don’t cover that in detail here, but know that most (if
    not all) ML frameworks have gradient descent and variations of it available for
    use to train your models. To learn more about the basics of gradient descent,
    see the corresponding section in the [“Machine Learning Crash Course”](https://oreil.ly/oSW8e)
    by Google.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 无论情况如何，如果你有大量示例或在解决正规方程时遇到问题，你可以采用称为*梯度下降*的第二种方法。我们这里不详细介绍，但需要知道大多数（如果不是所有）ML框架都提供梯度下降及其变体，用于训练模型。要了解更多关于梯度下降基础知识，请参阅Google的[“机器学习入门课程”](https://oreil.ly/oSW8e)中的相应章节。
- en: Note
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you have a little background working with matrices, then the normal equation
    is not too bad to describe once the notation is set up. The derivation is not
    covered here, but it is a common topic in calculus and linear algebra texts. For
    an example of the derivation using techniques from calculus, see [this blog post](https://oreil.ly/uX9tp).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一些矩阵工作背景，那么一旦符号设置好，正规方程并不难描述。这里没有涵盖推导过程，但这是微积分和线性代数教材中的常见主题。有关使用微积分技术推导的例子，请参阅[此博客文章](https://oreil.ly/uX9tp)。
- en: Feature Selection and Correlation
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征选择和相关性
- en: 'Now that the model type being used (linear regression) has been identified,
    it is time to select the features to be used. Recall that there are four columns
    in your prepared dataset in BigQuery that could be used to predict the energy
    production: `Temp`, `Ambient_Pressure`, `Relative_Humidity`, and `Exhaust_Vacuum`.
    How do you decide which of these features to use?'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在确定了使用的模型类型（线性回归），是时候选择要使用的特征了。请记住，在您准备的BigQuery数据集中有四列可能用于预测能源生产：`Temp`、`Ambient_Pressure`、`Relative_Humidity`和`Exhaust_Vacuum`。那么，如何决定使用哪些特征呢？
- en: 'In general, when selecting features there are three basic guidelines that you
    can follow:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，在选择特征时有三个基本准则可以遵循：
- en: The feature should be related to the problem objective.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征应与问题目标相关。
- en: The feature should be known at prediction time.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征应在预测时已知。
- en: The feature should be numeric, or can be transformed into a numeric value.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征应是数值的，或者可以转换为数值。
- en: These are by no means the only considerations, and you will look at more considerations
    throughout this chapter and later chapters, but they are a great place to get
    started. The third condition is important due to the nature of a linear regression
    model, and most other model types used in practice. When all is said and done,
    an ML model is a mathematical function that takes numeric features as inputs and
    outputs some real number, which then is interpreted depending on the model objective.
    So, either having numeric features or being able to transform the chosen features
    to numeric features is critical from the computational point of view.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这些绝不是唯一需要考虑的因素，您将在本章和后续章节中看到更多考虑因素，但它们是一个很好的起点。第三个条件由于线性回归模型的性质以及实践中使用的大多数其他模型类型而显得重要。当一切都说完了，机器学习模型是一个数学函数，它以数值特征作为输入并输出一些实数，然后根据模型目标进行解释。因此，从计算的角度来看，具有数值特征或能够将所选特征转换为数值特征是至关重要的。
- en: Warning
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Features with numeric values that do not have meaningful magnitudes need to
    be treated differently than those with meaningful magnitudes. Consider a feature
    that records the color of a car as a number, say 0 for red, 1 for blue, 2 for
    silver, etc. It does not make sense to say that silver has twice the value as
    blue. You will see techniques in later chapters, such as one-hot encoding, to
    properly encode features of this type as numeric features with meaningful magnitude.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 数值值特征如果没有有意义的数量级，需要与具有有意义数量级的特征进行区别对待。考虑一个记录汽车颜色的特征作为数字的例子，比如0代表红色，1代表蓝色，2代表银色等。说银色是蓝色的两倍是没有意义的。在后面的章节中，您将看到一些技术，如独热编码，来正确地将这类特征编码为具有有意义数量级的数值特征。
- en: 'Are your features related to the problem objective? Well, this can be a tricky
    question to answer in general. You have to have some level of domain knowledge
    to be able to address this question properly, and even then the answer can be
    rather subtle in certain cases. There are a couple different ways to address this
    issue:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您的特征与问题目标相关吗？这在一般情况下可能是一个棘手的问题。您必须具备一定的领域知识才能适当地回答这个问题，即使如此，答案在某些情况下也可能相当微妙。有几种不同的方法可以解决这个问题：
- en: You can leverage either your own or another expert’s domain expertise.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以利用自己或其他专家的领域专业知识。
- en: You can use statistical methods such as correlation to understand the relationship
    between a feature and an objective.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用统计方法如相关性来理解特征与目标之间的关系。
- en: As for the first approach, for the sake of simplicity, assume that, in the report,
    domain experts communicated that these features were indeed related to the objective.
    This may be an unsatisfying answer, but often as an ML practitioner, you have
    to rely on those who truly understand the domain to guide you toward possible
    features. This should not dissuade you from trying to research the problem domains
    your models address, though! As you work on more problems in a domain, you will
    learn more about the domain and will be able to really gain an intuitive understanding
    of key concepts in that domain. This intuition is another way of bringing human
    insight to your models. This is not only a useful tool, but often a necessary
    component in building robust models for your problems.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 至于第一种方法，为了简单起见，假设在报告中，领域专家确认这些特征确实与目标相关。这可能不是令人满意的答案，但作为机器学习从业者，你必须依靠真正了解领域的人来指导你找出可能的特征。然而，这并不应阻止你尝试研究你的模型所解决的问题领域！随着你在一个领域中处理更多问题，你会更多地了解该领域，并且能够真正直观地理解该领域的关键概念。这种直觉是将人类洞察力带入你的模型的另一种方式。这不仅是一个有用的工具，而且通常是构建解决问题的强大模型所必需的组成部分。
- en: Now to the second approach. Yes, you know that all the features should relate
    to the model objective, but how do you understand this relationship? When you
    are building a model, this “how” is very important in understanding how to utilize
    and transform your features. This process, often called *feature engineering*,
    tends to be one of the most powerful tools you have in improving model performance
    beyond improving the quality and quantity of your data.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来看第二种方法。是的，你知道所有特征都应与模型目标相关，但如何理解这种关系呢？在构建模型时，理解这个“如何”非常重要，因为它能帮助你如何利用和转换你的特征。这个过程通常被称为*特征工程*，它往往是提升模型性能的最强大工具之一，超越了数据的质量和数量。
- en: For linear models, one simple tool that you can use is called *Pearson correlation.*
    Given two (numeric) variables, *X* and *Y*, the Pearson correlation coefficient,
    *Corr(X, Y)*, is a number between –1 and 1 that measures how close the relationship
    between the two variables is to being linear. In particular, if the coefficient
    is exactly 1, then *X* and *Y* have a perfectly linear relationship. That is,
    *Y = m × X + b* for some positive number *m* and *b*. If the coefficient is exactly
    –1, it is the same idea, but now *m* is negative. What about in between? The closer
    the absolute value of the coefficient is to 0, the further away the variables
    are from having a linear relationship. There are several methods available to
    determine the correlation between features. Some examples of scatterplots with
    the corresponding correlation coefficients are shown in [Figure 6-14](#examples_of_scatterplots_and_their_corr).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性模型，你可以使用的一个简单工具称为*Pearson相关系数*。给定两个（数值）变量*X*和*Y*，Pearson相关系数*Corr(X, Y)*是一个介于–1和1之间的数字，用于衡量两个变量之间线性关系的紧密程度。特别地，如果系数恰好为1，则*X*和*Y*具有完全线性关系。也就是说，*Y
    = m × X + b*，其中*m*和*b*是正数。如果系数恰好为–1，则*m*为负数。那么系数在–1到1之间的情况又如何呢？系数的绝对值越接近于0，变量之间的线性关系就越远。有多种方法可用于确定特征之间的相关性。一些示例散点图及其对应的相关系数如图[6-14](#examples_of_scatterplots_and_their_corr)所示。
- en: '![Examples of scatterplots and their corresponding Pearson correlation coefficients](assets/lcai_0614.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![散点图示例及其对应的Pearson相关系数](assets/lcai_0614.png)'
- en: Figure 6-14\. Examples of  scatterplots and their corresponding Pearson correlation
    coefficients; image from [Wikipedia](https://oreil.ly/Demk9) (CC0 license).
  id: totrans-139
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-14\. 示例散点图及其对应的Pearson相关系数；图片来源于[Wikipedia](https://oreil.ly/Demk9)（CC0许可）。
- en: 'The first method is to compute the correlation coefficient for each pair of
    variables. For example, to compute the correlation coefficient in BigQuery between
    the `Temp` column and the `Exhaust_Vacuum` columns, you can use the `CORR` function
    as shown in the following query:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法是计算每对变量之间的相关系数。例如，要在BigQuery中计算`Temp`列和`Exhaust_Vacuum`列之间的相关系数，可以使用如下查询中的`CORR`函数：
- en: '[PRE7]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You will see that the correlation coefficient between the `Temp` and `Exhaust_Vacuum`
    is about 0.844\. How should you interpret this? This says that there is a moderate
    to strong (positive) linear relationship between the two features. From the physical
    perspective, this makes sense, as pressure increases with an increase in temperature
    (assuming all other variables are constant).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现`Temp`和`Exhaust_Vacuum`之间的相关系数约为0.844。你应该如何解释这个结果？这意味着这两个特征之间存在中等到强（正）的线性关系。从物理角度来看，这是有道理的，因为在温度增加时，压力也会增加（假设其他变量保持不变）。
- en: 'You could be a bit more efficient and do one column correlated to multiple
    columns at once—but that will still take time to write the query. For example:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以更高效一些，同时使一列与多列相关，但编写查询仍然需要时间。例如：
- en: '[PRE8]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For a low number of columns, this is not an unreasonable approach. Here we have
    5 columns including our label, so we would need to compute 10 correlation coefficients
    total. This number grows quickly, though, with the number of columns. Of course,
    you could go a step further and create more advanced queries with automation to
    compute all of the correlation coefficients, but this approach is beyond the scope
    of this book.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 对于列数较少的情况，这不是一个不合理的方法。在这里，我们有5列，包括我们的标签，因此总共需要计算10个相关系数。然而，随着列数的增加，这个数字增长得非常快。当然，你可以进一步创建更高级的自动化查询，计算所有相关系数，但这超出了本书的范围。
- en: Google Colaboratory
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Google Colaboratory
- en: Another method is to take advantage of Google Colaboratory, or Google Colab
    for short, to create, plot, and visualize a correlation matrix. In later chapters,
    when introducing ML packages in Python, you will use Colaboratory as an easy way
    to run Python code without having to set up an environment in advance. For now,
    you will see how to bring query results from BigQuery to Google Colab to perform
    exploratory data analysis (EDA) using some basic Python.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是利用Google Colaboratory，或简称Google Colab，创建、绘制和可视化相关矩阵。在后续章节中，当介绍Python中的ML包时，你将使用Colaboratory作为运行Python代码的简便方法，而无需事先设置环境。现在，你将看到如何将BigQuery的查询结果带到Google
    Colab中，使用一些基本的Python进行探索性数据分析（EDA）。
- en: The easiest way to load the data you want from BigQuery is to use built-in connectors
    in Google Colab. BigQuery has a feature to create a templated notebook to load
    the results of a query into the notebook environment. Now you will walk through
    the steps of setting up this environment.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 从BigQuery加载你想要的数据的最简单方法是使用Google Colab中的内置连接器。BigQuery具有创建模板笔记本的功能，以将查询结果加载到笔记本环境中。现在，你将逐步了解设置这种环境的步骤。
- en: 'First, you need to run the query whose results you want to load into the notebook
    environment. In this case, write and run a query that will return the entire cleaned
    dataset. As before, here’s the query in case you need a little help:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，你需要运行查询，以便将其结果加载到笔记本环境中。在这种情况下，编写并运行一个将返回整个清理数据集的查询。与之前一样，这是查询的内容，如果需要一点帮助： '
- en: '[PRE9]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Next, in the same window as the query you just ran, select Explore Data in the
    console (under the Query Editor) and then Explore with Python notebook, as shown
    in [Figure 6-15](#the_explore_with_python_notebook_option).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在刚刚运行的查询的同一个窗口中，选择在控制台中探索数据（在查询编辑器下方），然后选择使用Python笔记本进行探索，如[图6-15](#the_explore_with_python_notebook_option)所示。
- en: '![The Explore with Python notebook option for exploring query results](assets/lcai_0615.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![用于探索查询结果的Explore with Python笔记本选项](assets/lcai_0615.png)'
- en: Figure 6-15\. The Explore with Python notebook option for exploring query results.
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-15\. 用于探索查询结果的Explore with Python笔记本选项。
- en: 'When you select Explore with Python notebook, a templated notebook is created
    in Google Colab that enables you to explore with visualizations or create descriptive
    statistics using boilerplate Python. For creating visualizations, you simply add
    two `import` statements to the first cell (Setup):'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 当你选择使用Python笔记本进行探索时，在Google Colab中创建一个模板笔记本，可以让你通过样板Python进行可视化探索或创建描述性统计。要创建可视化图形，你只需将两个`import`语句添加到第一个单元格（设置）：
- en: '[PRE10]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After these two lines, the first cell should look like the following:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两行之后，第一个单元格应如下所示：
- en: '[PRE11]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now you are ready to run all of the cells that currently exist in the notebook.
    To do so, click the cell and then click the Run Cell button on the left side of
    the cell. You can also press Ctrl+Enter (or Cmd+Enter if you’re using macOS X)
    to execute the cell. Go through the cells one by one and run the cells in order.
    It is important to be sure to run the cells in order and not skip cells to ensure
    that everything runs without issue.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已准备好运行笔记本中当前存在的所有单元格。要执行此操作，请点击单元格，然后点击单元格左侧的“运行单元格”按钮。您还可以按Ctrl+Enter（或者如果您使用的是macOS
    X，则按Cmd+Enter）来执行单元格。逐个浏览单元格并按顺序运行单元格非常重要，不要跳过单元格以确保一切正常运行。
- en: The last cell is precoded to show descriptive statistics, such as `results.describe()`.
    Note that `results` is the DataFrame shown in [Figure 6-16](#an_example_of_the_cell_of_a_generated_n).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个单元格预先编码以显示描述性统计数据，例如`results.describe()`。请注意，`results`是[图6-16](#an_example_of_the_cell_of_a_generated_n)中显示的数据框的名称。
- en: '![An example of the cell of a generated notebook to retrieve the results and
    the first five rows of results](assets/lcai_0616.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![一个生成笔记本单元格的示例，用于检索结果和前五行结果](assets/lcai_0616.png)'
- en: Figure 6-16\. An example of the cell of a generated notebook to retrieve the
    results and the first five rows of results. Only the first three columns are shown
    for the sake of readability.
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-16\. 一个生成笔记本单元格的示例，用于检索结果和前五行结果。出于可读性考虑，仅显示了前三列。
- en: Now you can easily create a *correlation matrix*—an array of the different correlation
    coefficients for every pair of features.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以轻松创建*相关矩阵*——即每对特征的不同相关系数的数组。
- en: To create this matrix, create a new cell by clicking the + Code button above
    the notebook and type in the code **`results.corr().round(2)`**. The `round` method
    is used to round the correlations to two decimal places for improved readability.
    Run the cell as before and compare your results with those in [Figure 6-17](#the_new_code_cell_to_compute_the_correl).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建此矩阵，请点击笔记本上方的+ Code按钮创建一个新单元格，并输入代码 **`results.corr().round(2)`**。`round`方法用于将相关性四舍五入到小数点后两位，以提高可读性。如前所述运行单元格，并将结果与[图6-17](#the_new_code_cell_to_compute_the_correl)中的结果进行比较。
- en: '![The new code cell to compute the correlation matrix and the corresponding
    results](assets/lcai_0617.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![新代码单元格计算相关矩阵及相应结果](assets/lcai_0617.png)'
- en: Figure 6-17\. The new code cell to compute the correlation matrix and the corresponding
    results.
  id: totrans-165
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-17\. 新代码单元格计算相关矩阵及相应结果。
- en: The correlation matrix is easy to read. To find the correlation between two
    features—say, `Temp` and `Ambient_Pressure`—go to the column for `Temp` and the
    row for `Ambient_Pressure` (or vice versa) to find the value. In this case, that
    value is –0.508 (rounded to the nearest thousandth). This means that there is
    a moderate negative correlation between these two features, where decreasing the
    temperature will increase the ambient pressure or vice versa.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 相关矩阵易于阅读。要查找两个特征之间的相关性——比如`Temp`和`Ambient_Pressure`——请转到`Temp`列和`Ambient_Pressure`行（或者反之），以找到该值。在本例中，该值为–0.508（四舍五入到千分之一）。这意味着这两个特征之间存在适度的负相关性，即降低温度将增加环境压力，反之亦然。
- en: 'You can also visualize this matrix with a heat map. To do so, type the following
    code into a new cell and run the cell as before. Note that the two `import` statements
    you added to the first cell of the notebook earlier are needed to run these lines
    of code. The results are shown in [Figure 6-18](#a_correlation_heat_map_for_our_features):'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用热图来可视化这个矩阵。为此，请在一个新单元格中输入以下代码，并像以前一样运行该单元格。请注意，您前面在笔记本的第一个单元格中添加的两个`import`语句是运行这些代码行所必需的。结果显示在[图6-18](#a_correlation_heat_map_for_our_features)中：
- en: '[PRE12]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![A correlation heat map for our features. Darker colors correspond to larger
    negative correlations, and lighter colors to larger positive correlations.](assets/lcai_0618.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![特征的相关性热图。较深的颜色对应较大的负相关性，较浅的颜色对应较大的正相关性。](assets/lcai_0618.png)'
- en: Figure 6-18\. A correlation heat map for our features. Darker colors correspond
    to larger negative correlations, and lighter colors to larger positive correlations.
  id: totrans-170
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-18\. 特征的相关性热图。较深的颜色对应较大的负相关性，较浅的颜色对应较大的正相关性。
- en: 'Work through the following knowledge check on the data you are given before
    moving forward:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，请对您所拥有的数据进行以下知识检查：
- en: Which features have a strong correlation to `Energy_Production`? Why?
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些特征与`Energy_Production`有强相关性？为什么？
- en: Which features have a weak correlation to `Energy_Production`? Why?
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些特征与`Energy_Production`之间的相关性较弱？为什么？
- en: Which features have a moderate correlation to `Energy_Production`? Why?
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些特征与`Energy_Production`之间有中度相关性？为什么？
- en: Warning
  id: totrans-175
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: '*Collinearity* or *multicollinearity* exists when two or more of the predictors
    in a regression model are moderately or highly correlated, for example, meaning
    predictor variables are correlated with each other, making it harder to determine
    the role each of the correlated variables is playing. This means that, mathematically,
    the standard errors are increased. Multicollinearity occurs when there are high
    correlations among predictor variables, leading to unreliable and unstable estimates
    of regression coefficients. Multicollinearity can limit the research conclusions
    that can be drawn, especially when using linear models such as linear regression.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '*共线性*或*多重共线性*是指回归模型中两个或多个预测变量之间存在中度或高度相关的情况，例如，意味着预测变量彼此相关，这使得更难以确定每个相关变量所起的作用。这意味着，在数学上，标准误差会增加。当预测变量之间存在高度相关时，就会出现多重共线性，这会导致回归系数的估计不可靠和不稳定。多重共线性可能会限制可以得出的研究结论，特别是在使用线性回归等线性模型时。'
- en: Plotting Feature Relationships to the Label
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绘制特征与标签的关系图
- en: Performing EDA to visualize the relationship between the features and the label
    is also a great way to understand which features will be most useful for the model.
    You can continue visualizing your data in the same Google Colab notebook you were
    using before.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行探索性数据分析（EDA）来可视化特征与标签之间的关系，也是理解哪些特征对模型最有用的一种方法。您可以继续在之前使用的同一个Google Colab笔记本中可视化您的数据。
- en: 'First, visualize the relationship between the `Temp` feature and the label,
    `Energy_​Pro⁠duction`, by adding the following code to a new cell and running
    the cell. Check your results against the visualization in [Figure 6-19](#a_scatterplot_visualizing_the_relation):'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过将以下代码添加到新单元格并运行该单元格来可视化`Temp`特征和标签`Energy_​Pro⁠duction`之间的关系。将结果与[图 6-19](#a_scatterplot_visualizing_the_relation)中的可视化进行比较：
- en: '[PRE13]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![A scatterplot visualizing the relationship between Temp and Energy_Production.
    The relationship looks like a negative linear relationship.](assets/lcai_0619.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![一个散点图，显示`Temp`和`Energy_Production`之间的关系。该关系看起来是一个负线性关系。](assets/lcai_0619.png)'
- en: Figure 6-19\. A scatterplot visualizing the relationship between `Temp` and
    `Energy_Production`. The relationship looks like a negative linear relationship.
  id: totrans-182
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-19\. 一个散点图，显示`Temp`和`Energy_Production`之间的关系。该关系看起来是一个负线性关系。
- en: 'Now visualize the relationship between the `Ambient_Pressure` feature and the
    label, `Energy_Production`. Try to write the code yourself first, but the solution
    follows in case you need help. Check your results against the visualization in
    [Figure 6-20](#a_scatterplot_visualizing_the_relatio):'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可视化`Ambient_Pressure`特征和标签`Energy_Production`之间的关系。首先尝试自己编写代码，但如果需要帮助，以下是解决方案。将结果与[图 6-20](#a_scatterplot_visualizing_the_relatio)中的可视化进行比较：
- en: '[PRE14]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![A scatterplot visualizing the relationship between Ambient_Pressure and Energy_Production.
    The relationship seems to be vaguely positive, but this is not as clear as it
    was for the Temp feature.](assets/lcai_0620.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![一个散点图，显示`Ambient_Pressure`和`Energy_Production`之间的关系。该关系似乎是模糊正相关，但对于`Temp`特征来说不太明显。](assets/lcai_0620.png)'
- en: Figure 6-20\. A scatterplot  visualizing the relationship between `Ambient_Pressure`
    and `Energy_Production`. The relationship seems to be vaguely positive, but this
    is not as clear as it was for the `Temp` feature.
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-20\. 一个散点图，显示`Ambient_Pressure`和`Energy_Production`之间的关系。该关系似乎是模糊正相关，但对于`Temp`特征来说不太明显。
- en: 'Finally, repeat this process for both the `Relative_Humidity` and the `Exhaust_Vacuum`
    features. As before, the solution code is visualized next, and you should compare
    your results with the visualizations in Figures [6-21](#a_scatterplot_visualizing_the_relati)
    and [6-22](#a_scatterplot_visualizing_the_relations):'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对`Relative_Humidity`和`Exhaust_Vacuum`特征重复此过程。与之前一样，解决方案代码随后可视化，您应将结果与[图 6-21](#a_scatterplot_visualizing_the_relati)和[图 6-22](#a_scatterplot_visualizing_the_relations)中的可视化进行比较：
- en: '[PRE15]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![A scatterplot visualizing the relationship between Relative_Humidity and
    Energy_Production. The relationship seems to be weakly positive, but it is not
    very clear from this visualization.](assets/lcai_0621.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![一个散点图，显示`Relative_Humidity`和`Energy_Production`之间的关系。从这个可视化中看，关系似乎是弱正相关，但不是很清楚。](assets/lcai_0621.png)'
- en: Figure 6-21\. A scatterplot visualizing the relationship between `Relative_Humidity`
    and `Energy_Production`. The relationship seems to be weakly positive, but it
    is not very clear from this visualization.
  id: totrans-190
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-21\. 显示`Relative_Humidity`和`Energy_Production`之间关系的散点图。从这个可视化图中看，它们之间似乎呈现出微弱的正相关，但并不十分清晰。
- en: '[PRE16]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![A scatterplot visualizing the relationship between Vacuum_Pressure and Energy_Production.
    The relationship seems to be a negative linear relationship.](assets/lcai_0622.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![显示`Vacuum_Pressure`和`Energy_Production`之间关系的散点图。从这个可视化图中看，它们之间似乎呈现出负线性关系。](assets/lcai_0622.png)'
- en: Figure 6-22\. A scatterplot visualizing the relationship between `Vacuum_Pressure`
    and `Energy_Production`. The relationship seems to be a negative linear relationship.
  id: totrans-193
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-22\. 显示`Vacuum_Pressure`和`Energy_Production`之间关系的散点图。从这个可视化图中看，它们之间似乎呈现出负线性关系。
- en: To summarize, it appears that there is a strong “inverse” relationship between
    `Temp` and `Energy_Production`—the lower the temperature, the higher the energy
    output. If you refer to your previous correlation matrix in [Figure 6-17](#the_new_code_cell_to_compute_the_correl),
    the correlation between `Temp` and `Energy_Production` is –0.948\. This corresponds
    to what you see in [Figure 6-19](#a_scatterplot_visualizing_the_relation) about
    expecting a negative linear relationship.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，看起来`Temp`和`Energy_Production`之间存在强烈的“反向”关系——温度越低，能量输出越高。如果你参考[图 6-17](#the_new_code_cell_to_compute_the_correl)中的先前相关矩阵，`Temp`和`Energy_Production`的相关性为
    –0.948\. 这与[图 6-19](#a_scatterplot_visualizing_the_relation)中观察到的负线性关系相符。
- en: Recall that your goal is to predict energy production based on temperature,
    ambient pressure, relative humidity, and exhaust vacuum pressure. Should you discard
    the features with weak correlations? This would move you from a multivariate model
    to a univariate model. In essence, you would have one feature (`Temp`) that you
    would use to predict the label (`Energy_Production`). Would this model be generalizable?
    Is there additional data you could collect to determine feature importance to
    energy production? These are questions that you need to ask yourself when presented
    with this scenario. Utilize [Chapter 1](ch01.html#how_data_drives_decision_making_in_mach)’s
    business decision model to assist you.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，你的目标是根据温度、环境压力、相对湿度和排气真空压力来预测能量产出。你是否应该舍弃那些相关性较弱的特征？这将使你从多变量模型转变为单变量模型。实质上，你将只有一个特征
    (`Temp`) 来预测标签 (`Energy_Production`)。这样的模型是否具有泛化能力？是否有额外的数据可以收集，以确定特征对能量生产的重要性？这些是在面对这种情况时需要自问的问题。请利用[第 1 章](ch01.html#how_data_drives_decision_making_in_mach)的业务决策模型来帮助你。
- en: The CREATE MODEL Statement in BigQuery ML
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BigQuery ML 中的 CREATE MODEL 语句
- en: In this section you will use BigQuery ML to create a linear regression model
    that uses all of the features in your power plant dataset. As you will see, now
    that you have prepared your data the process is very straightforward.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将使用 BigQuery ML 创建一个线性回归模型，该模型使用电厂数据集中的所有特征。如你所见，现在你已经准备好数据，这个过程非常简单。
- en: Using the CREATE MODEL statement
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 CREATE MODEL 语句
- en: 'Return to the BigQuery console. Enter the following SQL statements in the BigQuery
    Editor window to create a linear regression model:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 返回 BigQuery 控制台。在 BigQuery Editor 窗口中输入以下 SQL 语句以创建线性回归模型：
- en: '[PRE17]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: A few things to note about the notation before executing the query. The `CREATE
    OR REPLACE MODEL` statement will create a new ML model, or replace a model of
    the same name, in the `data_driven_ml` dataset called `energy_production`. ML
    models in BigQuery are objects in datasets like tables. Two options are specified
    for the `CREATE OR REPLACE MODEL` statement. The first option, `model_type`, specifies
    the model type (here linear regression using `linear_reg`). The second option,
    `input_label_cols`, is where you specify the column that serves as your label.
    In this case, that is the `Energy_Production` column.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行查询之前，请注意一些符号的表示法。`CREATE OR REPLACE MODEL` 语句将在 `data_driven_ml` 数据集中创建一个新的
    ML 模型，名为 `energy_production`。BigQuery 中的 ML 模型是数据集中的对象，类似于表。`CREATE OR REPLACE
    MODEL` 语句指定了两个选项。第一个选项 `model_type` 指定模型类型（这里使用 `linear_reg` 进行线性回归）。第二个选项 `input_label_cols`
    是你指定作为标签的列。在这个案例中，即 `Energy_Production` 列。
- en: Now run the query to train the model. It should only take a few minutes. Wait
    for the model to finish training before moving to the next step.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在运行查询以训练模型。这只需要几分钟的时间。在进行下一步之前，请等待模型训练完成。
- en: View evaluation metrics of the trained model
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查看训练模型的评估指标
- en: You can see the model metrics in the console. After the model table is created,
    select the Evaluation tab to see the evaluation metrics. An example of these evaluation
    metrics is shown in [Figure 6-23](#evaluation_metrics_for_the_linear_regre). Note
    that the metrics that you see may slightly differ from the figure.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在控制台中看到模型评估指标。创建模型表后，选择“评估”选项卡以查看评估指标。这些评估指标的示例在[图 6-23](#evaluation_metrics_for_the_linear_regre)中展示。请注意，您看到的指标可能与图中稍有不同。
- en: '![Evaluation metrics for the linear regression model predicting energy production](assets/lcai_0623.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![线性回归模型预测能源产量的评估指标](assets/lcai_0623.png)'
- en: Figure 6-23\. Evaluation metrics for the linear regression model predicting
    energy production.
  id: totrans-206
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-23\. 预测能源产量的线性回归模型的评估指标。
- en: 'The `ML.EVALUATE` function also provides evaluation metrics. Run the following
    SQL query to return the evaluation metrics for your model:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`ML.EVALUATE` 函数还提供评估指标。运行以下 SQL 查询以返回模型的评估指标：'
- en: '[PRE18]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The output in JSON format is shown in [Figure 6-24](#output_of_the_mldotevaluate_commanddot).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 以 JSON 格式显示的输出在[图 6-24](#output_of_the_mldotevaluate_commanddot) 中。
- en: '![Output of the ML.EVALUATE command. The explained_variance output is the only
    output not included in the console.](assets/lcai_0624.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![ML.EVALUATE 命令的输出。详细方差输出是控制台中未包含的唯一输出。](assets/lcai_0624.png)'
- en: Figure 6-24\. Output of the `ML.EVALUATE` command. The `explained_variance`
    output is the only output not included in the console.
  id: totrans-211
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-24\. `ML.EVALUATE` 命令的输出。`explained_variance` 输出是控制台中未包含的唯一输出。
- en: As you can see, the output from the console and the `ML.EVALUATE` function are
    the same—except for one additional output. The `ML.EVALUATE` function also provides
    a metric called “explained variance” via the `explained_variance` column. Explained
    variance can be thought of as an answer to the question, “How much of the variance
    in the label does our model capture in its outputs?” We will not delve into the
    exact details here, but if the average label value and average predicted value
    are the same, then we expect explained variance and the R² score to be the same.
    This is called an *unbiased estimator*, and linear regression is such an example.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台和 `ML.EVALUATE` 函数输出可以看出，除了一个额外的输出之外，它们是相同的。`ML.EVALUATE` 函数还通过 `explained_variance`
    列提供了一种被称为“解释方差” 的度量。解释方差可以被看作是对这个问题的回答：“我们的模型在其输出中捕捉了标签中多少方差？” 我们这里不会深入讨论确切细节，但如果平均标签值和平均预测值相同，那么我们期望解释方差和
    R² 得分相同。这被称为*无偏估计器*，线性回归就是这样一个例子。
- en: Why are those scores different here? Because you are not evaluating the model
    on our training dataset! On the evaluation dataset, as long as the evaluation
    dataset and training dataset are statistically similar, you only expect that these
    metrics are close to each other. BigQuery ML automatically splits your dataset
    into training and evaluation datasets when you train your model, but there are
    options for having more control on how the data is split that are explored in
    [Chapter 7](ch07.html#training_custom_ml_models_in_python).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这些分数在这里不同？因为您没有在我们的训练数据集上评估模型！在评估数据集上，只要评估数据集和训练数据集在统计上相似，您就只期望这些指标彼此接近。BigQuery
    ML 在训练模型时会自动将数据集分成训练和评估数据集，但有一些选项可以更好地控制数据如何分割，详见[第 7 章](ch07.html#training_custom_ml_models_in_python)。
- en: Using the ML.PREDICT function to serve predictions
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 `ML.PREDICT` 函数提供预测
- en: Now that you have trained your model and explored the evaluation metrics, what
    is next? The ultimate goal of ML is to serve predictions for your use cases, not
    to simply train the best model possible. Once you have a model whose performance
    you are happy with in BigQuery ML, serving predictions with that model is very
    straightforward using the `ML.PREDICT` function. Note that `ML.PREDICT` will only
    work for predictions on data that is available to BigQuery for processing.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经训练了您的模型并探索了评估指标，接下来是什么？ML 的终极目标是为您的用例提供预测，而不仅仅是训练最好的模型。一旦您在 BigQuery ML
    中拥有性能满意的模型，使用 `ML.PREDICT` 函数非常简单地为该模型提供预测。请注意，`ML.PREDICT` 仅适用于 BigQuery 可用于处理的数据的预测。
- en: 'Suppose you want to know the power production during an hour where the temperature
    is on average 27.45°C, the ambient pressure is 1,001.23 millibar, relative humidity
    is 84%, and the exhaust vacuum pressure is 65.12 cm Hg. You could run the following
    query to compute this prediction:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您想要了解在平均气温为27.45°C、环境压力为1,001.23毫巴、相对湿度为84%、排气真空压力为65.12厘米汞柱的一个小时内的发电量。您可以运行以下查询来计算此预测：
- en: '[PRE19]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note that the second `SELECT` statement includes the feature values for the
    predicted energy production. It is a best practice to alias the columns using
    the `AS` keyword to ensure that values are plugged in appropriately to the model.
    Note that if you include extra columns that do not correspond to features, then
    they will simply be passed through to the result. This can be useful when you
    want to include the predicted label as a column in a result table, but also want
    to include columns that are not used in the model.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，第二个`SELECT`语句包括了预测能量产量的特征值。使用`AS`关键字为列命名是一种最佳实践，以确保将值适当地传递给模型。请注意，如果包含了不对应特征的额外列，则它们将简单地传递到结果中。这在您想将预测标签作为结果表中的一列时非常有用，但又希望包含未用于模型的列时尤为如此。
- en: Compare your results with the results in [Figure 6-25](#the_results_of_the_mldotpredict_functio),
    but note that the predicted label from your model may slightly differ from what
    is presented here. The column `predicted_label` contains the predicted energy
    production.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 与[图 6-25](#the_results_of_the_mldotpredict_functio)中的结果进行比较，但请注意，您模型预测的标签可能会略有不同。列`predicted_label`包含了预测的能量产量。
- en: '![The results of the ML.PREDICT function. The predicted energy production for
    the given feature values was 433.35 MW.](assets/lcai_0625.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![ML.PREDICT函数的结果。给定特征值的预测能量产量为433.35兆瓦。](assets/lcai_0625.png)'
- en: Figure 6-25\. The results of the `ML.PREDICT` function. The predicted energy
    production for the given feature values was 433.35 MW.
  id: totrans-221
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-25\. `ML.PREDICT`函数的结果。给定特征值的预测能量产量为433.35兆瓦。
- en: 'The method that you did here is great for single predictions, but what if you
    wanted to predict on a table of feature values instead? You can use the `ML.PREDICT`
    function to serve predictions on tables just as well. You can replace the second
    `SELECT` statement in the preceding example to specify a table as a result instead
    of a single row. For example:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 您在此处所做的方法非常适合单个预测，但如果您想要预测一个特征值表呢？您可以使用`ML.PREDICT`函数来在表格上进行预测，效果同样出色。您可以用一个表格替换前面示例中的第二个`SELECT`语句，以指定表格作为结果而不是单个行。例如：
- en: '[PRE20]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Queries of this form turn BigQuery into a wonderful tool for batch predictions,
    which is where you need predictions on a large number of instances at once.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这种形式的查询将BigQuery转变为一个批量预测的绝佳工具，这正是您需要一次性对大量实例进行预测的地方。
- en: Introducing Explainable AI
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入可解释人工智能
- en: 'In the past decade, with the growth of deep learning and more complex models
    in general, *explainable AI* (or XAI for short) has become a quickly growing field
    of research. The goal of XAI is to describe a model’s behavior in human-understandable
    terms. This understanding can be used in many different ways: improving the model’s
    performance, understanding issues with the model, ensuring that the model avoids
    certain biases for compliance or ethical reasons, and many other use cases. This
    section gives a quick introduction in the context of working in BigQuery ML.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的十年中，随着深度学习和更复杂的模型的增长，*可解释人工智能*（或简称为XAI）已成为一个快速发展的研究领域。XAI的目标是用人类可理解的术语描述模型的行为。这种理解可以用在许多不同的方式上：提高模型的性能，理解模型存在的问题，确保模型避免特定偏见以符合或保持伦理原因，以及许多其他用例。本节内容在BigQuery
    ML的工作环境中进行了快速介绍。
- en: When discussing XAI, often one discusses either local or global explanations.
    Local explanations focus on a single instance or maybe a small group of instances.
    You can think of the goal here as being “Why did my model give this prediction
    for this specific example?” Global predictions look at the model’s behavior as
    a whole over a certain dataset. For example, to answer the question, “Which features
    tend to contribute the most to this model’s predictions?” you could use global
    explanations.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 当讨论XAI时，通常会讨论局部或全局解释。局部解释聚焦于单个实例或可能是一小组实例。您可以将此目标看作是“为什么我的模型对于这个具体示例给出了这个预测？”全局解释则查看模型在某个数据集上的整体行为。例如，要回答“哪些特征往往对该模型的预测贡献最大？”这个问题，您可以使用全局解释。
- en: How do you compute these explanations? Most methods are used *post hoc*, that
    is, after the model has been trained. These methods can be specific to certain
    model types or agnostic to the model being used. In general, post hoc methods
    take a specific dataset (say, your evaluation dataset) and use how the model behaves
    on this dataset and perturbations to give explanations.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如何计算这些解释？大多数方法都是 *post hoc* 使用的，即在模型训练后。这些方法可以针对特定的模型类型，也可以对使用的模型不可知。一般来说，后续方法使用一个特定的数据集（例如，评估数据集），并利用模型在此数据集上的行为和扰动来提供解释。
- en: Some models are intrinsically explainable, such as linear regression models.
    In this case, the explanations can be derived directly from the model itself without
    the need to use a separate dataset. There is a trade-off, however. In general,
    the more complex models are less intrinsically explainable. More complex model
    types, such as deep neural networks used in most image and language models, are
    impossible to explain from the model definition, and you must rely on post hoc
    methods.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一些模型本质上是可解释的，比如线性回归模型。在这种情况下，可以直接从模型本身推导出解释，而无需使用单独的数据集。然而，存在一种权衡。一般来说，复杂模型的本质解释性较低。例如，大多数图像和语言模型中使用的深度神经网络等更复杂的模型类型，无法从模型定义中解释，必须依赖后续方法。
- en: You will see some of these methods along the way in this chapter and the following
    chapters, but for a more careful dive into these concepts, [*Explainable AI for
    Practitioners*](https://learning.oreilly.com/library/view/explainable-ai-for/9781098119126/)
    by Michael Munn and David Pitman (O’Reilly, 2022) is a great resource.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 本章及其后续章节中将看到一些这些方法的应用，但是要深入了解这些概念，[*Explainable AI for Practitioners*](https://learning.oreilly.com/library/view/explainable-ai-for/9781098119126/)
    由 Michael Munn 和 David Pitman（O’Reilly，2022）是一个很好的资源。
- en: Explainable AI in BigQuery ML
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BigQuery ML 中的可解释 AI
- en: 'While the `ML.EVALUATE` function provides evaluation metrics, BigQuery also
    offers a function that provides a way to explain the model and the predictions
    it produces. Global and local explanations available in BigQuery use Google Cloud’s
    Explainable AI service. Explainable AI in BigQuery provides “feature attributions”
    that show which input features are most important to your model overall and for
    specific predictions. To compute global explanations, you will need to modify
    the `CREATE MODEL` query and add one additional option enabling global explainability:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `ML.EVALUATE` 函数提供评估指标，但 BigQuery 还提供了一个功能，用于解释模型及其产生的预测。BigQuery 中的全局和局部解释使用
    Google Cloud 的可解释 AI 服务。BigQuery 中的可解释 AI 提供“特征归因”，显示对整体模型和特定预测最重要的输入特征。要计算全局解释，您需要修改
    `CREATE MODEL` 查询并添加一个额外选项以启用全局可解释性：
- en: '[PRE21]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Global explainability returns the feature’s overall influence on the model,
    often obtained by aggregating the feature attributions over the entire dataset.
    A higher absolute value indicates the feature had a greater influence on the model’s
    predictions.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 全局解释返回特征对模型的整体影响，通常通过对整个数据集的特征归因进行聚合获得。较高的绝对值表明特征对模型预测的影响更大。
- en: Local explanations can be computed without enabling global explanations. You
    will see examples of both in what follows.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在不启用全局解释的情况下计算局部解释。接下来的内容中将展示两者的例子。
- en: Modifying the CREATE MODEL statement
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 修改 CREATE MODEL 语句
- en: 'Copy the original `CREATE OR REPLACE MODEL` query into a new query window.
    Modify the query by adding the statement `enable_global_explain=TRUE` as shown
    here:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 将原始 `CREATE OR REPLACE MODEL` 查询复制到新的查询窗口中。按照以下方式修改查询，添加语句 `enable_global_explain=TRUE`：
- en: '[PRE22]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Run this altered query to train a new version of the model with global explanations
    enabled. This should only take a few minutes. Wait until the model has finished
    training before moving on to the next step.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 运行修改后的查询以训练启用全局解释的新版本模型。这只需几分钟时间。在模型训练完成之前，请等待再进行下一步操作。
- en: Using the ML.GLOBAL_EXPLAIN function
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 ML.GLOBAL_EXPLAIN 函数
- en: 'To see the explanations, you can create a basic “`SELECT * FROM`” SQL statement.
    The difference here is the `FROM` statement. Rather than the `FROM` statement
    referencing the project ID, dataset, and table, the `FROM` statement is modified
    as shown in the following code. The `ML.GLOBAL_EXPLAIN` function calls the model
    itself (in this case, “`energy_production`”) to retrieve the results. Run the
    following query in the BigQuery console to explore this for yourself:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看解释，您可以创建一个基本的“`SELECT * FROM`”SQL语句。 这里的不同之处在于`FROM`语句。 与`FROM`语句引用项目ID、数据集和表不同，`FROM`语句被修改如下代码所示。
    `ML.GLOBAL_EXPLAIN`函数调用模型本身（在本例中为“`energy_production`”）以检索结果。 在BigQuery控制台中运行以下查询来探索这个问题：
- en: '[PRE23]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[Figure 6-26](#mldotglobal_explain_returns_the_global) contains the query results
    and shows the features with the largest importance scores for your model overall.
    Based on the earlier analysis of features using correlation, you would expect
    that the `Temp` feature would have the largest attribution score, and this is
    confirmed here.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-26](#mldotglobal_explain_returns_the_global)包含查询结果，并显示了您模型整体中重要性评分最高的特征。
    基于先前使用相关性分析功能的特征分析，您预计`Temp`特征将具有最大的归因分数，这在这里得到了确认。'
- en: '![ML.GLOBAL_EXPLAIN returns the global feature attributions obtained by taking
    the mean absolute attribution that each feature receives for all the rows in the
    evaluation dataset](assets/lcai_0626.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![ML.GLOBAL_EXPLAIN返回通过对评估数据集中每行收到的平均绝对归因进行取得的全局特征归因](assets/lcai_0626.png)'
- en: Figure 6-26\. `ML.GLOBAL_EXPLAIN` returns the global feature attributions obtained
    by taking the mean absolute attribution that each feature receives for all the
    rows in the evaluation dataset.
  id: totrans-245
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-26。 `ML.GLOBAL_EXPLAIN`返回通过对评估数据集中每行收到的平均绝对归因进行取得的全局特征归因。
- en: Using the ML.EXPLAIN_PREDICT function to compute local explanations
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用`ML.EXPLAIN_PREDICT`函数计算局部解释
- en: 'Recall our earlier example: you wanted to know the power production during
    an hour where the temperature is on average 27.45°C, the ambient pressure is 1,001.23
    millibar, relative humidity is 84%, and the exhaust vacuum pressure is 65.12 cm
    Hg. You used the `ML_PREDICT` function to predict that the energy production would
    be 433.35 MW for this hour. You expect that temperature will have the greatest
    impact based on the global feature attributions for your model. However, global
    explanations in general aggregate over an entire dataset—what about this example
    in particular?'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下我们之前的例子：您想知道温度平均为27.45°C时的功率产生情况，环境压力为1,001.23毫巴，相对湿度为84%，排气真空压力为65.12厘米汞。
    您使用`ML_PREDICT`函数预测在这一小时内能量产生将为433.35兆瓦。 您预期温度将基于模型的全局特征归因对您的模型产生最大影响。 然而，一般的全局解释会对整个数据集进行聚合——那么特别的例子呢？
- en: 'You can replace the `ML.PREDICT` method with the `ML.EXPLAIN_PREDICT` method
    to return the prediction with *local* feature attributions instead. Run the following
    query to get feature attributions for the top three features. Note that your exact
    output may differ from the output shown in [Figure 6-27](#the_output_of_the_mldotexplain_predict):'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`ML.EXPLAIN_PREDICT`方法替换`ML.PREDICT`方法，以返回具有*局部*特征归因的预测。 运行以下查询以获取前三个特征的特征归因。
    请注意，您的确切输出可能与[图6-27](#the_output_of_the_mldotexplain_predict)中显示的输出不同：
- en: '[PRE24]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![The output of the ML.EXPLAIN_PREDICT function. In this case, the temperature
    had the largest (in magnitude) contribution to the output for this example.](assets/lcai_0627.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![ML.EXPLAIN_PREDICT函数的输出。 在这种情况下，温度对于这个例子的输出有最大的（按大小）贡献。](assets/lcai_0627.png)'
- en: Figure 6-27\. The output of the `ML.EXPLAIN_PREDICT` function. In this case,
    the temperature had the largest (in magnitude) contribution to the output for
    this example.
  id: totrans-251
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-27。 `ML.EXPLAIN_PREDICT`函数的输出。 在这种情况下，温度对于这个例子的输出有最大的（按大小）贡献。
- en: There is a little syntax and some new columns in the output to explain. The
    additional argument for `ML.EXPLAIN_PREDICT`, `STRUCT(3 AS top_k_features)`, restricts
    the output for feature attributions to the top three features. The `top_k_features`
    option is the option for doing so, and `ML.EXPLAIN_PREDICT` expects this information
    to be passed in as a `STRUCT`. You can think of a `STRUCT` in SQL as a list of
    values (or columns) with specific names and possibly different types.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 输出中有一些新的语法和新列需要解释。`ML.EXPLAIN_PREDICT` 的附加参数 `STRUCT(3 AS top_k_features)` 限制了特征归因的输出为前三个特征。`top_k_features`
    选项是进行此操作的选项，`ML.EXPLAIN_PREDICT` 期望将此信息作为 `STRUCT` 传递。在 SQL 中，可以将 `STRUCT` 理解为具有特定名称和可能不同类型的值（或列）列表。
- en: 'Now for the new columns. `top_feature_attributions` is itself a `STRUCT` with
    two fields, `feature` and `attribution`. The field `feature` gives the corresponding
    feature name, and `attribution` gives the attribution value for this instance.
    And there is another new column: `baseline_prediction_value`. This value gives
    a baseline to compare your instance to for the sake of getting local feature attributions.
    In the case of linear regression models, this baseline is the average label value
    (energy production) across the dataset.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来讲讲新的列。`top_feature_attributions` 本身就是一个 `STRUCT`，包含两个字段，`feature` 和 `attribution`。字段
    `feature` 给出了相应的特征名称，而 `attribution` 给出了此实例的归因值。另外还有一个新列：`baseline_prediction_value`。这个值为了获取局部特征归因，提供了一个用于将您的实例与之进行比较的基线。在线性回归模型中，这个基线是数据集中标签值（能量产量）的平均值。
- en: How do you interpret the attribution values then? Note that the predicted label
    is less than the baseline prediction, and the attributions are all negative. The
    temperature value accounts for about 18.52 MW of decrease on average from the
    baseline value, relative humidity about on average 2.16 MW, and ambient pressure
    on average 0.31 MW. Exhaust vacuum pressure is not included here since it was
    not in the top three, but it had an even smaller contribution than ambient pressure
    for this example. So, you see that, for this example, most of the deviation from
    the baseline energy production was because of the temperature, with some minor
    contributions from the other features.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 那么如何解释归因值呢？请注意，预测标签小于基线预测，并且所有归因值均为负值。温度值平均从基线值减少约 18.52 MW，相对湿度约为平均减少 2.16
    MW，环境压力约为平均减少 0.31 MW。本例中未包括排气真空压力，因为它不在前三位，但其对该示例的贡献甚至比环境压力更小。因此，您可以看到，对于此示例，与基线能量生产的大部分偏差是由温度引起的，其他特征的贡献较小。
- en: Another option is to leverage explainability libraries in Jupyter Notebooks,
    such as Google Colab notebooks. LIME and SHAP are two such popular Python libraries
    that are commonly used across many different use cases. A full discussion is beyond
    the scope of this book; we recommend this [blog post](https://oreil.ly/YdZ5x)
    and other explainable AI references mentioned already for a deeper discussion
    and explicit examples.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是利用 Jupyter Notebooks 中的可解释性库，如 Google Colab notebooks。LIME 和 SHAP 是两个流行的
    Python 库，广泛用于许多不同的用例。本书不涉及详细讨论；我们推荐这篇[博客文章](https://oreil.ly/YdZ5x)和其他已经提到的可解释
    AI 参考资料，以进行更深入的讨论和明确的示例。
- en: Note
  id: totrans-256
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'The phrase “on average” in the previous paragraph may seem a bit odd on first
    reading. BigQuery ML uses Shapley values to compute attributions for linear models.
    Shapley values are a tool from coalitional game theory that computes the average
    contribution of feature values across different coalitions—different combinations
    of the feature value you are interested in and some baseline feature value. Though
    there is a more technical definition (see *Interpretable Machine Learning: A Guide
    For Making Black Box Models Explainable* by Christoph Molnar [self-published,
    2022], for example) for linear models, these can be computed simply in terms of
    the weight corresponding to that feature and the feature value itself for local
    explanations.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一段中，“平均”这个词组在初次阅读时可能显得有些奇怪。BigQuery ML 使用 Shapley 值来计算线性模型的归因。Shapley 值是从联合博弈理论中借来的工具，它计算不同联合体（您感兴趣的特征值及某些基线特征值的不同组合）中特征值的平均贡献。尽管有更技术性的定义（例如，参见
    Christoph Molnar 的《可解释机器学习：使黑盒模型可解释的指南》[自出版，2022]），对于线性模型，这些可以简单地计算为对应于该特征的权重和该特征值本身的局部解释。
- en: Exercises
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: 'In [“Feature Selection and Correlation”](#feature_selection_and_correlation),
    you began gaining a better understanding of the feature selection process and
    some techniques to use for feature selection. However, you used all of the possible
    features for training your model in the previous section. Some exercises for the
    reader:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [“特征选择和相关性”](#feature_selection_and_correlation) 中，你开始更好地理解特征选择过程及其一些技术用于特征选择。然而，在前一节中，你使用了所有可能的特征来训练你的模型。读者的一些练习：
- en: Train new models using a subset of the features. Use what you learned about
    correlations and collinearity to select your features.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用一部分特征来训练新模型。利用你对相关性和共线性的了解来选择你的特征。
- en: Evaluate these new models. Which sets of features performed the best?
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估这些新模型。哪些特征集表现最好？
- en: Use the discussed explainability functions to explore which features contributed
    most to the models’ performance globally and locally. Are there any surprises?
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用讨论过的可解释性函数来探索哪些特征在全局和局部对模型性能贡献最大。有什么意外之处吗？
- en: Neural Networks in BigQuery ML
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BigQuery ML 中的神经网络
- en: 'Now  that you have trained linear regression models using BigQuery ML, it’s
    time to look at another popular ML model type: neural networks. Neural networks
    have become incredibly popular in the past decade due to the availability of additional
    compute resources, new model architectures, and their flexibility to apply knowledge
    from one problem to another in the form of transfer learning. This section offers
    a quick introduction to neural networks and then shows how to build such a model
    in BigQuery ML.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经使用 BigQuery ML 训练了线性回归模型，是时候看看另一种流行的 ML 模型类型：神经网络了。由于额外的计算资源、新的模型架构以及它们在转移学习中应用知识的灵活性，神经网络在过去十年变得非常流行。本节提供了神经网络的快速介绍，然后展示如何在
    BigQuery ML 中构建这样一个模型。
- en: Brief Overview of Neural Networks
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络简要概述
- en: As in the case of linear regression models, neural networks are also mathematical
    functions that take numeric feature values as inputs and output a prediction for
    the label. Neural networks can be used for both regression and classification
    problems, but in this section the focus will be on regression models.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 和线性回归模型一样，神经网络也是数学函数，接受数值特征值作为输入，并输出标签的预测值。神经网络可以用于回归和分类问题，但本节重点是回归模型。
- en: 'To describe neural networks, let us reframe the description of linear regression
    in visual terms. Recall for the problem of predicting energy production there
    were four features: temperature, ambient pressure, relative humidity, and exhaust
    vacuum pressure. For the sake of simplicity, label these as <math><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>3</mn></msub></mrow></math> , and <math><msub><mi>x</mi> <mn>4</mn></msub></math>
    . A linear regression model using these four features would have the following
    form:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 为了描述神经网络，让我们重新以视觉术语描述线性回归。回想一下，为了预测能源产量的问题，有四个特征：温度、环境压力、相对湿度和排气真空压力。为了简单起见，将它们标记为
    <math><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>3</mn></msub></mrow></math> 和 <math><msub><mi>x</mi>
    <mn>4</mn></msub></math> 。使用这四个特征的线性回归模型将具有以下形式：
- en: <math><mrow><mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <mi>y</mi> <mo>=</mo> <msub><mi>w</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>w</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>w</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msub><mi>w</mi> <mn>3</mn></msub> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>+</mo> <msub><mi>w</mi> <mn>4</mn></msub> <msub><mi>x</mi> <mn>4</mn></msub>
    <mo>.</mo></mrow></math>
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <mi>y</mi> <mo>=</mo> <msub><mi>w</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>w</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>w</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msub><mi>w</mi> <mn>3</mn></msub> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>+</mo> <msub><mi>w</mi> <mn>4</mn></msub> <msub><mi>x</mi> <mn>4</mn></msub>
    <mo>.</mo></mrow></math>
- en: To visualize this as a network, draw a graph like [Figure 6-28](#a_visual_representation_of_a_linear_reg).
    Draw a vertex for each of the four features and the output <math><mi>y</mi></math>
    . Draw arrows from the feature vertices to the output vertex and label those edges
    with the weights <math><mrow><msub><mi>w</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>w</mi>
    <mn>2</mn></msub> <mo>,</mo> <msub><mi>w</mi> <mn>3</mn></msub></mrow></math>
    , and <math><msub><mi>w</mi> <mn>4</mn></msub></math> , respectively. Often, nothing
    is drawn for the bias <math><msub><mi>w</mi> <mn>0</mn></msub></math> in this
    representation.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 要将其可视化为网络，请绘制如[图 6-28](#a_visual_representation_of_a_linear_reg)的图。为每个特征和输出<math><mi>y</mi></math>绘制一个顶点。从特征顶点到输出顶点画箭头，并用权重<math><mrow><msub><mi>w</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>w</mi>
    <mn>3</mn></msub></mrow></math>和<math><msub><mi>w</mi> <mn>4</mn></msub></math>标记这些边。通常在此表示中不绘制偏置<math><msub><mi>w</mi>
    <mn>0</mn></msub></math>。
- en: '![A visual representation of a linear regression model](assets/lcai_0628.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![线性回归模型的可视化表示](assets/lcai_0628.png)'
- en: Figure 6-28\. A visual representation of a linear regression model.
  id: totrans-271
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-28\. 线性回归模型的可视化表示。
- en: You have now visualized a linear regression model as a neural network! Before
    writing any formulas for neural networks in general, we’ll start out with a visual
    representation of one that is not a linear regression model. Now, suppose you
    want to combine the original features into new hidden features <math><msub><mi>z</mi>
    <mn>1</mn></msub></math> and <math><msub><mi>z</mi> <mn>2</mn></msub></math> ,
    where each of these features is a linear combination of the original features,
    or what you may consider as a weighted sum of the features. Technically, it is
    an expression of the form
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经将线性回归模型可视化为神经网络了！在撰写任何一般神经网络公式之前，我们将从一个不是线性回归模型的视觉表示开始。假设现在您想要将原始特征组合成新的隐藏特征<math><msub><mi>z</mi>
    <mn>1</mn></msub></math>和<math><msub><mi>z</mi> <mn>2</mn></msub></math>，其中每个特征都是原始特征的线性组合，或者您可以将其视为特征的加权和。从技术上讲，它是以下形式的表达式
- en: <math><mrow><msub><mi>z</mi> <mn>1</mn></msub> <mo>=</mo> <msub><mi>c</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>c</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>c</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msub><mi>c</mi> <mn>3</mn></msub> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>+</mo> <msub><mi>c</mi> <mn>4</mn></msub> <msub><mi>x</mi> <mn>4</mn></msub></mrow></math>
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><msub><mi>z</mi> <mn>1</mn></msub> <mo>=</mo> <msub><mi>c</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>c</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>c</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msub><mi>c</mi> <mn>3</mn></msub> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>+</mo> <msub><mi>c</mi> <mn>4</mn></msub> <msub><mi>x</mi> <mn>4</mn></msub></mrow></math>
- en: where the <math><msub><mi>c</mi> <mi>i</mi></msub></math> are some real numbers.
    The hidden feature <math><msub><mi>z</mi> <mn>2</mn></msub></math> would have
    a similar definition with different constants (say, <math><msub><mi>d</mi> <mi>i</mi></msub></math>
    instead of <math><msub><mi>c</mi> <mi>i</mi></msub></math> ). Strictly speaking,
    the <math><msub><mi>c</mi> <mn>0</mn></msub></math> term makes this something
    slightly different than a linear combination of the features on their own, but
    if you include 1 as a constant feature, then the technical definition does align
    with the usage here.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 其中<math><msub><mi>c</mi> <mi>i</mi></msub></math>是一些实数。隐藏特征<math><msub><mi>z</mi>
    <mn>2</mn></msub></math>将具有类似的定义，但常数不同（例如，使用<math><msub><mi>d</mi> <mi>i</mi></msub></math>而不是<math><msub><mi>c</mi>
    <mi>i</mi></msub></math>）。严格来说，<math><msub><mi>c</mi> <mn>0</mn></msub></math>项使其略微不同于特征本身的线性组合，但如果将1包括为恒定特征，则技术定义与此处的使用是一致的。
- en: We call these hidden features together a *hidden layer*. They are *hidden* since
    you do not see them in the input or the output of the model, but they play a role
    in computing the output from the inputs. You can draw a visual representation
    in the same manner as before, but now the feature vertices connect to the new
    hidden features <math><msub><mi>z</mi> <mn>1</mn></msub></math> and <math><msub><mi>z</mi>
    <mn>2</mn></msub></math> , and the hidden features connect to the output <math><mi>y</mi></math>
    , as in [Figure 6-29](#a_visual_representation_of_a_neural_ne).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些隐藏特征一起称为*隐藏层*。它们是*隐藏*的，因为您在模型的输入或输出中看不到它们，但它们在计算从输入到输出的过程中起到作用。您可以以与之前相同的方式绘制视觉表示，但现在特征顶点连接到新的隐藏特征<math><msub><mi>z</mi>
    <mn>1</mn></msub></math>和<math><msub><mi>z</mi> <mn>2</mn></msub></math>，而隐藏特征连接到输出<math><mi>y</mi></math>，如[图 6-29](#a_visual_representation_of_a_neural_ne)中所示。
- en: '![A visual representation of a neural network with one hidden layer](assets/lcai_0629.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![一个具有一个隐藏层的神经网络的视觉表示](assets/lcai_0629.png)'
- en: Figure 6-29\. A visual representation of a neural network with one hidden layer.
  id: totrans-277
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-29\. 一个具有一个隐藏层的神经网络的视觉表示。
- en: This is an example of a neural network with one hidden layer. How do you determine
    what these hidden features should be, though? That is, how do you find the best
    values for the various <math><msub><mi>c</mi> <mi>i</mi></msub></math> and <math><msub><mi>d</mi>
    <mi>i</mi></msub></math> ? There is no normal equation for neural networks, but
    you can use gradient descent in the same way as before! Instead of trying different
    combinations, you can treat the <math><msub><mi>c</mi> <mi>i</mi></msub></math>
    and <math><msub><mi>d</mi> <mi>i</mi></msub></math> just like the other weights
    before for your linear regression model and train the model to find the best weights.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这是具有一个隐藏层的神经网络的示例。然而，你如何确定这些隐藏特征应该是什么呢？也就是说，你如何找到各个 <math><msub><mi>c</mi> <mi>i</mi></msub></math>
    和 <math><msub><mi>d</mi> <mi>i</mi></msub></math> 的最佳值？神经网络没有正常方程，但你可以像以前一样使用梯度下降！不同于尝试不同的组合，你可以将
    <math><msub><mi>c</mi> <mi>i</mi></msub></math> 和 <math><msub><mi>d</mi> <mi>i</mi></msub></math>
    看作是你线性回归模型中的其他权重，通过训练模型来找到最佳权重。
- en: Activation Functions and Nonlinearity
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 激活函数与非线性
- en: 'There is still one piece of the neural network puzzle missing, however. To
    see what this is, consider a simple math problem. Suppose <math><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mn>3</mn> <mo>+</mo> <mn>2</mn> <mi>x</mi></mrow></math>
    and <math><mrow><mi>g</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mn>1</mn>
    <mo>+</mo> <mn>5</mn> <mi>x</mi></mrow></math> . What is <math><mrow><mi>g</mi>
    <mo>(</mo> <mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>)</mo></mrow></math>
    ? To compute a composition, take the output of the inner function (here <math><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math> ) and plug it into the second function:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，神经网络的拼图还缺少一部分。要看清楚这一点，考虑一个简单的数学问题。假设 <math><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi>
    <mo>)</mo> <mo>=</mo> <mn>3</mn> <mo>+</mo> <mn>2</mn> <mi>x</mi></mrow></math>
    和 <math><mrow><mi>g</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mn>1</mn>
    <mo>+</mo> <mn>5</mn> <mi>x</mi></mrow></math> 。那么 <math><mrow><mi>g</mi> <mo>(</mo>
    <mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>)</mo></mrow></math> 是多少？要计算一个复合函数，将内部函数的输出（这里是
    <math><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math> ）代入第二个函数：
- en: <math><mrow><mi>g</mi> <mo>(</mo> <mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo>
    <mo>)</mo> <mo>=</mo> <mi>g</mi> <mo>(</mo> <mn>3</mn> <mo>+</mo> <mn>2</mn> <mi>x</mi>
    <mo>)</mo> <mo>=</mo> <mn>1</mn> <mo>+</mo> <mn>5</mn> <mo>(</mo> <mn>3</mn> <mo>+</mo>
    <mn>2</mn> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mn>16</mn> <mo>+</mo> <mn>10</mn>
    <mi>x</mi></mrow></math>
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mi>g</mi> <mo>(</mo> <mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo>
    <mo>)</mo> <mo>=</mo> <mi>g</mi> <mo>(</mo> <mn>3</mn> <mo>+</mo> <mn>2</mn> <mi>x</mi>
    <mo>)</mo> <mo>=</mo> <mn>1</mn> <mo>+</mo> <mn>5</mn> <mo>(</mo> <mn>3</mn> <mo>+</mo>
    <mn>2</mn> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mn>16</mn> <mo>+</mo> <mn>10</mn>
    <mi>x</mi></mrow></math>
- en: What was the point of this exercise? Note that <math><mrow><mi>f</mi> <mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></math> and <math><mrow><mi>g</mi> <mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow></math> are linear functions of the form <math><mrow><mi>m</mi>
    <mi>x</mi> <mo>+</mo> <mi>b</mi></mrow></math> for some <math><mi>m</mi></math>
    and <math><mi>b</mi></math> . The final answer <math><mrow><mi>g</mi> <mo>(</mo>
    <mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>)</mo></mrow></math> is also a
    linear function of the same form (just with different <math><mi>m</mi></math>
    and <math><mi>b</mi></math> ). This is not a coincidence! In general, a composition
    of linear functions is always linear.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这项练习的目的是什么？请注意，<math><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math>
    和 <math><mrow><mi>g</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math> 是形式为 <math><mrow><mi>m</mi>
    <mi>x</mi> <mo>+</mo> <mi>b</mi></mrow></math> 的线性函数，其中 <math><mi>m</mi></math>
    和 <math><mi>b</mi></math> 是一些常数。最终答案 <math><mrow><mi>g</mi> <mo>(</mo> <mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>)</mo></mrow></math> 也是同样形式的线性函数（只是 <math><mi>m</mi></math>
    和 <math><mi>b</mi></math> 不同）。这并非巧合！一般来说，线性函数的复合仍然是线性的。
- en: How does this relate back to neural networks? The hidden features <math><msub><mi>z</mi>
    <mn>1</mn></msub></math> and <math><msub><mi>z</mi> <mn>2</mn></msub></math> are
    linear functions of <math><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>3</mn></msub></mrow></math>
    , and <math><msub><mi>x</mi> <mn>4</mn></msub></math> ; <math><mi>y</mi></math>
    is a linear function of <math><msub><mi>z</mi> <mn>1</mn></msub></math> and <math><msub><mi>z</mi>
    <mn>2</mn></msub></math> . You can think of your neural network as a composition
    of two linear functions. The first takes <math><mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>3</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>4</mn></msub> <mo>)</mo></mrow></math>
    to <math><mrow><mo>(</mo> <msub><mi>z</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>z</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math> , and the second takes <math><mrow><mo>(</mo>
    <msub><mi>z</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>z</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></math> to <math><mi>y</mi></math> . Both functions are linear,
    so the composition is also linear. We just found a more complicated way to write
    <math><mi>y</mi></math> as a linear function of <math><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>3</mn></msub></mrow></math>
    , and <math><msub><mi>x</mi> <mn>4</mn></msub></math> !
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这与神经网络有何关联？隐藏特征<math><msub><mi>z</mi> <mn>1</mn></msub></math>和<math><msub><mi>z</mi>
    <mn>2</mn></msub></math>是<math><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>3</mn></msub></mrow></math>和<math><msub><mi>x</mi>
    <mn>4</mn></msub></math>的线性函数；<math><mi>y</mi></math>是<math><msub><mi>z</mi> <mn>1</mn></msub></math>和<math><msub><mi>z</mi>
    <mn>2</mn></msub></math>的线性函数。您可以将神经网络视为两个线性函数的组合。第一个函数将<math><mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>4</mn></msub>
    <mo>)</mo></mrow></math>映射到<math><mrow><mo>(</mo> <msub><mi>z</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>z</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>，第二个函数将<math><mrow><mo>(</mo>
    <msub><mi>z</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>z</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></math>映射到<math><mi>y</mi></math>。由于两个函数都是线性的，所以组合也是线性的。我们刚刚找到了一个更复杂的方法，将<math><mi>y</mi></math>写成<math><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>3</mn></msub></mrow></math>和<math><msub><mi>x</mi> <mn>4</mn></msub></math>的线性函数！
- en: 'So, are neural networks with hidden layers pointless? Not at all, but you need
    to add in one more thing to make them interesting: a nonlinear activation function.
    *Activation functions* are functions applied to the features in hidden layers
    before passing along those values to the next layer. This is done so that the
    functions that go from one layer to the next are no longer linear, and the model
    can learn more interesting behavior. The most common activation function used
    for neural networks (and the simplest) is the *rectified linear unit* function,
    or ReLU for short. ReLU is a very simple function that takes in a single value
    and returns that value if it’s positive, or returns 0 if it’s negative (see [Figure 6-30](#graph_of_the_relu_activation_function)).'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 那么   所以，神经网络中带有隐藏层的网络毫无意义吗？完全不是，但你需要再添加一些东西才能使它们变得有趣：非线性激活函数。*激活函数*是应用于隐藏层特征的函数，在将这些值传递到下一层之前使用。这样做是为了使从一层到下一层的函数不再是线性的，从而使模型能够学习更有趣的行为。用于神经网络（也是最简单的）的最常见激活函数是*修正线性单元*函数，简称ReLU。ReLU是一个非常简单的函数，如果输入值为正数则返回该值，否则返回0（参见[图 6-30](#graph_of_the_relu_activation_function)）。
- en: '![Graph of the ReLU activation function](assets/lcai_0630.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![ReLU激活函数的图表](assets/lcai_0630.png)'
- en: Figure 6-30\. Graph of the ReLU activation function.
  id: totrans-286
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 激活函数通常应用于隐藏层，但不适用于回归问题的输出本身。现在你对神经网络有了一个定义，不仅仅是线性回归模型。具有 ReLU 激活的结果函数仍然是分段线性的，但它们不是线性的事实意味着你可以建模更复杂的函数。你可以看到这些激活函数如何被添加的视觉表示在[图 6-31](#a_visual_representation_of_a_neural_net)中。
- en: Activation functions will often be applied to the hidden layers but not the
    output itself for regression problems. Now you have a definition of neural networks
    that gives you something more than linear regression models. The resulting functions
    with ReLU activation are still piecewise linear, but the fact that they are not
    linear means that you can model more complicated functions. You can see a visual
    representation of how these activation functions are added in [Figure 6-31](#a_visual_representation_of_a_neural_net).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数通常应用于隐藏层，但不应用于th> 的线性函数！
- en: '![A visual representation of a neural network with one hidden layer and activation
    function ReLU for the hidden layer. The boxes represent ReLU being applied to
    the value of a hidden feature before being used to compute the final output.](assets/lcai_0631.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![一个具有一个隐藏层和激活函数ReLU的神经网络的视觉表示。盒子代表ReLU被应用于隐藏特征值之前，用于计算最终输出。](assets/lcai_0631.png)'
- en: Figure 6-31\. A visual representation of a neural network with one hidden layer
    and activation function ReLU for the hidden layer. The boxes represent ReLU being
    applied to the value of a hidden feature before being used to compute the final
    output.
  id: totrans-289
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-31\. 具有一个隐藏层和激活函数ReLU的神经网络的视觉表示。盒子代表ReLU被应用于隐藏特征值之前，用于计算最终输出。
- en: In general, you can build a neural network with as many hidden layers as you
    like. For example, if you have two hidden layers, you can conceptually think of
    the neural network doing the following. After training, the model will have learned
    hidden features for two different hidden layers. You can think of the features
    for the first hidden layer as being learned from the original input features,
    and the hidden features for the second hidden layer as being learned from the
    hidden features from the first hidden layer. You cannot see this directly by looking
    at the model inputs and outputs, of course, but it does correspond to how neural
    networks can build up concepts from one layer to another and ultimately apply
    these to computing the final output. See [Figure 6-32](#a_visual_representation_of_a_neural_n)
    for a visual example of such a neural network.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，您可以构建任意数量的隐藏层神经网络。例如，如果您有两个隐藏层，您可以概念化地认为神经网络执行以下操作。训练后，模型将学习两个不同隐藏层的隐藏特征。您可以将第一个隐藏层的特征看作是从原始输入特征学习到的，将第二个隐藏层的隐藏特征看作是从第一个隐藏层的隐藏特征学习到的。当然，通过查看模型的输入和输出无法直接看到这一点，但这确实对应于神经网络如何从一层到另一层逐步构建概念，并最终将其应用于计算最终输出。请参见[图
    6-32](#a_visual_representation_of_a_neural_n)以查看这样一个神经网络的视觉示例。
- en: '![A visual representation of a neural network with two hidden layers. The activation
    function ReLU is not visualized in this example.](assets/lcai_0632.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![一个具有两个隐藏层的神经网络的视觉表示。在这个例子中，激活函数ReLU没有被可视化。](assets/lcai_0632.png)'
- en: Figure 6-32\. A visual representation of a neural network with two hidden layers.
    The activation function ReLU is not visualized in this example.
  id: totrans-292
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-32\. 一个具有两个隐藏层的神经网络的视觉表示。在这个例子中，激活函数ReLU没有被可视化。
- en: Tip
  id: totrans-293
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Larger numbers of hidden layers give rise to more powerful models but have more
    weights to optimize and thus take more data and time to train. Smaller neural
    networks (fewer hidden layers) are easier to train but may not be able to learn
    as complex relationships compared with larger neural networks.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的隐藏层会导致更强大的模型，但需要优化更多的权重，因此需要更多的数据和时间来训练。较小的神经网络（较少的隐藏层）更容易训练，但可能无法像较大的神经网络那样学习复杂的关系。
- en: Training a Deep Neural Network in BigQuery ML
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 BigQuery ML 中训练深度神经网络
- en: 'Now that you know a little bit about neural networks, it is time to train a
    neural network in BigQuery ML. Training a deep neural network will give you a
    way to learn critical nonlinear relationships between your input variables and
    the label, power production. Fortunately, though the concepts are a bit more complicated,
    the SQL syntax for doing this is just as simple as before, with some small differences.
    Write and run the following query in the BigQuery console:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您对神经网络有了一些了解，是时候在 BigQuery ML 中训练一个神经网络了。训练深度神经网络将使您能够学习输入变量和标签（功率产生）之间的关键非线性关系。幸运的是，尽管概念有些复杂，但用于此操作的
    SQL 语法与以前一样简单，只是有些细微差别。在 BigQuery 控制台中编写并运行以下查询：
- en: '[PRE25]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This model will take longer to train due to both the model being more complex
    and the fact that BigQuery is exporting the data to Vertex AI to train a neural
    network using Vertex AI training.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型更加复杂，并且 BigQuery 正在将数据导出到 Vertex AI 以使用 Vertex AI 训练神经网络，因此这个模型的训练时间会更长。
- en: 'There are some small changes to the SQL statement that should be addressed
    while the model is training. First is the model type. `dnn_regressor` is the model
    type for deep neural network regression models. The word *deep* here corresponds
    to the fact that the neural network could have any number of hidden layers, that
    is, it could be many layers deep. The other new argument is `hidden_units`. A
    *hidden unit* or *neuron* is the more technical and commonly used term for what
    was called *hidden features* earlier. The `hidden_units` option expects an array
    of integers, and in this case the array `[32,16,8]` was given. This means that
    the neural network has three hidden layers: the first hidden layer has 32 neurons,
    the second has 16 neurons, and the third has 8 neurons. This would be a bit of
    a slog to draw out the visual representation of, but hopefully you can understand
    what this could look like by analogy to earlier diagrams.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练过程中，有一些 SQL 语句需要进行一些小的更改。首先是模型类型。`dnn_regressor` 是用于深度神经网络回归模型的模型类型。这里的
    *deep* 指的是神经网络可能具有任意数量的隐藏层，也就是说，它可以有很多层深度。另一个新参数是 `hidden_units`。*隐藏单元* 或 *神经元*
    是以前称为 *隐藏特征* 的更技术化和常用的术语。`hidden_units` 选项期望一个整数数组，在这种情况下，数组 `[32,16,8]` 被给定。这意味着神经网络有三个隐藏层：第一个隐藏层有
    32 个神经元，第二个有 16 个神经元，第三个有 8 个神经元。要绘制其可视化表示会有点繁琐，但希望您可以通过类比以前的图表来理解其可能的样子。
- en: Once your model is trained, go to your model and the Evaluation tab as you did
    for the linear model and look at the evaluation metrics for your model. Your metrics
    may differ from those that you see in [Figure 6-33](#trained_neural_network_evaluation_metri).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的模型训练完成，就像您为线性模型所做的那样，转到模型和评估选项卡，并查看您模型的评估指标。您的指标可能与您在 [图 6-33](#trained_neural_network_evaluation_metri)
    中看到的不同。
- en: '![Trained neural network evaluation metrics](assets/lcai_0633.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![经过训练的神经网络评估指标](assets/lcai_0633.png)'
- en: Figure 6-33\. Trained neural network evaluation metrics.
  id: totrans-302
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-33\. 经过训练的神经网络评估指标。
- en: The new neural network model did slightly worse than the linear regression model
    based on mean squared error (and RMSE, since RMSE is the square root of mean squared
    error). This is an example of *overfitting* (as shown in [Figure 6-34](#underfitting_and_overfitting_models_for)).
    The model that is overfitting can more accurately predict the labels for the data
    in the training set (shown), but this comes at the cost of missing the overall
    quadratic trend in the data. Models can also underfit. That is, the model is too
    simple and cannot learn trends in the data. [Figure 6-34](#underfitting_and_overfitting_models_for)
    shows an example where a linear model was used, so the model is not able to learn
    the quadratic trend in the data.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 新的神经网络模型在均方误差（以及 RMSE，因为 RMSE 是均方误差的平方根）方面略逊于线性回归模型。这是一个*过拟合*的例子（如 [图 6-34](#underfitting_and_overfitting_models_for)
    所示）。过拟合的模型可以更准确地预测训练集中数据的标签（如所示），但这是以错过数据整体二次趋势为代价的。模型也可能出现欠拟合。也就是说，模型过于简单，无法学习数据的趋势。[图 6-34](#underfitting_and_overfitting_models_for)
    展示了一个使用线性模型的例子，因此模型无法学习数据中的二次趋势。
- en: '![Underfitting and overfitting models for a dataset](assets/lcai_0634.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![数据集的欠拟合和过拟合模型](assets/lcai_0634.png)'
- en: Figure 6-34\. Underfitting and overfitting models for a dataset.
  id: totrans-305
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-34\. 数据集的欠拟合和过拟合模型。
- en: Tip
  id: totrans-306
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: When training ML models, you should compare the performance on the training
    dataset and the evaluation dataset to ensure that the model is not overfitting.
    You can approach this by altering the model architecture, using early stopping
    or various other regularization techniques. *Regularization* is a blanket term
    of techniques that combat overfitting in models. [Chapter 8](ch08.html#improving_custom_model_performance)
    discusses some of these techniques in more detail for different frameworks, including
    BigQuery ML.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练机器学习模型时，您应该比较训练数据集和评估数据集的性能，以确保模型没有过拟合。您可以通过改变模型架构、使用早停或各种其他正则化技术来解决这个问题。*正则化*
    是指用来抑制模型过拟合的一系列技术。[第8章](ch08.html#improving_custom_model_performance) 更详细地讨论了一些这些技术，适用于不同的框架，包括
    BigQuery ML。
- en: Naturally, you may have come across a major question along the way. How do you
    know you have the best number of hidden layers and neurons? You can try some different
    lists for the `hidden_units` option and see what performs the best, but in theory
    there are an infinite number of possibilities. The number of hidden layers, neurons
    per layer, and which activation function is used are all examples of what are
    called hyperparameters*.* *Hyperparameters* are different from parameters (such
    as weights) in that they are set before the model is trained. Hyperparameters
    define the model architecture, training process, and more, and parameters are
    what are optimized during the training process to try to find the best model defined
    by these hyperparameters. [Chapter 8](ch08.html#improving_custom_model_performance)
    explores different methods for finding the best hyperparameters for your model
    in BigQuery ML, Vertex AI, and other popular ML frameworks.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 自然而然地，您可能在路上遇到了一个重要问题。您如何知道您有最佳的隐藏层和神经元数？您可以尝试一些不同的列表来为 `hidden_units` 选项，并查看哪个表现最佳，但理论上有无限多种可能性。隐藏层的数量，每层的神经元数以及使用的激活函数都是所谓的超参数。超参数与参数（如权重）不同，它们在模型训练之前设置。超参数定义了模型架构、训练过程等，而参数则在训练过程中被优化，以尝试找到由这些超参数定义的最佳模型。[第
    8 章](ch08.html#improving_custom_model_performance) 探讨了在 BigQuery ML、Vertex AI
    和其他流行的 ML 框架中寻找最佳超参数的不同方法。
- en: Exercises
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: 'In [“Feature Selection and Correlation”](#feature_selection_and_correlation),
    you saw the feature selection process and learned some techniques to use for feature
    selection. However, you used all of the possible features for training your model
    in the previous section. Here are some exercises to try:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [“特征选择和相关性”](#feature_selection_and_correlation) 中，您看到了特征选择过程，并学习了一些用于特征选择的技术。但是，在前一节中，您使用了所有可能的特征来训练您的模型。以下是一些可以尝试的练习：
- en: Train another model using a larger neural network. You can either add additional
    neurons for each layer or additional layers. How did this affect mode performance?
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用更大的神经网络训练另一个模型。你可以为每一层添加额外的神经元，或者添加额外的层。这对模型性能有何影响？
- en: Train another model using a smaller neural network. You can either remove neurons
    for each layer or remove layers. How did this affect model performance?
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用较小的神经网络训练另一个模型。您可以为每一层删除神经元或删除层。这对模型性能有何影响？
- en: Use the discussed explainability functions to explore which features contributed
    most to the model’s performance globally and locally. Are there any surprises?
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用讨论过的可解释性函数来探索哪些特征在全局和局部上对模型性能贡献最大。是否有什么意外之处？
- en: 'Deep Dive: Using Cloud Shell to View Your Cloud Storage File'
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨：使用云 Shell 查看您的云存储文件
- en: '[Cloud Shell](https://cloud.google.com/shell) is a free service on Google Cloud
    that gives you terminal access to a small virtual machine with the Google Cloud
    CLI (command-line interface) preinstalled. This allows you to use the command
    line to interact with Google Cloud resources. We can’t cover all of its capabilities
    in this book, but you will see a simple example of how you can print off the first
    few lines of a text file stored in Google Cloud Storage without having to download
    the file.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '[云 Shell](https://cloud.google.com/shell) 是 Google Cloud 上的免费服务，提供对预安装有 Google
    Cloud CLI（命令行界面）的小型虚拟机的终端访问。这允许您使用命令行与 Google Cloud 资源进行交互。我们无法在本书中覆盖其所有功能，但您将看到一个简单的示例，演示如何在不下载文件的情况下打印存储在
    Google Cloud Storage 中文本文件的前几行。'
- en: To access Cloud Shell, click the Activate Cloud Shell button in the top right
    corner of the Google Cloud console UI (shown in [Figure 6-35](#the_activate_cloud_shell_button)).
    It may take a little time to provision the virtual machine.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问云 Shell，请在 Google Cloud 控制台 UI 的右上角单击激活云 Shell 按钮（在 [图 6-35](#the_activate_cloud_shell_button)
    中显示）。虚拟机的配置可能需要一些时间。
- en: '![The Activate Cloud Shell button](assets/lcai_0635.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![激活云 Shell 按钮](assets/lcai_0635.png)'
- en: Figure 6-35\. The Activate Cloud Shell button.
  id: totrans-318
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-35\. 激活云 Shell 按钮。
- en: Every time you open Cloud Shell (see [Figure 6-36](#the_cloud_shell_terminal)),
    the underlying virtual machine is different, but the persistent disk is not. What
    does that mean? It means that your data in Cloud Shell will always be available,
    but anything that is installed by you will have to be reinstalled whenever you
    reopen Cloud Shell. Since you will be using the Google Cloud CLI here, this will
    not be an issue.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 每次打开 Cloud Shell（参见[图 6-36](#the_cloud_shell_terminal)），底层的虚拟机都是不同的，但持久磁盘是不变的。这是什么意思？这意味着你在
    Cloud Shell 中的数据将始终可用，但你安装的任何东西在重新打开 Cloud Shell 时都需要重新安装。由于你将在这里使用 Google Cloud
    CLI，这不会成为问题。
- en: '![The Cloud Shell terminal](assets/lcai_0636.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![Cloud Shell 终端](assets/lcai_0636.png)'
- en: Figure 6-36\. The Cloud Shell terminal.
  id: totrans-321
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-36\. Cloud Shell 终端。
- en: 'First, ensure that your project is active in Cloud Shell. If it is active,
    you should see a terminal prompt similar to “`your-login@cloudshell:~ (your-project-id)$`.”
    If you do not see the project ID in the second part of the prompt, you will need
    to set this. Fortunately, that is very easy to do using the Google Cloud CLI.
    Type in the following command (replacing your-project-id with your project ID)
    and hit Enter/Return:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，请确保你的项目在 Cloud Shell 中是活动状态。如果是活动状态，你应该看到类似于 “`your-login@cloudshell:~ (your-project-id)$`”
    的终端提示符。如果你在提示符的第二部分看不到项目 ID，你需要设置一下。幸运的是，使用 Google Cloud CLI 非常容易做到这一点。键入以下命令（用你的项目
    ID 替换 `your-project-id`）并按 Enter/Return 键：
- en: '[PRE26]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You should now see your project ID in the second part of the terminal prompt.
    You can also check that the project ID is set successfully by running this command:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你应该在终端提示符的第二部分看到你的项目 ID。你也可以通过运行以下命令来检查项目 ID 是否设置成功：
- en: '[PRE27]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now that you have activated the CLI using your project ID, you can look at
    the first few lines of the CSV file together. Do this by running the following
    command:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经使用你的项目 ID 激活了 CLI，可以一起查看 CSV 文件的前几行。通过运行以下命令来实现：
- en: '[PRE28]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Unlike the previous commands, this one is likely not very obvious in purpose.
    `gcloud storage` is the family of commands for interacting with Google Cloud Storage,
    and you are executing the `cat` command. This command is short for *concatenate,*
    and it’s used to read a file from Google Cloud Storage and write it to the standard
    terminal output. The next part of the command, `-r 0-250`, specifies that you
    do not want to read the entire file, but rather just the first 250 bytes. For
    this CSV file, this will allow you to see the first few rows to just get a quick
    idea of what you are looking at. Finally, you have the file Uniform Resource Identifier
    (URI) in Google Cloud Storage: `gs://low-code-ai-book/ccpp.csv`'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 不同于之前的命令，这个命令的目的可能不太明显。`gcloud storage` 是与 Google Cloud Storage 交互的命令系列，你正在执行
    `cat` 命令。这个命令是 *concatenate* 的缩写，用于从 Google Cloud Storage 中读取文件并将其写入标准终端输出。命令的下一部分
    `-r 0-250` 指定你不想读取整个文件，而只是前 250 个字节。对于这个 CSV 文件，这将让你快速查看前几行，以了解你看到的内容。最后，你有 Google
    Cloud Storage 中文件的统一资源标识符（URI）：`gs://low-code-ai-book/ccpp.csv`
- en: 'The output of this command is the following:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令的输出如下：
- en: '[PRE29]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The last row was not completed, but that is OK! The goal here was to simply
    get an idea of what you were looking at. Note that this CSV file has five columns:
    `Temp, Exhaust_Vacuum`, `Ambient_Pressure`, `Relative_Humidity`, and `Energy_Production`.
    These correspond to the columns that were expected. At least in the first few
    rows, nothing seems off about this data, but of course there is likely a lot more
    data in this file than is shown now. How can you figure this out? There is a nice
    terminal command, `wc`, that can count the number of lines in a file:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一行没有完成，但没关系！这里的目标只是简单了解你看到的东西的概念。请注意，这个 CSV 文件有五列：`Temp, Exhaust_Vacuum`,
    `Ambient_Pressure`, `Relative_Humidity`, 和 `Energy_Production`。这些与预期的列相对应。至少在前几行，这些数据看起来都没问题，但当然，这个文件里可能会有比现在展示的更多的数据。你怎么能弄清楚呢？有一个很好的终端命令，`wc`，可以计算文件中的行数：
- en: '[PRE30]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The first part of the command is familiar: you are concatenating the CSV file
    from Google Cloud Storage. You are not specifying how many bytes to read, so the
    entire file will be read. But the last part of the command is new. This command
    is really two different commands chained together using the pipe operator `|`.
    The *pipe* operator takes the output from the first command and “pipes” it to
    the second command to use as the input. In this case, the second command is the
    `wc -l` command. This command uses `wc` (“word count”) to count the number of
    lines, words, and characters in the CSV file. The `-l` option is used to only
    print out the number of lines. In this case, you see that the CSV file has 9,590
    lines.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 命令的第一部分很熟悉：你正在连接来自Google Cloud Storage的CSV文件。你没有指定要读取多少字节，所以将会读取整个文件。但命令的最后一部分是新内容。这个命令实际上是使用管道运算符`|`将两个不同的命令链在一起。*管道*运算符将第一个命令的输出“管道”到第二个命令，作为其输入使用。在本例中，第二个命令是`wc
    -l`命令。这个命令使用`wc`（“word count”）来计算CSV文件中的行数、单词数和字符数。选项`-l`用于仅打印出行数。在本例中，你会看到CSV文件有9,590行。
- en: Summary
  id: totrans-334
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: In this chapter you analyzed power plant production data using SQL and Python.
    Using what you learned in your analysis, you built both linear regression and
    deep neural network regressor models to predict power plant production using SQL
    in BigQuery ML. Along the way, you explored new concepts around topics such as
    explainability and some of the mathematics behind neural networks.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您使用SQL和Python分析了发电厂生产数据。利用您在分析中学到的内容，您构建了线性回归和深度神经网络回归模型，以使用BigQuery ML预测发电厂生产。在此过程中，您探索了关于可解释性以及神经网络背后某些数学概念的新概念。
- en: The focus of this book so far has been on no-code and low-code solutions, but
    there may be situations where you need something more flexible. In the next chapter,
    you will be introduced to custom code solutions in Python using scikit-learn and
    Keras. Both libraries are very approachable and are a great place to start your
    exploration into using Python for ML.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本书的重点一直放在无代码和低代码解决方案上，但可能会有需要更灵活解决方案的情况。在下一章中，您将介绍如何使用Python中的scikit-learn和Keras进行自定义代码解决方案。这两个库非常易于上手，是开始探索使用Python进行机器学习的绝佳选择。
- en: ^([1](ch06.html#ch01fn2-marker)) This [dataset](https://oreil.ly/_EvWy) was
    created using the Combined Cycle Power Plant dataset from UC Irvine’s Machine
    Learning Repository. Some small changes were made to better demonstrate concepts
    in this chapter.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch06.html#ch01fn2-marker)) 这个[数据集](https://oreil.ly/_EvWy)是使用来自加州大学尔湾分校机器学习库的联合循环发电厂数据集创建的。为了更好地展示本章的概念，做了一些小的修改。
