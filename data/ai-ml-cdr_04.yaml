- en: Chapter 2\. Introduction to Computer Vision
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章 介绍计算机视觉
- en: The previous chapter introduced the basics of how machine learning works. You
    saw how to get started with programming using neural networks to match data to
    labels, and from there how to infer the rules that can be used to distinguish
    items. A logical next step is to apply these concepts to computer vision, where
    we will have a model learn how to recognize content in pictures so it can “see”
    what’s in them. In this chapter you’ll work with a popular dataset of clothing
    items and build a model that can differentiate between them, thus “seeing” the
    difference between different types of clothing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章介绍了机器学习的基础知识。你看到了如何使用神经网络开始编程，将数据与标签匹配，以及从那里推断可以用来区分物品的规则。一个逻辑的下一步是将这些概念应用到计算机视觉中，在那里我们将让一个模型学习如何识别图片中的内容，以便它可以“看到”其中的内容。在这一章中，你将使用一个流行的服装项目数据集构建一个模型，该模型能够区分它们之间的差异，从而“看到”不同类型的服装。
- en: Recognizing Clothing Items
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别服装项目
- en: For our first example, let’s consider what it takes to recognize items of clothing
    in an image. Consider, for example, the items in [Figure 2-1](#examples_of_clothing).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的第一个例子，让我们考虑如何在图像中识别服装。例如，考虑[图2-1](#examples_of_clothing)中的物品。
- en: '![Examples of clothing](Images/aiml_0201.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![服装示例](Images/aiml_0201.png)'
- en: Figure 2-1\. Examples of clothing
  id: totrans-5
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-1. 服装示例
- en: There are a number of different clothing items here, and you can recognize them.
    You understand what is a shirt, or a coat, or a dress. But how would you explain
    this to somebody who has never seen clothing? How about a shoe? There are two
    shoes in this image, but how would you describe that to somebody? This is another
    area where the rules-based programming we spoke about in [Chapter 1](ch01.xhtml#introduction_to_tensorflow)
    can fall down. Sometimes it’s just infeasible to describe something with rules.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有许多不同的服装项目，你可以识别它们。你理解什么是衬衫，或者外套，或者连衣裙。但是如果要向从未见过服装的人解释这些，你该如何做？鞋子呢？这张图片中有两只鞋子，但你该如何向别人描述呢？这也是我们在[第1章](ch01.xhtml#introduction_to_tensorflow)中谈到的基于规则的编程可能遇到困难的另一个领域。有时用规则描述某些事物是不可行的。
- en: Of course, computer vision is no exception. But consider how you learned to
    recognize all these items—by seeing lots of different examples, and gaining experience
    with how they’re used. Can we do the same with a computer? The answer is yes,
    but with limitations. Let’s take a look at a first example of how to teach a computer
    to recognize items of clothing, using a well-known dataset called Fashion MNIST.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，计算机视觉也不例外。但考虑一下你是如何学会识别所有这些物品的——通过看到许多不同的例子，并且获得它们使用方式的经验。我们能否用同样的方法来训练计算机呢？答案是肯定的，但有一定的限制。让我们首先看一个例子，介绍如何教会计算机识别服装，使用一个名为Fashion
    MNIST的知名数据集。
- en: 'The Data: Fashion MNIST'
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据：Fashion MNIST
- en: One of the foundational datasets for learning and benchmarking algorithms is
    the Modified National Institute of Standards and Technology (MNIST) database,
    by Yann LeCun, Corinna Cortes, and Christopher Burges. This dataset is comprised
    of images of 70,000 handwritten digits from 0 to 9\. The images are 28 × 28 grayscale.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于学习和基准算法的基础数据集之一是由Yann LeCun、Corinna Cortes和Christopher Burges创建的Modified National
    Institute of Standards and Technology（MNIST）数据库。这个数据集包含70,000张0到9的手写数字图像。图像为28
    × 28灰度图像。
- en: '[Fashion MNIST](https://oreil.ly/31Nzu) is designed to be a drop-in replacement
    for MNIST that has the same number of records, the same image dimensions, and
    the same number of classes—so, instead of images of the digits 0 through 9, Fashion
    MNIST contains images of 10 different types of clothing. You can see an example
    of the contents of the dataset in [Figure 2-2](#exploring_the_fashion_mnist_dataset).
    Here, three lines are dedicated to each clothing item type.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[Fashion MNIST](https://oreil.ly/31Nzu) 被设计成MNIST的一个直接替代品，它具有相同数量的记录，相同的图像尺寸和相同数量的类别——因此，与数字0到9的图像不同，Fashion
    MNIST包含10种不同类型的服装的图像。你可以在[图2-2](#exploring_the_fashion_mnist_dataset)中看到数据集内容的示例。在这里，每种服装项目类型都有三行。'
- en: '![Exploring the Fashion MNIST dataset](Images/aiml_0202.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![探索Fashion MNIST数据集](Images/aiml_0202.png)'
- en: Figure 2-2\. Exploring the Fashion MNIST dataset
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-2. 探索Fashion MNIST数据集
- en: It has a nice variety of clothing, including shirts, trousers, dresses, and
    lots of types of shoes. As you may notice, it’s monochrome, so each picture consists
    of a certain number of pixels with values between 0 and 255\. This makes the dataset
    simpler to manage.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 它有各种不错的服装，包括衬衫、裤子、连衣裙和各种类型的鞋子。正如您可能注意到的，它是单色的，因此每张图片由一定数量的像素组成，其值在0到255之间。这使得数据集更容易管理。
- en: You can see a closeup of a particular image from the dataset in [Figure 2-3](#closeup_of_an_image_in_the_fashion_mnis).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到数据集中特定图像的特写在[图 2-3](#closeup_of_an_image_in_the_fashion_mnis)中。
- en: '![Closeup of an image in the Fashion MNIST dataset](Images/aiml_0203.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![Fashion MNIST 数据集中图像的特写](Images/aiml_0203.png)'
- en: Figure 2-3\. Closeup of an image in the Fashion MNIST dataset
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-3\. Fashion MNIST 数据集中的图像特写
- en: Like any image, it’s a rectangular grid of pixels. In this case the grid size
    is 28 × 28, and each pixel is simply a value between 0 and 255, as mentioned previously.
    Let’s now take a look at how you can use these pixel values with the functions
    we saw previously.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何图像一样，它是像素的矩形网格。在这种情况下，网格大小为28 × 28，每个像素只是一个值，其范围在0到255之间，如前所述。现在让我们看看如何将这些像素值与我们之前看到的函数结合起来使用。
- en: Neurons for Vision
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视觉神经元
- en: In [Chapter 1](ch01.xhtml#introduction_to_tensorflow), you saw a very simple
    scenario where a machine was given a set of X and Y values, and it learned that
    the relationship between these was Y = 2X – 1\. This was done using a very simple
    neural network with one layer and one neuron.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 1 章](ch01.xhtml#introduction_to_tensorflow)中，您看到了一个非常简单的情景，其中一台机器获得了一组 X
    和 Y 值，并且学会了它们之间的关系是 Y = 2X - 1。这是通过一个非常简单的只有一层和一个神经元的神经网络完成的。
- en: If you were to draw that visually, it might look like [Figure 2-4](#a_single_neuron_learning_a_linear_relat).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您将其以图形方式绘制出来，它可能看起来像[图 2-4](#a_single_neuron_learning_a_linear_relat)。
- en: Each of our images is a set of 784 values (28 × 28) between 0 and 255\. They
    can be our X. We know that we have 10 different types of images in our dataset,
    so let’s consider them to be our Y. Now we want to learn what the function looks
    like where Y is a function of X.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每张图像都是一组784个值（28 × 28），其值在0到255之间。它们可以是我们的 X。我们知道我们的数据集中有10种不同类型的图像，所以让我们把它们视为我们的
    Y。现在我们想学习当 Y 是 X 的函数时函数的样子。
- en: '![A single neuron learning a linear relationship](Images/aiml_0204.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![单个神经元学习线性关系](Images/aiml_0204.png)'
- en: Figure 2-4\. A single neuron learning a linear relationship
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-4\. 单个神经元学习线性关系
- en: Given that we have 784 X values per image, and our Y is going to be between
    0 and 9, it’s pretty clear that we cannot do Y = mX + c as we did earlier.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于每个图像有784个 X 值，并且我们的 Y 将在0到9之间，很显然我们不能像之前那样做 Y = mX + c。
- en: But what we *can* do is have several neurons working together. Each of these
    will learn *parameters*, and when we have a combined function of all of these
    parameters working together, we can see if we can match that pattern to our desired
    answer ([Figure 2-5](#extending_our_pattern_for_a_more_comple)).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们*可以*让多个神经元一起工作。每个神经元将学习*参数*，当我们将所有这些参数的组合函数一起工作时，我们可以看到我们是否能将这种模式匹配到我们想要的答案（[图 2-5](#extending_our_pattern_for_a_more_comple)）。
- en: '![Extending our pattern for a more complex example](Images/aiml_0205.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![扩展我们的模式以获取更复杂的例子](Images/aiml_0205.png)'
- en: Figure 2-5\. Extending our pattern for a more complex example
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-5\. 扩展我们的模式以获取更复杂的例子
- en: The boxes at the top of this diagram can be considered the pixels in the image,
    or our X values. When we train the neural network we load these into a layer of
    neurons—[Figure 2-5](#extending_our_pattern_for_a_more_comple) shows them just
    being loaded into the first neuron, but the values are loaded into each of them.
    Consider each neuron’s weight and bias (m and c) to be randomly initialized. Then,
    when we sum up the values of the output of each neuron we’re going to get a value.
    This will be done for *every* neuron in the output layer, so neuron 0 will contain
    the value of the probability that the pixels add up to label 0, neuron 1 for label
    1, etc.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此图表顶部的框可以视为图像中的像素，或者我们的 X 值。当我们训练神经网络时，我们将这些加载到一层神经元中——[图 2-5](#extending_our_pattern_for_a_more_comple)显示它们只加载到第一个神经元中，但值加载到每个神经元中。考虑每个神经元的权重和偏置（m
    和 c）是随机初始化的。然后，当我们总结每个神经元输出的值时，我们将得到一个值。这将对输出层中的*每个*神经元执行，因此神经元0将包含像素累加到标签0的概率值，神经元1对应标签1，依此类推。
- en: Over time, we want to match that value to the desired output—which for this
    image we can see is the number 9, the label for the ankle boot shown in [Figure 2-3](#closeup_of_an_image_in_the_fashion_mnis).
    So, in other words, this neuron should have the largest value of all of the output
    neurons.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，我们希望将该值与所需的输出值匹配——对于这幅图像，我们可以看到其标签是数字9，即展示在[图2-3](#closeup_of_an_image_in_the_fashion_mnis)中的脚踝靴。换句话说，这个神经元应该是所有输出神经元中值最大的一个。
- en: Given that there are 10 labels, a random initialization should get the right
    answer about 10% of the time. From that, the loss function and optimizer can do
    their job epoch by epoch to tweak the internal parameters of each neuron to improve
    that 10%. And thus, over time, the computer will learn to “see” what makes a shoe
    a shoe or a dress a dress.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于有10个标签，随机初始化应该能在大约10%的时间内得到正确答案。从那里，损失函数和优化器可以在每个时代逐步调整每个神经元的内部参数，以改进这10%。因此，随着时间的推移，计算机将学会“看到”是什么使鞋子成为鞋子或服装成为服装。
- en: Designing the Neural Network
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计神经网络
- en: 'Let’s now explore what this looks like in code. First, we’ll look at the design
    of the neural network shown in [Figure 2-5](#extending_our_pattern_for_a_more_comple):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看这在代码中是什么样子。首先，我们将看看在[图2-5](#extending_our_pattern_for_a_more_comple)中展示的神经网络的设计：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you remember, in [Chapter 1](ch01.xhtml#introduction_to_tensorflow) we had
    a `Sequential` model to specify that we had many layers. It only had one layer,
    but in this case, we have multiple layers.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记得，在[第1章](ch01.xhtml#introduction_to_tensorflow)中，我们有一个`Sequential`模型来指定我们有许多层。它只有一层，但在这种情况下，我们有多个层。
- en: The first, `Flatten`, isn’t a layer of neurons, but an input layer specification.
    Our inputs are 28 × 28 images, but we want them to be treated as a series of numeric
    values, like the gray boxes at the top of [Figure 2-5](#extending_our_pattern_for_a_more_comple).
    `Flatten` takes that “square” value (a 2D array) and turns it into a line (a 1D
    array).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个`Flatten`不是一个神经元层，而是一个输入层规范。我们的输入是28 × 28的图像，但我们希望它们被视为一系列数值，就像[图2-5](#extending_our_pattern_for_a_more_comple)顶部的灰色框中的那样。`Flatten`将那个“方形”值（一个2D数组）转换成一条线（一个1D数组）。
- en: The next one, `Dense`, is a layer of neurons, and we’re specifying that we want
    128 of them. This is the middle layer shown in [Figure 2-5](#extending_our_pattern_for_a_more_comple).
    You’ll often hear such layers described as *hidden layers*. Layers that are between
    the inputs and the outputs aren’t seen by a caller, so the term “hidden” is used
    to describe them. We’re asking for 128 neurons to have their internal parameters
    randomly initialized. Often the question I’ll get asked at this point is “Why
    128?” This is entirely arbitrary—there’s no fixed rule for the number of neurons
    to use. As you design the layers you want to pick the appropriate number of values
    to enable your model to actually learn. More neurons means it will run more slowly,
    as it has to learn more parameters. More neurons could also lead to a network
    that is great at recognizing the training data, but not so good at recognizing
    data that it hasn’t previously seen (this is known as *overfitting*, and we’ll
    discuss it later in this chapter). On the other hand, fewer neurons means that
    the model might not have sufficient parameters to learn.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的`Dense`是一个神经元层，我们正在指定我们想要128个神经元。这是在[图2-5](#extending_our_pattern_for_a_more_comple)中展示的中间层。你经常会听到这样的层被描述为*隐藏层*。位于输入和输出之间的层对调用者是不可见的，因此术语“隐藏”用于描述它们。我们请求128个神经元以随机初始化其内部参数。通常在这一点上我会被问到的问题是“为什么是128？”这完全是任意的——没有固定的神经元数量规则。在设计层时，您需要选择适当数量的值以使您的模型真正学习。更多的神经元意味着它会运行得更慢，因为它必须学习更多的参数。更多的神经元也可能导致网络非常擅长识别训练数据，但在识别以前没有见过的数据时可能不那么好（这称为*过拟合*，我们稍后在本章中讨论）。另一方面，更少的神经元意味着模型可能没有足够的参数来学习。
- en: It takes some experimentation over time to pick the right values. This process
    is typically called *hyperparameter tuning*. In machine learning, a hyperparameter
    is a value that is used to control the training, as opposed to the internal values
    of the neurons that get trained/learned, which are referred to as parameters.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 需要一些时间的实验来选择正确的值。这个过程通常被称为*超参数调整*。在机器学习中，超参数是用来控制训练的值，而不是被训练/学习的神经元的内部值，这些被称为参数。
- en: You might notice that there’s also an *activation function* specified in that
    layer. The activation function is code that will execute on each neuron in the
    layer. TensorFlow supports a number of them, but a very common one in middle layers
    is `relu`, which stands for *rectified linear unit*. It’s a simple function that
    just returns a value if it’s greater than 0\. In this case, we don’t want negative
    values being passed to the next layer to potentially impact the summing function,
    so instead of writing a lot of `if-then` code, we can simply activate the layer
    with `relu`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能注意到该层还指定了一个*激活函数*。激活函数是在该层中每个神经元上执行的代码。TensorFlow支持多种激活函数，但在中间层中非常常见的一种是`relu`，即*修正线性单元*。它是一个简单的函数，如果大于0则返回该值。在这种情况下，我们不希望负值传递到下一层，可能影响求和函数，所以我们可以简单地使用`relu`激活该层，而不是编写大量的`if-then`代码。
- en: Finally, there’s another `Dense` layer, which is the output layer. This has
    10 neurons, because we have 10 classes. Each of these neurons will end up with
    a probability that the input pixels match that class, so our job is to determine
    which one has the highest value. We could loop through them to pick that value,
    but the `softmax` activation function does that for us.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，还有另一个`Dense`层，这是输出层。这有10个神经元，因为我们有10个类别。这些神经元每个都将得到一个概率，即输入像素匹配该类别，所以我们的任务是确定哪一个具有最高的值。我们可以循环遍历它们来选择那个值，但`softmax`激活函数会为我们完成这个任务。
- en: So now when we train our neural network, the goal is that we can feed in a 28
    × 28-pixel array and the neurons in the middle layer will have weights and biases
    (m and c values) that when combined will match those pixels to one of the 10 output
    values.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在当我们训练我们的神经网络时，目标是我们可以输入一个28×28像素数组，中间层的神经元将有权重和偏置（m和c值），当组合时将这些像素匹配到10个输出值中的一个。
- en: The Complete Code
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完整的代码
- en: 'Now that we’ve explored the architecture of the neural network, let’s look
    at the complete code for training one with the Fashion MNIST data:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了神经网络的架构，让我们来看看用Fashion MNIST数据训练的完整代码：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s walk through this piece by piece. First is a handy shortcut for accessing
    the data:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步走过这段文字。首先是一个方便的快捷方式来访问数据：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Keras has a number of built-in datasets that you can access with a single line
    of code like this. In this case you don’t have to handle downloading the 70,000
    images—splitting them into training and test sets, and so on—all it takes is one
    line of code. This methodology has been improved upon using an API called [TensorFlow
    Datasets](https://oreil.ly/gM-Cq), but for the purposes of these early chapters,
    to reduce the number of new concepts you need to learn, we’ll just use `tf.keras.datasets`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Keras有许多内置数据集，您可以像这样用一行代码访问。在这种情况下，您不必处理下载70,000张图片、将它们分割为训练和测试集等问题，只需一行代码就可以搞定。这种方法已经得到了改进，使用一个名为[TensorFlow数据集](https://oreil.ly/gM-Cq)的API，但在这些早期章节中，为了减少您需要学习的新概念数量，我们将仅使用`tf.keras.datasets`。
- en: 'We can call its `load_data` method to return our training and test sets like
    this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以调用它的`load_data`方法来返回我们的训练集和测试集，就像这样：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Fashion MNIST is designed to have 60,000 training images and 10,000 test images.
    So, the return from `data.load_data` will give you an array of 60,000 28 × 28-pixel
    arrays called `training_images`, and an array of 60,000 values (0–9) called `training_labels`.
    Similarly, the `test_images` array will contain 10,000 28 × 28-pixel arrays, and
    the `test_labels` array will contain 10,000 values between 0 and 9.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Fashion MNIST被设计为有60,000张训练图像和10,000张测试图像。所以，从`data.load_data`返回的将是一个包含60,000个28×28像素数组的`training_images`数组，以及一个包含60,000个值（0-9）的`training_labels`数组。类似地，`test_images`数组将包含10,000个28×28像素数组，而`test_labels`数组将包含10,000个值，范围在0到9之间。
- en: Our job will be to fit the training images to the training labels in a similar
    manner to how we fit Y to X in [Chapter 1](ch01.xhtml#introduction_to_tensorflow).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的任务将是以类似的方式将训练图像适配到训练标签，就像我们在[第1章](ch01.xhtml#introduction_to_tensorflow)中将Y适配到X一样。
- en: We’ll hold back the test images and test labels so that the network does not
    see them while training. These can be used to test the efficacy of the network
    with hitherto unseen data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将保留测试图像和测试标签，这样网络在训练时不会看到它们。这些可以用来测试网络在之前未见数据上的有效性。
- en: 'The next lines of code might look a little unusual:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的几行代码可能看起来有点不寻常：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Python allows you to do an operation across the entire array with this notation.
    Recall that all of the pixels in our images are grayscale, with values between
    0 and 255\. Dividing by 255 thus ensures that every pixel is represented by a
    number between 0 and 1 instead. This process is called *normalizing* the image.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Python 允许您使用此表示在整个数组上执行操作。请记住，我们图像中的所有像素都是灰度的，值在 0 到 255 之间。因此，除以 255 可确保每个像素由一个在
    0 到 1 之间的数字表示。这个过程称为*归一化*图像。
- en: The math for why normalized data is better for training neural networks is beyond
    the scope of this book, but bear in mind when training a neural network in TensorFlow
    that normalization will improve performance. Often your network will not learn
    and will have massive errors when dealing with non normalized data. The Y = 2X
    – 1 example from [Chapter 1](ch01.xhtml#introduction_to_tensorflow) didn’t require
    the data to be normalized because it was very simple, but for fun try training
    it with different values of X and Y where X is much larger and you’ll see it quickly
    fail!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么归一化数据对训练神经网络更好的数学原理超出了本书的范围，但请记住，在 TensorFlow 中训练神经网络时，归一化将改善性能。通常情况下，处理非归一化数据时，您的网络将无法学习，并且将会出现严重的错误。从[第1章](ch01.xhtml#introduction_to_tensorflow)中的
    Y = 2X - 1 示例可以看出，该数据不需要进行归一化，因为它非常简单，但是尝试使用 X 值不同的不同 Y 值进行训练，您将会看到它迅速失败！
- en: 'Next we define the neural network that makes up our model, as discussed earlier:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们定义组成我们模型的神经网络，如前所述：
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'When we compile our model we specify the loss function and the optimizer as
    before:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们编译我们的模型时，我们像以前一样指定损失函数和优化器：
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The loss function in this case is called *sparse categorical cross entropy*,
    and it’s one of the arsenal of loss functions that are built into TensorFlow.
    Again, choosing which loss function to use is an art in itself, and over time
    you’ll learn which ones are best to use in which scenarios. One major difference
    between this model and the one we created in [Chapter 1](ch01.xhtml#introduction_to_tensorflow)
    is that instead of us trying to predict a single number, here we’re picking a
    *category*. Our item of clothing will belong to 1 of 10 categories of clothing,
    and thus using a *categorical* loss function is the way to go. Sparse categorical
    cross entropy is a good choice.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，损失函数称为*稀疏分类交叉熵*，它是内置于 TensorFlow 中的损失函数库中的一员。再次选择使用哪种损失函数本身就是一门艺术，随着时间的推移，您将学会在哪些场景中使用最佳。这个模型与我们在[第1章](ch01.xhtml#introduction_to_tensorflow)中创建的模型之间的一个主要区别是，这里不是我们试图预测一个单一的数字，而是我们正在选择一个*类别*。我们的服装物品将属于10个服装类别之一，因此使用*分类*损失函数是正确的选择。稀疏分类交叉熵是一个不错的选择。
- en: The same applies to choosing an optimizer. The `adam` optimizer is an evolution
    of the stochastic gradient descent (`sgd`) optimizer we used in [Chapter 1](ch01.xhtml#introduction_to_tensorflow)
    that has been shown to be faster and more efficient. As we’re handling 60,000
    training images, any performance improvement we can get will be helpful, so that
    one is chosen here.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 选择优化器也是如此。`adam` 优化器是随机梯度下降 (`sgd`) 优化器的进化版，已被证明更快更高效。由于我们处理 60,000 张训练图像，我们能获得的任何性能提升都将是有帮助的，所以这里选择了它。
- en: You might notice that a new line specifying the metrics we want to report is
    also present in this code. Here, we want to report back on the accuracy of the
    network as we’re training. The simple example in [Chapter 1](ch01.xhtml#introduction_to_tensorflow)
    just reported on the loss, and we interpreted that the network was learning by
    looking at how the loss was reduced. In this case, it’s more useful to us to see
    how the network is learning by looking at the accuracy—where it will return how
    often it correctly matched the input pixels to the output label.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会注意到代码中还有一行新的指定我们要报告的指标。在这里，我们想要报告网络的准确性，因为我们正在训练。在[第1章](ch01.xhtml#introduction_to_tensorflow)中的简单示例只报告了损失，我们通过减少损失来解释网络正在学习。在这种情况下，更有用的是查看网络如何学习，即它将返回正确匹配输入像素与输出标签的频率。
- en: 'Next, we’ll train the network by fitting the training images to the training
    labels over five epochs:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过五个周期将训练图像拟合到训练标签来训练网络：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, we can do something new—evaluate the model, using a single line of
    code. We have a set of 10,000 images and labels for testing, and we can pass them
    to the trained model to have it predict what it thinks each image is, compare
    that to its actual label, and sum up the results:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以做一些新的事情——使用一行代码来评估模型。我们有一组 10,000 张图像和测试标签，可以将它们传递给训练好的模型，让它预测每张图像的内容，并将其与实际标签进行比较，然后汇总结果：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Training the Neural Network
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练神经网络
- en: 'Execute the code, and you’ll see the network train epoch by epoch. After running
    the training, you’ll see something at the end that looks like this:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 执行代码，你将看到网络逐个 epoch 进行训练。在运行训练后，你将看到类似于以下内容的结果：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that it’s now reporting accuracy. So in this case, using the training data,
    our model ended up with an accuracy of about 89% after only five epochs.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在它报告准确率。所以在这种情况下，使用训练数据，我们的模型在只经过五个 epochs 后的准确率约为 89%。
- en: 'But what about the test data? The results of `model.evaluate` on our test data
    will look something like this:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 但是测试数据呢？在我们的测试数据上执行`model.evaluate`的结果会看起来像这样：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In this case the accuracy of the model was 87.36%, which isn’t bad considering
    we only trained it for five epochs.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，模型的准确率为 87.36%，考虑到我们只训练了五个 epochs，这还算不错。
- en: 'You’re probably wondering why the accuracy is *lower* for the test data than
    it is for the training data. This is very commonly seen, and when you think about
    it, it makes sense: the neural network only really knows how to match the inputs
    it has been trained on with the outputs for those values. Our hope is that, given
    enough data, it will be able to generalize from the examples it has seen, “learning”
    what a shoe or a dress looks like. But there will always be examples of items
    that it hasn’t seen that are sufficiently different from what it has to confuse
    it.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想为什么测试数据的准确率*低于*训练数据。这是非常常见的现象，仔细想想就明白了：神经网络实际上只知道如何将其训练过的输入与相应的输出进行匹配。我们希望，如果提供足够的数据，它能够从所见的例子中进行泛化，“学习”出鞋子或裙子的外观。但总会有一些它从未见过的与其所知不同的例子会让它感到困惑。
- en: For example, if you grew up only ever seeing sneakers, and that’s what a shoe
    looks like to you, when you first see a high heel you might be a little confused.
    From your experience, it’s probably a shoe, but you don’t know for sure. This
    is a similar concept.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你的成长经历中只见过运动鞋，那对你来说运动鞋就是鞋子的样子，当你第一次看到高跟鞋时可能会感到有些困惑。从你的经验来看，它可能是一只鞋，但你并不确定。这是一个类似的概念。
- en: Exploring the Model Output
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索模型输出
- en: 'Now that the model has been trained, and we have a good gage of its accuracy
    using the test set, let’s explore it a little:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经训练好了，我们通过测试集也有了它的准确度，让我们来稍微探索一下它：
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We’ll get a set of classifications by passing the test images to `model.predict`.
    Then let’s see what we get if we print out the first of the classifications and
    compare it to the test label:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过`model.predict`传递测试图像来获得一组分类。然后，让我们看看如果我们打印出第一个分类结果并将其与测试标签进行比较会得到什么：
- en: '[PRE12]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You’ll notice that the classification gives us back an array of values. These
    are the values of the 10 output neurons. The label is the actual label for the
    item of clothing, in this case `9`. Take a look through the array—you’ll see that
    some of the values are very small, and the last one (array index 9) is the largest
    by far. These are the probabilities that the image matches the label at that particular
    index. So, what the neural network is reporting is that there’s a 91.4% chance
    that the item of clothing at index 0 is label 9\. We know that it’s label 9, so
    it got it right.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到分类结果返回给我们一个值数组。这些是 10 个输出神经元的值。标签是衣物的实际标签，本例中是`9`。浏览一下数组——你会看到一些值非常小，而最后一个值（数组索引
    9）远远最大。这些是图像与特定索引处标签匹配的概率。所以，神经网络报告的是图像在索引 0 处是标签 9 的概率为 91.4%。我们知道它是标签 9，所以它预测正确了。
- en: Try a few different values for yourself, and see if you can find anywhere the
    model gets it wrong.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 试试不同的值，看看模型哪里预测错误。
- en: Training for Longer—Discovering Overfitting
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更长时间的训练——发现过拟合
- en: 'In this case, we trained for only five epochs. That is, we went through the
    entire training loop of having the neurons randomly initialized, checked against
    their labels, having that performance measured by the loss function, and then
    updated by the optimizer five times. And the results we got were pretty good:
    89% accuracy on the training set and 87% on the test set. So what happens if we
    train for longer?'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们只训练了五个 epochs。也就是说，我们通过整个训练循环，神经元被随机初始化，根据它们的标签进行检查，通过损失函数来衡量性能，然后由优化器更新了五次。我们得到的结果非常不错：训练集准确率为
    89%，测试集准确率为 87%。那么，如果我们训练更长时间会发生什么呢？
- en: 'Try updating it to train for 50 epochs instead of 5\. In my case, I got these
    accuracy figures on the training set:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试将其更新为训练 50 个 epochs 而不是 5 个。在我的情况下，我在训练集上得到了这些准确率数据：
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This is particularly exciting because we’re doing much better: 96.27% accuracy.
    For the test set we reach 88.6%:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这特别令人兴奋，因为我们的表现要好得多：96.27% 的准确率。对于测试集，我们达到了 88.6%：
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: So, we got a big improvement on the training set, and a smaller one on the test
    set. This might suggest that training our network for much longer would lead to
    much better results—but that’s not always the case. The network is doing much
    better with the training data, but it’s not necessarily a better model. In fact,
    the divergence in the accuracy numbers shows that it has become overspecialized
    to the training data, a process often called *overfitting*. As you build more
    neural networks this is something to watch out for, and as you go through this
    book you’ll learn a number of techniques to avoid it.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们在训练集上有了很大的改进，而在测试集上只有小幅改进。这可能表明，如果我们训练我们的网络更长时间，结果会更好——但并非总是如此。网络在训练数据上表现更好，但不一定是一个更好的模型。事实上，准确率数字的分歧表明它已经过度专门化于训练数据，这个过程通常称为
    *过拟合*。在构建更多神经网络时，这是需要注意的问题，而在你阅读本书的过程中，你将学习到一些避免这种情况的技巧。
- en: Stopping Training
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 停止训练
- en: In each of the cases so far, we’ve hardcoded the number of epochs we’re training
    for. While that works, we might want to train until we reach the desired accuracy
    instead of constantly trying different numbers of epochs and training and retraining
    until we get to our desired value. So, for example, if we want to train until
    the model is at 95% accuracy on the training set, without knowing how many epochs
    that will take, how could we do that?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在每种情况下，我们都硬编码了我们训练的 epochs 数量。虽然这样做是有效的，但我们可能希望训练直到达到期望的准确率，而不是不断尝试不同的
    epochs 数量，重新训练直到达到我们想要的值。例如，如果我们想要在训练集上达到 95% 的准确率而不知道需要多少 epochs，我们该怎么做？
- en: 'The easiest approach is to use a *callback* on the training. Let’s take a look
    at the updated code that uses callbacks:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法是在训练上使用 *callback*。让我们看看使用回调函数的更新代码：
- en: '[PRE15]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Let’s see what we’ve changed here. First, we created a new class called `myCallback`.
    This takes a `tf.keras.callbacks.Callback` as a parameter. In it, we define the
    `on_epoch_end` function, which will give us details about the logs for this epoch.
    In these logs is an accuracy value, so all we have to do is see if it is greater
    than .95 (or 95%); if it is, we can stop training by saying `self.model.stop_training
    = True`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这里发生了什么变化。首先，我们创建了一个名为 `myCallback` 的新类。它接受 `tf.keras.callbacks.Callback`
    作为参数。在其中，我们定义了 `on_epoch_end` 函数，它将给我们提供这个 epoch 的日志详情。在这些日志中有一个准确率值，所以我们所要做的就是看它是否大于
    0.95（或 95%）；如果是，我们可以通过设置 `self.model.stop_training = True` 来停止训练。
- en: Once we’ve specified this, we create a `callbacks` object to be an instance
    of the `myCallback` function.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们指定了这一点，我们创建一个 `callbacks` 对象，作为 `myCallback` 函数的一个实例。
- en: Now check out the `model.fit` statement. You’ll see that I’ve updated it to
    train for 50 epochs, and then added a `callbacks` parameter. To this, I pass the
    `callbacks` object.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在看看 `model.fit` 语句。你会看到我已经更新为训练 50 个 epochs，并添加了一个 `callbacks` 参数。我将 `callbacks`
    对象传递给它。
- en: 'When training, at the end of every epoch, the callback function will be called.
    So at the end of each epoch you’ll check, and after about 34 epochs you’ll see
    that your training will end, because the training has hit 95% accuracy (your number
    may be slightly different because of the initial random initialization, but it
    will likely be quite close to 34):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，每个 epoch 结束时，回调函数将被调用。所以在每个 epoch 结束后你会检查一下，在大约 34 个 epochs 后，你会看到你的训练结束了，因为训练已经达到了
    95% 的准确率（由于初始随机初始化的不同，你的数字可能会有所不同，但它很可能非常接近 34）：
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Summary
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In [Chapter 1](ch01.xhtml#introduction_to_tensorflow) you learned about how
    machine learning is based on fitting features to labels through sophisticated
    pattern matching with a neural network. In this chapter you took that to the next
    level, going beyond a single neuron, and learned how to create your first (very
    basic) computer vision neural network. It was somewhat limited because of the
    data. All the images were 28 × 28 grayscale, with the item of clothing centered
    in the frame. It’s a good start, but it is a very controlled scenario. To do better
    at vision, we might need the computer to learn features of an image instead of
    merely the raw pixels.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](ch01.xhtml#introduction_to_tensorflow)中，你学习了机器学习是如何通过神经网络将特征与标签匹配来进行复杂的模式匹配。在这一章中，你将这一过程推向了更高的水平，超越了单个神经元，学会了如何创建你的第一个（非常基础的）计算机视觉神经网络。由于数据的限制，它有些受限。所有的图像都是28
    × 28的灰度图像，服装物品居中在框架内。这是一个很好的开端，但这只是一个非常受控制的情景。要在视觉方面做得更好，我们可能需要计算机学习图像的特征，而不仅仅是原始像素。
- en: We can do that with a process called *convolutions*. You’ll learn how to define
    convolutional neural networks to understand the contents of images in the next
    chapter.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过一种叫做*卷积*的过程来实现这一点。在下一章中，你将学习如何定义卷积神经网络来理解图像的内容。
