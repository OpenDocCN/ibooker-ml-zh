- en: 'Chapter 1\. Modernizing Your Data Platform: An Introductory Overview'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章：现代化您的数据平台：简介概述
- en: Data is a valuable asset that can help your company make better decisions, identify
    new opportunities, and improve operations. Google in 2013 undertook a strategic
    project to increase employee retention by improving manager quality. Even something
    as loosey-goosey as manager skill could be studied in a data-driven manner. Google
    was able to [improve management favorability](https://oreil.ly/MN6eZ) from 83%
    to 88% by analyzing 10K performance reviews, identifying common behaviors of high-performing
    managers, and creating training programs. Another example of a strategic data
    project was carried out at Amazon. The ecommerce giant implemented a [recommendation
    system based on customer behaviors](https://oreil.ly/URxN_) that drove 35% of
    purchases in 2017\. The Warriors, a San Francisco basketball team, is yet another
    example; they enacted an [analytics program](https://oreil.ly/dFZRW) that helped
    catapult them to the top of their league. All these—employee retention, product
    recommendations, improving win rates—are examples of business goals that were
    achieved by modern data analytics.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是一项宝贵的资产，可以帮助您的公司做出更好的决策，发现新的机会并改善运营。2013年，谷歌进行了一项战略性项目，通过提高经理质量来增加员工保留率。甚至像管理技能这样宽泛的事物也可以以数据驱动的方式进行研究。谷歌通过分析1万份绩效评审，识别高绩效经理的共同行为，并创建培训计划，将[管理偏好](https://oreil.ly/MN6eZ)从83%提高到88%。亚马逊也进行了一项战略性数据项目，实施了基于客户行为的[推荐系统](https://oreil.ly/URxN_)，该系统在2017年驱动了35%的购买。旧金山勇士篮球队是另一个例子；他们实施了一个[分析程序](https://oreil.ly/dFZRW)，帮助他们在联盟中跻身顶级。所有这些——员工保留、产品推荐、提高胜率——都是通过现代数据分析实现的商业目标。
- en: To become a data-driven company, you need to build an ecosystem for data analytics,
    processing, and insights. This is because there are many different types of applications
    (websites, dashboards, mobile apps, ML models, distributed devices, etc.) that
    create and consume data. There are also many different departments within your
    company (finance, sales, marketing, operations, logistics, etc.) that need data-driven
    insights. Because the entire company is your customer base, building a data platform
    is more than just an IT project.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 要成为一家数据驱动型公司，您需要建立一个数据分析、处理和洞察生态系统。这是因为有许多不同类型的应用程序（网站、仪表板、移动应用、机器学习模型、分布式设备等）会生成和消耗数据。您公司内部也有许多不同部门（财务、销售、营销、运营、物流等），它们需要数据驱动的洞察。由于整个公司都是您的客户群体，构建数据平台不仅仅是一个IT项目。
- en: This chapter introduces data platforms, their requirements, and why traditional
    data architectures prove insufficient. It also discusses technology trends in
    data analytics and AI, and how to build data platforms for the future using the
    public cloud. This chapter is a general overview of the core topics covered in
    more detail in the rest of the book.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了数据平台、其需求以及传统数据架构为何不足以满足要求。它还讨论了数据分析和人工智能的技术趋势，以及如何利用公共云构建未来的数据平台。本章概述了本书其余部分详细讨论的核心主题。
- en: The Data Lifecycle
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据生命周期
- en: The purpose of a data platform is to support the steps that organizations need
    to carry out to move from raw data to insightful information. It is helpful to
    understand the steps of the data lifecycle (collect, store, process, visualize,
    activate) because they can be mapped almost as-is to a data architecture to create
    a unified analytics platform.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 数据平台的目的是支持组织从原始数据到见解信息所需的步骤。了解数据生命周期的步骤（收集、存储、处理、可视化、激活）是有帮助的，因为它们几乎可以直接映射到数据架构，从而创建一个统一的分析平台。
- en: The Journey to Wisdom
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 智慧之旅
- en: 'Data helps companies to develop smarter products, reach more customers, and
    increase their return on investment (ROI). Data can also be leveraged to measure
    customer satisfaction, profitability, and cost. But the data by itself is not
    enough. Data is raw material that needs to pass through a series of stages before
    it can be used to generate insights and knowledge. This sequence of stages is
    what we call a *data lifecycle*. There are many definitions available in the literature,
    but from a general point of view, we can identify five main stages in modern data
    platform architecture:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 数据帮助公司开发更智能的产品，接触更多客户，并增加他们的投资回报率（ROI）。数据还可以用于衡量客户满意度、盈利能力和成本。但是单靠数据本身是不够的。数据是原材料，需要经过一系列阶段才能用于生成洞见和知识。这一系列阶段就是我们所说的*数据生命周期*。文献中有许多不同的定义，但从一般的角度来看，我们可以确定现代数据平台架构中的五个主要阶段：
- en: 1\. Collect
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 收集
- en: Data has to be acquired and injected into the target systems (e.g., manual data
    entry, batch loading, streaming ingestion, etc.).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据必须被获取并注入到目标系统中（例如，手动数据输入、批量加载、流式摄取等）。
- en: 2\. Store
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 存储
- en: Data needs to be persisted in a durable fashion with the ability to easily access
    it in the future (e.g., file storage system, database).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据需要以持久的方式存储，并且能够在将来轻松访问（例如，文件存储系统、数据库）。
- en: 3\. Process/transform
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 处理/转换
- en: Data has to be manipulated to make it useful for subsequent steps (e.g., cleansing,
    wrangling, transforming).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据必须经过处理以使其对后续步骤有用（例如，清洗、整理、转换）。
- en: 4\. Analyze/visualize
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 分析/可视化
- en: Data needs to be studied to derive business insights via manual elaboration
    (e.g., queries, slice and dice) or automatic processing (e.g., enrichment using
    ML application programming interfaces—APIs).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 需要研究数据，通过手动详细描述（例如，查询、切片和切块）或自动处理（例如，使用ML应用程序接口进行增强）来推导业务洞见。
- en: 5\. Activate
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 激活
- en: Surfacing the data insights in a form and place where decisions can be made
    (e.g., notifications that act as a trigger for specific manual actions, automatic
    job executions when specific conditions are met, ML models that send feedback
    to devices).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据洞见表现在一种形式和位置上，以便做出决策（例如，通知作为特定手动操作的触发器、在满足特定条件时执行自动作业、ML模型向设备发送反馈）。
- en: Each of these stages feeds into the next, similar to the flow of water through
    a set of pipes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 每个阶段都与下一个阶段相互关联，类似于水通过一组管道的流动。
- en: Water Pipes Analogy
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 水管类比
- en: To understand the data lifecycle better, think of it as a simplified water pipe
    system. The water starts at an aqueduct and is then transferred and transformed
    through a series of pipes until it reaches a group of houses. The data lifecycle
    is similar, with data being collected, stored, processed/transformed, and analyzed
    before it is used to make decisions (see [Figure 1-1](#water_lifecyclecomma_providing_an_analo)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要更好地理解数据生命周期，可以将其视为简化的水管系统。水从水道开始，然后通过一系列管道进行转移和转换，直到到达一组房屋。数据生命周期类似，数据在被收集、存储、处理/转换和分析之前，需经历这些阶段，然后才能用于决策（见[图1-1](#water_lifecyclecomma_providing_an_analo)）。
- en: '![Water lifecycle, providing an analogy for the five steps in the data lifecycle](assets/adml_0101.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![水循环，为数据生命周期中的五个步骤提供类比](assets/adml_0101.png)'
- en: Figure 1-1\. Water lifecycle, providing an analogy for the five steps in the
    data lifecycle
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 水循环，为数据生命周期中的五个步骤提供类比。
- en: You can see some similarities between the plumbing world and the data world.
    Plumbing engineers are like data engineers, who design and build the systems that
    make data usable. People who analyze water samples are like data analysts and
    data scientists, who analyze data to find insights. Of course, this is just a
    simplification. There are many other roles in a company that use data, like executives,
    developers, business users, and security administrators. But this analogy can
    help you remember the main concepts.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到管道世界与数据世界之间的一些相似之处。管道工程师就像数据工程师，他们设计并建造使数据可用的系统。分析水样本的人就像数据分析师和数据科学家，他们分析数据以找到洞见。当然，这只是一个简化。公司中有许多其他使用数据的角色，如高管、开发人员、业务用户和安全管理员。但是这种类比可以帮助你记住主要的概念。
- en: In the canonical data lifecycle, shown in [Figure 1-2](#simplified_data_lifecycle),
    data engineers collect and store data in an analytics store. The stored data is
    then processed using a variety of tools. If the tools involve programming, the
    processing is typically done by data engineers. If the tools are declarative,
    the processing is typically done by data analysts. The processed data is then
    analyzed by business users and data scientists. Business users use the insights
    to make decisions, such as launching marketing campaigns or issuing refunds. Data
    scientists use the data to train ML models, which can be used to automate tasks
    or make predictions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在经典的数据生命周期中，如[图1-2](#simplified_data_lifecycle)所示，数据工程师会在分析存储中收集和存储数据。然后使用各种工具处理存储的数据。如果工具涉及编程，处理通常由数据工程师完成。如果工具是声明性的，处理通常由数据分析师完成。处理后的数据然后由业务用户和数据科学家进行分析。业务用户利用这些洞察力做出决策，例如推出营销活动或发放退款。数据科学家利用数据训练机器学习模型，这些模型可以用于自动化任务或进行预测。
- en: '![Simplified data lifecycle](assets/adml_0102.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![简化数据生命周期](assets/adml_0102.png)'
- en: Figure 1-2\. Simplified data lifecycle
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. 简化数据生命周期
- en: The real world may differ from the preceding idealized description of how a
    modern data platform architecture and roles should work. The stages may be combined
    (e.g., storage and processing) or reordered (e.g., processing before storage,
    as in ETL [extract-transform-load], rather than storage before processing, as
    in ELT [extract-load-transform]). However, there are trade-offs to such variations.
    For example, combining storage and processing into a single stage leads to coupling
    that results in wasted resources (if data sizes grow, you’ll need to scale both
    storage and compute) and scalability issues (if your infrastructure can’t handle
    the extra load, you’ll be stuck).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界可能与前述现代数据平台架构和角色应如何工作的理想化描述不同。阶段可能会合并（例如存储和处理）或重新排序（例如处理在存储之前，如ETL [抽取-转换-加载]，而不是存储在处理之前，如ELT
    [抽取-加载-转换]）。然而，这些变化有其权衡之处。例如，将存储和处理合并为单个阶段会导致耦合，从而导致资源浪费（如果数据大小增长，您将需要扩展存储和计算）和可扩展性问题（如果您的基础设施无法处理额外负载，您将受阻）。
- en: Now that we have defined the data lifecycle and summarized the various stages
    of the data journey from raw data collection to activation, let us go through
    each of the five stages of the data lifecycle in turn.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了数据生命周期并总结了数据从原始数据收集到激活的各个阶段的旅程，让我们依次过一遍数据生命周期的五个阶段。
- en: Collect
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收集
- en: 'The first step in the design process is ingestion. *Ingestion* is the process
    of transferring data from a source, which could be anywhere (on premises, on devices,
    in another cloud, etc.), to a target system where it can be stored for further
    analysis. This is the first opportunity to consider the 3Vs of big data:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 设计过程中的第一步是摄取。*摄取*是将数据从源头（可以是任何地方，例如本地、设备、另一个云等）传输到目标系统的过程，在目标系统中可以进一步进行分析。这是考虑大数据的3V的第一个机会：
- en: Volume
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 体积
- en: What is the size of the data? Usually when dealing with big data this means
    terabyte (TB) or petabyte (PB) of data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的大小是多少？通常在处理大数据时，这意味着数据量是以TB（terabyte）或PB（petabyte）为单位。
- en: Velocity
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 速度
- en: What is the speed of the data coming in? Generally this is megabyte/second (MB/s)
    or TB/day. This is often termed the *throughput*.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 数据进入的速度是多少？一般来说，这是以MB/秒（megabyte/second）或TB/天（terabyte/day）计算的。这通常被称为*吞吐量*。
- en: Variety
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 多样性
- en: What is the format of the data? Tables, flat files, images, sound, text, etc.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的格式是什么？表格、扁平文件、图像、声音、文本等等。
- en: Identify the data type (structured, semistructured, unstructured), format, and
    generation frequency (continuously or at specific intervals) of the data to be
    collected. Based on the velocity of the data and the capability of the data platform
    to handle the resulting volume and variety, choose between batch ingestion, streaming
    ingestion, or a hybrid of the two.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 确定要收集的数据类型（结构化、半结构化、非结构化）、格式和生成频率（连续或特定间隔）。根据数据的速度和数据平台处理结果的体积和多样性的能力，选择批处理摄取、流式摄取或两者混合。
- en: As different parts of the organization may be interested in different data sources,
    design this stage to be as flexible as possible. There are several commercial
    and open source solutions that can be used, each specialized for a specific data
    type/approach mentioned earlier. Your data platform will need to be comprehensive
    and support the full range of volume, velocity, and variety required for all the
    data that needs to be ingested into the platform. You could have simple tools
    that transfer files between File Transfer Protocol (FTP) servers on regular intervals,
    or you could have complex systems, even geographically distributed, that collect
    data from IoT devices in real time.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于组织的不同部分可能对不同的数据源感兴趣，请设计此阶段尽可能灵活。有几种商业和开源解决方案可供选择，每种解决方案都专门用于前面提到的特定数据类型/方法。您的数据平台将需要全面支持所需的所有数据摄入平台所需的各种数据量、速度和多样性。您可以使用简单的工具定期在文件传输协议（FTP）服务器之间传输文件，或者您可以使用复杂的系统，甚至在地理上分布，实时从物联网设备收集数据。
- en: Store
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储
- en: In this step, store the raw data you collected in the previous step. You don’t
    change the data at all, you just store it. This is important because you might
    want to reprocess the data in a different way later, and you need to have the
    original data to do that.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，存储您在上一步中收集的原始数据。您不改变数据，只是存储它。这很重要，因为您可能希望以不同的方式重新处理数据，而您需要原始数据来完成这一操作。
- en: Data comes in many different forms and sizes. The way you store it will depend
    on your technical and commercial needs. Some common options include object storage
    systems, relational database management systems (RDBMSs), data warehouses (DWHs),
    and data lakes. Your choice will be driven to some extent by whether the underlying
    hardware, software, and artifacts are able to cope with the scalability, cost,
    availability, durability, and openness requirements imposed by your desired use
    cases.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 数据有许多不同的形式和大小。存储数据的方式将取决于您的技术和商业需求。一些常见的选项包括对象存储系统、关系数据库管理系统（RDBMS）、数据仓库（DWH）和数据湖。您的选择在某种程度上将受到底层硬件、软件和工件是否能够满足您所需的可扩展性、成本、可用性、耐久性和开放性需求的驱动。
- en: Scalability
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可扩展性
- en: '*Scalability* is the ability to grow and manage increased demands in a capable
    manner. There are two main ways to achieve scalability:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*可扩展性*是以一种能够处理增加需求的方式进行增长和管理的能力。实现可扩展性有两种主要方式：'
- en: Vertical scalability
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 垂直扩展
- en: This involves adding extra expansion units to the same node to increase the
    storage system’s capacity.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及向同一节点添加额外的扩展单元，以增加存储系统的容量。
- en: Horizontal scalability
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 水平扩展
- en: This involves adding one or more additional nodes instead of adding new expansion
    units to a single node. This type of distributed storage is more complex to manage,
    but it can achieve improved performance and efficiency.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及添加一个或多个附加节点，而不是向单个节点添加新的扩展单元。这种分布式存储类型管理更复杂，但可以实现更好的性能和效率。
- en: 'It is extremely important that the underlying system is able to cope with the
    volume and velocity required by modern solutions that have to work in an environment
    where the data is exploding and its nature is transitioning from batch to real
    time: we are living in a world where the majority of the people are continuously
    generating and requiring access to the information leveraging their smart devices;
    organizations need to be able to provide their users (both internal and external)
    with solutions that are able to provide real-time responses to the various requests.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 极为重要的是，底层系统能够应对现代解决方案所需的体积和速度，这些解决方案必须在数据不断增长且性质从批处理向实时转变的环境中运行：我们生活在一个大多数人持续生成并要求访问信息的世界，他们利用智能设备；组织需要能够为其用户（内部和外部）提供能够对各种请求提供实时响应的解决方案。
- en: Performance versus cost
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 性能与成本比较
- en: Identify the different types of data you need to manage, and create a hierarchy
    based on the business importance of the data, how often it will be accessed, and
    what kind of latency the users of the data will expect.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 确定您需要管理的不同类型的数据，并根据数据的业务重要性、访问频率以及数据使用者期望的延迟类型创建一个层次结构。
- en: Store the most important and most frequently accessed data (hot data) in a high-performance
    storage system such as a data warehouse’s native storage. Store less important
    data (cold data) in a less expensive storage system such as cloud storage (which
    itself has several tiers). If you need even higher performance, such as for interactive
    use cases, you can use caching techniques to load a meaningful portion of your
    hot data into a volatile storage tier.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 将最重要和最频繁访问的数据（热数据）存储在高性能存储系统中，例如数据仓库的原生存储。将较不重要的数据（冷数据）存储在成本较低的存储系统中，例如云存储（本身有多个层级）。如果需要更高的性能，例如用于交互式使用情景，可以使用缓存技术将热数据的有意义部分加载到易失性存储层。
- en: High availability
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高可用性
- en: '*High availability* means having the ability to be operational and deliver
    access to the data when requested. This is usually achieved via hardware redundancy
    to cope with possible physical failures/outages. This is achieved in the cloud
    by storing the data in at least three *availability zones*. Zones may not be physically
    separated (i.e., they may be on the same “campus”) but will tend to have different
    power sources, etc. Hardware redundancy is usually referred to as system *uptime*,
    and modern systems usually come with four 9s or more.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*高可用性* 意味着在请求时能够操作并提供对数据的访问。通常通过硬件冗余来应对可能的物理故障/停机。在云中，通过在至少三个*可用区*存储数据来实现。这些区域可能不是物理上分离的（即它们可能位于同一“校园”），但通常会有不同的电源来源等。硬件冗余通常被称为系统的*正常运行时间*，现代系统通常提供四个9或更多的运行时间保证。'
- en: Durability
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 耐久性
- en: '*Durability* is the ability to store data for a long-term period without suffering
    data degradation, corruption, or outright loss. This is usually achieved through
    storing multiple copies of the data in physically separate locations. Such data
    redundancy is implemented in the cloud by storing the data in at least two *regions*
    (e.g., in both London and Frankfurt). This is extremely important when dealing
    with data restore operations in the face of natural disasters: if the underlying
    storage system has a high durability (modern systems usually come with 11 9s),
    then all of the data can be restored with no issues unless a cataclysmic event
    takes down even the physically separated data centers.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*耐久性* 是指在长期存储数据时不会出现数据降解、损坏或直接丢失的能力。通常通过在物理上分离的多个位置存储数据的多个副本来实现。在云中，通过在至少两个*区域*（例如伦敦和法兰克福）存储数据来实现数据冗余。这在面对自然灾害时非常重要：如果底层存储系统具有较高的耐久性（现代系统通常提供11个9），则除非发生灾难性事件，否则所有数据都可以毫无问题地恢复，即使物理上分离的数据中心也可以。'
- en: Openness
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开放性
- en: As far as possible, use formats that are not proprietary and that do not generate
    lock-in. Ideally, it should be possible to query data with a choice of processing
    engines without generating copies of the data or having to move it from one system
    to another. That said, it is acceptable to use systems that use a proprietary
    or native storage format as long as they provide an easy export capability.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 尽可能使用非专有格式，并避免出现锁定情况。理想情况下，应能够使用多种处理引擎查询数据，而无需生成数据副本或将其从一个系统移动到另一个系统。尽管如此，使用具有专有或原生存储格式的系统也是可以接受的，只要它们提供简单的导出功能。
- en: As with most technology decisions, openness is a trade-off, and the ROI of a
    proprietary technology may be high enough that you are willing to pay the price
    of lock-in. After all, one of the reasons to go to the cloud is to reduce operational
    costs—these cost advantages tend to be higher in fully managed/serverless systems
    than on managed open source systems. For example, if your data use case requires
    transactions, Databricks (which uses a quasi-open storage format based on Parquet
    called Delta Lake) might involve lower operating costs than Amazon EMR or Google
    Dataproc (which will store data in standard Parquet on S3 or Google Cloud Storage
    [GCS] respectively)—the ACID (Atomicity, Consistency, Isolation, Durability) transactions
    that Databricks provides in Delta Lake will be expensive to implement and maintain
    on EMR or Dataproc. If you ever need to migrate away from Databricks, export the
    data into standard Parquet. Openness, per se, is not a reason to reject technology
    that is a better fit.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 和大多数技术决策一样，开放性是一种权衡，专有技术的投资回报率可能足够高，以至于您愿意承担封闭式技术的代价。毕竟，选择云的一个原因是降低运营成本——在完全托管/无服务器系统中，这些成本优势往往比托管开源系统更高。例如，如果您的数据使用情况需要事务处理，使用类似于Parquet的准开放存储格式Delta
    Lake的Databricks可能比Amazon EMR或Google Dataproc（分别在S3或Google Cloud Storage [GCS]上存储数据的标准Parquet）具有更低的运营成本——Databricks在Delta
    Lake中提供的ACID（原子性、一致性、隔离性、持久性）事务在EMR或Dataproc上实现和维护成本昂贵。如果您需要迁移离开Databricks，可以将数据导出为标准Parquet格式。单纯的开放性并不是拒绝更适合的技术的理由。
- en: Process/Transform
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过程/转换
- en: 'Here’s where the magic happens: raw data is transformed into useful information
    for further analysis. This is the stage where data engineers build data pipelines
    to make data accessible to a wider audience of nontechnical users in a meaningful
    way. This stage consists of activities that prepare data for analysis and use.
    Data integration involves combining data from multiple sources into a single view.
    Data cleansing may be needed to remove duplicates and errors from data. More generally,
    data wrangling, munging, and transformation are carried out to organize the data
    into a standard format.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是魔力发生的地方：原始数据被转换为进一步分析所需的有用信息。这是数据工程师构建数据管道的阶段，以使数据以有意义的方式对非技术用户可访问。这一阶段包括准备数据进行分析和使用的活动。数据集成涉及将来自多个源的数据合并为单一视图。可能需要进行数据清洗以删除数据中的重复项和错误。更广义上，数据整理、处理和转换是为了将数据组织成标准格式而进行的活动。
- en: There are several frameworks that can be used, each with its own capabilities
    that depend on the storage method you selected in the previous step. In general,
    engines that allow you to query and transform your data using pure SQL commands
    (e.g., AWS Athena, Google BigQuery, Azure DWH, and Snowflake) are the most efficient,
    cost effective,^([1](ch01.html#ch01fn1)) and easy to use. However, the capabilities
    they offer are limited in comparison to engines based on modern programming languages,
    usually Java, Scala, or Python (e.g., Apache Spark, Apache Flink, or Apache Beam
    running on Amazon EMR, Google Cloud Dataproc/Dataflow, Azure HDInsight, and Databricks).
    Code-based data processing engines allow you not only to implement more complex
    transformations and ML in batch and in real time but also to leverage other important
    features such as proper unit and integration tests.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种框架可供选择，每种框架都有自己的功能，这些功能取决于您在上一步选择的存储方法。总的来说，允许您使用纯SQL命令查询和转换数据的引擎（例如AWS Athena、Google
    BigQuery、Azure DWH和Snowflake）是最高效、成本效益最好，^([1](ch01.html#ch01fn1)) 也是最易于使用的。然而，与基于现代编程语言（通常是Java、Scala或Python）的引擎相比，它们提供的功能有限（例如在Amazon
    EMR、Google Cloud Dataproc/Dataflow、Azure HDInsight和Databricks上运行的Apache Spark、Apache
    Flink或Apache Beam）。基于代码的数据处理引擎不仅可以实现更复杂的批处理和实时转换以及机器学习，还可以利用其他重要功能，例如适当的单元测试和集成测试。
- en: Another consideration in choosing an appropriate engine is that SQL skills are
    typically much more prevalent in an organization than programming skills. The
    more of a data culture you want to build within your organization, the more you
    should lean toward SQL for data processing. This is particularly important if
    the processing steps (such as data cleansing or transformation) require domain
    knowledge.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择适当的引擎时，另一个考虑因素是组织中通常更普遍的SQL技能而不是编程技能。在组织内建立数据文化的程度越高，您就越应该倾向于使用SQL进行数据处理。如果处理步骤（如数据清洗或转换）需要领域知识，这尤为重要。
- en: This stage may also employ *data virtualization* solutions that abstract multiple
    data sources, and related logic to manage them, to make information directly available
    to the final users for analysis. We will not discuss virtualization further in
    this book, as it tends to be a stopgap solution en route to building a fully flexible
    platform. For more information about data virtualization, we suggest Chapter 10
    of the book [*The Self-Service Data Roadmap*](https://oreil.ly/p85Sj) by Sandeep
    Uttamchandani (O’Reilly).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这个阶段可能还会采用*数据虚拟化*解决方案，该解决方案将多个数据源和相关逻辑抽象出来，以便直接提供给最终用户进行分析。我们不会在本书中进一步讨论虚拟化，因为它往往是建立一个完全灵活平台的过渡性解决方案。关于数据虚拟化的更多信息，请参阅Sandeep
    Uttamchandani（O'Reilly）的书籍《*The Self-Service Data Roadmap*》第10章。
- en: Analyze/Visualize
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析/可视化
- en: Once you arrive at this stage, the data starts finally to have value in and
    of itself—you can consider it *information*. Users can leverage a multitude of
    tools to dive into the content of the data to extract useful insights, identify
    current trends, and predict new outcomes. At this stage, visualization tools and
    techniques that allow users to represent information and data in a graphical way
    (e.g., charts, graphs, maps, heat maps, etc.) play an important role because they
    provide an easy way to discover and evaluate trends, outliers, patterns, and behavior.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你到达这个阶段，数据最终开始有了自身的价值——你可以把它视为*信息*。用户可以利用多种工具深入挖掘数据内容，提取有用的见解，识别当前的趋势，并预测新的结果。在这个阶段，可视化工具和技术发挥着重要作用，允许用户以图形方式表示信息和数据（例如图表、图形、地图、热力图等），因为它们提供了一种简单的方式来发现和评估趋势、异常值、模式和行为。
- en: Visualization and analysis of data can be performed by several types of users.
    On one hand are people who are interested in understanding business data and want
    to leverage graphical tools to perform common analysis like slice and dice roll-ups
    and what-if analysis. On the other hand, there could be more advanced users (“power
    users”) who want to leverage the power of a query language like SQL to execute
    more fine-grained and tailored analysis. In addition, there might be data scientists
    who can leverage ML techniques to implement new ways to extract meaningful insights
    from the data, discover patterns and correlations, improve customer understanding
    and targeting, and ultimately increase a business’s revenue, growth, and market
    position.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的可视化和分析可以由多种类型的用户执行。一方面是对理解业务数据感兴趣并希望利用图形工具执行常见分析（如切片和切块汇总和假设分析）的人。另一方面，可能有更高级的用户（“权力用户”），他们希望利用SQL等查询语言执行更精细和定制的分析。此外，可能还有数据科学家，他们可以利用ML技术实施从数据中提取有意义见解、发现模式和相关性、改进客户理解和定位，并最终增加企业的收入、增长和市场地位。
- en: Activate
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 激活
- en: This is the step where end users are able to make decisions based on data analysis
    and ML predictions, thus enabling a data decision-making process. From the insights
    extracted or predicted from the available information set, it is the time to take
    some actions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步是最终用户能够基于数据分析和ML预测做出决策的阶段，从提取或预测的见解中，现在是采取一些行动的时候了。
- en: 'The actions that can be carried out fall into three categories:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 可执行的行动可以分为三类：
- en: Automatic actions
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 自动操作
- en: Automated systems can use the results of a recommendation system to provide
    customized recommendations to customers. This can help the business’s top line
    by increasing sales.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化系统可以利用推荐系统的结果向客户提供定制建议。这可以通过增加销售来帮助企业的收入。
- en: SaaS integrations
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: SaaS集成
- en: Actions can be performed by integrating with third-party services. For instance,
    a company might implement a marketing campaign to try to reduce customer churn.
    They could analyze data and implement a propensity model to identify customers
    who are likely to respond positively to a new commercial offer. The list of customer
    email addresses can then be sent automatically to a marketing tool to activate
    the campaign.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通过与第三方服务集成来执行操作。例如，一家公司可能实施市场营销活动，试图减少客户流失。他们可以分析数据并实施倾向模型，以识别可能对新商业提议积极响应的客户。然后，客户电子邮件地址列表可以自动发送给营销工具以启动活动。
- en: Alerting
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 警报
- en: You can create applications that monitor data in real time and send out personalized
    messages when certain conditions are met. For instance, the pricing team may receive
    proactive notifications when the traffic to an item listing page exceeds a certain
    threshold, allowing them to check whether the item is priced correctly.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以创建实时监控数据并在满足特定条件时发送个性化消息的应用程序。例如，当商品列表页的流量超过某个阈值时，定价团队可以收到主动通知，从而可以检查商品的定价是否正确。
- en: The technology stack for these three scenarios is different. For automatic actions,
    the “training” of the ML model is carried out periodically, usually by scheduling
    an end-to-end ML pipeline (this will be covered in [Chapter 11](ch11.html#architecting_an_ml_platform)).
    The predictions themselves are achieved by invoking the ML model deployed as a
    web service using tools like AWS SageMaker, Google Cloud Vertex AI, or Azure Machine
    Learning. SaaS integrations are often carried out in the context of function-specific
    workflow tools that allow a human to control what information is retrieved, how
    it is transformed, and the way it is activated. In addition, using large language
    models (LLMs) and their generative capabilities (we will dig more into those concepts
    in [Chapter 10](ch10.html#ai_application_architecture)) can help automate repetitive
    tasks by closely integrating with core systems. Alerts are implemented through
    orchestration tools such as Apache Airflow, event systems such as Google Eventarc,
    or serverless functions such as AWS Lambda.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这三种情况的技术堆栈是不同的。对于自动化操作，“训练”ML模型通常通过调度端到端的ML管道定期进行（这将在[第11章](ch11.html#architecting_an_ml_platform)中介绍）。预测本身通过调用部署为Web服务的ML模型实现，使用像AWS
    SageMaker、Google Cloud Vertex AI或Azure Machine Learning这样的工具。SaaS集成通常在功能特定的工作流工具的背景下进行，这些工具允许人员控制检索信息的方式、信息如何转换以及激活信息的方式。此外，利用大型语言模型（LLMs）及其生成能力（我们将在[第10章](ch10.html#ai_application_architecture)中深入探讨这些概念）可以通过与核心系统紧密集成来帮助自动化重复任务。通过像Apache
    Airflow这样的编排工具、像Google Eventarc这样的事件系统或像AWS Lambda这样的无服务器函数实现警报。
- en: In this section, we have seen the activities that a modern data platform needs
    to support. Next, let’s examine traditional approaches in implementing analytics
    and AI platforms to have a better understanding of how technology evolved and
    why the cloud approach can make a big difference.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们已经看到现代数据平台需要支持的活动。接下来，让我们研究实施分析和AI平台的传统方法，以更好地理解技术的发展以及为什么云方法可以产生重大差异。
- en: Limitations of Traditional Approaches
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统方法的局限性
- en: Traditionally, organizations’ data ecosystems consist of independent solutions
    that are used to provide different data services. Unfortunately, such task-specific
    data stores, which may sometimes grow to an important size, can lead to the creation
    of silos within an organization. The resulting siloed systems operate as independent
    solutions that are not working together in an efficient manner. *Siloed data is
    silenced data*—it’s data from which insights are difficult to derive. To broaden
    and unify enterprise intelligence, securely sharing data across business units
    is critical.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，组织的数据生态系统由用于提供不同数据服务的独立解决方案组成。不幸的是，这种特定任务的数据存储，有时可能会扩展到重要规模，可能会导致组织内部的信息孤岛的创建。结果产生的信息孤岛系统作为独立解决方案运行，而不是以高效的方式协同工作。*信息孤岛数据就是被沉默的数据*
    ——从中难以提取见解的数据。要扩展和统一企业智能，安全地跨业务部门共享数据至关重要。
- en: If the majority of solutions are custom built, it becomes difficult to handle
    scalability, business continuity, and disaster recovery (DR). If each part of
    the organization chooses a different environment to build their solution in, the
    complexity becomes overwhelming. In such a scenario, it is difficult to ensure
    privacy or to audit changes to data.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果大多数解决方案都是定制化构建的，那么处理可扩展性、业务连续性和灾难恢复（DR）就会变得困难。如果组织的每个部分选择在不同的环境中构建其解决方案，复杂性就会变得令人不堪重负。在这种情况下，很难确保隐私或审计数据的变更。
- en: One solution is to develop a unified data platform and, more precisely, a *cloud*
    data platform (please note that unified does not necessarily imply centralized,
    as will be discussed shortly). The purpose of the data platform is to allow *analytics
    and ML to be carried out over all of an organization’s data in a consistent, scalable,
    and reliable way*. When doing that, you should leverage, to the maximum extent
    possible, managed services so that the organization can focus on business needs
    instead of operating infrastructure. Infrastructure operations and maintenance
    should be delegated totally to the underlying cloud platform. In this book, we
    will cover the core decisions that you need to make when developing a unified
    platform to consolidate data across business units in a scalable and reliable
    environment.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个解决方案是开发一个统一的数据平台，更确切地说是一个*云*数据平台（请注意，统一并不一定意味着集中化，稍后将会讨论）。数据平台的目的是允许在一个组织的所有数据上以一致、可扩展和可靠的方式进行*分析和机器学习*。在此过程中，您应尽可能充分利用托管服务，以便组织能够专注于业务需求而不是运营基础设施。基础设施的运维应完全委托给底层的云平台。在本书中，我们将探讨开发统一平台时需要做出的核心决策，以在可扩展和可靠的环境中整合业务单元之间的数据。
- en: 'Antipattern: Breaking Down Silos Through ETL'
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反模式：通过ETL打破孤岛
- en: It is challenging for organizations to have a unified view of their data because
    they tend to have a multitude of solutions for managing it. Organizations typically
    solve this problem by using data movement tools. ETL applications allow data to
    be transformed and transferred between different systems to create a single source
    of truth. However, relying on ETL is problematic, and there are better solutions
    available in modern platforms.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于组织来说，很难对其数据拥有统一的视图，因为它们倾向于使用多种解决方案进行管理。组织通常通过使用数据移动工具来解决这个问题。ETL应用程序允许在不同系统之间转换和传输数据，以创建一个数据的单一真实来源。然而，依赖ETL存在问题，在现代平台上有更好的解决方案。
- en: Often, an ETL tool is created to extract the most recent transactions from a
    transactional database on a regular basis and store them in an analytics store
    for access by dashboards. This is then standardized. ETL tools are created for
    every database table that is required for analytics so that analytics can be performed
    without having to go to the source system each time (see [Figure 1-3](#etl_tools_can_help_break_down_data_silo)).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ETL工具通常被设计用来定期从事务性数据库中提取最新的交易数据，并将其存储在分析存储中，以便仪表板访问。这些数据会被标准化处理。为了能够在不每次都访问源系统的情况下进行分析，每个需要进行分析的数据库表都会创建相应的ETL工具（见[图 1-3](#etl_tools_can_help_break_down_data_silo)）。
- en: '![ETL tools can help break down data silos](assets/adml_0103.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![ETL工具可以帮助打破数据孤岛](assets/adml_0103.png)'
- en: Figure 1-3\. ETL tools can help break down data silos
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3\. ETL工具可以帮助打破数据孤岛
- en: 'The central analytics store that captures all the data across the organization
    is referred to as either a *DWH* or a *data lake* depending on the technology
    being used. A high-level distinction between the two approaches is based on the
    way the data is stored within the system: if the analytics store supports SQL
    and contains governed, quality-controlled data, it is referred to as a *DWH*.
    If instead it supports tools from the Apache ecosystem (such as Apache Spark)
    and contains raw data, it is referred to as a *data lake*. Terminology for referring
    to in-between analytics stores (such as governed raw data or ungoverned quality-controlled
    data) varies from organization to organization—some organizations call them data
    lakes and others call them DWH. As you will see later in the book, this confusing
    vocabulary is not a problem because data lake ([Chapter 5](ch05.html#architecting_a_data_lake))
    and DWH ([Chapter 6](ch06.html#innovating_with_an_enterprise_data_ware)) approaches
    are converging into what is known as data lakehouse ([Chapter 7](ch07.html#converging_to_a_lakehouse)).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 跨组织捕获所有数据的中心分析存储库，根据使用的技术，被称为*DWH*或*数据湖*。这两种方法之间的高级区别基于数据存储在系统内的方式：如果分析存储支持SQL并包含经过管理和质量控制的数据，则称为*DWH*。如果支持Apache生态系统工具（如Apache
    Spark）并包含原始数据，则称为*数据湖*。用于指代介于这两种方法之间的分析存储（如管理的原始数据或未管理的质量控制数据）的术语因组织而异——有些组织称之为数据湖，而其他组织称之为DWH。正如本书后面将会看到的，这种混淆的词汇不是问题，因为数据湖（[第5章](ch05.html#architecting_a_data_lake)）和DWH（[第6章](ch06.html#innovating_with_an_enterprise_data_ware)）的方法正在融合为所谓的数据湖仓（[第7章](ch07.html#converging_to_a_lakehouse)）。
- en: 'There are a few drawbacks to relying on data movement tools to try building
    a consistent view of the data:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖数据移动工具尝试构建数据一致视图有一些缺点：
- en: Data quality
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量
- en: ETL tools are often written by consumers of the data who tend to not understand
    it as well as the owners of the data. This means that, very often, the data that
    is extracted is not the right data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ETL工具通常由数据消费者编写，他们往往不如数据所有者理解数据。这意味着经常提取的数据并不是正确的数据。
- en: Latency
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟
- en: ETL tools introduce latency. For example, if the ETL tool to extract recent
    transactions runs once an hour and takes 15 minutes to run, the data in the analytics
    store could be stale by up to 75 minutes. This problem can be addressed by streaming
    ETL where events are processed as they happen.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ETL工具引入延迟。例如，如果ETL工具每小时运行一次以提取最近的交易，并且运行需要15分钟，那么分析存储中的数据可能会滞后多达75分钟。通过流式ETL可以解决这个问题，其中事件在发生时即被处理。
- en: Bottleneck
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 瓶颈
- en: ETL tools typically involve programming skills. Therefore, organizations set
    up bespoke data engineering teams to write the code for ETL. As the diversity
    of data within an organization increases, an ever-increasing number of ETL tools
    need to be written. The data engineering team becomes a bottleneck on the ability
    of the organization to take advantage of data.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ETL工具通常需要编程技能。因此，组织设立定制数据工程团队来为ETL编写代码。随着组织内数据的多样性增加，需要编写的ETL工具数量不断增加。数据工程团队成为组织利用数据能力的瓶颈。
- en: Maintenance
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 维护
- en: ETL tools need to be routinely run and troubleshot by system administrators.
    The underlying infrastructure system needs to be continually updated to cope with
    increased compute and storage capacity and to guarantee reliability.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 系统管理员需要定期运行和排除ETL工具的故障。底层基础设施系统需要持续更新以应对增加的计算和存储容量，并保证可靠性。
- en: Change management
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 变更管理
- en: Changes in the schema of the input table require the extract code of the ETL
    tool to be changed. This either makes changes hard to do or results in the ETL
    tool being broken by upstream changes.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 输入表模式的更改需要更改ETL工具的提取代码。这要么使得更改难以实现，要么导致ETL工具被上游更改破坏。
- en: Data gaps
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 数据缺失
- en: It is very likely that many errors have to be escalated to the owners of the
    data, the creators of the ETL tool, or the users of the data. This adds to maintenance
    overhead, and very often to tool downtime. There are quite frequently large gaps
    in the data record because of this.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能需要将许多错误升级到数据所有者、ETL工具的创建者或数据使用者。这增加了维护开销，而且工具停机也是非常频繁的。由于这个原因，数据记录中经常存在较大的空白。
- en: Governance
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 治理
- en: As ETL processes proliferate, it becomes increasingly likely that the same processing
    is carried out by different processes, leading to multiple sources of the same
    information. It’s common for the processes to diverge over time to meet different
    needs, leading to inconsistent data being used for different decisions.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ETL流程的增加，同样的处理很可能由不同的流程执行，导致同一信息的多源性。随着时间的推移，这些流程通常会分歧以满足不同的需求，导致用于不同决策的数据不一致。
- en: Efficiency and environmental impact
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 效率和环境影响
- en: The underlying infrastructure that supports these types of transformations is
    a concern, as it typically operates 24/7, incurring significant costs and increasing
    carbon footprint impact.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 支持这些类型转换的基础设施是一个关注点，因为它通常是24/7运行，会产生重大成本并增加碳足迹的影响。
- en: The first point in the preceding list (data quality) is often overlooked, but
    it tends to be the most important over time. Often you need to preprocess the
    data before it can be “trusted” to be made available in production. Data coming
    from upstream systems is generally considered to be raw, and it may contain noise
    or even bad information if it is not properly cleaned and transformed. For example,
    ecommerce web logs may need to be transformed before use, such as by extracting
    product codes from URLs or filtering out false transactions made by bots. Data
    processing tools must be built specifically for the task at hand. There is no
    global data quality solution or common framework for dealing with quality issues.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述列表中的第一个要点（数据质量）经常被忽视，但随着时间推移，它往往是最重要的。通常需要在数据能够“信任”投入生产之前对其进行预处理。来自上游系统的数据通常被认为是原始的，如果没有经过适当的清理和转换，可能会包含噪声或甚至错误信息。例如，电子商务网站日志可能需要在使用之前进行转换，例如从URL中提取产品代码或过滤掉机器人生成的虚假交易。数据处理工具必须专门为手头的任务构建。并不存在用于处理质量问题的全局数据质量解决方案或通用框架。
- en: While this situation is reasonable when considering one data source at a time,
    the total collection (see [Figure 1-4](#data_ecosystem_and_challenges)) leads
    to chaos.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在逐个考虑数据源时这种情况是合理的，但整体收集（参见[图1-4](#data_ecosystem_and_challenges)）导致混乱。
- en: '![Data ecosystem and challenges](assets/adml_0104.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![数据生态系统与挑战](assets/adml_0104.png)'
- en: Figure 1-4\. Data ecosystem and challenges
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. 数据生态系统与挑战
- en: 'The proliferations of storage systems, together with tailor-made data management
    solutions developed to satisfy the desires of different downstream applications,
    bring about a situation where analytics leaders and chief information officers
    (CIOs) face the following challenges:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 存储系统的增加，以及为满足不同下游应用程序需求而开发的定制数据管理解决方案的增多，导致分析领导者和首席信息官（CIO）面临以下挑战：
- en: Their DWH/data lake is unable to keep up with the ever-growing business needs.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们的DWH/数据湖无法跟上不断增长的业务需求。
- en: Increasingly, digital initiatives (and competition with digital natives) have
    transformed the business to be one where massive data volumes are flooding the
    system.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 越来越多地，数字化倡议（以及与数字原住民的竞争）已经使业务转变为一个大规模数据量涌入系统的业务。
- en: The need to create separate data lakes, DWHs, and special storage for different
    data science tasks ends up creating multiple data silos.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为不同的数据科学任务创建单独的数据湖、DWH和特殊存储的需求最终导致了多个数据孤岛的产生。
- en: Data access needs to be limited or restricted due to performance, security,
    and governance challenges.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据访问需要受限或受限制，由于性能、安全性和治理挑战。
- en: Renewing licenses and paying for expensive support resources become challenging.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 续订许可证和支付昂贵的支持资源变得具有挑战性。
- en: It is evident that this approach cannot be scaled to meet the new business requirements,
    not only because of the technological complexity but also because of the security
    and governance requirements that this model entails.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 显而易见，这种方法无法扩展以满足新的业务需求，不仅因为技术复杂性，还因为这种模型所需的安全性和治理要求。
- en: 'Antipattern: Centralization of Control'
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反模式：控制的集中化
- en: To try to address the problem of having siloed, spread, and distributed data
    managed via task-specific data processing solutions, some organizations have tried
    to centralize everything in a single, monolithic platform under the control of
    the IT department. As shown in [Figure 1-5](#data_ecosystem_and_challenges_with_it_c),
    the underlying technology solution doesn’t change—instead, the problems are made
    more tractable by assigning them to a single organization to solve.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尝试解决通过专门的数据处理解决方案管理的孤立、分散和分布式数据的问题，一些组织试图将一切集中在由IT部门控制的单一的、单块的平台中。如[图1-5](#data_ecosystem_and_challenges_with_it_c)所示，技术解决方案本质上并未改变，而是通过将问题分配给单一组织来使其更易于解决。
- en: '![Data ecosystem and challenges with IT centrally controlling data systems](assets/adml_0105.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![IT集中控制数据系统的数据生态系统和挑战](assets/adml_0105.png)'
- en: Figure 1-5\. Data ecosystem and challenges with IT centrally controlling data
    systems
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5\. IT集中控制数据系统的数据生态系统和挑战
- en: 'Such centralized control by a unique department comes with its own challenges
    and trade-offs. All business units (BUs)—IT itself, data analytics, and business
    users—struggle when IT controls all data systems:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由唯一部门进行的这种集中控制带来了其自身的挑战和权衡。所有业务单位（BU）——IT本身、数据分析以及业务用户——当IT控制所有数据系统时，都会面临困难：
- en: IT
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: IT
- en: 'The challenge that IT departments face is the diverse set of technologies involved
    in these data silos. IT departments rarely have all the skills necessary to manage
    all of these systems. The data sits across multiple storage systems on premises
    and across clouds, making it costly to manage DWHs, data lakes, and data marts.
    It is also not always clear how to define security, governance, auditing, etc.,
    across different sources. Moreover, it introduces a scalability problem in getting
    access to the data: the amount of work that IT needs to carry out linearly increases
    with the number of source systems and target systems that will be part of the
    picture because this will surely increase the number of data access requests by
    all the related stakeholders/business users.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: IT部门面临的挑战是这些数据孤岛涉及的各种技术集合。IT部门很少具备管理所有这些系统所需的所有技能。数据存储在本地和云中的多个存储系统中，管理数据仓库、数据湖和数据集市成本高昂。如何在不同来源之间定义安全性、治理、审计等问题也并不总是明确。此外，获取数据存在扩展性问题：IT需要进行的工作量随源系统和目标系统的增加而线性增加，因为这必然会增加所有相关利益相关者/业务用户的数据访问请求。
- en: Analytics
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 分析
- en: One of the main problems hindering effective analytics processes is not having
    access to the right data. When multiple systems exist, moving data to/from one
    monolithic data system becomes costly, resulting in unnecessary ETL tasks, etc.
    In addition, the preprepared and readily available data might not have the most
    recent sources, or there might be other versions of the data that provide more
    depth and broader information, such as having more columns or having more granular
    records. It is impossible to give your analytics team free rein whereby everyone
    can access all data due to data governance and operational issues. Organizations
    often end up limiting data access at the expense of analytic agility.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 有效分析过程中的一个主要问题是没有获取到正确的数据。当存在多个系统时，将数据移动到/从一个单块数据系统变得成本高昂，导致不必要的ETL任务等等。此外，预先准备和随时可用的数据可能没有最新的来源，或者可能存在其他版本的数据，提供更深入和更广泛的信息，例如拥有更多列或更细粒度记录。由于数据治理和运营问题，不可能让你的分析团队自由发挥，每个人都可以访问所有数据。组织往往最终限制数据访问，以牺牲分析灵活性为代价。
- en: Business
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 业务
- en: Getting access to data and analytics that your business can trust is difficult.
    There are issues around limiting the data you give the business so you can ensure
    the highest quality. The alternative approach is to open up access to all the
    data the business users need, even if that means sacrificing quality. The challenge
    then becomes a balancing act on the quality of the data and amount of trusted
    data given. It is often the case that IT does not have enough qualified business
    representatives to drive priorities and requirements. This can quickly become
    a bottleneck slowing down the innovation process within the organization.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 获取业务可信赖的数据和分析结果非常困难。围绕限制向业务提供数据的问题存在着，以确保最高质量。替代方法是为业务用户开放他们所需的所有数据访问权限，即使这意味着牺牲质量。然后，挑战变成了在数据质量和可信数据量之间的平衡。通常情况下，IT部门没有足够的合格业务代表来推动优先事项和需求。这很快会成为组织内部创新过程的瓶颈。
- en: Despite so many challenges, several organizations adopted this approach throughout
    the years, creating, in some cases, frustrations and tensions for business users
    who were delayed in getting access to the data they needed to fulfill their tasks.
    Frustrated business units often cope through another antipattern—that is, *shadow
    IT*—where entire departments develop and deploy useful solutions to work around
    such limitations but end up making the problem of siloed data worse.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在诸多挑战，多个组织多年来采用了这种方法，导致业务用户在获取所需数据以完成任务时延迟，从而产生了挫败和紧张情绪。受挫的业务部门经常通过另一种反模式来应对——即*影子IT*——整个部门开发和部署有用的解决方案，以规避这些限制，但最终加剧了数据孤岛问题。
- en: A technical approach called *data fabric* is sometimes employed. This still
    relies on centralization, but instead of physically moving data, the data fabric
    is a virtual layer to provide unified data access. The problem is that such standardization
    can be a heavy burden and introduce delays for organization-wide access to data.
    The data fabric is, however, a viable approach for SaaS products trying to access
    customers’ proprietary data—integration specialists provide the necessary translation
    from customers’ schema to the schema expected by the SaaS tool.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 有时会采用一种称为*数据布局*的技术方法。这仍然依赖于集中化，但是与物理移动数据不同，数据布局是一个虚拟层，用于提供统一的数据访问。问题在于，这样的标准化可能会给组织范围内的数据访问带来沉重的负担和延迟。然而，数据布局对于试图访问客户专有数据的SaaS产品来说是一种可行的方法——集成专家提供必要的从客户架构到SaaS工具期望的架构的转换。
- en: 'Antipattern: Data Marts and Hadoop'
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反模式：数据集市和Hadoop
- en: 'The challenges around a siloed centrally managed system created huge tension
    and overhead for IT. To resolve this, some businesses adopted two other antipatterns:
    data marts and ungoverned data lakes.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 围绕着孤立的集中管理系统存在的挑战给IT带来了巨大的紧张和开销。为了解决这个问题，一些企业采纳了另外两种反模式：数据集市和无治理数据湖。
- en: In the first approach, data was extracted to on-premises relational and analytical
    databases. However, despite being called data warehouses, these products were,
    in practice, *data marts* (a subset of enterprise data suited to specific workloads)
    due to scalability constraints. Data marts allow business users to design and
    deploy their own business data into structured data models (e.g., in retail, healthcare,
    banking, insurance, etc.). This enables them to easily get information about the
    current and the historical business (e.g., the amount of revenue of the last quarter,
    the number of users who played your last published game in the last week, the
    correlation between the time spent on the help center of your website and the
    number of tickets received in the last six months, etc.). For many decades, organizations
    have been developing data mart solutions using a variety of technologies (e.g.,
    Oracle, Teradata, Vertica) and implementing multiple applications on top of them.
    However, these on-premises technologies are severely limited in terms of capacity.
    IT teams and data stakeholders face the challenges of scaling infrastructure (vertically),
    finding critical talent, reducing costs, and ultimately meeting the growing expectation
    of delivering valuable insights. Moreover, these solutions tended to be costly
    because as data sizes grew, you needed to get a system with more compute to process
    it.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种方法中，数据被提取到本地的关系型和分析型数据库中。然而，尽管被称为数据仓库，但实际上这些产品是*数据集市*（企业数据的子集，适用于特定工作负载）由于可扩展性限制。数据集市允许业务用户设计和部署他们自己的业务数据到结构化数据模型中（例如在零售、医疗保健、银行、保险等领域）。这使得他们可以轻松获取有关当前和历史业务的信息（例如上个季度的收入金额、上周播放过你最新发布的游戏的用户数量、你的网站帮助中心花费的时间与过去六个月收到的工单数量之间的相关性等）。多年来，组织一直在使用各种技术（例如Oracle、Teradata、Vertica）开发数据集市解决方案，并在其上实施多个应用程序。然而，这些本地技术在容量方面严重受限。IT团队和数据利益相关者面临的挑战包括扩展基础设施（纵向）、寻找关键人才、降低成本，并最终满足提供有价值洞察的增长预期。此外，随着数据量的增长，这些解决方案往往成本高昂，因为你需要获取更多计算能力来处理它。
- en: Due to scalability and cost issues, big data solutions based on the Apache Hadoop
    ecosystem were created. Hadoop introduced distributed data processing (horizontal
    scaling) using low-cost commodity servers, enabling use cases that were previously
    only possible with high-end (and very costly) specialized hardware. Every application
    running on top of Hadoop was designed to tolerate node failures, making it a cost-effective
    alternative to some traditional DWH workloads. This led to the development of
    a new concept called *data lake*, which quickly became a core pillar of data management
    alongside the DWH.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于可扩展性和成本问题，基于Apache Hadoop生态系统的大数据解决方案被创建。Hadoop引入了使用低成本通用服务器的分布式数据处理（横向扩展），使得以前只能用高端（和非常昂贵）专用硬件实现的用例成为可能。在Hadoop上运行的每个应用程序都设计为容忍节点故障，使其成为一些传统数据仓库工作负载的经济有效替代方案。这导致了一个新概念的发展，称为*数据湖*，它迅速成为数据管理的核心支柱之一，与数据仓库并列。
- en: The idea was that while core operational technology divisions carried on with
    their routine tasks, all data was exported for analytics into a centralized data
    lake. The intent was for the data lake to serve as the central repository for
    analytics workloads and for business users. Data lakes have evolved from being
    mere storage facilities for raw data to platforms that enable advanced analytics
    and data science on large volumes of data. This enabled self-service analytics
    across the organization, but it required an extensive working knowledge of advanced
    Hadoop and engineering processes to access the data. The Hadoop Open Source Software
    (Hadoop OSS) ecosystem grew in terms of data systems and processing frameworks
    (HBase, Hive, Spark, Pig, Presto, SparkML, and more) in parallel to the exponential
    growth in organizations’ data, but this led to additional complexity and cost
    of maintenance. Moreover, data lakes became an ungoverned mess of data that few
    potential users of the data could understand. The combination of a skills gap
    and data quality issues meant that enterprises struggled to get good ROI out of
    data lakes on premises.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 思路是，尽管核心运营技术部门继续执行例行任务，但所有数据都被导出到一个集中的数据湖中进行分析。这个数据湖的目的是作为分析工作负载和业务用户的中心存储库。数据湖已经从仅仅是原始数据的存储设施发展为能够在大量数据上进行高级分析和数据科学的平台。这使得整个组织能够进行自助式分析，但需要对高级Hadoop和工程流程有广泛的工作知识才能访问数据。与企业数据的指数级增长相对应，Hadoop开源软件（Hadoop
    OSS）生态系统在数据系统和处理框架（如HBase、Hive、Spark、Pig、Presto、SparkML等）方面也有所发展，但这增加了额外的复杂性和维护成本。此外，数据湖变成了一团无政府状态的数据，很少有潜在的数据使用者能够理解。技能差距和数据质量问题的结合意味着企业很难从本地数据湖中获得良好的投资回报率。
- en: Now that you have seen several antipatterns, let’s focus on how you could design
    a data platform that provides a unified view of the data across its entire lifecycle.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经看到了几个反模式，让我们专注于如何设计一个数据平台，提供对整个生命周期内数据的统一视图。
- en: Creating a Unified Analytics Platform
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建统一的分析平台
- en: Data mart and data lake technologies enabled IT to build the first iteration
    of a data platform to break down data silos and to enable the organization to
    derive insights from all their data assets. The data platform enabled data analysts,
    data engineers, data scientists, business users, architects, and security engineers
    to derive better real-time insights and predict how their business will evolve
    over time.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 数据市场和数据湖技术使IT能够构建数据平台的第一个迭代版本，以打破数据孤岛，并使组织能够从其所有数据资产中获取洞察。数据平台使数据分析师、数据工程师、数据科学家、业务用户、架构师和安全工程师能够获取更好的实时洞察，并预测他们的业务随时间如何发展。
- en: Cloud Instead of On-Premises
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云而非本地部署
- en: DWH and data lakes are at the core of modern data platforms. DWHs support structured
    data and SQL, whereas data lakes support raw data and programming frameworks in
    the Apache ecosystem.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: DWH和数据湖是现代数据平台的核心。数据仓库支持结构化数据和SQL，而数据湖支持原始数据和Apache生态系统中的编程框架。
- en: 'However, running DWH and data lakes in an on-premises environment has some
    inherent challenges, such as scaling and operational costs. This has led organizations
    to reconsider their approach and to start considering the cloud (especially the
    public version of it) as the preferred environment for such a platform. Why? Because
    it allowed them to:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在本地环境中运行数据仓库（DWH）和数据湖也存在一些固有的挑战，如扩展和运营成本。这促使组织重新考虑他们的方法，并开始将云（尤其是公共版本）视为这样一个平台的首选环境。为什么？因为这使得他们能够：
- en: Reduce cost by taking advantage of new pricing models (*pay-per-use model*)
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过利用新的定价模型（*按使用付费模型*）来降低成本。
- en: Speed up innovation by taking advantage of best-of-breed technologies
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过利用最佳技术加快创新速度
- en: Scale on-premises resources using a “bursting” approach
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用“突发”方法扩展本地资源规模。
- en: Plan for business continuity and disaster recovery by storing data in multiple
    zones and regions
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在多个区域和地区存储数据来规划业务连续性和灾难恢复
- en: Manage disaster recovery automatically using fully managed services
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用完全托管的服务自动管理灾难恢复
- en: When users are no longer constrained by the capacity of their infrastructure,
    organizations are able to democratize data across their organization and unlock
    insights. The cloud supports organizations in their modernization efforts, as
    it minimizes the toil and friction by offloading the administrative, low-value
    tasks. A cloud data platform promises an environment where you no longer have
    to compromise and can build a comprehensive data ecosystem that covers the end-to-end
    data management and data processing stages from data collection to serving. And
    you can use your cloud data platform to store vast amounts of data in varying
    formats without compromising on latency.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户不再受到基础设施容量的限制时，组织可以在全公司范围内民主化数据，并释放洞察力。云支持组织进行现代化改造，因为它通过卸载管理、低价值任务来最小化麻烦和摩擦。云数据平台承诺提供一个环境，您不再需要妥协，可以构建一个全面的数据生态系统，覆盖从数据收集到服务的端到端数据管理和数据处理阶段。您可以使用云数据平台以不牺牲延迟的方式存储大量不同格式的数据。
- en: 'Cloud data platforms promise:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 云数据平台承诺：
- en: Centralized governance and access management
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集中式治理和访问管理
- en: Increased productivity and reduced operational costs
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加生产力和降低运营成本
- en: Greater data sharing across the organization
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织内部数据共享增加
- en: Extended access by different personas
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同角色的扩展访问权限
- en: Reduced latency of accessing data
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少访问数据的延迟
- en: In the public cloud environment, the lines between DWH and data lake technologies
    are blurring because cloud infrastructure (specifically, the separation of compute
    and storage) enables a convergence that was impossible in the on-premises environment.
    Today it is possible to apply SQL to data held in a data lake, and it’s possible
    to run what is traditionally a Hadoop technology (e.g., Spark) against data stored
    in a DWH. In this section we will give you an introduction to how this convergence
    works and how it can be the basis for brand-new approaches that can revolutionize
    the way organizations are looking at the data; you’ll get more details in Chapters
    [5](ch05.html#architecting_a_data_lake) through [7](ch07.html#converging_to_a_lakehouse).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在公共云环境中，数据仓库（DWH）和数据湖技术之间的界限变得模糊，因为云基础设施（特别是计算和存储的分离）使得在本地环境中不可能实现的融合成为可能。今天可以将SQL应用于存储在数据湖中的数据，并且可以在存储在数据仓库中的数据上运行传统的Hadoop技术（例如Spark）。在本节中，我们将为您介绍此融合如何运作以及如何成为革新组织数据观察方式的基础；在第5章至第7章中，您将获得更多详细信息。
- en: Drawbacks of Data Marts and Data Lakes
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集市（Data Marts）和数据湖（Data Lakes）的缺点
- en: Over the past 40 years, IT departments have come to realize that DWHs (actually
    data marts) are difficult to manage and can become very costly. Legacy systems
    that worked well in the past (such as on-premises Teradata and Netezza appliances)
    have proven to be difficult to scale, to be very expensive, and to pose a number
    of challenges related to data freshness. Additionally, they cannot easily provide
    modern capabilities such as access to AI/ML or real-time features without adding
    that functionality after the fact.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的40年里，IT部门意识到数据仓库（实际上是数据集市）难以管理，成本高昂。在过去表现良好的传统系统（如本地的Teradata和Netezza设备）已被证明难以扩展、成本昂贵，并带来了与数据新鲜度相关的一系列挑战。此外，它们不能轻松地提供现代能力，如接入AI/ML或实时功能，而不是事后添加该功能。
- en: DWH users are frequently analysts who are embedded in a specific business unit.
    They may have ideas about additional datasets, analysis, data processing, and
    business intelligence functionality that would be very beneficial to their work.
    However, in a traditional company, they frequently do not have direct access to
    data owners, nor can they easily influence the technical decision makers who decide
    on datasets and tools. Additionally, because they do not have access to raw data,
    they are unable to test hypotheses or gain a deeper understanding of the underlying
    data.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 数据仓库用户通常是嵌入在特定业务单位中的分析师。他们可能对额外的数据集、分析、数据处理和商业智能功能有想法，这些对他们的工作非常有益。然而，在传统公司中，他们经常无法直接访问数据所有者，也无法轻易影响决定数据集和工具的技术决策者。此外，由于他们无法访问原始数据，他们无法测试假设或深入理解底层数据。
- en: Data lakes are not as simple or cost-effective as they may seem. While they
    can be scaled easily in theory, organizations often face challenges in planning
    and provisioning sufficient storage, especially if they produce highly variable
    amounts of data. Additionally, provisioning computational capacity for peak periods
    can be expensive, leading to competition for scarce resources between different
    business units.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖并非像它们看起来那么简单或成本效益。虽然从理论上讲它们可以很容易地扩展，但组织通常面临规划和配置足够存储空间的挑战，特别是如果它们产生高度变化的数据量。此外，为高峰期配置计算能力可能会很昂贵，导致不同业务单位之间竞争稀缺资源。
- en: On-premises data lakes can be fragile and require time-consuming maintenance.
    Engineers who could be developing new features are often relegated to maintaining
    data clusters and scheduling jobs for business units. The total cost of ownership
    is often higher than expected for many businesses. In short, data lakes do not
    create value, and many businesses find that the ROI is negative.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在场数据湖可能会很脆弱，并且需要耗费时间的维护。那些本可以开发新功能的工程师经常被安排维护数据集群和为业务单位安排任务。对于许多企业来说，总体拥有成本往往比预期的要高。简而言之，数据湖并没有创造价值，许多企业发现投资回报率为负。
- en: With data lakes, governance is not easily solved, especially when different
    parts of the organization use different security models. Then, the data lakes
    become siloed and segmented, making it difficult to share data and models across
    teams.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据湖来说，治理并不容易解决，特别是当组织的不同部分使用不同的安全模型时。然后，数据湖变得分割和分段，使得跨团队分享数据和模型变得困难。
- en: Data lake users typically are closer to the raw data sources and need programming
    skills to use data lake tools and capabilities, even if it is just to explore
    the data. In traditional organizations, these users tend to focus on the data
    itself and are frequently held at arm’s length from the rest of the business.
    On the other hand, business users do not have the programming skills to derive
    insights from data in a data lake. This disconnect means that business units miss
    out on the opportunity to gain insights that would drive their business objectives
    forward to higher revenues, lower costs, lower risk, and new opportunities.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖的用户通常更接近原始数据源，并且需要使用数据湖工具和能力的编程技能，即使只是用于探索数据。在传统的组织中，这些用户倾向于专注于数据本身，并经常与业务的其他部门保持一定距离。另一方面，业务用户没有从数据湖中获取洞察力所需的编程技能。这种断开意味着业务部门错失了推动其业务目标提高收入、降低成本、降低风险和开发新机会的洞察力。
- en: Convergence of DWHs and Data Lakes
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据仓库（DWH）与数据湖的融合
- en: Given these trade-offs, many companies end up with a mixed approach, where a
    data lake is set up to graduate some data into a DWH or a DWH has a side data
    lake for additional testing and analysis. However, with multiple teams fabricating
    their own data architectures to suit their individual needs, data sharing and
    fidelity gets even more complicated for a central IT team.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 面对这些权衡，许多公司最终采取了混合方法，其中数据湖被建立用于向数据仓库（DWH）输出一些数据，或者数据仓库旁边设有数据湖用于额外的测试和分析。然而，由于多个团队根据各自的需求构建自己的数据架构，对于中央IT团队来说，数据共享和数据的准确性变得更加复杂。
- en: Instead of having separate teams with separate goals—where one explores the
    business and another knows the business—you can unite these functions and their
    data systems to create a virtuous cycle where a deeper understanding of the business
    drives exploration and that exploration drives a greater understanding of the
    business.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 不再有各自目标的独立团队——一个探索业务，另一个了解业务——你可以将这些功能及其数据系统联合起来，创造一个良性循环，在这个循环中，对业务的深入理解推动了探索，而探索则推动了对业务的更深理解。
- en: 'Starting from this principle, the data industry has begun shifting toward a
    new approach, *lakehouse* and *data mesh*, which work well together because they
    help solve two separate challenges within an organization:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个原则出发，数据行业已经开始转向一个新的方法，即*lakehouse*和*数据网格*，它们之间可以很好地配合，因为它们帮助解决组织内的两个不同挑战：
- en: Lakehouse allows users with different skill sets (data analysts and data engineers)
    to access the data using different technologies.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lakehouse允许具有不同技能集（数据分析师和数据工程师）的用户使用不同的技术访问数据。
- en: Data mesh allows an enterprise to create a unified data platform without centralizing
    all the data in IT—this way, different business units can own their own data but
    allow other business units to access it in an efficient, scalable way.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据网格允许企业创建统一的数据平台，而不是将所有数据集中在IT中，这样不同的业务单位可以拥有自己的数据，但允许其他业务单位以高效、可扩展的方式访问。
- en: As an added benefit, this architecture combination also brings in more rigorous
    data governance, something that data lakes typically lack. Data mesh empowers
    people to avoid being bottlenecked by one team and thus enables the entire data
    stack. It breaks silos into smaller organizational units in an architecture that
    provides access to data in a federated way.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 作为附加好处，这种架构组合还带来了更严格的数据治理，这是数据湖通常缺乏的。数据网格赋予人们避免被一个团队成为瓶颈的能力，从而使整个数据堆栈能够实现更高效的、可扩展的方式。它在一种架构中将隔离成较小的组织单元提供了对数据的联邦式访问。
- en: Lakehouse
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 湖屋
- en: Data lakehouse architecture is a combination of the key benefits of data lakes
    and data warehouses (see [Figure 1-6](#dwhcomma_data_lakecomma_and_lakehouse_p)).
    It offers a low-cost storage format that is accessible by various processing engines,
    such as the SQL engines of data warehouses, while also providing powerful management
    and optimization features.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖屋架构结合了数据湖和数据仓库的关键优势（见[图1-6](#dwhcomma_data_lakecomma_and_lakehouse_p)）。它提供了一种低成本存储格式，可被各种处理引擎访问，例如数据仓库的SQL引擎，同时还提供强大的管理和优化功能。
- en: '![DWH, data lake, and lakehouse patterns](assets/adml_0106.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![DWH、数据湖和湖屋模式](assets/adml_0106.png)'
- en: Figure 1-6\. DWH, data lake, and lakehouse patterns
  id: totrans-170
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-6\. DWH、数据湖和湖屋模式
- en: Databricks is a proponent of the lakehouse architecture because it was founded
    on Spark and needs to support business users who are not programmers. As a result,
    data in Databricks is stored in a data lake, but business users can use SQL to
    access it. However, the lakehouse architecture is not limited to Databricks.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks支持湖屋架构，因为它基于Spark的创始，并需要支持非程序员的业务用户。因此，Databricks中的数据存储在数据湖中，但业务用户可以使用SQL访问它。然而，湖屋架构并不局限于Databricks。
- en: 'DWHs running in cloud solutions like Google Cloud BigQuery, Snowflake, or Azure
    Synapse allow you to create a lakehouse architecture based around columnar storage
    that is optimized for SQL analytics: it allows you to treat the DWH like a data
    lake by also allowing Spark jobs running on parallel Hadoop environments to leverage
    the data stored on the underlying storage system rather than requiring a separate
    ETL process or storage layer.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 运行在Google Cloud BigQuery、Snowflake或Azure Synapse等云解决方案中的DWH，可以创建基于列存储的湖屋架构，这种架构针对SQL分析进行了优化：它允许您将DWH视为数据湖，同时允许在并行Hadoop环境中运行的Spark作业利用底层存储系统上存储的数据，而不需要单独的ETL过程或存储层。
- en: 'The lakehouse pattern offers several advantages over the traditional approaches:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 湖屋模式相对传统方法提供了几个优势：
- en: 'Decoupling of storage and compute that enable:'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解耦存储和计算，实现：
- en: Inexpensive, virtually unlimited, and seamlessly scalable storage
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 价格低廉、几乎无限制和无缝扩展的存储
- en: Stateless, resilient compute
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无状态、弹性计算
- en: ACID-compliant storage operations
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACID兼容的存储操作
- en: A logical database storage model, rather than physical
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑数据库存储模型，而非物理模型
- en: Data governance (e.g., data access restriction and schema evolution)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据治理（例如，数据访问限制和模式演变）
- en: Support for data analysis via the native integration with business intelligence
    tools
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过与商业智能工具的本地集成支持数据分析
- en: Native support of the typical multiversion approach of a data lake approach
    (i.e., bronze, silver, and gold)
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原生支持数据湖方法的典型多版本方法（即铜、银和金）
- en: Data storage and management via open formats like Apache Parquet and Iceberg
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据存储和管理通过开放格式如Apache Parquet和Iceberg
- en: Support for different data types in the structured or unstructured format
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持结构化或非结构化格式中的不同数据类型
- en: Streaming capabilities with the ability to handle real-time analysis of the
    data
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流式能力，能够处理数据的实时分析
- en: Enablement of a diverse set of applications varying from business intelligence
    to ML
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持多种应用，从商业智能到机器学习不等
- en: A lakehouse, however, is inevitably a technological compromise. The use of standard
    formats in cloud storage limits the storage optimizations and query concurrency
    that DWHs have spent years perfecting. Therefore, the SQL supported by lakehouse
    technologies is not as efficient as that of a native DWH (i.e., it will take more
    resources and cost more). Also, the SQL support tends to be limited, with features
    such as geospatial queries, ML, and data manipulation not available or incredibly
    inefficient. Similarly, the Spark support provided by DWHs is limited and tends
    to be not as performant as the native Spark support provided by a data lake vendor.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，数据湖屋是一种技术上的妥协。在云存储中使用标准格式限制了数据仓库多年来完善的存储优化和查询并发性。因此，与本地数据仓库（即需要更多资源并且成本更高）相比，数据湖屋技术支持的SQL不那么高效。此外，SQL支持往往有限，例如地理空间查询、机器学习和数据操作等功能要么不可用要么效率低下。同样，数据仓库提供的Spark支持也有限，并且性能不如数据湖供应商提供的本地Spark支持。
- en: The lakehouse approach enables organizations to implement the core pillars of
    an incredibly varied data platform that can support any kind of workload. But
    what about the organizations on top of it? How can users leverage the best of
    the platform to execute their tasks? In this scenario there is a new operating
    model that is taking shape, and it is data mesh.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖屋方法使组织能够实施支持任何工作负载类型的极度多样化数据平台的核心支柱。但是对于在其之上的组织呢？用户如何利用平台的最佳部分来执行他们的任务？在这种情况下，出现了一种新的运营模式，即数据网格。
- en: Data mesh
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据网格
- en: Data mesh is a decentralized operating model of tech, people, and process to
    solve the most common challenge in analytics—the desire for centralization of
    control in an environment where ownership of data is necessarily distributed,
    as shown in [Figure 1-7](#a_data_mesh_unifies_data_access_across). Another way
    of looking at data mesh is that it introduces a way of seeing data as a self-contained
    product rather than a product of ETL pipelines.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 数据网格是一种技术、人员和流程的分散化运营模式，用于解决分析中最常见的挑战——在数据所有权必然分布的环境中，对控制集中化的渴望，如图 [1-7](#a_data_mesh_unifies_data_access_across)
    所示。从另一个角度来看，数据网格介绍了一种将数据视为自包含产品而不是ETL流水线产品的方法。
- en: '![A data mesh unifies data access across the company, while retaining ownership
    of the data in distributed domains](assets/adml_0107.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![数据网格统一了公司内的数据访问，同时保留了分布领域中数据的所有权](assets/adml_0107.png)'
- en: Figure 1-7\. A data mesh unifies data access across the company, while retaining
    ownership of the data in distributed domains
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-7\. 数据网格统一了公司内的数据访问，同时保留了分布领域中数据的所有权
- en: Distributed teams in this approach own the data production and serve internal/​exter⁠nal
    consumers through well-defined data schema. As a whole, data mesh is built on
    a long history of innovation from across DWHs and data lakes, combined with the
    scalability, pay-for-consumption models, self-service APIs, and close integration
    associated with DWH technologies in the public cloud.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，分布式团队拥有数据生产，并通过明确定义的数据模式为内部/外部消费者提供服务。总体而言，数据网格建立在数据仓库和数据湖跨界创新的悠久历史之上，结合了公共云中数据仓库技术的可扩展性、按消费模式付费、自服务API以及紧密集成的特点。
- en: With this approach, you can effectively create an on-demand data solution. A
    data mesh decentralizes data ownership among domain data owners, each of whom
    are held accountable for providing their data as a product in a standard way (see
    [Figure 1-8](#data_as_a_product)). A data mesh also enables communication between
    various parts of the organization to distribute datasets across different locations.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方法，您可以有效地创建按需数据解决方案。数据网格将数据所有权分散到域数据所有者中，每个所有者都负责以标准方式提供其数据作为产品（参见图 [1-8](#data_as_a_product)）。数据网格还能够促进组织各部分之间的沟通，以在不同位置分发数据集。
- en: In a data mesh, the responsibility for generating value from data is federated
    to the people who understand it best; in other words, the people who created the
    data or brought it into the organization must also be responsible for creating
    consumable data assets as products from the data they create. In many organizations,
    establishing a “single source of truth” or “authoritative data source” is tricky
    due to the repeated extraction and transformation of data across the organization
    without clear ownership responsibilities over the newly created data. In the data
    mesh, the authoritative data source is the [data product](https://oreil.ly/2WUaq)
    published by the source domain, with a clearly assigned data owner and steward
    who is responsible for that data.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据网格中，从数据中生成价值的责任被委托给最了解数据的人；换句话说，创建数据或将其引入组织的人必须负责从他们创建的数据中创建可消费的数据资产作为产品。在许多组织中，由于在组织中多次提取和转换数据而没有明确的数据所有权责任，建立“真相的单一来源”或“权威数据来源”是棘手的。在数据网格中，权威数据来源是由源域发布的[数据产品](https://oreil.ly/2WUaq)，并有明确定义的数据所有者和监护人负责该数据。
- en: '![Data as a product](assets/adml_0108.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![数据作为产品](assets/adml_0108.png)'
- en: Figure 1-8\. Data as a product
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-8\. 数据作为产品
- en: Having access to this unified view from a technology perspective (lakehouse)
    and from an organizational perspective (data mesh) means that people and systems
    get data delivered to them in a way that makes the most sense for their needs.
    In some cases this kind of architecture has to span multiple environments, generating,
    in some cases, very complex architecture. Let’s see how companies can manage this
    challenge.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术视角（数据湖）和组织视角（数据网格）获得这种统一视图，意味着人们和系统以最适合其需求的方式获取数据。在某些情况下，这种架构必须跨越多个环境，有时产生非常复杂的架构。让我们看看公司如何应对这一挑战。
- en: Note
  id: totrans-198
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'For more information about data mesh, we recommend you read Zhamak Dehghani’s
    book [*Data Mesh: Delivering Data-Driven Value at Scale*](https://oreil.ly/OL7vg)
    (O’Reilly).'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数据网格的更多信息，我们建议您阅读Zhamak Dehghani的书籍[*数据网格：规模交付数据驱动价值*](https://oreil.ly/OL7vg)（O’Reilly）。
- en: Hybrid Cloud
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混合云
- en: When designing a cloud data platform, it might be that one single environment
    isn’t enough to manage a workload end to end. This could be because of regulatory
    constraints (i.e., you cannot move your data into an environment outside the organization
    boundaries), or because of the cost (e.g., the organization made some investments
    on the infrastructure that did not reach the end of life), or because you need
    a specific technology that is not available in the cloud. In this case a possible
    approach is adopting a hybrid pattern. A hybrid pattern is one in which applications
    are running in a combination of various environments. The most common example
    of hybrid pattern is combining a private computing environment, like an on-premises
    data center, and a public cloud computing environment. In this section we will
    explain how this approach can work in an enterprise.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计云数据平台时，可能会发现一个单一环境无法完全管理工作负载。这可能是因为监管限制（例如，您无法将数据移入组织边界之外的环境），或者是因为成本原因（例如，组织对未达到寿命终结的基础设施进行了一些投资），或者是因为您需要的特定技术在云中不可用。在这种情况下，采用混合模式可能是一个可行的方法。混合模式是指应用程序在各种环境的组合中运行的模式。混合模式的最常见例子是将私有计算环境（如现场数据中心）与公共云计算环境结合在一起。在本节中，我们将解释这种方法如何在企业中运作。
- en: Reasons Why Hybrid Is Necessary
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混合模式的必要原因
- en: Hybrid cloud approaches are widespread because almost no large enterprise today
    relies entirely on the public cloud. Many organizations have invested millions
    of dollars and thousands of hours into on-premises infrastructure over the past
    few decades. Almost all organizations are running a few traditional architectures
    and business-critical applications that they may not be able to move over to public
    cloud. They may also have sensitive data they can’t store in a public cloud due
    to regulatory or organizational constraints.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 混合云方法被广泛采用，因为现今几乎没有一个大型企业完全依赖公共云。在过去几十年中，许多组织已经投入了数百万美元和数千小时在现场基础设施上。几乎所有组织都在运行一些传统架构和业务关键应用程序，它们可能无法迁移至公共云。他们可能还有一些敏感数据，由于监管或组织约束，无法存储在公共云中。
- en: Allowing workloads to transition between public and private cloud environments
    provides a higher level of flexibility and additional options for data deployment.
    There are several reasons that drive hybrid (i.e., architecture spanning across
    on-premises, public cloud, and edge) and multicloud (i.e., architecture spanning
    across multiple public cloud vendors like AWS, Microsoft Azure, and Google Cloud
    Platform [GCP], for example) adoption.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 允许工作负载在公共和私有云环境之间过渡提供了更高的灵活性和数据部署的附加选项。有几个原因推动混合（即跨越本地、公共云和边缘的架构）和多云（即跨越多个公共云供应商如AWS、Microsoft
    Azure和Google Cloud Platform [GCP]等的架构）的采用。
- en: 'Here are some key business reasons for choosing hybrid and/or multicloud:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是选择混合和/或多云的一些关键业务原因：
- en: Data residency regulations
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 数据驻地法规
- en: Some may never fully migrate to the public cloud, perhaps because they are in
    finance or healthcare and need to follow strict industry regulations on where
    data is stored. This is also the case with workloads in countries without a public
    cloud presence and a data residency requirement.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人可能永远不会完全迁移到公共云，可能是因为他们处于金融或医疗保健行业，需要遵循严格的行业法规，规定数据存储的位置。在没有公共云存在和数据驻留要求的国家，工作负载也是如此。
- en: Legacy investments
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 传统投资
- en: Some customers want to protect their legacy workloads like SAP, Oracle, or Informatica
    on prem but want to take advantage of public cloud innovations like, for example,
    Databricks and Snowflake.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 一些客户希望保护其像SAP、Oracle或Informatica等遗留工作负载在本地运行，但希望利用公共云创新技术，例如Databricks和Snowflake。
- en: Transition
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 过渡
- en: Large enterprises often require a multiyear journey to modernize into cloud
    native applications and architectures. They will have to embrace hybrid architectures
    as an intermediate state for years.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 大型企业通常需要经过多年的旅程，将其现代化为云原生应用和架构。他们必须在数年间接受混合架构作为中间状态。
- en: Burst to cloud
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 云爆发
- en: There are customers who are primarily on premises and have no desire to migrate
    to the public cloud. However, they have challenges of meeting business service-level
    agreements (SLAs) due to ad hoc large batch jobs, spiky traffic during busy periods,
    or large-scale ML training jobs. They want to take advantage of scalable capacity
    or custom hardware in public clouds and avoid the cost to scale up on-premises
    infrastructure. Solutions like MotherDuck, which adopt a “local-first” computing
    approach, are becoming popular.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 有些客户主要在本地运营，并且没有迁移到公共云的意愿。然而，由于临时大批作业、繁忙时段的尖峰流量或大规模的机器学习训练作业，他们在满足业务服务级别协议（SLA）方面存在挑战。他们希望利用公共云中可扩展的容量或自定义硬件，并避免在本地基础设施上进行扩展的成本。像MotherDuck这样采用“本地优先”计算方法的解决方案正在变得流行。
- en: Best of breed
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 最优品种
- en: Some organizations choose different public cloud providers for different tasks
    in an intentional strategy to choose the technologies that best serve their needs.
    For example, Uber [uses AWS](https://oreil.ly/ajo8m) to serve their web applications,
    but it [uses Cloud Spanner on Google Cloud](https://oreil.ly/gMwLu) for its fulfillment
    platform. Twitter [runs its news feed on AWS](https://oreil.ly/5R4sy), but it
    [runs its data platform on Google Cloud](https://oreil.ly/ubxTX).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 一些组织选择在不同的公共云提供商之间进行不同任务的选择，这是一种有意识的策略，选择最适合其需求的技术。例如，Uber [使用AWS](https://oreil.ly/ajo8m)来提供其Web应用程序，但在其履行平台上
    [使用Google Cloud上的Cloud Spanner](https://oreil.ly/gMwLu)。Twitter [在AWS上运行其新闻订阅](https://oreil.ly/5R4sy)，但
    [在Google Cloud上运行其数据平台](https://oreil.ly/ubxTX)。
- en: Now that you understand the reasons why you might choose a hybrid solution,
    let’s have a look at the main challenges you will face when using this pattern;
    these challenges are why hybrid ought to be treated as an exception, and the goal
    should be to be cloud native.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您了解了选择混合解决方案的原因，让我们来看看在使用这种模式时可能会面临的主要挑战；这些挑战是为什么混合应该被视为一种例外的原因，而目标应该是云原生。
- en: Challenges of Hybrid Cloud
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混合云挑战
- en: 'There are several challenges that enterprises face when implementing hybrid
    or multicloud architectures:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 企业在实施混合或多云架构时面临几个挑战：
- en: Governance
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 治理
- en: It is difficult to apply consistent governance policies across multiple environments.
    For example, compliance security policies between on premises and public cloud
    are usually dealt with differently. Often, parts of the data are duplicated across
    on premises and cloud. Imagine your organization is running a financial report—how
    would you guarantee that the data used is the most recent updated copy if there
    are multiple copies that exist across platforms?
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个环境中应用一致的治理政策是困难的。例如，本地和公共云之间的合规安全政策通常有不同的处理方式。通常，数据的部分副本分布在本地和云中。想象一下，您的组织正在运行财务报告——如果数据在多个平台上存在多个副本，如何确保使用的数据是最新更新的副本？
- en: Access control
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 访问控制
- en: User access controls and policies differ between on-premises and public cloud
    environments. Cloud providers have their own user access controls (called *identity
    and access management*, or IAM) for the services provided, whereas on-premises
    uses technologies such as local directory access protocol (LDAP) or Kerberos.
    How do you keep them synchronized or have a single control plane across distinct
    environments?
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 用户访问控制和策略在本地和公共云环境之间有所不同。云服务提供商为其提供的服务有其自己的用户访问控制（称为*身份和访问管理*，或IAM），而本地则使用诸如本地目录访问协议（LDAP）或Kerberos等技术。如何保持它们同步或在不同环境中拥有单一控制平台？
- en: Workload interoperability
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 工作负载互操作性
- en: When going across multiple systems, it is inevitable to have inconsistent runtime
    environments that need to be managed.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在跨多个系统时，不可避免地会有需要管理的不一致的运行时环境。
- en: Data movement
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 数据迁移
- en: If both on-premises and cloud applications require access to some data, the
    two datasets must be in sync. It is costly to move data between multiple systems—there
    is a human cost to create and manage the pipeline, there may be licensing costs
    due to software used, and last but not least, it consumes system resources such
    as computation, network, and storage. How can your organization deal with the
    costs from multiple environments? How do you join heterogeneous data that is siloed
    across various environments? Where do you end up copying the data as a result
    of the join process?
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果本地和云应用程序都需要访问某些数据，则这两个数据集必须同步。在多个系统之间移动数据成本高昂——创建和管理管道有人力成本，可能由于使用的软件而产生许可成本，最后但同样重要的是，它消耗了计算、网络和存储资源。您的组织如何处理来自多个环境的成本？如何连接在各种环境中分散的异构数据？作为连接过程的结果，您最终将在何处复制数据？
- en: Skill sets
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 技能集
- en: Having the two clouds (or on premises and cloud) means teams have to know and
    build expertise in two environments. Since the public cloud is a fast-moving environment,
    there is a significant overhead associated with upskilling and maintaining the
    skills of employees in one cloud, let alone two. Skill sets can also be a challenge
    for hiring systems integrators (SIs)—even though most large SIs have practices
    for each of the major clouds, very few have teams that know two or more clouds.
    As time goes on, we anticipate that it will become increasingly difficult to hire
    people willing to learn bespoke on-premises technologies.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有两个云（或本地和云端）意味着团队必须了解并建立两个环境的专业知识。由于公共云是一个快速变化的环境，要提升和维护员工在一个云中的技能已经带来了显著的开销，更不用说两个了。技能集也可能对雇佣系统集成商（SIs）构成挑战——尽管大多数大型SIs都有每个主要云平台的实践，但很少有团队了解两个或更多的云平台。随着时间的推移，我们预计将越来越难雇佣愿意学习专有本地技术的人员。
- en: Economics
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 经济学
- en: 'The fact that the data is split between two environments can bring unforeseen
    costs: maybe you have data in one cloud and you want to make it available to another
    one, incurring egress costs.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分布在两个环境之间可能带来意想不到的成本：也许您在一个云中有数据，并希望将其提供给另一个云，这将产生数据流出成本。
- en: Despite these challenges, a hybrid setup can work. We’ll look at how in the
    next subsection.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些挑战，混合设置确实可行。我们将在下一小节中详细探讨如何做到。
- en: Why Hybrid Can Work
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么混合设置可以运作
- en: 'Cloud providers are aware of these needs and these challenges. Therefore, they
    provide some support for hybrid environments. These fall into three areas:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商意识到这些需求和挑战。因此，他们为混合环境提供了一些支持。这些支持可以分为三个方面：
- en: Choice
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 选择
- en: Cloud providers often make large contributions to open source technologies.
    For example, although Kubernetes and TensorFlow were developed at Google, they
    are open source so that managed execution environments for these exist in all
    the major clouds and they can be leveraged even in the on-premises environments.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商通常会大量贡献开源技术。例如，尽管 Kubernetes 和 TensorFlow 是在 Google 开发的，但它们是开源的，因此在所有主要云中都存在其托管执行环境，并且甚至可以在本地环境中利用它们。
- en: Flexibility
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 灵活性
- en: Frameworks such as Databricks and Snowflake allow you to run the same software
    on any of the major public cloud platforms. Thus, teams can learn one set of skills
    that will work everywhere. Note that the flexibility offered by tools that work
    on multiple clouds does not mean that you have escaped lock-in. You will have
    to choose between (1) lock-in at the framework level and flexibility at the cloud
    level (offered by technologies such as Databricks or Snowflake) and (2) lock-in
    at the cloud level and flexibility at the framework level (offered by the cloud
    native tools).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 类似 Databricks 和 Snowflake 的框架允许您在任何主要公共云平台上运行相同的软件。因此，团队可以学习一组能够在任何地方工作的技能。请注意，多云环境下工作的工具所提供的灵活性并不意味着您已经摆脱了锁定。您将不得不在以下两者之间做出选择：（1）在框架级别锁定和在云级别灵活性（由
    Databricks 或 Snowflake 等技术提供）之间；（2）在云级别锁定和在框架级别灵活性（由原生云工具提供）之间。
- en: Openness
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 开放性
- en: Even when the tool is proprietary, code for it is written in a portable manner
    because of the embrace of open standards and import/export mechanisms. Thus, for
    example, even though Redshift runs nowhere but on AWS, the queries are written
    in standard SQL and there are multiple import and export mechanisms. Together,
    these capabilities make Redshift and BigQuery and Synapse open platforms. This
    openness allows for [use cases like Teads](https://oreil.ly/avLkH), where data
    is collected using Kafka on AWS, aggregated using Dataflow and BigQuery on Google
    Cloud, and written back to AWS Redshift (see [Figure 1-9](#hybrid_analytics_pipeline_at_teads_left)).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 即使工具是专有的，由于采纳了开放标准和导入/导出机制，其代码也是以可移植的方式编写的。因此，例如，即使 Redshift 只能在 AWS 上运行，查询也是用标准
    SQL 编写的，并且有多种导入和导出机制。这些能力共同使得 Redshift、BigQuery 和 Synapse 成为开放平台。这种开放性允许[像 Teads
    这样的用例](https://oreil.ly/avLkH)，数据使用 Kafka 在 AWS 上收集，使用 Google Cloud 上的 Dataflow
    和 BigQuery 进行聚合，然后写回 AWS Redshift（参见[图 1-9](#hybrid_analytics_pipeline_at_teads_left)）。
- en: '![Hybrid analytics pipeline at Teads (figure based on an article by Alban Perillat-Merceroz
    published in Teads Engineering)](assets/adml_0109.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![Teads 的混合分析管道（基于 Alban Perillat-Merceroz 的一篇文章，发表在 Teads 工程）](assets/adml_0109.png)'
- en: Figure 1-9\. Hybrid analytics pipeline at Teads (figure based on an article
    by Alban Perillat-Merceroz and [published in Teads Engineering](https://oreil.ly/PyJUv))
  id: totrans-241
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-9\. Teads 的混合分析管道（基于 Alban Perillat-Merceroz 的一篇文章，[发表在 Teads 工程](https://oreil.ly/PyJUv)）
- en: Cloud providers are making a commitment to choice, flexibility, and openness
    by making heavy investments in open source projects that help customers use multiple
    clouds. Therefore, multicloud DWHs or hybrid data processing frameworks are becoming
    reality. So you can build out hybrid and multicloud deployments with better cloud
    software production, release, and management—the way you want, not how a vendor
    dictates.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商通过重视投资开源项目来承诺选择性、灵活性和开放性，这有助于客户在多个云中使用。因此，多云数据仓库或混合数据处理框架正在成为现实。因此，您可以按照您希望的方式构建混合和多云部署，以更好地生产、发布和管理云软件，而不是供应商强加的方式。
- en: Edge Computing
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边缘计算
- en: Another incarnation of the hybrid pattern is when you may want to have computational
    power spanning outside the usual data platform perimeter, maybe to interact directly
    with some connected devices. In this case we are talking about *edge computing*.
    Edge computing brings computation and data storage closer to the system where
    data is generated and needs to be processed. The aim in edge computing is to improve
    response times and save bandwidth. Edge computing can unlock many use cases and
    accelerate digital transformation. It has many application areas, such as security,
    robotics, predictive maintenance, smart vehicles, etc.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个混合模式的例子是当你可能希望计算能力跨越常规数据平台的边界，也许是直接与某些连接设备交互。在这种情况下，我们谈论的是*边缘计算*。边缘计算将计算和数据存储靠近生成数据并需要处理数据的系统。边缘计算的目标是提高响应时间并节省带宽。边缘计算可以解锁许多用例，并加速数字转型。它在许多应用领域有广泛的应用，例如安全、机器人技术、预测性维护、智能车辆等。
- en: 'As edge computing is adopted and goes mainstream, there are many potential
    advantages for a wide range of industries:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 随着边缘计算的采纳和普及，对于各行各业都存在许多潜在优势：
- en: Faster response time
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 更快的响应时间
- en: In edge computing, the power of data storage and computation is distributed
    and made available at the point where the decision needs to be made. Not requiring
    a round trip to the cloud reduces latency and empowers faster responses. In preventive
    maintenance, it will help stop critical machine operations from breaking down
    or hazardous incidents from taking place. In active games, edge computing can
    provide the millisecond response times that are required. In fraud prevention
    and security scenarios, it can protect against privacy breaches and denial-of-service
    attacks.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在边缘计算中，数据存储和计算能力被分布并提供在需要做出决策的地点。不需要往返云端将减少延迟，并使响应速度更快。在预防性维护中，这将有助于阻止关键机器操作的故障或危险事件的发生。在活动游戏中，边缘计算可以提供所需的毫秒级响应时间。在欺诈预防和安全场景中，它可以防止隐私泄露和拒绝服务攻击。
- en: Intermittent connectivity
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 断断续续的连接
- en: Unreliable internet connectivity at remote assets such as oil wells, farm pumps,
    solar farms, or windmills can make monitoring those assets difficult. Edge devices’
    ability to locally store and process data ensures no data loss or operational
    failure in the event of limited internet connectivity.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在石油井、农场水泵、太阳能场或风车等偏远资产存在不可靠的互联网连接性，这可能导致对这些资产的监控变得困难。边缘设备能够在本地存储和处理数据，确保在互联网连接受限的情况下不会丢失数据或操作失败。
- en: Security and compliance
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 安全和合规性
- en: Edge computing can eliminate a lot of data transfer between devices and the
    cloud. It’s possible to filter sensitive information locally and only transmit
    critical data model building information to the cloud. For example, with smart
    devices, watch-word processing such as listening for “OK Google” or “Alexa” can
    happen on the device itself. Potentially private data does not need to be collected
    or sent to the cloud. This allows users to build an appropriate security and compliance
    framework that is essential for enterprise security and audits.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算可以消除设备与云之间大量的数据传输。可以在本地过滤敏感信息，仅将关键数据模型构建信息传输到云端。例如，使用智能设备时，诸如监听“OK Google”或“Alexa”之类的关键词处理可以在设备本身上进行。潜在的私人数据不需要被收集或发送到云端。这使用户能够构建适当的安全性和合规性框架，对于企业的安全性和审核至关重要。
- en: Cost-effective solutions
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 成本有效的解决方案
- en: One of the practical concerns around IoT adoption is the up-front cost due to
    network bandwidth, data storage, and computational power. Edge computing can locally
    perform a lot of data computations, which allows businesses to decide which services
    to run locally and which ones to send to the cloud, which reduces the final costs
    of an overall IoT solution. This is where low-memory binary deployment of embedded
    models in a format like Open Neural Network Exchange (ONNX), built from a modern
    compiled language like Rust or Go, can excel.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在物联网采用中的一个实际关注点是由于网络带宽、数据存储和计算能力而产生的前期成本。边缘计算可以在本地执行大量数据计算，使企业能够决定哪些服务在本地运行，哪些发送到云端，从而降低整体物联网解决方案的最终成本。这就是嵌入式模型以低内存二进制部署的地方，在现代编译语言如Rust或Go中构建的格式（如开放神经网络交换ONNX）可以表现出色的地方。
- en: Interoperability
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 互操作性
- en: Edge devices can act as a communication liaison between legacy and modern machines.
    This allows legacy industrial machines to connect to modern machines or IoT solutions
    and provides immediate benefits of capturing insights from legacy or modern machines.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘设备可以作为传统和现代设备之间通信的联络人。这使得传统工业设备能够连接到现代设备或物联网解决方案，并立即从传统或现代设备中捕获见解的好处。
- en: All these concepts allow architects to be incredibly flexible in the definition
    of their data platform. In [Chapter 9](ch09.html#extending_a_data_platform_using_hybrid)
    we will deep dive more into these concepts and we will see how this pattern is
    becoming a standard.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些概念使架构师在定义他们的数据平台时极为灵活。在[第9章](ch09.html#extending_a_data_platform_using_hybrid)中，我们将深入探讨这些概念，看看这种模式如何成为标准。
- en: Applying AI
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用人工智能
- en: Many organizations are thrust into designing a cloud data platform because they
    need to adopt AI technologies—when designing a data platform, it is important
    to ensure that it will be future proof in being capable of supporting AI use cases.
    Considering the great impact AI is having on society and its diffusion within
    the enterprise environments, let’s take a quick deep dive into how it can be implemented
    in an enterprise environment. You will find a deeper discussion in Chapters [10](ch10.html#ai_application_architecture)
    and [11](ch11.html#architecting_an_ml_platform).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 许多组织因需要采用AI技术而被迫设计云数据平台——在设计数据平台时，重要的是确保它能够未来证明其能力以支持AI用例。考虑到AI对社会的巨大影响以及它在企业环境中的扩散，让我们快速深入地看一下它如何在企业环境中实施。您可以在第[10](ch10.html#ai_application_architecture)章和第[11](ch11.html#architecting_an_ml_platform)章中找到更深入的讨论。
- en: Machine Learning
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习
- en: These days, a branch of AI called *supervised machine learning* has become tremendously
    successful to the point where the term *AI* is more often used as an umbrella
    term for this branch. Supervised ML works by showing the computer program lots
    of examples where the correct answers (called *labels*) are known. The ML model
    is a standard algorithm (i.e., the exact same code) that has tunable parameters
    that “learn” how to go from the provided input to the label. Such a learned model
    is then deployed to make decisions on inputs for which the correct answers are
    not known.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一种名为*监督式机器学习*的AI分支已经取得了巨大成功，以至于术语*AI*更经常被用作这一分支的总称。监督式ML通过展示计算机程序许多已知正确答案（称为*标签*）的示例来工作。ML模型是一个标准算法（即完全相同的代码），具有可调参数，可以“学习”如何从提供的输入到标签。这样一个学习的模型随后被部署来对不知道正确答案的输入做出决策。
- en: Unlike expert systems, there is no need to explicitly program the AI model with
    the rules to make decisions. Because many real-world domains involve human judgment
    where experts struggle to articulate their logic, having the experts simply label
    input examples is much more feasible than capturing their logic.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 与专家系统不同，不需要明确编程AI模型的规则来做出决策。因为许多现实世界的领域涉及到专家判断，而专家往往难以表达他们的逻辑，所以让专家简单地标记输入示例比捕捉他们的逻辑要可行得多。
- en: Modern-day chess-playing algorithms and medical diagnostic tools use ML. The
    chess-playing algorithms learn from records of games that humans have played in
    the past,^([2](ch01.html#ch01fn3)) whereas medical diagnostic systems learn from
    having expert physicians label diagnostic data.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 现代象棋算法和医疗诊断工具使用ML。象棋算法从人类过去玩过的游戏记录中学习[^2]，而医疗诊断系统则从专家医生标记的诊断数据中学习。
- en: Generative AI, a branch of AI/ML that has recently become extremely capable,
    is capable of not just understanding images and text but of generating realistic
    images and text. Besides being able to create new content in applications such
    as marketing, generative AI streamlines the interaction between machines and users.
    Users are able to ask questions in natural language and automate many operations
    using English, or other languages, instead of having to know programming languages.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI，这是AI/ML的一个分支，最近变得非常强大，不仅能够理解图像和文本，还能生成逼真的图像和文本。除了能够在营销等应用中创建新内容外，生成式AI还简化了机器与用户之间的交互。用户能够用自然语言提问并使用英语或其他语言自动化许多操作，而不必了解编程语言。
- en: In order for these ML methods to operate, they require tremendous amounts of
    training data and readily available custom hardware. Because of this, organizations
    adopting AI start out by building a cloud data/ML platform.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这些ML方法运行，它们需要大量的训练数据和现成的定制硬件。因此，采用AI的组织首先建立了一个云数据/ML平台。
- en: Uses of ML
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML的用途
- en: 'There are a few key reasons for the spectacular adoption of ML in industry:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个关键原因导致了工业界对ML的惊人采纳：
- en: Data is easier.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 数据更容易。
- en: It is easier to collect labeled data than to capture logic. Every piece of human
    reasoning has exceptions that will be coded up over time. It is easier to get
    a team of ophthalmologists to label a thousand images than it is to get them to
    describe how they identify that a blood vessel is hemorrhaging.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 收集标记数据比捕捉逻辑更容易。人类推理的每一部分都有例外情况，随着时间的推移会被编码。让一组眼科医生标记一千张图像比让他们描述如何识别血管出血要容易得多。
- en: Retraining is easier.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 重新培训更容易。
- en: When ML is used for systems such as recommending items to users or running marketing
    campaigns, user behavior changes quickly to adapt. It is important to continually
    train models. This is possible in ML, but much harder with code.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 当机器学习用于系统，例如向用户推荐物品或运行营销活动时，用户行为迅速适应变化。继续训练模型非常重要。这在机器学习中是可能的，但用代码实现则更为困难。
- en: Better user interface.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的用户界面。
- en: A class of ML called *deep learning* has proven capable of being trained even
    on unstructured data such as images, video, and natural language text. These types
    of inputs are notoriously difficult to program against. This enables you to use
    real-world data as inputs—consider how much better the user interface of depositing
    checks becomes when you can simply take a photograph of a check instead of having
    to type all the information into a web form.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '*深度学习* 这类机器学习已被证明能够被训练，即使是在像图像、视频和自然语言文本这样的非结构化数据上。这些类型的输入通常很难编程。这使得你可以将真实世界的数据作为输入——考虑一下当你可以简单地拍摄支票照片而不必把所有信息都输入到网页表单时，存款支票界面会变得更好多少。'
- en: Automation.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化。
- en: The ability of ML models to understand unstructured data makes it possible to
    automate many business processes. Forms can be easily digitized, instrument dials
    can be more easily read, and factory floors can be more easily monitored because
    of the ability to automatically process natural language text, images, or video.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型理解非结构化数据的能力使得许多业务流程的自动化成为可能。表单可以轻松数字化，仪表盘读数可以更轻松，工厂车间可以更轻松地监控，因为可以自动处理自然语言文本、图像或视频。
- en: Cost-effectiveness.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 成本效益。
- en: ML APIs that give machines the ability to understand and create text, images,
    music, and video cost a fraction of a cent per invocation, whereas paying a human
    to do so would cost several orders of magnitude more. This enables the use of
    technology in situations such as recommendations, where a personal shopping assistant
    would be prohibitively expensive.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习API使得机器能够理解和创建文本、图像、音乐和视频，每次调用的成本仅为几分之一美分，而雇佣人类执行同样的任务则成本高出数个数量级。这使得技术在诸如推荐等情境中的应用成为可能，而雇佣个人购物助手则成本过高。
- en: Assistance.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 援助。
- en: Generative AI can empower developers, marketers, and other white-collar workers
    to be more productive. Coding assistants and workflow copilots are able to simplify
    parts of many corporate functions, such as sending out customized sales emails.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能可以赋予开发者、营销人员和其他白领工作者更高的生产力。编码助手和工作流合作者能够简化许多公司功能的部分，如发送定制销售邮件。
- en: 'Given these advantages, it is not surprising that a [*Harvard Business Review*
    article](https://oreil.ly/zhK6V) found that AI generally supports three main business
    requirements:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些优势，不足为奇，[*哈佛商业评论*文章](https://oreil.ly/zhK6V)发现，人工智能通常支持三个主要的业务需求：
- en: Automating business processes—typically automating back-office administrative
    and financial tasks
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化业务流程——通常是自动化后勤行政和财务任务
- en: Gaining insight through data analysis
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过数据分析获得洞见
- en: Engaging with customers and employees
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与顾客和员工互动
- en: ML increases the scalability to solve those problems using data examples and
    without needing to write custom code for everything. Then ML solutions such as
    deep learning allow solving these problems even when that data consists of unstructured
    information like images, speech, video, natural language text, etc.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习通过使用数据示例增加了解决问题的可扩展性，而无需为每件事情都编写自定义代码。然后，诸如深度学习之类的机器学习解决方案使得即使在处理像图像、语音、视频和自然语言文本等非结构化信息时也能解决这些问题。
- en: Why Cloud for AI?
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择云来支持人工智能？
- en: A key impetus behind designing a cloud data platform might be that the organization
    is rapidly adopting AI technologies such as deep learning. In order for these
    methods to operate, they require tremendous amounts of training data. Therefore,
    an organization that plans to build ML models will need to build a data platform
    to organize and make the data available to their data science teams. The ML models
    themselves are very complex, and training the models requires copious amounts
    of specialized hardware called *graphics processing units* (GPUs). Further, AI
    technologies such as speech transcription, machine translation, and video intelligence
    tend to be available as SaaS software on the cloud. In addition, cloud platforms
    provide key capabilities such as democratization, easier operationalization, and
    the ability to keep up with the state of the art.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 设计云数据平台的一个关键动机可能是组织正在快速采用深度学习等人工智能技术。为了使这些方法能够运作，它们需要大量的训练数据。因此，计划构建机器学习模型的组织需要建立一个数据平台，以组织并使数据可供其数据科学团队使用。这些机器学习模型本身非常复杂，训练这些模型需要大量的专用硬件，称为*图形处理单元*（GPUs）。此外，语音转录、机器翻译和视频智能等人工智能技术通常作为云端的SaaS软件提供。此外，云平台提供关键的功能，如民主化、更轻松的操作和跟上技术发展的能力。
- en: Cloud Infrastructure
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云基础设施
- en: The bottom line is that high-quality AI requires a lot of data—a famous paper
    titled [“Deep Learning Scaling Is Predictable, Empirically”](https://oreil.ly/NEoxe)
    found that for a 5% improvement in a natural language model, it was necessary
    to train twice as much data as was used to get the first result. The best ML models
    are not the most advanced ones—they are the ones that are trained on more data
    of high-enough quality. The reason is that increasingly sophisticated models require
    more data, whereas even simple models will improve in performance if trained on
    a sufficiently large dataset.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 关键是高质量的人工智能需要大量的数据——一篇著名的论文标题为[“深度学习扩展是可预测的，经验性的”](https://oreil.ly/NEoxe)发现，为了在自然语言模型中获得5%的改进，需要训练两倍于用于获得第一个结果的数据量。最优秀的机器学习模型并非最先进的那些——而是那些在足够高质量数据上训练的模型。原因在于，越来越复杂的模型需要更多的数据，而即使是简单的模型，如果在足够大的数据集上训练，也会提高性能。
- en: To give you an idea of the quantity of data required to complete the training
    of modern ML models, image classification models are routinely trained on [one
    million images](https://oreil.ly/l3yb2) and leading language models are trained
    on [multiple terabytes of data](https://oreil.ly/vmOWR).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解现代机器学习模型训练所需的数据量，可以举例说明，图像分类模型通常在[一百万张图片](https://oreil.ly/l3yb2)上进行训练，而主要的语言模型则是在[多个TB的数据](https://oreil.ly/vmOWR)上进行训练。
- en: As shown in [Figure 1-10](#ml_performance_increases_dramatically_w), this sort
    of data quantity requires a lot of efficient, bespoke computation—provided by
    accelerators such as GPUs and custom application-specific integrated circuits
    (ASICs) called *tensor processing units* (TPUs)—to harness this data and make
    sense of it.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图1-10](#ml_performance_increases_dramatically_w)所示，这种数据量需要大量高效的定制计算——通过加速器如GPU和定制的应用特定集成电路（ASICs）称为*张量处理单元*（TPUs）——来利用这些数据并理解它。
- en: Many recent AI advances can be attributed to increases in data size and compute
    power. The synergy between the large datasets in the cloud and the numerous computers
    that power it has enabled tremendous breakthroughs in ML. Breakthroughs include
    [reducing word error rates in speech recognition](https://oreil.ly/zDFuV) by 30%
    over traditional approaches, the biggest gain in 20 years.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 许多最近的人工智能进展可以归因于数据规模和计算能力的增加。云中大数据集和推动它的众多计算机之间的协同作用已经实现了机器学习的巨大突破。这些突破包括通过[降低语音识别中的词误差率](https://oreil.ly/zDFuV)30%，超过传统方法的最大进展已达20年之久。
- en: '![](assets/adml_0110.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/adml_0110.png)'
- en: Figure 1-10\. ML performance increases dramatically with greater memory, more
    processors, and/or the use of TPUs and GPUs (graph from [AVP Project](https://oreil.ly/e18-t))
  id: totrans-292
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10\. 随着内存增加、处理器增多以及使用TPUs和GPUs，机器学习性能显著提高（来自[AVP项目](https://oreil.ly/e18-t)的图表）
- en: Democratization
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 民主化
- en: Architecting ML models, especially in complex domains such as time-series processing
    or natural language processing (NLP), requires knowledge of ML theory. Writing
    code for training ML models using frameworks such as PyTorch, Keras, or TensorFlow
    requires knowledge of Python programming and linear algebra. In addition, data
    preparation for ML often requires data engineering expertise, and evaluating ML
    models requires knowledge of advanced statistics. Deploying ML models and monitoring
    them requires knowledge of DevOps and software engineering (often termed MLOps).
    Needless to say, it is rare that all these skills are present in every organization.
    Given this, leveraging ML for business problems can be difficult for a traditional
    enterprise.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 设计 ML 模型，特别是在复杂领域如时间序列处理或自然语言处理（NLP）中，需要掌握 ML 理论。使用 PyTorch、Keras 或 TensorFlow
    等框架编写 ML 模型训练代码需要掌握 Python 编程和线性代数知识。此外，为 ML 进行数据准备通常需要数据工程专业知识，并且评估 ML 模型需要高级统计学知识。部署
    ML 模型并监控它们需要 DevOps 和软件工程知识（通常称为 MLOps）。不用说，每个组织中都很少具备所有这些技能。考虑到这一点，利用 ML 解决业务问题对传统企业来说可能是困难的。
- en: 'Cloud technologies offer several options to democratize the use of ML:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 云技术提供了几种选项来使 ML 的使用民主化：
- en: ML APIs
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: ML API
- en: Cloud providers offer prebuilt ML models that can be invoked via APIs. At that
    point, a developer can consume the ML model like any other web service. All they
    require is the ability to program against representational state transfer (REST)
    web services. Examples of such ML APIs include Google Translate, Azure Text Analytics,
    and Amazon Lex—these APIs can be used without any knowledge of NLP. Cloud providers
    provide generative models for text and image generation as APIs where the input
    is just a text prompt.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商提供预构建的 ML 模型，可以通过 API 调用。此时，开发人员可以像使用任何其他 Web 服务一样使用 ML 模型。他们所需的只是能够针对表述状态转移（REST）Web
    服务进行编程的能力。这些 ML API 的示例包括 Google 翻译、Azure 文本分析和亚马逊 Lex —— 这些 API 可以在不需要任何 NLP
    知识的情况下使用。云服务提供商提供文本和图像生成的生成模型作为 API，其中输入只是一个文本提示。
- en: Customizable ML models
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 可定制的 ML 模型
- en: Some public clouds offer “AutoML,” which are end-to-end ML pipelines that can
    be trained and deployed with the click of a mouse. The AutoML models carry out
    “neural architecture search,” essentially automating the architecting of ML models
    through a search mechanism. While the training takes longer than if a human expert
    chooses an effective model for the problem, the AutoML system can suffice for
    lines of businesses that don’t have the capability to architect their own models.
    Note that not all AutoML is the same—sometimes what’s called AutoML is just parameter
    tuning. Make sure you are getting a custom-built architecture rather than simply
    a choice among prebuilt models, double-checking that there are various steps that
    can be automated (e.g., feature engineering, feature extraction, feature selection,
    model selection, parameter tuning, problem checking, etc.).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 一些公共云提供了“AutoML”，这些是端到端的 ML 流水线，可以通过点击鼠标进行训练和部署。AutoML 模型通过“神经架构搜索”来自动进行 ML
    模型的架构设计。虽然与人类专家选择有效模型相比，训练时间较长，但 AutoML 系统可以满足那些无法自行设计模型的业务线需求。请注意，并非所有的 AutoML
    都相同 —— 有时所谓的 AutoML 只是参数调优。确保您获得的是定制的架构而不仅仅是预构建模型的选择，双重检查是否有多个可以自动化的步骤（例如特征工程、特征提取、特征选择、模型选择、参数调优、问题检查等）。
- en: Simpler ML
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 更简单的 ML
- en: Some DWHs (BigQuery and Redshift at the time of writing) provide the ability
    to train ML models on structured data using just SQL. Redshift and BigQuery support
    complex models by delegating to Vertex AI and SageMaker respectively. Tools like
    DataRobot and Dataiku offer point-and-click interfaces to train ML models. Cloud
    platforms make fine-tuning of generative models much easier than otherwise.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在写作时，一些数据仓库（例如 BigQuery 和 Redshift）提供了使用 SQL 在结构化数据上训练 ML 模型的能力。Redshift 和 BigQuery
    支持通过委派给 Vertex AI 和 SageMaker 实现复杂模型。像 DataRobot 和 Dataiku 这样的工具提供了用于训练 ML 模型的点对点界面。与其它方式相比，云平台使生成模型的微调变得更加容易。
- en: ML solutions
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: ML 解决方案
- en: Some applications are so common that end-to-end ML solutions are available to
    purchase and deploy. Product Discovery on Google Cloud offers an end-to-end search
    and ranking experience for retailers. Amazon Connect offers a ready-to-deploy
    contact center powered by ML. Azure Knowledge Mining provides a way to mine a
    variety of content types. In addition, companies such as Quantum Metric and C3
    AI offer cloud-based solutions for problems common in several industries.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 一些应用程序如此常见，以至于可以购买和部署端到端的机器学习解决方案。Google Cloud上的产品发现提供了零售商的端到端搜索和排名体验。Amazon
    Connect提供了由机器学习驱动的即插即用的联系中心。Azure Knowledge Mining提供了一种挖掘各种内容类型的方式。此外，像Quantum
    Metric和C3 AI这样的公司为多个行业常见的问题提供基于云的解决方案。
- en: ML building blocks
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习构建块
- en: Even if no solution exists for the entire ML workflow, parts of it could take
    advantage of building blocks. For example, recommender systems require the ability
    to match items and products. A general-purpose matching algorithm called *two-tower
    encoders* is available from Google Cloud. While there is no end-to-end back-office
    automation ML model, you could take advantage of form parsers to help implement
    that workflow quicker.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 即使整个机器学习工作流程没有解决方案，部分工作也可以利用构建块。例如，推荐系统需要能够匹配项目和产品。Google Cloud提供了一种名为*two-tower
    encoders*的通用匹配算法。虽然没有端到端的后台自动化机器学习模型，但您可以利用表单解析器来帮助更快地实现该工作流程。
- en: These capabilities allow enterprises to adopt AI even if they don’t have deep
    expertise in it, thereby making AI more widely available.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这些能力使企业即使没有深入的专业知识也可以采用人工智能，从而使人工智能更广泛地可用。
- en: Even if the enterprise does have expertise in AI, these capabilities prove very
    useful because you still have to decide whether to buy or build an ML system.
    There are usually more ML opportunities than there are people to solve them. Given
    this, there is an advantage to allowing noncore functionality to be carried out
    using prebuilt tools and solutions. These out-of-the-box solutions can deliver
    a lot of value immediately without needing to write custom applications. For example,
    data from a natural language text can be passed to a prebuilt model via an API
    call to translate text from one language to another. This not only reduces the
    effort to build applications but also enables non-ML experts to use AI. On the
    other end of the spectrum, the problem may require a custom solution. For example,
    retailers often build ML models to forecast demand so they know how much product
    to stock. These models learn buying patterns from a company’s historical sales
    data, combined with in-house, expert intuition.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 即使企业具有人工智能的专业知识，这些能力也非常有用，因为您仍然需要决定是购买还是构建机器学习系统。通常情况下，机器学习的机会比解决它们的人员多。因此，允许使用预构建的工具和解决方案来执行非核心功能具有优势。这些即插即用的解决方案可以立即提供大量价值，而无需编写定制应用程序。例如，通过API调用将自然语言文本的数据传递给预构建模型以进行文本翻译。这不仅减少了构建应用程序的工作量，还使非机器学习专家能够使用人工智能。在另一端，问题可能需要定制解决方案。例如，零售商经常构建机器学习模型来预测需求，以便知道需要存货的量。这些模型从公司的历史销售数据和内部专家直觉中学习购买模式。
- en: Another common pattern is to use prebuilt, out-of-the-box models for quick experimentation,
    and once the ML solution has proven its value, a data science team can build it
    in a bespoke way to get greater accuracy and hopefully more differentiation against
    the competition.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见模式是使用预构建的即插即用模型进行快速实验，一旦机器学习解决方案证明其价值，数据科学团队可以以定制方式构建它，以获得更高的准确性，并希望在竞争中获得更多差异化优势。
- en: Real Time
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时
- en: It is necessary for the ML infrastructure to be integrated with a modern data
    platform because real-time, personalized ML is where the value is. As a result,
    speed of analytics becomes really important as the data platform must be able
    to ingest, process, and serve data in real time, or opportunities are lost. This
    is then complemented by the speed of action. ML drives personalized services,
    based on the customer’s context, but has to provide inference before the customer
    context switches—there’s a closing window for most commercial transactions within
    which the ML model needs to provide the customer with an option to act. To achieve
    this, you need the results of ML models to arrive at the point of action in real
    time.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: ML 基础设施必须与现代数据平台集成，因为实时个性化 ML 才有价值。因此，分析速度变得非常重要，因为数据平台必须能够实时摄取、处理和提供数据，否则就会错失机会。这还要加上行动速度。ML
    提供基于客户背景的个性化服务，但必须在客户背景切换之前提供推断——对于大多数商业交易，ML 模型在客户采取行动之前必须提供客户进行选择的选项。为了实现这一点，需要使
    ML 模型的结果实时到达行动点。
- en: Being able to supply ML models with data in real time and get the ML prediction
    in real time is the difference between preventing fraud and discovering fraud.
    To prevent fraud, it is necessary to ingest all payment and customer information
    in real time, run the ML prediction, and provide the result of the ML model back
    to the payment site in real time so that the payment can be rejected if fraud
    is suspected.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 能够实时向 ML 模型提供数据并在实时获得 ML 预测，这是防范欺诈和发现欺诈的区别。为了防范欺诈，必须实时摄取所有付款和客户信息，运行 ML 预测，并将
    ML 模型的结果实时返回到付款网站，以便如果怀疑有欺诈，则可以拒绝付款。
- en: Other situations where real-time processing saves money are customer service
    and cart abandonment. Catching customer frustration in a call center and immediately
    escalating the situation is important to render the service effective—it will
    cost a lot more money to reacquire a customer once lost than to render them good
    service in the moment. Similarly, if a cart is at risk of being discarded, offering
    an enticement such as 5% off or free shipping may cost less than the much larger
    promotions required to get the customer back on the website.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在客户服务和购物车放弃等情况下，实时处理节省了很多钱。在呼叫中心捕捉客户的沮丧，并立即升级情况，是提供有效服务的重要因素——与重新获得失去的客户相比，提供良好的服务成本要高得多。同样，如果购物车有被丢弃的风险，提供例如
    5% 折扣或免费运输的诱因，成本可能低于重新吸引客户回到网站所需的大幅促销活动。
- en: In other situations, batch processing is simply not an effective option. Real-time
    traffic data and real-time navigation models are required for Google Maps to allow
    drivers to avoid traffic.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他情况下，批处理不是一个有效的选择。Google 地图需要实时交通数据和实时导航模型，以允许驾驶员避开交通。
- en: As you will see in [Chapter 8](ch08.html#architectures_for_streaming), the resilience
    and autoscaling capability of cloud services is hard to achieve on premises. Thus,
    real-time ML is best done in the cloud.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您将在 [第 8 章](ch08.html#architectures_for_streaming) 中看到的，云服务的弹性和自动缩放能力在本地实现起来很困难。因此，实时
    ML 最好在云中进行。
- en: MLOps
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps
- en: Another reason that ML is better in the public cloud is that operationalizing
    ML is hard. Effective and successful ML projects require operationalizing both
    data and code. Observing, orchestrating, and acting on the ML lifecycle is termed
    *MLOps*.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 公共云中 ML 更好的另一个原因是 ML 的操作化很难。有效和成功的 ML 项目需要操作化数据和代码。观察、编排和执行 ML 生命周期被称为*MLOps*。
- en: Building, deploying, and running ML applications in production entails several
    stages, as shown in [Figure 1-11](#stages_of_an_ml_workflow). All these steps
    need to be orchestrated and monitored; if, for example, data drift is detected,
    the models may need to be automatically retrained. Models have to be retrained
    on a constant basis and deployed, after making sure they are safe to be deployed.
    For the incoming data, you have to perform data preprocessing and validation to
    make sure there are no data quality issues, followed by feature engineering, followed
    by model training, and ending with hyperparameter tuning.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中构建、部署和运行 ML 应用程序涉及几个阶段，如 [图 1-11](#stages_of_an_ml_workflow) 所示。所有这些步骤都需要编排和监控；例如，如果检测到数据漂移，则可能需要自动重新训练模型。必须定期对模型进行重新训练并部署，确保它们可以安全部署。对于传入数据，必须执行数据预处理和验证，确保没有数据质量问题，然后进行特征工程，接着是模型训练，最后进行超参数调整。
- en: '![Stages of an ML workflow](assets/adml_0111.png)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![一个ML工作流程的阶段](assets/adml_0111.png)'
- en: Figure 1-11\. Stages of an ML workflow
  id: totrans-319
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-11\. 一个ML工作流程的阶段
- en: In addition to the data-specific aspects of monitoring discussed, you also have
    the monitoring and operationalization that is necessary for any running service.
    A production application is often running continuously 24/7/365, with new data
    coming in regularly. Thus, you need tooling that makes it easy to orchestrate
    and manage these multiphase ML workflows and to run them reliably and repeatedly.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 除了讨论的监控数据特定方面之外，你还需要对任何运行服务所必需的监控和操作化进行监控。生产应用通常是持续运行的，每天24小时/7天/365天，新数据定期进入。因此，你需要能够轻松编排和管理这些多阶段ML工作流，并可靠地和重复地运行它们的工具。
- en: Cloud AI platforms such as Google’s Vertex AI, Microsoft’s Azure Machine Learning,
    and Amazon’s SageMaker provide managed services for the entire ML workflow. Doing
    this on premises requires you to cobble together the underlying technologies and
    manage the integrations yourself.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 云AI平台如Google的Vertex AI，微软的Azure机器学习和亚马逊的SageMaker提供整个ML工作流程的托管服务。在本地进行这些操作需要你将底层技术拼凑在一起并自行管理集成。
- en: At the time of writing this book, MLOps capabilities are being added at a breakneck
    pace to the various cloud platforms. This brings up an ancillary point, that with
    the rapid pace of change in ML, you are better off delegating the task of building
    and maintaining ML infrastructure and tooling to a third party and focusing on
    data and insights that are relevant to your core business.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，MLOps能力正在以极快的速度添加到各种云平台。这提出了一个相关的观点，即随着ML领域的快速变化，将构建和维护ML基础设施和工具委托给第三方，专注于与核心业务相关的数据和洞察力会更好。
- en: In summary, a cloud-based data and AI platform can help resolve traditional
    challenges with data silos, governance, and capacity while enabling the organization
    to prepare for a future where AI capabilities become more important.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，基于云的数据和AI平台可以帮助解决数据孤岛、治理和容量方面的传统挑战，同时使组织能够为AI能力变得更加重要的未来做好准备。
- en: Core Principles
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 核心原则
- en: When designing a data platform, it can help to set down key design principles
    to adhere to and the weight that you wish to assign to each of these principles.
    It is likely that you will need to make trade-offs between these principles, and
    having a predetermined scorecard that all stakeholders have agreed to can help
    you make decisions without having to go back to first principles or getting swayed
    by the squeakiest wheel.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 设计数据平台时，设定关键设计原则和希望分配给每个原则的权重可能会有所帮助。很可能需要在这些原则之间做出权衡，拥有所有利益相关者都同意的预先确定的评分卡可以帮助你在不必回到第一原则或被最强烈的需求左右的情况下做出决策。
- en: 'Here are the five key design principles for a data analytics stack that we
    suggest, although the relative weighting will vary from organization to organization:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们建议的数据分析堆栈的五个关键设计原则，尽管相对权重会因组织而异：
- en: Deliver serverless analytics, not infrastructure.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 提供无服务器分析，而非基础设施。
- en: Design analytics solutions for fully managed environments and avoid a lift-and-shift
    approach as much as possible. Focus on a modern serverless architecture to allow
    your data scientists (we use this term broadly to refer to data engineers, data
    analysts, and ML engineers) to keep their focus purely on analytics and move away
    from infrastructure considerations. For example, use automated data transfer to
    extract data from your systems and provide an environment for shared data with
    federated querying across any service. This eliminates the need to maintain custom
    frameworks and data pipelines.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 设计分析解决方案，避免尽可能地使用搬迁和移移方法。专注于现代无服务器架构，让你的数据科学家（我们广泛使用此术语来指数据工程师、数据分析师和ML工程师）专注于分析，远离基础设施考虑。例如，使用自动化数据传输从系统中提取数据，并提供跨任何服务的联邦查询共享数据环境。这消除了维护自定义框架和数据管道的必要性。
- en: Embed end-to-end ML.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入端到端机器学习。
- en: Allow your organization to operationalize ML end to end. It is impossible to
    build every ML model that your organization needs, so make sure you are building
    a platform within which it is possible to embed democratized ML options such as
    prebuilt ML models, ML building blocks, and easier-to-use frameworks. Ensure that
    when custom training is needed, there is access to powerful accelerators and customizable
    models. Ensure that MLOps is supported so that deployed ML models don’t drift
    and become no longer fit for purpose. Make the ML lifecycle simpler on the entire
    stack so that the organization can derive value from its ML initiatives faster.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 允许您的组织全面实现机器学习的运作。不可能为组织需要的每个机器学习模型构建一个模型，因此请确保您构建的平台能够嵌入民主化的机器学习选择，例如预构建的机器学习模型、机器学习构建块和更易于使用的框架。确保在需要自定义训练时，有权访问强大的加速器和可定制的模型。确保支持
    MLOps，以确保部署的机器学习模型不会漂移并且不再适合用途。简化整个堆栈上的机器学习生命周期，以便组织能够更快地从其机器学习倡议中获取价值。
- en: Empower analytics across the entire data lifecycle.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个数据生命周期中赋予分析能力。
- en: The data analytics platform should be offering a comprehensive set of core data
    analytics workloads. Ensure that your data platform offers data storage, data
    warehousing, streaming data analytics, data preparation, big data processing,
    data sharing and monetization, business intelligence (BI), and ML. Avoid buying
    one-off solutions that you will have to integrate and manage. Looking at the analytics
    stack much more holistically will, in return, allow you to break down data silos,
    power applications with real-time data, add read-only datasets, and make query
    results accessible to anyone.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析平台应提供一套全面的核心数据分析工作负载。确保您的数据平台提供数据存储、数据仓库、流数据分析、数据准备、大数据处理、数据共享与商业化、商业智能（BI）和机器学习。避免购买需要集成和管理的一次性解决方案。更全面地审视分析栈将有助于打破数据孤岛，为应用程序提供实时数据支持，添加只读数据集，并使查询结果对任何人都可访问。
- en: Enable open source software (OSS) technologies.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 启用开源软件（OSS）技术。
- en: Wherever possible, ensure that open source is at the core of your platform.
    You want to ensure that any code that you write uses OSS standards such as standard
    SQL, Apache Spark, TensorFlow, etc. By enabling the best open source technologies,
    you will be able to provide flexibility and choice in data analytics projects.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何可能的情况下，确保开源技术是您平台的核心。您希望确保您编写的任何代码都使用标准的开源软件标准，如标准 SQL、Apache Spark、TensorFlow
    等。通过启用最佳的开源技术，您将能够在数据分析项目中提供灵活性和选择性。
- en: Build for growth.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 为增长而构建。
- en: Ensure that the data platform that you build will be able to scale to the data
    size, throughput, and number of concurrent users that your organization is expected
    to face. Sometimes, this will involve picking different technologies (e.g., SQL
    for some use cases and NoSQL for other use cases). If you do so, ensure that the
    two technologies that you pick interoperate with each other. Leverage solutions
    and frameworks that have been proven and used by the world’s most innovative companies
    to run their mission-critical analytics apps.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您构建的数据平台能够适应您的组织预期面临的数据规模、吞吐量和并发用户数。有时，这将涉及选择不同的技术（例如，某些用例使用 SQL，而其他用例使用 NoSQL）。如果这样做，请确保您选择的两种技术能够互操作。利用已被全球最具创新力公司证明和使用的解决方案和框架来运行其关键任务的分析应用程序。
- en: Overall, these factors are listed in the order that we typically recommend them.
    Since the two primary motivations of enterprises in choosing to do a cloud migration
    are cost and innovation, we recommend that you prioritize serverless (for cost
    savings and freeing employees from routine work) and end-to-end ML (for the wide
    variety of innovation that it enables).
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这些因素按照我们通常推荐的顺序列出。由于企业选择进行云迁移的两个主要动机是成本和创新，我们建议您优先考虑无服务器架构（以节省成本并解放员工免于例行工作）和端到端机器学习（因其支持的广泛创新）。
- en: In some situations, you might want to prioritize some factors over others. For
    startups, we typically recommend that the most important factors are serverless,
    growth, and end-to-end ML. Comprehensiveness and openness can be sacrificed for
    speed. Highly regulated enterprises might favor comprehensiveness, openness, and
    growth over serverless and ML (i.e., on premises might be necessitated by regulators).
    For digital natives, we recommend, in order, end-to-end ML, serverless, growth,
    openness, and comprehensiveness.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，您可能希望优先考虑某些因素。对于初创公司，我们通常建议最重要的因素是无服务器、增长和端到端ML。全面性和开放性可以为速度而牺牲。高度监管的企业可能会偏向于全面性、开放性和增长，而不是无服务器和ML（即监管者可能需要在本地进行）。对于数字原生企业，我们建议依次是端到端ML、无服务器、增长、开放性和全面性。
- en: Summary
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This was a high-level introduction to data platform modernization. Starting
    from the definition of the data lifecycle, we looked at the evolution of data
    processing, the limitations of traditional approaches, and how to create a unified
    analytics platform on the cloud. We also looked at how to extend the cloud data
    platform to be a hybrid one and to support AI/ML. The key takeaways from this
    chapter are as follows:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于数据平台现代化的高层介绍。从数据生命周期的定义开始，我们看了数据处理的演变，传统方法的局限性，以及如何在云上创建统一的分析平台。我们还看了如何扩展云数据平台成为混合平台，并支持AI/ML。本章的关键要点如下：
- en: 'The data lifecycle has five stages: collect, store, process, analyze/visualize,
    and activate. These need to be supported by a data and ML platform.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据生命周期有五个阶段：收集、存储、处理、分析/可视化和激活。这些需要由数据和ML平台支持。
- en: Traditionally, organizations’ data ecosystems consist of independent solutions
    that lead to the creation of silos within the organization.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传统上，组织的数据生态系统由独立的解决方案组成，导致组织内部形成孤立。
- en: 'Data movement tools can break data silos, but they impose a few drawbacks:
    latency, data engineering resource bottlenecks, maintenance overhead, change management,
    and data gaps.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据移动工具可以打破数据孤立，但它们带来一些缺点：延迟、数据工程资源瓶颈、维护开销、变更管理和数据间隙。
- en: Centralizing control of data within IT leads to organizational challenges. IT
    departments don’t have necessary skills, analytics teams get poor data, and business
    teams do not trust the results.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在IT内集中控制数据会导致组织挑战。IT部门缺乏必要的技能，分析团队获取到的数据质量差，业务团队不信任结果。
- en: Organizations need to build a cloud data platform to obtain best-of-breed architectures,
    handle consolidation across business units, scale on-prem resources, and plan
    for business continuity.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织需要构建一个云数据平台来获得最佳架构，处理业务单位之间的整合，扩展本地资源，并规划业务连续性。
- en: A cloud data platform leverages modern approaches and aims to enable data-led
    innovation through replatforming data, breaking down silos, democratizing data,
    enforcing data governance, enabling decision making in real time and using location
    information, and moving seamlessly from descriptive analytics to predictive and
    prescriptive analytics.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云数据平台利用现代方法，旨在通过重新平台化数据、打破孤立、民主化数据、强化数据治理、实现实时决策并使用位置信息，从描述性分析顺畅过渡到预测性和规范性分析，从而促进数据驱动的创新。
- en: All data can be exported from operational systems to a centralized data lake
    for analytics. The data lake serves as the central repository for analytics workloads
    and for business users. The drawback, however, is that business users do not have
    the skills to program against a data lake.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有数据可以从运营系统导出到集中式数据湖进行分析。数据湖作为分析工作负载和业务用户的中央存储库。然而，其缺点是业务用户没有编程对接数据湖的技能。
- en: DWHs are centralized analytics stores that support SQL, something that business
    users are familiar with.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据仓库是支持SQL的集中式分析存储，这是业务用户熟悉的内容。
- en: The data lakehouse is based on the idea that all users, regardless of their
    technical skills, can and should be able to use data. By providing a centralized
    and underlying framework for making data accessible, different tools can be used
    on top of the lakehouse to meet the needs of each user.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据湖室建立在这样一个理念基础上，即所有用户，无论其技术技能如何，都可以并且应该能够使用数据。通过提供一个集中的底层框架来使数据可访问，可以在湖室顶部使用不同的工具，以满足每个用户的需求。
- en: Data mesh introduces a way of seeing data as a self-contained product. Distributed
    teams in this approach own the data production and serve internal/external consumers
    through well-defined data schema.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据网格引入了一种将数据视为自包含产品的方式。在这种方法中，分布式团队拥有数据的生产，并通过明确定义的数据模式为内部/外部消费者提供服务。
- en: A hybrid cloud environment is a pragmatic approach to meet the realities of
    the enterprise world such as acquisitions, local laws, and latency requirements.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合云环境是满足企业世界现实的实用方法，例如收购、本地法律和延迟要求。
- en: The ability of the public cloud to provide ways to manage large datasets and
    provision GPUs on demand makes it indispensable for all forms of ML, but deep
    learning and generative AI in particular. In addition, cloud platforms provide
    key capabilities such as democratization, easier operationalization, and the ability
    to keep up with the state of the art.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公共云提供了管理大型数据集和按需提供GPU的方式，使其对所有形式的ML都不可或缺，特别是深度学习和生成AI。此外，云平台还提供了民主化、更容易的操作和跟上最新技术的能力。
- en: The five core principles of a cloud data platform are to prioritize serverless
    analytics, end-to-end ML, comprehensiveness, openness, and growth. The relative
    weights will vary from organization to organization.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云数据平台的五个核心原则是优先考虑无服务器分析、端到端ML、全面性、开放性和增长性。这些相对权重会因组织而异。
- en: Now that you know where you want to land, in the next chapter, we’ll look at
    a strategy to get there.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道自己想要达到的目标位置后，在下一章中，我们将讨论达到目标的策略。
- en: ^([1](ch01.html#ch01fn1-marker)) Not just the cost of the technology or license
    fees—the cost here includes people costs, and SQL skills tend to cost less to
    an organization than Java or Python skills.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.html#ch01fn1-marker)) 这里的成本不仅包括技术或许可证费用，还包括人力成本，而SQL技能往往对组织的成本影响比Java或Python技能低。
- en: '^([2](ch01.html#ch01fn3-marker)) Recent ML systems such as [AlphaGo](https://oreil.ly/Garre)
    learn by looking at games played between machines themselves: this is an advanced
    type of ML called *reinforcement learning*, but most industrial uses of ML are
    of the simpler supervised kind.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch01.html#ch01fn3-marker)) 最近的ML系统，例如[AlphaGo](https://oreil.ly/Garre)，通过观察机器之间玩的游戏来学习：这是一种称为*强化学习*的高级ML类型，但大多数工业用途的ML属于更简单的监督学习类型。
