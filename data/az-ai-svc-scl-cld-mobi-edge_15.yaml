- en: Chapter 11\. Translating Multiple Languages at Scale for International Organizations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章。为国际组织大规模翻译多种语言
- en: While many Azure Machine Learning and Cognitive Services applications are focused
    on business and consumer services, they’re also important tools for governments
    and other public bodies. Machine learning–powered tools can help make organizations
    like these more efficient, removing bottlenecks and speeding up common processes.
    Microsoft has been championing these approaches, with initiatives like its AI
    for Good program.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然许多Azure机器学习和认知服务应用程序侧重于商业和消费服务，但它们也是政府和其他公共机构的重要工具。机器学习驱动的工具可以帮助这些组织更高效地运作，消除瓶颈并加快常见流程。微软一直在推动这些方法，例如其AI
    for Good计划。
- en: One important role for Microsoft’s AI tools is in breaking down barriers between
    different nationalities by providing tools for rapid, automatic translation. If
    you’ve used the captioning tools in PowerPoint or the Translator app on your smartphone,
    you’re using tools built around Azure’s speech recognition and translation services.
    We’ve looked at how to use them in your applications in [Chapter 4](ch04.xhtml#using_azure_cognitive_services_to_build),
    showing how speech recognition tools convert speech to text, how translation tools
    turn that text from one language to another, and how neural speech models deliver
    natural-sounding speech from translated text.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 微软人工智能工具的一个重要作用是通过提供快速自动翻译的工具来消除不同国籍之间的障碍。如果你使用过PowerPoint中的字幕工具或智能手机上的Translator应用程序，你正在使用围绕Azure语音识别和翻译服务构建的工具。我们已经看过如何在你的应用程序中使用它们，在[第4章](ch04.xhtml#using_azure_cognitive_services_to_build)中展示了语音识别工具如何将语音转换为文本，翻译工具如何将这些文本从一种语言翻译为另一种语言，以及神经语音模型如何从翻译后的文本中提供自然语音。
- en: Delivering Translations for an International Parliament
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为国际议会提供翻译
- en: Much of what we do with these tools is used to support individuals, translating
    menus or helping take a taxi across an unfamiliar city. But what if we need to
    provide near-real-time transcriptions of a large number of people, working in
    multiple languages, using a specialized vocabulary? That was the problem a team
    of Microsoft engineers had to solve in order to build a prototype translation
    service for the European Parliament, building on the same Cognitive Services APIs
    and tools we examined in [Chapter 4](ch04.xhtml#using_azure_cognitive_services_to_build).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这些工具的许多方式是为了支持个人，翻译菜单或帮助在陌生城市中搭乘出租车。但是，如果我们需要为大量使用专业词汇的多语种工作人员提供近实时的转录，会怎么样呢？这是微软工程团队必须解决的问题，以便为欧洲议会构建原型翻译服务，基于我们在[第4章](ch04.xhtml#using_azure_cognitive_services_to_build)中探讨过的同一认知服务API和工具。
- en: Multinational bodies like the European Parliament work in many languages, with
    delegates from 27 countries speaking 24 different languages, and more than 4,000
    interpreters. With no one official language, speeches needed both real-time transcriptions
    and translations, so that speakers could respond to speeches during debates while
    also creating an official record of proceedings. This means linking into the parliament
    sound and recording systems, automatically detecting languages and changing the
    transcription model on the fly as the language changes.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 像欧洲议会这样的跨国机构使用多种语言工作，代表来自27个国家的代表讲述24种不同的语言，并且有超过4,000名口译员。由于没有官方语言，演讲需要实时转录和翻译，以便发言者可以在辩论期间回应演讲，同时创建官方记录。这意味着需要连接到议会的声音和录音系统，自动检测语言并随着语言变化即时更改转录模型。
- en: Connecting to Existing Audio-Visual (AV) Systems
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接现有音视频（AV）系统
- en: A direct connection into the sound system wasn’t possible due to the nature
    of the competitive tender, so systems had to work with a web API using MPEG-DASH.
    This added complexity, as MPEG-DASH delivers adaptive-rate audio data, while the
    Azure Cognitive Services inputs expect pulse-code modulation (PCM) audio streams
    encoded at 60K hertz. The audio system also delivered 25 different streams, one
    for each language and a main audio track from the parliament floor.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由于竞标性质的关系，直接连接音响系统并不可行，因此系统必须通过使用MPEG-DASH的Web API工作。这增加了复杂性，因为MPEG-DASH提供自适应速率音频数据，而Azure认知服务输入则期望以60K赫兹编码的脉冲编码调制（PCM）音频流。音频系统还提供了25种不同的流，每种语言一种以及来自议会楼层的主音频轨道。
- en: The Microsoft system had to first identify the live stream, then separate video
    and audio signals, before transcoding the audio track into PCM. Once separated,
    the two streams needed to be time coded, so the resulting transcriptions could
    be synchronized with the video stream before delivering it to end users. With
    a fixed requirement for less than seven seconds latency, there was limited time
    for the system to handle data conversions and deliver transcribed and translated
    captions.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 微软系统首先需要识别直播流，然后分离视频和音频信号，再将音频轨道转码为PCM。一旦分离，两个流需要进行时间编码，以便将生成的转录与视频流同步，然后将其提供给最终用户。由于要求延迟不超过七秒，系统处理数据转换并传递转录和翻译字幕的时间有限。
- en: Cloud native development techniques proved to be appropriate, using a microservice
    architecture to handle the initial signal processing using familiar open source
    tools like FFmpeg to manage transcoding before delivering the converted audio
    stream to the Cognitive Services translation tools. The real-time protocol SignalR
    was used to deliver the resulting captions back to the portal, along with time-coded
    offsets that were used to align the text with the original video streams. Latency
    remained low, the whole process taking less than two seconds.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生开发技术被证明是合适的，使用微服务架构来处理初始信号处理，使用熟悉的开源工具如FFmpeg来管理转码，然后将转换后的音频流传递给认知服务翻译工具。实时协议SignalR用于将生成的字幕返回到门户，同时带有时间编码的偏移量，用于将文本与原始视频流对齐。延迟保持较低，整个过程不超过两秒。
- en: Using Custom Speech Recognition for Specialized Vocabularies
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用专用语音识别处理特定词汇
- en: As there was a significant amount of specialized vocabulary, Microsoft’s Cognitive
    Services group worked to deliver a set of custom language models for the 24 required
    languages, using a dataset of speeches to train the models. Two teams worked on
    this aspect of the project, one handling transcription models and another on translations.
    The models were evaluated using their BLEU scores, which show how close to human
    translations their results were, as well as their word error rate. There was a
    minimum level for both scores that the models needed to beat.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于存在大量专用词汇，微软的认知服务团队努力为24种所需语言交付一组定制语言模型，使用演讲数据集来训练这些模型。项目的一个团队负责处理转录模型，另一个团队负责翻译。这些模型通过它们的BLEU分数进行评估，该分数显示它们的结果与人工翻译有多接近，以及它们的词错误率。这些模型需要超过最低分数水平。
- en: Once trained, the custom models were made available through a private endpoint
    in Azure, with their own compute resources. This approach was no different from
    that available to anyone using Cognitive Services; the tools Microsoft used were
    the standard ones built into the platform.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，定制模型通过Azure中的私有端点提供，拥有自己的计算资源。这种方法与使用认知服务的任何人可用的方法没有区别；微软使用的工具是平台内置的标准工具。
- en: The biggest issue facing the team building out the service was the quality of
    the incoming audio streams and the length of the overall audio pipeline. Each
    processing step adds latency, so you need to keep the number of steps to a minimum.
    There’s also additional latency in the variable bit-rate web streams used as a
    source. A 32K stream could drop down to 5K and back up to 100K, before returning
    to its standard rate. While the prototype used software encoding to go from streams
    to an Azure-compatible format, in practice a hardware solution would have better
    performance and would keep latency to a minimum.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 服务团队面临的最大问题是入口音频流的质量以及整体音频管道的长度。每个处理步骤都会增加延迟，因此需要尽量减少步骤数。作为来源的可变比特率网络流也会增加额外的延迟。例如，32K流量可能会降至5K，然后再回升到100K，最终回归到其标准速率。尽管原型使用软件编码将流转换为Azure兼容格式，但实际上硬件解决方案将具有更好的性能，并将延迟保持在最低水平。
- en: The software team also found that their initial container-based design was slower
    than using VMs to host their microservices. This was because the containers couldn’t
    access GPU resources, while Azure provides GPU VMs. Switching from a serverless
    container host to infrastructure-as-a-service increases operating costs, but the
    gains in performance are significant. Like using hardware-based audio encoders,
    working with a limited latency budget means taking advantage of all the gains
    you can get from your hardware.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 软件团队还发现，他们最初基于容器的设计比使用虚拟机来托管微服务更慢。这是因为容器无法访问GPU资源，而Azure提供了GPU虚拟机。从无服务器容器主机切换到基础设施即服务会增加运营成本，但性能提升显著。与使用基于硬件的音频编码器一样，处理有限的延迟预算意味着要充分利用硬件带来的所有优势。
- en: From Specialized Prototype to General Application
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从专业原型到通用应用
- en: The same basic system has been white-labeled for use in different environments.
    One current proof of concept for another international body is being designed
    to work with in-meeting-room audio feeds using the popular Audinate Dante AV protocols.
    Here audio and video are delivered over Ethernet, using virtual sound cards to
    process the Dante audio stream. This meant rewriting the audio processor to handle
    alternate stream formats.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的基本系统已被白标，用于不同的环境。目前，另一国际机构的一个当前概念验证正在设计中，用于处理会议室内的音频，使用流行的Audinate Dante
    AV协议。在这里，音频和视频通过以太网传输，使用虚拟声卡处理Dante音频流。这意味着重新编写音频处理器以处理备用流格式。
- en: Here a .NET application running on a PC in the AV system takes the feed over
    Ethernet, using a virtual sound card from Audinate to get the audio channel. The
    app converts the sound data into a byte array that can then be delivered to Azure,
    either synchronously or using asynchronous processing techniques, depending on
    the requirements. Output data is delivered to a web portal, where it’s presented
    as either a transcription or a real-time speech-to-speech translation. The real-time
    speech system is designed so that you can define a single output language, so
    that your stream is always in your chosen language. For example, a French speaker
    can choose their native language and have all translations delivered in French.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在AV系统中，这里运行的是一个在PC上运行的.NET应用程序，通过以太网接收音频信号，使用Audinate提供的虚拟声卡获取音频通道。该应用程序将音频数据转换为字节数组，然后可以根据要求同步或异步地传递给Azure。输出数据通过Web门户传递，呈现为转录或实时语音到语音翻译。实时语音系统设计成可以定义单一输出语言，确保流始终是用户选择的语言。例如，法语发言者可以选择母语，所有翻译结果都将以法语呈现。
- en: To translate a stream you first need to identify the language being spoken,
    then run the stream through the appropriate Cognitive Services APIs. With both
    parliamentary and committee meetings, there’s an issue of rapid changes of speakers
    and languages. The system needed to be able to detect a change in language as
    soon as it happens, so that transcriptions are always in the right language. While
    the target is, again, the full 24 languages, initially it’s starting with 10.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要翻译流，首先需要识别正在使用的语言，然后通过适当的认知服务 API 处理流。在议会和委员会会议中，发言人和语言频繁变换是一个问题。系统需要能够在语言变换发生时立即检测到，以确保转录始终使用正确的语言。虽然目标是涵盖全部24种语言，但最初只启用了10种。
- en: Working within Constraints
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在限制条件下工作
- en: There’s a lot to consider when going from a proof of concept like this service,
    which, while it could work at scale, wasn’t fully tuned for full operations. A
    system like this needs to behave differently from a consumer service, as it needs
    to detect and remove vocal tics and pauses. It’s also important to make sure you
    are accounting for regional variations in languages and understand the default
    settings in the underlying services.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当从像这样的服务概念验证转向全面运营时，需要考虑很多因素。虽然该系统在规模上能够工作，但还未完全调整以实现全面运营。这样的系统需要与消费者服务有所不同，因为它需要检测并删除语音习惯和停顿。还要确保考虑到语言的地区变化，并理解底层服务的默认设置是非常重要的。
- en: For example, working in Europe you need to use PT-PT when translating Portuguese,
    not the default PT-BR, as Brazilian Portuguese has diverged from the original
    language. There’s also a need for more targeted vocabularies, models that can
    be switched depending on context. A parliamentary session about economics will
    use a very different terminology from one about fishing policies or one about
    international aid.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在欧洲工作时，翻译葡萄牙语需要使用PT-PT，而不是默认的PT-BR，因为巴西葡萄牙语已经与原始语言分道扬镳。还需要更有针对性的词汇表和可以根据上下文切换的模型。关于经济的议会会议将使用与渔业政策或国际援助有很大不同的术语。
- en: 'There are also constraints that need to be considered: the requirement for
    GPU-enabled VMs will limit the Azure regions where a service like this can be
    run. Working outside a supported region may add additional latency that could
    vary unpredictably, even with a direct network connection into Azure. Similarly,
    it’s important to stick to one hardware SKU for all your systems, as different
    processor generations handle machine learning data differently. For example, the
    high-efficiency BFLOAT instructions are only supported in recent server CPUs.
    Changing CPU to an older version will affect the accuracy of a model.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些需要考虑的约束条件：需要GPU启用的虚拟机将限制可以运行此类服务的Azure区域。在不受支持的区域工作可能会增加额外的延迟，这种延迟可能会因直接连接到Azure的网络连接而不可预测地变化。同样重要的是，在所有系统中坚持使用相同的硬件SKU，因为不同的处理器代数对机器学习数据的处理方式不同。例如，高效的BFLOAT指令仅在最近的服务器CPU中受支持。更换到旧版CPU将影响模型的准确性。
- en: What’s perhaps most interesting about Microsoft’s work in delivering a set of
    tools that can handle multilanguage translation with minimal latency and high
    accuracy is that it uses off-the-shelf APIs and tools. There’s no specialized
    research software running here; even where custom speech models are used, they’re
    built and trained using the same APIs and portal that anyone can use. Even the
    underlying microservice model is a common cloud native design pattern, taking
    advantage of production Azure VM images and hardware.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 或许最令人感兴趣的是微软在交付一套能够以极低延迟和高准确率处理多语言翻译的工具时所采用的方法，它使用现成的API和工具。这里没有专门的研究软件；即使使用自定义的语音模型，也是使用任何人都可以使用的相同API和门户进行构建和训练。即使底层的微服务模型也是一种常见的云原生设计模式，利用生产环境的Azure虚拟机镜像和硬件。
- en: Translation tools like this used to be science fiction but are now standard
    technologies available as APIs using common design patterns. These are tools anyone
    can use; the key to these projects was how Microsoft integrated them with existing
    AV systems. The same approach can be used in other environments.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的翻译工具曾经是科幻，但现在作为API的标准技术已经普及，采用常见的设计模式。这些工具任何人都可以使用；关键在于微软如何将它们与现有的AV系统集成。这种方法同样适用于其他环境。
