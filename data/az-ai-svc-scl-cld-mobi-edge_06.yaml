- en: Chapter 3\. Train, Tune, and Deploy Models with Azure Machine Learning, ONNX,
    and PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 3 章。使用 Azure 机器学习、ONNX 和 PyTorch 训练、调整和部署模型
- en: In the previous chapter, we tried to cover the full range of AI tools and services
    available from Microsoft. Now let’s focus on how you can use the Azure Machine
    Learning cloud service to build and train your own models, using familiar machine
    learning frameworks and a mix of Azure and Visual Studio tooling. We’ll be looking
    at how you can use the popular PyTorch machine learning framework as well as how
    you can export trained models as ONNX for use with local inferencing runtimes,
    like ML.Net.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们试图涵盖来自 Microsoft 的所有 AI 工具和服务的全范围。现在让我们专注于如何使用 Azure 机器学习云服务构建和训练您自己的模型，使用熟悉的机器学习框架和
    Azure 以及 Visual Studio 的混合工具。我们将看看如何使用流行的 PyTorch 机器学习框架，以及如何将训练好的模型导出为 ONNX，以便与本地推断运行时（如
    ML.Net）一起使用。
- en: Understanding Azure Machine Learning
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Azure 机器学习
- en: Microsoft’s approach to machine learning is to target different products to
    different groups of users, with different skill levels and different expectations
    for the technologies they’re using. At one end of the scale is the Power Platform’s
    AI Builder’s task-focused low-code connectors (we’ll look at those in [Chapter 6](ch06.xhtml#machine_learning_for_everyoneem_dashlow)),
    while at the other is Azure Machine Learning. Designed for experienced data scientists,
    it provides a cloud-based development environment where you can design, train,
    run, and manage machine learning models using popular frameworks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的机器学习方法是针对不同的用户群体和他们对技术使用的不同技能水平和不同期望，针对不同产品。在一个极端是 Power Platform 的 AI Builder
    的任务导向的低代码连接器（我们将在 [第 6 章](ch06.xhtml#machine_learning_for_everyoneem_dashlow)
    中看到），另一端是 Azure 机器学习。设计供经验丰富的数据科学家使用，它提供一个基于云的开发环境，您可以在其中使用流行框架设计、训练、运行和管理机器学习模型。
- en: The Azure Machine Learning environment is best thought of as a set of tools
    that all address the same backend model hosting infrastructure but that can be
    mixed and matched to fit with the way you want to work. If you’re new to advanced
    machine learning development, you can work with a drag-and-drop designer to build
    models, much like a low-code development environment. Experienced data scientists
    can use the numerical methods language R to build and test models, working with
    R’s own development tools through an Azure SDK. Meanwhile, Python machine learning
    developers can work with Jupyter Notebooks in Visual Studio Code or any other
    Python development environment.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习环境最好被看作是一组工具，所有这些工具都使用相同的后端模型托管基础架构，但可以混合匹配以适应您想要的工作方式。如果您是新手的高级机器学习开发者，您可以使用拖放设计器构建模型，就像低代码开发环境一样。经验丰富的数据科学家可以使用数值方法语言
    R 来构建和测试模型，通过 Azure SDK 与 R 的开发工具一起工作。同时，Python 机器学习开发者可以在 Visual Studio Code
    或任何其他 Python 开发环境中使用 Jupyter Notebooks。
- en: Under the hood, Azure Machine Learning is a flexible environment that supports
    multiple machine learning frameworks and methodologies. That means support for
    popular open frameworks like PyTorch and TensorFlow, and the ability to export
    trained models in ONNX for use anywhere there’s a compatible runtime. There’s
    even a command line option, using the Azure CLI to manage your models.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，Azure 机器学习是一个灵活的环境，支持多种机器学习框架和方法论。这意味着支持流行的开源框架如 PyTorch 和 TensorFlow，并且能够将训练好的模型导出为
    ONNX，在任何兼容运行时使用。甚至还有一种命令行选项，使用 Azure CLI 管理您的模型。
- en: Tip
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: We introduced ONNX in [Chapter 2](ch02.xhtml#understanding_ai_offerings_and_capabili).
    Open Neural Network Exchange is a standard for representing machine learning models
    in a portable format that simplifies optimizing models for inferencing across
    multiple platforms. Models from common frameworks like TensorFlow, PyTorch, scikit-learn,
    Keras, Chainer, MXNet, MATLAB, and SparkML can be converted to ONNX to take advantage
    of accelerators on different hardware platforms (like TensorRT on NVidia GPUs,
    OpenVINO on Intel processors, or DirectML on Windows) when you want to operationalize
    them, without needing to rewrite the model to optimize it for each one.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [第 2 章](ch02.xhtml#understanding_ai_offerings_and_capabili) 中介绍了 ONNX。开放神经网络交换格式是一种用便携格式表示机器学习模型的标准，简化了在多个平台上优化推断模型的过程。常见框架如
    TensorFlow、PyTorch、scikit-learn、Keras、Chainer、MXNet、MATLAB 和 SparkML 的模型可以转换为
    ONNX，以利用不同硬件平台上的加速器（例如 NVidia GPU 上的 TensorRT、Intel 处理器上的 OpenVINO 或 Windows 上的
    DirectML），在您希望将其运行时化时，无需重写模型以优化每个平台。
- en: It’s a system that’s designed to scale with you, from building and training
    models on local machines, to working with the cloud and with Azure data sources
    and compute. As you learn more and try new techniques, you’re able to take the
    tools you’re using and bring them to Azure, before delivering a machine learning
    model as a managed endpoint or an ONNX export. Once your model is trained, Azure
    Machine Learning makes it ready to run in your applications wherever they are,
    from mobile devices with neural processors to working with terabytes of data of
    all types stored in Azure Data Lakes or with streamed data from Event Grid and
    Azure IoT.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 它是一个设计为随着你的发展而扩展的系统，从在本地机器上构建和训练模型，到使用云和Azure数据源以及计算。随着你的学习和尝试新技术，你可以将你正在使用的工具带到Azure，然后将机器学习模型作为托管端点或ONNX导出交付。一旦你的模型训练完成，Azure
    Machine Learning使其准备在你的应用程序中运行，无论它们在哪里，从具有神经处理器的移动设备到与Azure Data Lakes中存储的各种类型的数据或来自Event
    Grid和Azure IoT的流数据一起工作。
- en: Understanding Azure Machine Learning Studio
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Azure Machine Learning Studio
- en: Azure Machine Learning studio is a web portal-based model development and training
    tool designed for data scientists. As it’s intended for different levels of experience
    and programming skill, it mixes traditional programming tools with no-code tools.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning Studio是一个基于Web的模型开发和训练工具，专为数据科学家设计。它旨在适应不同的经验水平和编程技能，混合了传统的编程工具与无代码工具。
- en: You shouldn’t confuse it with the now deprecated ML Studio visual tooling. You
    still get the same visual design experience, but there’s now full integration
    with the Azure Machine Learning SDKs, as well as more powerful model design and
    development tools. If anything, Azure Machine Learning is a significant upgrade,
    and any projects that still rely on ML Studio should be migrated to Azure Machine
    Learning. Models developed in the studio can be modified by developers using the
    SDK, while the studio tools can help tune models that have been developed using
    Python or R.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 不要将其与现已弃用的ML Studio可视化工具混淆。你仍然可以获得相同的视觉设计体验，但现在与Azure Machine Learning SDK完全集成，以及更强大的模型设计和开发工具。如果有的话，Azure
    Machine Learning是一个重要的升级，任何仍依赖于ML Studio的项目都应该迁移到Azure Machine Learning。在Studio中开发的模型可以通过SDK进行修改，而Studio工具可以帮助调整使用Python或R开发的模型。
- en: Microsoft recommends using the latest web browser releases to work with the
    Azure Machine Learning studio. Much of the studio editing experience relies on
    modern web technologies, building on the same Monaco code editing tools that are
    used by Visual Studio Code.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 微软建议使用最新的Web浏览器版本与Azure Machine Learning Studio一起工作。Studio的大部分编辑体验依赖于现代Web技术，构建在与Visual
    Studio Code相同的Monaco代码编辑工具基础上。
- en: Developers of all types are catered for by Azure Machine Learning studio. Experienced
    Python data science developers can work in Jupyter Notebooks, using a live code
    development environment with real-time code evaluation and debugging, so you can
    see the effects of your code as you write it. Alternatively, you can start with
    existing models and datasets in the Azure Machine Learning designer, which gives
    you a drag-and-drop surface where you can build a machine learning pipeline from
    your datasets and Azure Machine Learning modules.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning Studio适合所有类型的开发人员。有经验的Python数据科学开发人员可以在Jupyter Notebooks中工作，使用实时代码开发环境进行代码评估和调试，因此你可以在编写代码时看到代码的效果。或者，你可以从Azure
    Machine Learning设计师中开始使用现有的模型和数据集，它提供了一个拖放界面，你可以从数据集和Azure Machine Learning模块构建一个机器学习管道。
- en: An alternate approach offers automated machine learning, where Azure Machine
    Learning fits and tunes a model to your data. You can use this in conjunction
    with the Azure Machine Learning data labeling service, which helps you prepare
    data for use in a machine learning model, adding appropriate labels to improve
    training. This set of options is very important for opening up machine learning
    to a wider audience. There’s no need to have any data science experience, as you
    are guided through the process of uploading data and then selecting the best model
    for your data, finally testing it on more of your data to ensure that the resulting
    model is ready for use.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是提供自动化机器学习，其中Azure Machine Learning可以将模型拟合和调整到你的数据。你可以结合Azure Machine Learning数据标注服务使用它，这将帮助你准备数据以用于机器学习模型，添加适当的标签以提高训练效果。这组选项对于将机器学习开放给更广泛的受众非常重要。无需任何数据科学经验，因为你将被引导通过上传数据的过程，然后选择最适合你数据的模型，最后在更多数据上测试以确保生成的模型可以使用。
- en: You can treat Azure Machine Learning studio as a one-stop shop for machine learning.
    It’s where you can build and manage models, work with datasets, and add new data
    sources and storage. Other tools manage the compute resources used to build, test,
    and run models. Data science specialists get access to notebooks to build, run,
    and share experiments, with logs to help analyze results. At the same time, you
    can construct pipelines that bring data processing and machine learning together,
    ensuring that you have the best model for your problem.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将Azure机器学习工作室视为机器学习的一站式平台。你可以在这里构建和管理模型，处理数据集，并添加新的数据源和存储。其他工具用于管理用于构建、测试和运行模型的计算资源。数据科学专家可以访问笔记本来构建、运行和分享实验，并通过日志帮助分析结果。同时，你可以构建流水线，将数据处理和机器学习结合在一起，确保你有最佳的模型解决你的问题。
- en: Getting Started with Azure Machine Learning
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用Azure机器学习
- en: Azure Machine Learning offers a mix of visual and code-based development tooling.
    In this section, we will look at how to configure and use its machine learning
    environments.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Azure机器学习提供了一套视觉和基于代码的开发工具。在本节中，我们将看看如何配置和使用它的机器学习环境。
- en: Setting Up a Machine Learning Environment
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置机器学习环境
- en: The Azure Machine Learning service is part of the Azure portal and managed like
    any other Azure resource. From the home screen, choose to add a new resource to
    your tenant, and pick “Machine learning.” You’ll recognize it by its icon, a mashup
    of the Azure logo with a glass experimental flask to signify its data science
    roots.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Azure机器学习服务是Azure门户的一部分，像任何其他Azure资源一样进行管理。从主屏幕选择添加新资源到你的租户，然后选择“机器学习”。你可以通过它的图标识别它，它是Azure标志与玻璃试验烧瓶混合的图标，表示它的数据科学起源。
- en: If you’ve not created any machine learning workspaces, click the Create button
    to start setting up your first workspace. This is where you work with data to
    build and test machine learning models. The process requires setting up additional
    Azure services to support your machine learning development and to host and share
    your trained models. Start by assigning your workspace to a subscription and a
    resource group. If you’re just investigating the service, use a free trial account
    or credits from a Visual Studio or an Azure student account.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有创建任何机器学习工作区，请点击“创建”按钮开始设置你的第一个工作区。这是你处理数据、构建和测试机器学习模型的地方。这个过程需要设置额外的Azure服务来支持你的机器学习开发，并且托管和分享你训练好的模型。首先，将你的工作区分配给一个订阅和一个资源组。如果你只是在探索这项服务，可以使用免费试用账户或来自Visual
    Studio或Azure学生账户的信用点。
- en: From the portal, set a name for your workspace and assign it to an Azure region.
    This will automatically create a new storage account, along with a key vault for
    credentials, and an application insights instance for debugging. There’s also
    the option of choosing a container registry if you’re planning on exporting models
    as containers for use outside of Azure.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从门户设置你的工作区名称，并将其分配给Azure区域。这将自动创建一个新的存储账户，以及一个用于凭据的密钥保管库和一个用于调试的应用洞察实例。此外，还可以选择一个容器注册表，如果计划将模型导出为用于Azure外部的容器。
- en: Once you’ve completed the first page of settings, you’re given the option of
    setting public or private endpoint details. A private endpoint is much more secure,
    but it does require configuring an Azure virtual network and a link to a private
    DNS; you’ll need to work with your network team on this (and you may want to discuss
    the best practices for security and data access in [Chapter 8](ch08.xhtml#best_practices_for_machine_learning_pro)
    with them). While you’re just experimenting with the service, a public endpoint
    should be sufficient.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 完成第一页设置后，你可以选择设置公共或私有端点详细信息。私有端点更安全，但需要配置Azure虚拟网络和私有DNS的链接；你需要与你的网络团队合作（你可能还想和他们讨论[第8章](ch08.xhtml#best_practices_for_machine_learning_pro)中的安全和数据访问的最佳实践）。当你只是试验这项服务时，公共端点应该足够了。
- en: The service’s advanced settings give you the tools to manage account access,
    data encryption, and whether or not you’re working with sensitive data. This last
    point is particularly important; as if your data contains personally identifiable
    information or commercially sensitive data you can choose to use a high business
    impact workspace. This reduces the diagnostic information sent to Microsoft as
    well as applying a higher standard of encryption.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 服务的高级设置为您提供了管理帐户访问、数据加密以及是否处理敏感数据的工具。最后一点尤为重要；如果您的数据包含个人身份信息或商业敏感数据，您可以选择使用高业务影响力工作区。这样可以减少发送给
    Microsoft 的诊断信息，并应用更高标准的加密。
- en: Finally, you can apply tags to your workspace to help track its costs in your
    organization’s billing statement. This is particularly important if you’re sharing
    costs across business groups and where you may have multiple machine learning
    workspaces at any one time. You can then review your settings before creating
    your workspace. Usefully, Azure gives you the option of downloading an ARM template
    of your settings, so you can automate future deployments.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以为您的工作区应用标签，以帮助跟踪其在您组织的账单报表中的成本。如果您跨业务组共享成本并且同时拥有多个机器学习工作区，这点尤为重要。在创建工作区之前，您可以审查您的设置。有用的是，Azure
    提供了下载您设置的 ARM 模板的选项，因此您可以自动化未来的部署。
- en: Click Create to build a workspace. This may take some time to deploy.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 单击创建以构建工作区。这可能需要一些时间来部署。
- en: Once your workspace is deployed, you can launch Machine Learning studio to start
    work with your models. You’ll find a URL for your studio workspace in the portal
    overview; bookmark this for quick access to the service in the future. It’s also
    worth saving your workspace’s properties, as these can be used by external tools
    to access Machine Learning services directly.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦部署了您的工作区，您可以启动机器学习工作室开始使用您的模型。您可以在门户概述中找到工作室工作区的 URL，请将其书签以便将来快速访问服务。值得注意的是，保存工作区的属性也很重要，因为外部工具可以使用这些属性直接访问机器学习服务。
- en: You may need to log in to the Machine Learning studio portal again using your
    Azure account; this runs as a specialized environment. Once logged in, you’ll
    be presented with a welcome screen where you can choose different options to get
    started with building and training a model. The three most popular options get
    their own launch buttons, one for using Python and the machine learning SDK in
    a Notebook, one for using automated machine learning, and one for the machine
    learning.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能需要使用您的 Azure 帐户再次登录到机器学习工作室门户；这是一个专门的环境。登录后，您将看到一个欢迎屏幕，在这里您可以选择不同的选项开始构建和训练模型。最受欢迎的三个选项有各自的启动按钮，一个用于在
    Notebook 中使用 Python 和机器学习 SDK，一个用于使用自动化机器学习，另一个用于机器学习。
- en: The Machine Learning studio portal has three roles, detailed in the left-hand
    menu pane. These are Author, Assets, and Manage. Author gives access to the three
    key development environments, while Assets allows you to manage the features used
    to build and deliver machine learning services, from your datasets through experiments
    and pipelines, to your models and the endpoints used to access them. Finally,
    the Manage section helps you control Azure resources used by the studio, choosing
    the right compute and storage services.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习工作室门户在左侧菜单窗格中详细说明了三种角色：作者、资产和管理。作者角色提供了访问三个关键开发环境的权限，而资产允许您管理用于构建和交付机器学习服务的功能，从数据集、实验和管道到您的模型和用于访问它们的端点。最后，管理部分帮助您控制工作室使用的
    Azure 资源，选择合适的计算和存储服务。
- en: There are other ways to set up an Azure Machine Learning environment. One option
    is to use the Azure Machine Learning Python SDK to set one up from your Python
    development environment, while another is to use the Azure CLI. Details of how
    to do this are in the platform documentation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他设置 Azure 机器学习环境的方式。一种选择是使用 Azure 机器学习 Python SDK 从您的 Python 开发环境设置一个，另一种是使用
    Azure CLI。如何操作可以在平台文档中找到详细说明。
- en: You can now start to build your Azure-hosted machine learning models.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以开始构建托管在 Azure 上的机器学习模型。
- en: Integration with Azure Services
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与 Azure 服务集成
- en: An Azure Machine Learning workspace is a set of Azure resources, all bundled
    together using a common UI. Under the hood there’s a set of VMs for handling compute,
    a storage account for your data, and integrations with Application Insights, Key
    Vault, and the Container Registry.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习工作区是一组 Azure 资源，使用统一的用户界面捆绑在一起。在幕后，有一组处理计算的 VM、用于数据的存储帐户，以及与 Application
    Insights、Key Vault 和 Container Registry 的集成。
- en: There’s also support for Azure Active Directory (Azure AD), giving you role-based
    access control (RBAC). This can help manage user access to the service, controlling
    who gets to do what. For example, you can ensure that only data science team members
    get access to the storage accounts used to manage data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Active Directory（Azure AD）支持角色基础访问控制（RBAC），有助于管理用户对服务的访问，控制谁可以做什么。例如，您可以确保只有数据科学团队成员可以访问用于管理数据的存储帐户。
- en: 'It’s worth using the guided experience tool to set up your first training environment,
    so you can see what resources you need to configure and how they need to be configured.
    Start by creating a compute environment. There are three options: an Azure Machine
    Learning compute cluster, an Azure Machine Learning compute instance, and using
    Kubernetes via Azure Arc. The Kubernetes option is an interesting one, as it allows
    you to set up your own machine learning cluster on your own hardware in your own
    data center.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 值得使用引导式体验工具来设置您的第一个训练环境，这样您可以查看需要配置的资源及其配置方式。首先创建一个计算环境。有三个选项：Azure 机器学习计算群集、Azure
    机器学习计算实例以及通过 Azure Arc 使用 Kubernetes。Kubernetes 选项非常有趣，因为它允许您在自己的硬件和数据中心上设置自己的机器学习群集。
- en: If you’re using Azure-hosted compute, pick the VM types you want to use as a
    host. You will be charged per VM instance per hour.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用 Azure 托管的计算资源，请选择您希望用作主机的 VM 类型。每个 VM 实例每小时收取费用。
- en: 'Compute VMs are available as general purpose, compute optimized, or memory
    optimized:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 计算 VM 可用作通用用途、计算优化或内存优化：
- en: Memory optimized VMs are best for training on large datasets, while compute
    optimized are best where latency is an issue.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存优化的 VM 最适合大型数据集的训练，而计算优化的 VM 则适合延迟较为敏感的场景。
- en: You can save money by choosing a low-priority VM, which may be preempted by
    other tasks. However, it’s a trade-off that’s worth making for experimentation.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以通过选择低优先级 VM 来节省费用，但这可能会被其他任务中断。然而，这是值得尝试的权衡。
- en: Other options allow you to choose to use a GPU VM, with your code automatically
    optimized for use on GPUs.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他选项允许您选择使用 GPU VM，代码会自动优化以在 GPU 上运行。
- en: Select the option you want to use, and then choose a name and the number of
    nodes you intend to use, both minimum and maximum. You can also enable Secure
    Shell (SSH) access and connect your VM to a virtual network.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 选择您想要使用的选项，然后选择名称和您打算使用的节点数量，包括最小和最大值。您还可以启用安全外壳（SSH）访问，并将您的 VM 连接到虚拟网络。
- en: Wait for your compute instance to be created before continuing to set up your
    development environment. Once it’s been created, you can select it and set up
    your machine learning platform. Azure Machine Learning studio provides four different
    models as Ubuntu-based VM images. You can choose between scikit-learn (with two
    options, one of which adds LightGBM and XGBoost support, which both can help speed
    up training), PyTorch, and TensorFlow. All four images are preconfigured with
    the Azure Machine Learning SDK and have the appropriate Python packages installed.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续设置开发环境之前，请等待计算实例的创建。一旦创建完成，您可以选择它并设置您的机器学习平台。Azure 机器学习工作室提供四种不同的模型作为基于 Ubuntu
    的 VM 映像。您可以选择使用 scikit-learn（有两个选项，其中一个添加了对 LightGBM 和 XGBoost 的支持，这两者都有助于加速训练）、PyTorch
    或 TensorFlow。所有四个映像都预先配置了 Azure 机器学习 SDK，并安装了适当的 Python 包。
- en: You can now configure your training job, setting up experiments and uploading
    your own code. Code will need a shell command to run from the upload directory,
    so be sure to add appropriate parameters and any necessary environment variables.
    Code can also be run from your workspace’s Blob storage. At the same time, you’ll
    need to configure your dataset, giving it a name and ensuring it’s ready for use.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以配置您的训练作业，设置实验并上传您自己的代码。代码将需要从上传目录运行的 shell 命令，因此请确保添加适当的参数和任何必要的环境变量。代码也可以从工作区的
    Blob 存储中运行。同时，您需要配置您的数据集，为其命名并确保它可以立即使用。
- en: With everything in place, you’re ready to run your first machine learning experiment
    using your Azure resources.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一切就绪后，您可以使用 Azure 资源运行您的第一个机器学习实验。
- en: Using Visual Studio Code
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Visual Studio Code
- en: You don’t need to be logged into the Azure portal to use Azure Machine Learning.
    Microsoft provides a [set of extensions for its Visual Studio Code editor](https://go.microsoft.com/fwlink/?linkid=2190261)
    that add support to its suite of Azure tools.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要登录 Azure 门户即可使用 Azure 机器学习。微软为其 [Visual Studio Code 编辑器提供了一组扩展](https://go.microsoft.com/fwlink/?linkid=2190261)，用于支持其套件中的
    Azure 工具。
- en: Once installed from the Visual Studio Marketplace, the extension adds Machine
    Learning controls to its Azure control pane, alongside the other Azure extensions.
    Having all the Azure features in one place simplifies finding what you need, especially
    as you’ll often be using different Azure features in the same applications. The
    extension simplifies working with Python-based machine learning products, and
    it’s well worth installing the Visual Studio Code’s Python language support in
    advance for IntelliSense code completion, language server-based syntax highlighting,
    and linting, as well as built-in Jupyter Notebooks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦从 Visual Studio Marketplace 安装，此扩展将在其 Azure 控制面板中添加机器学习控件，与其他 Azure 扩展并列。将所有
    Azure 功能集中在一个地方有助于简化找到你需要的内容，尤其是在同一应用程序中经常使用不同的 Azure 功能。此扩展简化了与基于 Python 的机器学习产品的工作，提前安装
    Visual Studio Code 的 Python 语言支持对于智能感知代码完成、基于语言服务器的语法突出显示和代码检查以及内置的 Jupyter 笔记本是非常值得的。
- en: Next, sign into the extension with your Azure account to get access to your
    Azure Machine Learning resources. You can set a default workspace that gives you
    access to diagnostics and autocompletion, using the Azure Machine Learning commands
    that are added to the Visual Studio Code command palette by the extension. You
    can quickly create new resources as well as manage resources created through the
    portal, using Code to edit JavaScript Object Notation (JSON) schema. Once set
    up, resources can be started and stopped as needed.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用你的 Azure 帐户登录扩展以访问 Azure 机器学习资源。你可以设置一个默认工作区，从而可以访问诊断和自动完成，使用扩展添加到 Visual
    Studio Code 命令面板的 Azure 机器学习命令。你可以快速创建新资源，并管理通过门户创建的资源，使用 Code 来编辑 JavaScript
    Object Notation (JSON) 架构。一旦设置好，可以根据需要启动和停止资源。
- en: Tip
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: It’s worth ensuring you have Code’s YAML and JSON tooling installed to help
    with managing Azure Machine Learning configurations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 值得确保你已安装了 Code 的 YAML 和 JSON 工具，以帮助管理 Azure 机器学习配置。
- en: Working with Azure Machine Learning resources inside your development environment
    simplifies and streamlines the process. You don’t need to switch context; the
    same command palette you use for working with Python or with JavaScript APIs controls
    your Azure Machine Learning environment.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发环境中使用 Azure 机器学习资源简化和优化了流程。你无需切换上下文；你用于处理 Python 或 JavaScript API 的相同命令面板也控制着你的
    Azure 机器学习环境。
- en: The same YAML editing environment is used to create training jobs, uploading
    local Python files to your choice of CPU or GPU compute clusters. Again, you’ll
    need to choose an appropriate environment from [Microsoft’s library of curated
    images](https://go.microsoft.com/fwlink/?linkid=2190139).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 同一 YAML 编辑环境用于创建训练作业，将本地 Python 文件上传到你选择的 CPU 或 GPU 计算集群。同样，你需要从 [Microsoft
    的精选镜像库](https://go.microsoft.com/fwlink/?linkid=2190139) 中选择一个合适的环境。
- en: The Azure Machine Learning Python SDK for Local Development
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure 机器学习 Python SDK 用于本地开发
- en: While Azure Machine Learning studio provides an environment for building and
    training models, experienced AI developers and data scientists may prefer to use
    familiar development environments and tools, bringing their own algorithms and
    numerical methods to Azure. One way to do this is using the Azure Machine Learning
    SDK for Python, along with your choice of Python development environments.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Azure 机器学习工作室提供了一个构建和训练模型的环境，但经验丰富的 AI 开发人员和数据科学家可能更喜欢使用熟悉的开发环境和工具，将他们自己的算法和数值方法带入
    Azure。其中一种方法是使用 Azure 机器学习 SDK for Python，以及你选择的 Python 开发环境。
- en: This allows you to install the SDK into a tool like Visual Studio Code and build
    and test your models from the Python command line or use Jupyter Notebooks on
    your own system to build, test, and share models using the notebook as an interactive
    test bed for code. Once installed, the SDK adds tools for working with the development
    lifecycle of models and datasets, as well as managing Azure cloud resources. You
    can then train models either in the cloud or on your own system, a useful option
    if you’ve got a significant amount of GPU processing capability.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这使您可以将SDK安装到诸如Visual Studio Code之类的工具中，并且可以在Python命令行上构建和测试您的模型，或者在自己的系统上使用Jupyter
    Notebooks构建、测试和共享模型，使用笔记本作为交互式代码的测试平台。一旦安装完成，SDK将添加用于处理模型和数据集的开发生命周期工具，以及管理Azure云资源的工具。然后，您可以在云中或在您自己的系统上训练模型，如果您拥有大量的GPU处理能力，则这是一个有用的选项。
- en: While most users will prefer to use the SDK to train their models interactively,
    there’s an option to use automated machine learning to tune models to find the
    best fit for your dataset. If you’re a data scientist, you may well find this
    a useful way of delivering machine learning models from your data. Finally, the
    SDK provides tools to go from a model to an Azure-hosted REST API that can be
    called from any code.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大多数用户更喜欢使用SDK交互式地训练他们的模型，但也有使用自动化机器学习调整模型以找到最佳数据集拟合度的选项。如果您是数据科学家，您可能会发现这是从数据交付机器学习模型的有用方式。最后，SDK提供了从模型到托管在Azure的REST
    API的工具，可以从任何代码中调用。
- en: The SDK provides a mix of stable production-ready features alongside experimental
    code. In practice you’re likely to use the stable features, leaving the experiments
    for future exploration as they get closer to release, especially as they may well
    have bugs.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: SDK提供了一系列稳定的生产就绪功能以及实验性代码。在实践中，您可能会使用稳定的功能，将实验留给未来的探索，因为它们接近发布时可能会有错误。
- en: Much of the Azure Machine Learning platform is accessible through a series of
    classes in the SDK. These include foundational classes like Workspace, which creates
    workspace objects using your Azure subscription details. If you’re planning on
    working with multiple models, save your configuration details as a JSON file,
    which can be called each time you create a new workspace.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Azure机器学习平台的许多功能通过SDK中的一系列类访问。这些包括像Workspace这样的基础类，使用您的Azure订阅详细信息创建工作空间对象。如果您计划使用多个模型进行工作，请将配置详细信息保存为一个JSON文件，每次创建新的工作空间时都可以调用它。
- en: Once you have a workspace, you’ll need to create an Experiment to host your
    model runs and results. Runs are another class in their own right, creating a
    Run object that monitors a trial, with function calls to retrieve its results.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了工作空间，您需要创建一个实验来承载您的模型运行和结果。运行是另一个独立的类，创建一个监视试验的运行对象，通过函数调用来检索其结果。
- en: 'Install the SDK using pip:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pip安装SDK：
- en: '[PRE0]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once it’s installed, use an import statement to bring azureml.core into your
    runtime environment. This then allows you to create a workspace from code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装完成，使用导入语句将azureml.core引入您的运行环境。然后，您可以从代码中创建一个工作空间：
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you’re using the same account details for multiple scripts, save the configuration
    as a JSON file and load it for every script.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在多个脚本中使用相同的帐户详细信息，请将配置保存为JSON文件，并在每个脚本中加载它。
- en: 'The following code snippet loads a configuration for a workspace, then opens
    an experiment, before running the experiment:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段加载了一个工作空间的配置，然后打开一个实验，并运行该实验：
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Use the URL to monitor the progress of a run.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用URL来监视运行的进度。
- en: There are additional packages that aren’t installed by default, as they’re required
    only for specific functions, for example, working with automated training or using
    FPGA-based deep neural networks with Azure Machine Learning Hardware Accelerated
    Models. You’ll need a 64-bit Python environment to use automated machine learning
    training, as it requires the LightGBM framework. There is a thin client option,
    intended for use with remote automated machine learning—for example, using the
    tools built into Azure Machine Learning studio.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些默认未安装的附加包，因为它们仅在特定功能中需要，例如使用自动训练或使用基于FPGA的Azure机器学习硬件加速模型进行深度神经网络。您需要一个64位Python环境来使用自动化机器学习训练，因为它需要LightGBM框架。还有一个薄客户端选项，用于与远程自动化机器学习配合使用，例如使用内置到Azure机器学习工作室中的工具。
- en: It’s important to keep the SDK up to date, so you’re in sync with the current
    set of Azure Machine Learning features. This is especially important if you’re
    using its notebooks, which have dependencies on the service.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 保持SDK的最新更新非常重要，这样您就可以与当前的Azure机器学习功能集保持同步。如果使用其笔记本电脑，这一点尤为重要，因为笔记本电脑依赖于该服务。
- en: A good approach to using the Python SDK is to first create a model in Python
    using your choice of numeric methods and machine learning frameworks, with PyTorch
    the most common option. You’ll need a model script and a training script. The
    training script downloads and sets up your training set and configures PyTorch
    for you.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python SDK的一个好方法是首先使用您选择的数值方法和机器学习框架在Python中创建一个模型，其中PyTorch是最常见的选择。您需要一个模型脚本和一个训练脚本。训练脚本下载并设置您的训练集，并为您配置PyTorch。
- en: Once you have these in place, create a control script that uses the SDK to build,
    configure, and run your model as part of an experiment in a fresh workspace. You
    will be able to monitor your experiment from Azure Machine Learning studio.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您完成这些步骤，创建一个控制脚本，使用SDK构建、配置和运行您的模型，作为新工作区实验的一部分。您将能够从Azure机器学习工作室监视您的实验。
- en: Azure Machine Learning and R
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure机器学习和R
- en: 'While Python is the popular choice for data science and machine learning, R
    remains popular, especially when building statistical models and analyzing big
    data. Microsoft offers R support across Azure as one of its main data science
    tools, with specialized VMs and support across its main big data platforms: Azure
    HDInsight and Azure Databricks, as well as inside Azure SQL Managed Instance,
    where you can embed R code inside your database.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Python是数据科学和机器学习的热门选择，但R仍然很受欢迎，特别是在构建统计模型和分析大数据时。微软在Azure上提供了R支持作为其主要数据科学工具之一，具有专门的虚拟机和支持其主要的大数据平台：Azure
    HDInsight和Azure Databricks，以及在Azure SQL托管实例内部，您可以在数据库中嵌入R代码。
- en: R used to be a key element in the deprecated Classic Azure Machine Learning
    Studio, where R-based models could be used as part of your machine learning pipeline.
    That’s changed with the launch of the newer Azure Machine Learning platform and
    its own drag-and-drop machine learning tools. However, R support is not completely
    gone, as it’s supported in the currently in preview Azure CLI 2.0, which replaces
    the Azure Machine Learning SDK for R.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: R曾经是已弃用的Classic Azure机器学习工作室的关键元素，其中R基础模型可以作为您的机器学习流水线的一部分使用。随着新版Azure机器学习平台的推出及其自己的拖放式机器学习工具，情况发生了变化。但是，R支持并没有完全消失，因为它在目前预览版的Azure
    CLI 2.0中得到了支持，该版本替代了用于R的Azure机器学习SDK。
- en: The Azure CLI’s R support gives you a complete R-based training and deployment
    environment for your machine learning models. You will be able to call R code
    from the command line, working with datasets and standard R functionality.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Azure CLI的R支持为您提供了完整的基于R的机器学习模型训练和部署环境。您将能够从命令行调用R代码，处理数据集和标准的R功能。
- en: As R is designed for statistical operations, the code needed to build and train
    a model can be very compact. Start by using the Azure CLI to create an appropriate
    compute cluster for your model. You can then define a job in YAML that loads an
    R container and runs your training code.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 由于R专为统计操作设计，用于构建和训练模型的代码可以非常紧凑。首先使用Azure CLI创建适当的计算集群以供您的模型使用。然后，您可以在YAML中定义一个作业，加载一个R容器并运行您的训练代码。
- en: 'The following YAML loads an R Dockerfile and runs a generalized linear model
    on a set of car accident data:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下YAML加载了一个R Dockerfile，并在一组车祸数据上运行广义线性模型：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It’s very similar to working with Python, swapping it out for R and using an
    appropriate Dockerfile for your job. This loads the R packages needed to work
    with Azure.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 它与使用Python非常相似，可以将其替换为R，并为您的作业使用适当的Dockerfile。这将加载与在Azure上工作所需的R包。
- en: 'The R code to train the model looks like this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型的R代码如下所示：
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can find the sample code and data [for training R models in Azure Machine
    Learning](https://go.microsoft.com/fwlink/?linkid=2190143).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[用于在Azure机器学习中训练R模型的示例代码和数据](https://go.microsoft.com/fwlink/?linkid=2190143)中找到示例代码和数据。
- en: Build Your First Model Using Azure Machine Learning Studio
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Azure机器学习工作室构建您的第一个模型
- en: The studio is at the heart of the Azure Machine Learning platform. As well as
    hosting your own scripts and experiments, providing a management and training
    environment, it includes tooling to simplify and accelerate machine learning,
    using both automation and visual development environments.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 工作室是Azure机器学习平台的核心。除了托管您自己的脚本和实验、提供管理和训练环境外，它还包括简化和加速机器学习的工具，使用自动化和可视化开发环境。
- en: Use Automated Machine Learning
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用自动化机器学习
- en: Azure Machine Learning offers a useful set of low- and no-code machine learning
    development tools. Once you’ve created a machine learning workspace and assigned
    compute resources, you can use its automated machine learning tools to create
    and train a model without writing a line of code.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Azure机器学习提供了一套有用的低代码和无代码机器学习开发工具。一旦您创建了一个机器学习工作空间并分配了计算资源，您可以使用其自动化机器学习工具创建和训练模型，而无需编写一行代码。
- en: Start by creating a new dataset. Microsoft provides sample data in comma-separated
    values (CSV) format you can use to try the service out; you can either [download
    the data to your PC](https://aka.ms/bike-rentals) or make a web files connection
    to the data from inside your studio workspace. Use the data to make a dataset,
    ready for consumption in Azure Machine Learning.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 首先创建一个新数据集。微软提供以逗号分隔值（CSV）格式的示例数据，您可以使用它来尝试该服务；您可以将数据下载到您的PC上，也可以从工作室工作空间内部连接到数据。使用数据创建数据集，以便在Azure机器学习中使用。
- en: 'On the AutoML page, create a new run using your dataset. You will need to configure
    your training run, setting an experiment name and choosing the target column in
    your dataset. This will be the output data for the model and will be used to train
    the model, using your compute resources. Next, choose a task type from a list
    of basic machine learning model types: classification, regression, and time series.
    For most numeric models you’ll want to choose regression.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在AutoML页面上，使用您的数据集创建一个新运行。您需要配置您的训练运行，设置实验名称并选择数据集中的目标列。这将是模型的输出数据，并将用于训练模型，使用您的计算资源。接下来，从基本机器学习模型类型的列表中选择任务类型：分类、回归和时间序列。对于大多数数值模型，您将希望选择回归。
- en: You can fine-tune the task configuration, choosing the algorithms used, whether
    the model will be explained or not, and defining when and how a training run will
    end. You will want to block out most of the available algorithms, as exploring
    them all can take a large amount of time—and could add significant costs depending
    on the size of your compute cluster.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以微调任务配置，选择使用的算法，是否解释模型以及定义训练运行的结束时间和方式。你会想要阻止大部分可用算法的探索，因为探索所有算法可能需要大量时间，并且可能根据计算集群的规模增加显著的成本。
- en: The service will run automatically once you submit your task. You can watch
    the models being generated in the Models tab of your workspace. Once a run has
    completed, depending on your exit criteria, you’ll be presented with the best
    model and tools to help you determine if it will meet your requirements, showing
    the error rate, and a set of graphs that show whether predicted and actual values
    match.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提交任务，服务将自动运行。您可以在工作区的“模型”选项卡中观看生成的模型。一旦运行完成，根据您的退出标准，您将会展示最佳模型及工具，帮助您确定它是否符合您的要求，显示错误率以及显示预测值和实际值是否匹配的一组图表。
- en: It’s worth running through a series of different trials, using different algorithms.
    This will allow you to find the most appropriate one for your model, comparing
    different runs in the studio dashboard. As each training run uses the same dataset,
    you have an effective baseline to compare different algorithms and sets of parameters.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 值得进行一系列不同的试验，使用不同的算法。这将使您能够找到最适合您模型的算法，比较工作室仪表板中的不同运行。由于每个训练运行使用相同的数据集，您有一个有效的基准来比较不同的算法和参数集。
- en: Once a model is trained and ready for use, a few clicks deploy it as an inferencing
    service in Azure as a container or running in a Kubernetes cluster. Studio will
    generate appropriate endpoints for your model, with a REST API and a set of authentication
    keys. You can now test the resulting machine learning model in a studio notebook
    using Python.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成并准备好使用，只需点击几下，即可将其部署为Azure中的推理服务，作为容器运行或在Kubernetes集群中运行。工作室将为您的模型生成适当的端点，带有REST
    API和一组认证密钥。您现在可以使用Python在工作室笔记本中测试生成的机器学习模型。
- en: Using Designer
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用设计师
- en: As an alternative to writing code, you can use the no-code Azure Machine Learning
    designer. This gives you a drag-and-drop surface for connecting the various elements
    needed to process your data and then train it against various common models. The
    resulting pipelines bring all the necessary steps together, running them in your
    Azure Machine Learning workspace.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 作为编写代码的替代方案，您可以使用无代码的 Azure 机器学习设计师。这为您提供了一个拖放界面，用于连接处理数据和训练各种常见模型所需的各种元素。生成的流水线将所有必要的步骤整合在一起，在
    Azure 机器学习工作区中运行它们。
- en: Inside studio, choose the Designer option to open the designer and create a
    new pipeline. The tool automatically creates and names a pipeline, ready for you
    to add modules, as shown in [Figure 3-1](#azure_machine_learningapostrophes_desig).
    You can rename it from the default date-based name if you prefer.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作室内，选择“设计师”选项以打开设计师并创建新的流水线。工具会自动创建和命名一条流水线，准备让您添加模块，如 [图 3-1](#azure_machine_learningapostrophes_desig)
    所示。如果您愿意，可以将其从默认的基于日期的名称重新命名。
- en: Next, choose a compute resource for your model training. You can choose an existing
    target or create a new one. There’s an option to use the same target for all your
    pipeline modules, or you can choose custom targets for each one. It’s probably
    best to stick with one target, unless you have the budget to support multiple
    compute or GPU instances. Resources do scale down to zero when not running, but
    this will add time to runs when they start up.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，选择计算资源进行模型训练。您可以选择现有的目标或创建一个新的目标。有一个选项可以为所有流水线模块使用相同的目标，或者您可以为每个模块选择自定义目标。除非您有预算支持多个计算或
    GPU 实例，否则最好坚持选择一个目标。资源在停止运行时会缩减到零，但这会增加它们启动时的时间。
- en: The designer drag-and-drop canvas is similar to that used by tools like Azure
    Logic Apps. On the left of the screen is a set of modules that can be added to
    your canvas. Start by dragging on a data source, either one of your own or from
    a selection of sample datasets. Once these are selected, you can start to process
    data, using built-in data transformations to select columns for use in a model.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 设计师的拖放画布类似于 Azure Logic Apps 等工具使用的画布。屏幕左侧是可以添加到画布中的一组模块。首先拖放数据源，可以是您自己的数据源或一组示例数据集中的一个。选择这些后，您可以开始处理数据，使用内置数据转换来选择用于模型的列。
- en: Connect the elements by connecting the output port of one module to the input
    of the next. This process builds your pipeline. Data processing modules include
    tools to clean up data, running cleaning algorithms and splitting out data into
    separate training and testing sets. You can choose the fraction of data used for
    each set.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通过连接一个模块的输出端口到下一个模块的输入端口来连接这些元素。此过程构建了您的流水线。数据处理模块包括用于清理数据的工具，运行清理算法并将数据拆分为单独的训练和测试集。您可以选择每个集合使用的数据分数。
- en: '![Azure Machine Learning’s designer builds pipelines with drag-and-drop tooling](Images/aasc_0301.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![Azure 机器学习的设计师使用拖放工具构建流水线](Images/aasc_0301.png)'
- en: Figure 3-1\. Azure Machine Learning’s designer builds pipelines with drag-and-drop
    tooling
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. Azure 机器学习的设计师使用拖放工具构建流水线
- en: Next, drag on your choice of model. You get a choice of model types; choose
    the one that’s appropriate for the type of prediction you want to make. Connect
    your model to a Train Model module, along with a link to your training set. This
    feeds into a Score module, which uses the test dataset to evaluate the resulting
    machine learning model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，拖放您选择的模型。您可以选择不同类型的模型；选择适合您要进行的预测类型的模型。将您的模型连接到“训练模型”模块，并与训练集链接。这将馈入“评分”模块，该模块使用测试数据集评估生成的机器学习模型。
- en: The results of tests can be visualized, allowing you to quickly evaluate a model.
    If the results are good, you can quickly publish it ready for use. You have the
    option of producing a real-time or batch inferencing pipeline. This adds web service
    inputs and outputs to your pipeline and removes the training modules. You can
    then test the inferencing endpoints, before deploying in an Azure Kubernetes Service
    cluster.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 测试结果可以进行可视化，使您能够快速评估模型。如果结果良好，您可以快速发布它以供使用。您可以选择生成实时或批处理推理流水线。这会将网络服务输入和输出添加到您的流水线中，并移除训练模块。然后，您可以测试推理端点，然后部署到
    Azure Kubernetes Service 群集中。
- en: Using Azure Machine Learning with Notebooks and Python
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Azure 机器学习与笔记本电脑和 Python
- en: Jupyter Notebooks are an open source tool that allow you to link text, images,
    and code to build and share live, interactive documents. That makes them an ideal
    tool for data science, as you can construct series of notebooks that embed all
    the steps to build and run a machine learning model, alongside its documentation.
    There’s support for many different languages, though Python is one of the most
    popular.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter 笔记本是一种开源工具，允许您链接文本、图像和代码来构建和共享实时交互式文档。这使它们成为数据科学的理想工具，因为您可以构建一系列笔记本，嵌入所有构建和运行机器学习模型的步骤，以及其文档说明。支持许多不同的语言，尽管
    Python 是最受欢迎的之一。
- en: Azure Machine Learning studio can host Jupyter notebooks directly in your workspace,
    as well as working with both Jupyter and JupyterLab authoring environments. Notebooks
    get their own section of studio, with a file system for storing documents and
    code and a browser-hosted terminal. Finally, alongside space for your own notebooks,
    there’s quick access to a series of notebooks that host Azure Machine Learning
    tutorials and samples.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习工作室可以直接在您的工作空间中托管 Jupyter 笔记本，同时支持 Jupyter 和 JupyterLab 作者环境。笔记本在工作室中有自己的部分，具有用于存储文档和代码的文件系统和基于浏览器的终端。最后，除了您自己的笔记本空间外，还可以快速访问一系列托管
    Azure 机器学习教程和样本的笔记本。
- en: To create a new file, click the file creation icon in the Notebook file browser.
    This lets you upload files and folders, create new folders, and create a new file.
    Choose to create a notebook file and give it a name. This will open an editing
    canvas for both code and markdown content, as you can see in [Figure 3-2](#working_with_python_code_in_azure_machi).
    The file can also be edited externally using Visual Studio Code.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建新文件，请单击笔记本文件浏览器中的文件创建图标。这样可以上传文件和文件夹，创建新文件夹和新文件。选择创建笔记本文件并为其命名。这将在编辑画布上打开代码和
    Markdown 内容，正如您可以在[图 3-2](#working_with_python_code_in_azure_machi)中看到的那样。文件也可以在外部使用
    Visual Studio Code 进行编辑。
- en: '![Working with Python code in Azure Machine Learning Notebooks](Images/aasc_0302.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![在 Azure 机器学习笔记本中使用 Python 代码](Images/aasc_0302.png)'
- en: Figure 3-2\. Working with Python code in Azure Machine Learning Notebooks
  id: totrans-107
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. 在 Azure 机器学习笔记本中使用 Python 代码
- en: Like all Jupyter notebooks, Azure Machine Learning’s uses cells to hold code
    and content. You can use the integrated web-based editor to add new cells. It’s
    based on Microsoft’s Monaco editing engine (as used in Visual Studio Code), so
    there’s full support for code completion and snippets with IntelliSense. The resulting
    combination is a complete Jupyter environment, with debugging tooling to manage
    and explore variables, making it a quick and powerful way to build and test prototypes
    in a collaborative space. Models can be built using any machine learning tooling
    with Python support—for example, calling out to both PyTorch and TensorFlow.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有 Jupyter 笔记本一样，Azure 机器学习使用单元格来保存代码和内容。您可以使用集成的基于 Web 的编辑器添加新的单元格。它基于微软的
    Monaco 编辑引擎（如同 Visual Studio Code 中使用的），因此完全支持代码完成和智能提示。这种组合结果是一个完整的 Jupyter 环境，具备调试工具，可管理和探索变量，是在协作空间中构建和测试原型的快速而强大的方式。可以使用任何支持
    Python 的机器学习工具构建模型，例如调用 PyTorch 和 TensorFlow。
- en: Python code interacts with Azure Machine Learning using the Python SDK, so you
    can chain a set of cells that load the SDK, log in to the service, and then set
    up and run an experiment, with a separate cell for your model. Microsoft provides
    a set of code snippets for common operations that you can use to speed up writing
    code, with an option to submit your choice of snippets for future use.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Python 代码通过 Python SDK 与 Azure 机器学习进行交互，因此您可以链接一系列单元格，加载 SDK、登录服务，然后设置和运行实验，使用一个单独的单元格来处理您的模型。微软提供了一组常见操作的代码片段，可以加快编写代码的速度，并可选择提交您选择的代码片段以供将来使用。
- en: You can also add comments to notebooks, allowing collaboration around code.
    You can pick a section of code and add a comment in the comment pane. Comments
    give you a way to easily create and manage issues, with tools to turn them into
    conversation threads. Once complete, notebooks can be exported and shared using
    common formats, for documentation or as pure code for use in production applications.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在笔记本中添加注释，允许围绕代码进行协作。您可以选择代码部分，并在注释窗格中添加评论。注释功能使您能够轻松创建和管理问题，并具备将其转换为对话线程的工具。一旦完成，笔记本可以导出并使用常见格式共享，用于文档编写或作为生产应用程序中的纯代码。
- en: Notebooks can be managed with tools like Git, ensuring that they can be shared
    and stored outside of an Azure environment. Notebooks can also be run on local
    Jupyter instances, allowing offline development and testing before using Azure
    resources to train a full-scale model. There’s no need to worry about cost when
    editing notebooks; they connect to a compute instance only when you run a cell
    containing code.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本可以通过类似 Git 的工具进行管理，确保可以在 Azure 环境之外共享和存储。笔记本还可以在本地 Jupyter 实例上运行，允许脱机开发和测试，然后再利用
    Azure 资源训练完整规模的模型。在编辑笔记本时无需担心成本问题；它们只在运行包含代码的单元格时连接到计算实例。
- en: Working with Azure Machine Learning Using Different Machine Learning Frameworks
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用不同机器学习框架进行 Azure 机器学习工作
- en: Azure Machine Learning is designed to support a wide selection of different
    machine learning frameworks, with prebuilt compute images that simplify using
    them to train models. These include the popular PyTorch and TensorFlow frameworks.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习旨在支持多种不同的机器学习框架，预构建的计算镜像简化了使用它们训练模型的过程。这些包括流行的 PyTorch 和 TensorFlow
    框架。
- en: PyTorch is an open source machine learning library based on the Lua-scripted
    Torch, developed mainly at Facebook’s AI Research laboratory. It offers Python
    and C++ interfaces, with the Python option the most commonly used. It now also
    includes support for Caffe2, with support for both tensor-based and deep neural
    network models.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 是基于 Lua-scripted Torch 的开源机器学习库，主要在 Facebook 的 AI 研究实验室开发。它提供 Python
    和 C++ 接口，其中 Python 选项最常用。现在还包括对 Caffe2 的支持，支持基于张量和深度神经网络模型。
- en: Microsoft uses PyTorch internally, with support for it in Azure Machine Learning’s
    Python development environment. A set of prebuilt compute instances are available
    with the PyTorch environment, allowing you to get started quickly using tooling
    in the Azure Machine Learning studio. This includes using it interactively through
    Jupyter Notebooks or from the Azure CLI.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft 在内部使用 PyTorch，在 Azure 机器学习的 Python 开发环境中支持它。预构建的计算实例可用于 PyTorch 环境，使您可以快速使用
    Azure 机器学习工作室中的工具。这包括通过 Jupyter 笔记本交互式地使用它，或者通过 Azure CLI 使用它。
- en: Azure Machine Learning also includes support for Google’s open source TensorFlow.
    This uses Python data structures to train neural networks. As it’s relatively
    easy to build and develop models with TensorFlow, it’s become popular as a quick
    on-ramp to developing machine learning models. Its eager execution option works
    directly with NumPy linear algebra tooling, making it a logical choice for data
    scientists.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习还包括对 Google 的开源 TensorFlow 的支持。这使用 Python 数据结构来训练神经网络。由于使用 TensorFlow
    构建和开发模型相对简单，因此它已成为快速开发机器学习模型的流行选择。它的即时执行选项直接与 NumPy 线性代数工具集集成，使其成为数据科学家的逻辑选择。
- en: Like PyTorch, Azure provides prebuilt compute environments for TensorFlow, as
    well as support in Azure Machine Learning’s Python development environments. The
    two frameworks work in much the same way and have similar performance characteristics.
    The question you need to ask when choosing which to use is what experience does
    your data science team have, and how close a fit is your intended workload to
    either option?
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 与 PyTorch 类似，Azure 为 TensorFlow 提供了预构建的计算环境，以及在 Azure 机器学习的 Python 开发环境中的支持。这两个框架的工作方式类似，并具有类似的性能特征。在选择使用哪种选项时，您需要考虑您的数据科学团队有何经验，以及您的预期工作负载与哪个选项更匹配。
- en: Start by importing the Azure Machine Learning libraries into a Python configuration
    script and set up a workspace using them. You’ll then need to build a training
    script that calls either PyTorch or TensorFlow on a set of labeled data. Scripts
    need to be stored in your workspace along with the data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 首先将 Azure 机器学习库导入到 Python 配置脚本中，并使用它们设置一个工作空间。然后需要编写一个训练脚本，在一组带标签数据上调用 PyTorch
    或 TensorFlow。脚本需要与数据一起存储在您的工作空间中。
- en: An Azure Machine Learning PyTorch script is like any other PyTorch script. There’s
    no need to change existing scripts to run on compute targets, so anyone who’s
    familiar with writing PyTorch transforms and working with its parser will be able
    to use Azure Machine Learning. Microsoft provides [sample scripts and data](https://go.microsoft.com/fwlink/?linkid=2190266)
    to help you get started.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习 PyTorch 脚本与任何其他 PyTorch 脚本一样。无需更改现有脚本即可在计算目标上运行，因此任何熟悉编写 PyTorch
    转换并使用其解析器的人都可以使用 Azure 机器学习。微软提供了[示例脚本和数据](https://go.microsoft.com/fwlink/?linkid=2190266)以帮助您入门。
- en: The same is true for TensorFlow. Again, you’ll create a workspace before creating
    a dataset reference to your training data, which can then be registered and shared
    with your team. Once your dataset is registered, create a compute cluster.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow也是如此。再次，在创建数据集引用您的训练数据之前，您将创建一个工作区，然后可以将其注册并与您的团队共享。一旦您的数据集注册完成，创建一个计算集群。
- en: The next step is to define a compute target, using the Python SDK to create
    a cluster. As both PyTorch and TensorFlow are focused on tensors and transforms,
    you should use a GPU cluster to get the best results (and to keep costs to a minimum).
    Microsoft provides curated environments with either PyTorch or TensorFlow preinstalled,
    a much easier approach than creating a VM with all the appropriate dependencies.
    You will be limited to Azure’s currently supported version of each framework,
    though in practice this shouldn’t make too much difference unless you plan to
    use new features or intend to experiment with prerelease tooling.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是定义一个计算目标，使用Python SDK创建一个集群。由于PyTorch和TensorFlow都专注于张量和转换，您应该使用GPU集群以获得最佳结果（并将成本最小化）。Microsoft提供了预先安装了PyTorch或TensorFlow的精选环境，这比创建带有所有适当依赖项的虚拟机要容易得多。您将受限于Azure当前支持的每个框架版本，尽管在实践中，除非您计划使用新功能或打算尝试预发布工具，否则这不会太大的影响。
- en: Alternatively, you can use the Python SDK to construct your own compute environment,
    using a YAML script to set up the appropriate dependencies, installing Python,
    and then using pip to install the tools your code needs. You will also need to
    define your compute environment’s base image.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用Python SDK来构建自己的计算环境，使用YAML脚本设置适当的依赖项，安装Python，然后使用pip安装您的代码所需的工具。您还需要定义您的计算环境的基础映像。
- en: Once this is all in place, either via the CLI or through a set of notebooks,
    you can create a training job that wraps your data and your script. This will
    load the contents of your training folder to your compute cluster and then run
    a set number of training runs. You’ll need to include specific details for either
    PyTorch or TensorFlow.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这些都就位，无论是通过CLI还是通过一组笔记本，您都可以创建一个训练作业，包装您的数据和脚本。这将加载您的训练文件夹的内容到您的计算集群，然后运行一组训练运行。您需要为PyTorch或TensorFlow包含具体的细节。
- en: 'A PyTorch training script will look something like this:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch训练脚本看起来会像这样：
- en: '[PRE5]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Similarly, a TensorFlow training script will look something like this:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，TensorFlow训练脚本看起来会像这样：
- en: '[PRE6]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You’ll notice that TensorFlow requires you to define the structure of a neural
    network as part of its configuration, in the args section.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到，TensorFlow要求您在args部分中定义神经网络的结构。
- en: When run, this builds the appropriate container for your runtime and scales
    this across your cluster, running it on your training data. Details of the run
    are logged in real time to help you monitor it, with the results copied back to
    your workspace when done. If the model results meet expectations, you can then
    register it for use in Azure or download the resulting model for use locally.
    You also have the option of exporting it as ONNX for use with ONNX inferencing
    runtimes.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行时，这将为您的运行时构建适当的容器，并在集群中进行扩展，将其运行在您的训练数据上。运行的详细信息将实时记录以帮助您监控，完成后将结果复制回您的工作区。如果模型结果符合预期，您可以将其注册供Azure使用，或者下载结果模型以在本地使用。您还可以选择将其导出为ONNX格式，以便与ONNX推理运行时一起使用。
- en: An Introduction to MLOps
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps简介
- en: MLOps is the application of DevOps principles to machine learning, applying
    the software development lifecycle to your model development, and at the same
    time using responsible AI techniques (see [Chapter 7](ch07.xhtml#responsible_ai_development_and_use))
    to provide a governance framework for your application development. It’s an important
    set of techniques to use if you’re to make machine learning a collaborative and
    repeatable process, taking advantage of the built-in monitoring and tuning tools
    in Azure Machine Learning.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps是将DevOps原则应用于机器学习的应用，将软件开发生命周期应用于您的模型开发，并同时使用负责任的AI技术（参见[第7章](ch07.xhtml#responsible_ai_development_and_use)）为您的应用开发提供治理框架。这是一套重要的技术，如果要使机器学习成为一种协作和可重复的过程，则可以利用Azure机器学习中内置的监控和调整工具。
- en: While DevOps is important for modern application development, MLOps is significantly
    more important for platforms like Azure Machine Learning. Models are not like
    code; they need maintenance to operate effectively. The more data we have, the
    more predictions we make; it’s easier to see where our models fail and what’s
    necessary to improve them. That data science task needs to be baked into our machine
    learning application development lifecycle.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然DevOps在现代应用程序开发中很重要，但对于像Azure Machine Learning这样的平台来说，MLOps显然更为重要。模型不同于代码；它们需要维护才能有效运行。我们拥有的数据越多，我们做出的预测也就越多；很容易看出模型失败的地方以及改进它们所需的内容。这项数据科学任务需要融入我们的机器学习应用程序开发生命周期中。
- en: Using a tool like Azure Machine Learning helps build MLOps processes into your
    workflow, as shown in [Figure 3-3](#the_azure_mlops_lifecycle_describes_how).
    Its pipeline approach to building and testing models gives you access to essential
    log file data, while tunable parameters help quickly reject failing models. It’s
    also easy to use Azure Machine Learning to quickly package and deploy models,
    either as REST API endpoints, as Kubernetes-ready inferencing containers, or as
    cross-platform, cross-device ONNX. Integration with the Azure DevOps platform
    via its Azure Machine Learning allows you to start to automate the process.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Azure Machine Learning等工具有助于将MLOps流程集成到您的工作流程中，如[图 3-3](#the_azure_mlops_lifecycle_describes_how)所示。其管道方法用于构建和测试模型，使您可以访问必要的日志文件数据，同时可调参数帮助快速拒绝失败的模型。Azure
    Machine Learning还能够快速打包和部署模型，无论是作为REST API端点、准备好的Kubernetes推理容器，还是跨平台、跨设备的ONNX。通过Azure
    Machine Learning与Azure DevOps平台的集成，您可以开始自动化这一过程。
- en: '![The Azure MLOps lifecycle describes how you can manage your models using
    the Azure Machine Learning tools](Images/aasc_0303.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![Azure MLOps生命周期描述如何使用Azure Machine Learning工具管理模型](Images/aasc_0303.png)'
- en: Figure 3-3\. The Azure MLOps lifecycle describes how you can manage your models
    using the Azure Machine Learning tools
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. Azure MLOps生命周期描述如何使用Azure Machine Learning工具管理模型
- en: 'Microsoft’s MLOps lifecycle has five steps:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft的MLOps生命周期分为五个步骤：
- en: Create/train/retrain your model using Azure Machine Learning studio.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Azure Machine Learning Studio创建/训练/重新训练您的模型。
- en: Register the model for use in applications; use tools like GitHub and Azure
    DevOps to manage model versions.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注册模型以供应用程序使用；使用GitHub和Azure DevOps等工具管理模型版本。
- en: Create scoring files and dependencies to get an audit trail for operations,
    to ensure regulatory compliance and give users a level of explainability for prediction
    results.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建评分文件和依赖项，以获取操作的审计跟踪，确保符合监管要求，并为预测结果提供解释性。
- en: Deploy and monitor, using logs and other performance monitoring tooling to gain
    observability into model operations.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署和监控，使用日志和其他性能监控工具获取模型操作的可观察性。
- en: Use monitoring data to understand model drift and determine when best to retrain
    the model based on real-world data and metrics.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用监控数据了解模型漂移，并基于真实世界数据和指标确定重新训练模型的最佳时机。
- en: Azure provides a suite of monitoring tools that can be built into machine learning
    applications to improve performance, while built-in logging in Azure Machine Learning
    can be used to improve models both during training and when they’re running as
    inferencers.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Azure提供了一套监控工具，可内置到机器学习应用程序中以提高性能，同时Azure Machine Learning中的内置日志记录可用于在训练期间和模型作为推理器运行时改进模型。
- en: Those monitoring tools can also be used to help tune models during training,
    to help ensure that they’re initially robust and that retraining will be an infrequent
    process, an important requirement considering the compute and GPU requirements
    of training, which can be significant. The tuning tools are also an important
    part of the MLOps lifecycle, as they allow developers to fine-tune models and
    the neural networks they’re built on during the training process. It’s worth drilling
    down into these features to understand how logging can be used to tune your models.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这些监控工具还可用于在训练期间帮助调整模型，以确保它们最初是稳健的，并且重新训练将成为一个不经常进行的过程，这是一个重要的要求，考虑到训练的计算和GPU需求可能相当大。调整工具也是MLOps生命周期的重要组成部分，因为它们允许开发人员在训练过程中微调模型和构建在其上的神经网络。值得深入了解这些功能，以了解如何使用日志记录来调整您的模型。
- en: Logging in Azure Machine Learning
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure Machine Learning中的日志记录
- en: Azure Machine Learning provides tools for monitoring training runs, using real-time
    logging via the default Python logging tools and its own custom logging tools
    in the SDK. You can use the MLflow logging tool to handle this data, installing
    the appropriate packages in your Azure Machine Learning workspace.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习提供工具来监视训练运行，使用默认的 Python 日志记录工具和 SDK 中自定义的日志记录工具进行实时记录。您可以使用 MLflow
    日志记录工具处理这些数据，在 Azure 机器学习工作空间安装适当的包。
- en: '[PRE7]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You can then write logging scripts that work against the Azure Machine Learning
    service. If you’re using notebooks to build and test experiments, the resulting
    data can be viewed in a notebook, using Python visualization tools. Alternatively,
    you can get postrun visualizations via the studio, using the Experiments tab to
    view data and compare different runs and using filters to extract specific data.
    Notebooks provide tools for interactive logging, as well as widgets for displaying
    log data.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以编写针对 Azure 机器学习服务的日志记录脚本。如果您使用笔记本来构建和测试实验，生成的数据可以在笔记本中查看，使用 Python 可视化工具。或者，您可以通过工作室获取后运行的可视化结果，使用实验选项卡查看数据并比较不同运行，并使用筛选器提取特定数据。笔记本提供交互式日志记录工具，以及用于显示日志数据的小部件。
- en: All the log files for a run are stored in your workspace, and you can download
    them for additional analysis, with a mix of text files, JSON, and log format files.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 每次运行的所有日志文件都存储在您的工作空间中，您可以下载这些文件进行额外分析，包括文本文件、JSON 和日志格式文件的混合。
- en: Tuning Using Hyperparameters
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用超参数进行调整
- en: Logs can help provide input into tuning models through Azure Machine Learning’s
    hyperparameters. A key element of managing the learning process, these let you
    tune model and neural network performance from outside your experiments. Set before
    learning starts, these include settings like the learning rate and the number
    of branches in a decision tree.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 日志可以帮助通过 Azure 机器学习的超参数来调整模型。管理学习过程的关键元素，这些元素让您能够从实验外部调整模型和神经网络的性能。在学习开始之前设置，这些设置包括学习速率和决策树中分支的数量等。
- en: Azure Machine Learning’s HyperDrive tooling can automate tuning for you, helping
    optimize parameters, killing poorly performing runs early, and automatically tuning
    neural networks to get the best configuration for your model. This includes defining
    the number of layers in a network and the number of nodes in each layer.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习的 HyperDrive 工具可以为您自动调整参数，帮助优化参数，及早终止表现不佳的运行，并自动调整神经网络以获取最佳配置。这包括定义网络中的层数以及每层中的节点数。
- en: It’s important to understand the deep architecture of your machine learning
    models before tuning their parameters. In the past this was a complex manual process
    that required a significant amount of compute resources. Azure Machine Learning’s
    tooling allows you to treat tuning as an experiment, automating large parts of
    the process and running tests in parallel to find the best set of hyperparameters
    for your model.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在调整参数之前了解机器学习模型的深度架构非常重要。过去这是一个复杂的手动过程，需要大量计算资源。Azure 机器学习的工具允许您将调整视为实验，自动化过程的大部分，并且并行运行测试以找到模型最佳的超参数组合。
- en: Hyperparameter tuning experiments are written in Python using the Azure Machine
    Learning SDK and the HyperDrive SDK. You will need to define the search space
    for tuning specific hyperparameters, the metric you’re using for tuning, how you
    will be sampling your training runs, and how your experiment can be terminated.
    Each run will be a complete training run in its own right, loading all the data
    as well as rebuilding the model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Azure 机器学习 SDK 和 HyperDrive SDK 编写的超参数调整实验是用 Python 编写的。您需要定义调整特定超参数的搜索空间，用于调整的指标，如何对训练运行进行采样，以及实验如何终止。每次运行都将是完整的训练运行，加载所有数据并重建模型。
- en: Azure Machine Learning studio provides visualization tooling to help you determine
    which run was the best for your model. Its charts can be used to show correlations
    between your chosen metrics and hyperparameter values.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习工作室提供可视化工具，帮助您确定哪个运行结果对您的模型最佳。其图表可用于展示您选择的指标与超参数数值之间的相关性。
- en: Working with hyperparameters does require a significant level of machine learning
    understanding, to help identify the specific parameters that will help improve
    your model accuracy. In practice you’ll get a similar effect from using a custom
    model in Azure Machine Learning’s automated machine learning tools.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 使用超参数确实需要相当水平的机器学习理解，以帮助识别可以帮助提高模型准确性的特定参数。实际上，通过在Azure机器学习的自动化机器学习工具中使用自定义模型，您将获得类似的效果。
- en: Exporting with ONNX
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ONNX导出
- en: Microsoft CEO Satya Nadella talks about “the intelligent cloud and the intelligent
    edge”; it’s the combination of WinML and ONNX that powers a large portion of that
    edge intelligence. ONNX is an important tool for taking trained machine learning
    models and using them for inference on many different platforms. It allows you
    to develop and train models using an appropriate machine learning framework in
    Azure Machine Learning, and when they are ready for general use, exporting them
    in an ONNX format for use with a local ONNX runtime on the target system. There’s
    support for it on everything from phones to PCs, with Windows offering its own
    WinML ONNX service for use in desktop applications.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft CEO Satya Nadella谈到了“智能云和智能边缘”；正是WinML和ONNX的结合推动了大部分边缘智能。ONNX是一个重要工具，用于在许多不同平台上推理经过训练的机器学习模型。它允许您在Azure机器学习中使用适当的机器学习框架开发和训练模型，当它们准备好用于通用用途时，将它们导出为ONNX格式，以便在目标系统上的本地ONNX运行时中使用。从手机到PC，Windows为桌面应用程序提供了自己的WinML
    ONNX服务的支持。
- en: You can export ONNX files from common machine learning frameworks, including
    PyTorch and TensorFlow. Microsoft uses ONNX internally along with the ONNX Runtime,
    showing significant performance gains over using alternative inferencing services.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从常见的机器学习框架（包括PyTorch和TensorFlow）中导出ONNX文件。Microsoft在内部使用ONNX以及ONNX Runtime，显示出与使用替代推理服务相比的显著性能提升。
- en: Machine Learning doesn’t only create ONNX models; if you’ve brought in an ONNX
    model from another machine learning training service or from your own systems,
    you can run it inside Azure Machine Learning, using it to manage and control access
    to your service APIs, while taking advantage of its automated inference scaling
    and access to Azure compute’s global reach.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习不仅仅创建ONNX模型；如果您从另一个机器学习训练服务或自己的系统中导入了ONNX模型，您可以在Azure机器学习中运行它，用它来管理和控制对服务API的访问，同时利用其自动推理扩展和访问Azure计算的全球范围。
- en: Using ONNX with WinML
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ONNX与WinML
- en: Microsoft has built a set of inferencing APIs into the latest Windows SDKs for
    both Windows and Windows Server. These support working with pretrained ONNX models,
    allowing you to use the scale of Azure to design and train machine learning models
    before building them into Windows applications.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft已将一组推断API集成到最新的Windows SDK中，适用于Windows和Windows Server。这些API支持使用预训练的ONNX模型，允许您利用Azure的规模来设计和训练机器学习模型，然后将其构建到Windows应用程序中。
- en: Running models locally reduces the load on networks, allowing you to put learning
    where it’s needed, even when there’s little or no bandwidth. With local ONNX models,
    machine learning code can run anywhere it’s needed, bringing it to the edge of
    the network.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地运行模型可以减少网络负载，使您可以将学习放在需要的地方，即使网络带宽很少或没有。通过本地ONNX模型，机器学习代码可以在任何需要的地方运行，将其带到网络的边缘。
- en: WinML has APIs for use with most common Windows development platforms, from
    native access with C and C++, to WinRT APIs for C# code. These provide abstractions
    from the WinML runtime and its ONNX inference engine, which works either directly
    with a PC’s CPU or uses DirectML to take advantage of GPU processing capabilities.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: WinML具有适用于大多数常见Windows开发平台的API，从使用C和C++的本机访问，到用于C#代码的WinRT API。这些提供了对WinML运行时及其ONNX推理引擎的抽象，该引擎可以直接与PC的CPU配合工作，或者利用DirectML利用GPU处理能力。
- en: 'When using ONNX with WinML, include the ONNX model as an asset in your project
    file. The techniques used to load and run the model will depend on your choice
    of language, but you will find using a recent build of Visual Studio provides
    tools for exposing model inputs and outputs, ready for use with your code. No
    matter what language you use, working with ONNX uses a common pattern: load, bind,
    and evaluate.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用WinML时，将ONNX模型作为项目文件的资产包含进去。加载和运行模型的技术取决于您选择的语言，但使用最新版本的Visual Studio提供了工具，用于公开模型的输入和输出，以供您的代码使用。无论您使用哪种语言，与ONNX一起工作都使用一种通用模式：加载、绑定和评估。
- en: Your code needs to first load the model from asset storage. As ONNX models can
    be large, it’s a good idea to build your inferencing application around an asynchronous
    method to handle the load. Once the model is loaded, you can bind inputs and outputs
    to it, making sure that your input and output classes support the expected data
    types. We can now iterate through our input data, calling an asynchronous evaluation
    method for each input value and then taking returned output data and using the
    results in the rest of our application.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 您的代码需要首先从资产存储加载模型。由于 ONNX 模型可能很大，建议围绕异步方法构建您的推断应用程序来处理加载。一旦加载了模型，您可以将输入和输出绑定到它，确保您的输入和输出类支持预期的数据类型。现在，我们可以迭代我们的输入数据，为每个输入值调用异步评估方法，然后使用返回的输出数据，并在应用程序的其余部分中使用结果。
- en: Using WinML and ONNX, you can build standalone machine learning applications
    in just a few lines of code, taking trained models from Azure Machine Learning
    and running them anywhere you have a Windows PC or server.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 WinML 和 ONNX，您可以仅需几行代码构建独立的机器学习应用程序，使用来自 Azure 机器学习的训练模型，并在您拥有 Windows PC
    或服务器的任何地方运行它们。
- en: Using ONNX in Machine Learning Container Runtimes
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在机器学习容器运行时中使用 ONNX
- en: Portable machine learning systems are an important tool for edge computing,
    as we showed in [Chapter 2](ch02.xhtml#understanding_ai_offerings_and_capabili),
    putting machine learning models where they’re needed. To simplify deployment,
    you can package an entire ONNX runtime in a container, along with your ONNX model.
    Deployment is simply a matter of loading and running the container on an edge
    Kubernetes system like K3s or using a standalone container runtime. Updates are
    handled by swapping out containers with minimal service downtime and disruption.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 便携式机器学习系统是边缘计算的重要工具，正如我们在[第 2 章](ch02.xhtml#understanding_ai_offerings_and_capabili)中展示的那样，将机器学习模型放在需要的地方。为了简化部署，您可以将整个
    ONNX 运行时与您的 ONNX 模型一起打包到一个容器中。部署只是加载和在边缘 Kubernetes 系统（如 K3s）上运行容器，或使用独立容器运行时。通过最小化服务停机时间和中断来处理更新。
- en: Setting up an ONNX runtime container is easy enough. Start by building a container
    image that’s configured with Python. Use pip to install the ONNX runtime, either
    for CPU or GPU. You can find Microsoft’s at [ONNX Runtime for Azure Machine Learning](https://go.microsoft.com/fwlink/?linkid=2190243).
    The Python ONNX runtime loads the model as an inference session, and you can use
    it to extract model data to enumerate inputs and outputs, as well as confirming
    the model metadata.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 ONNX 运行时容器非常简单。首先构建一个配置了 Python 的容器映像。使用 pip 安装 ONNX 运行时，无论是用于 CPU 还是 GPU。您可以在[ONNX
    Runtime for Azure Machine Learning](https://go.microsoft.com/fwlink/?linkid=2190243)找到
    Microsoft 的版本。Python ONNX 运行时将模型加载为推断会话，您可以使用它提取模型数据以枚举输入和输出，以及确认模型元数据。
- en: Running a model is as easy as calling your inference session with your model
    inputs. You can define which outputs you want to use or simply accept all responses.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 运行模型就像调用推断会话并提供模型输入一样简单。您可以定义要使用的输出，或者简单地接受所有响应。
- en: Microsoft provides a prebuilt ONNX runtime container for use with pretrained
    Azure Machine Learning models. Based on Ubuntu 18.04 and Python 3.7, it’s designed
    to use CPU inference and should run on most Docker or container systems. Preinstalled
    packages also include NumPy and Pandas, so you can work with results using common
    numeric methods. The prebuilt Dockerfile can be used as the foundation for your
    own image, adding additional libraries and code as a nested Docker image.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft 提供了预构建的 ONNX 运行时容器，用于与预先训练的 Azure 机器学习模型一起使用。基于 Ubuntu 18.04 和 Python
    3.7，设计用于使用 CPU 推断，并应该在大多数 Docker 或容器系统上运行。预安装的包还包括 NumPy 和 Pandas，因此您可以使用常见的数值方法处理结果。预构建的
    Dockerfile 可以用作构建您自己图像的基础，添加额外的库和代码作为嵌套 Docker 图像。
- en: Wrapping It Up
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we have explored using the tooling in Azure Machine Learning
    to build and train your own custom machine learning models, using common frameworks
    like PyTorch and TensorFlow, as well as its own no-code designer tooling. But
    you won’t always want to build your own machine learning models, so in the next
    chapter we’ll look at the prebuilt AI cloud services you can call as APIs: the
    Azure Cognitive Services.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了使用 Azure 机器学习中的工具来构建和训练自定义机器学习模型，使用常见框架如 PyTorch 和 TensorFlow，以及其自身的无代码设计工具。但您并不总是想要构建自己的机器学习模型，因此在下一章中，我们将看看您可以调用作为
    API 的预构建 AI 云服务：Azure 认知服务。
