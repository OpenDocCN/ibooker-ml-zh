- en: Chapter 8\. Selecting and Debugging XGBoost Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 选择和调试XGBoost模型
- en: The ways that data scientists measure a model’s real-world performance are usually
    inadequate. According to [“Underspecification Presents Challenges for Credibility
    in Modern Machine Learning”](https://oreil.ly/27jFT), penned by 40 researchers
    at Google and other leading machine learning research institutions, “ML models
    often exhibit unexpectedly poor behavior when they are deployed in real-world
    domains.” A fundamental issue is that we measure performance like we’re writing
    research papers, no matter how complex and high-risk the deployment scenario.
    Test data measurements like accuracy or area under the curve (AUC) don’t tell
    us much about fairness, privacy, security, or stability. These simple measurements
    of prediction quality or error on static test sets are not informative enough
    for risk management. They are only correlated with real-world performance, and
    don’t guarantee good performance in deployment. Put plainly, we should be more
    concerned with in vivo performance and risk management than in silico test data
    performance, because a primary thrust of the applied practice of ML is to make
    good decisions in the real world.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家衡量模型在现实世界表现的方式通常是不充分的。据谷歌及其他领先的机器学习研究机构的40位研究人员在《“Underspecification Presents
    Challenges for Credibility in Modern Machine Learning”》中指出，“当ML模型在实际应用中部署时，其表现通常会出现意外的差异”。一个根本性问题在于，我们衡量性能的方式就像我们在撰写研究论文一样，无论部署场景多么复杂且高风险。像准确率或曲线下面积（AUC）这样的测试数据测量并不能告诉我们有关公平性、隐私性、安全性或稳定性的多少。这些对静态测试集的简单预测质量或错误测量对风险管理而言并不够信息化。它们只与实际表现相关，并不能保证在部署中表现良好。简言之，我们应更关注体内表现和风险管理，而非体外测试数据性能，因为ML实践的主要推动力之一是在现实世界中做出良好的决策。
- en: This chapter will introduce several methods that go beyond traditional model
    assessment to select models that generalize better, and that push models to their
    limits to find hidden problems and failure modes. The chapter starts with a concept
    refresher, puts forward an enhanced process for model selection, and then focuses
    on model debugging exercises that better simulate real-world stresses, along with
    sensitivity analysis and tests that uncover model errors using residual analysis.
    The overarching goal of model debugging is to increase trust in model performance
    in the real world, but in the process, we’ll also increase the transparency of
    our models. Code examples that accompany the chapter are available [online](https://oreil.ly/machine-learning-high-risk-apps-code);
    [Chapter 9](ch09.html#unique_chapter_id_9) addresses debugging for images and
    unstructured data, and [Chapter 3](ch03.html#unique_chapter_id_3) covers model
    debugging more broadly.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍一些超越传统模型评估的方法，以选择更好地泛化的模型，并将模型推向极限以发现隐藏的问题和故障模式。该章节从概念复习开始，提出了一个增强的模型选择过程，然后专注于模型调试练习，这些练习更好地模拟现实世界的压力，以及使用残差分析揭示模型错误的敏感性分析和测试。模型调试的总体目标是增强对模型在现实世界中性能的信任，但在此过程中，我们还将增强模型的透明度。本章附带的代码示例可在[在线](https://oreil.ly/machine-learning-high-risk-apps-code)获取；[第9章](ch09.html#unique_chapter_id_9)处理图像和非结构化数据的调试，而[第3章](ch03.html#unique_chapter_id_3)则广泛涵盖了模型调试。
- en: 'Concept Refresher: Debugging ML'
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念复习：调试机器学习
- en: If readers haven’t picked up on it yet, we’re much more concerned about in vivo
    performance than in silico performance. In vivo performance matters for users;
    in silico performance doesn’t. With this central tenet in mind, we’ll be covering
    model selection, sensitivity analysis tests, residual analysis, and remediating
    (i.e., fixing) models.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果读者还没有注意到，我们更关注体内表现，而不是体外表现。体内表现对用户很重要；而体外表现则无关紧要。以这一核心原则为指导，我们将涵盖模型选择、敏感性分析测试、残差分析以及修正（即修复）模型。
- en: Model Selection
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型选择
- en: 'Traditionally we select models by choosing features and selecting hyperparameters.
    We try to find the best set of features using approaches like stepwise regression,
    feature importance measurements, or L1 regularization. We often use grid searches
    to find the best hyperparameter settings for our ML models. In [Chapter 2](ch02.html#unique_chapter_id_2),
    we used a more deliberate approach in which we started with a linear model benchmark
    and introduced nonlinearity and interactions into our models, then used human
    judgment to pick our favorite model. In this chapter, we’ll see that random grid
    search is especially problematic on small datasets for hyperparameter selection
    and when we compare it to a more sophisticated cross-validated ranking procedure
    inspired by [“KDD-Cup 2004: Results and Analysis”](https://oreil.ly/osrK4). We’ll
    compare the rank of model performance across several validation folds and several
    different traditional assessment metrics to get a better idea of estimated in
    vivo performance and pick a better model. We’ll also highlight how to estimate
    the business value of a model—a crucial consideration. No one in the business
    world wants to deploy a model that loses money!'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '传统上，我们通过选择特征和选择超参数来选择模型。我们尝试使用诸如逐步回归、特征重要性测量或L1正则化等方法找到最佳特征集。我们通常使用网格搜索来找到我们机器学习模型的最佳超参数设置。在[第二章](ch02.html#unique_chapter_id_2)，我们采用了一种更为深思熟虑的方法，从线性模型基准开始，引入非线性和交互作用到我们的模型中，然后使用人为判断选择我们最喜欢的模型。在本章中，我们将看到，对于超参数选择，随机网格搜索在小数据集上尤为棘手，特别是当我们将其与灵感来自[“KDD-Cup
    2004: Results and Analysis”](https://oreil.ly/osrK4)的更复杂的交叉验证排名程序进行比较时。我们将比较模型性能在多个验证折叠和多个不同传统评估指标中的排名，以更好地估计体内性能并选择更好的模型。我们还将强调如何估计模型的业务价值——这是一个至关重要的考虑因素。商业世界中没有人想要部署会赔钱的模型！'
- en: Sensitivity Analysis
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 敏感性分析
- en: Because ML models tend to extrapolate in complex ways, we won’t really know
    how our model will perform on unseen data unless we test it explicitly on different
    types of data. That’s what we’re attempting to do with sensitivity analysis. Broadly
    speaking, sensitivity analysis shows us whether our model will be stable on different
    kinds of data. Sensitivity analysis might show us that our model has robustness
    issues, i.e., it fails under data drift. It might show us that our model has reliability
    or resilience problems, i.e., that some types of input cause our to model to behave
    in surprising or inappropriate ways. There are many structured approaches to sensitivity
    analysis. If readers would like to learn more, we suggest exploring resources
    associated with [PiML](https://oreil.ly/84KCZ) or [SALib](https://oreil.ly/Kgnmg).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 因为机器学习模型往往以复杂的方式进行外推，除非我们明确在不同类型的数据上进行测试，否则我们不会真正知道我们的模型在未见数据上的表现如何。这就是我们试图通过敏感性分析来做的事情。广义上讲，敏感性分析告诉我们我们的模型在不同类型数据上是否稳定。敏感性分析可能会显示我们的模型存在鲁棒性问题，即在数据漂移下失败。它可能会显示我们的模型存在可靠性或弹性问题，即某些类型的输入导致我们的模型表现出令人意外或不合适的方式。关于敏感性分析，有许多结构化方法。如果读者想要了解更多信息，我们建议探索与[PiML](https://oreil.ly/84KCZ)或[SALib](https://oreil.ly/Kgnmg)相关的资源。
- en: 'We’ll highlight two other related sensitivity analysis methods in this chapter
    that appear most directly useful to practitioners: stress testing and adversarial
    example searches. Stress testing is roughly aligned to testing for robustness,
    whereas adversarial example searches probe for reliability and resilience problems:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点介绍另外两种相关的敏感性分析方法，它们似乎对从业者最直接有用：应力测试和对抗样本搜索。应力测试大致与测试鲁棒性对齐，而对抗样本搜索则探索可靠性和弹性问题：
- en: Stress testing
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 应力测试
- en: 'Stress testing is a global perturbation approach that tests models in foreseeable
    stressful circumstances. When we stress test our model, we’ll change our validation
    data to simulate recession conditions and see if it remains robust under these
    foreseeable difficult conditions. The idea is to make our model robust to predictable
    circumstances, or at least to document expected performance degradation for whoever
    might be maintaining the model when recession—or another kind of domain shift—strikes.^([1](ch08.html#idm45990005370304))
    We’ll be doing a much less rigorous analysis on a single model, but the idea is
    the same: to test how our model will perform under foreseeable concept or data
    drift, such as a recession, to make sure we are prepared for the likeliest types
    of failures.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 压力测试是一种全局扰动方法，用于在可预见的紧张环境中测试模型。当我们对模型进行压力测试时，我们将改变验证数据以模拟经济衰退条件，并查看它是否在这些可预见的困难条件下保持稳健。这个想法是使我们的模型能够应对可预见的情况，或者至少为可能维护模型的人员记录预期的性能下降，当经济衰退或其他类型的领域转变发生时。^([1](ch08.html#idm45990005370304))
    我们将对单一模型进行一种不那么严格的分析，但思路是一样的：测试我们的模型在可预见的概念或数据漂移（如经济衰退）下的表现，以确保我们为最有可能的失败做好准备。
- en: Adversarial example searches
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗性示例搜索
- en: Adversarial example searches are a local perturbation approach that helps uncover
    local, logical flaws in the model’s reliability and potential security vulnerabilities
    (i.e., resilience issues). Adversarial examples are rows of data that create strange
    responses from complex ML models. Sometimes we can craft these rows by hand, but
    often we have to search for them. In this chapter, we will search for them by
    perturbing, or changing, values of important features in certain rows of data
    and checking how this change affects model performance. Both the search itself
    and the individual adversarial examples we find are useful. The search creates
    a response surface that displays model performance across many interesting input
    values, and often reveals logical flaws in model performance. The individual rows
    we find that evoke strange responses are good to document and share with security
    colleagues, so that model monitoring can be primed to detect known adversarial
    examples.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗性示例搜索是一种局部扰动方法，有助于揭示模型可靠性和潜在安全漏洞（即韧性问题）中的局部逻辑缺陷。对抗性示例是数据行，会导致复杂机器学习模型产生奇怪的响应。有时我们可以手工制作这些行，但通常我们需要搜索它们。在本章中，我们将通过扰动或改变某些数据行中重要特征的值来搜索它们，并检查此变化如何影响模型性能。搜索本身以及我们发现的个别对抗性示例都是有用的。搜索创建一个响应表面，显示模型在许多有趣输入值上的性能，并经常揭示模型性能的逻辑缺陷。我们发现引发奇怪响应的个别行很好地记录并与安全同事分享，以便模型监控能够检测已知的对抗性示例。
- en: 'In deep learning, data scientists tend to use gradient information and generative
    adversarial networks (GANs) to create adversarial examples. In structured data
    tasks, we have to use other methods, like those described in [“Adversarial Attacks
    for Tabular Data: Application to Fraud Detection and Imbalanced Data”](https://oreil.ly/KF843),
    heuristics based on individual conditional expectation, or genetic algorithms.
    We’ll be pursuing a heuristic method in [“Adversarial Example Search”](#adversarial_example_search_ch08_1680868791511),
    both to find adversarial examples, and to probe our model’s response surface for
    problems.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，数据科学家倾向于使用梯度信息和生成对抗网络（GANs）来创建对抗性示例。在结构化数据任务中，我们必须使用其他方法，比如[“表格数据的对抗攻击：应用于欺诈检测和不平衡数据”](https://oreil.ly/KF843)中描述的基于个体条件期望的启发式方法或遗传算法。我们将在[“对抗性示例搜索”](#adversarial_example_search_ch08_1680868791511)中追求一种启发式方法，既能找到对抗性示例，又能探索我们模型的响应表面以寻找问题。
- en: The most important method we don’t treat in this chapter is random attacks,
    or simply exposing our model or API to *a lot* of random data and seeing what
    kinds of issues emerge. If we don’t know where to start with sensitivity analysis,
    we try random attacks first. Then we try PiML, SALib, and the methods we’ll put
    forward in the sections that follow. Regardless of how we implement sensitivity
    analysis, the key is to do something about the problems we find. We often use
    data augmentation, business rules, regularization, constraints, and monitoring
    to remediate sensitivity issues.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中我们没有处理的最重要的方法是随机攻击，或者简单地将我们的模型或API暴露给大量随机数据，并查看出现什么样的问题。如果我们不知道从哪里开始进行敏感性分析，我们首先尝试随机攻击。然后我们尝试
    PiML、SALib 和接下来章节中将提出的方法。无论我们如何实施敏感性分析，关键是针对我们发现的问题采取行动。我们通常使用数据增强、业务规则、正则化、约束和监控来解决敏感性问题。
- en: Residual Analysis
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 残差分析
- en: 'Residual analysis is a primary method of model debugging. It is the careful
    study of modeling mistakes made in training data, or other labeled data, for testing
    and debugging purposes. While readers may be familiar with residual analysis for
    traditional linear models, it can and should be applied to ML models. The basic
    idea is the same as with linear models. Good models should have mostly random
    errors. When we examine the errors in our ML models and strong patterns emerge,
    this most likely means that we forgot something or we made a mistake when we built
    our model. Then we have to use our human brains to try to fix the problem. In
    this chapter, we’ll focus on three major approaches to residual analysis—residual
    plots, segmented error analysis, and modeling residuals:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 残差分析是模型调试的主要方法。这是对在训练数据中出现的建模错误或其他标记数据进行仔细研究，用于测试和调试的目的。尽管读者可能熟悉传统线性模型的残差分析，但它同样适用于机器学习模型。基本思想与线性模型相同。良好的模型应该具有大部分是随机误差。当我们检查我们的机器学习模型中的误差并出现强烈模式时，这很可能意味着我们遗漏了某些内容或在建模过程中出现了错误。然后我们必须动用我们的大脑来尝试解决问题。在本章中，我们将集中讨论三种主要的残差分析方法——残差图、分段误差分析和建模残差：
- en: Residual plots
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 残差图
- en: 'We’ll examine residual plots for the entire model, and then break down the
    plots by feature and by level. We’ll look to answer questions like: Which rows
    are causing the largest errors? Do we see any strong patterns in the residual
    plots? Can we isolate any patterns to specific input features or levels of a feature?
    Then we’ll try to think through how to fix any issues that we uncover.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对整个模型的残差图进行检查，然后按特征和水平分解这些图。我们将试图回答以下问题：哪些行造成了最大的误差？在残差图中是否看到任何强烈的模式？我们能够将任何模式孤立到特定的输入特征或特征的级别吗？然后我们将设法思考如何修复我们发现的任何问题。
- en: Segmented error analysis
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 分段误差分析
- en: We shouldn’t deploy a model without checking to see how it performs across major
    segments in our training or test data. Failing to do so can have grave consequences
    for both overall model performance and algorithmic discrimination, when a model
    performs poorly on historically marginalized demographic groups. We’ll be focusing
    on the performance aspect in this chapter, and looking into other types of segments
    apart from demographic segments. We do this because commonly used average assessment
    metrics for entire datasets can mask poor performance on small but important subpopulations.
    Sparsity in training data can lead to nearly random performance on some segments
    too. Segmented error analysis has also been put forward as an in silico test for
    the nasty problem of underspecification. All of these issues—poor performance
    in small segments, random performance in sparse regions of training data, and
    underspecification—can lead to unpleasant surprises and serious problems once
    a model is deployed. One cool extension of segmented error analysis, implemented
    in PiML, is to examine overfitting across segments. Doing so can highlight additional
    issues that will affect an in vivo model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署模型之前，我们不应该忽视其在训练或测试数据的主要段上的表现。如果不这样做，可能会对整体模型性能和算法歧视产生严重后果，尤其是当模型在历史上被边缘化的人群中表现不佳时。本章节将重点关注性能方面，并研究除人口统计分段外的其他类型的段。我们这样做是因为通常用于整个数据集的平均评估指标可能会掩盖对小但重要的子群体的不良表现。训练数据的稀缺性也可能导致在某些段上表现几乎随机。分段误差分析也被提出作为对欠规范问题的一种体外测试。所有这些问题——在小段上的性能不佳、在训练数据稀疏区域的随机性能以及欠规范——都可能导致在部署模型后出现不愉快的意外和严重问题。在
    PiML 中实施的分段误差分析的一个很酷的扩展是检查各个段的过拟合情况。这样做可以突显会影响体内模型的其他问题。
- en: Modeling residuals
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 建模残差
- en: Another way to learn patterns in residuals is to model them. If we can fit a
    straightforward, interpretable model to another model’s residuals, that means,
    almost by definition, that there are strong patterns in the residuals. (And strong
    patterns in residuals usually means we made a modeling mistake.) Moreover, modeling
    residuals implies we can reduce them. The models we fit to residuals should also
    inform how to fix the discovered mistakes. As an example, we’ll fit a decision
    tree to our model’s residuals. We’ll then examine the rules of that tree, because
    they are rules that describe when our model is most often wrong. We’ll try to
    understand those rules to try to fix the problems they highlight.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 学习残差中的模式的另一种方法是对其进行建模。如果我们能够将一个简单直观的模型拟合到另一个模型的残差中，那么，几乎可以说，残差中存在强烈的模式。而且，建模残差意味着我们可以减少它们。我们拟合到残差的模型还应该帮助我们修复发现的错误。例如，我们将为我们模型的残差拟合一个决策树。然后，我们将检查该树的规则，因为这些规则描述了我们的模型通常出错的情况。我们将尝试理解这些规则，以尝试解决它们突出的问题。
- en: As with sensitivity analysis, we won’t be able to treat all the important ways
    to conduct residual analysis in ML in one chapter. Some of the most noteworthy
    approaches we won’t cover include methods for discovering nonrobust features,
    such as Shapley value contributions to model loss. See [Chapter 3](ch03.html#unique_chapter_id_3)
    for a broader overview of residual analysis for ML.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 与敏感性分析一样，我们无法在一章中涵盖所有机器学习中进行残差分析的重要方法。一些最显著的方法包括发现非鲁棒特征的方法，例如 Shapley 值对模型损失的贡献。请参阅[第3章](ch03.html#unique_chapter_id_3)，了解更广泛的机器学习残差分析概述。
- en: Remediation
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 补救措施
- en: 'Once we find problems, we need to fix them. The bad news is that a lot of problems
    in ML arise from the use of low-quality, biased data and from confirmation bias.
    For most projects, this will involve two difficult pills to swallow: (1) collecting
    better data, with at least some consideration for experimental design, and (2)
    going back to the drawing board and redefining our experiment with better adherence
    to the scientific method to minimize human, statistical, and systemic biases in
    our modeling workflow.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦发现问题，我们就需要解决它们。坏消息是，机器学习中很多问题源于低质量、偏见数据的使用以及确认偏见。对于大多数项目来说，这将涉及到接受两个难以忍受的现实：（1）收集更好的数据，至少考虑一些实验设计，和（2）回到起点，重新定义我们的实验，更好地遵循科学方法，以减少我们建模工作流中的人为、统计和系统性偏差。
- en: Once serious data, methodological, or bias issues are addressed in our workflows,
    we can try some tech fixes for our model, as we do in this chapter. For example,
    we can apply monotonic constraints, interaction constraints, or regularization
    to our models to stabilize them, make them more logical and interpretable, and
    to improve performance in vivo. We can apply business rules, sometimes also called
    *model assertions*, or manual prediction limits to fix foreseeable bad outcomes.
    Business rules and model assertions boil down to adding code to our scoring engine
    that changes predictions we think will be wrong. We can edit the formulas or production
    code of our models to correct for problematic modeling mechanisms or predictions,
    and we can manage and monitor our models once they are deployed to track them
    and spot anomalies quickly.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的工作流中解决了严重的数据、方法论或偏见问题，我们就可以尝试一些技术修复我们模型的方法，正如我们在本章中所做的那样。例如，我们可以应用单调约束、交互约束或正则化到我们的模型中，以稳定它们，使它们更具逻辑性和可解释性，并提高在实际应用中的性能。我们可以应用业务规则，有时也称为*模型断言*，或手动预测限制来修复可预见的不良结果。业务规则和模型断言归结为向我们的评分引擎添加代码，以更改我们认为将会出错的预测。我们可以编辑我们模型的公式或生产代码，以纠正问题建模机制或预测，并且一旦部署了模型，我们可以管理和监控它们，以快速发现异常。
- en: For our model in this chapter, we’ll hopefully have done a decent job sticking
    with the scientific method, mainly by expressing our hypotheses for model outcomes
    through monotonic constraints and by very rigorous model selection, as discussed
    in the next section. We’ll apply both sensitivity and residual analyses to the
    model to find bugs, and then we’ll try our best to remediate those bugs in [“Remediating
    the Selected Model”](#remediating_selected_model_ch08_1680868845039).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章中的模型，我们希望通过表达我们模型结果的假设，主要通过单调约束和非常严格的模型选择来遵循科学方法，如下一节所讨论的。我们将对模型应用敏感性和残差分析，以发现错误，并且我们将尽力在[“修复所选模型”](#remediating_selected_model_ch08_1680868845039)中解决这些错误。
- en: Selecting a Better XGBoost Model
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择更好的XGBoost模型
- en: Although it’s not technically debugging, we want to start our debugging exercise
    on solid footing by selecting a highly stable, generalizable, and valuable model.
    To do that, we won’t just rely on grid search. Instead, we’ll select a model as
    inspired by the [Caruana et al. cross-validation ranking approach](https://oreil.ly/kJT7d)
    used in the 2004 Knowledge Discovery in Databases (KDD) Cup. We’ll also compare
    these results to a standard random grid search so we can get an idea of the difference
    between a grid search and the cross-validation ranking procedure described in
    this section. Then, before moving onto sensitivity analysis, we’ll do a basic
    estimation of our model’s business value to check that we’re not wasting money.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然从技术上讲这不是调试，但我们希望从选择一个高度稳定、通用且有价值的模型开始我们的调试练习。为了做到这一点，我们不仅仅依赖于网格搜索。相反，我们将选择一种模型，灵感来自于2004年数据库知识发现（KDD）杯中使用的[Caruana
    et al. 交叉验证排名方法](https://oreil.ly/kJT7d)。我们还将这些结果与标准的随机网格搜索进行比较，以便了解网格搜索与本节描述的交叉验证排名过程之间的差异。然后，在进行敏感性分析之前，我们将对模型的商业价值进行基本估算，以确保我们不会浪费金钱。
- en: Note
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: According to Richard Feynman, it’s our responsibility as scientists to engage
    in “a kind of leaning over backward” to make sure we don’t fool ourselves and
    others. If this model selection approach seems over the top, think of it as bending
    over backward to find the best model we can.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 根据理查德·费曼的说法，作为科学家，我们有责任进行“一种倾向于的倾斜”，以确保我们不会欺骗自己和他人。如果这种模型选择方法看起来有些过分，可以把它看作是为了尽力找到最好的模型而做出的努力。
- en: 'The first thing we do to begin our model selection process is split our validation
    data into five folds. Then we select five relevant performance metrics to apply
    to each fold. These metrics should measure different aspects of performance, such
    as AUC measuring ranking capabilities across thresholds and accuracy measuring
    correctness at one threshold. In our case, we’ll take maximum accuracy, AUC, maximum
    F1 statistic, logloss, and mean squared error (MSE) as our five metrics. The first
    step of our selection process is to calculate the value of each of these different
    statistics on each fold. That’s what the following code snippet does:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们开始模型选择过程是将验证数据分为五折。然后我们选择五个相关的性能指标来应用到每个折叠上。这些指标应该测量性能的不同方面，比如AUC用于衡量跨阈值的排名能力，准确度用于衡量在一个阈值上的正确性。在我们的情况下，我们将最大准确度，AUC，最大F1统计量，对数损失和均方误差（MSE）作为我们的五个指标。我们选择过程的第一步是计算每个折叠上每个不同统计量的值。以下代码片段就是在做这件事：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once we have the performance metric for each model across each fold, we move
    to the second step of the selection procedure and rank the performance of each
    model on each fold and for each measure. The following code does the ranking.
    Our search includes 50 different XGBoost models, and we test them using five performance
    measures on five folds. For each fold and metric, we rank the models first through
    fiftieth by the current metric, allowing for ties. We take the model with the
    lowest average rank across each fold and metric as the best model for in vivo
    usage. Think about this as if you were giving a test to 50 students, but instead
    of one test per student, it’s five tests for each student. Then, we don’t pass
    every student who makes above a certain numeric grade; we’re only interested in
    the student who performs better than all others across the most tests. Of course,
    this would make us very mean teachers, but luckily, it’s fine to be extremely
    selective when it comes to ML models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们获得每个模型在每个折叠上的性能指标，我们就会进入选择过程的第二步，即对每个模型在每个折叠和每个测量上的性能进行排名。以下代码就是进行排名的过程。我们的搜索包括50个不同的XGBoost模型，并且我们使用五个性能指标对它们进行测试，每个模型测试五个折叠。对于每个折叠和指标，我们按照当前指标将模型从第一到第五十进行排名，允许出现并列情况。我们将每个折叠和指标上的平均排名最低的模型视为适用于体内使用的最佳模型。可以将其想象为给50名学生做测试，但不是每名学生只有一次测试，而是每名学生有五次测试。然后，我们并不会通过每个学生的数值成绩来决定是否通过，我们只对那位在最多测试中表现最好的学生感兴趣。当然，这样做可能会让我们显得非常苛刻，但幸运的是，在选择机器学习模型时，极度挑剔是可以的。
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Ties occur because we round performance scores. If two models score, say, an
    AUC of 0.88811 and 0.88839, that’s a tie. Those last decimals of AUC are likely
    irrelevant for in vivo performance, and our approach handles ties well. Two models
    with the same score simply have the same rank for that fold and metric. Because
    we try so many metrics and so many scores, and take the average rank across all
    of them, those ties rarely matter in the end for selecting the best model. In
    our example, each of the 50 models is assigned 25 different ranking values, one
    rank for each metric and fold. Our best model ranked first and second on several
    fold and metric combinations, but also ranked as high as 26.5—indicating a tie—for
    its worst-performing fold and metric. In the end, our best-performing model in
    terms of lowest ranks across metrics and folds showed an average rank of 10.38.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们会四舍五入性能得分，所以会出现并列情况。例如，如果两个模型得分分别为0.88811和0.88839，那么就会并列。对于体内表现来说，AUC的最后小数点可能是不相关的，我们的方法可以很好地处理这些并列情况。得分相同的两个模型在该折叠和指标上的排名就会一样。因为我们尝试了那么多指标和得分，而且取所有指标的平均排名，所以这些并列情况最终很少影响选择最佳模型的结果。在我们的示例中，每个50个模型分别被分配25个不同的排名值，即每个指标和折叠各一个。我们最好的模型在几个折叠和指标的组合上排名第一和第二，但在其表现最差的折叠和指标上的排名也高达26.5—表明存在并列情况。最终，在所有指标和折叠的最低排名方面，我们表现最佳的模型平均排名为10.38。
- en: For comparison purposes, this ranking procedure was applied to the top 50 models
    selected, and models were ranked by a standard random grid search. In the grid
    search, the lowest logloss on validation data was used to rank models. When we
    compare the grid search ranking to the cross-validation ranking, the dissimilarity
    is striking ([Table 8-1](#table_grid-search-vs-cross-val)).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较目的，这种排名程序适用于所选的前50个模型，并且模型是通过标准的随机网格搜索进行排名的。在网格搜索中，使用验证数据上的最低对数损失来排名模型。当我们将网格搜索的排名与交叉验证的排名进行比较时，它们之间的差异是显著的（[表8-1](#table_grid-search-vs-cross-val)）。
- en: Table 8-1\. Overall rank of the top 10 models across a random grid search ranked
    by logloss and the more in-depth cross-validated model selection approach
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-1\. 根据对数损失排名的随机网格搜索的前10个模型的整体排名以及更深入的交叉验证模型选择方法
- en: '| Grid search rank | Cross-validation rank |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 网格搜索排名 | 交叉验证排名 |'
- en: '| --- | --- |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Model 0 | Model 2 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 模型 0 | 模型 2 |'
- en: '| Model 1 | Model 5 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 模型 1 | 模型 5 |'
- en: '| Model 2 | Model 1 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 模型 2 | 模型 1 |'
- en: '| Model 3 | Model 4 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 模型 3 | 模型 4 |'
- en: '| Model 4 | Model 12 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 模型 4 | 模型 12 |'
- en: '| Model 5 | Model 0 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 模型 5 | 模型 0 |'
- en: '| Model 6 | Model 21 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 模型 6 | 模型 21 |'
- en: '| Model 7 | Model 48 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 模型 7 | 模型 48 |'
- en: '| Model 8 | Model 30 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 模型 8 | 模型 30 |'
- en: '| Model 9 | Model 29 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 模型 9 | 模型 29 |'
- en: '| Model 10 | Model 17 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 模型 10 | 模型 17 |'
- en: The ranking for the grid search is on the left, while the ranking for the cross-validation
    approach is on the right. The first row in the table indicates that the third-best
    model in the grid search (indexed from 0, Model 2) was the best model in cross-validated
    ranking. The two model selection processes exhibit a Pearson correlation of 0.35,
    indicating only moderate positive correlation. In short, the best model derived
    from a grid search may not be the best model selected by more in-depth selection
    approaches. In fact, one interesting informal study used a similar technique to
    reveal [stability problems](https://oreil.ly/H6oRC) in data science competitions
    that used small datasets. This selection approach is a good way to start “leaning
    over backward” to increase the scientific integrity of ML model selection exercises.
    To see exactly how we did it, check out this chapter’s [code examples](https://oreil.ly/9nxyQ).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 表中的网格搜索排名在左侧，而交叉验证方法的排名在右侧。表的第一行指示网格搜索中排名第三的模型（从0开始索引，即模型2）在交叉验证排名中是最佳模型。这两种模型选择过程显示了0.35的Pearson相关系数，表明仅有中等正相关。简而言之，从网格搜索得出的最佳模型可能并非更深入的选择方法所选出的最佳模型。事实上，一个有趣的非正式研究使用了类似的技术来揭示在使用小数据集的数据科学竞赛中的[稳定性问题](https://oreil.ly/H6oRC)。这种选择方法是开始“全力以赴”以增强机器学习模型选择练习的科学完整性的好方法。要了解我们是如何做到的，请查看本章的[代码示例](https://oreil.ly/9nxyQ)。
- en: Another important consideration for model selection is business value. Building
    models costs money. Often, a lot of money. Our salaries, healthcare, retirement,
    snacks, coffee, computers, office space, and air-conditioning are not cheap. If
    we want our model to be a success, that often means recouping the resources used
    to train, test, and deploy the system. Though really understanding the value of
    our model requires [monitoring and measuring business value in real time](https://oreil.ly/tuMD8),
    we can use some tricks to estimate its value before we deploy.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 选择模型的另一个重要考虑因素是业务价值。建立模型需要花费大量资金。通常是很多钱。我们的薪水、医疗保健、退休金、零食、咖啡、计算机、办公空间和空调都不便宜。如果我们希望我们的模型取得成功，通常意味着要收回用于训练、测试和部署系统的资源。尽管真正理解我们模型的价值需要[实时监控和衡量业务价值](https://oreil.ly/tuMD8)，我们可以使用一些技巧在部署前估计其价值。
- en: To get started, we assign estimated monetary values to the outcomes from our
    model. For classifiers, this means assigning a monetary value to the elements
    of a confusion matrix. In [Figure 8-1](#business_value), we can see an illustration
    of a confusion matrix on the left and an illustration of a residual plot on the
    right.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，我们为模型的结果分配估计的货币价值。对于分类器来说，这意味着为混淆矩阵的元素分配一个货币价值。在[图 8-1](#business_value)中，我们可以看到左侧是混淆矩阵的示意图，右侧是残差图的示意图。
- en: '![mlha 0801](assets/mlha_0801.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![mlha 0801](assets/mlha_0801.png)'
- en: Figure 8-1\. Example assessment procedures with estimated monetary values for
    (a) classifiers and (b) regression models
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-1\. 示例评估程序，包括分类器(a)和回归模型(b)的估计货币价值
- en: The confusion matrix on the left can be applied to our selected model. We came
    up with the values in the cells by thinking through the model’s in vivo outcomes.
    A true positive for our model means we decided not to extend credit to someone
    who would have been delinquent on payments. There are no opportunity costs or
    write-offs, but also no positive revenue, associated with this outcome. A false
    positive results in us refusing to extend credit to someone who would have made
    payments—an opportunity cost. We associate that opportunity cost with an estimated
    customer lifetime value (LTV) of negative $23,000\. A false negative is the worst
    outcome. That means we extend credit to someone who did not pay. That is a write-off,
    and we estimate that value, based off of the mean of the customer credit limits
    (`LIMIT_BAL`), at about negative $85,000—ouch. A true negative is where we make
    money. That’s were the model says to extend credit to a paying customer. We associate
    that outcome with the opposite of a false positive, and we recoup the customer’s
    LTV for the credit product. For each true negative, we gain $23,000 in revenue.
    Now we have to add up these values for each customer in our validation set, as
    each customer will either represent a true positive, false positive, false negative,
    or true negative outcome. For our model, in the small portfolio represented by
    the validation set, that estimated value comes out to be $4,240,000\. So, there
    is real business value in our model, but it’s not eye-popping after one thinks
    through all the expenses and taxes associated with this revenue.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧的混淆矩阵可以应用于我们选择的模型。我们通过思考模型的体内结果得出了单元格中的值。对于我们的模型来说，真正的正面意味着我们决定不向那些可能会拖欠付款的人员提供信用。这种情况没有机会成本或注销，但也没有正面收入。假阳性导致我们拒绝向那些将会支付的人提供信用——这是一种机会成本。我们将这种机会成本与估计的客户终身价值（LTV）负$23,000联系起来。假阴性是最糟糕的结果。这意味着我们向未支付的人提供了信用。这是一种注销，我们估计这种价值基于客户信用额度（`LIMIT_BAL`）的平均值，约为负$85,000——痛苦。真阴性是我们赚钱的地方。这是模型建议我们向一个付款客户提供信用。我们将这种结果与假阳性相反联系起来，并为信用产品收回客户的LTV。对于每个真阴性，我们可以获得$23,000的收入。现在，我们必须为验证集中的每位客户加总这些值，因为每位客户将代表真正的正面、假阳性、假阴性或真阴性结果。对于我们的模型，在验证集所代表的小型投资组合中，该估算值为$4,240,000。因此，我们的模型确实有实际的业务价值，但在考虑所有相关的支出和税收后，并不是非常惊人。
- en: 'For regression models, we can assign a single value to overprediction and underprediction.
    Or, as illustrated in [Figure 8-1](#business_value), we can attempt to assign
    a monetary value to each residual unit in a logical manner for both over- and
    underprediction. Then we calculate the residuals for each row in our dataset and
    sum up the estimated value of the model. Once we assign monetary values, we can
    answer the basic business question: “Does this model provide any real value?”
    Now that we *think* we’ve selected a decent model, and one with some business
    value, let’s try to figure out what’s wrong with it, using sensitivity analysis.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归模型，我们可以为过度预测和低于预测分配一个单一的值。或者，如在[图8-1](#business_value)中所示，我们可以尝试以逻辑方式为过度和低于预测的每个残差单位分配一个货币价值。然后，我们计算数据集中每行的残差并总结模型的预估价值。一旦分配了货币价值，我们就可以回答基本的业务问题：“这个模型提供了任何真实价值吗？”既然我们*认为*我们选择了一个体面的模型，并且具有一些业务价值，让我们尝试使用敏感性分析找出其中的问题。
- en: Sensitivity Analysis for XGBoost
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: XGBoost的敏感性分析
- en: We’ll start putting our model through its paces with sensitivity analysis in
    this section. We’ve selected stress testing and adversarial example searches for
    detailed examples of sensitivity analysis in this chapter. Both techniques have
    direct applicability for a wide range of applications, and help to spot different
    kinds of problems. Stress testing looks for global weaknesses in our model across
    entire datasets in foreseeable stressful circumstances, like recessions. Adversarial
    example searches help us spot potential surprise issues, like wild predictions
    or security vulnerabilities, often on a local, row-by-row basis.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本节中通过敏感性分析开始对我们的模型进行全面测试。在本章中，我们选择了压力测试和对抗性示例搜索作为敏感性分析的详细示例。这两种技术对于广泛的应用具有直接适用性，并有助于发现不同类型的问题。压力测试寻找模型在整个数据集中的全局弱点，在可预见的压力情况下，如经济衰退。对抗性示例搜索帮助我们发现潜在的意外问题，如荒谬的预测或安全漏洞，通常是基于本地的逐行分析。
- en: Stress Testing XGBoost
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对XGBoost进行压力测试
- en: Linear models extrapolate linearly, but ML models can do almost anything on
    data outside their training domain. Unless we’re stress testing our models on
    the right data, we’re just not going to be aware of it. For instance, consider
    training a model on a dataset where the highest income of an individual is $200,000\.
    How would the model behave if it encounters an individual income of, let’s say,
    20 million dollars? Will it break? Will it return accurate results, or not? There’s
    no way to know this unless we test it explicitly. The basics are not hard. Simulate
    a row of data, put a 20 million dollar income in there, and run it back through
    our model to see how it behaves. When we do this more thoroughly and more systematically,
    we call it stress testing.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型进行线性外推，但ML模型在其训练领域之外的数据上几乎可以做任何事情。除非我们在正确的数据上对模型进行压力测试，否则我们将无法意识到这一点。例如，考虑在一个最高收入为20万美元的数据集上训练模型。如果模型遇到一个个人收入为2000万美元的情况，它会如何？它会崩溃吗？它会返回准确的结果吗？没有办法知道这一点，除非我们明确地进行测试。基础不难。模拟一行数据，放入2000万美元的收入，并通过我们的模型运行它，看看它的行为如何。当我们更彻底、更系统地进行这样的测试时，我们称之为压力测试。
- en: Warning
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Complex ML models often behave poorly when extrapolating outside of their training
    data domain, but even simpler models have problems with extrapolation. Tree-based
    models often cannot make predictions outside the ranges of training data, and
    polynomial models can suffer from [Runge’s phenomenon](https://oreil.ly/1Nabl)
    at the edges of their training data domains. We are taking a risk whenever we
    use standard statistical or ML models for predictions outside the domain of training
    data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂的ML模型在超出其训练数据领域进行外推时通常表现不佳，但即使是更简单的模型也存在外推问题。基于树的模型在训练数据范围之外往往无法进行预测，而多项式模型在其训练数据领域的边缘可能会受到[Runge现象](https://oreil.ly/1Nabl)的影响。每当我们在训练数据领域之外使用标准统计或ML模型进行预测时，都存在风险。
- en: Stress testing is an in silico exercise conducted to test the resilience of
    models under external, adverse, in vivo scenarios, like recessions or pandemics.
    The basic idea behind stress testing is to simulate data that represents realistic
    future scenarios and then redo traditional model assessment to see how the model
    performs. This ensures that the ML models can withstand the reasonably likely
    adverse developments they will encounter in the wild, and that they’re robust
    to inevitable in vivo variations in new data, commonly known as data and concept
    drift.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 压力测试是一种通过仿真数据来测试模型在外部、不利、体内场景（如经济衰退或大流行病）下抗性的仿真性锻炼。压力测试的基本思想是模拟代表现实未来情景的数据，然后重新进行传统模型评估，以查看模型的表现如何。这确保了ML模型能够抵御它们在野外可能遇到的相当可能的不利情况，并且能够应对新数据中不可避免的体内变化，通常称为数据和概念漂移。
- en: Data scientists often say they already validate their models against holdout
    datasets, so is there really a need for additional stress tests? Well, there is
    a need, and even more so when models will get deployed and affect people. An ML
    model with a perfect in silico AUC is of no use if it falters when it encounters
    common stressors in new data. When we deploy ML models in the real world, we have
    to think about more aspects and situations than simple in silico test error. Even
    though it is difficult to predict the future, we can use validation data to simulate
    foreseeable problems. We can then see how the model performs under these conditions,
    document any issues, and if possible, update our model to address any discovered
    issues.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家们经常说他们已经通过保留数据集验证了他们的模型，所以真的需要额外的压力测试吗？嗯，确实有需要，尤其是当模型将被部署并影响人们时更是如此。如果一个ML模型在遇到新数据中的常见压力时出现问题，那么拥有完美的仿真AUC的ML模型是毫无用处的。当我们在现实世界中部署ML模型时，我们必须考虑比简单的仿真测试错误更多的方面和情况。尽管预测未来很困难，但我们可以使用验证数据来模拟可预见的问题。然后我们可以看到模型在这些条件下的表现，记录任何问题，并在可能的情况下更新我们的模型以解决发现的任何问题。
- en: A gold standard for stress tests is the Federal Reserve’s Comprehensive Capital
    Analysis and Review (CCAR). It is an exercise conducted by the US Federal Reserve
    annually to ensure that large banks and financial institutions have adequate capital
    planning processes and maintain sufficient capital to withstand economic shocks.
    For instance, the CCAR conducted two separate tests to gauge the robustness of
    the big banks in the US in the wake of the COVID-19 pandemic. Even though the
    banks were well-capitalized under extreme simulated situations, [CCAR results
    still warranted restrictions](https://oreil.ly/RM-pS) on bank payouts due to uncertainty
    surrounding the situation. We’ll take inspiration from CCAR in the following subsections
    when trying to determine if our selected XGBoost model is robust to recession
    conditions, a common and foreseeable stressor for credit models.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 应力测试的黄金标准是美联储的综合资本分析与审查（CCAR）。这是美国联邦储备系统每年进行的一项练习，旨在确保大型银行和金融机构具有足够的资本规划过程，并保持足够的资本以抵御经济冲击。例如，CCAR在COVID-19大流行后进行了两次单独测试，以评估美国大银行的健壮性。尽管在极端模拟情况下这些银行资本充足，由于情况不确定，[CCAR结果仍要求对银行支付限制](https://oreil.ly/RM-pS)。在接下来的小节中，我们将从CCAR中汲取灵感，试图确定我们选定的XGBoost模型是否能够抵御经济衰退条件，这是信用模型常见且可预见的压力源。
- en: Stress Testing Methodology
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应力测试方法论
- en: A recession is a situation wherein there is a substantial decline in a country’s
    economy, lasting several months. Remember the financial crisis of 2008 and, more
    recently, the economic slowdown caused by the COVID pandemic? We want to see how
    our model might perform if a recession occurs while it is deployed. In this section,
    we’ll simulate a recession scenario and then reassess the performance of our constrained
    and regularized XGBoost model. As seen in [Figure 8-2](#ROC_curve_before_Stress_test),
    the model performs well on both the validation and holdout test data before the
    stress testing.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 经济衰退是一个国家经济大幅度下降的情况，持续数月。还记得2008年的金融危机以及最近由COVID大流行引起的经济放缓吗？我们想看看我们的模型在部署时如果发生经济衰退会表现如何。在本节中，我们将模拟经济衰退的情景，然后重新评估我们的受限和正则化的XGBoost模型的表现。如[图8-2](#ROC_curve_before_Stress_test)所示，该模型在应力测试前的验证和留置测试数据上表现良好。
- en: '![mlha 0802](assets/mlha_0802.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![mlha 0802](assets/mlha_0802.png)'
- en: Figure 8-2\. ROC curve before stress analysis on a constrained and regularized
    XGBoost model ([digital, color version](https://oreil.ly/48-em))
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-2\. 受限和正则化XGBoost模型在应力分析之前的ROC曲线（[数字，彩色版本](https://oreil.ly/48-em)）
- en: We’ll now create a copy of the original dataset and rename it as `data_reces⁠sion​_modified`.
    We’ll alter the values of some of the features in this dataset using basic economic
    and business intuitions, and should be able to emulate a recession scenario.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将创建原始数据集的副本，并将其重命名为`data_reces⁠sion​_modified`。我们将使用基本的经济和商业直觉改变这个数据集中某些特征的值，并应该能够模拟经济衰退的情景。
- en: Note
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意事项
- en: It’s difficult to simulate realistic out-of-distribution data, because it’s
    impossible to know in advance how each feature will co-vary in some new circumstance.
    For that reason, stress testing is an exercise best undertaken in close collaboration
    with subject matter experts. Even better than simulating stress test data would
    be to *back-test* the model on real data during adverse conditions, such as the
    2008 global recession.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 难以模拟真实的分布外数据，因为不可能预先知道每个特征在新情况下如何共变。因此，最好与学科专家密切合作进行应力测试。比模拟应力测试数据更好的是在不利条件下*回测*模型的实际数据，例如2008年的全球经济衰退。
- en: Altering Data to Simulate Recession Conditions
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修改数据以模拟经济衰退条件
- en: 'First, we’ll choose some of the observations in the dataset to modify. We take
    these observations to be the ones that would be affected by the recession—perhaps
    they or someone in their household will have lost their jobs. We choose to modify
    25% of customers who were previously in good standing:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将选择数据集中的一些观察结果进行修改。我们选择这些受影响的观察结果，可能是他们或家庭中的某人已经失去了工作。我们选择修改之前良好的25%的客户：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Assuming that the simulated recession has recently hit, we’ll assume that these
    observations have fallen behind on their most recent payments:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 假设最近模拟的经济衰退已经到来，我们将假设这些观察结果已经拖欠了他们最近的付款：
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here, `PAY_*` represents the various repayment statuses. Next, we’ll decrease
    the payment amount of the customers by one thousand dollars each:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`PAY_*`代表各种还款状态。接下来，我们将每位客户的支付金额减少一千美元：
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'During times of financial crisis, banks often tighten their purse strings,
    and one way to do that is by lowering credit limits. We’ll now incorporate this
    scenario in our stress test exercise by decreasing the credit limits of these
    affected customers, in a fixed proportion of their original credit limits:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融危机期间，银行经常收紧钱包的弦，其中一种方法是降低信用额度。我们现在将通过按照他们原始信用额度的固定比例降低受影响客户的信用额度，将此场景纳入我们的压力测试练习：
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We’ll also decrease the bill amounts of these customers by a fixed proportion,
    to simulate lower spending:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将按固定比例减少这些客户的账单金额，以模拟较低的消费：
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, we’ll assume that some proportion of these affected customers will
    go delinquent on their accounts. In particular, we’ll flip half of the target
    variables from zero to one:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们假设这些受影响客户中的一部分会拖欠账户。特别地，我们将把一半目标变量从零翻转为一：
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: After reintegrating the affected observations into the rest of the data, we
    have a dataset that mimics some of the adverse conditions our model might encounter
    in the real world. It is time to look at the performance metrics on this simulated
    data. In [Figure 8-3](#ROC_curve_after_Stress_test), we see a moderate decline
    in performance once recession-like data and concept drift is applied to test data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 将受影响的观察数据重新整合到其余数据中后，我们得到了一个数据集，模拟了我们的模型在真实世界中可能遇到的一些不利条件。现在是时候在这些模拟数据上查看性能指标了。在[图 8-3](#ROC_curve_after_Stress_test)中，我们看到一旦对测试数据应用类似经济衰退的数据和概念漂移，性能出现了适度的下降。
- en: '![mlha 0803](assets/mlha_0803.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![mlha 0803](assets/mlha_0803.png)'
- en: Figure 8-3\. ROC curve after stress analysis on a constrained and regularized
    XGBoost model ([digital, color version](https://oreil.ly/R46Oo))
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-3\. 受限制和正则化的 XGBoost 模型压力分析后的 ROC 曲线（[数字、彩色版本](https://oreil.ly/R46Oo)）
- en: The first step after encountering such results is to document them and share
    them with our team and management. This enables an informed decision to be made
    about whether to deploy the model. If economic conditions look rosy, then we might
    reasonably decide to deploy the model, with the knowledge that it will need to
    be refreshed quickly if economic conditions change. A more nuanced analysis would
    entail reassessing the financial risk we’d be taking on if our AUC were to drop
    from 0.777 to 0.738\. Can we afford to make that many additional wrong credit
    decisions?
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在遇到这些结果后的第一步是记录并与我们的团队和管理层分享它们。这使得可以基于信息做出是否部署模型的决策。如果经济状况看起来乐观，那么我们可能会合理地决定部署模型，但要知道，如果经济状况改变，模型需要迅速更新。更为细致的分析将涉及重新评估如果我们的AUC从0.777下降到0.738会承担的金融风险。我们能否承担因错误的信用决策增多而造成的损失？
- en: Once the results are documented and discussed with stakeholders, another next
    step might be to attempt to improve the model. This would definitely be the case
    if economic conditions are looking discouraging, or if the results of this or
    other stress tests were more dire. As readers might have guessed from the number
    of pages left in this chapter, we’re going to find other problems with this model
    soon. We’ll wait to remediate, or fix, all of the problems that we find until
    the end of the chapter.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦结果被记录并与利益相关者讨论，下一个步骤可能是尝试改进模型。如果经济情况看起来令人担忧，或者其他压力测试的结果更为严峻，那么这肯定会成为情况。正如读者可能已经从本章剩下的页数中猜到的那样，我们很快将发现这个模型的其他问题。我们将等待到本章结束前解决所有发现的问题。
- en: We’d also like to highlight one more thing before we move on to adversarial
    example searches. We were careful when we trained this model, using regularization,
    monotonic constraints, grid search, and a highly robust model selection approach.
    These decisions likely had a positive impact on the robustness of the model under
    the stress test. Models trained without these specifications may have performed
    worse during the stress test. Either way, if we’re not testing for problems that
    affect in vivo deployment, we’re just ignoring them.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续进行对抗性示例搜索之前，我们想再强调一件事情。在训练这个模型时，我们非常谨慎地采用了正则化、单调约束、网格搜索以及高度健壮的模型选择方法。这些决策很可能对模型在压力测试下的稳健性产生了积极的影响。没有这些规范训练的模型在压力测试中的表现可能会更差。无论如何，如果我们不测试影响现场部署的问题，我们就是在忽视它们。
- en: Adversarial Example Search
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对抗性示例搜索
- en: 'We’ll apply an adversarial example search as our next debugging technique.
    The goal of our search is two-fold: to find adversarial examples that could be
    used to trick our model once it’s deployed, and to see what we can learn about
    our model—good and bad—as a result of our search.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将采用对抗性示例搜索作为我们下一个调试技术。我们搜索的目标有两个：一是找到对抗性示例，可以在模型部署后用来欺骗我们的模型；二是通过我们的搜索了解我们的模型——无论是好是坏。
- en: There are lots of packages and software that can help us find adversarial examples
    for image data, but we need to find adversaries for structured data. While some
    progress has been made in using generative adversarial networks (GANs) and genetic
    algorithms to find adversaries for structured data, we’ll apply a heuristic approach
    instead. The first step is to find a row of data that will make a good initial
    guess for an adversarial example. We’ll do this with ICE plots. [Figure 8-4](#adv_ice)
    displays ICE curves across deciles of predicted probability along with partial
    dependence.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像数据，有许多包和软件可以帮助我们找到对抗性示例，但我们需要为结构化数据找到对抗者。虽然在使用生成对抗网络（GAN）和遗传算法来为结构化数据找到对抗者方面已经取得了一些进展，但我们将采用一种启发式方法。第一步是找到一行数据，作为对抗性示例的良好初始猜测。我们将通过ICE图来实现这一点。[图8-4](#adv_ice)显示了预测概率的十分位数上的ICE曲线以及部分依赖性。
- en: 'In [Figure 8-4](#adv_ice) we can see the ICE curve associated with the 80th
    percentile shows the largest swing in predicted values across the values of `PAY_0`.
    Because we know this row of data can lead to large changes in predictions just
    by changing the value of one feature, we’ll use the original row of data at the
    80th percentile of predicted probability in the selected model to seed our adversarial
    example search. In more detail, for each important variable our adversarial search
    heuristic goes as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图8-4](#adv_ice)中，我们可以看到与第80百分位相关联的ICE曲线显示出在`PAY_0`的值变化中预测值的最大摆动。因为我们知道这行数据可能会因为一个特征值的变化而导致预测值的大变化，所以我们将使用所选模型中预测概率第80百分位处的原始数据行来作为我们对抗性示例搜索的初始数据。更详细地说，对于每个重要变量，我们的对抗性搜索启发式方法如下：
- en: Calculate ICE curves at each decile of model predictions.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算模型预测的每个十分位数的ICE曲线。
- en: Find the ICE curve with the largest swing in predictions.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到预测摆动最大的ICE曲线。
- en: Isolate the row of data associated with this ICE curve.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分离与此ICE曲线相关联的数据行。
- en: 'For this row of data:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于这行数据：
- en: Perturb 1–3 additional important variables in the row. (It’s hard to plot results
    for more than 1–3 variables.)
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在行中扰动1至3个额外重要的变量。（对于超过1至3个变量的结果很难绘制。）
- en: Rescore the perturbed row.
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新评分扰动后的行。
- en: Continue until each additional important variable has cycled through its domain
    in the training data, and through missing or other interesting out-of-range values.
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续直到每个额外重要的变量在训练数据中循环完其域，并经历缺失或其他有趣的超出范围的值。
- en: Plot and analyze the results.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制和分析结果。
- en: '![mlha 0804](assets/mlha_0804.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![mlha 0804](assets/mlha_0804.png)'
- en: Figure 8-4\. Partial dependence and ICE of the selected XGBoost model ([digital,
    color version](https://oreil.ly/w0jkL))
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-4. 选定XGBoost模型的部分依赖性和ICE（[数字，彩色版本](https://oreil.ly/w0jkL)）
- en: 'We’ve already addressed steps 1–3, so how will we perform step 4? We’ll take
    advantage of `itertools.product()` to automatically generate all possible feature
    perturbations for a set of features supplied to a Python function. Also, remember
    that when working with the native XGBoost API, we always have to supply an extra
    argument (`iteration_range`) to the `predict()` function to apply model selection:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经解决了步骤1至3，那么我们如何执行步骤4呢？我们将利用`itertools.product()`自动生成一组特征的所有可能的特征扰动，以供Python函数使用。此外，请记住，在使用原生XGBoost
    API时，我们始终需要向`predict()`函数提供额外参数（`iteration_range`）来应用模型选择：
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We supplied the validation data and input features `PAY_0`, `PAY_2`, `PAY_AMT1`,
    and `PAY_AMT2` to the search code. The chosen input features were based on a Shapley
    summary plot that showed that these features have the widest spread of prediction
    contributions. The result of running this code on the selected inputs is data
    for several response surfaces that can be used to see how our model behaves in
    potentially interesting circumstances. The only thing left to do now is to plot
    and analyze these response functions. [Figure 8-5](#adv_search_2) shows the results
    of the adversarial example search, seeded by an ICE curve, and presents some positive
    and negative findings.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们向搜索代码提供了验证数据和输入特征 `PAY_0`、`PAY_2`、`PAY_AMT1` 和 `PAY_AMT2`。选择这些输入特征是基于一个 Shapley
    总结图，显示这些特征在预测贡献上具有最广泛的分布。在选定的输入上运行此代码的结果是几个响应表面的数据，可以用来查看我们的模型在可能有趣的情况下的行为。现在唯一剩下的事情是绘制和分析这些响应函数。[图 8-5](#adv_search_2)
    显示了对抗性示例搜索的结果，由 ICE 曲线引导，并呈现了一些积极和消极的发现。
- en: On the positive side, each response surface shows monotonicity. These simulations
    confirm that monotonic constraints, supplied at training time and based on domain
    knowledge, held up during training. On the negative side, a potential logical
    flaw was also discovered. According to one of the response surfaces, the example
    model will issue high probability of default predictions once customers become
    two months late on their most recent payment (`PAY_0`). The issue to be aware
    of is that denials are likely applied even in the circumstance where a customer
    repays (`PAY_AMT1`) over their credit limit. This potential logical flaw could
    prevent prepayment or overpenalize good customers who failed to pay their bill,
    say, while on vacation. While this behavior is not necessarily problematic, it’s
    definitely something model operators would like to know about. Therefore, we need
    to add it into our model documentation.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在积极的一面，每个响应表面都显示单调性。这些模拟确认了单调约束，在训练时提供并基于领域知识，仍然在训练期间持续存在。在消极的一面，还发现了一个潜在的逻辑缺陷。根据其中一个响应表面的说法，一旦客户最近支付（`PAY_0`）超过两个月，示例模型将会发出高违约概率的预测。需要注意的问题是，即使客户支付（`PAY_AMT1`）超过他们的信用额度，拒绝仍可能被应用。这种潜在的逻辑缺陷可能会阻止预付或对未能支付账单（例如在度假时）的良好客户进行过度处罚。虽然这种行为不一定有问题，但模型操作者肯定希望了解这一点。因此，我们需要将其添加到我们的模型文档中。
- en: Of course, there is the issue of the actual adversarial examples. Don’t worry,
    we found lots of those. We found many rows of data that can evoke low probabilities
    of default—around 5%—and plenty that can evoke high probabilities of default—around
    70%—and everything in between. We now have a complete set of adversarial examples
    to draw from that can create almost any probability of default we want from the
    model. If readers are wondering why this matters, see Chapters [5](ch05.html#unique_chapter_id_5)
    and [11](ch11.html#unique_chapter_id_11) on ML security. To see all the code and
    results details, check out this chapter’s [code examples](https://oreil.ly/9nxyQ).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，还有实际对抗性示例的问题。别担心，我们找到了很多这样的例子。我们找到了许多数据行，可以引发低违约概率——约5%——以及可以引发高违约概率——约70%——和介于两者之间的情况。我们现在有了一整套可以从中提取的对抗性示例，可以从模型中获得几乎任何我们想要的违约概率。如果读者想知道这为什么重要，请参阅第
    [5](ch05.html#unique_chapter_id_5) 和 [11](ch11.html#unique_chapter_id_11) 章关于机器学习安全性的内容。要查看所有的代码和结果详情，请查看本章的
    [代码示例](https://oreil.ly/9nxyQ)。
- en: Note
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Another favorite sensitivity analysis technique we want to highlight is a trick-of-the-trade
    that involves label shuffling:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要强调的另一种喜爱的敏感性分析技术是一种行业诀窍，涉及标签重排：
- en: Randomly shuffle the target feature and retrain the model.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机重排目标特征并重新训练模型。
- en: Recalculate feature importance.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新计算特征重要性。
- en: Consider removing features that are important for predicting a randomly shuffled
    target.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑移除那些对随机重排目标预测重要的特征。
- en: This helps us find and remove nonrobust features.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这帮助我们找到并移除非稳健特征。
- en: '![mlha 0805](assets/mlha_0805.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![mlha 0805](assets/mlha_0805.png)'
- en: Figure 8-5\. Adversarial example search shows model behavior in a number of
    scenarios ([digital, color version](https://oreil.ly/hlLzb))
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-5\. 对抗性示例搜索显示了模型在多种场景下的行为（[数字版，彩色版](https://oreil.ly/hlLzb)）
- en: When debugging, we always want to consider fixing the problems that we find.
    The logical issues around prepayment could likely be handled by business rules
    or model assertions. For instance, if a customer makes a large prepayment and
    lets the bank know that they are headed to a tropical island, subsequently issued
    probabilities of default could be decreased for a few months. As for the adversarial
    examples, the most effective adversarial rows could be recorded in model documentation
    with examples, so that future maintainers could understand these potential issues
    for the model. We could even discuss adversarial example attacks with our colleagues
    in security and consider monitoring for adversarial examples in real time.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在调试时，我们总是希望考虑解决我们发现的问题。围绕预付款周围的逻辑问题可能可以通过业务规则或模型断言来处理。例如，如果客户进行大额预付款并告知银行他们要前往热带岛屿，随后发出的违约概率可能会在几个月内降低。至于对抗性示例，最有效的对抗性行为可能会记录在模型文档中，并附有示例，以便将来的维护人员能够了解这些潜在的模型问题。我们甚至可以与安全团队的同事讨论对抗性示例攻击，并考虑实时监控对抗性示例。
- en: Residual Analysis for XGBoost
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: XGBoost 的残差分析
- en: 'We’ve now taken a look at local perturbations that can cause problems for our
    model using an adversarial example search, and at problematic global perturbations
    using stress testing. It’s time to move on to residual analysis. To do that, we’ll
    begin with something traditional: plotting residuals by each level of an important
    input feature. We’ll be on the lookout for the rows that cause the largest mistakes
    and any strong patterns in our residual plots. Then we’ll break our predictions
    down into segments and analyze performance across those segments. It’s not enough
    to understand how a model performs on average for high-risk use cases. We need
    to know how our model performs across important segments in our data. To finish
    off residual analysis, we’ll try to model our residuals with a decision tree.
    From that tree we’ll learn rules about how our model makes mistakes, and we can
    try to use those rules to avoid them. Time to start learning from our mistakes.
    Let’s look at some residuals.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经通过对抗性示例搜索查看了可能对我们模型造成问题的局部扰动，以及使用压力测试查看了问题性全局扰动。现在是时候转向残差分析了。为了做到这一点，我们将从传统方法开始：按重要输入特征的每个级别绘制残差图。我们将密切关注导致最大误差的行以及残差图中的任何强模式。然后，我们将将我们的预测分解为段，并分析这些段的性能。仅仅了解模型在高风险用例的平均表现是不够的。我们需要知道我们的模型在数据中重要段上的表现。为了完成残差分析，我们将尝试用决策树建模我们的残差。从那棵树上，我们将学习关于我们的模型如何出错的规则，并尝试使用这些规则来避免错误。是时候开始从我们的错误中学习了。让我们看看一些残差。
- en: Analysis and Visualizations of Residuals
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 残差的分析和可视化
- en: 'As highlighted in [Figure 8-1](#business_value), residuals can help us understand
    the business value—or lack thereof—of our model. They’re also a great way to learn
    technical details about how our model makes mistakes. We’ll be looking at logloss
    residuals for our model, as opposed to traditional residuals, because our model
    was trained using logloss. For most people, one of the easiest ways to start thinking
    through an ML model’s residuals is to plot them. In this subsection, we’ll start
    out by looking at the global logloss residuals for our selected model and then
    zoom in to the residuals for the most important input feature, `PAY_0`. In both
    cases, we’ll be looking to understand the drivers of our model’s mistakes and
    how, if at all, we can fix them. The first step to plotting residuals is, of course,
    to calculate them. We’re going to use logloss residuals—the type of error used
    during model training for the `binary:logistic` loss function in XGBoost. This
    way, remediating large residuals should have a direct effect on model training.
    To calculate our residuals, we’ll need the target and prediction values, as the
    following code block shows, and then we apply the standard formula for binary
    logloss:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在 [图 8-1](#business_value) 中突出显示的那样，残差可以帮助我们理解我们模型的业务价值——或者缺乏价值。它们也是了解我们模型如何犯错技术细节的好方法。我们将查看我们模型的对数损失残差，而不是传统残差，因为我们的模型是使用对数损失进行训练的。对于大多数人来说，开始思考
    ML 模型残差的最简单方法之一就是绘制它们。在本小节中，我们将首先查看我们选择的模型的全局对数损失残差，然后缩小到最重要的输入特征 `PAY_0` 的残差。在这两种情况下，我们将试图理解我们模型错误的驱动因素，以及我们是否可以修正它们。绘制残差的第一步当然是计算它们。我们将使用对数损失残差——这是
    XGBoost 中 `binary:logistic` 损失函数模型训练时使用的错误类型。因此，纠正大残差应直接影响模型训练。要计算残差，我们需要目标和预测值，如下代码块所示，然后应用二元对数损失的标准公式：
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: One small benefit of calculating residuals this way is that we can check that
    the mean residual value matches the logloss reported by XGBoost at the end of
    training to ensure we selected exactly the right size model when we generated
    our predictions. After passing that check, we can move on to plotting the residuals,
    which readers can see in [Figure 8-6](#global_resid). Note that [Figure 8-6](#global_resid)
    contains the feature `r_DELINQ_NEXT`. The logloss residual value is named `r_DELINQ_NEXT`,
    and `p_DELINQ_NEXT` is the prediction of the target, `DELINQ_NEXT`. Logloss residuals
    look a bit different from the typical regression residuals we might remember from
    statistics class. Instead of a random blob of points, we can see one curve for
    each outcome of the model; for `DELINQ_NEXT = 0`, it’s curving up and to the right,
    and for `DELINQ_NEXT = 1`, it’s curving toward the upper left. One of the first
    things that we can see in this plot is some large outlying residuals for both
    outcomes, but they are more numerous and extreme for `DELINQ_NEXT = 1`.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种计算残差的小好处是，我们可以检查平均残差值是否与 XGBoost 在训练结束时报告的对数损失匹配，以确保我们在生成预测时选择了完全正确的模型大小。通过通过了这个检查，我们可以继续绘制残差图，读者可以在
    [图 8-6](#global_resid) 中看到。注意 [图 8-6](#global_resid) 包含特征 `r_DELINQ_NEXT`。对数损失残差值命名为
    `r_DELINQ_NEXT`，`p_DELINQ_NEXT` 是目标 `DELINQ_NEXT` 的预测。对数损失残差看起来与我们在统计课上可能记得的典型回归残差有所不同。我们不是看到一个随机的点簇，而是看到模型每个结果的一条曲线；对于
    `DELINQ_NEXT = 0`，它向右上方弯曲，而对于 `DELINQ_NEXT = 1`，它朝着左上方弯曲。在这个图中，我们可以看到的第一件事是，对于两种结果，都有一些较大的异常残差，但对于
    `DELINQ_NEXT = 1`，它们更多且更极端。
- en: '![mlha 0806](assets/mlha_0806.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![mlha 0806](assets/mlha_0806.png)'
- en: Figure 8-6\. Logloss residuals for positive and negative responses for the selected
    XGBoost model ([digital, color version](https://oreil.ly/h5wnc))
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-6. 选定 XGBoost 模型的正面和负面响应的对数损失残差（[数字，彩色版本](https://oreil.ly/h5wnc))
- en: This pattern tells us that there are some customers in our validation data who
    miss payments, but our model *really* thinks they won’t. By sorting the validation
    data by the new `r_DELINQ_NEXT` column and looking at the largest residual rows,
    we can get an idea of what’s going on with these customers. So, who are these
    customers? It turns out they are good customers—with large credit limits and who
    always paid on time—who will miss their next payment. They’d surprise our model
    and cause huge residuals.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式告诉我们，在验证数据中有些客户拖欠款项，但我们的模型*真的*认为他们不会。通过按新列 `r_DELINQ_NEXT` 对验证数据进行排序，并查看最大残差行，我们可以了解这些客户的情况。那么，这些客户是谁呢？事实证明，他们是好客户——信用额度很大，并且总是按时付款的客户——他们会错过下一次付款。他们会让我们的模型感到惊讶，并导致巨大的残差。
- en: These results point to a fundamental flaw in our training data. We’re missing
    features that could help us understand more about a consumer’s financial life
    and why they might be late on payments. For example, the debt-to-income (DTI)
    ratio is often used in credit models. We might see an increase in a customer’s
    DTI ratio before they miss a payment. Without this kind of additional information,
    we have to recognize that we’ve discovered a serious limitation of our model.
    We just don’t have the columns we need to do better. Recognizing that with the
    available data, our model can be easily surprised, we might as well consider removing
    these rows from our training data, because they’re bringing useless noise into
    the training process. It might be a good idea to drop them, and similar individuals,
    because there’s not much we can learn from them as of now. We’d likely improve
    our validation and test performance, and we might train a more stable and reliable
    model.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果指出了我们训练数据的根本缺陷。我们缺少能帮助我们更多了解消费者金融生活及其为何可能逾期付款的特征。例如，债务收入比（DTI）在信用模型中经常使用。我们可能会看到客户逾期前的DTI比率增加。缺少这类额外信息，我们必须认识到我们发现了模型的严重局限性。我们没有所需的列来做得更好。在现有数据的情况下，我们的模型可能很容易受到惊吓，因此我们可以考虑从训练数据中删除这些行，因为它们为训练过程带来了无用的噪音。现在抛弃它们，和类似的个体，可能是个好主意，因为我们现在无法从中学到太多东西。我们可能会提高验证和测试性能，并可能训练一个更稳定和可靠的模型。
- en: 'Before we get rid of these points, let’s plot logloss residuals by each level
    of the most important feature `PAY_0`. If we see a more specific story or question
    in the initial analysis of global residuals, we should let that information guide
    which residuals to investigate next. Since we didn’t see information linking these
    individuals to any specific feature, we default to investigating the most important
    input feature. To do that, we’ll rely on the convenience of a Seaborn `FacetGrid`
    plot. The following code shows how to quickly break down the residuals by the
    levels of `PAY_0` and plot the residuals at each level in a neat grid:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们清理这些点之前，让我们通过每个最重要特征 `PAY_0` 的级别来绘制对数损失残差图。如果我们在全局残差的初始分析中看到了更具体的故事或问题，我们应该让这些信息指导我们下一步调查哪些残差。由于我们没有看到将这些个体与任何具体特征联系起来的信息，我们默认要调查最重要的输入特征。为此，我们将依赖
    Seaborn 的 `FacetGrid` 绘图功能。以下代码展示了如何通过 `PAY_0` 的各个级别快速分解残差，并在一个整洁的网格中绘制每个级别的残差：
- en: '[PRE10]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[Figure 8-7](#pay_0_resid) shows the logloss residuals for positive and negative
    outcomes across the 11 levels of `PAY_0` in the validation data. In general, we
    should be on the lookout for any strong patterns in the plots.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-7](#pay_0_resid) 显示了验证数据中 `PAY_0` 的 11 个水平的对数损失残差，针对正面和负面结果。总体而言，我们应该密切关注图表中的任何明显模式。'
- en: '![mlha 0807](assets/mlha_0807.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![mlha 0807](assets/mlha_0807.png)'
- en: Figure 8-7\. Customers with good payment track records who default suddenly
    cause large residuals, as do customers with poor payment track records who suddenly
    start paying on time ([digital, color version](https://oreil.ly/ubGpn))
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-7。拥有良好付款记录的客户突然违约会导致大额残差，与此同时，拥有较差付款记录的客户突然开始按时支付也会导致大额残差（[数字，彩色版](https://oreil.ly/ubGpn)）
- en: '[Figure 8-7](#pay_0_resid) reaffirms the story told by the global residuals,
    and adds some specifics. In the top row of [Figure 8-7](#pay_0_resid), favorable
    values for `PAY_0` (`-2`, `-1`, or `0`), representing paying on time or not using
    credit, are associated with large residuals for customers who default (`DELINQ_NEXT
    = 1`). These are some of those high-residual customers we saw in [Figure 8-6](#global_resid).
    In the bottom rows the exact opposite behavior is displayed. Customers with unfavorable
    values for `PAY_0` cause large residuals when they suddenly pay on time (`DELINQ_NEXT
    = 0`). What’s the lesson here? [Figure 8-7](#pay_0_resid) indicates that our ML
    model makes the same mistakes a human, or a simple business rule, would make.
    From [Chapter 6](ch06.html#unique_chapter_id_6), we know that this model is too
    reliant on `PAY_0`. Now we see one consequence of that pathology. If customers
    have favorable values for `PAY_0`, the model is shocked when they default. If
    customers have unfavorable values for `PAY_0`, the model is shocked if they pay.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-7](#pay_0_resid) 重新确认了全局残差所述的情况，并增加了一些具体细节。在[图 8-7](#pay_0_resid)的顶行中，对于`PAY_0`的有利值（`-2`，`-1`或`0`），代表按时付款或不使用信用的客户，与违约（`DELINQ_NEXT
    = 1`）的大残差相关联。这些是我们在[图 8-6](#global_resid)中看到的高残差客户之一。在底行中展示了完全相反的行为。当`PAY_0`的不利值客户突然按时付款（`DELINQ_NEXT
    = 0`）时，将会造成大残差。这里的教训是什么？[图 8-7](#pay_0_resid)表明我们的机器学习模型会犯和人类或简单的业务规则相同的错误。从[第六章](ch06.html#unique_chapter_id_6)我们知道，该模型过于依赖于`PAY_0`。现在我们看到了这种病态的一个后果。如果客户的`PAY_0`值有利，模型在他们违约时会感到震惊。如果客户的`PAY_0`值不利，模型在他们付款时会感到震惊。'
- en: 'This is problematic because we don’t need an ML model with hundreds of thousands
    of rules to make this kind of decision. Those thousands of rules hide a great
    deal of complexity, which in turn could be hiding bias or security problems. This
    model either needs to be substantially improved by collecting more columns of
    data and retraining it or we can consider replacing it with a more transparent
    and secure business rule: `IF PAY_0 < 2 THEN APPROVE, ELSE DENY`. Essentially
    the model needs more data—some new input column that could tell us about a customer’s
    financial stability outside the context of this credit account. Without this information,
    we are deploying an overly complex—and hence, unduly risky—pipeline to make what
    end up being simplistic decisions. We’ll attempt remediation in [“Remediating
    the Selected Model”](#remediating_selected_model_ch08_1680868845039), but before
    we do, let’s make sure this model isn’t hiding any other surprises. Next, we’ll
    perform segmented error analysis and look into any trouble spots in the model’s
    performance.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个问题，因为我们不需要一个有数十万条规则的机器学习模型来做出这种决定。这些成千上万的规则隐藏了大量的复杂性，而这反过来可能隐藏了偏见或安全问题。这个模型要么通过收集更多列的数据并重新训练来大幅改进，要么我们可以考虑用一个更透明和安全的业务规则替换它：`IF
    PAY_0 < 2 THEN APPROVE, ELSE DENY`。基本上，该模型需要更多的数据——一些新的输入列，可以告诉我们客户在这个信用账户之外的财务稳定情况。没有这些信息，我们部署了一个过于复杂——因此也过于风险的——管道来做最终是简单的决策。我们将在[“修复选定的模型”](#remediating_selected_model_ch08_1680868845039)中尝试纠正，但在此之前，让我们确保这个模型没有隐藏其他的意外。接下来，我们将进行分段错误分析，并查看模型性能中的任何问题点。
- en: Segmented Error Analysis
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分段错误分析
- en: Our selected model has a validation AUC of 0.78\. That’s a respectable AUC,
    and indicates that our model ranks negative and positive outcomes correctly about
    80% of the time in validation data. So, we’re good to deploy right? Well, we just
    saw how a more careful analysis of errors can reveal serious problems that simpler
    assessment statistics do not. And, unfortunately, we’re about to see that respectable
    top-level AUC doesn’t mean much either.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选定的模型在验证中的AUC为0.78。这是一个令人尊重的AUC，表明我们的模型在验证数据中大约80%的情况下正确排列负面和正面结果。那么，我们可以直接部署了吗？好吧，我们刚刚看到，对错误的更仔细分析可以揭示简单评估统计无法显示的严重问题。不幸的是，我们即将看到，尊重的顶级AUC也意味着不了了之。
- en: In [Table 8-2](#segmented_error_tab), we calculate many common binary classification
    performance and error metrics across all the levels of `PAY_0`. This technique
    is sometimes known as *segmented error analysis*. The basic idea is that different
    performance and error metrics tell us different information about the model. For
    example, a top-level AUC tells us about the model’s overall ability to rank customers
    correctly, and accuracy tells us about error rates at a specific probability threshold,
    whereas measures like true positive rate and false positive rate break accuracy
    down into more specific perspectives on correct and incorrect decisions. Moreover,
    we want to know this information about different segments in the modeled population.
    The best-performing models will exhibit reliable decision making across all the
    segments of the modeled population, not just for the largest segments in the data.
    When we’re dealing with a billion-dollar lending portfolio, those smaller segments
    still represent a large amount of money. In other high-risk applications, smaller
    segments might represent other important financial, criminal justice, or life-and-death
    decisions.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [表 8-2](#segmented_error_tab) 中，我们计算了所有 `PAY_0` 水平上许多常见的二元分类性能和错误指标。这种技术有时被称为
    *分段误差分析*。其基本思想是，不同的性能和错误指标告诉我们关于模型不同信息。例如，顶级的AUC告诉我们模型正确排列顾客的总体能力，准确率告诉我们在特定概率阈值下的错误率，而像真阳性率和假阳性率这样的指标则从更具体的角度分解了准确性，显示出正确和错误决策的不同视角。此外，我们希望了解所建模人群的不同细分信息。表现最佳的模型将在所建模人群的所有细分中表现出可靠的决策能力，而不仅仅是数据中最大的细分。当我们处理数十亿美元的贷款组合时，这些较小的细分仍然代表了大量资金。在其他高风险应用中，较小的细分可能代表其他重要的金融、刑事司法或生死决策。
- en: Note that the values we’ll calculate in [Table 8-2](#segmented_error_tab) arise
    from confusion matrices and can vary based on our selection of a probability threshold.
    The values are calculated using a threshold selected by maximizing the model’s
    F1 statistic. If we were to deploy this model, we should use the probability threshold
    used in the production pipeline. It’s our responsibility to make sure the model
    performs well in vivo, using several different metrics, for all the groups that
    are subject to the model’s decisions. This has serious ramifications for fairness
    as well, but we’ll tackle those in other chapters. For now, let’s dig into [Table 8-2](#segmented_error_tab).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意，我们将在 [表 8-2](#segmented_error_tab) 中计算的值源自混淆矩阵，并且可能根据我们选择的概率阈值而变化。这些值是使用最大化模型F1统计量所选择的阈值计算的。如果我们要部署这个模型，我们应该使用生产流水线中使用的概率阈值。我们有责任确保模型在
    vivo 中表现良好，使用多种不同的指标，适用于所有受到模型决策影响的群体。这对公平性有严重的影响，但我们将在其他章节中解决这些问题。现在，让我们深入研究
    [表 8-2](#segmented_error_tab)。  '
- en: Table 8-2\. Segmented error analysis table
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-2\. 分段误差分析表
- en: '| PAY_0 | Prevalence | Accuracy | True positive rate | Precision | Specificity
    | Negative predicted value | False positive rate | …​ | False negative rate |
    False omissions rate |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| PAY_0 | 患病率 | 准确率 | 真阳性率 | 精度 | 特异性 | 负预测值 | 假阳性率 | …​ | 假阴性率 | 错过率 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| –2 | 0.118 | 0.876 | 0.000 | 0.000 | 0.993 | 0.881 | 0.007 | …​ | 1.000 |
    0.119 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| –2 | 0.118 | 0.876 | 0.000 | 0.000 | 0.993 | 0.881 | 0.007 | …​ | 1.000 |
    0.119 |'
- en: '| –1 | 0.177 | 0.812 | 0.212 | 0.438 | 0.941 | 0.847 | 0.059 | …​ | 0.788 |
    0.153 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| –1 | 0.177 | 0.812 | 0.212 | 0.438 | 0.941 | 0.847 | 0.059 | …​ | 0.788 |
    0.153 |'
- en: '| 0 | 0.129 | 0.867 | 0.089 | 0.418 | 0.982 | 0.880 | 0.018 | …​ | 0.911 |
    0.120 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.129 | 0.867 | 0.089 | 0.418 | 0.982 | 0.880 | 0.018 | …​ | 0.911 |
    0.120 |'
- en: '| 1 | 0.337 | 0.566 | 0.799 | 0.424 | 0.448 | 0.814 | 0.552 | …​ | 0.201 |
    0.186 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.337 | 0.566 | 0.799 | 0.424 | 0.448 | 0.814 | 0.552 | …​ | 0.201 |
    0.186 |'
- en: '| 2 | 0.734 | 0.734 | 1.000 | 0.734 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.734 | 0.734 | 1.000 | 0.734 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
- en: '| 3 | 0.719 | 0.719 | 1.000 | 0.719 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.719 | 0.719 | 1.000 | 0.719 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
- en: '| 4 | 0.615 | 0.615 | 1.000 | 0.615 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.615 | 0.615 | 1.000 | 0.615 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
- en: '| 5 | 0.571 | 0.571 | 1.000 | 0.571 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 0.571 | 0.571 | 1.000 | 0.571 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
- en: '| 6 | 0.333 | 0.333 | 1.000 | 0.333 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 0.333 | 0.333 | 1.000 | 0.333 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
- en: '| 7 | 0.500 | 0.500 | 1.000 | 0.500 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 0.500 | 0.500 | 1.000 | 0.500 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
- en: '| 8 | 0.750 | 0.750 | 1.000 | 0.750 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 0.750 | 0.750 | 1.000 | 0.750 | 0.000 | 0.500 | 1.000 | …​ | 0.000 |
    0.500 |'
- en: Everything looks normal in [Table 8-2](#segmented_error_tab), until we hit the
    fifth row, where `PAY_0 = 2`. From there on, the table shows a serious problem,
    maybe even worse than the residuals plotted by `PAY_0` in the previous section.
    To be blunt, for `PAY_0 = 2` and above, this model doesn’t really work. For example,
    we observe a false positive rate of 1.0\. This means that the model is wrong about
    everyone who does not miss a payment—the model predicts that all of them will
    be late. Why might this be happening? The clearest reason is, again, the training
    data. In the residual plot, we saw that we might be missing some important input
    features. With segmented error analysis, we can now see that we may be missing
    some important *rows* of data too. We simply do not have enough people in the
    training data with `PAY_0 > 1` for the model to learn anything intelligent about
    them. Have a look back at some of the figures in [Chapter 6](ch06.html#unique_chapter_id_6)
    or look at [Figure 8-7](#pay_0_resid). There just aren’t many dots in the subfigures
    for `PAY_0 > 1`.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [表8-2](#segmented_error_tab) 中，一切看起来正常，直到我们到达第五行，其中 `PAY_0 = 2`。从那以后，表格显示出了一个严重的问题，甚至可能比前一节中
    `PAY_0` 所绘制的残差还要严重。坦率地说，对于 `PAY_0 = 2` 及以上，这个模型并不真正有效。例如，我们观察到了 1.0 的假阳性率。这意味着模型错误地预测了所有不逾期付款的人——模型预测所有这些人都会迟到。为什么会发生这种情况呢？最明显的原因再次是训练数据。在残差图中，我们看到可能漏掉了一些重要的输入特征。通过分段误差分析，我们现在可以看到，我们可能也错过了一些重要的*数据行*。在我们的训练数据中，`PAY_0
    > 1` 的人太少，以至于模型无法对他们学到任何有用的信息。回顾一下 [第6章](ch06.html#unique_chapter_id_6) 中的一些图表或查看
    [图8-7](#pay_0_resid)，我们会发现 `PAY_0 > 1` 的子图中几乎没有点。
- en: Warning
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Top-level or average error metrics can hide nasty problems. Always conduct segmented
    error analysis for high-risk applications.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 高层次或平均误差指标可能会掩盖严重的问题。对于高风险应用程序，始终进行分段误差分析。
- en: It’s pretty incredible what that 0.78 AUC can hide. We hope this example convinces
    readers of the importance of segmented error analysis. Readers might rightly be
    thinking about how to fix this problem. The most obvious answer is to wait to
    deploy this model until we can capture enough data about customers who miss payments
    to train a better model. If the model has to be deployed as-is, we’ll likely need
    human case workers to make denial decisions, at least for those customers with
    `PAY_0 > 1`. We’ll consider more strategies for remediation to close out the chapter,
    but before we do, we want to learn more about these patterns in the residuals
    we’ve found. Next, we’ll be fitting an interpretable model to our residuals to
    get some details about what’s behind these flaws in our model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 那个 0.78 的 AUC 能隐藏多少东西，真是令人难以置信。我们希望这个例子能说服读者重视分段误差分析的重要性。读者可能正在思考如何解决这个问题。最显而易见的答案是等到我们能够收集足够关于逾期付款客户的数据，以训练出更好的模型再部署这个模型。如果不得不按现状部署模型，我们可能需要人工案件工作者来做拒绝决策，至少对于那些
    `PAY_0 > 1` 的客户来说是这样。我们将考虑更多的补救策略来结束本章，但在此之前，我们希望更多了解我们发现的这些残差模式。接下来，我们将拟合一个可解释的模型到我们的残差中，以获取一些关于我们模型中这些缺陷背后的细节。
- en: Modeling Residuals
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型残差
- en: In [Chapter 6](ch06.html#unique_chapter_id_6), we used an interpretable decision
    tree to model our predictions based on input features to get a better idea about
    which input features were driving predictions and how. Now we’ll use the same
    approach to get some insight into what’s driving our residuals. If we’re noticing
    some overlap between explanation and debugging, that’s not a coincidence. One
    of the best uses for post hoc explanation is to aid in debugging efforts.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第6章](ch06.html#unique_chapter_id_6) 中，我们使用了一个可解释的决策树来基于输入特征建模我们的预测，以便更好地了解哪些输入特征驱动了预测以及如何驱动的。现在我们将使用相同的方法来深入了解驱动我们残差的因素。如果我们注意到解释和调试之间有一些重叠，这并非巧合。事后解释最好的用途之一就是帮助调试工作。
- en: We’ll use the following code to fit a four-level decision tree to our `DELINQ_NEXT
    = 0` and `DELINQ_NEXT = 1` residuals, separately. To fit this tree, we’ll use
    our original inputs as the tree inputs, but instead of training with `DELINQ_NEXT`
    as the target, we’ll train on the residuals, or `r_DELINQ_NEXT`. Once the tree
    is trained, we’ll then store an H2O MOJO (for *m*odel *o*b*j*ect, *o*ptimized).
    The MOJO contains a specialized function that can redraw our residual tree using
    Graphviz, an open source library for technical renderings. We can do something
    similar with several other packages, including scikit-learn.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下代码来将四级决策树拟合到我们 `DELINQ_NEXT = 0` 和 `DELINQ_NEXT = 1` 的残差中。为了拟合这棵树，我们将使用原始输入作为树的输入，但是不再将
    `DELINQ_NEXT` 作为目标进行训练，而是训练残差或 `r_DELINQ_NEXT`。一旦树训练完成，我们将存储一个 H2O MOJO（模型对象优化），MOJO
    包含一个专门的函数，可以使用 Graphviz 重新绘制我们的残差树，Graphviz 是一个用于技术绘图的开源库。我们可以使用几个其他包，包括 scikit-learn，做类似的事情。
- en: '[PRE11]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](assets/1.png)](#co_selecting_and_debugging_xgboost_models_CO1-1)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_selecting_and_debugging_xgboost_models_CO1-1)'
- en: Use only one tree.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 只使用一棵树。
- en: '[![2](assets/2.png)](#co_selecting_and_debugging_xgboost_models_CO1-2)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_selecting_and_debugging_xgboost_models_CO1-2)'
- en: Use all rows in that tree.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 使用树中的所有行。
- en: '[![3](assets/3.png)](#co_selecting_and_debugging_xgboost_models_CO1-3)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_selecting_and_debugging_xgboost_models_CO1-3)'
- en: Use all columns in that tree’s split search.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 使用树的分割搜索中的所有列。
- en: '[![4](assets/4.png)](#co_selecting_and_debugging_xgboost_models_CO1-4)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_selecting_and_debugging_xgboost_models_CO1-4)'
- en: Shallow trees are easier to understand.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 浅树更容易理解。
- en: '[![5](assets/5.png)](#co_selecting_and_debugging_xgboost_models_CO1-5)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_selecting_and_debugging_xgboost_models_CO1-5)'
- en: Set random seed for reproducibility.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可重复性，设置随机种子。
- en: '[![6](assets/6.png)](#co_selecting_and_debugging_xgboost_models_CO1-6)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_selecting_and_debugging_xgboost_models_CO1-6)'
- en: Cross-validation for stability, and the only way to get metrics for one tree
    in H2O.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 用于稳定性的交叉验证，以及在 H2O 中获取一个树指标的唯一方法。
- en: '[![7](assets/7.png)](#co_selecting_and_debugging_xgboost_models_CO1-7)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_selecting_and_debugging_xgboost_models_CO1-7)'
- en: Gives MOJO artifact a recognizable name.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为 MOJO 产物命名一个可识别的名称。
- en: Just as with our surrogate model for explanation purposes, there’s no fundamental
    theoretical guarantees that this model actually tells us what’s driving residuals.
    As always, we need to be careful and thoughtful. For this decision tree, we’ll
    calculate overall error metrics to make sure the tree actually fits the residuals.
    Because instability is a well-known failure mode for single decision trees, we’ll
    look at cross-validated error metrics to ensure the tree is stable too. It’s also
    important to keep in mind that if what’s driving residuals is outside the scope
    of the input features, this tree can’t tell us about it. We already know that
    some of the major issues in our model arise from data we don’t have, so we need
    to keep that in mind while analyzing the tree.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们用于解释目的的替代模型一样，实际上没有根本理论保证这个模型确实告诉我们驱动残差的原因。像往常一样，我们需要谨慎和深思熟虑。对于这棵决策树，我们将计算总体错误指标，以确保树确实适应残差。因为不稳定性是单一决策树的已知故障模式，我们将查看交叉验证的错误指标，以确保树也是稳定的。还需要牢记的是，如果驱动残差的原因超出了输入特征的范围，这棵树就无法告诉我们相关信息。我们已经知道我们模型中的一些主要问题源于我们没有的数据，因此在分析树时需要牢记这一点。
- en: '[Figure 8-8](#resid_model_2) displays the decision tree model of our ML model’s
    residuals for `DELINQ_NEXT = 0`, or customers who do not miss an upcoming payment.
    While it reflects what was discovered in [Figure 8-7](#pay_0_resid), it does so
    in a very direct way that exposes the logic of the failures. In fact, it’s even
    possible to build programmatic rules about when the model is likely to fail the
    worst based on this tree.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-8](#resid_model_2) 显示了我们 ML 模型对于 `DELINQ_NEXT = 0` 的残差的决策树模型，即不会错过即将到期付款的客户。虽然它反映了
    [图 8-7](#pay_0_resid) 中发现的内容，但它以一种非常直接的方式展示了失败逻辑。事实上，根据这棵树，甚至可以建立关于模型何时可能在最坏情况下失败的程序规则。'
- en: Tracing from the top of the tree, to the largest average residual value at the
    bottom of the tree, [Figure 8-8](#resid_model_2) shows that the largest residuals
    for negative decisions occur when `PAY_0 >= 1.5 AND PAY_3 >= 1.0 AND BILL_AMT3
    < 2829.50 AND PAY_6 >= 0.5`. This means, as we saw in [Figure 8-7](#pay_0_resid),
    when a customer has questionable repayment over months and small bill amounts,
    the model is shocked when they make their next payment. Now we’ve narrowed this
    down to the specific customers that cause the worst residuals on average, and
    have a business rule to define the situation of highest concern.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 从树顶部开始追踪，到树底部的最大平均残余值，[图 8-8](#resid_model_2)显示，在`PAY_0 >= 1.5 AND PAY_3 >=
    1.0 AND BILL_AMT3 < 2829.50 AND PAY_6 >= 0.5`的情况下，负面决策的最大残余发生。这意味着，正如我们在[图 8-7](#pay_0_resid)中看到的那样，当客户在几个月内有疑问的还款和较小的账单金额时，当他们做下一个付款时，模型会感到震惊。现在我们已经缩小到引起平均最差残余的具体客户，并且有一个业务规则来定义最令人担忧的情况。
- en: '![mlha 0808](assets/mlha_0808.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![mlha 0808](assets/mlha_0808.png)'
- en: Figure 8-8\. A decision tree showing model’s residuals, revealing patterns that
    can be used to spot failure modes and design mitigation approaches
  id: totrans-184
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-8\. 显示模型残余的决策树，揭示可以用来发现故障模式并设计缓解方法的模式
- en: 'In general, this residual modeling technique helps uncover failure modes. Once
    failure modes are known, they can often be mitigated to increase performance and
    safety. If the group of customers causing the largest residuals in [Figure 8-8](#resid_model_2)
    can be isolated from patterns that result in missing payments, this can lead to
    precise remediation strategies in the form of business rules (or model assertions).
    If a customer presents themselves to our model with `PAY_0 >= 1.5 AND PAY_3 >=
    1.0 AND BILL_AMT3 < 2829.50 AND PAY_6 >= 0.5` characteristics, maybe we shouldn’t
    just assume they will default. We could consider adjusting this cohort of customers’
    default probability down with a business rule or sending their credit decision
    along for more nuanced consideration from a human case worker. So far, debugging
    has uncovered a major issue with our model. Our model did not have the right training
    data, neither columns nor rows, and it’s easily surprised in common and important
    decision-making scenarios. Aside from collecting or simulating better data, we’ve
    now found one potential remediation tactic: business rules that flag when we are
    about to make a bad decision that can be used to take some action to mitigate
    that bad decision. In the next section, we’ll close out the chapter by discussing
    further remediation activities.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，这种残留建模技术有助于发现故障模式。一旦了解了故障模式，通常可以采取措施来提高性能和安全性。如果能够将导致[图 8-8](#resid_model_2)中最大残余的客户群体与导致逾期支付模式隔离开来，这可能会导致通过商业规则（或模型断言）的精确修复策略。如果客户以`PAY_0
    >= 1.5 AND PAY_3 >= 1.0 AND BILL_AMT3 < 2829.50 AND PAY_6 >= 0.5`的特征出现在我们的模型中，也许我们不应该仅仅假设他们会违约。我们可以考虑通过商业规则调整这些客户群体的违约概率，或者将他们的信用决策送交给人工案件工作者进行更加细致的考虑。到目前为止，调试已经发现了我们模型的一个重大问题。我们的模型没有正确的训练数据，无论是列还是行，它在常见且重要的决策情境中很容易受到惊吓。除了收集或模拟更好的数据外，我们现在找到了一个潜在的补救策略：当我们即将做出错误决策时，使用业务规则进行标记并采取行动以减轻该错误决策。在接下来的部分中，我们将通过讨论进一步的补救活动来结束这一章节。
- en: Note
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Post hoc explanation techniques, such as interpretable surrogate models, are
    often most useful as model debugging tools.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 后续解释技术，如可解释的替代模型，通常作为模型调试工具最有用。
- en: Remediating the Selected Model
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修复所选模型
- en: 'Despite using monotonic constraints and regularization, despite a careful grid
    search and strenuous model selection tests, and despite really wanting to train
    a good model, we simply trained a bad model that shouldn’t be deployed. In addition
    to insufficient training data, recall that we found this model:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用了单调约束和正则化，尽管进行了仔细的网格搜索和严格的模型选择测试，尽管真的希望训练一个好模型，我们仍然训练了一个不应该部署的糟糕模型。除了训练数据不足外，回想一下，我们发现这个模型：
- en: Pathologically overemphasizes a customer’s most recent repayment status (`PAY_0`)
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 病态地过分强调客户的最近还款状态（`PAY_0`）
- en: Exhibits logical errors that could preclude prepayment or negatively affect
    high net worth customers
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在可能排除预付或对高净值客户产生负面影响的逻辑错误
- en: Could be vulnerable to adversarial example attacks
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能对敌对示例攻击有脆弱性
- en: Performed poorly for `PAY_0 > 1`
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`PAY_0 > 1`的表现不佳
- en: While we’ll address each of these issues separately, together they conspired
    to make a seemingly passable ML model potentially less appealing than a simple
    business rule, at least for the authors. Because many ML models are not adequately
    debugged before deployment, it’s likely that we could find ourselves with similar
    bugs to handle if we applied the debugging techniques in this chapter to one of
    our organization’s models. Whether our team would try to fix this model or head
    back to the drawing board, it’s going to be important to think through how to
    solve the problems that sensitivity and residual analysis uncovered. In other
    words, these problems have to be remediated before this, or a similar model, is
    deployed. For the example data and model, several techniques could be applied
    to remediate the highlighted bugs.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们将分别解决每一个问题，但它们共同合谋，使看似合格的机器学习模型比简单的业务规则可能更不吸引人，至少对于作者来说是这样。因为许多机器学习模型在部署前未经充分调试，所以如果我们将本章节的调试技术应用于我们组织的一个模型，很可能会发现自己需要处理类似的错误。无论我们的团队是否尝试修复这个模型或重新开始设计，都很重要思考如何解决敏感性和残余分析揭示的问题。换句话说，在部署此模型或类似模型之前，这些问题必须得到解决。对于示例数据和模型，可以应用多种技术来解决突出的错误。
- en: The training data presents both the easiest and hardest remediation options.
    The solution is clear. Implementing the solution takes common sense and hard work.
    Collect more and better training data. Use experimental design techniques to inform
    data collection and selection. Use causal discovery techniques to select input
    features that actually affect the prediction target. Consider simulating data
    where necessary.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据呈现了最简单和最困难的补救选项。解决方案很明确。实施解决方案需要常识和努力。收集更多和更好的训练数据。使用实验设计技术来指导数据收集和选择。使用因果发现技术选择实际影响预测目标的输入特征。如有必要，考虑模拟数据。
- en: Note
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Often, the best thing we can do to improve the performance of our ML system
    is to collect more and higher-quality data.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 常常，我们改善机器学习系统性能的最佳方法是收集更多和更高质量的数据。
- en: For the rest of the identified issues, let’s try to address them one by one
    as an example of how we would take on these bugs at our job. We’ll put special
    focus on the overemphasis of `PAY_0`, as it has the most readily apparent training-
    and coding-oriented mitigants, and then proceed to the other identified failure
    modes.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其余的已识别问题，让我们试着逐一解决它们，作为我们在工作中处理这些错误的示例。我们将特别关注过度强调 `PAY_0`，因为它在训练和编码方面有最明显的缓解措施，然后继续处理其他已识别的故障模式。
- en: Overemphasis of PAY_0
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过度强调 PAY_0
- en: 'Perhaps the biggest problem with our selected model, and many other ML models,
    is bad training data. In this case, training data should be augmented with new,
    relevant features to spread the primary decision-making mechanisms within the
    model across more than one feature. One strategy to improve stability and generalization
    is to introduce a new feature that summarizes a customer’s spending behavior over
    time to expose any potential financial instability: the standard deviation of
    a customer’s bill amounts over six months, `bill_std`. Pandas has a one-liner
    for calculating standard deviations for a set of columns.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 或许我们选定的模型，以及许多其他机器学习模型，最大的问题是糟糕的训练数据。在这种情况下，训练数据应该通过新的相关特征进行扩充，以将模型内的主要决策机制分散到不止一个特征上。一种提高稳定性和泛化能力的策略是引入一个新特征，概括客户的长期消费行为，以暴露任何潜在的财务不稳定性：客户账单金额六个月内的标准差，`bill_std`。Pandas
    提供了一行代码来计算一组列的标准差。
- en: '[PRE12]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Along the same lines, we could also create a new feature, `pay_std`, containing
    information about payment status, except the most recent one (we don’t want to
    overemphasize `PAY_0` again):'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 沿着同样的思路，我们也可以创建一个新特征，`pay_std`，包含关于支付状态的信息，除了最近的一个（我们不想再次过度强调 `PAY_0`）：
- en: '[PRE13]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Noise injection to corrupt `PAY_0` could also be used to mitigate overemphasis,
    but only if there are other accurate signals available in better training data.
    We’ll randomize the `PAY_0` column, but only where `PAY_0` is either equal to
    0, 1, or 2\. This type of corruption is akin to strong regularization. We really
    want to force the model to pay attention to other features.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声注入以破坏 `PAY_0` 也可以用于减轻过度强调，但仅在更好的训练数据中有其他准确的信号可用时。我们将随机化 `PAY_0` 列，但只在 `PAY_0`
    等于 0、1 或 2 时。这种类型的破坏类似于强正则化。我们真的希望迫使模型注意其他特征。
- en: '[PRE14]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: After taking these steps to deemphasize `PAY_0` in the training data, we retrain
    our model. The resultant SHAP summary plot ([Figure 8-9](#de-emphasizing_PAY_0))
    shows that we have been able to deemphasize the `PAY_0`. It’s been moved way down
    from the top spot in the summary plot and replaced by `PAY_2`, and our new engineered
    features appear higher in importance than `PAY_0`. We also observe a slight decrease
    in the AUC, which now stands at 0.7501, from the original 0.7787.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在采取这些步骤弱化训练数据中的`PAY_0`之后，我们重新训练我们的模型。结果的SHAP摘要图（[图8-9](#de-emphasizing_PAY_0)）显示我们已经成功地减弱了`PAY_0`。它已经从摘要图中的首位移开，并被`PAY_2`取代，我们的新工程特征显得比`PAY_0`更重要。我们还观察到AUC轻微下降，现在为0.7501，原来为0.7787。
- en: '![mlha 0809](assets/mlha_0809.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![mlha 0809](assets/mlha_0809.png)'
- en: Figure 8-9\. Shapley values for each input variable after deemphasizing `PAY_0`
    ([digital, color version](https://oreil.ly/H6zU9))
  id: totrans-208
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-9. 在弱化`PAY_0`之后的每个输入变量的Shapley值（[数字，彩色版本](https://oreil.ly/H6zU9)）
- en: 'Now for the hard part: is this a better model? The overall AUC, often relied
    on for picking a “good” classifier, has decreased. First of all, we already saw
    that in silico AUC doesn’t mean very much. Secondly, a decrease in test metrics
    is almost assured when we change a model. ML training ruthlessly optimizes against
    some chosen criterion and then tends to select the best model by that same criterion
    in validation data. If we fiddle with that process, we’re likely to see a worsening
    of those selected in silico test metrics.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是难点：这是一个更好的模型吗？总体AUC，通常用于选择“好”的分类器，已经降低。首先，我们已经看到体外AUC并没有多大意义。其次，当我们改变模型时，测试指标的下降几乎是肯定的。机器学习训练无情地优化某些选择的标准，然后倾向于根据同样的标准在验证数据中选择最佳模型。如果我们调整这个过程，我们很可能会看到所选的体外测试指标恶化。
- en: Note
  id: totrans-210
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: Remediation is likely to make our model look worse, according to test data statistics.
    That’s OK. There is no statistic that truly predicts real-world performance. So
    long as remediation is based on solid domain knowledge, we can sacrifice some
    in silico performance in test data to deploy a more parsimonious model in vivo.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 修复工作很可能会根据测试数据统计使我们的模型看起来更糟。这没关系。没有统计数据能真正预测实际表现。只要修复基于扎实的领域知识，我们就可以在测试数据中牺牲一些体外性能，以部署更节俭的模型。
- en: 'The only way to know if this model is better is to debug it again and consult
    with domain experts. While this may be disappointing, it’s a truth that’s always
    been known. There’s no statistic that foretells amazing in vivo performance, not
    yet anyway. Good models have always needed debugging and domain expertise to function
    properly in the real world. Now, let’s continue to make our model better by looking
    into the remaining problems we identified while debugging: logical errors, security
    vulnerabilities, and poor performance for `PAY_0 > 1`.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 确定这个模型是否更好的唯一方法是再次调试它并与领域专家进行咨询。虽然这可能令人失望，但这是一个一直以来就已知的事实。没有统计数据可以预测惊人的体内性能，至少目前还没有。好的模型总是需要调试和领域专业知识才能在实际世界中正常运行。现在，让我们继续通过查找我们在调试过程中确定的其余问题来改进我们的模型：逻辑错误、安全漏洞以及对`PAY_0
    > 1`的性能不佳。
- en: Miscellaneous Bugs
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 杂项错误
- en: 'We’ll get to other technical remediation approaches soon, but let’s consider
    experimental design issues briefly here. To address the misalignment between treating
    ML models like engineering projects focused on in silico test error versus experiments
    focused on in vivo outcomes, we should try update our workflow to more closely
    align with the traditional scientific method:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快会考虑其他技术修复方法，但让我们在这里简要考虑实验设计问题。为了解决处理机器学习模型时像工程项目一样关注体外测试错误与实验关注体内结果之间的不一致性，我们应尝试更新我们的工作流程，以更紧密地与传统科学方法对齐：
- en: Develop a credible hunch (e.g., based on prior experiments or literature review).
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发展一个可信的直觉（例如，基于先前的实验或文献综述）。
- en: Record our hypothesis (i.e., the intended real-world outcome of our ML system).
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记录我们的假设（即，我们的机器学习系统的预期实际效果）。
- en: Collect appropriate data (e.g., using design of experiment approaches).
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集适当的数据（例如，使用实验设计方法）。
- en: 'Test the hypothesis that the ML system has the intended in vivo effect on a
    treatment group, using methods like:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试假设，即机器学习系统对治疗组的预期体内效果，使用诸如
- en: A/B testing to understand the effect of model outcomes on an informal treatment
    group.
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: A/B测试以了解模型结果对非正式治疗组的影响。
- en: '[Coarsened exact matching](https://oreil.ly/jEf8O) to construct control and
    treatment groups from collected observational data and test for statistically
    significant treatment effects of the model.'
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[粗糙的精确匹配](https://oreil.ly/jEf8O)来构建来自收集的观测数据的控制和处理组，并测试模型的统计显著处理效果。'
- en: If we’re doing a bunch of trial-and-error work with unexplainable models and
    with strong doses of confirmation bias and funding bias leading the way—as many
    ML projects are today—then we’re likely going to be surprised about how our model
    performs once it’s deployed. (Remember the quote from Google’s research group
    at the beginning of the chapter?) There’s no tech fix for a cultural lack of scientific
    rigor. And as of today, a great deal of ML is still an experimental science, not
    rote engineering tasks. [Chapter 12](ch12.html#conclusion) explores issues with
    data science and the scientific method in more depth.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们正在进行一系列带有不可解释模型的试验和大量的确认偏见和资金偏见，正如今天许多机器学习项目所做的那样，那么我们在模型部署后可能会对其表现感到惊讶（请记住章节开头的谷歌研究小组的引言？）。对于文化上缺乏科学严谨性，没有技术可以修复。截至今日，大部分机器学习仍然是实验性科学，而不是机械化的工程任务。[第12章](ch12.html#conclusion)更深入地探讨了数据科学和科学方法中的问题。
- en: Warning
  id: totrans-222
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: We often think of the experiment we’re doing as picking the best algorithm.
    But it really should be about the in vivo outcomes experienced by users, customers,
    or subjects of the system.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常把我们正在进行的实验看作是选择最佳算法。但实际上，它应该关注用户、客户或系统主体的体验中的体内结果。
- en: Fixing serious data and methodological errors would likely have had a positive
    effect on logical errors, security vulnerabilities, and general poor performance
    in our model. In the following list, we look at some more direct fixes that might
    work better in contemporary data science workflows too. We’ll close out the section
    with a brief discussion of calibration. Calibration of predictions to past known
    outcomes is another broad fix that’s based in common sense.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 修复严重的数据和方法错误很可能对逻辑错误、安全漏洞和我们模型的总体表现有积极的影响。在以下列表中，我们将探直接的修复措施，这些措施在当代数据科学工作流中可能效果更好。我们将在本节中以简要讨论校准来结束。将预测结果校准到过去已知的结果，是另一种基于常识的广泛修复方法。
- en: Logical errors
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑错误
- en: For the logical errors that cause a high probability of default to be issued,
    even after very large payments are made, model assertions or business rules are
    a likely solution. For customers who just recently became two-month delinquent,
    use a model assertion or business rule to check if a large payment was also made
    recently before posting the adverse default prediction. A residual model like
    the one in [Figure 8-8](#resid_model_2), focused on that small group of customers,
    could help suggest or refine more targeted assertions or rules.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 对于   对于出现高概率违约的逻辑错误，即使在进行了非常大额度的付款后，模型断言或业务规则也是一个可能的解决方案。对于刚刚逾期两个月的客户，可以使用模型断言或业务规则来检查是否最近也有大额付款，然后发布不利的违约预测。像[图 8-8](#resid_model_2)中的残差模型，专注于这一小部分客户，可以帮助提出或完善更具针对性的断言或规则。
- en: Security vulnerabilities
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 安全漏洞
- en: We found the model is easily manipulated with adversarial examples. In general,
    best practices like API throttling and authentication, coordinated with real-time
    model monitoring, help a lot with ML security (see [Chapter 5](ch05.html#unique_chapter_id_5)).
    What may also be applied for this model is data integrity constraints or monitoring
    for random or simulated data, i.e., anomaly detection. Essentially, this model
    may require an extra bit of monitoring that checks for anomalies, such as on-time
    most recent payment (`PAY_0 = 1`) and being six months late on the second most
    recent payment (`PAY_2 = 6`). If anomalous data is identified in the scoring queue,
    using anything from isolation forest algorithms to logical data integrity constraints,
    that data should be routed for closer inspection before a credit decision is made.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现该模型很容易受到对抗性示例的影响。通常，像API限流和认证这样的最佳实践，结合实时模型监控，对机器学习安全性有很大帮助（见[第5章](ch05.html#unique_chapter_id_5)）。对于这个模型可能适用的还有数据完整性约束或监控随机或模拟数据的方法，即异常检测。基本上，这个模型可能需要额外的监控，检查异常数据，例如及时最近支付（`PAY_0
    = 1`）和第二最近支付拖欠六个月（`PAY_2 = 6`）。如果在评分队列中发现异常数据，应该使用隔离森林算法或逻辑数据完整性约束等方法，将这些数据路由到更近一步的检查之前做出信用决策。
- en: Poor performance for `PAY_0 > 1`
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '`PAY_0 > 1` 的表现不佳'
- en: Like many of the other problems with our selected model, this model needs better
    data to learn more about customers who end up defaulting. In the absence of this
    information, observation weights, oversampling, or simulation could be used to
    increase the influence of the small number of customers who did miss payments.
    Also, the model’s monotonic constraints are one of the best mitigants to try when
    faced with sparse training data. The monotonic constraints enforce well-understood
    real-world controls on the model. Yet, model performance for `PAY_0 > 1` is extremely
    poor even with these constraints. Predictions in this range may have to be handled
    by a more specialized model, a rule-based system, or even human case workers.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 和我们选定模型的其他问题一样，这个模型需要更好的数据来更好地了解最终违约的客户。在没有这些信息的情况下，可以使用观察权重、过采样或模拟来增加那些确实错过付款的少数客户的影响力。此外，当面对稀疏训练数据时，模型的单调约束是尝试的最佳缓解措施之一。单调约束对模型强加了深入理解的现实世界控制。然而，即使有这些约束条件，对于`PAY_0
    > 1`的模型性能也非常糟糕。这个范围内的预测可能需要由更专门的模型、基于规则的系统或甚至人工案例工作者来处理。
- en: Calibration of predictions to past known outcomes is another traditional remediation
    approach that would likely have improved many attributes of our model. Calibration
    means that our model’s probabilities are linked to past known outcomes—essentially
    meaning that when our model issues a prediction of, say, 0.3, customers in the
    training data, like the customer that caused that prediction, do actually default
    about 30% of the time in validation or test data. We can use plots and the Brier
    score to detect calibration issues and rescale output probabilities to remediate
    them. The [probability calibration](https://oreil.ly/LP9nf) module in scikit-learn
    has good information and functionality to get started with calibrating binary
    classifiers.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 预测与过去已知结果的校准是另一种传统的纠正方法，可能会改善我们模型的许多属性。校准意味着我们模型的概率与过去已知的结果相关联——基本上意味着当我们的模型发出例如0.3的预测时，在验证或测试数据中像导致该预测的客户一样，实际上约30%的时间会违约。我们可以使用图表和Brier分数来检测校准问题，并重新调整输出概率以进行纠正。scikit-learn中的[概率校准](https://oreil.ly/LP9nf)模块具有良好的信息和功能，可帮助开始校准二元分类器。
- en: Conclusion
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'Readers might be able to think of other ways to fix our poor example model,
    and that’s great. The key is to try debugging the next time we train a model.
    In many ways, ML is just like other code. If we’re not testing it, we aren’t somehow
    magically avoiding bugs. We’re ignoring bugs. Debugging is crucially important
    in all software exercises—from operating systems to ML models. While we can use
    unit, integration, and functional testing to catch software bugs in ML, those
    often don’t help us detect and isolate math and logic issues. This is where ML
    is different from other code: it uses sophisticated mathematical optimization
    to make decisions, and it can be hard to find those kinds of bugs.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 读者可能能想到其他方法来修复我们的糟糕示例模型，这很好。关键是在下次训练模型时尝试调试。在很多方面，机器学习就像其他代码一样。如果我们不测试它，我们并没有以某种神奇的方式避免错误。我们只是忽视了错误。在所有软件练习中，调试都至关重要——从操作系统到机器学习模型。虽然我们可以使用单元测试、集成测试和功能测试来捕捉机器学习中的软件错误，但这些通常无法帮助我们检测和隔离数学和逻辑问题。这就是机器学习与其他代码不同之处：它使用复杂的数学优化来做出决策，很难找到这类错误。
- en: In this chapter, we used sensitivity and residual analysis to find several ML
    bugs in what appeared to be a decent model. We bemoaned the lack of information
    in the training data, took a stab at fixing one of the worst issues, and presented
    other options for remediation. If we were to get this far at our jobs, we’d still
    not be done. The model would at least still have to be monitored. Finding and
    fixing bugs, and running those fixes by domain experts, does decrease the chances
    of an incident. But it doesn’t guarantee a perfect model. (Nothing does, and if
    you find something, please tell us!) Moreover, as the old saying goes, the road
    to hell is paved with good intentions. It’s [been documented](https://oreil.ly/A6UK2)
    that trying to fix bias problems in ML models can make bias problems worse. The
    same is likely true of remediating bugs for performance reasons. The only way
    to know our model actually works in deployment is to monitor it in deployment.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用敏感性和残差分析来查找看似不错的模型中的几个机器学习错误。我们对训练数据中信息的不足感到惋惜，尝试修复了其中一个最严重的问题，并提出了其他解决方案。如果我们在工作中能够达到这一步，我们的工作还远未结束。模型至少仍需监控。查找和修复错误，并将这些修复方案提交给领域专家，确实会减少事故发生的机会。但这并不能保证一个完美的模型（没有任何东西可以保证，如果你找到了，请告诉我们！）。此外，正如古老的谚语所说，通往地狱的道路铺满了善意。已经有记录表明，试图修复机器学习模型中的偏见问题可能会使偏见问题变得更加严重。出于性能原因进行缓解错误的做法可能也是如此。唯一确定我们的模型在部署中实际有效的方法是在部署中对其进行监控。
- en: This is all a lot of extra work compared to how ML models are tested currently,
    but testing ML for deployment is very different from testing a model for publication—which
    is what most of us were taught in school and on the job. Papers don’t directly
    make decisions about people’s lives, and papers generally don’t have security
    vulnerabilities. The way we were taught to assess models in school just isn’t
    sufficient for in vivo deployments. We hope the techniques explored in this chapter
    will empower readers to find ML bugs, fix them, and make better models.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 与当前机器学习模型测试方式相比，这些额外工作量都很大，但为了部署测试机器学习模型，与学校和工作中教导我们的评估模型发布的方式完全不同。论文不会直接决定人们生活，而论文通常不会有安全漏洞。我们在学校里学习的评估模型的方式对于体内部署并不足够。我们希望本章探讨的技术能够赋予读者发现机器学习错误、修复错误并创建更好模型的能力。
- en: Resources
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: Code Examples
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 代码示例
- en: '[Machine-Learning-for-High-Risk-Applications-Book](https://oreil.ly/machine-learning-high-risk-apps-code)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[面向高风险应用的机器学习书籍](https://oreil.ly/machine-learning-high-risk-apps-code)'
- en: Model Debugging Tools
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 模型调试工具
- en: '[drifter](https://oreil.ly/Pur4F)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[漂移者](https://oreil.ly/Pur4F)'
- en: '[manifold](https://oreil.ly/If0n5)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[流形](https://oreil.ly/If0n5)'
- en: '[mlextend](https://oreil.ly/j27C_)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[mlextend](https://oreil.ly/j27C_)'
- en: '[PiML](https://oreil.ly/7QLK1)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PiML](https://oreil.ly/7QLK1)'
- en: '[SALib](https://oreil.ly/djeTQ)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SALib](https://oreil.ly/djeTQ)'
- en: '[What-If Tool](https://oreil.ly/1n-Fl)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[What-If工具](https://oreil.ly/1n-Fl)'
- en: ^([1](ch08.html#idm45990005370304-marker)) Keep in mind that large US banks
    perform near-exhaustive stress tests for their models each year in accordance
    with the Federal Reserve’s [Comprehensive Capital Analysis and Review](https://oreil.ly/rczyU)
    process, known as CCAR.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch08.html#idm45990005370304-marker)) 请记住，大型美国银行每年都会按照联邦储备委员会的[全面资本分析和审查](https://oreil.ly/rczyU)（CCAR）流程进行几乎彻底的压力测试。
