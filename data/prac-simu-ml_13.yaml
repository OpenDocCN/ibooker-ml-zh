- en: Chapter 11\. Working with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 11 章。使用 Python 进行工作
- en: In this chapter, we’re going to explore the possibilities for using Unity’s
    ML-Agents together with Python, in a more active way. Everything we’ve done so
    far has focused on the combination of Unity and (by way of ML-Agents) Python,
    but we’ve taken a Unity-centric approach.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探索更多使用 Unity 的 ML-Agents 与 Python 结合的可能性。迄今为止，我们所做的一切都集中在 Unity 和（通过
    ML-Agents）Python 的组合上，但我们采取了 Unity 为中心的通过 ML-Agents）Python 的组合上，但我们采取了以 Unity
    为中心的方法。
- en: This chapter is going to present a few ways you can do things from a Python-centric
    approach. Specifically, we’ll look at how you can use Python to interact with
    Unity and ML-Agents.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍几种从 Python 中心化方法完成任务的方式。具体来说，我们将探讨如何使用 Python 与 Unity 和 ML-Agents 交互。
- en: Python All the Way Down
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 无处不在
- en: We’ve been using Python throughout the book, but we’re also using a script that
    runs the training and connects it to Unity. PyTorch is also being used deep under
    the hood to do the training. Beyond that, though, it’s not really relevant that
    we’re using Python. It just happens to be Python that powers the scripts we’re
    running. It could be anything.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在整本书中一直在使用 Python，但我们还使用了一个运行训练并将其连接到 Unity 的脚本。深层次来看，PyTorch 也被用于训练。除此之外，并不重要我们使用的是
    Python。碰巧我们运行的脚本是由 Python 提供支持的。这可能是任何语言。
- en: In this chapter, we’ll experiment more with Python and get a handle on the capabilities
    generated by combining Python with ML-Agents, beyond the provided scripts. We’ll
    prove that it’s actually Python you’re using when you run `mlagents-learn` to
    train an agent, and look beyond the provided scripts a little bit.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将更多地使用 Python，并掌握将 Python 与 ML-Agents 结合生成的能力，超越提供的脚本。我们将证明，当您运行 `mlagents-learn`
    来训练一个代理时，实际上是在使用 Python，并稍微超出提供的脚本。
- en: 'The environment we’ll spend most of our time poking at in this chapter, via
    Python, is called the GridWorld environment. It’s a simple 3x3 grid, where the
    agent is a blue square that needs to touch a green +, and not touch a red x. It
    uses an exclusively visual observation system: a camera pointed down at the grid.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将主要探讨 Python 中的 GridWorld 环境，这是一个简单的 3x3 网格，代理是一个蓝色的正方形，需要触碰绿色的 + 号，但不能触碰红色的
    x 号。它采用纯视觉观测系统：一个朝向网格的摄像头。
- en: 'Its actions are one of five discrete options:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 它的动作是五个离散选项之一：
- en: Do nothing
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么也不做
- en: Move up
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向上移动
- en: Move down
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向下移动
- en: Move right
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向右移动
- en: Move left
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向左移动
- en: The agent is rewarded with `1.0` if it touches the goal (green plus sign), and
    penalized with `-1.0` if it touches the red x. There’s an existential penalty
    of `-0.01` for every step.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果代理触碰到目标（绿色加号），奖励`1.0`，如果触碰到红色 x，惩罚`-1.0`。每步还会有一个存在惩罚`-0.01`。
- en: You can see what the GridWorld looks like in [Figure 11-1](#fig:gridworld_env).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [图 11-1](#fig:gridworld_env) 中看到 GridWorld 的样子。
- en: '![psml 1101](assets/psml_1101.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![psml 1101](assets/psml_1101.png)'
- en: Figure 11-1\. The GridWorld, a digital frontier
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-1。GridWorld，数字前沿
- en: Experimenting with an Environment
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 尝试环境
- en: To work with Python, naturally you’ll need to set up a new Python environment.
    This is almost exactly the same as the Python environment we worked on all the
    way back in [“Setting Up”](ch02.html#ch02-setup), with a few small differences.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Python，自然需要设置一个新的 Python 环境。这几乎与我们在[“设置”](ch02.html#ch02-setup)中使用的 Python
    环境完全相同，只有一些小的区别。
- en: 'To get ready, you’ll need to do the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备好，您需要完成以下步骤：
- en: Set up a new Python environment, per [“Setting Up”](ch02.html#ch02-setup).
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照 [“设置”](ch02.html#ch02-setup) 中的说明，设置一个新的 Python 环境。
- en: 'Once it’s configured to those specifications, install a few extra things. First,
    install matplotlib:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置完成后，按照以下规格安装一些额外的内容。首先，安装 matplotlib：
- en: '[PRE0]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We’ll use matplotlib to show some images on the screen as we explore Python
    and ML-Agents. It’s beyond the scope of this book to discuss matplotlib in detail,
    but if you search O’Reilly’s Learning Platform, or DuckDuckGo, you’ll find *plenty*
    of material. There’s also a [website](https://matplotlib.org).
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将使用 matplotlib 在屏幕上展示一些图像，同时探索 Python 和 ML-Agents。这本书不涵盖 matplotlib 的详细讨论，但如果你搜索
    O'Reilly 的学习平台或 DuckDuckGo，会有大量资料。还有一个[网站](https://matplotlib.org)。
- en: 'Next, install Jupyter Lab:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，安装 Jupyter Lab：
- en: '[PRE1]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And fire up Jupyter Lab:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点   启动 Jupyter Lab：
- en: '[PRE2]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Jupyter Lab is a tool for creating “notebooks,” which allow you to execute Python
    in a form that’s easy to run and write. It’s commonly used for scientific computing,
    and you might have been exposed to it as Jupyter Notebooks, IPython, or Google’s
    branded version, Google Colab.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Jupyter Lab 是一个创建“笔记本”的工具，它允许您以易于运行和编写的形式执行 Python。它通常用于科学计算，您可能已经接触过它，例如 Jupyter
    Notebooks、IPython 或 Google 的品牌版本 Google Colab。
- en: Once it’s running, create an empty notebook, as shown in [Figure 11-2](#fig:Python-jupyter).
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦运行，创建一个空白的笔记本，如 [图 11-2](#fig:Python-jupyter) 所示。
- en: '![psml 1102](assets/psml_1102.png)'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1102](assets/psml_1102.png)'
- en: Figure 11-2\. The empty Jupyter notebook
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-2\. 空白的 Jupyter 笔记本
- en: That’s it.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。
- en: 'Next, we’re going to start coding, and we’ll explain what’s up as we go:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将开始编码，并且我们将在进行时解释情况：
- en: 'Right away, we need to import ML-Agents:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 立即，我们需要导入 ML-Agents：
- en: '[PRE3]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This brings the Python-based ML-Agents package into our notebook.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将在我们的笔记本中引入基于 Python 的 ML-Agents 软件包。
- en: 'Next, we’re going to import `matplotlib.pyplot`, so we can display plots:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将导入 `matplotlib.pyplot`，这样我们就可以显示绘图：
- en: '[PRE4]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And we’ll tell `matplotlib` that we want it to be displayed `inline`:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们告诉 `matplotlib` 我们希望它内联显示：
- en: '[PRE5]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This makes sure `matplotlib` will display images inline, within the notebook.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这确保 `matplotlib` 将在笔记本中内联显示图像。
- en: 'Now we ask ML-Agents for its default registry:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们要询问 ML-Agents 它的默认注册表：
- en: '[PRE6]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This provides a database of prebuilt Unity environments (called the [“Unity
    Environment Registry”](https://oreil.ly/pDNML)), based on the ML-Agents examples.
    These environments can be used to experiment with the Python API without having
    to build out an environment to a binary, or run Unity at the same time.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这提供了一个预构建的 Unity 环境数据库（称为[“Unity 环境注册表”](https://oreil.ly/pDNML)），基于 ML-Agents
    的示例。这些环境可用于通过 Python API 进行实验，而无需将环境构建为二进制文件，也无需同时运行 Unity。
- en: 'With the default registry imported, we can take a quick look to see what we’ve
    got:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入默认注册表后，我们可以快速查看我们得到了什么：
- en: '[PRE7]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If you run your notebook at this point (using the Run menu → Run all cells),
    you’ll see a list of environments, as shown in [Figure 11-3](#fig:Python-envs.png).
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您此时运行笔记本（使用“运行”菜单 → 运行所有单元格），您将看到一个环境列表，如 [图 11-3](#fig:Python-envs.png) 所示。
- en: '![psml 1103](assets/psml_1103.png)'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1103](assets/psml_1103.png)'
- en: Figure 11-3\. The list of environments
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-3\. 环境列表
- en: 'Next, we’re going to load one of the provided environments:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将加载其中一个提供的环境：
- en: '[PRE8]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This will load the GridWorld environment from the default environments.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将从默认环境中加载 GridWorld 环境。
- en: 'With the GridWorld environment loaded, the first thing we want to do is ask
    for the behavior:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 载入 GridWorld 环境后，我们首先要做的是询问其行为：
- en: '[PRE9]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This gets a handle on the behavior of the environment (corresponding to the
    Behavior Parameters component attached to the agent in the environment), and prints
    its name and team ID (which will be 0, because the environment doesn’t use teams).
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这会获取环境行为的处理（对应于环境中附加到代理的“行为参数”组件），并打印其名称和团队 ID（因为环境不使用团队，所以团队 ID 将为 0）。
- en: 'Next, we’ll find out how many observations it has:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将找出它有多少观察结果：
- en: '[PRE10]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And we’ll take a look to see if it has any visual observations:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着我们将查看是否有视觉观察：
- en: '[PRE11]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We’ll also check how many continuous and discrete actions there are:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还将检查连续和离散动作的数量：
- en: '[PRE12]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And we’ll check the options on the discrete branches:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将检查离散分支的选项：
- en: '[PRE13]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can run the notebook again to get a bit of information about it. You should
    see something like [Figure 11-4](#fig:Python-behaviors.png).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以再次运行笔记本以获取有关其的一些信息。您应该会看到类似于 [图 11-4](#fig:Python-behaviors.png) 的内容。
- en: '![psml 1104](assets/psml_1104.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![psml 1104](assets/psml_1104.png)'
- en: Figure 11-4\. Exploring the environment
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-4\. 探索环境
- en: 'Next, we’ll step through the environment:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们将按步骤执行环境：
- en: 'First, we’ll store the number of steps from the environment:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将存储环境中的步骤数：
- en: '[PRE14]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We’ll set the actions for the agent’s behavior, passing in the behavior we
    want to use, and a tensor of dimension 2:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将设置代理行为的动作，传入我们想要使用的行为和一个维度为 2 的张量：
- en: '[PRE15]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, we’ll move the simulation forward by one step:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将使仿真向前推进一步：
- en: '[PRE16]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'With the simulation stepped once, it’s time to take a look at what it can see.
    First, we’ll check for any visual observations:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仿真推进一次后，现在是时候看看它能看到什么了。首先，我们将检查是否有任何视觉观察：
- en: '[PRE17]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This will grab the first visual observation from one of the agents in the environment
    and display it using `matplotlib`.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将从环境中的一个代理获取第一个视觉观察，并使用 `matplotlib` 显示它。
- en: 'Next, we’ll check for any vector observations:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将检查任何向量观察：
- en: '[PRE18]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Running the notebook at this point should result in an image of the agent’s
    first visual observation, as shown in [Figure 11-5](#fig:Python-visualob.png).
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此时运行笔记本应该会显示代理的第一个视觉观察图像，如[图11-5](#fig:Python-visualob.png)所示。
- en: '![psml 1105](assets/psml_1105.png)'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1105](assets/psml_1105.png)'
- en: Figure 11-5\. The first visual observation
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-5\. 第一个视觉观察
- en: 'Now we’ll step the environment through three episodes:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将使环境通过三个情节：
- en: '[PRE19]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Run the entire notebook again, and you should see some familiar-looking training
    information, as shown in [Figure 11-6](#fig:Python-training.png).
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次运行整个笔记本，您应该看到一些看起来熟悉的训练信息，如[图11-6](#fig:Python-training.png)所示。
- en: '![psml 1106](assets/psml_1106.png)'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1106](assets/psml_1106.png)'
- en: Figure 11-6\. Training in a notebook
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-6\. 笔记本中的训练
- en: 'Finally, close the environment:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，关闭环境：
- en: '[PRE20]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: What Can Be Done with Python?
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用Python？
- en: The `mlagents` Python package we’re using is the same package that’s used to
    drive the `mlagents-learn` script we’ve been using to train agents in simulations.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的`mlagents` Python包与我们用来在模拟中训练代理的`mlagents-learn`脚本相同。
- en: Tip
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: It’s out of scope, and thoroughly unnecessary, for this book to explore the
    entirety of the `mlagents` Python API. There’s a lot in there, and we’re just
    here to give you the highlights in a tutorial form. But if you’re curious, you
    can find all the `mlagents` Python API documentation [online](https://oreil.ly/7O0h3).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本书来说，探索`mlagents` Python API的全部内容是超出范围并且完全不必要的。里面有很多东西，我们只是在这里以教程形式为您介绍亮点。但如果您感兴趣，可以在[在线文档](https://oreil.ly/7O0h3)中找到所有`mlagents`
    Python API的文档。
- en: You can use the Python API to control, interact with, and get information from
    a Unity simulation environment. This means you could use it to develop entirely
    custom training and learning algorithms, instead of relying on the provided algorithms
    (which you use via the `mlagents-learn` script).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Python API来控制、与Unity模拟环境交互并获取信息。这意味着您可以开发完全定制的训练和学习算法，而不是依赖通过`mlagents-learn`脚本使用的提供的算法。
- en: Later, in [Chapter 12](ch12.html#ch12-Beyond), we’ll look at connecting Unity-built
    simulation environments to the OpenAI Gym.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后，在[第12章](ch12.html#ch12-Beyond)中，我们将探讨如何将Unity构建的模拟环境连接到OpenAI Gym。
- en: Using Your Own Environment
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用您自己的环境
- en: You can, of course, use your own environment instead of one of the Unity-provided
    examples from the registry.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您可以使用自己的环境，而不是Unity提供的注册表中的示例之一。
- en: 'Before you can use your own environment, you’ll need to build it. We’ll build
    one of Unity’s example projects, the GridWorld we used earlier, as an example:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用您自己的环境之前，您需要构建它。我们将建立Unity的一个示例项目，即我们之前使用过的GridWorld，作为一个示例：
- en: Open the ML-Agents Unity project that comes as part of the ML-Agents GitHub
    Repository, as shown in [Figure 11-7](#fig:Python-project.png).
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开作为ML-Agents GitHub仓库一部分的ML-Agents Unity项目，如[图11-7](#fig:Python-project.png)所示。
- en: '![psml 1107](assets/psml_1107.png)'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1107](assets/psml_1107.png)'
- en: Figure 11-7\. The project in the ML-Agents repository
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-7\. ML-Agents存储库中的项目
- en: Once you’re in the project, open the GridWorld scene from the Project pane,
    as shown in [Figure 11-8](#fig:Python-projpanegridworld.png).
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您进入项目，从项目面板中打开GridWorld场景，如[图11-8](#fig:Python-projpanegridworld.png)所示。
- en: '![psml 1108](assets/psml_1108.png)'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1108](assets/psml_1108.png)'
- en: Figure 11-8\. The GridWorld scene
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-8\. GridWorld场景
- en: To simplify things, select and delete all the numbered areas from the Hierarchy
    view, as shown in [Figure 11-9](#fig:Python-numberedareas.png).
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为简化操作，请选择并从层次结构视图中删除所有编号区域，如[图11-9](#fig:Python-numberedareas.png)所示。
- en: '![psml 1109](assets/psml_1109.png)'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1109](assets/psml_1109.png)'
- en: Figure 11-9\. The areas you’ll need to delete
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-9\. 您需要删除的区域
- en: These are duplicates of the main area used to speed up training by training
    multiple agents at once. Because we’ll be experimenting with this environment
    in Python, we only want the one area.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些是用于通过同时训练多个代理以加快训练速度的主区域的副本。因为我们将在Python中尝试这个环境，所以我们只想要一个区域。
- en: Next, open the Player settings via the Edit menu → Project Settings → Player.
    Find the Resolution and Presentation section, as shown in [Figure 11-10](#fig:Python-settings.png),
    and check Run in Background. Close the Player settings.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，通过编辑菜单 → 项目设置 → 玩家打开玩家设置。找到分辨率和呈现部分，如[图11-10](#fig:Python-settings.png)所示，并选中“在后台运行”。关闭玩家设置。
- en: '![psml 1110](assets/psml_1110.png)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1110](assets/psml_1110.png)'
- en: Figure 11-10\. The Player settings
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-10\. 玩家设置
- en: Open the Build settings from File → Build Settings, as shown in [Figure 11-11](#fig:Python_scenestobuild).
    Choose the platform you want to run this on (we’re using a MacBook Pro for our
    screenshots), and make sure the GridWorld scene is the only scene checked in the
    list.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开文件菜单中的“构建设置”从 File → Build Settings，如 [图 11-11](#fig:Python_scenestobuild)
    所示。选择您要在其上运行此程序的平台（我们在 MacBook Pro 上进行截图），并确保 GridWorld 场景是列表中唯一选中的场景。
- en: Tip
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: If the list of scenes is empty, only the currently open scene will be built.
    That’s also fine.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果场景列表为空，则只会构建当前打开的场景。这也没关系。
- en: '![psml 1111](assets/psml_1111.png)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1111](assets/psml_1111.png)'
- en: Figure 11-11\. The Build settings
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-11\. 构建设置
- en: Click the Build button, and save the resulting output to a path you’re familiar
    with, as shown in [Figure 11-12](#fig:Python-savebuild.png).
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击构建按钮，并将结果输出保存到您熟悉的路径，如 [图 11-12](#fig:Python-savebuild.png) 所示。
- en: Note
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: On macOS, the saved output will be a standard *.app* file. On Windows, the output
    will be a folder that contains an executable.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 macOS 上，保存的输出将是一个标准的 *.app* 文件。在 Windows 上，输出将是一个包含可执行文件的文件夹。
- en: '![psml 1112](assets/psml_1112.png)'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1112](assets/psml_1112.png)'
- en: Figure 11-12\. Choosing where the build goes
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-12\. 选择构建位置
- en: Unity will build the environment, as shown in [Figure 11-13](#fig:Python-building.png).
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Unity 将构建环境，如 [图 11-13](#fig:Python-building.png) 所示。
- en: '![psml 1113](assets/psml_1113.png)'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![psml 1113](assets/psml_1113.png)'
- en: Figure 11-13\. The build occurring
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-13\. 构建正在进行
- en: Completely Custom Training
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完全自定义训练
- en: Because the Python package is, effectively, just an API to control the processes
    occurring within the Unity simulation environment, we can actually use it to replace
    the training processes supplied by the `mlagents-learn` script. In this section,
    we’re going to take a quick look at an example largely based on one of Unity’s
    examples.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 Python 包实际上只是一个 API，用来控制 Unity 模拟环境中发生的进程，我们实际上可以用它来替换 `mlagents-learn` 脚本提供的训练过程。在本节中，我们将快速查看一个主要基于
    Unity 示例之一的示例。
- en: Before we get started, you’ll need a Python environment set up, as per [“Setting
    Up”](ch02.html#ch02-setup). Once you’ve done that, make sure Jupyter Lab is running,
    and you’re ready to continue.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，您需要设置好 Python 环境，如 [“设置”](ch02.html#ch02-setup) 所述。完成后，请确保 Jupyter Lab
    正在运行，并准备继续。
- en: In this example, we’re going to once again use Unity’s GridWorld example environment,
    and instead of training it using one of the training algorithms supplied in Unity,
    we’ll train it using Q-learning. Q-learning is a model-free reinforcement learning
    algorithm that is designed to learn the value of actions for particular states.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将再次使用 Unity 的 GridWorld 示例环境，而不是使用 Unity 提供的训练算法之一来训练它，而是使用 Q-learning
    进行训练。Q-learning 是一种无模型的强化学习算法，旨在学习特定状态下行动的价值。
- en: Tip
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The “model-free” aspect of Q-learning refers to the way Q-learning does not
    require a model of the environment. Everything relates to states and actions,
    rather than a specific understanding of the environment. PPO, the standard algorithm
    employed by Unity ML-Agents, is also model-free. Exploring the specifics of [Q-learning](https://oreil.ly/4UjqA)
    is beyond the scope of this book, however.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Q-learning 的“无模型”方面指的是 Q-learning 不需要环境的模型。一切都与状态和动作相关，而不是对环境特定理解的具体模型。Unity
    ML-Agents 使用的标准算法 PPO 也是无模型的。探索 [Q-learning](https://oreil.ly/4UjqA) 的具体细节超出了本书的范围。
- en: We’re going to jump-start the process here by supplying some code, since there’s
    a fair bit of it. Locate the `PracticalSims_CustomTraining.ipynb` notebook in
    the resources you downloaded for the book, and load it into Jupyter Lab.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里通过提供一些代码来启动这个过程，因为代码有点多。在您下载的书籍资源中找到 `PracticalSims_CustomTraining.ipynb`
    笔记本，并将其加载到 Jupyter Lab 中。
- en: 'Let’s take a look at what the code in this notebook does:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这个笔记本中的代码都做了些什么：
- en: The `import` statements bring in `mlagents`, as usual, as well as `torch` (PyTorch),
    and some Python `math` and `typing` (Python’s type hinting library), as well as
    `numpy`.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入语句引入了 `mlagents`，如往常一样，以及 `torch`（PyTorch）、一些 Python 的 `math` 和 `typing`（Python
    的类型提示库），以及 `numpy`。
- en: 'After that, a class to represent the neural network that’ll be trained is created:
    `VisualQNetwork`. This class defines a neural network that takes some images as
    input, and spits out a collection of numbers as output.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，创建一个表示将进行训练的神经网络的类：`VisualQNetwork`。这个类定义了一个神经网络，它以图像作为输入，并输出一组数字。
- en: Next, we create an `Experience` class, which stores an action, observation,
    reward combination. The experiences that will be stored as an `Experience` will
    be used to train the neural network that will be made.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个 `Experience` 类，它存储一个动作、观察、奖励组合。将存储为 `Experience` 的经验将用于训练将要制作的神经网络。
- en: Now, the bulk of the notebook, the `Trainer` class, will take data from our
    Unity environment and generate a buffer of `Experience` objects, using the policy
    from the `VisualQNetwork`.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，笔记本的主要部分，`Trainer` 类，将从我们的 Unity 环境中获取数据，并生成 `Experience` 对象的缓冲区，使用 `VisualQNetwork`
    的策略。
- en: 'With the setup provided, we’ll write the training loop together. We’re going
    to do this step by step as usual, since it’s good to get a picture of what’s going
    on:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 有了提供的设置，我们将一起编写训练循环。和往常一样，我们将逐步进行，因为了解发生的情况很重要：
- en: 'First we’ll make sure any existing environments are closed:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将确保关闭任何现有的环境：
- en: '[PRE21]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then we’ll get a GridWorld from the Unity default registry:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将从 Unity 默认注册表获取一个 GridWorld：
- en: '[PRE22]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now we’ll create an instance of the `VisualQNetwork` that we discussed a moment
    ago (using the class defined earlier in the notebook):'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将创建前面讨论过的 `VisualQNetwork` 的实例（使用笔记本中早期定义的类）：
- en: '[PRE23]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'And we’ll create a `Buffer` (which is defined earlier, with `Experience`) to
    store experiences in:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将创建一个 `Buffer`（早期定义，使用 `Experience`）来存储经验：
- en: '[PRE24]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We’ll also create an optimizer, which is just a standard Adam optimizer, direct
    from PyTorch:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还将创建一个优化器，这只是一个标准的 Adam 优化器，直接来自 PyTorch：
- en: '[PRE25]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'And we’ll create a list of floats to store the cumulative rewards:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将创建一个浮点数列表来存储累积奖励：
- en: '[PRE26]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Next, we’ll define a few environment variables, like the number of training
    steps we want, the number of new experiences we want to collect per training step,
    and the maximum size of the buffer:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一些环境变量，如我们希望的训练步数，我们希望每个训练步收集的新经验数量，以及缓冲区的最大大小：
- en: '[PRE27]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'And, almost last (and definitely not least), we’re going to write the training
    loop:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后（当然不是最后一个），我们将编写训练循环：
- en: '[PRE28]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Our training loop iterates through to the maximum number of training steps that
    we defined, creates a new experience for each step, stores it in the buffer, updates
    the model, updates the rewards, and continues. It’s a pretty standard training
    loop.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的训练循环迭代到我们定义的最大训练步数，每一步创建一个新的经验，将其存储在缓冲区中，更新模型，更新奖励，然后继续。这是一个非常标准的训练循环。
- en: 'Finally, we close the environment, and we use `matplotlib` to plot a nice training
    graph:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们关闭环境，并使用 `matplotlib` 绘制一个漂亮的训练图表：
- en: '[PRE29]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: With that, we can run the notebook, and wait a while as it trains.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 有了它，我们可以运行笔记本，并等待一段时间，因为它在训练。
- en: What’s the Point of Python?
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 的意义是什么？
- en: The ML-Agents Toolkit is actually a really powerful way to control a simulation
    entirely from Python. You don’t need to use it for machine learning at all if
    you don’t want to.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ML-Agents Toolkit 实际上是完全通过 Python 控制模拟的强大方法。如果不想，您完全不需要将其用于机器学习。
- en: But of course, you *can* use it for machine learning. The Python API components
    of ML-Agents are useful if you want to go beyond what the `mlagents-learn` command
    allows you to do automatically (in concert with the YAML files, defining the hyperparameters).
    You can create a completely custom training pipeline, using all the glorious features
    of PyTorch (or TensorFlow, or anything you can get your hands on) to train the
    entities that live inside your Unity simulation beyond the limitations of the
    algorithms and scenarios provided by `mlagents-learn` (PPO, GAIL, and so on).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您可以将其用于机器学习。ML-Agents 的 Python API 组件在与定义超参数的 YAML 文件配合使用时非常有用。如果您想要超越 `mlagents-learn`
    命令自动执行的内容（与算法和场景的限制），您可以创建完全定制的训练管道，使用 PyTorch（或 TensorFlow，或您能找到的任何东西）的所有出色功能来训练生活在
    Unity 模拟中的实体。
- en: You could also use the Python API to add extra steps to the training and learning
    process, injecting calls to specialist domain libraries before or after in-engine
    observations take place, as needed.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用 Python API 添加额外的步骤来训练和学习过程中，根据需要在引擎观察发生之前或之后注入对专业领域库的调用。
