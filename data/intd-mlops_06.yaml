- en: Chapter 4\. Developing Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章\. 模型开发
- en: Adrien Lavoillotte
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 阿德里安·拉瓦约特
- en: Anyone who wants to be serious about MLOps needs to have at least a cursory
    understanding of the model development process, which is presented in [Figure 4-1](#model_development_highlighted_in_the_la)
    as an element of the larger ML project life cycle. Depending on the situation,
    the model development process can range from quite simple to extremely complex,
    and it dictates the constraints of subsequent usage, monitoring, and maintenance
    of models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 任何希望认真对待MLOps的人都需要对模型开发过程有至少粗略的了解，这在[图4-1](#model_development_highlighted_in_the_la)中作为更大的ML项目生命周期的一个元素呈现。根据情况，模型开发过程可以从非常简单到极其复杂不等，并且它决定了后续使用、监控和维护模型的约束条件。
- en: '![](assets/imlo_0401.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/imlo_0401.png)'
- en: Figure 4-1\. Model development highlighted in the larger context of the ML project
    life cycle
  id: totrans-4
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-1\. 模型开发在ML项目生命周期的更大背景中突出显示
- en: The implications of the data collection process on the rest of the model’s life
    is quite straightforward, and one easily sees how a model can become stale. For
    other parts of the model, the effects may be less obvious.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集过程对模型余生的影响非常直接，人们很容易看到模型如何变得陈旧。对于模型的其他部分，影响可能不那么明显。
- en: For example, take feature creation, where feeding a date to the model versus
    a flag indicating whether the day is a public holiday may make a big difference
    in performance, but also comes with significantly different constraints on updating
    the model. Or consider how the metrics used for evaluating and comparing models
    may enable automatic switching to the best possible version down the line, should
    the situation require it.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑特征创建，向模型提供日期与指示该日期是否为公共假日的标志可能会在性能上产生很大差异，但在更新模型时也伴随着显著不同的约束条件。或者考虑评估和比较模型所使用的指标如何在需要时实现自动切换到最佳版本。
- en: This chapter therefore covers the basics of model development, specifically
    in the context of MLOps, that is, how models might be built and developed in ways
    that make MLOps considerations easier to implement down the line.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本章重点介绍了模型开发的基础知识，特别是在MLOps的背景下，即如何以使MLOps考虑更容易实施的方式构建和开发模型。
- en: What Is a Machine Learning Model?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习模型？
- en: Machine learning models are leveraged both in academia and in the real world
    (i.e., business contexts), so it’s important to distinguish what they represent
    in theory versus how they are implemented in practice. Let’s dive into both, building
    on what we’ve already seen in [Chapter 3](ch03.html#key_mlops_features).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型在学术界和实际世界（即商业环境）中都得到了利用，因此区分它们在理论上代表什么与在实践中如何实现是非常重要的。让我们深入探讨这两者，基于我们在[第3章](ch03.html#key_mlops_features)中已经看到的内容。
- en: In Theory
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在理论上
- en: A machine learning model is a projection of reality; that is, it’s a partial
    and approximate representation of some aspect (or aspects) of a real thing or
    process. Which aspects are represented often depends on what is available and
    useful. A machine learning model, once trained, boils down a mathematical formula
    that yields a result when fed some inputs—say, a probability estimation of some
    event happening or the estimated value of a raw number.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型是现实的投射；也就是说，它是某个真实事物或过程的部分和近似表示。所表示的方面通常取决于可用和有用的内容。一旦训练完成，机器学习模型将简化为一个数学公式，在输入某些数据时产生结果——例如，某事件发生的概率估计或原始数字的估计值。
- en: Machine learning models are based on statistical theory, and machine learning
    algorithms are the tools that build models from training data. Their goal is to
    find a synthetic representation of the data they are fed, and this data represents
    the world as it was at the time of collection. Therefore, machine learning models
    can be used to make predictions when the future looks like the past, because their
    synthetic representation is still valid.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型基于统计理论，机器学习算法是从训练数据中构建模型的工具。它们的目标是找到数据的综合表示，而这些数据代表了收集时的世界。因此，当未来看起来像过去时，机器学习模型可以用于进行预测，因为它们的综合表示仍然有效。
- en: An often-used example for how machine learning models can predict and generalize
    is the price of a house. Of course, the selling price of a house will depend on
    too many factors too complex to model precisely, but getting close enough to be
    useful is not so difficult. The input data for that model may be things inherent
    to the house like surface area, number of bedrooms and bathrooms, year of construction,
    location, etc., but also other more contextual information like the state of the
    housing market at the time of sale, whether the seller is in a hurry, and so on.
    With complete enough historical data, and provided the market conditions do not
    change too much, an algorithm can compute a formula that provides a reasonable
    estimate.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型如何预测和泛化的一个常用例子是房屋价格。当然，房屋的销售价格取决于太多因素，这些因素过于复杂，无法精确建模，但足够接近以便有用并非难事。该模型的输入数据可能是房屋固有的事物，如房屋面积、卧室和浴室数量、建造年份、地理位置等，还可能包括其他更具上下文信息的内容，例如销售时的住房市场状况、卖方是否急于出售等。有了足够完整的历史数据，并且市场条件没有发生太大变化的情况下，算法可以计算出一个能够提供合理估计的公式。
- en: Another frequent example is a health diagnosis or prediction that someone will
    develop a certain disease within a given timeframe. This kind of classification
    model often outputs the probability of some event, sometimes also with a confidence
    interval.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的例子是健康诊断或预测某人在特定时间内将会发展某种疾病。这种分类模型通常会输出某些事件发生的概率，有时还会附带置信区间。
- en: In Practice
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在实践中
- en: A model is the set of parameters necessary to rebuild and apply the formula.
    It is usually stateless and deterministic (i.e., the same inputs always give the
    same outputs, with some exceptions; see [“Online Learning”](ch07.html#online_learning)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一个模型是重建和应用公式所需的参数集。它通常是无状态和确定性的（即，相同的输入始终产生相同的输出，但也有一些例外情况；参见[“在线学习”](ch07.html#online_learning)）。
- en: 'This includes the parameters of the end formula itself, but it also includes
    all the transformations to go from the input data that will be fed to the model
    to the end formula that will yield a value plus the possible derived data (like
    a classification or a decision). Given this description in practice, it usually
    does not make a difference whether the model is ML-based or not: it is just a
    computable mathematical function applied to the input data, one row at a time.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括最终公式本身的参数，但也包括从输入数据到将要产生值的最终公式的所有转换，以及可能的派生数据（例如分类或决策）。在实际操作中，给定这种描述，模型是否基于机器学习通常并不重要：它只是应用于输入数据的可计算数学函数，一次处理一行。
- en: In the house price case, for instance, it may not be practical to gather enough
    pricing data for every zip code to get a model that’s accurate enough in all target
    locations. Instead, maybe the zip codes will be replaced with some derived inputs
    that are deemed to have the most influence on price—say, average income, population
    density, or proximity to some amenities. But since end users will continue to
    input the zip code and not these derived inputs, for all intents and purposes,
    all of this transformation is also part of the pricing model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在房价案例中，可能无法实际收集到足够的定价数据以获得在所有目标位置上足够准确的模型。因此，也许会用某些被认为对价格影响最大的派生输入替换邮政编码——比如平均收入、人口密度或接近某些便利设施的情况。但由于最终用户将继续输入邮政编码而不是这些派生输入，出于所有目的而言，所有这些转换也是定价模型的一部分。
- en: Outputs can also be richer than a single number. A system that detects fraud,
    for example, will often provide some kind of probability (and in some cases maybe
    also a confidence interval) rather than a binary answer. Depending on the acceptability
    of fraud and the cost of subsequent verification or denial of the transaction,
    it may be set up to only classify fraudulent instances where the probability reaches
    some fine-tuned threshold. Some models even include recommendations or decisions,
    such as which product to show a visitor to maximize spending or which treatment
    provides the most probable recovery.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 输出也可以比一个单一数字更丰富。例如，一个检测欺诈的系统通常会提供某种概率（有时还可能是置信区间），而不是一个二元答案。根据欺诈的可接受程度以及后续验证或交易拒绝的成本，系统可能会设置为仅对概率达到一定精细调节阈值的欺诈实例进行分类。有些模型甚至包括建议或决策，例如为了最大化支出而向访客展示哪种产品，或者哪种治疗方法提供最可能的康复。
- en: All of these transformations and associated data are part of the model to some
    degree; however, this does not mean they are always bundled in a monolithic package,
    as one single artifact compiled together. This could quickly get unwieldy, and,
    in addition, some parts of this information come with varying constraints (different
    refresh rates, external sources, etc.).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些转换和相关数据在某种程度上都是模型的一部分；然而，这并不意味着它们总是捆绑在一个单一的、编译在一起的整体包中。这可能很快变得难以管理，此外，这些信息的某些部分还带有各种约束条件（不同的刷新率、外部来源等）。
- en: Required Components
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 所需的组件
- en: Building a machine learning model requires many components as outlined in [Table 4-1](#table_four_one).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 构建机器学习模型需要许多组件，如[表 4-1](#table_four_one)中所述。
- en: Table 4-1\. Required components of a machine learning model
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-1\. 机器学习模型的必要组件
- en: '| ML component | Description |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习组件 | 描述 |'
- en: '| --- | --- |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Training data | Training data is usually labeled for the prediction case
    with examples of what is being modeled (supervised learning). It might sound obvious,
    but it’s important to have *good* training data. An illustrative example of when
    this was not the case was [data from damaged planes during World War II](https://oreil.ly/sssfA),
    which suffered from survivor bias and therefore was not good training data. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 训练数据 | 训练数据通常是标记为预测案例的，例如所建模的例子（监督学习）。这听起来很明显，但重要的是要有*良好的*训练数据。一个说明性的例子是二战期间受损飞机的数据，这些数据受到幸存者偏见的影响，因此不适合作为训练数据。
    ([链接](https://oreil.ly/sssfA)) |'
- en: '| A performance metric | A performance metric is what the model being developed
    seeks to optimize. It should be chosen carefully to avoid unintended consequences,
    like the [cobra effect](https://oreil.ly/DYOss) (named for a famous anecdote,
    where a reward for dead cobras led some to breed them). For example, if 95% of
    the data has class A, optimizing for raw accuracy may produce a model that always
    predicts A and is 95% accurate. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 性能指标 | 性能指标是正在开发的模型寻求优化的内容。应谨慎选择，以避免意外后果，如[眼镜蛇效应](https://oreil.ly/DYOss)（以一则著名轶事命名，奖励杀死眼镜蛇导致一些人开始饲养它们）。例如，如果数据中有
    95% 的数据属于类 A，优化原始准确率可能会导致模型总是预测 A 并且准确率达到 95%。 |'
- en: '| ML algorithm | There are a variety of models that work in various ways and
    have different pros and cons. It is important to note that some algorithms are
    more suited to certain tasks than others, but their selection also depends on
    what needs to be prioritized: performance, stability, interpretability, computation
    cost, etc. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习算法 | 有各种工作方式和不同优缺点的模型。需要注意的是，一些算法更适合特定任务，但其选择还取决于需要优先考虑的因素：性能、稳定性、可解释性、计算成本等等。
    |'
- en: '| Hyperparameters | Hyperparameters are configurations for ML algorithms. The
    algorithm contains the basic formula, the *parameters* it learns are the operations
    and operands that make up this formula for that particular prediction task, and
    the *hyperparameters* are the ways that the algorithm may go to find these parameters.
    For example, in a decision tree (where data continues to be split in two according
    to what looks to be the best predictor in the subset that reached this path),
    one hyperparameter is the depth of the tree (i.e., the number of splits). |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 超参数 | 超参数是 ML 算法的配置。算法包含基本的公式，它学习的*参数*是构成该特定预测任务的操作和操作数，而*超参数*是算法为了找到这些参数可能采取的方式。例如，在决策树中（数据根据在达到此路径的子集中看起来是最佳预测器的内容分割），一个超参数是树的深度（即分割的次数）。
    |'
- en: '| Evaluation dataset | When using labeled data, an evaluation dataset that
    is different from the training set will be required to evaluate how the model
    performs on unseen data (i.e., how well it can generalize). |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 评估数据集 | 在使用标记数据时，需要一个与训练集不同的评估数据集来评估模型在未见数据上的表现（即它能够进行泛化的程度）。 |'
- en: The sheer number and complexity of each individual component is part of what
    can make good MLOps a challenging undertaking. But the complexity doesn’t stop
    here, as algorithm choice is yet another piece of the puzzle.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每个组件的数量和复杂性正是使得优秀的 MLOps 成为一项具有挑战性的任务的一部分。但是复杂性并不止于此，算法选择也是难题的另一部分。
- en: Different ML Algorithms, Different MLOps Challenges
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不同的 ML 算法，不同的 MLOps 挑战
- en: What ML algorithms all have in common is that they model patterns in past data
    to make inferences, and the quality and relevance of this experience are the key
    factors in their effectiveness. Where they differ is that each style of algorithm
    has specific characteristics and presents different challenges in MLOps (outlined
    in [Table 4-2](#table_four_two)).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法的共同特点是它们模拟过去数据中的模式以进行推断，而这种经验的质量和相关性是它们有效性的关键因素。它们的区别在于每种算法风格具有特定特征，并在
    MLOps 中提出了不同的挑战（详见[表 4-2](#table_four_two)）。
- en: Table 4-2\. MLOps considerations by algorithm type
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-2\. 算法类型的 MLOps 考虑因素
- en: '| Algorithm type | Name | MLOps considerations |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 算法类型 | 名称 | MLOps 考虑因素 |'
- en: '| --- | --- | --- |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Linear | Linear regression | There is a tendency for overfitting. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 线性 | 线性回归 | 存在过拟合的倾向。 |'
- en: '|   | Logistic regression | There is a tendency for overfitting. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|   | 逻辑回归 | 存在过拟合的倾向。 |'
- en: '| Tree-based | Decision tree | Can be unstable—small changes in data can lead
    to a large change in the structure of the optimal decision tree. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 基于树的 | 决策树 | 可能不稳定——数据的微小变化可能导致最优决策树结构的大变化。 |'
- en: '| Random forest | Predictions can be difficult to understand, which is challenging
    from a Responsible AI perspective. Random forest models can also be relatively
    slow to output predictions, which can present challenges for applications. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林 | 预测结果可能难以理解，这在负责任的人工智能视角下是个挑战。随机森林模型还可能相对缓慢地输出预测结果，这对应用程序构成了挑战。 |'
- en: '| Gradient boosting | Like random forest, predictions can be difficult to understand.
    Also, a small change in the feature or training set can create radical changes
    in the model. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 梯度提升 | 像随机森林一样，预测结果可能难以理解。此外，特征或训练集的微小变化可能会导致模型发生根本性变化。 |'
- en: '| Deep learning | Neural networks | In terms of interpretability, deep learning
    models are almost impossible to understand. Deep learning algorithms, including
    neural networks, are also extremely slow to train and require a lot of power (and
    data). Is it worth the resources, or would a simpler model work just as well?
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 深度学习 | 神经网络 | 就可解释性而言，深度学习模型几乎是不可能理解的。深度学习算法（包括神经网络）训练速度极慢，需要大量资源（和数据）。资源值得投入吗？还是简单模型同样有效？
    |'
- en: Some ML algorithms can best support specific use cases, but governance considerations
    may also play a part in the choice of algorithm. In particular, highly regulated
    environments where decisions must be explained (e.g., financial services) cannot
    use opaque algorithms such as neural networks; rather, they have to favor simpler
    techniques, such as decision trees. In many use cases, it’s not so much a trade-off
    on performance but rather a trade-off on cost. That is, simpler techniques usually
    require more costly manual feature engineering to reach the same level of performance
    as more complex techniques.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 某些机器学习算法可以最好地支持特定用例，但治理考虑因素也可能影响算法选择。特别是在高度规管的环境中，必须解释决策的地方（例如金融服务），不能使用像神经网络这样的不透明算法；相反，它们必须偏向于像决策树这样的简单技术。在许多用例中，问题不在于性能的权衡，而在于成本的权衡。简单技术通常需要更昂贵的手工特征工程才能达到与更复杂技术相同的性能水平。
- en: Data Exploration
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据探索
- en: When data scientists or analysts consider data sources to train a model, they
    need to first get a grasp of what that data looks like. Even a model trained using
    the most effective algorithm is only as good as its training data. At this stage,
    a number of issues can prevent all or part of the data from being useful, including
    incompleteness, inaccuracy, inconsistency, etc.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家或分析师考虑数据源来训练模型时，他们首先需要了解数据的实际情况。即使使用最有效的算法训练的模型，其好坏也取决于训练数据。在这个阶段，许多问题可能会导致数据全部或部分无用，包括不完整性、不准确性、不一致性等。
- en: 'Examples of such processes can include:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此类流程的示例包括：
- en: Documenting how the data was collected and what assumptions were already made
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录数据收集方式及已经做出的假设
- en: 'Looking at summarizing statistics of the data: What is the domain of each column?
    Are there some rows with missing values? Obvious mistakes? Strange outliers? No
    outliers at all?'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看数据的总结统计：每列的域是什么？是否有缺失值的行？显而易见的错误？奇怪的异常值？或者根本没有异常值？
- en: Taking a closer look at the distribution of the data
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更详细地查看数据的分布情况
- en: Cleaning, filling, reshaping, filtering, clipping, sampling, etc.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据清洗、填充、重塑、过滤、剪切、采样等
- en: Checking correlations between the different columns, running statistical tests
    on some subpopulations, fitting distribution curves
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查不同列之间的相关性，对一些子群体进行统计检验，拟合分布曲线。
- en: 'Comparing that data to other data or models in the literature: Is there some
    usual information that seems to be missing? Is this data comparably distributed?'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将该数据与文献中的其他数据或模型进行比较：是否存在某些常见信息似乎缺失？这些数据是否分布相当？
- en: 'Of course, domain knowledge is required to make informed decisions during this
    exploration. Some oddities may be hard to spot without specific insight, and assumptions
    made can have consequences that are not obvious to the untrained eye. Industrial
    sensor data is a good example: unless the data scientist is also a mechanical
    engineer or expert in the equipment, they might not know what constitutes normal
    versus strange outliers for a particular machine.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在此探索过程中需要领域知识来做出明智的决策。一些异常可能很难在没有特定见解的情况下发现，而且所做的假设可能会对未经训练的人产生不明显的后果。工业传感器数据是一个很好的例子：除非数据科学家也是机械工程师或者设备专家，否则他们可能不知道对于特定机器来说什么是正常的、什么是奇怪的异常值。
- en: Feature Engineering and Selection
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程和选择
- en: 'Features are how data is presented to a model, serving to inform that model
    on things it may not infer by itself. This table provides examples of how features
    may be engineered:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 特征是将数据呈现给模型的方式，帮助模型了解它本身无法推断出的事物。以下表格提供了特征工程的一些示例：
- en: '| Feature engineering category | Description |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 特征工程类别 | 描述 |'
- en: '| --- | --- |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Derivatives | Infer new information from existing information—e.g., what
    day of the week is this date? |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 派生 | 从现有信息推断新信息，例如，这个日期是星期几？ |'
- en: '| Enrichment | Add new external information—e.g., is this day a public holiday?
    |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 丰富化 | 添加新的外部信息，例如，今天是否是公共假日？ |'
- en: '| Encoding | Present the same information differently—e.g., day of the week
    or weekday versus weekend. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 编码 | 以不同方式呈现相同的信息，例如，工作日或周末中的星期几。 |'
- en: '| Combination | Link features together—e.g., the size of the backlog might
    need to be weighted by the complexity of the different items in it. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 组合 | 将特征链接在一起，例如，积压的大小可能需要根据其中不同项目的复杂性进行加权。 |'
- en: For instance, in trying to estimate the potential duration of a business process
    given the current backlog, if one of the inputs is a date, it is pretty common
    to derive the corresponding day of the week or how far ahead the next public holiday
    is from that date. If the business serves multiple locations that observe different
    business calendars, that information may also be important.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，试图估计当前积压下的业务流程潜在持续时间时，如果输入之一是日期，则通常会推导出该日期对应的星期几或者距离下一个公共假日还有多久。如果企业服务的多个位置遵循不同的业务日历，这些信息也可能很重要。
- en: Another example, to follow up on the house pricing scenario from the previous
    section, would be using average income and population density, which ideally allows
    the model to better generalize and train on more diverse data than trying to segment
    by area (i.e., zip code).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是继续上一节中的房屋定价场景，可以使用平均收入和人口密度，这样模型可以更好地泛化和训练更多样化的数据，而不是尝试按地区（即邮政编码）分割。
- en: Feature Engineering Techniques
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程技术
- en: A whole market exists for such complementary data that extends far beyond the
    open data that public institutions and companies share. Some services provide
    direct enrichment that can save a lot of time and effort.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个整个市场专门提供这种补充数据，远远超出了公共机构和公司分享的开放数据。一些服务提供直接的丰富化，可以节省大量时间和精力。
- en: There are, however, many cases when information that data scientists need for
    their models is not available. In this case, there are techniques like impact
    coding, whereby data scientists replace a modality by the average value of the
    target for that modality, thus allowing the model to benefit from data in a similar
    range (at the cost of some information loss).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有许多情况是数据科学家所需的信息并不可得。在这种情况下，有一些技术，比如影响编码，数据科学家通过替换模态值为该模态的目标平均值，使模型能够从类似范围的数据中受益（尽管会有一些信息损失）。
- en: Ultimately, most ML algorithms require a table of numbers as input, each row
    representing a sample, and all samples coming from the same dataset. When the
    input data is not tabular, data scientists can use other tricks to transform it.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，大多数机器学习算法需要以数字表格的形式作为输入，每一行代表一个样本，所有样本来自同一数据集。当输入数据不是表格时，数据科学家可以使用其他技巧来转换它。
- en: The most common one is *one-hot encoding*. For example, a feature that can take
    three values (e.g., Raspberry, Blueberry, and Strawberry) is transformed into
    three features that can take only two values—yes or no (e.g., Raspberry yes/no,
    Blueberry yes/no, Strawberry yes/no).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的是*独热编码*。例如，一个可以取三个值的特征（例如，Raspberry、Blueberry和Strawberry）被转换为三个只能取两个值的特征—是或否（例如，Raspberry
    是/否，Blueberry 是/否，Strawberry 是/否）。
- en: Text or image inputs, on the other hand, require more complex engineering. Deep
    learning has recently revolutionized this field by providing models that transform
    images and text into tables of numbers that are usable by ML algorithms. These
    tables are called *embeddings*, and they allow data scientists to perform transfer
    learning because they can be used in domains on which they were not trained.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，文本或图像输入需要更复杂的工程技术。深度学习最近通过提供将图像和文本转换为可供机器学习算法使用的数字表的模型彻底改变了这一领域。这些表被称为*嵌入*，它们使数据科学家能够进行迁移学习，因为它们可以在未经过培训的领域中使用。
- en: How Feature Selection Impacts MLOps Strategy
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征选择如何影响MLOps策略
- en: 'When it comes to feature creation and selection, the question of how much and
    when to stop comes up regularly. Adding more features may produce a more accurate
    model, achieve more fairness when splitting into more precise groups, or compensate
    for some other useful missing information. However, it also comes with downsides,
    all of which can have a significant impact on MLOps strategies down the line:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征的创建和选择方面，经常会出现如何在什么程度上及何时停止的问题。增加更多的特征可能会产生更准确的模型，在将数据分割为更精确组别时实现更多的公平性，或弥补其他有用的缺失信息。然而，这也伴随着一些不利因素，所有这些因素都可能对MLOps策略产生重大影响。
- en: The model can become more and more expensive to compute.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算模型可能变得越来越昂贵。
- en: More features require more inputs and more maintenance down the line.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多的特征需要更多的输入和未来的维护。
- en: More features mean a loss of some stability.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多的特征意味着某些稳定性的损失。
- en: The sheer number of features can raise privacy concerns.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征数量的增加可能引发隐私问题。
- en: Automated feature selection can help by using heuristics to estimate how critical
    some features will be for the predictive performance of the model. For instance,
    one can look at the correlation with the target variable or quickly train a simple
    model on a representative subset of the data and then look at which features are
    the strongest predictors.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化特征选择可以通过使用启发式方法来估计某些特征对模型预测性能的关键性有所帮助。例如，可以查看与目标变量的相关性或快速在数据的代表性子集上训练一个简单模型，然后查看哪些特征是最强的预测因子。
- en: Which inputs to use, how to encode them, how they interact or interfere with
    each other—such decisions require a certain understanding of the inner workings
    of the ML algorithm. The good news is that some of this can be partly automated,
    e.g., by using tools such as Auto-sklearn or AutoML applications that cross-reference
    features against a given target to estimate which features, derivatives, or combinations
    are likely to yield the best results, leaving out all the features that would
    probably not make that much of a difference.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如何选择使用哪些输入，如何对它们进行编码，它们如何相互作用或干扰—这些决策需要对机器学习算法的内部工作有一定的理解。好消息是，其中一些可以部分自动化，例如使用诸如Auto-sklearn或AutoML应用程序这样的工具，这些工具会将特征与给定目标进行交叉引用，以估计哪些特征、导数或组合可能会产生最佳结果，避免使用那些可能不会产生太大影响的特征。
- en: Other choices still require human intervention, such as deciding whether to
    try to collect additional information that might improve the model. Spending time
    to build business-friendly features will often improve the final performance and
    ease the adoption by end users, as model explanations are likely to be simpler.
    It can also reduce modeling debt, allowing data scientists to understand the main
    prediction drivers and ensure that they are robust. Of course, there are trade-offs
    to consider between the cost of time spent to understand the model and the expected
    value, as well as risks associated with the model’s use.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其他选择仍然需要人工干预，例如决定是否尝试收集可能改进模型的附加信息。花时间构建业务友好的特征通常会提高最终性能，并简化最终用户的采用，因为模型解释可能更简单。这也可以减少建模债务，帮助数据科学家理解主要的预测驱动因素，并确保它们的稳健性。当然，在理解模型所需时间的成本与预期价值之间，以及与模型使用相关的风险之间需要权衡考虑。
- en: The bottom line is that when building models, the process of engineering and
    selecting features, like many other ML model components, is a delicate balance
    between considering MLOps components and performance.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 底线是，在构建模型时，工程和选择特征的过程，就像许多其他ML模型组件一样，是在考虑MLOps组件和性能之间的微妙平衡。
- en: Experimentation
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验
- en: 'Experimentation takes place throughout the entire model development process,
    and usually every important decision or assumption comes with at least some experiment
    or previous research to justify it. Experimentation can take many shapes, from
    building full-fledged predictive ML models to doing statistical tests or charting
    data. Goals of experimentation include:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 实验发生在整个模型开发过程中，通常每个重要决策或假设都至少伴随着一些实验或先前的研究来加以证明。实验可以采用多种形式，从构建成熟的预测ML模型到进行统计测试或绘制数据。实验的目标包括：
- en: Assessing how useful or how good of a model can be built given the elements
    outlined in [Table 4-1](#table_four_one). (The next section will cover model evaluation
    and comparison in more detail.)
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估在[表 4-1](#table_four_one)中概述的元素给定的模型有多有用或多好。（下一节将更详细地讨论模型评估和比较。）
- en: Finding the best modeling parameters (algorithms, hyperparameters, feature preprocessing,
    etc.).
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到最佳的建模参数（算法、超参数、特征预处理等）。
- en: Tuning the bias/variance trade-off for a given training cost to fit that definition
    of “best.”
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整偏差/方差权衡以适应给定训练成本的“最佳”定义。
- en: Finding a balance between model improvement and improved computation costs.
    (Since there’s always room for improvement, how good is good enough?)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到模型改进和改进的计算成本之间的平衡。（由于总是有改进的空间，那么好有多好？）
- en: When experimenting, data scientists need to be able to quickly iterate through
    all the possibilities for each of the model building blocks outlined in [Table 4-1](#table_four_one).
    Fortunately, there are tools to do all of this semiautomatically, where you only
    need to define what should be tested (the space of possibilities) depending on
    prior knowledge (what makes sense) and the constraints (e.g., computation, budget).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行实验时，数据科学家需要能够快速迭代地尝试[表 4-1](#table_four_one)中每个模型构建模块的所有可能性。幸运的是，有工具可以半自动化地完成所有这些，您只需要定义应该测试的内容（可能性的空间），这取决于先前的知识（什么是有意义的）和约束条件（例如计算预算）。
- en: Some tools allow for even more automation, for instance by offering stratified
    model training. For example, say the business wants to predict customer demand
    for products to optimize inventory, but behavior varies a lot from one store to
    the next. Stratified modeling consists of training one model per store that can
    be better optimized for each store rather than a model that tries to predict in
    all stores.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一些工具甚至允许更多自动化，例如通过提供分层模型训练。例如，假设企业希望预测产品的顾客需求以优化库存，但各店的行为差异很大。分层建模包括为每个店铺训练一个模型，可以更好地针对每个店铺进行优化，而不是一个试图在所有店铺中进行预测的模型。
- en: Trying all combinations of every possible hyperparameter, feature handling,
    etc., quickly becomes untraceable. Therefore, it is useful to define a time and/or
    computation budget for experiments as well as an acceptability threshold for usefulness
    of the model (more on that notion in the next section).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试所有可能的超参数组合、特征处理等，很快就变得无法追踪。因此，定义实验的时间和/或计算预算以及模型实用性的可接受阈值（更多关于该概念的内容将在下一节讨论）非常有用。
- en: Notably, all or part of this process may need to be repeated every time anything
    in the situation changes (including whenever the data and/or problem constraints
    change significantly; see [“Drift Detection in Practice”](ch07.html#drift_detection_in_practice)).
    Ultimately, this means that all experiments that informed the final decisions
    data scientists made to arrive at the model as well as all the assumptions and
    conclusions along the way may need to be rerun and reexamined.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，这个过程的全部或部分可能需要在任何情况变化时重复（包括数据和/或问题约束发生重大变化时；参见[“实践中的漂移检测”](ch07.html#drift_detection_in_practice)）。最终，这意味着所有为数据科学家们在模型到达最终决策时所做的实验以及沿途所有的假设和结论都可能需要重新运行和重新审视。
- en: Fortunately, more and more data science and machine learning platforms allow
    for automating these workflows not only on the first run, but also to preserve
    all the processing operations for repeatability. Some also allow for the use of
    version control and experimental branch spin-off to test theories and then merge,
    discard, or keep them (see [“Version Management and Reproducibility”](#version_management_and_reproducibility)).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，越来越多的数据科学和机器学习平台不仅允许在第一次运行时自动化这些工作流程，而且还可以保留所有处理操作以便重复使用。有些还允许使用版本控制和实验分支派生来测试理论，然后合并、丢弃或保留它们（参见[“版本管理与可重复性”](#version_management_and_reproducibility)）。
- en: Evaluating and Comparing Models
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估和比较模型
- en: George E. P. Box, a twentieth century British statistician, once said that all
    models are wrong, but some are useful. In other words, a model should not aim
    to be perfect, but it should pass the bar of “good enough to be useful” while
    keeping an eye on the uncanny valley—typically a model that *looks* like it’s
    doing a good job but does a bad (or catastrophic) job for a specific subset of
    cases (say, an underrepresented population).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 二十世纪英国统计学家乔治·E·P·博克斯曾经说过，所有模型都是错误的，但有些是有用的。换句话说，模型不应该追求完美，而是应该达到“足够好以便有用”的标准，同时要注意神秘谷效应——通常是一个看起来做得很好的模型，但在特定情况下（比如，少数群体）却表现糟糕（甚至灾难性）。
- en: With this in mind, it’s important to evaluate a model in context and have some
    ability to compare it to what existed before the model—whether a previous model
    or a rules-based process—to get an idea of what the outcome would be if the current
    model or decision process were replaced by the new one.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，重要的是在上下文中评估模型，并具备一定的能力将其与之前的模型或基于规则的过程进行比较，以了解如果当前模型或决策过程被新模型取代，结果将会如何。
- en: A model with an absolute performance that could technically be considered disappointing
    can still possibly enhance an existing situation. For instance, having a slightly
    more accurate forecast of demand for a certain product or service may result in
    huge cost-savings.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一个技术上可以被认为是令人失望的绝对表现的模型，仍然有可能改善现有情况。例如，对某种产品或服务的需求有稍微更精确的预测可能会导致巨大的成本节约。
- en: Conversely, a model that gets a perfect score is suspicious, as most problems
    have noise in the data that’s at least somewhat hard to predict. A perfect or
    nearly-perfect score may be a sign that there is a leak in the data (i.e., that
    the target to be predicted is also in the input data or that an input feature
    is very correlated to the target but, practically, available only once the target
    is known) or that the model overfits the training data and will not generalize
    well.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，得分完美的模型是可疑的，因为大多数问题的数据中存在噪声，这些噪声至少在某种程度上很难预测。完美或接近完美的得分可能表明数据中存在泄漏（即被预测的目标也在输入数据中，或者输入特征与目标非常相关，但在实际中只有在目标已知时才可用），或者模型过度拟合训练数据，无法很好地泛化。
- en: Choosing Evaluation Metrics
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择评估指标
- en: 'Choosing the proper metric by which to evaluate and compare different models
    for a given problem can lead to very different models (think of the cobra effect
    mentioned in [Table 4-1](#table_four_one)). A simple example: accuracy is often
    used for automated classification problems but is rarely the best fit when the
    classes are unbalanced (i.e., when one of the outcomes is very unlikely compared
    to the other). In a binary classification problem where the positive class (i.e.,
    the one that is interesting to predict because its prediction triggers an action)
    is rare, say 5% of occurrences, a model that constantly predicts the negative
    class is therefore 95% accurate, while also utterly useless.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估和比较不同模型的适当指标，针对给定问题选择适当的度量标准可能导致非常不同的模型（可以想象一下表4-1中提到的眼镜蛇效应）。一个简单的例子：对于自动分类问题，通常使用准确率，但当类别不平衡时（即一个结果比另一个结果发生的可能性非常小），准确率很少是最佳选择。在一个二元分类问题中，正类（即有趣的预测类，因为其预测会触发某种行动）很少见，例如发生的5%的情况，一个总是预测负类的模型因此准确率为95%，但同时也是毫无用处的。
- en: Unfortunately, there is no one-size-fits-all metric. You need to pick one that
    matches the problem at hand, which means understanding the limits and trade-offs
    of the metric (the mathematics side) and their impact on the optimization of the
    model (the business side).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，并不存在一种适合所有的指标。你需要选择一个与手头问题匹配的指标，这意味着理解指标的限制和权衡（数学方面）以及它们对模型优化的影响（业务方面）。
- en: To get an idea of how well a model will generalize, that metric should be evaluated
    on a part of the data that was not used for the model’s training (a holdout dataset),
    a method called *cross-testing*. There can be multiple steps where some data is
    held for evaluation and the rest is used for training or optimizing, such as metric
    evaluation or hyperparameter optimization. There are different strategies as well,
    not necessarily just a simple split. In *k*-fold cross-validation, for example,
    data scientists rotate the parts that they hold out to evaluate and train multiple
    times. This multiplies the training time but gives an idea of the stability of
    the metric.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解模型的泛化能力如何，该指标应在未用于模型训练的数据部分上进行评估（保留数据集），这种方法称为*交叉测试*。可能有多个步骤，在这些步骤中，一些数据被保留用于评估，其余数据则用于训练或优化，如度量评估或超参数优化。还有不同的策略，不一定只是简单的分割。例如，在*k*-折交叉验证中，数据科学家多次轮换保留用于评估和训练的部分。这增加了训练时间，但能够提供指标稳定性的想法。
- en: With a simple split, the holdout dataset can consist of the most recent records
    instead of randomly chosen ones. Indeed, as models are usually used for future
    predictions, it is likely that assessing them as if they were used for prediction
    on the most recent data leads to more realistic estimations. In addition, it allows
    one to assess whether the data drifted between the training and the holdout dataset
    (see [“Drift Detection in Practice”](ch07.html#drift_detection_in_practice) for
    more details).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在简单分割中，保留数据集可以包含最近的记录，而不是随机选择的记录。实际上，由于模型通常用于未来预测，因此评估它们就像在最新数据上进行预测一样，可以得出更真实的估计。此外，这还可以评估数据在训练和保留数据集之间是否发生漂移（有关更多详细信息，请参阅[“实际中的漂移检测”](ch07.html#drift_detection_in_practice)）。
- en: As an example, [Figure 4-2](#an_example_of_dataset_split_for_model_e) shows
    a scheme in which a test dataset is a holdout (in gray) in order to perform the
    evaluation. The remaining data is split into three parts to find the best hyperparameter
    combination by training the model three times with a given combination on each
    of the blue datasets, and validating its performance on their respective green
    datasets. The gray dataset is used only once with the best hyperparameter combination,
    while the other datasets are used with all of them.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[图 4-2](#an_example_of_dataset_split_for_model_e)展示了一种方案，其中测试数据集是保留的（灰色），以执行评估。其余数据分为三部分，通过在每个蓝色数据集上使用给定组合训练模型三次，并在各自的绿色数据集上验证其性能，来找到最佳超参数组合。灰色数据集仅在最佳超参数组合下使用一次，而其他数据集则与所有组合一起使用。
- en: '![](assets/imlo_0402.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/imlo_0402.png)'
- en: Figure 4-2\. An example of dataset split for model evaluation
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. 模型评估的数据集分割示例
- en: 'Oftentimes, data scientists want to periodically retrain models with the same
    algorithms, hyperparameters, features, etc., but on more recent data. Naturally,
    the next step is to compare the two models and see how the new version fares.
    But it’s also important to make sure all previous assumptions still hold: that
    the problem hasn’t fundamentally shifted, that the modeling choices made previously
    still fit the data, etc. This is more specifically part of performance and drift
    monitoring (find more details on this in [Chapter 7](ch07.html#monitoring_and_feedback_loop)).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，数据科学家希望定期使用相同的算法、超参数、特征等对模型进行重新训练，但使用更新的数据。自然而然地，下一步是比较两个模型，看看新版本的表现如何。但同样重要的是确保所有先前的假设仍然成立：问题没有根本性转变，先前做出的建模选择仍然适合数据等。这更具体地属于性能和漂移监控的一部分（在[第7章](ch07.html#monitoring_and_feedback_loop)中可以找到更多详细信息）。
- en: Cross-Checking Model Behavior
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查模型行为
- en: 'Beyond the raw metrics, when evaluating a model, it’s critical to understand
    how it will behave. Depending on the impact of the model’s predictions, decisions,
    or classifications, a more or less deep understanding may be required. For example,
    data scientists should take reasonable steps (with respect to that impact) to
    ensure that the model is not actively harmful: a model that would predict that
    *all* patients need to be checked by a doctor may score high in terms of raw prevention,
    but not so much on realistic resource allocation.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估模型时，除了原始指标外，了解其行为方式至关重要。根据模型预测、决策或分类的影响，可能需要更深入或更浅显的理解。例如，数据科学家应该采取合理步骤（尊重该影响），以确保模型不会造成实质性伤害：例如，预测*所有*患者都需要由医生检查的模型，在原始预防方面可能得分很高，但在现实资源分配方面则可能不那么理想。
- en: 'Examples of these reasonable steps include:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这些合理步骤的示例包括：
- en: Cross-checking different metrics (and not only the ones on which the model was
    initially optimized)
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉检查不同的度量（而不仅仅是模型最初优化的那些）
- en: Checking how the model reacts to different inputs—e.g., plot the average prediction
    (or probability for classification models) for different values of some inputs
    and see whether there are oddities or extreme variability
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查模型对不同输入的反应方式，例如，绘制某些输入值的平均预测（或分类模型的概率），看看是否存在异常或极端变化情况。
- en: Splitting one particular dimension and checking the difference in behavior and
    metrics across different subpopulations—e.g., is the error rate the same for males
    and females?
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割一个特定维度并检查不同子群体间行为和度量的差异，例如，男性和女性的错误率是否相同？
- en: These kinds of global analyses should not be understood as causality, just as
    correlation. They do not necessarily imply a specific causal relationship between
    some variables and an outcome; they merely show how the *model* sees that relationship.
    In other words, the model should be used with care for what-if analysis. If one
    feature value is changed, the model prediction is likely to be wrong if the new
    feature value has never been seen in the training dataset or if it has never been
    seen in combination with the values of the other features in this dataset.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这些全局分析不应被理解为因果关系，而只是相关性。它们并不一定暗示某些变量与结果之间的特定因果关系；它们仅仅展示了模型如何看待这种关系。换句话说，应谨慎使用模型进行假设分析。如果一个特征值发生了变化，那么如果这个新特征值在训练数据集中从未见过，或者从未与该数据集中其他特征的值组合过，模型的预测可能会是错误的。
- en: When comparing models, those different aspects should be accessible to data
    scientists, who need to be able to go deeper than a single metric. That means
    the full environment (interactive tooling, data, etc.) needs to be available for
    all models, ideally allowing for comparison from all angles and between all components.
    For example, for drift, the comparison might use the same settings but different
    data, while for modeling performance, it might use the same data but different
    settings.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当比较模型时，这些不同的方面应该对数据科学家可见，他们需要能够深入了解而不仅仅是单一的度量标准。这意味着完整的环境（交互式工具、数据等）应该对所有模型都可用，理想情况下允许从所有角度和所有组件之间进行比较。例如，对于漂移，比较可能会使用相同的设置但不同的数据，而对于建模性能，则可能使用相同的数据但不同的设置。
- en: Impact of Responsible AI on Modeling
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负责任的人工智能对建模的影响
- en: Depending on the situation (and sometimes depending on the industry or sector
    of the business), on top of a general understanding of model behavior, data scientists
    may also need models’ individual predictions to be explainable, including having
    an idea of what specific features pushed the prediction one way or the other.
    Sometimes predictions may be very different for a specific record than on average.
    Popular methods to compute individual prediction explanations include Shapley
    value (the average marginal contribution of a feature value across all possible
    coalitions) and individual conditional expectation (ICE) computations, which show
    the dependence between the target functions and features of interest.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 根据情况（有时也取决于行业或企业部门），除了对模型行为的一般理解之外，数据科学家还可能需要模型的单独预测是可解释的，包括对推动预测朝某个方向的具体特征有所了解。有时，特定记录的预测可能与平均值非常不同。计算单独预测解释的流行方法包括夏普利值（特征值在所有可能联盟中的平均边际贡献）和个体条件期望（ICE）计算，这些方法显示了目标函数与感兴趣特征之间的依赖关系。
- en: 'For example, the measured level of a specific hormone could generally push
    a model to predict someone has a health issue, but for a pregnant woman, that
    level makes the model infer she is at no such risk. Some legal frameworks mandate
    some kind of explainability for decisions made by a model that have consequences
    on humans, like recommending a loan to be denied. [“Element 2: Bias”](ch08.html#element_two_bias)
    discusses this topic in detail.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，特定激素的测量水平通常会促使模型预测某人存在健康问题，但对于怀孕的女性来说，该水平使模型推断她没有这种风险。某些法律框架要求对模型做出的对人类有后果的决定提供某种程度的可解释性，例如推荐拒绝贷款。[“元素2：偏见”](ch08.html#element_two_bias)详细讨论了这个主题。
- en: Note that the notion of explainability has several dimensions. In particular,
    deep learning networks are sometimes called *black-box* models because of their
    complexity (though when reading the model coefficients, a model is fully specified,
    and it is usually a conceptually remarkably simple formula, but a very large formula
    that becomes impossible to intuitively apprehend). Conversely, global and local
    explanation tools—such as partial dependence plots or Shapley value computations—give
    some insights but arguably do not make the model intuitive. To actually communicate
    a rigorous and intuitive understanding of what exactly the model is doing, limiting
    the model complexity is required.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，可解释性的概念有几个方面。特别是，深度学习网络有时被称为*黑匣子*模型，因为它们的复杂性（尽管在阅读模型系数时，一个模型是完全指定的，通常是一个概念上非常简单的公式，但是一个非常庞大的公式，变得不可能直观理解）。相反，全局和局部解释工具——如部分依赖图或沙普利值计算——提供了一些洞见，但可以说并没有使模型变得直观。要真正传达对模型正在做什么的严格而直观的理解，需要限制模型的复杂性。
- en: 'Fairness requirements can also have dimensioning constraints on model development.
    Consider this theoretical example to better understand what is at stake when it
    comes to bias: a US-based organization regularly hires people who do the same
    types of jobs. Data scientists could train a model to predict the workers’ performance
    according to various characteristics, and people would then be hired based on
    the probability that they would be high-performing workers.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 公平性要求还可能对模型开发产生尺寸约束。考虑这个理论例子以更好地理解偏见问题的重要性：一个总部位于美国的组织定期雇佣从事相同类型工作的人员。数据科学家可以训练一个模型来预测员工的绩效，根据各种特征，然后人们将根据他们成为高绩效员工的概率被聘用。
- en: 'Though this seems like a simple problem, unfortunately, it’s fraught with pitfalls.
    To make this problem completely hypothetical and to detach it from the complexities
    and problems of the real world, let’s say everyone in the working population belongs
    to one of two groups: Weequay or Togruta.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个问题看起来很简单，不幸的是，它充满了陷阱。为了使这个问题完全假设化，并将其与现实世界的复杂性和问题分离开来，让我们假设工作人口中的每个人都属于两个群体之一：韦奎人或托格鲁塔人。
- en: For this hypothetical example, let’s claim that a far larger population of Weequay
    attend university. Off the bat, there would be an initial bias in favor of Weequay
    (amplified by the fact they would have been able to develop their skills through
    years of experience).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个假设性的例子，让我们假设韦奎人中有更大比例的人上大学。从一开始，韦奎人会因此而受到偏见的影响（因为他们通过多年的经验发展了他们的技能）。
- en: As a result, there would not only be more Weequay than Togruta in the pool of
    applicants, but Weequay applicants would tend to be more qualified. The employer
    has to hire 10 people during the month to come. What should it do?
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，申请者池中不仅会有更多的韦奎人而不是托格鲁塔人，而且韦奎人的申请者往往更有资格。雇主在未来一个月需要招聘10人。它应该怎么做？
- en: As an equal opportunity employer, it should ensure the fairness of its recruitment
    process as it controls it. That means in mathematical terms, for each applicant
    and all things being equal, being hired (or not) should not depend on their group
    affiliation (in this case, Weequay or Togruta). However, this results in bias
    in and of itself, as Weequay are more qualified. Note that “all things being equal”
    can be interpreted in various ways, but the usual interpretation is that the organization
    is likely not considered accountable for processes it does not control.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为一个平等机会的雇主，它应该确保招聘过程的公平性，因为它控制着这一过程。这意味着在数学术语中，对于每个申请者，一切条件相等的情况下，被录用（或不被录用）不应取决于他们所属的群体（在本例中为韦奎人或托格鲁塔人）。然而，这本身会导致偏见，因为韦奎人更有资格。注意，“一切条件相等”可以有多种解释，但通常的解释是，该组织可能不会被认为对其不控制的过程负责。
- en: The employer may also have to avoid disparate impact, that is, practices in
    employment that adversely affect one group of people of a protected characteristic
    more than another. Disparate impact is assessed on subpopulations and not on individuals;
    practically, it assesses whether proportionally speaking, the company has hired
    as many Weequay as Togruta. Once again, the target proportions may be those of
    the applicants or those of the general population, though the former is more likely,
    as again, the organization can’t be accountable for biases in processes out of
    its control.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雇主可能还需要避免不平等影响，即就业实践对一个受保护特征群体的不利影响大于对另一个群体的影响。不平等影响是针对亚群体进行评估的，而不是针对个人；实际上，它评估的是公司是否与韦奎人和托格鲁塔族的比例一样多地雇佣了人。再次强调，目标比例可能是申请者的比例或总体人口的比例，尽管前者更有可能，因为组织无法对其控制之外的过程中的偏见负责。
- en: The two objectives are mutually exclusive. In this scenario, equal opportunity
    would lead to hiring 60% (or more) Weequay and 40% (or fewer) Togruta. As a result,
    the process has a disparate impact on the two populations, because the hiring
    rates are different.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个目标是互斥的。在这种情况下，平等机会会导致招聘60%（或更多）的韦奎人和40%（或更少）的托格鲁塔族。因此，这个过程对这两个群体产生了不平等影响，因为招聘率不同。
- en: Conversely, if the process is corrected so that 40% of people hired are Togruta
    to avoid disparate impact, it means that some rejected Weequay applicants will
    have been predicted as more qualified than some accepted Togruta applicants (contradicting
    the equal opportunity assertion).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，如果过程经过修正，以使得被雇佣的人中有40%是托格鲁塔族，以避免不平等影响，这意味着一些被拒绝的韦奎人申请者被预测为比一些被接受的托格鲁塔族申请者更合格（这与平等机会的声明相矛盾）。
- en: There needs to be a trade-off—the law sometimes referred to as the 80% rule.
    In this example, it would mean that the hiring rate of Togruta should be equal
    to or larger than 80% of the hiring rate of Weequay. In this example, it means
    that it would be OK to hire up to 65% Weequay.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 需要进行权衡——有时法律称之为80%法则。在这个例子中，这意味着托格鲁塔族的雇佣率应等于或大于韦奎人雇佣率的80%。在这个例子中，这意味着可以雇佣高达65%的韦奎人。
- en: 'The point here is that defining these objectives cannot be a decision made
    by data scientists alone. But even once the objectives are defined, the implementation
    itself may also be problematic:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的重点在于，定义这些目标不能仅由数据科学家决定。但即使一旦定义了这些目标，实施本身也可能存在问题：
- en: 'Without any indications, data scientists naturally try to build equal opportunity
    models because they correspond to models of the world as it is. Most of the tools
    data scientists employ also try to achieve this because it is the most mathematically
    sound option. Yet some ways to achieve this goal may be unlawful. For example,
    the data scientist may choose to implement two independent models: one for Weequay
    and one for Togruta. This could be a reasonable way to address the biases induced
    by a training dataset in which Weequay are overrepresented, but it would induce
    a disparate treatment of the two that could be considered discriminatory.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有任何迹象的话，数据科学家自然会尝试构建平等机会的模型，因为这些模型符合世界的实际情况。大多数数据科学家使用的工具也试图实现这一目标，因为这是最符合数学原理的选择。然而，有些实现这一目标的方式可能是非法的。例如，数据科学家可以选择实施两个独立的模型：一个用于韦奎人，一个用于托格鲁塔族。这可能是解决由训练数据集中韦奎人过度代表性引起的偏见的一种合理方式，但这会导致对这两个群体的不平等对待，可能被认为是歧视性的。
- en: To let data scientists use their tools in the way they were designed (i.e.,
    to model the world as it is), they may decide to post-process the predictions
    so that they fit with the organization’s vision of the world as it should be.
    The simplest way of doing this is to choose a higher threshold for Weequay than
    for Togruta. The gap between them will adjust the trade-off between “equal opportunity”
    and “equal impact”; however, it may still be considered discriminatory because
    of the disparate treatment.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了让数据科学家按照工具设计的方式使用它们（即模拟实际世界），他们可以决定对预测结果进行后处理，使其符合组织对世界应该是什么样的愿景。最简单的做法是为韦奎人选择一个比托格鲁塔族更高的阈值。它们之间的差距将调整“平等机会”和“平等影响”之间的权衡，但由于不平等对待的原因，这仍可能被认为是歧视性的。
- en: Data scientists are unlikely to be able to sort this problem out alone (see
    [“Key Elements of Responsible AI”](ch08.html#key_elements_of_responsible_ai) for
    a broader view on the subject). This simple example illustrates the complexity
    of the subject, which may be even more complex given that there may be many protected
    attributes, and the fact that bias is as much a business question as a technical
    question.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个问题上，数据科学家可能无法独自解决问题（请参阅[“负责任人工智能的关键要素”](ch08.html#key_elements_of_responsible_ai)以获取更广泛的视角）。这个简单的例子说明了这个主题的复杂性，考虑到可能存在许多受保护的属性，以及偏见既是业务问题也是技术问题。
- en: Consequently, the solution heavily depends on the context. For instance, this
    example of Weequay and Togruta is representative of processes that give access
    to privileges. The situation is different if the process has negative impacts
    on the user (like fraud prediction that leads to transaction rejection) or is
    neutral (like disease prediction).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，解决方案在很大程度上取决于上下文。例如，Weequay 和 Togruta 的这个示例代表了使用户获得权限的过程。如果该过程对用户有负面影响（如导致交易被拒绝的欺诈预测）或者是中立的（如疾病预测），情况就不同了。
- en: Version Management and Reproducibility
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 版本管理和可复现性
- en: Discussing the evaluation and comparison of models (for fairness as discussed
    immediately before, but also a host of other factors) necessarily brings up the
    idea of version control and the reproducibility of different model versions. With
    data scientists building, testing, and iterating on several versions of models,
    they need to be able to keep all the versions straight.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论模型的评估和比较（如前文所述的公平性，以及许多其他因素）必然会提出版本控制和不同模型版本的可复现性的概念。由于数据科学家正在构建、测试和迭代多个模型版本，他们需要能够清楚地保持所有版本。
- en: 'Version management and reproducibility address two different needs:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 版本管理和可复现性解决了两个不同的需求：
- en: During the experimentation phase, data scientists may find themselves going
    back and forth on different decisions, trying out different combinations, and
    reverting when they don’t produce the desired results. That means having the ability
    to go back to different “branches” of the experiments—for example, restoring a
    previous state of a project when the experimentation process led to a dead end.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实验阶段，数据科学家可能会在不同的决策之间来回摆动，尝试不同的组合，并在产生不理想结果时回退。这意味着能够回到不同的实验“分支”的能力——例如，在实验过程中恢复项目的先前状态，当时的实验过程导致了死胡同。
- en: Data scientists or others (auditors, managers, etc.) may need to be able to
    replay the computations that led to model deployment for an audit team several
    years after the experimentation was first done.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几年后，数据科学家或其他人（审计员、经理等）可能需要重放导致模型部署的计算，这些计算是在首次进行实验几年后进行的。
- en: Versioning has arguably been somewhat solved when everything is code-based,
    with source version control technology. Modern data processing platforms typically
    offer similar capabilities for data transformation pipelines, model configuration,
    etc. Merging several parts is, of course, less straightforward than merging code
    that diverged, but the basic need is to be able to go back to some specific experiment,
    if only to be able to copy its settings to replicate them in another branch.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当一切都基于代码时，版本控制技术已经在某种程度上得到了解决。现代数据处理平台通常为数据转换管道、模型配置等提供类似的能力。当然，合并几个部分没有合并分歧的代码那么简单，但基本需求是能够回到某个特定实验，即使只是为了能够复制其设置以在另一个分支中复制它们。
- en: 'Another very important property of a model is reproducibility. After a lot
    of experiments and tweaking, data scientists may arrive at a model that fits the
    bill. But after that, operationalization necessitates model reproduction not only
    in another environment, but also possibly from a different starting point. Repeatability
    also makes debugging much easier (sometimes even simply possible). To this end,
    all facets of the model need to be documented and reusable, including:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的另一个非常重要的属性是可复现性。经过许多实验和调整后，数据科学家可能会得到一个符合要求的模型。但在此之后，运行模型需要在另一个环境中重现模型，可能还需要从不同的起始点开始。可重复性也使得调试变得更加容易（有时甚至只是可能）。为此，模型的所有方面都需要进行文档化和可重复使用，包括：
- en: Assumptions
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 假设
- en: When a data scientist makes decisions and assumptions about the problem at hand,
    its scope, the data, etc., they should all be explicit and logged so that they
    can be checked against any new information down the line.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家在做出关于手头问题、其范围、数据等的决策和假设时，所有这些都应该是明确的并且记录下来，以便随时与任何新信息进行对比。
- en: Randomness
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 随机性
- en: A lot of ML algorithms and processes, such as sampling, make use of pseudo-random
    numbers. Being able to precisely reproduce an experiment, such as for debugging,
    means to have control over that pseudo-randomness, most often by controlling the
    “seed” of the generator (i.e., the same generator initialized with the same seed
    would yield the same sequence of pseudo-random numbers).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法和过程（例如采样）使用伪随机数。能够精确地重现实验，如用于调试，意味着要控制这种伪随机性，通常是通过控制生成器的“种子”（即使用相同种子初始化的相同生成器将产生相同的伪随机数序列）。
- en: Data
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 数据
- en: To get repeatability, the same data must be available. This can sometimes be
    tricky because the storage capacity required to version data can be prohibitive
    depending on the rate of update and quantity. Also, branching on data does not
    yet have as rich an ecosystem of tools as branching on code.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现重复性，必须有相同的数据可用。这有时可能会有些棘手，因为版本化数据所需的存储容量可能会因更新速度和数量而受到限制。此外，与代码分支不同，数据分支尚未拥有如此丰富的工具生态系统。
- en: Settings
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 设置
- en: 'This one is a given: all processing that has been done must be reproducible
    with the same settings.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个已知的事实：所有已完成的处理必须在相同的设置下可再现。
- en: Results
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 结果
- en: While developers use merging tools to compare and merge different text file
    versions, data scientists need to be able to compare in-depth analysis of models
    (from confusion matrices to partial dependence plots) to obtain models that satisfy
    the requirements.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员使用合并工具来比较和合并不同的文本文件版本，而数据科学家需要能够比较从混淆矩阵到偏依赖图的深度模型分析，以获得满足要求的模型。
- en: Implementation
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 实施
- en: Ever-so-slightly different implementations of the same model can actually yield
    different models, enough to change the predictions on some close calls. And the
    more sophisticated the model, the higher the chances that these discrepancies
    happen. On the other hand, scoring a dataset in bulk with a model comes with different
    constraints than scoring a single record live in an API, so different implementations
    may sometimes be warranted for the same model. But when debugging and comparing,
    data scientists need to keep the possible differences in mind.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 同一模型的微小不同实现实际上可能会产生不同的模型，足以改变某些接近调用的预测。并且模型越复杂，这些差异发生的可能性就越高。另一方面，批量使用模型对数据集进行评分与在API中实时评分单个记录具有不同的约束条件，因此有时可能需要为同一模型进行不同的实现。但在调试和比较时，数据科学家需要记住可能的差异。
- en: Environment
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 环境
- en: Given all the steps covered in this chapter, it’s clear that a model is not
    just its algorithm and parameters. From the data preparation to the scoring implementation,
    including feature selection, feature encoding, enrichment, etc., the environment
    in which several of those steps run may be more or less implicitly tied to the
    results. For instance, a slightly different version of a Python package involved
    in one step may change the results in ways that can be hard to predict. Preferably,
    data scientists should make sure that the runtime environment is also repeatable.
    Given the pace at which ML is evolving, this might require techniques that freeze
    the computation environments.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到本章涵盖的所有步骤，显然一个模型不仅仅是其算法和参数。从数据准备到评分实现，包括特征选择、特征编码、丰富化等，这些步骤运行的环境可能更多或更少地与结果隐含相关。例如，一个在某一步骤中涉及的Python包的稍有不同版本可能以难以预测的方式改变结果。最好，数据科学家应确保运行时环境也是可重复的。鉴于机器学习的发展速度，这可能需要冻结计算环境的技术。
- en: Fortunately, part of the underlying documentation tasks associated with versioning
    and reproducibility can be automated, and the use of an integrated platform for
    design and deployment can greatly decrease the reproducibility costs by ensuring
    structured information transfer.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，与版本和可再现性相关的底层文档任务的一部分可以自动化，并且使用集成平台进行设计和部署可以通过确保结构化信息传输大大降低可再现性成本。
- en: Clearly, while maybe not the sexiest part of model development, version management
    and reproducibility are critical to building machine learning efforts in real-world
    organizational settings where governance—including audits—matters.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，虽然可能不是模型开发中最吸引人的部分，但版本管理和可重现性对于在现实世界的组织环境中构建机器学习工作至关重要，其中包括治理和审计在内。
- en: Closing Thoughts
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结语
- en: Model development is one of the most critical and consequential steps of MLOps.
    The many technical questions that are necessarily answered during this phase have
    big repercussions on all aspects of the MLOps process throughout the life of the
    models. Therefore, exposure, transparency, and collaboration are crucial to long-term
    success.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发是 MLOps 中最关键和最具影响力的步骤之一。在这个阶段必须回答许多技术问题，这些问题对模型的整个生命周期中的所有方面都有重大影响。因此，暴露、透明度和协作对长期成功至关重要。
- en: The model development stage is also the one that has been practiced the most
    by profiles like data scientists and, in the pre-MLOps world, often represents
    the whole ML effort, yielding a model that will then be used as is (with all its
    consequences and limitations).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发阶段也是数据科学家等个人经常实践的阶段，在 MLOps 之前的世界中，这通常代表整个机器学习工作，生成的模型将会按原样使用（带有其所有的后果和局限性）。
- en: ^([1](ch04.html#ch01fn6-marker)) CycleGAN is the implementation of [recent research
    by Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros](https://oreil.ly/7A_qd).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch04.html#ch01fn6-marker)) CycleGAN 是由 Jun-Yan Zhu、Taesung Park、Phillip
    Isola 和 Alexei A. Efros 的最新研究实现的。
