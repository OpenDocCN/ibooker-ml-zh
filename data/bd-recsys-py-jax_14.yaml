- en: Chapter 11\. Personalized Recommendation Metrics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章. 个性化推荐度量
- en: Having explored the powerful methodologies of MF and neural networks in the
    context of personalization, we are now equipped with potent tools to craft sophisticated
    recommendation systems. However, the order of recommendations in a list may have
    a profound impact on user engagement and satisfaction.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索了MF和神经网络在个性化上下文中的强大方法后，我们现在装备有强大的工具来打造复杂的推荐系统。然而，在列表中的推荐顺序可能对用户参与度和满意度产生深远影响。
- en: Our journey so far has primarily been focused on predicting what a user may
    like, using latent factors or deep learning architectures. However, the manner
    in which we present these predictions, or more formally, how we rank these recommendations,
    holds paramount significance. Therefore, this chapter will shift our gaze from
    the prediction problem and will unravel the complex landscape of ranking in recommendation
    systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的旅程主要集中在预测用户可能喜欢的内容，使用潜在因素或深度学习架构。然而，我们如何呈现这些预测结果，或者更正式地说，我们如何排列这些推荐，这些都具有至关重要的意义。因此，这一章将把我们的视线从预测问题转向排名在推荐系统中的复杂景观。
- en: This chapter is dedicated to understanding key ranking metrics including mean
    average precision (mAP), mean reciprocal rank (MRR), and normalized discounted
    cumulative gain (NDCG). Each of these metrics takes a unique approach toward quantifying
    the quality of our rankings, catering to different aspects of the user interaction.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章专注于理解关键的排名度量标准，包括平均精度（mAP）、平均倒数排名（MRR）和归一化折损累积增益（NDCG）。这些度量标准各自采用独特的方法来量化我们排名的质量，满足用户交互的不同方面。
- en: We’ll dive into the intricacies of these metrics, unveiling their computational
    details and discussing their interpretation, covering their strengths and weaknesses,
    and pointing out their specific relevance to various personalization scenarios.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将深入研究这些度量标准的复杂性，揭示它们的计算细节，讨论它们的解释，涵盖它们的优势和劣势，并指出它们在各种个性化场景中的具体相关性。
- en: This exploration forms an integral part of the evaluation process in recommendation
    systems. It not only gives us a robust framework to measure the performance of
    our system but also provides essential insights into understanding how different
    algorithms might perform in online settings. This will lay the foundation for
    future discussions on algorithmic bias, diversity in recommendations, and a multistakeholder
    approach to recommendation systems.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这种探索是推荐系统评估过程的一个重要组成部分。它不仅为我们提供了一个强大的框架来衡量系统的性能，还提供了理解不同算法在在线设置中可能表现的重要见解。这将为未来讨论算法偏见、推荐多样性以及推荐系统的多利益相关者方法奠定基础。
- en: In essence, the knowledge garnered in this chapter will be instrumental in fine-tuning
    our recommendation system, ensuring that we don’t just predict well but also recommend
    in a way that truly resonates with individual user preferences and behaviors.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，本章所获得的知识将对微调我们的推荐系统至关重要，确保我们不仅预测得好，而且推荐方式真正与个体用户的偏好和行为产生共鸣。
- en: Environments
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 环境
- en: Before we dig into defining the key metrics, we’re going to spend a few moments
    discussing the kinds of evaluation we can do. Evaluation for recommendation systems,
    as you’ll soon see, is frequently characterized by how *relevant* the recommendations
    are for a user. This is similar to search metrics, but we add in additional factors
    to account for *where* in the list the most relevant items are.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入定义关键度量标准之前，我们将花一些时间讨论我们可以进行的评估类型。正如您很快会看到的那样，推荐系统的评估通常通过推荐对用户的*相关性*来特征化。这与搜索度量类似，但我们加入了额外因素来考虑最相关项在列表中的*位置*。
- en: For an extremely comprehensive view on evaluation of recommender systems, the
    recent project [RecList](https://oreil.ly/b6mPy) builds a useful checklist-based
    framework for organizing metrics and evaluations.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于推荐系统评估的极其全面的视角，最近的项目[RecList](https://oreil.ly/b6mPy)构建了一个基于检查表的有用框架，用于组织度量和评估。
- en: 'Often you’ll hear about evaluating recommenders in a few setups:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通常你会听到在几种设置下评估推荐系统：
- en: Online/offline
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线/离线
- en: User/item
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户/物品
- en: A/B
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A/B
- en: Each setup provides slightly different kinds of evaluations and tells you different
    things. Let’s quickly break down the differences to set some assumptions about
    terminology.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 每种设置提供略有不同类型的评估，并告诉您不同的信息。让我们快速分解这些差异，以建立有关术语的一些假设。
- en: Online and Offline
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线和离线
- en: When we refer to online versus offline recommenders, we are referring to *when*
    you’re running evals. In *offline evaluation*, you start with a test/evaluation
    dataset, outside your production system, and compute a set of metrics. This is
    often the simplest recommender to set up but has the highest expectation of existing
    data. Using historical data, you construct a set of relevant responses, which
    you can then use during simulated inference. This approach is the most similar
    to other kinds of traditional ML, although with slightly different computations
    for the error.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们提到在线与离线推荐器时，我们指的是*何时*运行评估。在*离线评估*中，您从测试/评估数据集开始，该数据集位于生产系统之外，并计算一组指标。这通常是设置最简单的推荐器，但对现有数据的期望最高。使用历史数据，您构建了一组相关响应，然后可以在模拟推断期间使用。这种方法与其他种类的传统机器学习最相似，尽管对误差的计算略有不同。
- en: When we’re training large models, these datasets are similar to an offline dataset.
    We previously saw prequential data, which is much more relevant in recommendation
    systems than in lots of other ML applications. Sometimes you’ll hear people say
    that “all recommenders are sequential recommenders” because of the importance
    of historical exposure to the recommender problem.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们训练大型模型时，这些数据集类似于离线数据集。我们之前看到了前序数据，这在推荐系统中比许多其他机器学习应用程序更为相关。有时您会听到人们说“所有推荐系统都是序列推荐系统”，因为历史曝光对推荐问题的重要性。
- en: '*Online evaluation* takes place during inference, usually in production. The
    tricky part is that you essentially never know the counterfactual outcomes. You
    can compute specific metrics on the online rankings: frequency and distributions
    of covariates, CTR/success rate, or time on platform, but ultimately these are
    different from the offline metrics.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*在线评估*发生在推断期间，通常是在生产环境中。棘手的部分在于，你基本上永远不知道反事实的结果。您可以计算在线排名的特定指标：协变量的频率和分布，点击率/成功率，或平台上的停留时间，但最终这些指标与离线指标有所不同。'
- en: Bootstrapping from Historical Evaluation Data
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从历史评估数据中自举
- en: One of the most common questions from people building a recommender from scratch
    is “Where do you get the initial training data?” This is a hard problem. Ultimately,
    you have to be clever to come up with a useful dataset. Consider our co-occurrence
    data in the Wikipedia recommender; we didn’t require any user interactions to
    get to a set of data to build a recommender. Bootstrapping from item to item is
    the most popular strategy, but you can use other tricks as well. The simplest
    way to start moving into user-item recommenders is to simply ask the user questions.
    If you ask for preference information across a set of item features, you can build
    simple models that start to incorporate this.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始构建推荐系统的人最常问的一个问题是“你从哪里获取初始训练数据？”这是一个难题。最终，您必须聪明地构建一个有用的数据集。考虑我们在维基百科推荐系统中的共现数据；我们并不需要任何用户交互来获取一组用于构建推荐系统的数据。从项目到项目的自举是最流行的策略，但您也可以使用其他技巧。进入用户-项目推荐器的最简单方法是简单地询问用户问题。如果您要求跨一组项目特征的偏好信息，您可以构建开始融入此信息的简单模型。
- en: User Versus Item Metrics
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户与项目指标
- en: Because recommender systems are personalization machines, it can be easy to
    think that we always want to be making recommendations for the user and measuring
    the performance as such. Subtleties exist, though. We want to be sure individual
    items are getting a fair chance, and sometimes looking at the other side of the
    equation can help assess this. In other words, are the items getting recommended
    frequently enough to have a chance to find their niche? We should explicitly compute
    our metrics over user *and* item axes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因为推荐系统是个性化机器，很容易认为我们总是希望为用户提供推荐并衡量其性能。然而，存在微妙之处。我们要确保每个单独的项目都有公平的机会，并且有时审视方程的另一面可以帮助评估这一点。换句话说，推荐的项目是否频繁推荐到足够有机会找到自己的定位？我们应明确计算我们的指标跨用户
    *和* 项目轴。
- en: Another aspect of item-side metrics is for set-based recommenders. The other
    items that are recommended in context can have a significant effect on the performance
    of a recommendation. As a result, we should be careful to measure the pairwise
    item metrics in our large-scale evaluations.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 项目方面度量的另一个方面是基于集合的推荐器。在上下文中推荐的其他项目可以显著影响推荐的性能。因此，在我们的大规模评估中，我们应该谨慎地测量成对项目指标。
- en: A/B Testing
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A/B 测试
- en: It’s good to use randomized, controlled trials to evaluate how your new recommendation
    model is performing. For recommendations, this is quite tricky. At the end of
    this chapter, you’ll see some of the nuance, but for now, let’s consider a quick
    reminder of how to think about A/B testing in a closed-loop paradigm.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于评估新推荐模型的性能，使用随机对照试验是很好的。对于推荐来说，这非常棘手。在本章的最后，您将看到一些细微之处，但现在，让我们考虑一下在闭环范式中如何思考
    A/B 测试的一个快速提醒。
- en: A/B tests ultimately attempt to estimate the effect size of swapping one model
    in for another; effect size estimation is the process of measuring the causal
    impact of an intervention on a target metric. First, we would need to deploy two
    recommender models. We’d also hope that there’s a reasonable randomization of
    users into each of the recommenders. However, what’s the randomization unit? It’s
    easy to quickly assume it’s the user, but what has changed about the recommender?
    Has the recommender changed in a way that covaries with some properties of the
    distribution—e.g., have you built a new recommender that is less friendly toward
    seasonal TV specials just as we enter into the second week of November?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: A/B 测试最终试图估计将一个模型替换为另一个模型的效果大小；效果大小估计是衡量干预对目标指标的因果影响的过程。首先，我们需要部署两个推荐模型。我们也希望用户在每个推荐系统中有合理的随机分配。但是，随机分配单位是什么？很容易迅速假设它是用户，但是推荐系统发生了什么变化？推荐系统发生了什么变化，使得它与分布的某些属性相关联——例如，您是否构建了一个新的推荐系统，该系统对于季节性电视特别节目的友好程度较低，就在我们进入十一月的第二周？
- en: Another consideration with this sort of testing for recommendation systems is
    the long-term compounding effects. A frequent rejoinder about a series of positive
    A/B test outcomes over several years is “Have you tested the first recommender
    against the last?” This is because populations change, both the users and the
    items. As you also vary the recommender system, you frequently find yourself in
    a double-blind situation where you’ve never seen this user or item population
    with any other recommender. If all the effect sizes of every A/B test were additive
    across the industry, the world GDP would likely be two to three times as large.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种考虑推荐系统这种测试的方式是长期复利效应。关于几年来一系列积极的 A/B 测试结果的常见反驳是“你是否测试了第一个推荐系统和最后一个推荐系统之间的差异？”这是因为人口会变化，用户和项目都会变化。当您也改变推荐系统时，您经常会发现自己处于双盲情况下，在这种情况下，您从未看到过这个用户或项目群体与任何其他推荐系统。如果每个
    A/B 测试的效果大小在整个行业中都是相加的，那么世界 GDP 可能会增加两到三倍。
- en: The way to guard against protests like this is via a *long-term holdout*, a
    random subset of users (continually being added to) who will not be upgraded to
    new models through time. By measuring the target metrics on this set versus the
    most cutting-edge model in production, you’re always able to understand the long-term
    effects of your work. The downside of a long-term holdout? It’s hard to maintain,
    and it’s hard to sacrifice some of the effects of your work on a subset of the
    population.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 抵制这种抗议的方法是通过*长期保留*，这是一组随机选择的用户（不断增加），他们不会随时间升级到新模型。通过在此集合上测量目标指标与生产中最前沿的模型相比，您始终能够了解您工作的长期影响。长期保留的缺点是什么？它
- en: Now let’s finally get to the metrics already!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们最终谈谈指标吧！
- en: Recall and Precision
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 召回率和精确度
- en: Let’s begin by considering four recommender problems and how each may have different
    implications for the kind of results you want.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先考虑四个推荐问题以及每个问题对你想要的结果的不同影响。
- en: 'First, let’s consider entering a bookstore and looking for a book by a popular
    author. We would say this is the recommender problem:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们考虑进入书店并寻找一本知名作者的书。我们会说这是推荐问题：
- en: Provides a lot of recommendations
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提   提供了大量的推荐
- en: Offers few possible relevant results
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了一些可能的相关结果
- en: Additionally, if the bookstore has a good selection, we’d expect that *all*
    the relevant results are contained in the recommendations because bookstores often
    carry most or all of an author’s oeuvre once they’ve become popular. However,
    many of the recommendations—the books in the bookstore–are simply not relevant
    for this search.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果书店的选择很好，我们期望*所有*相关结果都包含在推荐中，因为一旦作者变得受欢迎，书店通常会携带大多数或所有作者的作品。然而，许多推荐——书店里的书——对于这个搜索来说根本不相关。
- en: 'Second, let’s consider looking for a gas station nearby on a mapping app while
    in a large metro. We expect that a lot of gas stations are relatively close by,
    but you would probably consider only the first couple—or maybe even only one,
    the first one that you see. Thus a recommender for this problem has the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，让我们考虑在大都会地区使用地图应用程序附近找加油站。我们预期附近有很多加油站，但你可能只考虑前几个—或者甚至只有一个，你看到的第一个。因此，这个问题的推荐器有以下特点：
- en: Many relevant results
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多相关结果。
- en: Few useful recommendations
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很少有用的建议。
- en: In the first scenario, the relevant results may be fully contained in the recommendations,
    and in the second scenario, the recommendations may be fully contained in the
    relevant results.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个情景中，相关结果可能完全包含在建议中；而在第二个情景中，建议可能完全包含在相关结果中。
- en: Let’s now look at more common scenarios.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看更常见的情景。
- en: 'For our third example, consider that you’re searching on a streaming video
    platform for something to watch tonight when you’re feeling romantic. Streaming
    platforms tend to show a lot of recommendations—pages and pages from this one
    theme or another. But on this night, and on just this platform, only a couple
    of movies or TV shows might really fit what you’re looking for. Our recommender,
    then, does the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的第三个示例，请考虑您在流媒体视频平台上搜索今晚想要观看的浪漫电影。流媒体平台往往会显示很多建议—一页又一页来自这个或那个主题的建议。但是在这个夜晚，在这个平台上，只有几部电影或电视节目可能真正符合您的要求。因此，我们的推荐器做以下事情：
- en: Provides many recommendations
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了许多建议。
- en: Offers only a few that are actually relevant
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅提供了一些实际相关的建议。
- en: However, importantly, not all relevant results will be in the recommendations!
    As we know, different platforms have different media, so some of the relevant
    results won’t appear in the recommendations no matter how many we look at.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，重要的是，并非所有相关结果都会出现在建议中！正如我们所知，不同的平台具有不同的媒体，所以一些相关结果无论我们查看多少都不会出现在建议中。
- en: 'Fourth, and finally, you’re a high-end coffee lover with distinguished tastes
    headed into the local roaster for a third-wave, single-origin coffee. As an experienced
    coffee connoisseur, you love high-quality coffees from all over the world and
    enjoy most but not all origins. On any given day, your local cafe has only a few
    single-origin hand-brewed options. Despite your worldly palette, there are some
    popular terroirs that you just don’t love. This little recommendation brew bar
    can be described as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 第四，最后，您是一位高端咖啡爱好者，品味高雅，正前往当地的烘焙商店品尝第三浪、单品种咖啡。作为经验丰富的咖啡鉴赏家，您喜欢来自世界各地的高质量咖啡，大多数都很享受但并非所有产地。在任何给定的一天，您的本地咖啡馆只有几种单品种手冲咖啡。尽管您有着世界性的口味，但有一些受欢迎的产地您并不喜欢。这个小小的推荐啤酒吧可以描述如下：
- en: Provides a few recommendations
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了一些建议。
- en: Offers many possible recommendations that are relevant
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了许多可能相关的建议。
- en: On any given day, only some of the few recommendations may be relevant to you.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何给定的一天，只有一些建议可能与您相关。
- en: So those are our matching four scenarios. For the latter two, the intersection
    between recommendation and relevance may be proportionally small or large—or even
    empty! The main idea is that the full size of the smaller sample is not always
    in use.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这些是我们匹配的四个情景。对于后两种情况，建议和相关性之间的交集可能很小或很大—甚至可能为空！主要思想是较小样本的完整大小并不总是在使用中。
- en: 'Now that we’ve worked through a few examples, let’s see how they relate to
    the core metrics for a recommender: precision and recall *@ k* ([Figure 11-1](#recall_sets)).
    Focusing on examples 3 and 4, we can see that only some of the recommendations
    intersect with the options that are relevant. And only some of the relevant options
    intersect with the recommendations. It’s often overlooked, but in fact *these
    two ratios define our metrics*—let’s go!'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经通过了一些示例，让我们看看它们与推荐器的核心指标之间的关系：精度和召回率 *@ k*（[图11-1](#recall_sets)）。关注示例3和4，我们可以看到只有一些建议与相关选项相交。而只有一些相关选项与建议相交。它经常被忽视，但事实上*这两个比率定义了我们的指标*—让我们去吧！
- en: '![The sets in a retreival problem](assets/brpj_1101.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![检索问题中的集合](assets/brpj_1101.png)'
- en: Figure 11-1\. Recall and precision sets
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-1\. 召回和精度集合
- en: '@ k'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '@ k'
- en: In much of this chapter and RecSys metrics discussion, we say things like *@
    k*. This means “at *k*,” which should really be “in *k*” or “out of *k*.” These
    are simply the size of the set of recommendations. We often anchor the customer
    experience on how many recommendations we can show the user without the experience
    suffering. We also need to know the cardinality of the set of relevant items,
    which we call *@ r*. Note that while it may not feel like it’s possible to ever
    know this number, we assume this refers to “known relevant” options via our training
    or test data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章和推荐系统度量讨论的大部分内容中，我们会说“*@ k*”。这意味着“在*k*”，实际上应该是“在*k*中”或“在*k*之外”。这些只是建议集的大小。我们经常将客户体验锚定在我们可以展示给用户多少建议而不会影响体验。我们还需要知道相关项集合的基数，我们称之为*@
    r*。请注意，虽然可能感觉永远无法知道这个数字，但我们假设这是指通过我们的训练或测试数据知道的“已知相关”选项。
- en: Precision at k
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Top-k 精度
- en: '*Precision* is the ratio of the size of the set of relevant recommendations
    to *k*, the size of the set of recommendations.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*精度*是相关建议集大小与建议集合*k*大小的比率。'
- en: <math alttext="upper P r e c i s i o n commercial-at k equals StartFraction
    n u m Subscript r e l e v a n t Baseline Over left-parenthesis k right-parenthesis
    EndFraction" display="block"><mrow><mi>P</mi> <mi>r</mi> <mi>e</mi> <mi>c</mi>
    <mi>i</mi> <mi>s</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>@</mo> <mi>k</mi> <mo>=</mo>
    <mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mi>n</mi><mi>u</mi><msub><mi>m</mi>
    <mrow><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>t</mi></mrow></msub></mrow>
    <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></mfrac></mstyle></mrow></math>
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P r e c i s i o n commercial-at k equals StartFraction
    n u m Subscript r e l e v a n t Baseline Over left-parenthesis k right-parenthesis
    EndFraction" display="block"><mrow><mi>P</mi> <mi>r</mi> <mi>e</mi> <mi>c</mi>
    <mi>i</mi> <mi>s</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>@</mo> <mi>k</mi> <mo>=</mo>
    <mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mi>n</mi><mi>u</mi><msub><mi>m</mi>
    <mrow><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>t</mi></mrow></msub></mrow>
    <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></mfrac></mstyle></mrow></math>
- en: Notice that the size of the relevant items doesn’t appear in the formula. That’s
    OK; the size of the intersection is still dependent on the size of the set of
    relevant items.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，相关项的大小在公式中并不出现。没关系；交集的大小仍然取决于相关项集合的大小。
- en: Looking at our examples, 2 technically has the highest precision, but it’s a
    bit of a red herring because of the number of relevant results. This is one reason
    precision is not the most common metric for evaluating recommendation systems.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 看看我们的例子，技术上例子2有最高的精度，但由于相关结果的数量，它有点误导人。这是精度不是评估推荐系统最常见的度量标准的一个原因。
- en: Recall at k
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在*k*处的召回率
- en: '*Recall* is the ratio of the size of the set of relevant recommendations to
    *r*, the size of the set of relevant items.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*召回率*是相关建议集大小与相关项集合*r*大小的比率。'
- en: But wait! If the ratio is the relevant recommendations over the relevant items,
    where is *k*? *k* is still important here because the size of the set of recommendations
    constrains the possible size of the intersection. Recall that these ratios are
    operating on that intersection that is always dependent on *k*. This means you
    often consider the max of *r* and *k*.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 但等等！如果比率是相关建议与相关项的比率，那么*k*在哪里？在这里*k*仍然很重要，因为建议集的大小限制了可能的交集大小。请记住，这些比率是在始终依赖于*k*的交集上操作的。这意味着你经常考虑*r*和*k*的最大值。
- en: In scenario 3, we hope that some of the movies that fit our heart’s desire will
    be on the right streaming platform. The number of these divided by the count of
    all the media anywhere is the *recall*. If all your relevant movies are on this
    platform, you might call that *total recall*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3个场景中，我们希望一些符合我们心愿的电影会出现在正确的流媒体平台上。这些电影的数量除以所有媒体的总数就是*召回率*。如果所有相关的电影都在这个平台上，你可能会称之为*全面召回*。
- en: 'Scenario 4’s café experience shows that recall is sometimes the inverse probability
    of an avoid; because you like so many coffees, we might instead find it easier
    to talk about what you don’t like. In this case, the number of avoids in the offering
    will have a large effect on the recall:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 第4场景的咖啡馆体验表明，召回率有时是一个避免的反向概率；因为你喜欢这么多的咖啡，我们可能更容易谈论你不喜欢的事物。在这种情况下，提供的避免数量将对召回率产生很大影响：
- en: <math alttext="upper R e c a l l commercial-at k equals StartFraction left-parenthesis
    k minus upper A v o i d commercial-at k right-parenthesis Over n u m Subscript
    r e l e v a n t Baseline EndFraction" display="block"><mrow><mi>R</mi> <mi>e</mi>
    <mi>c</mi> <mi>a</mi> <mi>l</mi> <mi>l</mi> <mo>@</mo> <mi>k</mi> <mo>=</mo> <mstyle
    displaystyle="true" scriptlevel="0"><mfrac><mrow><mo>(</mo><mi>k</mi><mo>-</mo><mi>A</mi><mi>v</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo>@</mo><mi>k</mi><mo>)</mo></mrow>
    <mrow><mi>n</mi><mi>u</mi><msub><mi>m</mi> <mrow><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>t</mi></mrow></msub></mrow></mfrac></mstyle></mrow></math>
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper R e c a l l commercial-at k equals StartFraction left-parenthesis
    k minus upper A v o i d commercial-at k right-parenthesis Over n u m Subscript
    r e l e v a n t Baseline EndFraction" display="block"><mrow><mi>R</mi> <mi>e</mi>
    <mi>c</mi> <mi>a</mi> <mi>l</mi> <mi>l</mi> <mo>@</mo> <mi>k</mi> <mo>=</mo> <mstyle
    displaystyle="true" scriptlevel="0"><mfrac><mrow><mo>(</mo><mi>k</mi><mo>-</mo><mi>A</mi><mi>v</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo>@</mo><mi>k</mi><mo>)</mo></mrow>
    <mrow><mi>n</mi><mi>u</mi><msub><mi>m</mi> <mrow><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>t</mi></mrow></msub></mrow></mfrac></mstyle></mrow></math>
- en: This is the core mathematical definition for recall and is often one of the
    first measurements we’ll consider because it’s a pure estimate of how your retrieval
    is performing.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这是召回率的核心数学定义，通常是我们考虑的第一个衡量标准，因为它纯粹地估计了你的检索性能如何。
- en: R-precision
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: R-精度
- en: If we also have a ranking on our recommendations, we can take the ratio of relevant
    recommendations to *r* in the *top-r* recommendations. This improves this metric
    in cases where *r* is very small, as in examples 1 and 3.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在建议上也有排名，我们可以在*top-r*建议中考虑相关建议到*r*的比率。这在*r*非常小的情况下（例如示例1和3）改进了这个度量标准。
- en: mAP, MMR, NDCG
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: mAP、MMR、NDCG
- en: 'Having delved into the reliable domains of precision@*k* and recall@*k*, we’ve
    gained valuable insights into the quality of our recommendation systems. However,
    these metrics, as crucial as they are, can sometimes fall short in capturing an
    important aspect of these systems: *the order of recommendations*.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 深入研究了精度@*k*和召回率@*k*的可靠领域后，我们对我们推荐系统的质量获得了宝贵的见解。然而，尽管这些指标至关重要，有时却无法完全捕捉这些系统的一个重要方面：*推荐顺序*。
- en: In recommendation systems, the ordering in which we present suggestions carries
    significant weight and needs to be evaluated to ensure that it’s effective.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在推荐系统中，我们提供建议的顺序具有重要的权重，需要评估以确保其有效性。
- en: That’s why we’ll now journey beyond precision@*k* and recall@*k* to explore
    some key ranking-sensitive metrics—namely, mean average precision (mAP), mean
    reciprocal rank (MRR), and normalized discounted cumulative gain (NDCG). These
    metrics consider not only whether our recommendations are relevant but also whether
    they are well-ordered.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我们现在将超越 precision@*k* 和 recall@*k*，探索一些关键的排名敏感性指标——即平均精度（mAP）、平均倒数排名（MRR）和归一化折现累计增益（NDCG）。
- en: The mAP metric lends importance to each relevant document and its position,
    and MRR concentrates on the rank of the first relevant item. NDCG gives more importance
    to relevant documents at higher ranks. By understanding these metrics, you’ll
    have an even more robust set of tools to evaluate and refine your recommendation
    systems.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: mAP 指标强调每个相关文档及其位置的重要性，而 MRR 则集中于第一个相关项的排名。NDCG 更重视高排名的相关文档。通过了解这些指标，您将拥有更强大的工具来评估和优化推荐系统。
- en: So, let’s carry on with our exploration, striking a balance between precision
    and comprehensibility. By the end of this section, you will be well equipped to
    handle these essential evaluation methods in a confident and knowledgeable manner.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们继续探索，平衡精确性与易懂性。到本节末，您将能够自信而且有见地地处理这些重要的评估方法。
- en: mAP
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: mAP
- en: This vital metric in recommendation systems is particularly adept at accounting
    for the rank of relevant items. If, in a list of five items, the relevant ones
    are found at positions 2, 3, and 5, mAP would be calculated by computing precision@2,
    precision@3, and precision@5 and then taking an average of these values. The strength
    of mAP lies in its sensitivity to the ordering of relevant items, providing a
    higher score when these items are ranked higher.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在推荐系统中，这一重要的指标尤其擅长考虑相关项的排名。例如，在五个项目的列表中，如果相关项目分别位于位置 2、3 和 5，那么 mAP 将通过计算 precision@2、precision@3
    和 precision@5 并对这些值取平均来计算。mAP 的强大之处在于其对相关项顺序的敏感性，当这些项排名较高时，提供更高的分数。
- en: 'Consider an example with two recommendation algorithms A and B:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个具有两个推荐算法 A 和 B 的示例：
- en: 'For algorithm A, we compute the mAP as follows:'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于算法 A，我们计算 mAP 如下：
- en: (precision@2 + precision@3 + precision@5) / 3 = (1/2 + 2/3 + 3/5) / 3 = 0.6
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: （precision@2 + precision@3 + precision@5）/ 3 = （1/2 + 2/3 + 3/5）/ 3 = 0.6
- en: 'For algorithm B, which perfectly ranks the items, we calculate mAP as follows:'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于完美排列项目的算法 B，我们计算 mAP 如下：
- en: mAP = (precision@1 + precision@2 + precision@3) / 3 = (1/1 + 2/2 + 3/3) / 3
    = 1
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: mAP = （precision@1 + precision@2 + precision@3）/ 3 = （1/1 + 2/2 + 3/3）/ 3 =
    1
- en: 'The generalized formula for mAP across a set of queries Q is shown here:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: mAP 在查询集合 Q 上的广义公式如下所示：
- en: <math alttext="dollar-sign m upper A upper P equals StartFraction 1 Over StartAbsoluteValue
    upper Q EndAbsoluteValue EndFraction sigma-summation Underscript q equals 1 Overscript
    StartAbsoluteValue upper Q EndAbsoluteValue Endscripts StartFraction 1 Over m
    Subscript q Baseline EndFraction sigma-summation Underscript k equals 1 Overscript
    n Endscripts upper P left-parenthesis k right-parenthesis asterisk r e l left-parenthesis
    k right-parenthesis dollar-sign"><mrow><mi>m</mi> <mi>A</mi> <mi>P</mi> <mo>=</mo>
    <mfrac><mn>1</mn> <mrow><mo>|</mo><mi>Q</mi><mo>|</mo></mrow></mfrac> <msubsup><mo>∑</mo>
    <mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow> <mrow><mo>|</mo><mi>Q</mi><mo>|</mo></mrow></msubsup>
    <mfrac><mn>1</mn> <msub><mi>m</mi> <mi>q</mi></msub></mfrac> <msubsup><mo>∑</mo>
    <mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup> <mi>P</mi> <mrow><mo>(</mo>
    <mi>k</mi> <mo>)</mo></mrow> <mo>*</mo> <mi>r</mi> <mi>e</mi> <mi>l</mi> <mrow><mo>(</mo>
    <mi>k</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="dollar-sign m upper A upper P equals StartFraction 1 Over StartAbsoluteValue
    upper Q EndAbsoluteValue EndFraction sigma-summation Underscript q equals 1 Overscript
    StartAbsoluteValue upper Q EndAbsoluteValue Endscripts StartFraction 1 Over m
    Subscript q Baseline EndFraction sigma-summation Underscript k equals 1 Overscript
    n Endscripts upper P left-parenthesis k right-parenthesis asterisk r e l left-parenthesis
    k right-parenthesis dollar-sign"><mrow><mi>m</mi> <mi>A</mi> <mi>P</mi> <mo>=</mo>
    <mfrac><mn>1</mn> <mrow><mo>|</mo><mi>Q</mi><mo>|</mo></mrow></mfrac> <msubsup><mo>∑</mo>
    <mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow> <mrow><mo>|</mo><mi>Q</mi><mo>|</mo></mrow></msubsup>
    <mfrac><mn>1</mn> <msub><mi>m</mi> <mi>q</mi></msub></mfrac> <msubsup><mo>∑</mo>
    <mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup> <mi>P</mi> <mrow><mo>(</mo>
    <mi>k</mi> <mo>)</mo></mrow> <mo>*</mo> <mi>r</mi> <mi>e</mi> <mi>l</mi> <mrow><mo>(</mo>
    <mi>k</mi> <mo>)</mo></mrow></mrow></math>
- en: Here, <math alttext="StartAbsoluteValue upper Q EndAbsoluteValue"><mrow><mo>|</mo>
    <mi>Q</mi> <mo>|</mo></mrow></math> is the total number of queries, <math alttext="m
    Subscript q"><msub><mi>m</mi> <mi>q</mi></msub></math> is the number of relevant
    documents for a specific query <math alttext="q"><mi>q</mi></math> , <math alttext="upper
    P left-parenthesis k right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>k</mi>
    <mo>)</mo></mrow></math> stands for the precision at the _k_th cutoff, and <math
    alttext="r e l left-parenthesis k right-parenthesis"><mrow><mi>r</mi> <mi>e</mi>
    <mi>l</mi> <mo>(</mo> <mi>k</mi> <mo>)</mo></mrow></math> is an indicator function
    equating to 1 if the item at rank <math alttext="k"><mi>k</mi></math> is relevant,
    and 0 otherwise.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，<math alttext="StartAbsoluteValue upper Q EndAbsoluteValue"><mrow><mo>|</mo>
    <mi>Q</mi> <mo>|</mo></mrow></math> 是查询总数，<math alttext="m Subscript q"><msub><mi>m</mi>
    <mi>q</mi></msub></math> 是特定查询 <math alttext="q"><mi>q</mi></math> 的相关文档数，<math
    alttext="upper P left-parenthesis k right-parenthesis"><mrow><mi>P</mi> <mo>(</mo>
    <mi>k</mi> <mo>)</mo></mrow></math> 表示截止到第 _k_ 个位置的精确度，<math alttext="r e l left-parenthesis
    k right-parenthesis"><mrow><mi>r</mi> <mi>e</mi> <mi>l</mi> <mo>(</mo> <mi>k</mi>
    <mo>)</mo></mrow></math> 是一个指示函数，如果第 k 个位置的项目是相关的，则等于 1，否则为 0。
- en: MRR
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MRR
- en: Another effective metric used in recommendation systems is MRR. Unlike MAP,
    which considers all relevant items, MRR primarily focuses on the position of the
    first relevant item in the recommendation list. It’s computed as the reciprocal
    of the rank where the first relevant item appears.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个在推荐系统中使用的有效度量标准是 MRR。与考虑所有相关项目的 MAP 不同，MRR 主要关注推荐列表中第一个相关项目的位置。它被计算为第一个相关项目出现的排名的倒数。
- en: Consequently, MRR can reach its maximum value of 1 if the first item in the
    list is relevant. If the first relevant item is found farther down the list, MRR
    takes a value less than 1\. For instance, if the first relevant item is positioned
    at rank 2, the MRR would be 1/2.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果列表中的第一个项目是相关的，MRR 可以达到其最大值 1。如果第一个相关项目在列表中的位置更靠后，那么 MRR 将小于 1。例如，如果第一个相关项目位于排名
    2 的位置，那么 MRR 将为 1/2。
- en: 'Let’s look at this in the context of the recommendation algorithms A and B
    that we used earlier:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这在我们先前使用的推荐算法 A 和 B 的背景下的情况：
- en: For algorithm A, the first relevant item is at rank 2, so the MRR equals 1/2
    = 0.5.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于算法 A，第一个相关项目位于排名 2，因此 MRR 等于 1/2 = 0.5。
- en: For algorithm B, which perfectly ranked the items, the first relevant item is
    at rank 1, so the MRR equals 1/1 = 1.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于完美排名项目的算法 B，第一个相关项目位于排名 1，因此 MRR 等于 1/1 = 1。
- en: 'Extending this to multiple queries, the general formula for MRR is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个推广到多个查询，MRR 的一般公式如下：
- en: <math alttext="dollar-sign upper M upper R upper R equals StartFraction 1 Over
    StartAbsoluteValue upper Q EndAbsoluteValue EndFraction sigma-summation Underscript
    i equals 1 Overscript StartAbsoluteValue upper Q EndAbsoluteValue Endscripts StartFraction
    1 Over r a n k Subscript i Baseline EndFraction dollar-sign"><mrow><mi>M</mi>
    <mi>R</mi> <mi>R</mi> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mo>|</mo><mi>Q</mi><mo>|</mo></mrow></mfrac>
    <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mrow><mo>|</mo><mi>Q</mi><mo>|</mo></mrow></msubsup>
    <mfrac><mn>1</mn> <mrow><mi>r</mi><mi>a</mi><mi>n</mi><msub><mi>k</mi> <mi>i</mi></msub></mrow></mfrac></mrow></math>
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="dollar-sign upper M upper R upper R equals StartFraction 1 Over
    StartAbsoluteValue upper Q EndAbsoluteValue EndFraction sigma-summation Underscript
    i equals 1 Overscript StartAbsoluteValue upper Q EndAbsoluteValue Endscripts StartFraction
    1 Over r a n k Subscript i Baseline EndFraction dollar-sign"><mrow><mi>M</mi>
    <mi>R</mi> <mi>R</mi> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mo>|</mo><mi>Q</mi><mo>|</mo></mrow></mfrac>
    <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mrow><mo>|</mo><mi>Q</mi><mo>|</mo></mrow></msubsup>
    <mfrac><mn>1</mn> <mrow><mi>r</mi><mi>a</mi><mi>n</mi><msub><mi>k</mi> <mi>i</mi></msub></mrow></mfrac></mrow></math>
- en: Here, |*Q*| represents the total number of queries, and <math alttext="r a n
    k Subscript i"><mrow><mi>r</mi> <mi>a</mi> <mi>n</mi> <msub><mi>k</mi> <mi>i</mi></msub></mrow></math>
    is the position of the first relevant item in the list for the _i_th query. This
    metric provides valuable insight into how well a recommendation algorithm delivers
    a relevant recommendation right at the top of the list.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，|*Q*| 表示查询的总数，<math alttext="r a n k Subscript i"><mrow><mi>r</mi> <mi>a</mi>
    <mi>n</mi> <msub><mi>k</mi> <mi>i</mi></msub></mrow></math> 是列表中第 _i_ 个查询的第一个相关项目的位置。这个度量标准提供了有价值的见解，用于评估推荐算法在列表顶部提供相关推荐的效果。
- en: NDCG
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NDCG
- en: To further refine our understanding of ranking metrics, let’s step into the
    world of NDCG. Like mAP and MRR, NDCG also acknowledges the rank order of relevant
    items but introduces a twist. It discounts the relevance of items as we move down
    the list, signifying that items appearing earlier in the list are more valuable
    than those ranked lower.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步完善我们对排名指标的理解，让我们深入了解 NDCG。和 mAP 和 MRR 一样，NDCG 也承认相关项目的排名顺序，但引入了一个变化。它随着我们在列表中移动到更低的排名，递减项目的相关性，这意味着在列表中出现较早的项目比排名较低的项目更有价值。
- en: NDCG begins with the concept of cumulative gain (CG), which is simply the sum
    of the relevance scores of the top *k* items in the list. Discounted cumulative
    gain (DCG) goes a step further, discounting the relevance of each item based on
    its position. NDCG, then, is the DCG value normalized by the ideal DCG (IDCG),
    the DCG that we would obtain if all relevant items appeared at the very top of
    the list.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: NDCG 从累积增益（CG）的概念开始，它简单地是列表中前 *k* 个项目的相关性得分之和。折现累积增益（DCG）更进一步，根据项目的位置对每个项目的相关性进行折现。因此，NDCG
    是由理想折现累积增益（IDCG）标准化的 DCG 值，如果所有相关项目出现在列表的最顶部，我们将获得的 DCG 值。
- en: Assuming we have five items in our list and a specific user for whom the relevant
    items are found at positions 2 and 3, the IDCG@*k* would be (1/log(1 + 1) + 1/log(2
    + 1)) = 1.5 + 0.63 = 2.13.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的列表中有五个项目，特定用户的相关项目位于位置 2 和 3，那么 IDCG@*k* 将会是 (1/log(1 + 1) + 1/log(2 +
    1)) = 1.5 + 0.63 = 2.13。
- en: Let’s put this into the context of our example algorithms A and B.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这放到我们先前使用的算法 A 和 B 的背景中。
- en: For algorithm A
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于算法 A
- en: DCG@5 = 1/log(2 + 1) + 1/log(3 + 1) + 1/log(5 + 1) = 0.63 + 0.5 + 0.39 = 1.52
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DCG@5 = 1/log(2 + 1) + 1/log(3 + 1) + 1/log(5 + 1) = 0.63 + 0.5 + 0.39 = 1.52
- en: NDCG@5 = DCG@5 / IDCG@5 = 1.52 / 2.13 = 0.71
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NDCG@5 = DCG@5 / IDCG@5 = 1.52 / 2.13 = 0.71
- en: For algorithm B
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对于算法 B
- en: DCG@5 = 1/log(1 + 1) + 1/log(2 + 1) + 1/log(3 + 1) = 1 + 0.63 + 0.5 = 2.13
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DCG@5 = 1/log(1 + 1) + 1/log(2 + 1) + 1/log(3 + 1) = 1 + 0.63 + 0.5 = 2.13
- en: NDCG@5 = DCG@5 / IDCG@5 = 2.13 / 2.13 = 1
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NDCG@5 = DCG@5 / IDCG@5 = 2.13 / 2.13 = 1
- en: The general formula for NDCG can be represented as
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: NDCG 的一般公式可以表示为
- en: <math alttext="upper N upper D upper C upper G commercial-at k equals StartFraction
    upper D upper C upper G commercial-at k Over upper I upper D upper C upper G commercial-at
    k EndFraction"><mrow><mi>N</mi> <mi>D</mi> <mi>C</mi> <mi>G</mi> <mo>@</mo> <mi>k</mi>
    <mo>=</mo> <mfrac><mrow><mi>D</mi><mi>C</mi><mi>G</mi><mo>@</mo><mi>k</mi></mrow>
    <mrow><mi>I</mi><mi>D</mi><mi>C</mi><mi>G</mi><mo>@</mo><mi>k</mi></mrow></mfrac></mrow></math>
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <math alttext="upper N upper D upper C upper G commercial-at k equals StartFraction
    upper D upper C upper G commercial-at k Over upper I upper D upper C upper G commercial-at
    k EndFraction"><mrow><mi>N</mi> <mi>D</mi> <mi>C</mi> <mi>G</mi> <mo>@</mo> <mi>k</mi>
    <mo>=</mo> <mfrac><mrow><mi>D</mi><mi>C</mi><mi>G</mi><mo>@</mo><mi>k</mi></mrow>
    <mrow><mi>I</mi><mi>D</mi><mi>C</mi><mi>G</mi><mo>@</mo><mi>k</mi></mrow></mfrac></mrow></math>
- en: where
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: <math alttext="upper D upper C upper G commercial-at k equals sigma-summation
    Underscript i equals 1 Overscript k Endscripts StartFraction r e l Subscript i
    Baseline Over l o g 2 left-parenthesis i plus 1 right-parenthesis EndFraction"><mrow><mi>D</mi>
    <mi>C</mi> <mi>G</mi> <mo>@</mo> <mi>k</mi> <mo>=</mo> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>k</mi></msubsup> <mfrac><mrow><mi>r</mi><mi>e</mi><msub><mi>l</mi> <mi>i</mi></msub></mrow>
    <mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow></mrow></mfrac></mrow></math>
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <math alttext="upper D upper C upper G commercial-at k equals sigma-summation
    Underscript i equals 1 Overscript k Endscripts StartFraction r e l Subscript i
    Baseline Over l o g 2 left-parenthesis i plus 1 right-parenthesis EndFraction"><mrow><mi>D</mi>
    <mi>C</mi> <mi>G</mi> <mo>@</mo> <mi>k</mi> <mo>=</mo> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>k</mi></msubsup> <mfrac><mrow><mi>r</mi><mi>e</mi><msub><mi>l</mi> <mi>i</mi></msub></mrow>
    <mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow></mrow></mfrac></mrow></math>
- en: <math alttext="upper I upper D upper C upper G commercial-at k equals sigma-summation
    Underscript i equals 1 Overscript StartAbsoluteValue script upper R EndAbsoluteValue
    Endscripts StartFraction 1 Over l o g 2 left-parenthesis i plus 1 right-parenthesis
    EndFraction"><mrow><mi>I</mi> <mi>D</mi> <mi>C</mi> <mi>G</mi> <mo>@</mo> <mi>k</mi>
    <mo>=</mo> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mrow><mo>|</mo><mi>ℛ</mi><mo>|</mo></mrow></msubsup>
    <mfrac><mn>1</mn> <mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi> <mn>2</mn></msub>
    <mrow><mo>(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow></mrow></mfrac></mrow></math>
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <math alttext="upper I upper D upper C upper G commercial-at k equals sigma-summation
    Underscript i equals 1 Overscript StartAbsoluteValue script upper R EndAbsoluteValue
    Endscripts StartFraction 1 Over l o g 2 left-parenthesis i plus 1 right-parenthesis
    EndFraction"><mrow><mi>I</mi> <mi>D</mi> <mi>C</mi> <mi>G</mi> <mo>@</mo> <mi>k</mi>
    <mo>=</mo> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mrow><mo>|</mo><mi>ℛ</mi><mo>|</mo></mrow></msubsup>
    <mfrac><mn>1</mn> <mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi> <mn>2</mn></msub>
    <mrow><mo>(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow></mrow></mfrac></mrow></math>
- en: and <math alttext="script upper R"><mi>ℛ</mi></math> is the set of relevant
    documents.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 并且 <math alttext="script upper R"><mi>ℛ</mi></math> 是相关文档的集合。
- en: This metric gives us a normalized score for how well our recommendation algorithm
    ranks relevant items, discounting as we move further down the list.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这个度量标准为我们提供了一个归一化分数，用于衡量我们的推荐算法在排名相关项目方面的表现，随着列表的向下移动而递减。
- en: mAP Versus NDCG?
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: mAP 与 NDCG 的比较？
- en: Both mAP and NDCG are holistic metrics that offer a comprehensive perspective
    of ranking quality by incorporating all relevant items and their respective ranks.
    However, the interpretability and use cases of these metrics can vary based on
    the specifics of the recommendation context and the nature of relevance.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: mAP 和 NDCG 都是综合评估排名质量的全面指标，通过包含所有相关项目及其相应的排名提供了全面的视角。然而，这些指标的可解释性和使用案例可以根据推荐背景的具体情况和相关性的性质而变化。
- en: While MRR does not consider all relevant items, it does provide an interpretable
    insight into an algorithm’s performance, highlighting the average rank of the
    first relevant item. This can be particularly useful when the topmost recommendations
    hold significant value.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 MRR 不考虑所有相关项目，但它确实提供了对算法性能的可解释洞察，突出显示第一个相关项目的平均排名。当最高推荐具有显著价值时，这尤为有用。
- en: mAP, on the other hand, is a rich evaluation measure that effectively represents
    the area under the precision-recall curve. Its average aspect confers an intuitive
    interpretation related to the trade-off between precision and recall across different
    rank cutoffs.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，mAP 是一个丰富的评估指标，有效地表示了精确率-召回率曲线下的面积。它的平均特性提供了一个直观的解释，涉及在不同排名截断下精确率和召回率之间的权衡。
- en: NDCG introduces a robust consideration of the relevance of each item and is
    sensitive to the rank order, employing a logarithmic discount factor to quantify
    the diminishing significance of items as we move down the list. This allows it
    to handle scenarios in which items can have varying degrees of relevance, extending
    beyond binary relevance often used in mAP and MRR. However, this versatility of
    NDCG can also limit its interpretability because of the complexity of the logarithmic
    discount.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: NDCG 引入了对每个项目相关性的强健考虑，并对排名顺序敏感，使用对数折现因子来量化随着我们在列表中向下移动项目的递减重要性。这使得它能够处理项目具有不同程度相关性的情况，超越了
    mAP 和 MRR 中常用的二元相关性。然而，NDCG 的这种多功能性也可能由于对数折现的复杂性而限制其可解释性。
- en: Further, although NDCG is well equipped for use cases where items carry distinct
    relevance weights, procuring accurate ground-truth relevance scores can pose a
    significant challenge in practical applications. This imposes a limitation on
    the real-world usefulness of NDCG.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，尽管 NDCG 在项目具有不同重要性权重的使用案例中表现良好，但在实际应用中获取准确的地面真实相关性评分可能构成重大挑战。这对于 NDCG 的现实世界有效性施加了限制。
- en: Cumulatively, these metrics form the backbone of offline evaluation methodologies
    for recommendation algorithms. As we advance in our exploration, we’ll cover online
    evaluations, discuss strategies to assess and mitigate algorithmic bias, understand
    the importance of ensuring diversity in recommendations, and optimize recommendation
    systems to cater to various stakeholders in the ecosystem.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这些指标构成了推荐算法离线评估方法的基础。随着我们在探索中的进展，我们将涵盖在线评估，讨论评估和减轻算法偏差的策略，了解确保推荐多样性的重要性，并优化推荐系统以满足生态系统中各方的需求。
- en: Correlation Coefficients
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关系数
- en: While correlation coefficients like Pearson’s or Spearman’s can be employed
    to evaluate the similarity between two rankings (for instance, between the predicted
    and the ground-truth rankings), they do not provide the exact same information
    as mAP, MRR, or NDCG.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然像 Pearson 或 Spearman 这样的相关系数可以用来评估两个排名之间的相似性（例如，预测排名与地面真实排名之间），但它们并不像 mAP、MRR
    或 NDCG 那样提供完全相同的信息。
- en: Correlation coefficients are typically used to measure the degree of linear
    association between two continuous variables, and in the context of ranking, they
    can indicate the overall similarity between two ordered lists. However, they do
    not directly account for aspects such as the relevance of individual items, the
    position of relevant items, or varying degrees of relevance among items, which
    are integral to mAP, MRR, and NDCG.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 相关系数通常用于衡量两个连续变量之间的线性关联程度，在排名的背景下，它们可以指示两个有序列表之间的整体相似性。然而，它们并未直接考虑诸如个别项目的相关性、相关项目的位置或项目间不同程度的相关性等方面，这些对于
    mAP、MRR 和 NDCG 非常重要。
- en: For example, say a user has interacted with five items in the past. A recommender
    system might predict that the user will interact with these items again but rank
    them in the opposite order of importance. Even though the system has correctly
    identified the items of interest, the reversed ranking would lead to poor performance
    as measured by mAP, MRR, or NDCG, but a high negative correlation coefficient
    would be obtained because of the linear relationship.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设用户过去与五个项目互动过。推荐系统可能预测用户会再次与这些项目互动，但会按重要性相反的顺序排名。即使系统正确识别了感兴趣的项目，但由于排名颠倒，根据mAP、MRR或NDCG测量会导致性能较差，但由于线性关系，会获得较高的负相关系数。
- en: As a result, while correlation coefficients can provide a high-level understanding
    of ranking performance, they are not sufficient substitutes for the more detailed
    information provided by metrics like mAP, MRR, and NDCG.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，虽然相关系数可以提供对排名性能的高层次理解，但它们不足以取代像mAP、MRR和NDCG这样提供更详细信息的度量。
- en: To utilize correlation coefficients in the context of ranking, it would be essential
    to pair them with other metrics that account for the specific nuances of the recommendation
    problem, such as the relevance of individual items and their positions in the
    ranking.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 要在排名背景下利用相关系数，关键是将其与其他考虑推荐问题特定细微差别的度量配对，例如个别项目的相关性及其在排名中的位置。
- en: RMSE from Affinity
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RMSE来自亲和力
- en: Root mean square error (RMSE) and ranking metrics like mAP, MRR, and NDCG offer
    fundamentally different perspectives when evaluating a recommendation system that
    outputs affinity scores.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 均方根误差（RMSE）和mAP、MRR和NDCG等排名指标，在评估输出亲和力分数的推荐系统时，提供了根本不同的视角。
- en: RMSE is a popular metric for quantifying prediction error. It computes the square
    root of the average of squared differences between the predicted affinity scores
    and the true values. Lower RMSE signifies better predictive accuracy. However,
    RMSE treats the problem as a standard regression task and disregards the inherent
    ranking structure in recommendation systems.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: RMSE是量化预测误差的常用指标。它计算预测的亲和力分数与真实值之间平方差的平均值的平方根。较低的RMSE表示更好的预测精度。但是，RMSE将问题视为标准回归任务，并忽视了推荐系统中的固有排名结构。
- en: Conversely, mAP, MRR, and NDCG are explicitly designed to evaluate the quality
    of rankings, which is essential in a recommendation system. In essence, while
    RMSE measures the closeness of predicted affinity scores to actual values, mAP,
    MRR, and NDCG assess the ranking quality by considering the positions of relevant
    items. Therefore, if your main concern is ranking items rather than predicting
    precise affinity scores, these ranking metrics are generally more appropriate.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，mAP、MRR和NDCG明确设计用于评估排名的质量，在推荐系统中至关重要。本质上，虽然RMSE衡量预测亲和力分数与实际值的接近程度，但mAP、MRR和NDCG通过考虑相关项的位置来评估排名质量。因此，如果您关注的是排名项目而不是预测精确的亲和力分数，则通常应选择这些排名指标更为合适。
- en: 'Integral Forms: AUC and cAUC'
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 积分形式：AUC和cAUC
- en: When it comes to recommendation systems, we are producing a ranked list of items
    for each user. As you’ve seen, these rankings are based on affinity, the probability
    or level of preference that the user has for each item. Given this framework,
    several metrics have been developed to evaluate the quality of these ranked lists.
    One such metric is the AUC-ROC, which is complemented by mAP, MRR, and NDCG. Let’s
    take a closer look at understanding these.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在推荐系统中，我们为每个用户生成一个项目的排名列表。正如您所见，这些排名基于亲和力，即用户对每个项目的偏好或优先级的概率。在这个框架下，已经开发了几个度量来评估这些排名列表的质量。其中一个度量是AUC-ROC，它与mAP、MRR和NDCG相辅相成。让我们更仔细地了解这些度量。
- en: Recommendation Probabilities to AUC-ROC
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐概率到AUC-ROC
- en: In a binary classification setup, the area *under the receiver operating characteristic
    curve* (AUC-ROC) measures the ability of the recommendation model to distinguish
    between positive (relevant) and negative (irrelevant) instances. It is calculated
    by plotting the true positive rate (TPR) against the false positive rate (FPR)
    at various threshold settings and then computing the area under this curve.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在二元分类设置中，接收器工作特征曲线下的面积（AUC-ROC）衡量推荐模型区分正（相关）和负（不相关）实例的能力。它通过在各种阈值设置下绘制真正例率（TPR）与假正例率（FPR）曲线，然后计算此曲线下的面积来计算。
- en: In the context of recommendations, you can think of these “thresholds” as varying
    the number of top items recommended to a user. The AUC-ROC metric becomes an evaluation
    of how well your model ranks relevant items over irrelevant ones, irrespective
    of the actual rank position. In other words, AUC-ROC effectively quantifies the
    likelihood that a randomly chosen relevant item is ranked higher than a randomly
    chosen irrelevant one by the model. This, however, doesn’t account for the actual
    position or order of items in the list, only the relative ranking of positive
    versus negative instances. The affinity of a calibrated item may be interpreted
    as a confidence measure by the model that an item is relevant, and when considering
    historical data, even uncalibrated affinity scores may make a great suggestion
    for the number of recommendations necessary to find something useful.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在推荐的背景下，你可以将这些“阈值”视为将向用户推荐的前几个项目的数量。AUC-ROC指标变成了评估模型在排列相关项目和不相关项目时的表现，而与实际排名位置无关。换句话说，AUC-ROC有效地量化了模型随机选择的相关项目被排在比随机选择的不相关项目更高的概率。然而，这并不考虑项目在列表中的实际位置或顺序，只考虑了正例与负例的相对排名。通过校准项目的亲和力可以被解释为模型对项目相关性的置信度，并且在考虑历史数据时，即使是未校准的亲和力分数也可能成为发现有用内容所需的推荐数量的很好建议。
- en: One serious implementation of these affinity scores might be to show users only
    items over a particular score and otherwise tell them to come back later or use
    exploration methods to improve the data. For example, if you sold hygiene products
    and were considering asking customers to add some Aesop soap during checkout,
    you may wish to evaluate the Aesop ROC and make this suggestion only when the
    observed affinity passed the learned threshold. You’ll also see these concepts
    used later in [“Inventory Health”](ch14.html#InvHealth).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这些亲和力分数的一个严肃实现可能是只向用户展示超过特定分数的项目，否则告诉他们稍后再来或使用探索方法来改进数据。例如，如果你销售卫生产品，并且正在考虑在结账时询问客户添加一些Aesop肥皂，你可能希望评估Aesop
    ROC，并且仅当观察到的亲和力超过学习阈值时才进行此建议。您还将在之后看到这些概念在[“库存健康”](ch14.html#InvHealth)中的应用。
- en: Comparison to Other Metrics
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与其他指标的比较
- en: 'Let’s put these in context with the other metrics:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这些与其他指标放在一起来看：
- en: mAP
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: mAP
- en: This metric expands on the idea of precision at a specific cutoff in the ranked
    list to provide an overall measure of model performance. It does this by averaging
    the precision values computed at the ranks where each relevant item is found.
    Unlike AUC-ROC, mAP puts emphasis on the higher-ranked items and is more sensitive
    to changes at the top of the ranking.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指标扩展了在排名列表中特定截止点处的精度的思想，以提供模型性能的总体度量。它通过计算每个相关项目被发现的排名处的精度值的平均值来实现这一点。与AUC-ROC不同，mAP更加强调排名较高的项目，并且对排名顶部的变化更为敏感。
- en: MRR
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: MRR
- en: Unlike AUC-ROC and mAP, which consider all relevant items in the list, MRR focuses
    only on the rank of the first relevant item in the list. It is a measure of how
    quickly the model can find a relevant item. If the model consistently places a
    relevant item at the top of the list, it will have a higher MRR.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 与AUC-ROC和mAP不同，MRR只关注列表中第一个相关项目的排名。它衡量模型能够多快地找到相关项目。如果模型始终将相关项目置于列表顶部，那么它的MRR将更高。
- en: NDCG
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: NDCG
- en: This metric evaluates the quality of the ranking by not only considering the
    order of recommendations but also taking into account the graded relevance of
    items (which the previous metrics don’t). NDCG discounts items further down the
    list, rewarding relevant items that appear near the top of the list.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 该指标评估了排名的质量，不仅考虑了推荐的顺序，还考虑了项目的分级相关性（而前面的指标没有考虑）。NDCG降低了列表下面的项目的权重，奖励出现在列表顶部附近的相关项目。
- en: AUC-ROC provides a valuable aggregate measure of a model’s ability to differentiate
    between relevant and irrelevant items; mAP, MRR, and NDCG offer a more nuanced
    evaluation of the model’s ranking quality, considering factors like position bias
    and varying degrees of relevance.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: AUC-ROC提供了一个有价值的综合度量，用于衡量模型区分相关和不相关项目的能力；mAP、MRR和NDCG提供了对模型排名质量更细致的评估，考虑了位置偏差和不同相关程度等因素。
- en: Note that we sometimes compute the AUC per customer and then average. That’s
    customer AUC (cAUC), which can often provide a good expectation for a user’s experience.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们有时会计算每个客户的AUC然后取平均值。这就是客户AUC（cAUC），它经常可以为用户的体验提供一个良好的期望。
- en: BPR
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BPR
- en: '*Bayesian personalized ranking* (BPR) presents a Bayesian approach to the task
    of item ranking in recommendation systems, effectively providing a probability
    framework to model the personalized ranking process. Instead of transforming the
    item recommendation problem into a binary classification problem (relevant or
    not), BPR focuses on pairwise preferences: given two items, which does the user
    prefer? This approach aligns better with the nature of implicit feedback that
    is common in recommendation systems.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '*贝叶斯个性化排名*（Bayesian personalized ranking，BPR）提出了在推荐系统中进行项目排名的贝叶斯方法，有效地提供了一个概率框架来模拟个性化排名过程。与将项目推荐问题转化为二元分类问题（相关或不相关）不同，BPR专注于成对偏好：给定两个项目，用户更喜欢哪个？这种方法更符合推荐系统中常见的隐式反馈的性质。'
- en: 'The BPR model uses a pairwise loss function that takes into account the relative
    order of a positive item and a negative item for a specific user. It seeks to
    maximize the posterior probability of the observed rankings being correct. The
    model is typically optimized using stochastic gradient descent or a variant thereof.
    It’s important to note that BPR (unlike other metrics we’ve discussed, including
    AUC-ROC, mAP, MRR, and NDCG) is a model training objective rather than an evaluation
    metric. Therefore, while the aforementioned metrics evaluate a model’s performance
    post-training, BPR provides a mechanism to guide the model learning process in
    a way that directly optimizes for the ranking task. A much deeper discussion of
    these topics is in [“BPR: Bayesian Personalized Ranking from Implicit Feedback”](https://oreil.ly/NwCYa)
    by Steffen Rendle et al.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 'BPR模型使用成对损失函数，考虑了特定用户对正向项目和负向项目的相对顺序。它旨在最大化观察到的排名正确的后验概率。该模型通常使用随机梯度下降或其变体进行优化。需要注意的是，BPR（与我们讨论过的其他指标，包括AUC-ROC、mAP、MRR和NDCG不同）是一个模型训练目标，而不是一个评估指标。因此，虽然前述的指标评估模型训练后的性能，但BPR提供了一种机制，以直接优化排名任务的方式来引导模型学习过程。关于这些主题的更深入讨论详见[“BPR:
    Bayesian Personalized Ranking from Implicit Feedback”](https://oreil.ly/NwCYa)
    by Steffen Rendle et al.'
- en: Summary
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: 'Now that you know how to evaluate the performance of the recommendation systems
    that you train, you may be wondering how to actually train them. You may have
    noticed that many of the metrics we introduced would not make very good loss functions;
    they involve a lot of simultaneous observations about sets and lists of items.
    This would unfortunately make the signal that the recommender would be learning
    from highly combinatorial. Additionally, the metrics we’ve presented really have
    two aspects to consider: the binary metric associated to recall, and the rank
    weighting.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经知道如何评估你训练的推荐系统的性能，或许你会想知道如何实际训练它们。你可能已经注意到，我们介绍的许多指标并不适合作为损失函数；它们涉及关于项目集和项目列表的大量同时观察。不幸的是，这会使推荐者从中学习的信号高度组合。此外，我们提出的指标确实有两个方面需要考虑：与召回相关联的二元指标和排名加权。
- en: In the next chapter, you’re going to learn some loss functions that make excellent
    training objectives. The importance of these, we’re sure, won’t be lost on you.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习一些优秀的训练目标损失函数。我们相信这些的重要性不会被忽视。
