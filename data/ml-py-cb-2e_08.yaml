- en: Chapter 8\. Handling Images
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章. 处理图像
- en: 8.0 Introduction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.0 介绍
- en: Image classification is one of the most exciting areas of machine learning.
    The ability of computers to recognize patterns and objects from images is an incredibly
    powerful tool in our toolkit. However, before we can apply machine learning to
    images, we often first need to transform the raw images to features usable by
    our learning algorithms. As with textual data, there are also many pretrained
    classifiers available for images that we can use to extract features or objects
    of interest to use as inputs to our own models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类是机器学习中最激动人心的领域之一。计算机从图像中识别模式和物体的能力是我们工具箱中非常强大的工具。然而，在将机器学习应用于图像之前，我们通常需要将原始图像转换为我们的学习算法可用的特征。与文本数据一样，也有许多预训练的分类器可用于图像，我们可以使用这些分类器来提取我们自己模型的输入中感兴趣的特征或对象。
- en: To work with images, we will primarily use the Open Source Computer Vision Library
    (OpenCV). While there are a number of good libraries out there, OpenCV is the
    most popular and well-documented library for handling images. It can occasionally
    be challenging to install, but if you run into issues, there are many guides online.
    This book in particular was written with `opencv-python-headless==4.7.0.68`. You
    can also run these chapters with [the ML in Python Cookbook Runner](https://oreil.ly/MLwPython)
    to ensure all commands are reproducible.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理图像，我们将主要使用开源计算机视觉库（OpenCV）。虽然市面上有许多优秀的库，但 OpenCV 是处理图像最流行和文档最完善的库。安装时可能会遇到一些挑战，但如果遇到问题，网上有很多指南。本书特别使用的是
    `opencv-python-headless==4.7.0.68`。您也可以使用 [Python Cookbook Runner 中的 ML](https://oreil.ly/MLwPython)
    确保所有命令可复现。
- en: Throughout this chapter, we will use as examples a set of images, which is available
    to download from [GitHub](https://oreil.ly/gV5Zc).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用一组图像作为示例，可以从 [GitHub](https://oreil.ly/gV5Zc) 下载。
- en: 8.1 Loading Images
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.1 加载图像
- en: Problem
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to load an image for preprocessing.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您想要加载一幅图像进行预处理。
- en: Solution
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use OpenCV’s `imread`:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 OpenCV 的 `imread`：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If we want to view the image, we can use the Python plotting library Matplotlib:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想查看图像，我们可以使用 Python 绘图库 Matplotlib：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![mpc2 08in01](assets/mpc2_08in01.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in01](assets/mpc2_08in01.png)'
- en: Discussion
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: 'Fundamentally, images are data, and when we use `imread`, we convert that data
    into a data type we are very familiar with—​a NumPy array:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从根本上讲，图像是数据，当我们使用`imread`时，我们将该数据转换为我们非常熟悉的数据类型——一个 NumPy 数组：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We have transformed the image into a matrix whose elements correspond to individual
    pixels. We can even take a look at the actual values of the matrix:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将图像转换为一个矩阵，其元素对应于各个像素。我们甚至可以查看矩阵的实际值：
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The resolution of our image is 3600 × 2270, the exact dimensions of our matrix:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们图像的分辨率是 3600 × 2270，正好是我们矩阵的确切尺寸：
- en: '[PRE6]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'What does each element in the matrix actually represent? In grayscale images,
    the value of an individual element is the pixel intensity. Intensity values range
    from black (0) to white (255). For example, the intensity of the top leftmost
    pixel in our image has a value of 140:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵中的每个元素实际上表示什么？在灰度图像中，单个元素的值是像素强度。强度值从黑色（0）到白色（255）变化。例如，我们图像左上角像素的强度值为 140：
- en: '[PRE8]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In a matrix representing a color image, each element actually contains three
    values corresponding to blue, green, and red values, respectively (BGR):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在表示彩色图像的矩阵中，每个元素实际上包含三个值，分别对应蓝色、绿色和红色的值（BGR）：
- en: '[PRE10]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'One small caveat: by default OpenCV uses BGR, but many image applications—​including
    Matplotlib—​use red, green, blue (RGB), meaning the red and the blue values are
    swapped. To properly display OpenCV color images in Matplotlib, we first need
    to convert the color to RGB (apologies to hardcopy readers for whom there are
    no color images):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个小细节：默认情况下，OpenCV 使用 BGR，但许多图像应用程序——包括 Matplotlib——使用红色、绿色、蓝色（RGB），这意味着红色和蓝色值被交换了。为了在
    Matplotlib 中正确显示 OpenCV 彩色图像，我们首先需要将颜色转换为 RGB（对于硬拷贝读者，没有彩色图像我们深感抱歉）。
- en: '[PRE12]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![mpc2 08in02](assets/mpc2_08in02.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in02](assets/mpc2_08in02.png)'
- en: See Also
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Difference Between RGB and BGR](https://oreil.ly/N1Ub6)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RGB 和 BGR 的区别](https://oreil.ly/N1Ub6)'
- en: '[RGB color model, Wikipedia](https://oreil.ly/OEesQ)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RGB 颜色模型，维基百科](https://oreil.ly/OEesQ)'
- en: 8.2 Saving Images
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.2 保存图像
- en: Problem
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to save an image for preprocessing.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您想要保存一幅图像进行预处理。
- en: Solution
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use OpenCV’s `imwrite`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 OpenCV 的 `imwrite`：
- en: '[PRE13]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Discussion
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: 'OpenCV’s `imwrite` saves images to the filepath specified. The format of the
    image is defined by the filename’s extension (*.jpg*, *.png*, etc.). One behavior
    to be careful about: `imwrite` will overwrite existing files without outputting
    an error or asking for confirmation.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV的`imwrite`将图像保存到指定的文件路径。图像的格式由文件名的扩展名（*.jpg*，*.png*等）定义。要注意的一个行为是：`imwrite`会覆盖现有文件而不输出错误或要求确认。
- en: 8.3 Resizing Images
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.3 调整图像大小
- en: Problem
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to resize an image for further preprocessing.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 您想要调整图像的大小以进行进一步的预处理。
- en: Solution
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use `resize` to change the size of an image:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`resize`来改变图像的大小：
- en: '[PRE15]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![mpc2 08in03](assets/mpc2_08in03.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in03](assets/mpc2_08in03.png)'
- en: Discussion
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Resizing images is a common task in image preprocessing for two reasons. First,
    images come in all shapes and sizes, and to be usable as features, images must
    have the same dimensions. Standardizing (resizing) images does come at the cost
    of losing some information present in the larger image, as can be seen in the
    picture of the airplane. Images are matrices of information, and when we reduce
    the size of the image, we are reducing the size of that matrix and the information
    it contains. Second, machine learning can require thousands or hundreds of thousands
    of images. When those images are very large they can take up a lot of memory,
    and by resizing them we can dramatically reduce memory usage. Some common image
    sizes for machine learning are 32 × 32, 64 × 64, 96 × 96, and 256 × 256\. In essence,
    the method we choose for image resizing will often be a tradeoff between the statistical
    performance of our model and computational cost to train it. The [Pillow library
    offers many options for resizing images](https://oreil.ly/NiJn_) for this reason.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 调整图像大小是图像预处理中的常见任务，有两个原因。首先，图像以各种形状和大小出现，为了作为特征可用，图像必须具有相同的尺寸。标准化（调整大小）图像的过程会丢失较大图像中存在的一些信息，就像飞机图片中所看到的那样。图像是信息的矩阵，当我们减小图像的尺寸时，我们减少了该矩阵及其所包含信息的大小。其次，机器学习可能需要成千上万张图像。当这些图像非常大时，它们会占用大量内存，通过调整它们的大小，我们可以显著减少内存使用量。机器学习中常见的一些图像尺寸包括32
    × 32、64 × 64、96 × 96和256 × 256。总的来说，我们选择的图像调整方法往往是模型统计性能与训练计算成本之间的权衡。出于这个原因，[Pillow库提供了许多调整图像大小的选项](https://oreil.ly/NiJn_)。
- en: 8.4 Cropping Images
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.4 裁剪图像
- en: Problem
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to remove the outer portion of the image to change its dimensions.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 您想要删除图像的外部部分以更改其尺寸。
- en: Solution
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'The image is encoded as a two-dimensional NumPy array, so we can crop the image
    easily by slicing the array:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图像被编码为二维NumPy数组，因此我们可以通过切片数组轻松地裁剪图像：
- en: '[PRE16]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![mpc2 08in04](assets/mpc2_08in04.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in04](assets/mpc2_08in04.png)'
- en: Discussion
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Since OpenCV represents images as a matrix of elements, by selecting the rows
    and columns we want to keep we can easily crop the image. Cropping can be particularly
    useful if we know that we want to keep only a certain part of every image. For
    example, if our images come from a stationary security camera we can crop all
    the images so they contain only the area of interest.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于OpenCV将图像表示为元素的矩阵，通过选择我们想保留的行和列，我们可以轻松地裁剪图像。如果我们知道我们只想保留每个图像的特定部分，裁剪可以特别有用。例如，如果我们的图像来自固定的安全摄像机，我们可以裁剪所有图像，使它们仅包含感兴趣的区域。
- en: See Also
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Slicing NumPy Arrays](https://oreil.ly/8JN5p)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[切片NumPy数组](https://oreil.ly/8JN5p)'
- en: 8.5 Blurring Images
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.5 模糊图像
- en: Problem
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to smooth out an image.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 您想要使图像变得平滑。
- en: Solution
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'To blur an image, each pixel is transformed to be the average value of its
    neighbors. This neighbor and the operation performed are mathematically represented
    as a kernel (don’t worry if you don’t know what a kernel is). The size of this
    kernel determines the amount of blurring, with larger kernels producing smoother
    images. Here we blur an image by averaging the values of a 5 × 5 kernel around
    each pixel:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模糊图像，每个像素被转换为其邻居的平均值。数学上将这个邻居和操作表示为一个核（如果你不知道核是什么也不用担心）。这个核的大小决定了模糊的程度，较大的核产生更平滑的图像。在这里，我们通过对每个像素周围的5
    × 5核的值取平均来模糊图像：
- en: '[PRE17]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![mpc2 08in05](assets/mpc2_08in05.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in05](assets/mpc2_08in05.png)'
- en: 'To highlight the effect of kernel size, here is the same blurring with a 100
    × 100 kernel:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了突出显示核大小的效果，这里是使用100 × 100核进行的相同模糊处理的图像：
- en: '[PRE18]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![mpc2 08in06](assets/mpc2_08in06.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in06](assets/mpc2_08in06.png)'
- en: Discussion
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: 'Kernels are widely used in image processing to do everything from sharpening
    to edge detection and will come up repeatedly in this chapter. The blurring kernel
    we used looks like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积核在图像处理中被广泛使用，从锐化到边缘检测等方面，本章节将反复讨论。我们使用的模糊核如下所示：
- en: '[PRE19]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The center element in the kernel is the pixel being examined, while the remaining
    elements are its neighbors. Since all elements have the same value (normalized
    to add up to 1), each has an equal say in the resulting value of the pixel of
    interest. We can manually apply a kernel to an image using `filter2D` to produce
    a similar blurring effect:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 核心元素在内核中是被检查的像素，而其余元素是其邻居。由于所有元素具有相同的值（归一化为总和为1），因此每个元素对感兴趣像素的结果值都有相同的影响力。我们可以使用`filter2D`手动将内核应用于图像，以产生类似的模糊效果：
- en: '[PRE21]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![mpc2 08in07](assets/mpc2_08in07.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in07](assets/mpc2_08in07.png)'
- en: See Also
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Image Kernels Explained Visually](https://oreil.ly/9yvdg)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像卷积核的直观解释](https://oreil.ly/9yvdg)'
- en: '[Kernel (image processing), Wikipedia](https://oreil.ly/ByREC)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积核（图像处理），维基百科](https://oreil.ly/ByREC)'
- en: 8.6 Sharpening Images
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.6 锐化图像
- en: Problem
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to sharpen an image.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 您想要锐化图像。
- en: Solution
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Create a kernel that highlights the target pixel. Then apply it to the image
    using `filter2D`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个突出显示目标像素的内核。然后使用`filter2D`将其应用于图像：
- en: '[PRE22]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![mpc2 08in08](assets/mpc2_08in08.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in08](assets/mpc2_08in08.png)'
- en: Discussion
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Sharpening works similarly to blurring, except instead of using a kernel to
    average the neighboring values, we constructed a kernel to highlight the pixel
    itself. The resulting effect makes contrasts in edges stand out more.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 锐化的工作原理与模糊类似，但不同于使用内核来平均周围值，我们构建了一个内核来突出像素本身。其结果效果使得边缘处的对比更加明显。
- en: 8.7 Enhancing Contrast
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.7 增强对比度
- en: Problem
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: We want to increase the contrast between pixels in an image.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望增加图像中像素之间的对比度。
- en: Solution
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: '*Histogram equalization* is a tool for image processing that can make objects
    and shapes stand out. When we have a grayscale image, we can apply OpenCV’s `equalizeHist`
    directly on the image:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*直方图均衡化* 是一种图像处理工具，可以使物体和形状更加突出。当我们有一个灰度图像时，可以直接在图像上应用OpenCV的`equalizeHist`：'
- en: '[PRE23]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![mpc2 08in09](assets/mpc2_08in09.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in09](assets/mpc2_08in09.png)'
- en: 'However, when we have a color image, we first need to convert the image to
    the YUV color format. The Y is the luma, or brightness, and U and V denote the
    color. After the conversion, we can apply `equalizeHist` to the image and then
    convert it back to BGR or RGB (apologies to hardcopy readers for whom there are
    no color images):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我们有一幅彩色图像时，我们首先需要将图像转换为YUV颜色格式。Y代表亮度，U和V表示颜色。转换后，我们可以将`equalizeHist`应用于图像，然后再转换回BGR或RGB（对于只有黑白图像的读者表示抱歉）：
- en: '[PRE24]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![mpc2 08in10](assets/mpc2_08in10.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in10](assets/mpc2_08in10.png)'
- en: Discussion
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: While a detailed explanation of how histogram equalization works is beyond the
    scope of this book, the short explanation is that it transforms the image so that
    it uses a wider range of pixel intensities.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然详细解释直方图均衡化的工作原理超出了本书的范围，简短的解释是它转换图像，使其使用更广泛的像素强度范围。
- en: While the resulting image often does not look “realistic,” we need to remember
    that the image is just a visual representation of the underlying data. If histogram
    equalization is able to make objects of interest more distinguishable from other
    objects or backgrounds (which is not always the case), then it can be a valuable
    addition to our image preprocessing pipeline.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然生成的图像通常看起来不够“真实”，但我们需要记住，图像只是底层数据的视觉表示。如果直方图均衡化能够使感兴趣的对象与其他对象或背景更易于区分（这并非总是如此），那么它可以成为我们图像预处理流程中的有价值的补充。
- en: 8.8 Isolating Colors
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.8 分离颜色
- en: Problem
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to isolate a color in an image.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 您想要在图像中隔离一种颜色。
- en: Solution
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Define a range of colors and then apply a mask to the image (apologies to hardcopy
    readers for whom there are no color images):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个颜色范围，然后将掩码应用于图像（对于只有黑白图像的读者表示抱歉）：
- en: '[PRE25]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![mpc2 08in11](assets/mpc2_08in11.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in11](assets/mpc2_08in11.png)'
- en: Discussion
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: 'Isolating colors in OpenCV is straightforward. First we convert an image into
    HSV (hue, saturation, and value). Second, we define a range of values we want
    to isolate, which is probably the most difficult and time-consuming part. Third,
    we create a mask for the image. Image masking is a common technique meant to extract
    regions of interest. In this case, our mask keeps only the white areas:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在 OpenCV 中隔离颜色是直接的。首先我们将图像转换为 HSV（色调、饱和度和值）。其次，我们定义我们想要隔离的值范围，这可能是最困难和耗时的部分。第三，我们为图像创建一个掩码。图像掩码是一种常见的技术，旨在提取感兴趣的区域。在这种情况下，我们的掩码仅保留白色区域：
- en: '[PRE26]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![mpc2 08in12](assets/mpc2_08in12.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in12](assets/mpc2_08in12.png)'
- en: Finally, we apply the mask to the image using `bitwise_and` and convert to our
    desired output format.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用 `bitwise_and` 将掩码应用于图像，并将其转换为我们期望的输出格式。
- en: 8.9 Binarizing Images
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.9 图像二值化
- en: Problem
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: Given an image, you want to output a simplified version.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一张图像，您想要输出一个简化版本。
- en: Solution
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: '*Thresholding* is the process of setting pixels with intensity greater than
    some value to be white and less than the value to be black. A more advanced technique
    is *adaptive thresholding*, where the threshold value for a pixel is determined
    by the pixel intensities of its neighbors. This can be helpful when lighting conditions
    change over different regions in an image:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*阈值化* 是将像素强度大于某个值的像素设置为白色，小于该值的像素设置为黑色的过程。更高级的技术是 *自适应阈值化*，其中像素的阈值由其邻域的像素强度决定。当图像中不同区域的光照条件发生变化时，这可能会有所帮助：'
- en: '[PRE27]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![mpc2 08in13](assets/mpc2_08in13.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in13](assets/mpc2_08in13.png)'
- en: Discussion
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: 'The process of binarizing an image involves converting a greyscale image to
    its black and white form. Our solution has four important arguments in `adaptiveThreshold`.
    `max_output_value` simply determines the maximum intensity of the output pixel
    intensities. `cv2.ADAPTIVE_THRESH_GAUSSIAN_C` sets a pixel’s threshold to be a
    weighted sum of the neighboring pixel intensities. The weights are determined
    by a Gaussian window. Alternatively, we could set the threshold to simply the
    mean of the neighboring pixels with `cv2.ADAPTIVE_THRESH_MEAN_C`:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对图像进行二值化的过程涉及将灰度图像转换为其黑白形式。我们的解决方案在 `adaptiveThreshold` 中有四个重要参数。`max_output_value`
    简单地确定输出像素强度的最大值。`cv2.ADAPTIVE_THRESH_GAUSSIAN_C` 将像素的阈值设置为其相邻像素强度的加权和。权重由高斯窗口确定。或者，我们可以将阈值简单地设置为相邻像素的平均值，使用
    `cv2.ADAPTIVE_THRESH_MEAN_C`：
- en: '[PRE28]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![mpc2 08in14](assets/mpc2_08in14.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in14](assets/mpc2_08in14.png)'
- en: The last two parameters are the block size (the size of the neighborhood used
    to determine a pixel’s threshold) and a constant subtracted from the calculated
    threshold (used to manually fine-tune the threshold).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个参数是块大小（用于确定像素阈值的邻域大小）和从计算阈值中减去的常数（用于手动微调阈值）。
- en: A major benefit of thresholding is *denoising* an image—​keeping only the most
    important elements. For example, thresholding is often applied to photos of printed
    text to isolate the letters from the page.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值化的一个主要好处是 *去噪* 图像 —— 仅保留最重要的元素。例如，经常将阈值应用于印刷文本的照片，以隔离页面上的字母。
- en: 8.10 Removing Backgrounds
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.10 移除背景
- en: Problem
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to isolate the foreground of an image.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 您想要隔离图像的前景。
- en: Solution
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Mark a rectangle around the desired foreground, then run the GrabCut algorithm:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在所需前景周围标记一个矩形，然后运行 GrabCut 算法：
- en: '[PRE29]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![mpc2 08in15](assets/mpc2_08in15.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in15](assets/mpc2_08in15.png)'
- en: Discussion
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: The first thing we notice is that even though GrabCut did a pretty good job,
    there are still areas of background left in the image. We could go back and manually
    mark those areas as background, but in the real world we have thousands of images
    and manually fixing them individually is not feasible. Therefore, we would do
    well by simply accepting that the image data will still contain some background
    noise.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先注意到，即使 GrabCut 做得相当不错，图像中仍然有一些背景区域。我们可以回去手动标记这些区域为背景，但在现实世界中，我们有成千上万张图片，逐个手动修复它们是不可行的。因此，我们最好接受图像数据仍然会包含一些背景噪声。
- en: 'In our solution, we start by marking a rectangle around the area that contains
    the foreground. GrabCut assumes everything outside this rectangle to be background
    and uses that information to figure out what is likely background inside the square.
    (To learn how the algorithm does this, see this explanation from [Itay Blumenthal](https://oreil.ly/DTGwb).)
    Then a mask is created that denotes the different definitely/likely background/foreground
    regions:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的解决方案中，我们首先在包含前景的区域周围标记一个矩形。GrabCut假定这个矩形外的所有内容都是背景，并利用这些信息来推断出正方形内部可能是背景的区域。（要了解算法如何做到这一点，请参阅[Itay
    Blumenthal](https://oreil.ly/DTGwb)的解释。）然后创建一个标记不同明确/可能背景/前景区域的掩码：
- en: '[PRE30]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![mpc2 08in16](assets/mpc2_08in16.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in16](assets/mpc2_08in16.png)'
- en: The black region is the area outside our rectangle that is assumed to be definitely
    background. The gray area is what GrabCut considered likely background, while
    the white area is likely foreground.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 黑色区域是矩形外部被假定为明确背景的区域。灰色区域是GrabCut认为可能是背景的区域，而白色区域则是可能是前景的区域。
- en: 'This mask is then used to create a second mask that merges the black and gray
    regions:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用该掩码创建第二个掩码，将黑色和灰色区域合并：
- en: '[PRE31]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![mpc2 08in17](assets/mpc2_08in17.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in17](assets/mpc2_08in17.png)'
- en: The second mask is then applied to the image so that only the foreground remains.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将第二个掩码应用于图像，以便仅保留前景。
- en: 8.11 Detecting Edges
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.11 检测边缘
- en: Problem
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to find the edges in an image.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望在图像中找到边缘。
- en: Solution
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use an edge detection technique like the Canny edge detector:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像Canny边缘检测器这样的边缘检测技术：
- en: '[PRE32]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![mpc2 08in18](assets/mpc2_08in18.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in18](assets/mpc2_08in18.png)'
- en: Discussion
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Edge detection is a major topic of interest in computer vision. Edges are important
    because they are areas of high information. For example, in our image one patch
    of sky looks very much like another and is unlikely to contain unique or interesting
    information. However, patches where the background sky meets the airplane contain
    a lot of information (e.g., an object’s shape). Edge detection allows us to remove
    low-information areas and isolate the areas of images containing the most information.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘检测是计算机视觉中的一个主要话题。边缘非常重要，因为它们是信息量最大的区域。例如，在我们的图像中，一片天空看起来非常相似，不太可能包含独特或有趣的信息。然而，背景天空与飞机相遇的区域包含大量信息（例如，物体的形状）。边缘检测允许我们去除低信息量的区域，并分离包含最多信息的图像区域。
- en: There are many edge detection techniques (Sobel filters, Laplacian edge detector,
    etc.). However, our solution uses the commonly used Canny edge detector. How the
    Canny detector works is too detailed for this book, but there is one point that
    we need to address. The Canny detector requires two parameters denoting low and
    high gradient threshold values. Potential edge pixels between the low and high
    thresholds are considered weak edge pixels, while those above the high threshold
    are considered strong edge pixels. OpenCV’s `Canny` method includes the low and
    high thresholds as required parameters. In our solution, we set the lower and
    upper thresholds to be one standard deviation below and above the image’s median
    pixel intensity. However, we often get better results if we determine a good pair
    of low and high threshold values through manual trial and error on a few images
    before running `Canny` on our entire collection of images.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘检测有许多技术（Sobel滤波器、Laplacian边缘检测器等）。然而，我们的解决方案使用常用的Canny边缘检测器。Canny检测器的工作原理对本书来说过于详细，但有一点我们需要解决。Canny检测器需要两个参数来指定低梯度阈值和高梯度阈值。低和高阈值之间的潜在边缘像素被认为是弱边缘像素，而高于高阈值的像素被认为是强边缘像素。OpenCV的`Canny`方法包括所需的低和高阈值参数。在我们的解决方案中，我们将低和高阈值设置为图像中位数下方和上方的一个标准偏差。然而，在运行`Canny`处理整个图像集之前，我们经常通过手动在几幅图像上试错来确定一对好的低和高阈值，以获得更好的结果。
- en: See Also
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Canny Edge Detector, Wikipedia](https://oreil.ly/gG9xo)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Canny边缘检测器，维基百科](https://oreil.ly/gG9xo)'
- en: '[Canny Edge Detection Auto Thresholding](https://oreil.ly/YvjM5)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Canny边缘检测自动阈值](https://oreil.ly/YvjM5)'
- en: 8.12 Detecting Corners
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.12 检测角点
- en: Problem
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to detect the corners in an image.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望检测图像中的角点。
- en: Solution
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use OpenCV’s implementation of the Harris corner detector, `cornerHarris`:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用OpenCV的Harris角检测器`cornerHarris`的实现：
- en: '[PRE33]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![mpc2 08in19](assets/mpc2_08in19.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in19](assets/mpc2_08in19.png)'
- en: Discussion
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: 'The *Harris corner detector* is a commonly used method of detecting the intersection
    of two edges. Our interest in detecting corners is motivated by the same reason
    as for detecting edges: corners are points of high information. A complete explanation
    of the Harris corner detector is available in the external resources at the end
    of this recipe, but a simplified explanation is that it looks for windows (also
    called *neighborhoods* or *patches*) where small movements of the window (imagine
    shaking the window) create big changes in the contents of the pixels inside the
    window. `cornerHarris` contains three important parameters that we can use to
    control the edges detected. First, `block_size` is the size of the neighbor around
    each pixel used for corner detection. Second, `aperture` is the size of the Sobel
    kernel used (don’t worry if you don’t know what that is), and finally there is
    a free parameter where larger values correspond to identifying softer corners.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '*Harris角点检测器*是一种常用的检测两条边交点的方法。我们对检测角点的兴趣与检测边缘的原因相同：角点是信息量很高的点。Harris角点检测器的完整解释可以在本文末尾的外部资源中找到，但简化的解释是它寻找窗口（也称为*邻域*或*补丁*），在这些窗口中，窗口的微小移动（想象抖动窗口）导致窗口内像素内容的显著变化。`cornerHarris`包含三个重要参数，我们可以用它来控制检测到的边缘。首先，`block_size`是用于角点检测的每个像素周围的邻域的大小。其次，`aperture`是使用的Sobel核的大小（如果你不知道是什么也没关系），最后有一个自由参数，较大的值对应于识别更软的角点。'
- en: 'The output is a grayscale image depicting potential corners:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一个灰度图像，描述了潜在的角点：
- en: '[PRE34]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![mpc2 08in20](assets/mpc2_08in20.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in20](assets/mpc2_08in20.png)'
- en: 'We then apply thresholding to keep only the most likely corners. Alternatively,
    we can use a similar detector, the Shi-Tomasi corner detector, which works in
    a similar way to the Harris detector (`goodFeaturesToTrack`) to identify a fixed
    number of strong corners. `goodFeaturesToTrack` takes three major parameters—​the
    number of corners to detect, the minimum quality of the corner (0 to 1), and the
    minimum Euclidean distance between corners:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们应用阈值处理，仅保留最可能的角点。或者，我们可以使用类似的检测器，即Shi-Tomasi角点检测器，它的工作方式与Harris检测器类似（`goodFeaturesToTrack`），用于识别固定数量的强角点。`goodFeaturesToTrack`有三个主要参数——要检测的角点数目，角点的最小质量（0到1之间），以及角点之间的最小欧氏距离：
- en: '[PRE35]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![mpc2 08in21](assets/mpc2_08in21.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in21](assets/mpc2_08in21.png)'
- en: See Also
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '[OpenCV’s cornerHarris](https://oreil.ly/vLMBj)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenCV的cornerHarris](https://oreil.ly/vLMBj)'
- en: '[OpenCV’s goodFeaturesToTrack](https://oreil.ly/Ra-x6)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenCV的goodFeaturesToTrack](https://oreil.ly/Ra-x6)'
- en: 8.13 Creating Features for Machine Learning
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.13 为机器学习创建特征
- en: Problem
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to convert an image into an observation for machine learning.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望将图像转换为机器学习的观察结果。
- en: Solution
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use NumPy’s `flatten` to convert the multidimensional array containing image
    data into a vector containing the observation’s values:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NumPy的`flatten`将包含图像数据的多维数组转换为包含观察值的向量：
- en: '[PRE36]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Discussion
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: 'Images are presented as a grid of pixels. If an image is in grayscale, each
    pixel is presented by one value (i.e., pixel intensity is `1` if white, `0` if
    black). For example, imagine we have a 10 × 10–pixel image:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图像呈像素网格的形式呈现。如果图像是灰度的，每个像素由一个值表示（即，如果是白色，则像素强度为`1`，如果是黑色则为`0`）。例如，想象我们有一个10
    × 10像素的图像：
- en: '[PRE38]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '![mpc2 08in22](assets/mpc2_08in22.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in22](assets/mpc2_08in22.png)'
- en: 'In this case, the dimensions of the image’s data will be 10 × 10:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，图像数据的尺寸将是10 × 10：
- en: '[PRE39]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'And if we flatten the array, we get a vector of length 100 (10 multiplied by
    10):'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们展平数组，我们得到长度为100的向量（10乘以10）：
- en: '[PRE41]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This is the feature data for our image that can be joined with the vectors from
    other images to create the data we will feed to our machine learning algorithms.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们图像的特征数据，可以与其他图像的向量合并，以创建我们将提供给机器学习算法的数据。
- en: 'If the image is in color, instead of each pixel being represented by one value,
    it is represented by multiple values (most often three) representing the channels
    (red, green, blue, etc.) that blend to make the final color of that pixel. For
    this reason, if our 10 × 10 image is in color, we will have 300 feature values
    for each observation:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如果图像是彩色的，每个像素不是由一个值表示，而是由多个值表示（通常是三个），表示混合以形成该像素的最终颜色的通道（红色、绿色、蓝色等）。因此，如果我们的10
    × 10图像是彩色的，每个观察值将有300个特征值：
- en: '[PRE43]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'One of the major challenges of image processing and computer vision is that
    since every pixel location in a collection of images is a feature, as the images
    get larger, the number of features explodes:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图像处理和计算机视觉的一个主要挑战是，由于图像集合中每个像素位置都是一个特征，随着图像变大，特征数量会急剧增加：
- en: '[PRE45]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'And the number of features grows even larger when the image is in color:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当图像为彩色时，特征数量甚至变得更大：
- en: '[PRE47]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: As the output shows, even a small color image has almost 200,000 features, which
    can cause problems when we are training our models because the number of features
    might far exceed the number of observations.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如输出所示，即使是小型彩色图像也有接近200,000个特征，这可能在训练模型时会引发问题，因为特征数量可能远远超过观察值的数量。
- en: This problem will motivate dimensionality strategies discussed in a later chapter,
    which attempt to reduce the number of features while not losing an excessive amount
    of information contained in the data.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题将推动后面章节讨论的降维策略，试图在不失去数据中过多信息的情况下减少特征数量。
- en: 8.14 Encoding Color Histograms as Features
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.14 将颜色直方图编码为特征
- en: Problem
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to create a set of features representing the colors appearing in an
    image.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 您想创建一组表示图像中出现的颜色的特征。
- en: Solution
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Compute the histograms for each color channel:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 计算每个颜色通道的直方图：
- en: '[PRE49]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Discussion
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: 'In the RGB color model, each color is the combination of three color channels
    (i.e., red, green, blue). In turn, each channel can take on one of 256 values
    (represented by an integer between 0 and 255). For example, the top leftmost pixel
    in our image has the following channel values:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在RGB颜色模型中，每种颜色都是三个颜色通道（即红色、绿色、蓝色）的组合。每个通道可以取0到255之间的256个值（由整数表示）。例如，我们图像中左上角的像素具有以下通道值：
- en: '[PRE51]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'A histogram is a representation of the distribution of values in data. Here’s
    a simple example:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图是数据值分布的表示。这里有一个简单的例子：
- en: '[PRE53]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '![mpc2 08in23](assets/mpc2_08in23.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in23](assets/mpc2_08in23.png)'
- en: In this example, we have some data with two `1`s, two `2`s, three `3`s, one
    `4`, and one `5`. In the histogram, each bar represents the number of times each
    value (`1`, `2`, etc.) appears in our data.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们有一些数据，其中有两个`1`，两个`2`，三个`3`，一个`4`和一个`5`。在直方图中，每个条形表示数据中每个值（`1`，`2`等）出现的次数。
- en: 'We can apply this same technique to each of the color channels, but instead
    of five possible values, we have 256 (the number of possible values for a channel
    value). The x-axis represents the 256 possible channel values, and the y-axis
    represents the number of times a particular channel value appears across all pixels
    in an image (apologies to hardcopy readers for whom there are no color images):'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这种技术应用到每个颜色通道上，但是不是五种可能的值，而是256种（通道值的可能数）。x轴表示256个可能的通道值，y轴表示图像中所有像素中特定通道值出现的次数（对于没有彩色图像的纸质读者表示歉意）：
- en: '[PRE54]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '![mpc2 08in24](assets/mpc2_08in24.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in24](assets/mpc2_08in24.png)'
- en: As we can see in the histogram, barely any pixels contain the blue channel values
    between 0 and ~180, while many pixels contain blue channel values between ~190
    and ~210\. This distribution of channel values is shown for all three channels.
    The histogram, however, is not simply a visualization; it has 256 features for
    each color channel, making for 768 total features representing the distribution
    of colors in an image.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在直方图中看到的，几乎没有像素包含蓝色通道值在0到约180之间，而许多像素包含蓝色通道值在约190到约210之间。该通道值分布显示了所有三个通道的情况。然而，直方图不仅仅是一种可视化工具；每个颜色通道有256个特征，总共为768个特征，代表图像中颜色分布。
- en: See Also
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Histogram, Wikipedia](https://oreil.ly/nPbJT)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[直方图，维基百科](https://oreil.ly/nPbJT)'
- en: '[pandas documentation: Histogram](https://oreil.ly/h60M5)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pandas 文档：直方图](https://oreil.ly/h60M5)'
- en: '[OpenCV tutorial: Histogram](https://oreil.ly/BuX1C)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenCV 教程：直方图](https://oreil.ly/BuX1C)'
- en: 8.15 Using Pretrained Embeddings as Features
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.15 使用预训练的嵌入作为特征
- en: Problem
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to load pretrained embeddings from an existing model in PyTorch and
    use them as input to one of your own models.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 您想从现有的PyTorch模型中加载预训练的嵌入，并将其用作您自己模型的输入。
- en: Solution
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use `torchvision.models` to select a model and then retrieve an embedding from
    it for a given image:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`torchvision.models`选择模型，然后从中检索给定图像的嵌入：
- en: '[PRE55]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Discussion
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: In the ML space, *transfer learning* is often defined as taking information
    learned from one task and using it as input to another task. Instead of starting
    from zero, we can use representations already learned from large pretrained image
    models (such as ResNet) to get a head start on our own machine learning models.
    More intuitively, you can understand how we could use the weights of a model trained
    to recognize cats as a good start for a model we want to train to recognize dogs.
    By sharing information form one model to another, we can leverage the information
    learned from other datasets and model architectures without the overhead of training
    a model from scratch.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习领域，*迁移学习*通常被定义为从一个任务学到的信息，并将其作为另一个任务的输入。我们可以利用已经从大型预训练图像模型（如ResNet）学到的表示来快速启动我们自己的机器学习模型，而不是从零开始。更直观地说，你可以理解为，我们可以使用一个训练用于识别猫的模型的权重作为我们想要训练用于识别狗的模型的一个良好的起点。通过从一个模型向另一个模型共享信息，我们可以利用从其他数据集和模型架构学到的信息，而无需从头开始训练模型。
- en: 'The entire application of transfer learning in computer vision is outside the
    scope of this book; however, there are many different ways we can extract embeddings-based
    representations of images outside of PyTorch. In TensorFlow, another common library
    for deep learning, we can use `tensorflow_hub`:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉中应用迁移学习的整个过程超出了本书的范围；然而，我们可以在PyTorch之外的许多不同方式中提取基于嵌入的图像表示。在TensorFlow中，另一个常见的深度学习库，我们可以使用`tensorflow_hub`：
- en: '[PRE57]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: See Also
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[PyTorch tutorial: Transfer Learning for Computer Vision](https://oreil.ly/R8RTk)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch教程：计算机视觉的迁移学习](https://oreil.ly/R8RTk)'
- en: '[TensorFlow Hub](https://oreil.ly/iwHI6)'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow Hub](https://oreil.ly/iwHI6)'
- en: 8.16 Detecting Objects with OpenCV
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.16 使用OpenCV检测对象
- en: Problem
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to detect objects in images using pretrained cascade classifiers with
    OpenCV.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望使用OpenCV中预训练的级联分类器来检测图像中的对象。
- en: Solution
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Download and run one of OpenCV’s [Haar cascade classifiers](https://oreil.ly/XlXbm).
    In this case, we use a pretrained face detection model to detect and draw a rectangle
    around a face in an image:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并运行一个OpenCV的[Haar级联分类器](https://oreil.ly/XlXbm)。在这种情况下，我们使用一个预训练的人脸检测模型来检测图像中的人脸并画一个矩形框：
- en: '[PRE59]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '![mpc2 08in25](assets/mpc2_08in25.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![mpc2 08in25](assets/mpc2_08in25.png)'
- en: Discussion
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: '*Haar cascade classifiers* are machine learning models used to learn a set
    of image features (specifically Haar features) that can be used to detect objects
    in images. The features themselves are simple rectangular features that are determined
    by calculating the difference in sums between rectangular regions. Subsequently,
    a gradient boosting algorithm is applied to learn the most important features
    and, finally, create a relatively strong model using cascading classifiers.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '*Haar级联分类器*是用于学习一组图像特征（特别是Haar特征）的机器学习模型，这些特征可以用于检测图像中的对象。这些特征本身是简单的矩形特征，通过计算矩形区域之间的和的差异来确定。随后，应用梯度提升算法来学习最重要的特征，并最终使用级联分类器创建相对强大的模型。'
- en: While the details of this process are outside the scope of this book, it’s noteworthy
    that these pretrained models can be easily downloaded from places such as the
    [OpenCV GitHub](https://oreil.ly/273DA) as XML files and applied to images without
    training a model yourself. This is useful in cases where you want to add simple
    binary image features such as `contains_face` (or any other object) to your data.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个过程的详细信息超出了本书的范围，但值得注意的是，这些预训练模型可以轻松从诸如[OpenCV GitHub](https://oreil.ly/273DA)这样的地方下载为XML文件，并应用于图像，而无需自己训练模型。在你想要将简单的二进制图像特征（如`contains_face`或任何其他对象）添加到你的数据中的情况下，这非常有用。
- en: See Also
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[OpenCV tutorial: Cascade Classifier](https://oreil.ly/dFhu6)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenCV教程：级联分类器](https://oreil.ly/dFhu6)'
- en: 8.17 Classifying Images with Pytorch
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.17 使用Pytorch对图像进行分类
- en: Problem
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to classify images using pretrained deep learning models in Pytorch.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望使用Pytorch中预训练的深度学习模型对图像进行分类。
- en: Solution
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Use `torchvision.models` to select a pretrained image classification model
    and feed the image through it:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`torchvision.models`选择一个预训练的图像分类模型，并将图像输入其中：
- en: '[PRE60]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Discussion
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Many pretrained deep learning models for image classification are easily available
    via both PyTorch and TensorFlow. In this example, we used ResNet18, a deep neural
    network architecture that was trained on the ImageNet dataset that is 18 layers
    deep. Deeper ResNet models, such as ResNet101 and ResNet152, are also available
    in Pytorch—and beyond that there are many other image models to choose from. Models
    trained on the ImageNet dataset are able to output predicted probabilities for
    all classes defined in the `imagenet_class_index` variable in the previous code
    snippet, which we downloaded from GitHub.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 许多预训练的深度学习模型用于图像分类，通过PyTorch和TensorFlow都很容易获取。在这个例子中，我们使用了ResNet18，这是一个深度神经网络架构，它在ImageNet数据集上训练，深度为18层。在PyTorch中还有更深的ResNet模型，如ResNet101和ResNet152，此外还有许多其他可供选择的图像模型。在ImageNet数据集上训练的模型能够为我们在之前代码片段中从GitHub下载的`imagenet_class_index`变量中定义的所有类别输出预测概率。
- en: Like the facial recognition example in OpenCV (see [Recipe 8.16](#detecting-objects-with-open-cv)),
    we can use the predicted image classes as downstream features for future ML models
    or handy metadata tags that add more information to our images.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在OpenCV中的面部识别示例（参见[Recipe 8.16](#detecting-objects-with-open-cv)）一样，我们可以将预测的图像类别作为未来ML模型的下游特征，或者作为有用的元数据标签，为我们的图像添加更多信息。
- en: See Also
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[PyTorch documentation: Models and Pre-trained Weights](https://oreil.ly/MhlxR)'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch文档：模型和预训练权重](https://oreil.ly/MhlxR)'
