- en: 'ML Ops: Operationalizing Data Science'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML Ops：数据科学的运营化
- en: Would you spend many years and big money training athletes and then send them
    to the Olympic Games, only to make them stay in their hotel instead of competing?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你会花费多年时间和大量资金来训练运动员，然后把他们送去参加奥运会，却只让他们待在酒店不参赛吗？
- en: “Of course not,” you say. “That would be ridiculous. Nobody would do that.”
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: “当然不会”，你说。“那太荒谬了。没人会这样做。”
- en: You’re right. It is ridiculous.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 你说得对。这太荒谬了。
- en: But if you’re spending a lot of time and money developing and training your
    analytics and machine learning (ML) models without getting them into production—be
    that because of operational difficulties or because models are not consistent
    with applicable regulations and laws—aren’t you making the same mistake? Models
    that do nothing more than provide static insights in a slideshow are not truly
    “operational,” and they don’t drive real business change.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果你花费了大量时间和金钱开发和培训你的分析和机器学习（ML）模型，却没有将它们投入生产——无论是因为操作困难还是因为模型与适用法规不一致——难道你不是在犯同样的错误吗？那些仅在幻灯片中提供静态见解的模型并不真正“运营化”，它们不能带来真正的业务变革。
- en: You’re probably not setting your models on the shelf deliberately. There are
    plenty of reasons why so many models—by some estimates, more than half—don’t make
    it into production. But if they’re not in production, they can’t do what you’ve
    trained them to do.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能不是故意把你的模型放在架子上。据估计，有超过一半的模型之所以未能投入生产，有很多原因。但如果它们没有投入生产，它们就无法完成你训练它们要做的事情。
- en: ML Operations, or ML Ops, is the process of operationalizing data science by
    getting ML models into production—being able to monitor their performance and
    ensure they are fair and in compliance with applicable regulations. The four main
    steps in the process (Build, Manage, Deploy and Integrate, and Monitor) form a
    repeatable cycle for handling models as reusable software artifacts. ML Ops ensures
    that models continue to deliver value to the organization, while also providing
    critical insights for managing the potential risks of model-based decision-making,
    even as underlying business and technical conditions change.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ML运营，或者ML Ops，是通过将ML模型投入生产来实现数据科学运营的过程——能够监控它们的性能，并确保它们在适用法规下是公平和合规的。该过程的四个主要步骤（构建、管理、部署和集成、监控）形成了处理模型作为可重复使用软件构件的循环。ML
    Ops确保模型继续为组织提供价值，同时为管理基于模型决策的潜在风险提供关键见解，即使基础业务和技术条件发生变化。
- en: In your organization, what does it take to operationalize the ML models that
    make up your data science initiatives? You may have data science and ML, but do
    you have ML Operations? Have you created the processes needed to get your models
    from the data scientists who first develop them all the way to the applications
    that make advanced analytics available to the business? Are your models fair,
    and do you understand why specific predictions are made? Can you efficiently manage
    new (“challenger”) models under development as well as current (“champion”) production
    models, and have you implemented versioning and approval processes to support
    your ML Operations? Who else—line-of-business (LOB) managers, application developers,
    data engineers, DevOps, IT—is involved in the ML Ops life cycle in your company?
    Do you think about it as a life cycle? All of that is ML Ops.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的组织中，要实现组成数据科学计划的ML模型运营化，需要什么？你可能拥有数据科学和ML，但你有ML运营吗？你是否创建了从最初开发模型的数据科学家到使高级分析可用于业务的应用程序的流程？你的模型公平吗？你了解特定预测为何做出吗？你能有效地管理正在开发的新（“挑战者”）模型以及当前（“冠军”）生产模型吗？你是否实施了支持ML运营的版本控制和批准流程？在你公司的ML
    Ops生命周期中，还有谁——业务线（LOB）经理、应用程序开发人员、数据工程师、DevOps、IT——参与其中？你是否将其视为一个生命周期？所有这些都是ML
    Ops。
- en: Based on the experience of numerous projects across the globe, this report introduces
    concepts that enable you to realize business value by operationalizing machine
    learning models. It presents a practical, four-step approach (Build, Manage, Deploy
    and Integrate, Monitor) for realizing the value of data science and machine learning
    by creating ML-infused applications within your organization. The report is designed
    as an overview of the capabilities needed to operationalize data science and machine
    learning pipelines so that you can ultimately create business applications using
    AI and ML technology. Readers will benefit from real-world case studies and the
    perspectives of data scientists on how best to operationalize data science.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 基于全球众多项目的经验，本报告介绍了通过创建ML注入应用程序实现操作化数据科学和机器学习价值的概念。它提出了一个实用的四步方法（构建、管理、部署与集成、监控），以便您最终可以使用AI和ML技术在您的组织内创建业务应用程序。该报告旨在概述操作化数据科学和机器学习管道所需的能力，以便您最终可以使用AI和ML技术创建业务应用程序。读者将从实际案例研究和数据科学家对如何最佳操作化数据科学的观点中受益。
- en: 'Analytics leaders, application developers, data engineers, line-of-business
    (LOB) executives, IT managers, and business analysts regularly come into contact
    with models at various points as AI applications are developed and data science
    pipelines are operationalized. Here are the most important things readers will
    learn from this report:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 分析领导者、应用程序开发人员、数据工程师、业务线（LOB）高管、IT经理和业务分析师经常在AI应用程序开发和数据科学管道操作化的各个环节接触到模型。以下是读者从本报告中学到的最重要的事情：
- en: In its life cycle, an ML model is developed and improved in an analytics pipeline
    or workflow that touches stakeholders all around the organization. Realizing the
    value of data science and machine learning is a matter of reducing friction throughout
    those pipelines and workflows.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在其生命周期中，ML模型在涉及组织各方利益相关者的分析管道或工作流程中进行开发和改进。实现数据科学和机器学习的价值是通过减少这些管道和工作流程中的摩擦来实现的。
- en: ML models need constant refinement. They include data transformations and embody
    relationships with continually changing data that impact the accuracy of their
    predictions. As such, operationalizing ML pipelines has management implications
    that are different from those of traditional software application engineering.
    In particular, long-term accuracy depends on periodic tuning, retraining, and
    even complete remodeling.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ML模型需要不断完善。它们包括数据转换，并体现与不断变化的数据关系，这些因素影响其预测的准确性。因此，操作化ML管道具有与传统软件应用工程不同的管理影响。特别是，长期的准确性取决于定期的调整、重新训练甚至完全重建。
- en: ML models that are people-facing must be unbiased, fair, and explainable; that
    is what the public demands and what regulatory agencies and bodies increasingly
    require. For such applications, the ML Ops life cycle must be designed to enable
    transparency and explainability.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面向公众的ML模型必须是无偏见、公平和可解释的；这是公众的要求，也是监管机构和机构日益需要的。因此，针对这类应用程序，ML Ops生命周期必须设计为能够实现透明度和可解释性。
- en: Operationalizing models means not only reducing their friction in deployment
    of the pipeline but also embedding them in a business system. Frequently, the
    environment in which models are developed is quite different from the environment
    in which they are ultimately deployed. Integration of predictive models into external
    systems is an area that is not only complex but also less standardized than other
    aspects of the ML life cycle.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的运营化意味着不仅要减少其在管道部署中的摩擦，还要将其嵌入业务系统中。模型开发的环境往往与最终部署的环境大不相同。将预测模型集成到外部系统是一个复杂且比ML生命周期的其他方面标准化程度低的领域。
- en: 'Smart organizations currently think about and structure their data science
    and machine learning pipelines in four steps: Build, Manage, Deploy and Integrate,
    and Monitor.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前，聪明的组织正考虑并构建他们的数据科学和机器学习管道，分为四个步骤：构建、管理、部署与集成以及监控。
- en: An Introduction to ML Ops and Operationalizing Data Science Models
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍ML Ops和操作化数据科学模型
- en: ML Ops is an outgrowth of existing well-documented data science and machine
    learning processes—for example, [CRISP-DM](https://oreil.ly/XhEPd)—that align
    advanced analytics with the needs of the business. However, these established
    processes largely cover the model development process and do not address the needs
    of operationalizing those models within business systems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ML Ops是现有充分记录的数据科学和机器学习过程的延伸，例如[CRISP-DM](https://oreil.ly/XhEPd)——它将高级分析与业务需求对齐。然而，这些已建立的过程主要涵盖模型开发过程，并未解决在业务系统内操作这些模型的需求。
- en: What Is ML Ops?
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是ML Ops？
- en: ML Ops is a cross-functional, collaborative, continuous process that focuses
    on operationalizing data science by managing statistical, data science, and machine
    learning models as reusable, highly available software artifacts, via a repeatable
    deployment process. It encompasses unique management aspects that span model inference,
    scalability, maintenance, auditing, and governance, as well as the ongoing monitoring
    of models in production to ensure they are still delivering positive business
    value as the underlying conditions change.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ML Ops是一个跨职能、协作、持续的过程，专注于通过可重复的部署流程管理统计学、数据科学和机器学习模型作为可重用、高度可用的软件工件来实现数据科学的操作化。它涵盖了跨模型推理、可伸缩性、维护、审计和治理的独特管理方面，以及对生产中模型的持续监控，以确保它们在基础条件变化时仍能为业务创造正面价值。
- en: The organization needs to look at realizing the value of data science and machine
    learning models as a whole, rather than as simply a process of developing models.
    As shown in [Figure 1](#fig_1__steps_in_the_process_of_operationalizing_data_sc),
    ML Ops involves four conceptually simple steps, but the complexity is certainly
    in the details.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 组织需要考虑整体实现数据科学和机器学习模型的价值，而不仅仅是开发模型的过程。如图[Figure 1](#fig_1__steps_in_the_process_of_operationalizing_data_sc)所示，ML
    Ops涉及四个概念简单的步骤，但复杂性显然在于细节。
- en: In practice, in many organizations business stakeholders and data scientists
    sometimes focus most of their attention and resources on building models, rather
    than—and perhaps at the expense of—considering how to operationalize all critical
    steps of the entiredata science process.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，许多组织的业务利益相关者和数据科学家有时将大部分注意力和资源集中在建立模型上，而忽视——或者说是以牺牲——操作化整个数据科学过程的所有关键步骤。
- en: '![](Images/mlop_0101.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/mlop_0101.png)'
- en: Figure 1\. Steps in the process of operationalizing data science
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1. 数据科学操作化过程中的步骤
- en: 'The ML Ops Pain Point: Time to Deployment'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML Ops的痛点：部署时间
- en: ML models need to be embedded and running in a business system so that their
    predictions have an impact on the business. But models of any kind—whether they
    are models that reduce customer churn, optimize real-time pricing, create targeted
    marketing campaigns, or identify fraud—are affected by obstacles to operationalization.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型需要嵌入并在业务系统中运行，以便它们的预测对业务产生影响。但任何类型的模型——无论是减少客户流失、优化实时定价、创建定向营销活动还是识别欺诈——都受到操作化障碍的影响。
- en: A common obstacle is the long delay between initiating a data science project
    and deploying the model so it can make predictions. The delay often leads to having
    a model in production that no longer conforms to the reality of real-world data,
    as in the following example.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见障碍是启动数据科学项目和部署模型之间的长时间延迟，以至于最终部署的模型可能不再符合现实世界数据的情况，如下例所示。
- en: A few years ago, the authors worked on developing models around customer turnover
    (“churn”) for a major US mobile phone company. The original models were developed
    with legacy analytics software, using data from an MPP database. The volume of
    data was quite high, and it needed to be sampled, extracted, transformed, and
    loaded (ETL) into the modeling server, which required coordination with the database
    administrator. Then, after a period of development and training, the models were
    finally converted into SQL so they could be used for scoring against the original
    data within the database. The entire process—from extraction through prep, modeling,
    and evaluation to deployment—took about four months. That meant that the variable
    the model was supposed to predict wasn’t “Will this customer churn?” but rather
    “Will this customer churn had we evaluated her (via a predictive score) four months
    ago?” The data was old, and the model was insensitive to often rapid changes in
    the business environment.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 几年前，作者们曾致力于为一家美国主要移动电话公司开发客户流失（“流失”）模型。最初的模型是使用传统分析软件和来自MPP数据库的数据开发的。数据量相当大，需要抽样、提取、转换和加载（ETL）到建模服务器中，这需要与数据库管理员协调。然后，在一段时间的开发和培训之后，模型最终被转换为SQL，以便对原始数据进行评分。整个过程——从提取到准备、建模、评估到部署——大约需要四个月的时间。这意味着模型预测的变量不是“这个客户会流失吗？”，而是“如果我们在四个月前评估她（通过预测分数），那么这个客户会流失吗？”数据已经过时，模型对业务环境的快速变化不敏感。
- en: So what was taking so long? It did not take much time to develop the models.
    But the upstream and downstream activities were vastly more time-consuming. Clearly,
    there was an urgent need for as much effort and sophistication to go into streamlining
    the ML Ops process as had gone into creating the models themselves. We were able
    to prove statistically that operationalizing these models more rapidly would provide
    a huge “lift” to the accuracy of the models with current customers and would identify
    many more at-risk customers.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 那么究竟是什么拖慢了进度？开发模型并不需要花费太多时间。但上下游活动却要耗费大量时间。显然，急需像开发模型本身一样大量投入精力和复杂性来简化ML Ops流程。我们能够统计证明，更快地使这些模型运营化将显著提升与当前客户模型准确性，并识别更多潜在风险客户。
- en: 'That delay led to one type of pain point. Considered more broadly, the pain
    in the organization sounds like this:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这种延迟导致了一种类型的痛点。更广泛地考虑，组织内的痛点听起来像这样：
- en: “We run a software application that relies on decision points generated by predictive
    models. How do we *build* that application and those models to handle all of the
    data and variables that go into useful predictions? How do we apply standards
    and approvals to *manage* multiple versions of models, with varying levels of
    performance, accuracy, and security? How do we take models from individual developers
    writing in Python and *deploy*those models into an executable form that can be
    *integrated* into our various application environments? How do we *monitor* the
    model so that it is fair and also continually keeps up with changing market conditions
    to deliver accurate predictions for our application? Finally, how do we accomplish
    all that and ensure that all the work we’re putting into data science and machine
    learning models pays off?”
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: “我们运行一个依赖于预测模型生成决策点的软件应用程序。我们如何*构建*这样的应用程序和模型来处理所有输入有用预测所需的数据和变量？我们如何应用标准和批准来*管理*各种性能、准确性和安全性水平的多个模型版本？我们如何将个别开发人员用Python编写的模型*部署*为可*集成*到各种应用环境中的可执行形式？我们如何*监控*模型，以确保公平，并持续跟上不断变化的市场条件，为我们的应用程序提供准确的预测？最后，我们如何完成所有这些工作，并确保我们投入到数据科学和机器学习模型中的所有工作都有所回报？”
- en: What, Really, Is a Model?
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 究竟什么是模型？
- en: Deploying models is rarely about deploying just the predictive model in its
    purest form. Much more often, the model also includes a number of transformations
    and business rules that can get in the way of operationalizing ML.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 部署模型很少只涉及纯粹的预测模型部署。更常见的是，模型还包括一些转换和业务规则，这些可能妨碍ML的运营化。
- en: 'Consider again the example of a model designed to make predictions about churn
    among cell phone subscribers. The data scientist includes central variables such
    as these:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 再次考虑一个模型的例子，该模型旨在预测手机用户的流失情况。数据科学家包括这些核心变量：
- en: Account balance
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 账户余额
- en: Recent phone usage
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近的手机使用情况
- en: Number of other subscribers, if a family account
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是家庭账户，其他订户的数量
- en: Residence
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 居住地
- en: Age
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄
- en: These variables already exist in the raw data, without additional calculations
    or minor cleanup. They may be relevant to the possibility of churn (an account
    balance in the red may be a risk factor), but by themselves they may not be the
    ideal predictors. An even more useful variable for highlighting propensity to
    churn may be phone usage in the past seven days compared to the overall weekly
    average for the life of the account. But a data point like that would not likely
    come straight out of a database. It would be necessary to start with raw data
    and then combine and transform the inputs to arrive at the more useful variable.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变量已经存在于原始数据中，无需额外计算或轻微清理。它们可能与客户流失的可能性相关（账户余额为负可能是风险因素），但单独来看它们可能不是理想的预测因子。更有用于突显流失倾向的变量可能是过去七天内的电话使用情况，与账户寿命的整体每周平均值相比较。但像这样的数据点可能不会直接从数据库中获得。需要从原始数据开始，然后组合和转换输入，以得到更有用的变量。
- en: Or consider a predictive model for setting the price of books in an online marketplace.
    All other things being equal, demand is proportional to the price of the book.
    But all other things are not always equal, which is why doubling the price does
    not always halve the sales volume. Transformations must be introduced to account
    for the non-linear relationship between price and sales volume, which requires
    a transformation that must accompany the pricing model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 或者考虑一个预测模型，用于设定在线市场书籍的价格。其他所有条件相等时，需求与书籍价格成正比。但并非所有其他条件总是相等，这就是为什么将价格翻倍并不总是会减半销量的原因。必须引入转换来解释价格与销量之间的非线性关系，这需要一个必须与定价模型相伴的转换。
- en: Thus, the model is the sum of itself plus all transformations. The whole must
    be managed as an artifact throughout the pipeline and during the model’s entire
    life cycle.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，模型是它自身加上所有转换的总和。整体必须作为管道中的一个工件进行管理，并在模型的整个生命周期内进行管理。
- en: Introducing the Four-Step ML Ops Approach
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入四步ML Ops方法
- en: 'Companies determined to successfully operationalize their ML models think of
    ML Ops in four main steps:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 企业决心成功将其ML模型运作化，将ML Ops分为四个主要步骤：
- en: Build
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 构建
- en: Data scientists use languages like Python and R, as well as commercial applications,
    to create analytics pipelines. They use standard machine learning algorithms,
    they build predictive models, and they perform feature engineering to create the
    transformations most likely to boost the predictive power of the ML model.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家使用像Python和R这样的语言，以及商业应用程序，来创建分析管道。他们使用标准的机器学习算法，构建预测模型，并进行特征工程，以创建最有可能提升ML模型预测能力的转换。
- en: Manage
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 管理
- en: Models have a life cycle that is best managed from a central repository where
    their provenance, versioning, consistency with regulatory rules and policies,
    approval for production, testing, deployment, and eventual replacement can be
    tracked. Besides the metadata associated with model artifacts, the management
    platform and the repository should track accuracy metrics as well as links between
    models and datasets.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 模型有一个生命周期，最好从一个中央库管理，其中可以跟踪其来源、版本管理、与监管规则和政策的一致性、生产批准、测试、部署以及最终替换。除了与模型工件相关的元数据外，管理平台和库还应跟踪准确性指标以及模型与数据集之间的链接。
- en: Deploy and Integrate
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 部署和集成
- en: In this step, a data science pipeline is taken from its original development
    environment and expressed in a form that can be executed independently and integrated
    into business applications. For example, a model developed in a Python Notebook
    may need to be converted into SQL code for execution in a Teradata database. At
    TIBCO, we’ve created mechanisms for exporting visual data science workflows as
    Java code (for example), which can then be embedded into application code. Additionally,
    model artifacts can be accessed via REST frameworks and APIs. Modern ML Ops architectures
    also may support containerized deployment of model artifacts to public or private
    cloud environments, enabling much faster time to production as well as flexible
    scalability and elasticity in support of highly variable scoring demands. In the
    end, you need to be able to deploy the pipeline in a format/language that is appropriate
    to the target runtime environment, consistent with your business requirements.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，数据科学管道从原始开发环境中取出，并以可以独立执行并集成到业务应用中的形式表达。例如，一个在 Python Notebook 中开发的模型可能需要转换为
    SQL 代码，以便在 Teradata 数据库中执行。在 TIBCO，我们创建了将可视化数据科学工作流程导出为 Java 代码（例如）的机制，然后可以嵌入到应用程序代码中。此外，模型工件可以通过
    REST 框架和 API 访问。现代 ML Ops 架构还可能支持将模型工件容器化部署到公共或私有云环境，实现更快的生产时间以及在支持高度可变评分需求方面的灵活扩展性和弹性。最终，你需要能够将管道以适合目标运行时环境的格式/语言部署，符合你的业务要求。
- en: Monitor
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 监控
- en: After a model has been deployed, it is monitored for the accuracy of its predictions,
    as well as model fairness and other important business criteria, to provide full
    visibility into general business impact. Such monitoring can be done via BI tools
    connected to predictions and model inputs, or it may take the form of regularly
    scheduled reports on all critical business key performance indicators (KPIs).
    Accuracy and other KPIs can be improved manually, through occasional iteration
    with input from a human expert, or automatically, through ongoing retraining and
    champion–challenger loops with approval by a human, for example.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署后，将监测其预测准确性、模型公平性和其他重要业务标准，以提供对一般业务影响的全面可见性。这种监测可以通过连接到预测和模型输入的 BI 工具完成，或者以定期报告所有关键业务绩效指标（KPI）形式存在。准确性和其他
    KPI 可以通过人工定期迭代获得人类专家的输入，或者通过持续的再训练和人类批准的冠军-挑战者循环自动提高。
- en: The following sections explore each step of the pipeline through the questions
    most organizations ask themselves.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分通过大多数组织会问自己的问题，探讨了管道的每个步骤。
- en: Build
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建
- en: In the build step, data scientists examine the data landscape to ensure a close
    fit between the data the model will use in training and the data it will use once
    deployed in the real world. They then use various development platforms (Python,
    R, commercial IDEs with drag-and-drop workflows, etc.) to create machine learning
    and data pipelines. Through feature engineering, they analyze variables for the
    transformations that make the ML model more powerful. They then test and train
    the resulting models until accuracy has reached the level beyond which it would
    not be beneficial to continue tweaking or adding data, features, or algorithms.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建步骤中，数据科学家检查数据环境，确保模型在训练时使用的数据与实际部署后使用的数据之间的紧密匹配。他们使用各种开发平台（如 Python、R、商业
    IDE，带有拖放工作流程的 IDE 等）创建机器学习和数据管道。通过特征工程，他们分析变量的变换，以使机器学习模型更加强大。然后，他们测试并训练生成的模型，直到准确度达到超出继续调整或添加数据、特征或算法后仍有益的水平。
- en: 'Data Considerations: Structures and Access'
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据考虑：结构和访问
- en: '*How close is our training data to the data that the model will see in real
    life? And how can we be sure that the models will be able to access similar data
    structures in both places?*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们的训练数据与模型在现实生活中将看到的数据有多接近？我们如何确保模型在两个地方都能访问到相似的数据结构？*'
- en: Models usually need to be trained on data that is extracted from real-time systems
    and warehoused offline. But after training, the model deployed for the application
    may run online against real-time streaming data. If the data structures and even
    the programming languages change between training and operational modes, that
    difference complicates the ML Ops process and can affect the usefulness of the
    model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 模型通常需要在从实时系统中提取并离线存储的数据上进行训练。但是在训练之后，部署到应用程序中的模型可能会在线对抗实时流数据。如果数据结构甚至编程语言在训练和操作模式之间发生变化，这种差异会使得
    ML Ops 过程变得复杂，并且可能影响模型的实用性。
- en: Of course, the model’s usefulness depends heavily on the data on which it has
    been trained. So if the model is meant to run on a website in JavaScript on streaming
    data, then training it on an offline cluster in PySpark may provide access to
    a rich set of historical clickstream data, but it will make the deployment process
    much more complex. These fundamental differences between development and production
    environments are not just common, but often inevitable. When creating business
    applications, data scientists, data engineers, Model Ops engineers, and application
    developers need to work closely together to understand what elements will be available
    in production environments.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，模型的实用性在很大程度上取决于其训练所依赖的数据。因此，如果模型旨在在 JavaScript 的网站上通过流数据运行，则在 PySpark 的离线集群中进行训练可能提供对丰富的历史点击流数据的访问，但这将使得部署过程变得更加复杂。开发和生产环境之间的这些基本差异不仅普遍存在，而且通常是不可避免的。在创建业务应用程序时，数据科学家、数据工程师、模型运维工程师和应用程序开发人员需要密切合作，以了解在生产环境中哪些元素将可用。
- en: In the real world, access to the data—at design time versus runtime—is also
    important. A financial model, for example, might perform text analytics on recent
    analyst reports to predict whether the price of a given stock is more likely to
    rise or fall. Adding metrics gleaned by carefully processing the language in these
    documents may well make the resulting model much more accurate when tested “in
    the lab.” But for high-frequency trading models, it would not be possible to analyze
    text from the latest news feeds rapidly enough, so the data scientist needs to
    consider whether the models will have access to a cache of recent text metrics
    or whether it’s reasonable to include such variables at all.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，访问数据——无论是在设计时还是运行时——都非常重要。例如，财务模型可能会对最近的分析师报告进行文本分析，以预测某只股票的价格是上涨还是下跌。通过精心处理这些文档中的语言得出的度量指标，很可能会使得在“实验室”中测试时结果更加准确。但是对于高频交易模型来说，从最新的新闻源快速分析文本是不可能的，因此数据科学家需要考虑模型是否可以访问最近文本度量的缓存，或者是否合理地包括这些变量。
- en: Feature Engineering
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程
- en: '*How do we create new variables that give us more accurate models? Can the
    variables be replicated in an operational environment?*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们如何创建新的变量以获得更准确的模型？这些变量是否可以在操作环境中复制？*'
- en: In feature engineering, data scientists analyze variables in the data to determine
    what transformations could be applied to these variables as well as what new variables
    could be created that would increase the predictive power of a machine learning
    model. From a deployment point of view, it is critical that important features
    that have been engineered in this way can be reproduced in the operational system.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征工程中，数据科学家分析数据中的变量，确定可以应用到这些变量的转换，以及可以创建哪些新变量，以增强机器学习模型的预测能力。从部署的角度来看，重要特征经过这种方式进行工程化处理后，能够在操作系统中进行复现，这一点至关重要。
- en: For example, consider a generalized linear model (GLM) for generating premium
    quotes on insurance policies. The model starts with the data that users enter
    to the insurance company’s web portal and then it applies transformations to calculate
    a premium discount for the customer’s market segment and return a quote to the
    user. The raw data entered must be converted to the model input formats. For example,
    a numeric entry for the user’s age is bucketed into age band, and other entries
    are converted into the features and units required for the model, and then they
    passed into the currently active model. In production, all of those transformations
    must take place on the event stream of user data coming in from the web portal.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个用于生成保险单保费报价的广义线性模型（GLM）。模型从用户输入的数据开始，通过转换计算客户的市场细分的保费优惠，并向用户返回报价。输入的原始数据必须转换为模型输入格式。例如，用户年龄的数字输入被划分为年龄段，并且其他输入被转换为模型所需的特征和单位，然后传递到当前活动的模型。在生产过程中，所有这些转换都必须在从网络门户进入的用户数据事件流上进行。
- en: Geography and jurisdiction are also factors in feature engineering. Consider
    variables like age or postal code, which may contribute to accuracy but which
    local laws and accepted standards of fairness might preclude from use in an ML
    model for a marketing campaign. Thus, some features that are not universal should
    be combined with geofencing—the use of radios and networks to define a boundary—at
    the application level to ensure they are not active in prohibited times and places.
    Although there are various philosophies on how to approach this, more often than
    not, organizations use the most restrictive policies for all of their needs. (At
    TIBCO, we believe that all software tools should enable the greatest flexibility
    for compliance with regulations like the European GDPR rules, the US HIPAA laws,
    or the EU Guidelines on Ethics in Artificial Intelligence. A global adherence
    to broadly accepted standards like these seems like the best and simplest way
    to ensure privacy and fairness consistent with local rules and cultural values,
    now and in the future as predictive modeling technologies continue to advance
    at a rapid pace.)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 地理位置和司法管辖权也是特征工程中的因素。考虑到诸如年龄或邮政编码之类的变量，它们可能有助于提高准确性，但当地法律和公平公正的接受标准可能会阻止在营销活动的机器学习模型中使用它们。因此，一些不具普遍性的特征应与地理围栏结合使用—即使用无线电和网络来定义边界—在应用层级上确保它们在禁止的时间和地点不活跃。虽然有各种哲学观点来解决这个问题，但更多时候，组织会对他们所有需求使用最严格的政策。（在TIBCO，我们相信所有软件工具应当为遵守类似欧洲
    GDPR 规定、美国 HIPAA 法律或欧盟关于人工智能道德原则的规定提供最大的灵活性。遵守这些广泛接受的标准似乎是确保与本地规则和文化价值一致的隐私和公平性的最佳和最简单的方式，现在和未来当预测建模技术继续以快速步伐进展时。）
- en: Complexity affects feature engineering because while complex features may yield
    greater accuracy, they usually come at some cost. Weather data could improve a
    model used in agriculture, but not all relevant inputs are accessible in an operational
    environment. Similarly, text analysis could be used to train a model to understand
    language, but if the memory requirement is too great, it will hamper performance
    once the application is implemented. Some models depend on an interaction of terms,
    in which pairs of variables are combined to express business drivers that work
    in concert; however, an explosion of all possible combinations may degrade performance
    (and lead to “overfitting”).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂度影响特征工程，因为虽然复杂的特征可能会带来更高的准确性，但通常会伴随一些成本。天气数据可能会改进在农业中使用的模型，但并非所有相关输入在运行环境中都是可访问的。同样，文本分析可以用于训练模型以理解语言，但如果内存需求太大，那么一旦应用实施，它将影响性能。有些模型依赖术语之间的互动，其中变量对组合以表达共同作用的业务驱动因素；然而，所有可能组合的激增可能降低性能（导致“过拟合”）。
- en: Finally, complexity ties into explainability, the idea that technical professionals
    should be able to use the structure of a model to gain business understanding
    and to account for the accuracy or inaccuracy of models to decision-makers and
    consumers. Explainability plays a role in helping everyone along the ML pipeline
    understand how models arrive at their predictions. An example of explainability
    that relates to ML Ops is a reason code that explains why a model has denied credit
    to a given applicant. Explainability in ML Ops is important because, as the features
    that go into a model grow more complex, it becomes more difficult to explain the
    model’s predictions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，复杂性与可解释性相关联，技术专业人员应能够利用模型结构获得业务理解，并向决策者和消费者解释模型的准确性或不准确性。可解释性在帮助ML管道中的所有人理解模型如何得出预测方面起到了作用。与ML
    Ops相关的可解释性示例包括解释为何模型拒绝给定申请人信用的原因代码。ML Ops中的可解释性很重要，因为随着进入模型的特征变得更加复杂，解释模型的预测变得更加困难。
- en: Model Testing
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型测试
- en: '*How do we test our models in a way that reflects the production environment?*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们如何测试我们的模型以反映生产环境？*'
- en: Like debugging in the context of software application development, model testing
    includes executing a model on representative data and examining it for performance
    and accuracy. When testing models, data scientists can attempt simple fixes for
    unintended consequences before the model is deployed. The goal is to feed production
    data to the model in an environment where the model can be safely executed. Similarly,
    realistic production data should occur in the test stream also. In practice, there
    are often many development, testing, and other pre-production environments; for
    example, to stage new versions of scoring software, to debug predictions, or to
    evaluate multiple (“challenger”) models scoring data in parallel with the production
    model so that the value of improved models can be evaluated. Modern cloud-based
    technologies can often deliver such agility without adding much overhead in cost
    and effort.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 像在软件应用程序开发环境中的调试一样，模型测试包括在代表性数据上执行模型，并检查其性能和准确性。在测试模型时，数据科学家可以在部署模型之前尝试简单的修复措施，以解决意外后果。目标是在可以安全执行模型的环境中向模型提供生产数据。类似地，真实的生产数据也应该出现在测试流中。实际上，通常存在许多开发、测试和其他预生产环境；例如，为了上线评分软件的新版本，调试预测或评估多个（“挑战者”）模型并行评分数据，以便评估改进模型的价值。现代基于云的技术通常可以在不增加太多成本和工作量的情况下提供这种灵活性。
- en: Manage
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理
- en: As models start to proliferate in the organization, a new role—that of the ML
    Ops engineer—emerges. Somebody must manage the model life cycle, including provenance,
    version control, approval, testing, deployment, and replacement. It also becomes
    apparent that models need to be managed in a central repository to enable approvals,
    electronic signatures, version control, tracking, and reuse.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型在组织中开始大量出现，一个新角色——ML Ops工程师——应运而生。必须有人来管理模型的生命周期，包括来源、版本控制、批准、测试、部署和替换。显然，需要将模型管理在一个中央库中，以便进行批准、电子签名、版本控制、跟踪和重复使用。
- en: The ML Ops Engineer
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML Ops工程师
- en: '*Do we need a dedicated engineer to better operationalize our models? Do we
    have somebody who is our ML Ops engineer without even knowing it?*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们是否需要一个专门的工程师来更好地实现我们的模型操作化？我们是否已经有人是我们的ML Ops工程师，甚至自己都不知道？*'
- en: It is necessary to organize the people and tasks involved in ML Ops. Even in
    small companies, a division of labor soon arises between those who create models
    and those who are responsible for operationalizing them. The skill sets diverge
    too much to be present in one person or team for very long. Thus, an ML Ops engineer
    is someone with enough knowledge of machine learning models to understand how
    to deploy them and with enough knowledge of operational systems to understand
    how to integrate, scale, and monitor models.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 需要组织涉及ML Ops的人员和任务。即使在小公司中，也很快形成了划分劳动力的情况，一部分人负责创建模型，另一部分人负责实现操作化。技能集过于分散，很难长时间由一个人或一个团队负责。因此，ML
    Ops工程师需要足够了解机器学习模型，以理解如何部署它们，并具有足够了解操作系统的知识，以理解如何集成、扩展和监视模型。
- en: '[Figure 2](#fig_2__the_role_of_the_ml_ops_engineer_through_the_enti) depicts
    the people and functions along the ML pipeline.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2](#fig_2__the_role_of_the_ml_ops_engineer_through_the_enti) 描述了沿着ML管道的人员和功能。'
- en: '![](Images/mlop_0102.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/mlop_0102.png)'
- en: Figure 2\. The role of the ML Ops engineer through the entire pipeline
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2. ML Ops工程师贯穿整个管道的角色
- en: The *data engineer* works on the databases to ensure that all the sources are
    available and to provide curated datasets to the rest of the analytics team. *Data
    scientists* explore the data, train, and build the predictive model. They then
    work with the *ML Ops engineer* to test the trained model on production data in
    a development or “sandbox” environment, after which the engineer takes that model
    and deploys it into production environments (e.g., first into pre-production,
    then into final production). Data scientists and ML Ops engineers both incorporate
    requirements and changes from *business users* (and often the risk manager) to
    understand what the model is meant to predict and what regulatory constraints
    are applicable. Those users provide guidance on what the model should predict,
    on how the model should be used, on whether the data scientists’ features make
    business sense and are allowable or not, and on which additional features could
    be added to the model. The *application designer* works with the data scientists
    to decide which models to use or build and how best to integrate the model so
    that it is useful to business users, and the *application developer* writes the
    code to weave the model into the application. The *DevOps team* smooths the transition
    from development to *IT operations*, which maintains the infrastructure and ensures
    that the application and its models run, perform, and scale optimally.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据工程师*负责数据库工作，确保所有数据源都可用，并向其余分析团队提供筛选后的数据集。*数据科学家*探索数据，训练和构建预测模型。然后他们与*ML
    Ops工程师*合作，在开发或“沙盒”环境中测试训练好的模型，并将模型部署到生产环境（例如，首先是预生产，然后是最终生产）。数据科学家和ML Ops工程师都会考虑*业务用户*（通常还包括风险管理人员）的需求和变更，以理解模型的预测目标及适用的监管约束条件。这些用户提供关于模型应该预测什么、模型如何使用、数据科学家的特征是否合理及是否允许等方面的指导，并提出哪些额外的特征可以添加到模型中。*应用设计师*与数据科学家合作决定使用或构建哪些模型，以及如何最好地将模型集成到对业务用户有用的应用程序中，而*应用程序开发人员*则编写代码将模型嵌入应用程序中。*DevOps团队*负责从开发到*IT运营*的顺畅过渡，维护基础架构，确保应用程序及其模型的运行、性能和优化扩展。'
- en: With one foot in data science and one foot in DevOps, the *ML Ops engineer*
    plays the newest role in the pipeline and an important one in the successful operationalization
    of ML models. The role bridges the aforementioned division of labor between data
    scientists and the people responsible for deploying, maintaining, and monitoring
    applications that use predictive models. With the data scientist, the ML Ops engineer
    tests and deploys models and sometimes implements monitoring. The role involves
    a combination of understanding ML models and data transformations, plus engineering
    (usually at the level of scripting).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*ML Ops工程师*既涉足数据科学，又涉足DevOps，在管道中扮演着最新的角色，并且是成功实现机器学习模型运营的重要角色之一。该角色桥接了数据科学家和负责部署、维护和监控使用预测模型的应用程序的人员之间的分工。与数据科学家一起，ML
    Ops工程师测试和部署模型，有时还实施监控。这个角色涉及理解ML模型和数据转换的结合，以及工程（通常在脚本编写的层面上）。'
- en: In the early stages of operationalizing ML, it is common for somebody to be
    the de facto ML Ops engineer without even knowing it. If there is no ML Ops engineer,
    then the app engineer must work with the data scientist. If the app engineer does
    not understand the underlying concepts, then this makes the process take much
    longer. Or you may have a data scientist with some computer science skills that
    steps in to do this, but that creates the opposite issue—data scientists writing
    production app code. Once the problem starts to scale, then you really need someone
    in the ML Ops role. Without having the appropriate team in place, the business
    will not be able to effectively respond and adapt to ever-changing conditions.
    Of course, dedicated ML Ops software solutions make this collaboration between
    roles and model deployment life-cycle processes increasingly more efficient and
    simpler.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习运营的早期阶段，很常见有人在事实上成为了ML Ops工程师，即使他们自己都没有意识到。如果没有ML Ops工程师，那么应用工程师必须与数据科学家合作。如果应用工程师不理解底层概念，这将使得整个过程变得更加耗时。或者你可能会有一位具备一定计算机科学技能的数据科学家介入处理，但这会带来相反的问题——数据科学家编写生产应用程序代码。一旦问题开始扩展，你确实需要一个ML
    Ops角色的人员。如果没有适当的团队，企业将无法有效地应对不断变化的情况。当然，专门的ML Ops软件解决方案使得角色之间的协作以及模型部署生命周期过程变得越来越高效和简单。
- en: Getting Out in Front of Model Proliferation
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提前应对模型扩散
- en: '*Where did all these models come from?*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*所有这些模型都是从哪里来的?*'
- en: In the same way that virtual machines, document files, and versions of source
    code proliferate, ML models and pipelines tend to accumulate fast and become difficult
    to track. Where once there were dozens, soon there are hundreds, perhaps thousands.
    In addition, there are often dependencies between models, for example, where a
    common model for customer segmentation is used in multiple prediction models.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 就像虚拟机、文档文件和源代码的版本不断增加一样，ML模型和流水线往往迅速积累，并变得难以跟踪。曾经有几十个模型，很快可能就会有数百个，甚至数千个。此外，模型之间通常存在依赖关系，例如，在多个预测模型中使用的客户细分共用模型。
- en: One factor in proliferation is the increased number of people along the ML pipeline.
    More people create and test more models and then store them somewhere afterward,
    even if not in production. Over time, it turns out that a growing percentage of
    those models address the same problem, but people working in isolation are unaware
    of one another’s efforts. Automation techniques (for example, Auto ML) make it
    easy to generate new models and variations of existing models.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种增加的一个因素是沿ML流水线增加的人数。更多的人创建和测试更多的模型，然后在某处存储它们，即使这些模型不在生产中。随着时间的推移，事实证明，这些模型中越来越多的百分比解决了相同的问题，但孤立工作的人不知道彼此的努力。自动化技术（例如Auto
    ML）使生成新模型和现有模型的变体变得容易。
- en: The result is a greater need to track, govern, and manage models across the
    organization.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是组织内对模型进行跟踪、治理和管理的需求增加。
- en: Auditing, Approvals, and Version Control
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审计、批准和版本控制
- en: '*Why do we need to track models?*'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*为什么我们需要跟踪模型?*'
- en: 'ML Ops becomes complicated by lack of clarity about the differences between
    model versions: the provenance and history of each model; how models relate to
    one another and to the data; how they change over time; and how they move from
    development to production.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ML运营由于缺乏有关模型版本差异、每个模型的来源和历史、模型与数据之间的关系、它们如何随时间变化以及它们如何从开发转移到生产的清晰度而变得复杂。
- en: Some form of model management system is therefore necessary to record model
    metadata in a structured form, in order to make it easier to monitor and report
    on changes from one version to the next, and automate processes (e.g., approvals,
    electronic signatures, re-training) around the metadata.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有必要使用某种形式的模型管理系统，以结构化方式记录模型元数据，以便更轻松地监控和报告从一个版本到下一个版本的变化，并自动化处理（例如审批、电子签名、重新训练）与元数据相关的流程。
- en: Like years of archived data, a large body of models—if well managed—can be an
    advantage in both governance and reporting. Consider a financial technology company
    that is using models to evaluate and score credit applications. Even though its
    models change over time, the company is always responsible for its approval process
    and must be able to report why a certain credit application was approved or denied.
    In case of an audit, it needs to demonstrate how it arrived at a score and why
    the score was below the threshold of acceptability.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 就像多年的归档数据一样，如果管理良好，大量模型可以在治理和报告方面带来优势。考虑一个金融科技公司，该公司使用模型评估和评分信贷申请。即使其模型随时间变化，公司始终负责其批准流程，并必须能够报告为何批准或拒绝某个特定信贷申请。在审计时，公司需要展示如何得出评分以及为何评分低于可接受阈值。
- en: The advantage of a large body of models is related to change management, whereby
    anybody on the ML pipeline can determine exactly who made which change at what
    time and for what reason. Change management is useful not only for compliance
    with outside regulations (like the approval process described before) but also
    for efficient collaboration, internal governance, and justifying changes to the
    model.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 大量模型的优势与变更管理相关，通过该管理，ML流水线上的任何人都可以准确确定是谁在什么时间做了哪些更改以及出于何种原因。变更管理不仅有助于遵守外部法规（如前述的批准流程），还有助于高效的合作、内部治理以及证明对模型的变更的正当性。
- en: The purpose of version control for models is to track the data and the parameters
    that were used to build each version, as well as the model outputs (e.g., coefficients,
    accuracy). That way, when reviewing the evolution of the model, there is clear
    provenance and a way to track how the model was produced.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 模型版本控制的目的是跟踪用于构建每个版本的数据和参数，以及模型输出（例如系数、准确性）。这样，当审查模型的演变时，就有清晰的来源和追踪模型生成方式的方法。
- en: Reusing and Repurposing Models from a Centrally Managed Repository
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从中央管理的存储库中重用和再利用模型
- en: '*How do we manage so many models coming from so many sources?*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们如何管理来自如此多来源的如此多模型？*'
- en: Centralization is useful in an organization where tens, hundreds, or even thousands
    of line-of-business or individual users work with advanced analytics.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要许多业务线或个人用户使用高级分析的组织中，集中化是非常有用的。
- en: The best way to centralize is to reuse and repurpose models from a centrally
    managed repository that allows multiple people to use a single, approved model
    for multiple applications. The repository tracks who is building which model and
    clarifies the number of existing versions. It sheds light on the progress of the
    data science team and the quantity of models it is building. It tracks connections
    between data and models and projects, and it is searchable—as different lines
    of business ask for advanced analytics on scenarios A and B, the repository makes
    it easier to see that A and B are two sides of the same issue. A suitable, tested
    model already exists in the repository, so reusing and repurposing it reduces
    the amount of duplicated effort and decongests the ML pipeline.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 集中化的最佳方式是重用和重新配置来自集中管理的存储库的模型，该存储库允许多人为多个应用程序使用单个已批准的模型。该存储库跟踪谁在构建哪个模型，并明确现有版本的数量。它揭示了数据科学团队的进展及其构建模型的数量。它跟踪数据与模型及项目之间的连接，并且是可搜索的——随着不同业务线要求关于场景A和B的高级分析，存储库使得更容易看到A和B是同一个问题的两个方面。存储库中已经存在适当的测试模型，因此重用和重新配置可以减少重复努力，并减少ML管道的拥堵。
- en: Companies still experimenting with ML may be able to handle model management
    with simple email messages. But once they exit the experimentation phase, their
    handful of models tends to burgeon, and control and reuse become an issue.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 仍在尝试ML技术的公司可能能够通过简单的电子邮件消息处理模型管理。但一旦他们退出实验阶段，他们手头的模型数量往往会急剧增加，控制和重复利用就成了问题。
- en: Deploy and Integrate
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署和集成
- en: 'In the Deploy and Integrate step, the model stops looking in the rearview mirror
    at historical data and looks through the windshield at live, real-world data.
    But to do that, the model must be integrated with one of the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署和集成步骤中，模型停止查看历史数据的后视镜，转而查看实时的现场数据。但要做到这一点，模型必须与以下之一集成：
- en: An execution endpoint somewhere, such as a database, where customer data is
    scored to help drive a marketing campaign
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 某个执行端点，如数据库，用于对客户数据进行评分，以帮助推动市场营销活动
- en: A website, to improve interaction with the user
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个网站，用于改善与用户的互动
- en: A device at the network edge, to make *in situ* predictions about machine condition
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边缘网络设备，用于对机器状态进行*原地*预测。
- en: An inline operational system with requirements for no downtime, and with single
    versions of models used across multiple scoring instances, or an AI/ML-infused
    BI dashboard, application, or report that allows stakeholders to translate model
    insights and predictions into decisions; to improve, optimize, or affect real-world
    operations
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内联操作系统，要求无停机时间，并且单个模型版本用于多个评分实例，或者AI/ML融入的BI仪表板、应用程序或报告，允许利益相关者将模型洞察和预测转化为决策；以改善、优化或影响现实世界的运作
- en: '*Why can’t we deploy without integrating, or integrate without deploying?*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*为什么不能单独部署，或者单独集成？*'
- en: 'Deploy and Integrate are closely intertwined: “Deployment” is the process of
    taking a model from the environment in which it is developed and turning it into
    an executable form (e.g., a code snippet, or an API) that can be used within an
    application or other external system. “Integration” is the process of taking that
    deployed model and embedding it within those external systems. Deployment options
    depend on the integration endpoints (targets), and those endpoints usually depend,
    in turn, on the deployment methods.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 部署和集成密切相关：“部署”是将模型从其开发环境中提取并转换为可执行形式（例如，代码片段或API）的过程，可以在应用程序或其他外部系统中使用。而“集成”是将已部署的模型嵌入到这些外部系统中的过程。部署选项取决于集成端点（目标），而这些端点通常又取决于部署方法。
- en: Thus, the best way to approach deployment is as a function of how the model
    will be integrated. And the best way to regard integration is as an extension
    of deployment.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最好的部署方法是将模型集成的功能作为其部署的一部分。而最好的集成方法是将其视为部署的延伸。
- en: Consider a credit card application process. Banks want to use some kind of predictive
    analytics to score an application as a good or bad credit risk. A bank may use
    a credit agency, whose data scientists build a predictive model in a tool that
    supports export to Predictive Model Markup Language (PMML). The credit agencies
    export their analytics to PMML or code and then integrate the model into a REST
    API available to the banks as a credit service through an integration. Again,
    modern cloud-based ML Ops tools and solutions will make deployment of models and
    their integration into REST APIs increasingly simple and efficient, requiring
    little or no actual coding.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个信用卡申请流程。银行希望使用某种预测分析来评分申请是否为良好或不良的信用风险。银行可能会使用信用机构，其数据科学家在支持导出到预测模型标记语言（PMML）的工具中构建预测模型。信用机构将他们的分析结果导出到
    PMML 或代码中，然后通过集成将模型作为信用服务的 REST API 提供给银行。再次强调，现代基于云的 ML Ops 工具和解决方案将使模型的部署和集成到
    REST API 变得越来越简单和高效，几乎不需要实际编码。
- en: To applicants, the integration is transparent, of course. They go to a bank
    or lender—maybe to an automated kiosk or website—enter their information, and
    request a loan or a credit line. The same model is applied through the same API
    regardless of integration endpoint, and creditworthiness is assessed consistently,
    with the same effectiveness and confidence.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于申请者来说，集成是透明的。当然，他们去银行或贷款人那里——也许是自动服务台或网站——输入他们的信息，并申请贷款或信用额度。无论集成端点如何，都通过同样的
    API 应用相同的模型进行评估信用价值，始终保持一致的效果和信心。
- en: Where Deploy and Integrate Meet
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署与集成的交集
- en: '*Which deployment methods and integration endpoints are the best match? Which
    combinations are not worth trying?*'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*哪种部署方法和集成端点最匹配？哪些组合不值得尝试？*'
- en: 'Each method of model deployment and integration carries its own set of special
    considerations:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 每种模型部署和集成方法都有其特殊考虑事项：
- en: Code Gen (e.g., Java, C++, Python, stored procedures)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 代码生成（例如，Java，C++，Python，存储过程）
- en: Here, the execution environment must support the language generated, performance
    requirements are crucial, and updates to models may need to be recompiled.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，执行环境必须支持生成的语言，性能要求至关重要，并且可能需要重新编译模型的更新。
- en: Serverless (e.g., function as a service)
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器（例如，作为服务的函数）
- en: Language support in FaaS must match the code required for model scoring. Also,
    because initiating serverless functions typically requires processing time on
    every call, requirements for scoring latencies and compute costs should be considered.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: FaaS 中的语言支持必须与模型评分所需的代码匹配。此外，由于启动无服务器函数通常需要每次调用的处理时间，因此应考虑评分延迟和计算成本的要求。
- en: Container (e.g., model inferencing within a Docker container)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 容器（例如，在 Docker 容器中进行模型推理）
- en: Here, a container is the artifact used for deployment—which is highly compatible
    with container orchestration systems used in modern IT environments. Note that
    “hot” redeployments (updating without restarting) of models so they remain identical
    across all containers can be a challenge and may require additional specialization
    for continuous deployment/continuous delivery (CI/CD).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，容器是用于部署的工件，高度兼容现代 IT 环境中使用的容器编排系统。请注意，“热”重新部署（无需重启更新）模型，以确保在所有容器中保持一致，可能是一个挑战，可能需要额外的专业知识来实现持续部署/持续交付（CI/CD）。
- en: Server
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器
- en: This method of deployment, using a centralized scoring server, requires one
    or more (often virtualized) servers for deployment. Flexible scalability and failover
    robustness must be specifically designed into the server-based system.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用集中式评分服务器的部署方法通常需要一个或多个（通常是虚拟化的）服务器。灵活的可伸缩性和故障转移的健壮性必须特别设计到基于服务器的系统中。
- en: Model interchange standards (e.g., model export format, PFA, PMML, ONNX, TensorFlow
    Saved Model)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 模型交换标准（例如，模型导出格式，PFA，PMML，ONNX，TensorFlow Saved Model）
- en: The execution environment must support running the interchange artifact. This
    method usually requires separate steps to transform and prepare the data. A serialized
    file representing a model is convenient for supporting no-downtime “hot” redeployments
    and ensuring consistent updates of models across multiple scoring servers or containers.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 执行环境必须支持运行交换工件。通常，这种方法需要单独的步骤来转换和准备数据。代表模型的序列化文件对支持无停机“热”重新部署和确保跨多个评分服务器或容器的模型一致更新非常方便。
- en: 'For the integration endpoints, the following options are generally available:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对于集成端点，通常有以下选项：
- en: Batch
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理
- en: Scoring many rows of data at a time, often on a schedule, often in a database.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 通常在计划中批量对多行数据进行评分，通常在数据库中进行。
- en: Interactive App
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 交互应用
- en: Execution of a model typically via API to drive the behavior of an end-user
    application.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 通过API执行模型，通常驱动最终用户应用程序的行为。
- en: Realtime Streaming
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 实时流
- en: Scoring of one row from a continuous stream of data, usually for making predictions
    at high frequencies.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对一连串数据流中的一行进行评分，通常用于高频率预测。
- en: Edge
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘
- en: Execution of a model to drive the behavior of a connected device.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 执行模型以驱动连接设备的行为。
- en: '[Table 1](#Table_1) summarizes the authors’ recommendations on considerations
    for the most common integration endpoints and the methods for deploying to them.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 1](#Table_1) 总结了作者对最常见集成端点和部署方法的考虑建议。'
- en: Table 1\. Recommendations and considerations for the most common execution endpoints
    and methods for deploying to them
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. 最常见执行端点和部署方法的建议和考虑。
- en: '| INTEGRATION ENDPOINTS | DEPLOYMENT METHODS |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 集成端点 | 部署方法 |'
- en: '| --- | --- |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Code gen | Serverless | Container | Server | Model interchange standards
    |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 代码生成 | 无服务器 | 容器 | 服务器 | 模型互操作标准 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '|  |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| Batch | Very high data volume scoring jobs, typically nightly or scheduled
    jobs | *N/A* | Can leverage elastic scale and automatic provisioning, and high-availability
    | Traditional Server-based architecture, scheduling of repetitive scoring “jobs”
    | Convenient when in-database scoring not efficient or possible, and interchange
    format scoring application/server is available |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 批处理 | 非常高数据量评分作业，通常是每夜或定期作业 | *不适用* | 可利用弹性规模和自动配置，以及高可用性 | 传统的基于服务器的架构，重复评分“作业”的调度
    | 当数据库中评分效率不高或不可行时，以及应用程序/服务器可用的交换格式评分时，非常方便。'
- en: '| Interactive app | Transaction systems and end-user applications with moderately
    high performance requirements | Small number of lightweight models that may be
    used infrequently | Many models in diverse formats as managed/cloud-scalable services.
    | Many models as enterprise-scalabe services. | Local execution of scoring is
    desired, but maintaining generated source code is not. |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 交互应用 | 具有适度高性能要求的交易系统和最终用户应用程序 | 可能偶尔使用的少量轻量级模型 | 多种格式的许多模型作为托管/云可扩展服务。 |
    多个模型作为企业可扩展服务。 | 期望本地执行评分，但不维护生成的源代码。 |'
- en: '| Real-time streaming | Extremely high throughput proessing requirements; can
    ensure no-downtime updates to models | *Not common because of initial-start and
    thus latency concerns* | Applicable for medium- to low-latency use cases, e.g.,
    best-next-action and e-commerce | *If latency-of-response is sufficient, can support
    no-downtime updates to models* | Good for “hot” no-downtime redeployments |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 实时流 | 非常高的吞吐处理要求；可以确保模型无停机更新 | *由于初始启动和延迟问题，不常见* | 适用于中低延迟用例，例如最佳下一步行动和电子商务
    | *如果响应延迟足够，可以支持模型无停机更新* | 适合“热”无停机重新部署 |'
- en: '| Edge | Lightweight models that may be required to operate offline | Many
    devices calling few models | Many models in diverse formats and many devices |
    Internal network devices | May be optimal if interchange format is supported on
    device OS |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 边缘 | 可能需要离线运行的轻量级模型 | 多设备调用少量模型 | 多种格式的多个模型和多个设备 | 内部网络设备 | 如果设备操作系统支持交换格式，则可能是最佳选择。
    |'
- en: In some cases, in addition to deploying the machine learning model, it is necessary
    to integrate and embed the models into multiple business applications.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，除了部署机器学习模型外，还需要将模型集成和嵌入到多个业务应用程序中。
- en: Business App Development
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 业务应用开发
- en: '*How do we combine the efforts of ML Ops and our application developers?*'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们如何结合ML Ops和应用开发人员的努力？*'
- en: The goal of Deploy and Integrate is that the predictive model has some sort
    of impact on the way business is done. The most effective way of doing that is
    to embed it directly into business applications. Examples include embedding product
    recommendations into an e-commerce site or mobile application, suggesting solutions
    in a CRM system, and routing assignments intelligently in an ERP system.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 部署和集成的目标是预测模型对业务进行某种影响。最有效的方法是将其直接嵌入到业务应用程序中。例如，将产品推荐嵌入到电子商务网站或移动应用程序中，建议CRM系统中的解决方案，以及在ERP系统中智能路由分配。
- en: That means application engineers need to consider how to fit ML Ops into the
    software development life cycle. It isn’t just another feature that needs to be
    considered during design, development, and testing. It may fundamentally change
    the nature of deployment.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 应用工程师需要考虑如何将 ML Ops 融入软件开发生命周期。这不仅仅是设计、开发和测试过程中需要考虑的另一个特性。它可能会从根本上改变部署的性质。
- en: The ideal approach to business app development is to entirely decouple machine
    learning models from the application, by providing them as a service—a set of
    APIs that developers can discover, test, and incorporate into their code. Data
    scientists must then provide comprehensive documentation: how the models are to
    be used, required inputs and expected outputs, their limitations or realms of
    applicability, levels of accuracy and confidence, and data dependencies. They
    should also provide well-defined mechanisms for recording how the models perform
    over time.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 企业应用开发的理想方法是通过提供服务的方式完全将机器学习模型与应用程序解耦，即一组开发人员可以发现、测试和整合到其代码中的 API。然后，数据科学家必须提供全面的文档：如何使用模型、所需的输入和预期的输出、模型的限制或适用领域、准确度和信心水平以及数据依赖关系。他们还应提供明确定义的机制来记录模型随时间的表现。
- en: Even if models are called as a service, the data scientists cannot simply “throw
    models over the wall” and walk away. Application engineers and data scientists
    will need to collaborate closely when iterating on model development and refinement.
    Each group involved in business app development will provide feedback to the other,
    ideally through a shared collaborative platform. For example, the application
    engineers may not have the same level of access to data and will need to change
    the model requirements. Performance considerations may change as the application
    handles more load. The engineers may even have suggestions about new features
    to include in the model.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 即使模型被称为服务，数据科学家也不能简单地“把模型扔过墙”，然后走开。在模型开发和精炼迭代过程中，应用工程师和数据科学家需要密切合作。业务应用开发中的每个参与者将向另一个提供反馈，理想情况下通过共享协作平台。例如，应用工程师可能无法获得与数据相同的访问级别，需要调整模型的需求。随着应用程序处理更多负载，性能考虑可能会发生变化。工程师甚至可能对要包含在模型中的新功能提出建议。
- en: As noted earlier, the structure of a model and its data requirements may need
    to change with little notice. As market conditions change, a model may become
    dangerously inaccurate, or even obsolete. So developers need to build in safeguards
    that allow models to be swapped or disabled without requiring a new version of
    the application. And that means they need to monitor the model over time, as we
    discuss in the next section.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，模型的结构和数据要求可能需要在短时间内进行变更。随着市场条件的变化，模型可能会变得极不准确甚至过时。因此，开发人员需要建立防护措施，使模型可以在不需要新版本应用的情况下进行更换或禁用。这意味着他们需要随时间监控模型，正如我们在下一节讨论的那样。
- en: Monitor
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: 'The Monitor step starts once the models have been deployed. It covers three
    types of metrics: statistical, performance, and business/ROI. Also, because models
    need updating to remain fresh and useful, the Monitor step includes the tasks
    of automatic retraining and remodeling.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型部署完成，监控步骤就开始了。它涵盖了三种类型的指标：统计、性能和业务/ROI。此外，因为模型需要更新以保持新鲜和有用，监控步骤还包括自动重新训练和重建的任务。
- en: Statistical Metrics
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统计指标
- en: '*How accurate is the model now that it is running on real-world data? How do
    we set a threshold and configure alerts when the model becomes inaccurate? How
    exactly do we measure accuracy on new or real-time data?*'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型在运行实际数据时的准确度如何？我们如何设置阈值并配置在模型变得不准确时触发警报？我们如何精确地测量新或实时数据的准确度？*'
- en: Operationalizing data science and ML includes ongoing monitoring. It extends
    to continuously reviewing the model, retraining it when necessary, and comparing
    new “challenger” models to what has already been deployed. Statistical metrics
    compare accuracy now to accuracy when the model was first deployed or most recently
    updated. The term “model drift” applies to the change in accuracy over time (discussed
    later).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学和机器学习的运作包括持续监控。这延伸到持续审查模型，必要时重新训练模型，并将新的“挑战者”模型与已部署的模型进行比较。统计指标比较了现在的准确度与模型首次部署或最近更新时的准确度。术语“模型漂移”指的是随时间变化的准确度变化（稍后讨论）。
- en: 'There are three parts to statistical metrics:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 统计指标有三个部分：
- en: '*Accuracy tracking* covers metrics like misclassification rate, confidence
    rate, or the error rates deemed most important to the data scientists. When accuracy
    falls below a given threshold, it’s time to retrain the model, or remodel altogether.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '*准确性跟踪*涵盖了诸如错误分类率、置信率或数据科学家认为最重要的错误率等指标。当准确性低于给定的阈值时，是时候重新训练模型或完全重建模型了。'
- en: '*Champion–challenger*is the practice of continually looking for a better model
    (challenger) than the one already in production (champion). It consists of periodically
    running either an updated version of the current model or a different model completely
    and then comparing the results between the two and deploying the more accurate
    one.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*冠军挑战者*是不断寻找比当前生产中的模型（冠军）更好的模型（挑战者）的做法。它包括定期运行当前模型的更新版本或完全不同的模型，然后比较两者的结果，并部署更准确的那个。'
- en: '*Population stability* ensures that current models are still relevant by constantly
    checking the distribution of datasets over time for reasonable consistency. Consider
    a model for home mortgage applications. Even the most accurate model deployed
    in the spring of 2008 would have been overcome by events and real-world market
    conditions later in the year. With so much change in the population, running the
    model on end-of-year data would yield significantly different results from running
    it when the model was trained.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*人口稳定性*通过持续检查数据集随时间分布的合理一致性来确保当前模型仍然相关。考虑一个家庭抵押贷款申请模型。即使在2008年春季部署的最准确的模型，在后来的事件和现实市场条件中也会被超越。随着人口变化如此之大，使用年底数据运行模型将产生与训练模型时显著不同的结果。'
- en: Performance Metrics
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绩效指标
- en: '*Is our infrastructure adequate to support our models?*'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们的基础设施是否足以支持我们的模型？*'
- en: Models run only as well as resources permit. Performance metrics include input/output,
    execution time, and number of records scored per second, plus the factors they
    depend on, such as memory and CPU usage. Such metrics are increasingly available
    in many dedicated ML Ops solutions.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 模型只有在资源允许的情况下才能运行良好。性能指标包括输入/输出、执行时间和每秒评分记录数，以及它们依赖的因素，如内存和CPU使用率。这些指标在许多专门的ML
    Ops解决方案中日益可用。
- en: Business Metrics and ROI
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 业务指标和投资回报率
- en: '*If the dashboards are showing that the model’s error rate is low, then why
    aren’t we seeing the increase in margins that we were hoping for?*'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果仪表板显示模型的错误率很低，那么为什么我们没有看到我们希望看到的利润增长？*'
- en: Business metrics determine the desired impact of the model on the business and
    serve as an important check on statistical metrics. When a new model is deployed,
    those business metrics are often the most important ones to monitor. How are these
    metrics defined and monitored? How do they interact with basic measures of model
    accuracy?
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 业务指标确定模型对业务的期望影响，并作为对统计指标的重要检查。当部署新模型时，这些业务指标通常是最重要的监控指标。这些指标如何定义和监测？它们如何与模型准确性的基本衡量标准互动？
- en: Consider a model for predicting the people most likely to purchase a given product.
    Even when the most likely purchasers are not buying, it is conceivable that the
    model could be performing correctly, given the variables that went into it. As
    another example, digital media and social network companies look at things like
    click-through rates and engagement metrics.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个预测购买特定产品的最有可能的人群的模型。即使最有可能购买的人没有购买，考虑到输入的变量，可以想象该模型可能是正确的。例如，数字媒体和社交网络公司关注点击率和参与度等因素。
- en: When statistical and business metrics do align, however, it is an indicator
    of return on investment in the operationalization of ML models. Take a company
    whose statistical metrics show that its advanced analytics model is contributing
    to *x* percent conversion of sales leads. Through champion–challenger it deploys
    a model that is more accurate and results in *2x* percent conversion of sales
    leads. The company can point to the improvement as solid ROI on its efforts with
    advanced analytics.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当统计和业务指标确实对齐时，这表明在运营化ML模型的投资回报率指标。以一个公司为例，其统计指标显示其先进分析模型为销售线索转化率贡献了*x*百分比。通过冠军挑战者，它部署了一个更准确的模型，导致销售线索转化率提高了*2x*百分比。公司可以指出这一改进是其先进分析工作的稳固投资回报率。
- en: As the life of the model continues, acceptance and rejection data is obtained
    from each sales offer and stored, along with the offer details, in a relational
    database. In time, that causes the model to be automatically retrained and promoted
    to production, with attendant internal approvals. The process can be scheduled
    with user-defined intervals (daily, weekly, etc.). It can be activated by events,
    like a drop in the conversion rate or log-loss ratio below a given threshold,
    or by the accumulation of offer data.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型的使用，每次销售提议都会获取接受和拒绝数据，并将其与提议详细信息一起存储在关系数据库中。随着时间的推移，这使得模型可以自动重新训练并提升到生产环境，并获得相应的内部批准。该过程可以按用户定义的间隔（每日、每周等）进行调度。它可以由事件触发，例如转化率下降或日志损失率低于给定阈值，或通过提议数据的累积来激活。
- en: When Models Drift
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型漂移时
- en: '*Why aren’t the predictions accurate anymore? Is the model drifting?*'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '*为什么预测不再准确？模型在漂移吗？*'
- en: With traditional software systems, IT puts components in place and then occasionally
    checks that the API is working correctly or that the system is up and running
    end to end. Models, on the other hand, are dynamic. They require constant monitoring
    and updating to counteract model drift, a phenomenon that occurs after deployment,
    when the model’s predictions become less and less accurate. Drift arises as the
    real-world variables in the model change over time—they change in their distribution,
    they change in their relationship to each other, they change because of new variables
    that weren’t present or significant in the original model.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统软件系统中，IT部门部署组件，然后偶尔检查API是否正常工作或系统是否完全运行。而模型则是动态的。它们需要不断监控和更新，以抵消模型漂移，这种现象在部署后会出现，模型的预测变得越来越不准确。漂移是由于模型中的实际变量随时间变化而产生的——它们在分布上发生变化，它们在彼此之间的关系发生变化，或者是因为原始模型中不存在或不显著的新变量而发生变化。
- en: For example, in a model that predicts sales of a soft drink, summer temperatures
    may be unusually low and therefore beyond the range that worked in the model;
    customers may become more sensitive to price during an economic downturn that
    doesn’t match the historical conditions used for model training; or a new advertising
    campaign may have been launched. If the model’s predictions used to be 80 percent
    accurate and now they are 75 percent accurate and falling, then model drift may
    be at work.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在预测某款软饮的销售模型中，夏季温度可能异常偏低，因此超出了模型中有效的范围；经济衰退期间，顾客可能变得更加价格敏感，而这种情况并不符合模型训练所使用的历史条件；或者可能推出了新的广告活动。如果模型的预测曾经是80%的准确率，而现在是75%并且持续下降，那么可能是模型漂移在起作用。
- en: The error rate begins to creep up, so data scientists examine underlying data
    distributions to understand what has changed. And when a model is generating predictions
    that effectively cost the business money because of inaccuracy, this activity
    is as important as the original development of the model.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 错误率开始逐渐上升，因此数据科学家们会检查基础数据分布，以了解发生了什么变化。当一个模型由于不准确而导致企业损失时，这种活动和模型的原始开发同样重要。
- en: Retraining and Remodeling
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新训练和重新建模
- en: '*The business is complaining that the predictions don’t make sense. How do
    we get the model back on track?*'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '*业务部门抱怨预测不合理。我们如何让模型恢复正轨？*'
- en: Most of the time, the solution to model drift is to retrain (or “recalibrate”)
    the models on the most recent data. Occasionally, it is necessary to remodel altogether.
    As shown in [Figure 3](#fig_4__model_drift), a model is retrained in October and
    January, and accuracy and precision rise sharply. But following retraining in
    March, accuracy and precision decrease, indicating that it is time to remodel.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，应对模型漂移的解决方案是根据最新数据重新训练（或“重新校准”）模型。偶尔，需要彻底重新建模。如图3所示（参见 [Figure 3](#fig_4__model_drift)），模型在10月和1月重新训练后，准确性和精度显著提高。但在3月重新训练后，准确性和精度下降，表明是时候重新建模了。
- en: '![](Images/mlop_0104.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![模型漂移](Images/mlop_0104.png)'
- en: Figure 3\. Model drift
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3. 模型漂移
- en: Retraining involves the same variables and model structure applied when the
    model was first developed, but it uses fresher data. A model may predict, for
    example, that sales volume is some multiple of price, plus some multiple of temperature,
    plus some multiple of the previous week’s sales. Those multiples may change over
    time, so retraining the model by running it against current data will produce
    new multiples. The variables themselves do not change.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 重新训练使用的是模型首次开发时应用的相同变量和模型结构，但使用了更新的数据。例如，模型可能预测销售量是价格的某个倍数，加上温度的某个倍数，再加上上周销售量的某个倍数。这些倍数可能随时间变化，因此通过对当前数据运行模型进行重新训练将产生新的倍数。变量本身不会改变。
- en: Remodeling, however, involves adding, changing, or deleting variables and is
    usually more work than retraining. In the previous example, suppose the business
    realized that it had neglected to factor a competitor’s pricing into its model
    and that the competitor was quickly capturing market share. To offset that effect,
    the data scientists would remodel to add the competitor’s pricing as a variable
    then test against current data.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 重建涉及添加、更改或删除变量，通常比重新训练更加复杂。在前面的例子中，假设业务意识到忽略了竞争对手的定价因素，并且竞争对手快速占据市场份额。为抵消这种影响，数据科学家将通过重建来添加竞争对手的定价作为变量，然后针对当前数据进行测试。
- en: 'When a model is retrained and promoted to production, several steps ensue:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型重新训练并投入生产时，会经历几个步骤：
- en: Model accuracy assessment
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 模型准确度评估
- en: This step is based on a set of Gini coefficients (a common model accuracy metric).
    If outside allowable limits, models are reevaluated automatically using a genetic
    algorithm for searching the parameter space. Candidate models are regularized
    with Elastic Net to decrease the variance (at the cost of introducing some bias).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤基于一组基尼系数（常见的模型准确度指标）。如果超出允许的限制，模型将使用遗传算法自动重新评估参数空间。候选模型使用弹性网进行正则化以减少方差（但引入一些偏差）。
- en: Model updates and explainability
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 模型更新和可解释性
- en: This includes assessment of business goals, variable importance, over-fit, bias
    or outliers, and regulatory perspectives. Segments and factors summarizing the
    differential model attributes (current versus prior model) are evaluated in a
    champion–challenger setting. Questions about the effects on customers are assessed.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括评估业务目标、变量重要性、过度拟合、偏差或异常值，以及监管角度。在冠军-挑战者设置中评估总结差异模型属性（当前与之前模型）。评估对客户影响的问题。
- en: Model diagnostics
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 模型诊断
- en: Assessment of local predictive power and accuracy across the predictor space
    is a consideration. Particular regions of the predictor space may be assessed
    in accordance with recent trends, and areas of concern can be identified. Statistical
    hypothesis test results are assessed, along with model diagnostic metrics such
    as Akaike information criterion (AIC), Bayesian information criterion (BIC), area
    under the ROC curve (AUROC), and visualizations (ROC curves, lift charts).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 根据预测空间中的本地预测能力和准确性进行考虑。可以根据最近的趋势评估预测空间的特定区域，并确定关注的领域。评估统计假设检验结果，以及模型诊断指标，如赤池信息准则（AIC）、贝叶斯信息准则（BIC）、ROC曲线下面积（AUROC）和可视化（ROC曲线、提升图）。
- en: Model versioning, approval, and audit
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 模型版本管理、批准和审计
- en: In most cases, models need to be retrained on fresh data to account for variance
    in market conditions since the previous model training. As such, several versions
    of the models need to be saved and governed (per regulatory requirements). The
    models should also be available for auditing and compliance assessments.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，模型需要根据市场条件的变化重新训练，因此需要保存并管理多个模型版本（根据监管要求）。这些模型也应可用于审计和合规评估。
- en: The team needs to decide whether retraining or remodeling is appropriate and
    what the triggers should be.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 团队需要决定何时进行重新训练或重建，并确定触发条件。
- en: Monitoring Meets Automation
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控与自动化相结合
- en: '*Why do we need to do this manually? Can’t retraining take place automatically?*'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '*为什么我们需要手动进行此操作？难道重新训练不能自动进行吗？*'
- en: Although a human ultimately approves redeployment at the end of the monitoring
    step, it makes sense to automate model retraining instead of waiting for a human
    to inspect a dashboard, detect model drift, and manually launch the retraining.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最终是人类在监控步骤结束时批准再部署，但自动化模型重新训练是有意义的，而不是等待人类检查仪表板、检测模型漂移并手动启动重新训练。
- en: Suitably advanced tools should conduct frequent champion–challenger loops that
    retrain with the most recent data and possibly with different features. The automation
    would compare the accuracy of each retrained model against the currently deployed
    model. Upon finding a better model, the automation would trigger an alert to the
    data scientists. Also, as described earlier in “Feature Engineering,” iterating
    between event stream updates and historical accumulation results in a better-fitting
    feature set and model.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 适当先进的工具应进行频繁的冠军挑战循环，使用最新数据和可能不同的特征进行重新训练。自动化将比较每个重新训练模型与当前部署模型的准确性。一旦找到更好的模型，自动化将触发警报给数据科学家。此外，正如在“特征工程”中早先描述的那样，在事件流更新和历史累积之间迭代可以得到更合适的特征集和模型。
- en: 'Case Study: Operationalizing Data Science in the Manufacturing Industry—Digital
    Twin Models'
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究：在制造业中实现数据科学——数字孪生模型
- en: Leaders in high-tech manufacturing industries are increasingly turning to digital
    twins. These virtual representations of physical systems help manufacturers better
    manage assets to improve performance, efficiency, and quality of operations. But
    those improvements can only be realized once the digital twins are embedded into
    business operations with model operations (aka ML Ops).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 高科技制造业的领导者越来越多地转向数字孪生。这些物理系统的虚拟表征帮助制造商更好地管理资产，以提高性能、效率和运营质量。但只有将数字孪生模型与模型运营（也称为ML
    Ops）结合到业务运营中，这些改进才能得以实现。
- en: In the semiconductor manufacturing industry, the processes that produce integrated
    circuits (chips) are growing more complex. There can be thousands of processing
    steps, thousands of pieces of equipment, hundreds of equipment types, and millions
    of measurements taken during the course of the manufacturing process.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在半导体制造业中，用于生产集成电路（芯片）的过程变得越来越复杂。在制造过程中可能涉及数千个加工步骤，数千台设备，数百种设备类型，并且可能会进行数百万次测量。
- en: To manage this complexity, digital twin models are becoming the key to efficient
    operations and high product yields. Developing and operationalizing these models
    can help modern fabricators not only to overcome complex manufacturing challenges
    but also to address intricate scheduling and transporting of material.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 为了管理这种复杂性，数字孪生模型正成为高效运营和高产品产量的关键。开发和操作化这些模型可以帮助现代制造商不仅克服复杂的制造挑战，还可以解决复杂的材料调度和运输问题。
- en: One semiconductor manufacturer did just that, turning to data science and model
    operations to develop and train digital twin models to deal with the petabytes
    of data generated daily by sensors in its manufacturing process. This company’s
    business requirements were no longer satisfied by traditional, knowledge-driven
    analysis, which resulted in lost opportunity, suboptimal product yield, and lowered
    revenue. To remain competitive, this manufacturer needed to operationalize digital
    twin models to help them understand, control, and optimize all processes (and
    their resulting quality, efficiency, and yield).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一家半导体制造商正是这样做的，转向数据科学和模型运营来开发和训练数字孪生模型，以处理其制造过程中每天传感器生成的数据量级。该公司的业务需求不再满足传统的、知识驱动的分析，这导致了机会的损失、产品产量的次优和收入的降低。为了保持竞争力，这家制造商需要将数字孪生模型操作化，帮助他们理解、控制和优化所有过程（以及由此产生的质量、效率和产量）。
- en: Previously, the company’s engineers had to manually compare defect and electrical
    patterns one wafer at a time. After adopting digital twin models, they found that
    clustering of wafers with similar defects and identifying the relationships through
    electrical tests could be completely automated. Using a combination of visual
    analytics and data science, the time needed to detect and understand defects decreased
    from 12 hours to less than one minute per day. Data-driven insights also now enable
    rapid remediation of issues detected in the upstream process, before those issues
    can cause costly quality or yield problems.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在以前，公司的工程师不得不逐片比较缺陷和电子图案。采用数字孪生模型后，他们发现可以完全自动化地对具有相似缺陷的晶圆进行聚类，并通过电气测试识别它们之间的关系。利用视觉分析和数据科学的组合，检测和理解缺陷所需的时间从每天12小时减少到不到一分钟。数据驱动的洞察力现在也能够快速解决上游过程中检测到的问题，以避免这些问题导致昂贵的质量或产量问题。
- en: Analysis and modeling now take less than five minutes per run. With near real-time
    results, the manufacturer can now identify subtle equipment changes, process shift
    or drift in certain tools, and remedy substandard yield for a batch moving through
    the factory. None of this could have been possible without model operations, which
    ensured that the digital twin models went into production and enacted real business
    change.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每次运行分析和建模的时间不到五分钟。凭借几乎实时的结果，制造商现在能够识别工厂中经过的批次中微妙的设备变化、工具的工艺转变或漂移，并解决批次中的不合格产量问题。没有模型操作的支持，数字孪生模型进入生产并实施真正的业务变革是不可能的。
- en: 'Case Study: Operationalizing Data Science in the Insurance Industry—Dynamic
    Pricing Models'
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究：在保险业中实施数据科学——动态定价模型
- en: Companies that still use traditional dynamic pricing software are struggling
    to compete in today’s digital economy. These black-box point solutions leave little
    room to react to market trends and regulations, or even keep up with the increasing
    volume and complexity of data. The insurance industry especially has started to
    move away from these outdated solutions.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的数字经济中，仍然使用传统动态定价软件的公司正在苦苦挣扎。这些黑箱式的点解决方案几乎没有空间来应对市场趋势和法规的变化，甚至无法跟上日益增长的数据量和复杂性。特别是保险业已开始摒弃这些过时的解决方案。
- en: In insurance, the goal is to acquire and retain customers with the highest potential
    lifetime value while covering underwriting costs, handling demand for coverage,
    and dealing with unexpected external factors such as natural disasters. A dynamic
    pricing strategy, in which a business sets prices for services based on market
    demands and other factors, helps insurers adjust price based on potential risks,
    customers’ willingness to pay, competitor pricing, and other variables. Artificial
    intelligence (AI)–fueled dynamic pricing models, put into production using model
    operations, can ensure that insurers are able to quickly react to market changes
    and stay competitive.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在保险业中，目标是获取和保留具有最高潜在终身价值的客户，同时覆盖核保成本，处理保障需求，并应对自然灾害等意外外部因素。动态定价策略使企业能够根据市场需求和其他因素为服务设定价格，帮助保险公司根据潜在风险、客户付款意愿、竞争对手定价和其他变量调整价格。通过模型操作投入生产的人工智能驱动的动态定价模型，可以确保保险公司能够快速应对市场变化，保持竞争力。
- en: TIBCO developed and deployed a dynamic pricing system for the auto insurance
    unit of a large client using model operations. This pricing model solution included
    configurations for price optimization and customer acquisition and retention.
    It also showcased price elasticity data and modeling of acceptance as a function
    of price.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: TIBCO使用模型操作为一家大型客户的汽车保险部门开发并部署了动态定价系统。该定价模型解决方案包括价格优化和客户获取与保留的配置。它还展示了价格弹性数据以及作为价格函数的接受建模。
- en: Before the company operationalized data science, it had used the same market-dominant
    analytics software for many years. It took new data scientists a year or so before
    they learned how to use that software and could begin retraining existing models
    and generating new ones.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在公司实施数据科学之前，多年来一直使用同一市场主导的分析软件。新的数据科学家在学会使用该软件并开始重新训练现有模型并生成新模型之前需要一年左右的时间。
- en: But since implementing the new dynamic pricing system with model operations,
    the company can hire data scientists with no coding or math background, and within
    three months, they are able to release models and therefore generate revenue.
    They have at their disposal the computational power to run models for fraud identification
    and embedded customer value.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 自实施新的模型操作动态定价系统以来，公司可以雇佣没有编程或数学背景的数据科学家，他们在三个月内就能发布模型并因此生成收入。他们拥有计算能力来运行用于欺诈识别和嵌入式客户价值的模型。
- en: Users within the company are empowered and connected across departments now.
    In the case of a sudden rise or drop in sales, for instance, business users would
    normally approach IT and ask them to look into it, with no idea how long it would
    take to get a useful answer. Now, those same users can simply click on relevant
    metrics and run a model that sheds light on the change in sales volume. If business
    users want to dive into the data or perform predictive analysis, they have the
    opportunity.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，公司内部用户能够跨部门联通和赋能。例如，如果销售量突然上升或下降，业务用户通常会向IT部门寻求帮助，不知道获取有用答案需要多长时间。现在，这些用户可以简单地点击相关指标并运行模型，阐明销售量变化的原因。如果业务用户想深入数据或进行预测分析，他们都有这个机会。
- en: The company can update its dynamic pricing models in live environments, resulting
    in real-time predictability and informed decision-making. Data goes out to models
    almost as soon as it comes in. Rather than generating simple predictions, the
    company is able to answer questions like “If we increase or decrease discounts,
    what is the effect on volume and profitability?” More importantly, the company
    can ask questions about what to do differently, how to change pricing, and where
    in the organization to make changes. This is just one example of how operationalizing
    data science and machine learning models with model operations can bring real
    value to an organization.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 公司可以在实时环境中更新其动态定价模型，从而实现实时预测和知情决策。数据进入模型后几乎立即可用。公司不再仅生成简单的预测，而是能够回答类似于“如果我们增加或减少折扣，对销量和利润率的影响是什么？”等问题。更重要的是，公司可以询问如何做出不同的决策、如何调整定价以及在组织中哪里进行变更。这只是通过模型运营将数据科学和机器学习模型操作化，为组织带来实际价值的一个示例。
- en: Conclusion
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The sequence of Build, Manage, Deploy and Integrate, and Monitor introduces
    structure and logical flow around analytics pipelines, and allows the organization
    to realize the value of data science through ML Ops. It ensures that the best
    model gets embedded into a business system, that the deployed models are consistent
    with business requirements as well as constraints imposed by company policies
    or regulatory oversight, and that the model remains current.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 通过“构建、管理、部署和集成”以及监控的顺序，引入结构化和逻辑流程围绕分析管道，并使组织通过 ML Ops 实现数据科学的价值。这确保最佳模型被嵌入到业务系统中，部署的模型符合业务需求以及公司政策或监管监督所施加的限制，并且保持模型的当前性。
- en: Companies that build this kind of methodical thinking into their data science
    have a big competitive advantage over those that consistently fail to operationalize
    models and that fail to prioritize action over mere insight. These organizations
    can move beyond building models in isolation to operationalizing data science
    for all applicable business-critical processes, with confidence and with clear
    visibility into associated risks, costs, and benefits.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 那些将这种系统化思维融入到他们的数据科学中的公司，比那些一直未能将模型操作化并将行动优先于简单洞察的公司具有更大的竞争优势。这些组织能够超越孤立建模，为所有适用的业务关键流程实现数据科学的操作化，且具备信心和对相关风险、成本和效益的清晰可见性。
- en: About the Authors
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作者简介
- en: '**David Sweenor**, global analytics marketing leader at TIBCO, is responsible
    for the GTM strategy for the advanced analytics portfolio. He has over 20 years
    of hands-on business analytics experience, spanning product marketing, business
    strategy, product development, IoT, advanced analytics, data warehousing, and
    manufacturing. Prior to TIBCO, David served in a variety of roles, including solutions
    consultant for SAS, IBM, Quest, and Dell. David holds a BS in applied physics
    from Rensselaer Polytechnic Institute and an MBA from the University of Vermont.
    Find David on Twitter @DavidSweenor, and [LinkedIn](https://www.linkedin.com/in/davidsweenor).'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '**David Sweenor**，TIBCO 全球分析营销领导者，负责先进分析产品组合的市场推广战略。他拥有超过 20 年的实际业务分析经验，涵盖产品营销、业务战略、产品开发、物联网、先进分析、数据仓库和制造业。在加入
    TIBCO 之前，David 曾在多个公司担任解决方案顾问，包括 SAS、IBM、Quest 和 Dell。David 拥有美国伦斯勒理工学院的应用物理学学士学位和佛蒙特大学的工商管理硕士学位。关注
    David 的 Twitter 账号 @DavidSweenor 和 [LinkedIn](https://www.linkedin.com/in/davidsweenor)。'
- en: '**Steven Hillion**, senior director of data science at TIBCO, has been leading
    large engineering and analytics projects for 20 years. He founded Alpine Data,
    acquired by TIBCO, to build a collaborative platform for data science. He led
    the global team of data scientists at Pivotal and developed a suite of open source
    and enterprise software in machine learning. Before that, he led engineering at
    a series of start-ups. He received his PhD in mathematics from the University
    of California, Berkeley, and before that read mathematics at Oxford University.
    Find Steven on [LinkedIn](https://www.linkedin.com/in/shillion).'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '**Steven Hillion**，TIBCO的高级数据科学总监，领导大型工程和分析项目已有20年。他创办了Alpine Data，该公司被TIBCO收购，致力于建立一个数据科学的协作平台。他领导了Pivotal的全球数据科学团队，并开发了一套开源和企业软件的机器学习工具。在此之前，他曾在一系列初创公司领导工程工作。他在加州大学伯克利分校获得数学博士学位，并在此之前在牛津大学学习数学。在[LinkedIn](https://www.linkedin.com/in/shillion)上找到Steven。'
- en: '**Dan Rope** is a senior director of data science at TIBCO. Two decades after
    leading development and bringing to market the first software implementation of
    the Grammar of Graphics, Dan has been implementer, architect, and technical leader
    of a wide variety of forward-looking data science and visualization products.
    Dan was a chief architect of IBM’s earliest commercially available automated machine
    learning product and cocreator of IBM’s language agnostic visualization platform.
    At TIBCO, Dan continues driving key product innovations including AI for Business
    Intelligence, Machine Learning for Edge devices, and Auto ML and ML Ops for TIBCO’s
    big data platform. Dan is a coinventor on several patents and an open source contributor.
    He has served as chair and program chair of the Statistical Graphics section of
    the American Statistical Association. Find Dan on [LinkedIn](https://www.linkedin.com/in/dan-rope-4951517).'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dan Rope**是TIBCO的高级数据科学总监。在开发和推出第一个语法图形软件实现两十年后，Dan成为了各种前瞻性数据科学和可视化产品的实施者、架构师和技术领导者。Dan是IBM最早商业化的自动化机器学习产品的首席架构师和IBM语言不可知可视化平台的共同创造者。在TIBCO，Dan继续推动关键产品创新，包括面向商业智能的AI、边缘设备的机器学习、以及TIBCO大数据平台的Auto
    ML和ML Ops。Dan是多项专利的共同发明人和开源贡献者，曾担任美国统计协会统计图形部门的主席和程序主席。在[LinkedIn](https://www.linkedin.com/in/dan-rope-4951517)上找到Dan。'
- en: '**Dev Kannabiran** is a data scientist with TIBCO. He holds a master’s degree
    in management information systems from Oklahoma State University and has experience
    in the application of predictive modeling and model operationalization. Dev has
    been involved with numerous data science deployment projects across various industries,
    including insurance, manufacturing, and financial services. Dev has authored technical
    blogs and run multiple webinars on the topics of AI, ML and text analytics. Find
    Dev on [LinkedIn](https://www.linkedin.com/in/dev-kannabiran-5613503).'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dev Kannabiran**是TIBCO的数据科学家。他拥有俄克拉荷马州立大学管理信息系统硕士学位，并在预测建模和模型运行方面积累了丰富经验。Dev参与了多个跨行业的数据科学部署项目，包括保险、制造和金融服务领域。他撰写了技术博客，并举办了多场关于人工智能、机器学习和文本分析的网络研讨会。在[LinkedIn](https://www.linkedin.com/in/dev-kannabiran-5613503)上找到Dev。'
- en: '**Thomas Hill** is a senior director and product manager for data science products
    at TIBCO. He was the cofounder of StatSoft Inc., where he was responsible for
    building out the Statistica software into a leading analytics platform before
    it was acquired by TIBCO. Dr. Hill has published widely on innovative applications
    for predictive analytics and has coauthored numerous papers, books, and patents
    related to human learning and cognition, machine learning, statistics, and analytics.
    Find Tom on Twitter @DrTomHill and [LinkedIn](https://www.linkedin.com/in/DrThomasHill).'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '**Thomas Hill**是TIBCO数据科学产品的高级总监和产品经理。他是StatSoft Inc.的联合创始人，在该公司被TIBCO收购前负责将Statistica软件打造成领先的分析平台。Hill博士广泛发表了关于预测分析创新应用的文章，并共同撰写了许多与人类学习与认知、机器学习、统计学和分析相关的论文、书籍和专利。在Twitter上@DrTomHill和[LinkedIn](https://www.linkedin.com/in/DrThomasHill)上找到Tom。'
- en: '**Michael O’Connell** is the chief analytics officer at TIBCO, developing analytic
    solutions across a number of industries including financial services; energy;
    life sciences; consumer goods and retail; and telco, media and networks. He has
    been working on statistical software applications for the past 20 years, and has
    published more than 50 papers and several software packages on statistical methods.
    Michael did his PhD work in statistics at North Carolina State University, where
    he is an adjunct professor of statistics. Find Michael on Twitter @MichOConnell
    and [LinkedIn](https://www.linkedin.com/in/michaelo15).'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**迈克尔·奥康奈尔** 是TIBCO的首席分析官，负责在金融服务、能源、生命科学、消费品和零售业、电信、媒体和网络等多个行业开发分析解决方案。他在统计软件应用领域有超过20年的工作经验，发表了50多篇论文，并开发了多个统计方法软件包。迈克尔在北卡罗来纳州立大学获得统计学博士学位，并担任该校的兼职教授。在Twitter上关注迈克尔的账号是@MichOConnell，在[LinkedIn](https://www.linkedin.com/in/michaelo15)上可以找到他。'
- en: '[ML Ops: Operationalizing Data Science](ch01.xhtml#ml_ops_operationalizing_data_science)'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ML Ops：数据科学的运营化](ch01.xhtml#ml_ops_operationalizing_data_science)'
- en: '[An Introduction to ML Ops and Operationalizing Data Science Models](ch01.xhtml#an_introduction_to_ml_ops_and_operationalizing_dat)'
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ML Ops和数据科学模型运营化简介](ch01.xhtml#an_introduction_to_ml_ops_and_operationalizing_dat)'
- en: '[What Is ML Ops?](ch01.xhtml#what_is_ml_ops)'
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ML Ops是什么？](ch01.xhtml#what_is_ml_ops)'
- en: '[The ML Ops Pain Point: Time to Deployment](ch01.xhtml#the_ml_ops_pain_point_time_to_deployment)'
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ML Ops的痛点：部署时间](ch01.xhtml#the_ml_ops_pain_point_time_to_deployment)'
- en: '[What, Really, Is a Model?](ch01.xhtml#what_really_is_a_model)'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[什么才是真正的模型？](ch01.xhtml#what_really_is_a_model)'
- en: '[Introducing the Four-Step ML Ops Approach](ch01.xhtml#introducing_the_four_step_ml_ops_approach)'
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[介绍四步骤的ML Ops方法](ch01.xhtml#introducing_the_four_step_ml_ops_approach)'
- en: '[Build](ch01.xhtml#build_idpZjZhv)'
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[构建](ch01.xhtml#build_idpZjZhv)'
- en: '[Data Considerations: Structures and Access](ch01.xhtml#data_considerations_structures_and_access)'
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[数据考虑：结构和访问](ch01.xhtml#data_considerations_structures_and_access)'
- en: '[Feature Engineering](ch01.xhtml#feature_engineering)'
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[特征工程](ch01.xhtml#feature_engineering)'
- en: '[Model Testing](ch01.xhtml#model_testing)'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[模型测试](ch01.xhtml#model_testing)'
- en: '[Manage](ch01.xhtml#manage_id6abxO3)'
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[管理](ch01.xhtml#manage_id6abxO3)'
- en: '[The ML Ops Engineer](ch01.xhtml#the_ml_ops_engineer)'
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ML Ops工程师](ch01.xhtml#the_ml_ops_engineer)'
- en: '[Getting Out in Front of Model Proliferation](ch01.xhtml#getting_out_in_front_of_model_proliferation)'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[应对模型扩展的挑战](ch01.xhtml#getting_out_in_front_of_model_proliferation)'
- en: '[Auditing, Approvals, and Version Control](ch01.xhtml#auditing_approvals_and_version_control)'
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[审核、批准和版本控制](ch01.xhtml#auditing_approvals_and_version_control)'
- en: '[Reusing and Repurposing Models from a Centrally Managed Repository](ch01.xhtml#reusing_and_repurposing_models_from_a_centrally_ma)'
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[从集中管理的存储库重用和重新利用模型](ch01.xhtml#reusing_and_repurposing_models_from_a_centrally_ma)'
- en: '[Deploy and Integrate](ch01.xhtml#deploy_integrate)'
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[部署与集成](ch01.xhtml#deploy_integrate)'
- en: '[Where Deploy and Integrate Meet](ch01.xhtml#where_deploy_and_integrate_meet)'
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[部署与集成的交汇点](ch01.xhtml#where_deploy_and_integrate_meet)'
- en: '[Business App Development](ch01.xhtml#business_app_development)'
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[业务应用开发](ch01.xhtml#business_app_development)'
- en: '[Monitor](ch01.xhtml#monitor_id4zn3C9)'
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[监控](ch01.xhtml#monitor_id4zn3C9)'
- en: '[Statistical Metrics](ch01.xhtml#statistical_metrics)'
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[统计指标](ch01.xhtml#statistical_metrics)'
- en: '[Performance Metrics](ch01.xhtml#performance_metrics)'
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[性能指标](ch01.xhtml#performance_metrics)'
- en: '[Business Metrics and ROI](ch01.xhtml#business_metrics_and_roi)'
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[业务指标和投资回报率](ch01.xhtml#business_metrics_and_roi)'
- en: '[When Models Drift](ch01.xhtml#when_models_drift)'
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[当模型漂移时](ch01.xhtml#when_models_drift)'
- en: '[Retraining and Remodeling](ch01.xhtml#retraining_and_remodeling)'
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[重新训练和重建](ch01.xhtml#retraining_and_remodeling)'
- en: '[Monitoring Meets Automation](ch01.xhtml#monitoring_meets_automation)'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[监控与自动化的结合](ch01.xhtml#monitoring_meets_automation)'
- en: '[Case Study: Operationalizing Data Science in the Manufacturing Industry—Digital
    Twin Models](ch01.xhtml#case_study_operationalizing_data_science_in_the_m)'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[案例研究：在制造业中实现数据科学的运营—数字孪生模型](ch01.xhtml#case_study_operationalizing_data_science_in_the_m)'
- en: '[Case Study: Operationalizing Data Science in the Insurance Industry—Dynamic
    Pricing Models](ch01.xhtml#case_study_operationalizing_data_science_in_the_i)'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[案例研究：在保险业中实现数据科学的运营—动态定价模型](ch01.xhtml#case_study_operationalizing_data_science_in_the_i)'
- en: '[Conclusion](ch01.xhtml#conclusion)'
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[结论](ch01.xhtml#conclusion)'
