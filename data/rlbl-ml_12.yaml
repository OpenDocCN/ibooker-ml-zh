- en: Chapter 11\. Incident Response
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章。事故响应
- en: 'In this world, sometimes bad things happen, even to good data and systems.
    Disks fail. Files get corrupted. Machines break. Networks go down. API calls return
    errors. Data gets stuck or changes subtly. Models that were once accurate and
    representative models become less so. The world can also change around us: things
    that never, or almost never, previously happened can become commonplace; this
    itself has an impact on our models.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个世界上，有时候坏事情会发生，即使是对良好的数据和系统也是如此。磁盘故障。文件损坏。机器损坏。网络中断。API调用返回错误。数据卡住或轻微变化。曾经准确代表模型的模型变得不那么准确。世界也可能在我们周围改变：以前几乎从未发生的事情可能变得司空见惯；这本身对我们的模型产生影响。
- en: 'Much of this book is about building ML systems that prevent these things from
    happening, or when they happen—and they will—recognizing the situation correctly
    and mitigating it. Specifically, this chapter is about how to respond when bad,
    urgent things happen to ML systems. You may already be familiar with how teams
    handle systems going down or otherwise having a problem: this is known as *incident
    management*, and best practices exist for managing incidents that are common across
    lots of computer systems.^([1](ch11.xhtml#ch01fn122))'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的大部分内容涉及构建能够预防这些问题发生的机器学习系统，或者在这些问题发生时——而它们确实会发生——正确识别情况并加以缓解。具体而言，本章讨论了在机器学习系统遇到坏事情并需要紧急响应时的应对方法。你可能已经熟悉团队如何处理系统宕机或出现问题的情况：这被称为*事故管理*，并且有关管理这些事故的最佳实践在许多计算机系统中都是通用的^([1](ch11.xhtml#ch01fn122))。
- en: We cover these generally applicable practices, but our focus is on how to manage
    outages for ML systems, and in particular how those outages and their management
    differ from other distributed computing system outages.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了这些通用的实践方法，但我们的重点是如何管理机器学习系统的故障，并特别关注这些故障及其管理与其他分布式计算系统的不同之处。
- en: The main thing to remember is that ML systems have attributes that make resolving
    their incidents potentially very different from the incidents of non-ML production
    systems. The most important attribute in this context is their strong connection
    to real-world situations and user behavior. This means that we can see unintuitive
    effects where there is a disconnect among the ML system, the world, or the user
    behavior we are trying to model. We cover this in detail later, but the major
    thing to understand now is that troubleshooting ML incidents can involve very
    much more of the organization than standard production incidents do, including
    finance, supplier and vendor management, PR, legal, and so on. ML incident resolution
    is not necessarily something that only engineering does.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的一点是，机器学习系统具有使其故障处理可能与非机器学习生产系统的故障处理截然不同的特性。在这种情况下最重要的特性是它们与真实世界情况和用户行为的紧密联系。这意味着我们可能会看到不直观的效果，例如ML系统、世界或我们试图建模的用户行为之间的不一致。我们稍后会详细讨论这一点，但现在需要理解的主要事情是，解决机器学习事故可能需要组织的更多参与，远超标准生产事故的工程部门，包括财务、供应商和供应商管理、公关、法律等。ML事故的解决不一定只是工程部门的事情。
- en: A final serious point we would like to make here at the beginning is that, as
    with other aspects of ML systems, incident management has serious implications
    for ethics in general and very commonly for privacy. It is a mistake to focus
    on getting the system working first and worry about privacy afterward. Do not
    lose sight of this critical part of our work in this section. Privacy and ethics
    will make an appearance in several parts of the chapter and are addressed directly
    toward the end because by then we will be in a better place to draw some clear
    conclusions about how ML ethics principles interact with incident management.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个严肃的观点是，在此开篇，我们想要表明的是，和机器学习系统的其他方面一样，事故管理对伦理有着严重的影响，并且很常见地涉及到隐私问题。将重点放在先让系统工作，然后担心隐私，这是一个错误。在本节中，不要忽视我们工作的这一关键部分。隐私和伦理问题会在本章的几个部分中显现，并且朝着章节结束直接讨论，因为到那时我们将能够更清晰地得出一些关于机器学习伦理原则如何与事故管理互动的结论。
- en: Incident Management Basics
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事故管理基础知识
- en: Three basic concepts for successful incident management are *knowing the state
    the incident is in*, *establishing the roles*, and *recording information for
    follow-up*. Many incidents are prolonged because of failures to identify what
    state the incident is in, and who is responsible for managing which aspects of
    it. If this continues for long enough, you have an *unmanaged incident*, which
    is the worst kind of incident.^([2](ch11.xhtml#ch01fn123))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 成功的事故管理的三个基本概念是*了解事故所处的状态*，*确定角色*，以及*记录信息以便后续跟进*。许多事故因未能识别事故所处状态和谁负责管理其各个方面而拖延。如果这种情况持续足够长的时间，你就会有一个*未管理的事故*，这是最糟糕的事故类型。^([2](ch11.xhtml#ch01fn123))
- en: 'Indeed, if you’ve worked with incidents for long enough, you’ve probably seen
    one already, and it probably starts something like this: an engineer becomes aware
    of a problem; they troubleshoot the problem alone, hoping to figure out the cause;
    they fail to assess the impact of the problem on end users; and they don’t communicate
    the state of the problem, either to other members of their team or the rest of
    the organization. The troubleshooting itself is typically disorganized and characterized
    by delays between actions, and assessing what happened after the actions. Once
    the initial troubleshooters realize the scope of the incident, even more delays
    may arise while they try to figure out which other teams need to be involved and
    send pages or alerts to track them down. If the problem continues indefinitely,
    other parts of the organization can notice that something is wrong and independently
    (sometimes counterproductively) take uncoordinated steps to resolve the problem.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，如果你处理事故的时间足够长，你可能已经见过这样的事故，并且它可能是这样开始的：一个工程师意识到有问题；他们独自排除问题，希望找出原因；他们未能评估问题对最终用户的影响；他们也未向团队其他成员或组织其余部分沟通问题的状态。排除问题本身通常是杂乱无章的，并且在行动之间存在延迟，以及在行动后评估发生的情况。一旦初始排查者意识到事故的范围，他们可能会遇到更多延迟，因为他们试图弄清楚需要协助的其他团队，并发送页面或警报以跟踪它们。如果问题无限期持续下去，组织的其他部门可能会注意到问题存在，并独立（有时是适得其反地）采取不协调的步骤来解决问题。
- en: The key idea here is to actually have a process—a well-rehearsed one—and to
    apply it reliably and methodically when something bad that’s happened is worthy
    of being called an incident. Of course, creating a managed incident has a cost,
    and formalizing communications, behavior, and follow-up incurs overhead. So we
    don’t do it for everything; not every `WARNING` in our logs warrants a couple
    of hours of meetings or phone calls. Being an effective on-call engineer requires
    developing a sense for what is serious and what isn’t, and smoothly engaging incident
    machinery when required. It is enormously helpful to have clearly defined guidelines
    ahead of time about when to declare an incident, how to manage it, and how to
    follow up after it.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 关键思想在于实际上有一个过程——一个经过充分演练的过程——在发生值得称为事故的不良事件时可靠而系统地应用它。当然，创建一个管理良好的事故是有成本的，正式化沟通、行为和后续行动会增加开销。所以我们并不是每一个在日志中的`WARNING`都需要几个小时的会议或电话。成为一名有效的值班工程师需要发展出对什么是严重问题和什么不是的感觉，并在需要时平稳地启动事故处理机制。提前明确定义关于何时宣布事故、如何管理它以及事后如何跟进的指南是极其有帮助的。
- en: Life of an Incident
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事故的生命周期
- en: 'Incidents have distinct phases of their existence. Although people of good
    will may differ on the specifics, incidents probably include states such as the
    following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 事故在其存在中有明显的各个阶段。尽管有良好意愿的人可能在具体细节上有分歧，但事故可能包括以下状态：
- en: Pre-incident
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 事前事故
- en: Architectural and structural decisions that set the conditions for the outage.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 导致中断的架构和结构决策。
- en: Trigger
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 触发
- en: Something happens to create the user-facing impact.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 发生某些事情导致用户端影响。
- en: Outage begins
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 中断开始
- en: Our service is affected in a noticeable way by at least some users for at least
    some functions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的服务受到至少一些用户在至少一些功能上的显著影响。
- en: Detection
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 检测
- en: The owners of the service become aware of the problem, either through automated
    monitoring notifying us or outside users complaining.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 服务的所有者通过自动化监控通知我们或外部用户投诉而意识到问题的存在。
- en: Troubleshooting
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 故障排除
- en: We try to figure out what is going on and devise a means of fixing the problem.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们试图找出问题的原因并设计修复问题的方法。
- en: Mitigation
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解
- en: We identify the fastest and least risky steps to prevent at least the worst
    of the problems. This can range from something as mild as posting a notice that
    some things don’t work right all the way to completely disabling our service.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确定最快和最少风险的步骤，以至少防止问题中最严重的情况发生。这可能从发布一则通知表明某些事情不正常工作，一直到完全禁用我们的服务。
- en: Resolution
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: We fix the underlying problem and the service returns to normal.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解决了根本问题，服务恢复正常。
- en: Follow-up
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 后续
- en: We conduct a retrospective, learn what we can about the outage, identify a series
    of things we’d like to fix or other actions we would like to take, and then carry
    those out.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行回顾，了解关于中断的所有信息，确定我们希望修复的一系列问题或其他要采取的行动，然后实施这些行动。
- en: Computer system outages can roughly be described by these phases. We’ll briefly
    cover the roles in a typical incident and then will try to understand what differs
    in handling an ML incident.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机系统的中断大致可由以下阶段描述。我们将简要介绍典型事件中的角色，然后尝试理解处理ML事件的不同之处。
- en: Incident Response Roles
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件响应角色
- en: Some companies have thousands of engineers working on systems infrastructure,
    and others might be lucky to have a single person. But whether your organization
    is large or small, the roles described in this section need to be filled.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一些公司有成千上万的工程师从事系统基础设施工作，而其他公司可能只有一名幸运儿。但无论您的组织规模是大还是小，本节描述的角色都需要填补。
- en: 'It’s important to note that not all of the roles must be filled by a separate
    person, since not all of the responsibilities are equally urgent, and not all
    incidents demand isolated focus. Also, your organization and your team has a particular
    size—not every team can fill every position directly. Furthermore, certain problems
    emerge only at scale: communication costs, in particular, tend to increase in
    larger organizations, often correlated with the complexity of infrastructure under
    management. Conversely, smaller engineering teams can suffer from tunnel vision
    and a lack of diversity of experience. Nothing in our guidance frees you of the
    necessity of adapting to the situation, and making the right choices—often by
    first making the wrong ones. But one critical fact is that you must plan ahead
    for the organizational capacity to properly support incident management duties.
    If they are a poorly staffed afterthought or you assume anyone can jump in when
    incidents occur with no structure, training, or spare time, the results can be
    quite bad.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，并非所有角色必须由不同的人填补，因为并非所有责任同等紧急，也不是所有事件都需要孤立的关注。此外，您的组织和团队有特定的规模，不是每个团队都能直接填补每个职位。此外，某些问题只在规模上产生：尤其是与管理的基础设施复杂性相关的沟通成本往往会在较大的组织中增加。相反，较小的工程团队可能会受到狭隘视野和经验多样性不足的困扰。我们的指导并不意味着您无需适应情况，以及做出正确选择——通常是首先做出错误选择。但有一个关键事实是，您必须提前计划好组织能力，以妥善支持事件管理职责。如果它们是人员招募不足的事后想法，或者您假设任何人都可以在没有结构、培训或空闲时间的情况下参与事件处理，结果可能会很糟糕。
- en: 'The framework we are most familiar with for incident management derives from
    the US Federal Emergency Management Agency (FEMA) [National Incident Management
    System](https://oreil.ly/pFkaa). In this framework, the minimum viable set of
    roles is typically as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最熟悉的事件管理框架源自美国联邦应急管理局（FEMA）[国家事件管理系统](https://oreil.ly/pFkaa)。在此框架中，典型的最小可行角色集通常如下：
- en: Incident commander
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 事件指挥官
- en: A coordinator who has a clear understanding, at a high level, of the incident
    as a whole, and is responsible for assigning and monitoring the other roles.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一位具有整体高层次了解事件的协调员，负责分配和监控其他角色。
- en: Communications lead
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通讯负责人
- en: Responsible for outbound and inbound communication. The actual responsibilities
    for this role differ significantly based on the system but may include updating
    public documents for end users, contacting other internal services groups and
    asking for help, or answering queries from customer-facing support personnel.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 负责出站和入站通讯。根据系统不同，此角色的实际职责差异显著，可能包括更新面向最终用户的公共文档，联系其他内部服务团队寻求帮助，或回答面向客户支持人员的查询。
- en: Operations lead
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 运维负责人
- en: Approves, schedules, and records all production changes related to the outage
    (including stopping previously scheduled production changes on the same systems
    even if unrelated to the outage).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 批准、安排并记录与中断相关的所有生产变更（包括停止先前计划的与中断无关的同一系统的生产变更）。
- en: Planning lead
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 计划负责人
- en: Keeps track of longer-term items that should not be lost but do not impact immediate
    outage resolution. This includes recording work items to be fixed, storing logs
    to be analyzed, and scheduling time to review the incident in the future. (Where
    applicable, the planning lead should also order dinner for the team.)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 记录那些不应丢失但不影响即时故障解决的长期项目。这包括记录待修复的工作项目、存储待分析的日志以及安排未来审查事故的时间。（如适用，规划负责人还应为团队订晚餐。）
- en: 'These roles are invariant, whether or not you are dealing with an ML incident.
    The things that *do* vary are listed here:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些角色是不变的，无论您是否处理机器学习事故。以下是*变化*的内容：
- en: Detection
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 检测
- en: ML systems are less deterministic than non-ML systems. As a result, it is harder
    to write monitoring rules to catch all incidents before a human user detects them.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 与非机器学习系统相比，机器学习系统的确定性较低。因此，编写监控规则以在人类用户之前捕捉所有事故变得更加困难。
- en: Roles and systems involved in resolution
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 参与解决方案的角色和系统
- en: ML incidents usually involve a broader range of staff during troubleshooting
    and resolution, including business/product and management/leadership. ML systems
    have a broad impact on multiple systems, and are generally built on and fed by
    multiple complex systems. This leads to a likely diverse set of stakeholders for
    any incident. ML outages often impact multiple systems because of their role in
    integrating with and modifying other parts of your infrastructure.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习事故通常在故障排除和解决过程中涉及更广泛的员工，包括业务/产品和管理/领导层。机器学习系统对多个系统产生广泛影响，并且通常建立在多个复杂系统之上并由其供给。这导致任何事故都可能涉及多样化的利益相关者。由于其在集成和修改基础设施的角色，机器学习故障通常会影响多个系统。
- en: Unclear timeline/resolution
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 时间轴/解决方案不清晰
- en: Many ML incidents involve impact to quality metrics that themselves already
    vary over time. This makes the timeline of the incident and the resolution more
    difficult to specify precisely.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习事故会影响到已经随时间变化的质量指标。这使得事故和解决方案的时间轴更难以精确指定。
- en: To develop a more intuitive and concrete understanding of why these differences
    show up in this context, let’s consider a few example outages of ML systems.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对为何在这种情境中出现这些差异有更直观和具体的理解，让我们考虑一些机器学习系统中的实际故障案例。
- en: Anatomy of an ML-Centric Outage
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中心故障的解剖
- en: These examples are drawn from real experiences by the authors but do *not* correspond
    to individual, specific examples that we have participated in. Nonetheless, our
    hope is that many people with experience running ML systems will see familiar
    characteristics in at least one of these examples.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例是作者根据真实经验绘制的，但并*不*对应于我们参与过的具体案例。尽管如此，我们希望许多有经验运行机器学习系统的人能在至少一个这些示例中看到熟悉的特征。
- en: 'As you read through them, play close attention to some of the following characteristics
    that may differ substantially from other kinds of outages:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当您阅读它们时，请特别注意以下一些可能与其他类型的故障大不相同的特征：
- en: Architecture and underlying conditions
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 架构和基础条件
- en: What decisions did we make about the system before this point that could have
    played a role in the incident?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前我们对系统做出了哪些决定，这些决定可能在事故中发挥了作用？
- en: Impact start
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 影响开始
- en: How do we determine the start of the incident?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何确定事故的开始？
- en: Detection
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 检测
- en: How easy is it to detect the incident? How do we do it?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 检测事故有多容易？我们如何做到？
- en: Troubleshooting and investigation
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 故障排除和调查
- en: Who is involved? What roles do they play in our organization?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 谁参与其中？他们在我们组织中扮演什么角色？
- en: Impact
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 影响
- en: What is the “cost” of the outage to our users? How do we measure that?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们的用户来说，故障的“成本”是多少？我们如何衡量它？
- en: Resolution
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: How confident are we in the resolution?
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对解决方案的信心有多大？
- en: Follow-up
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 后续处理
- en: Can we distinguish between fixing and improving? How do we know when the follow-up
    from the incident is done and prospective engineering is taking place?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能区分修复和改进吗？我们如何知道从事故的后续处理结束并进行前瞻性工程？
- en: Keep these questions in mind while you consider the stories presented later
    in this chapter.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在您考虑本章后面呈现的故事时，请牢记以下问题。
- en: 'Terminology Reminder: Model'
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语提醒：模型
- en: 'In [Chapter 3](ch03.xhtml#basic_introduction_to_models), we introduced distinctions
    among the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](ch03.xhtml#basic_introduction_to_models)中，我们介绍了以下几点的区别：
- en: Model architecture
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 模型架构
- en: The general approach to learning
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 学习的一般方法
- en: Model (or configured model)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模型（或配置模型）
- en: The specific configuration of an individual model plus the learning environment,
    and the structure of the data we will train on
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特定模型的具体配置，以及我们将在其上进行训练的学习环境和数据结构
- en: Trained model
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型
- en: A specific instance of one configured model trained on one set of data at a
    point in time
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个时间点上，针对一个配置的模型训练的特定实例
- en: This distinction matters particularly because we often care about which of these
    has changed, to possibly be implicated in an incident. We will try to be clear
    in the following sections which we’re referring to.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是这种区别很重要，因为我们经常关心哪些因素发生了变化，可能涉及到事故。在以下各节中，我们将尽量明确我们所指的是哪一个。
- en: Story Time
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讲述时间
- en: We tell the following stories within the framework of our invented firm, YarnIt,
    in order to help them resonate with you. But they are all based on, or at least
    inspired by, real events that we’ve observed in production. In some cases, they
    are based on a single outage at a single time, and in others they are composites.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在我们虚构的公司YarnIt框架内讲述以下故事，以便让它们与您产生共鸣。但它们都是基于或至少受到我们在生产中观察到的真实事件的启发。在某些情况下，它们基于某个特定时间的单个故障，而在其他情况下，它们则是组合的。
- en: 'Story 1: Searching but Not Finding'
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故事1：搜索但未找到
- en: One of the main ML models that YarnIt uses is a search ranking model. Like most
    web stores, customers come to the site and click links offered to them on the
    front page, but they also search directly for the products they’re looking for.
    To generate those search results, we first filter our product database for all
    of the products that roughly match the words that the customer is looking for,
    and then rank them with an ML model that tries to predict how to order those results,
    given everything we know about the search at the time it’s performed.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: YarnIt使用的主要ML模型之一是搜索排名模型。像大多数网络商店一样，顾客会访问网站并点击首页提供的链接，但他们也直接搜索他们正在寻找的产品。为了生成这些搜索结果，我们首先过滤我们的产品数据库，以找到粗略匹配顾客搜索词的所有产品，然后使用ML模型对这些结果进行排序，试图预测如何在搜索时根据我们了解的一切对它们进行排序。
- en: Ariel, a production engineer who works on search system reliability, is working
    on the backlog of monitoring ideas. One of the things the search team has been
    wishing it monitored and trended over time is the rate that a user clicks one
    of the first five links in a search result. The team members hypothesize that
    that might be a good way to see whether the ranking system is working optimally.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Ariel，一位从事搜索系统可靠性工作的生产工程师，正在处理监控想法的积压。搜索团队希望监控和趋势化的一项指标是用户在搜索结果的前五个链接中点击的速率。团队成员假设这可能是查看排名系统是否运行最佳的好方法之一。
- en: Ariel looks through the available logs and determines an approach for exposing
    the resulting metric. After doing a week-on-week report for the past 12 weeks
    to make sure that the numbers look reasonable, Ariel finds some initially promising
    results. From 12 weeks ago to 3 weeks ago, Ariel sees that the top five links
    are clicked by customers around 62% of the time. Of course, that could be better,
    but a substantial majority of the time we’re finding *something* that the users
    are curious about within the first few results.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Ariel查看了可用的日志，并确定了公开生成指标的方法。在对过去12周进行了逐周报告以确保数字看起来合理后，Ariel发现了一些最初令人鼓舞的结果。从12周前到3周前，Ariel看到顾客大约62%的时间内会点击前五个链接。当然，这可以更好，但我们在大多数时间内仍然在前几个结果中找到*某些*用户感兴趣的内容。
- en: 'Three weeks ago, however, the click rate on the first five links started going
    down. In fact, this week it’s only 54%, and Ariel notes that it appears to still
    be dropping. That’s a huge drop in a very short period of time. Ariel suspects
    that the new dashboard is flawed and asks the search reliability team to take
    a look. Instead, the team confirms: the data looks correct, and those numbers
    are really concerning!'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，三周前，前五个链接的点击率开始下降。事实上，本周只有54%，而Ariel注意到它似乎仍在下降。这在很短的时间内是一个巨大的下降。Ariel怀疑新仪表盘存在缺陷，并要求搜索可靠性团队进行查看。然而，团队确认：数据看起来正确，这些数字确实令人担忧！
- en: Note
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Detection has occurred.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 检测已发生。
- en: 'Ariel declares an incident and notifies the search model team since it might
    be a problem with the model. Ariel also notifies the retail team, just to check
    that we’re not suddenly making less money from customers who are searching for
    products (as opposed to browsing for them) and also asks the team to check for
    recent changes to the website that would change the way results are rendered.
    Ariel then digs into the infrastructure for the search reliability team itself:
    what has changed on its end? Ariel finds—and the search model team confirms—that
    no changes have been made to the model configuration in the past two months. There
    have also been no big changes in the data or accompanying metadata used by the
    model—just the normal addition of customer activity to the logs.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Ariel 宣布了一次紧急事件，并通知了搜索模型团队，因为可能是模型出了问题。Ariel 也通知了零售团队，只是为了确认我们并非突然在从搜索产品的顾客那里少赚钱（而不是简单地浏览产品），并要求团队检查网站最近是否有更改，这些更改可能会影响搜索结果的呈现方式。然后，Ariel
    探究了搜索可靠性团队自身的基础设施：他们那边有什么变动？Ariel 发现——并且搜索模型团队确认——在过去两个月内，并没有对模型配置进行任何更改。数据或模型使用的相关元数据也没有发生大的变动——只是正常地将顾客活动添加到日志中。
- en: 'Instead, one of the search model team members notes something interesting:
    they use a *golden set* of queries to test new models daily, and they’ve noticed
    that in the past three weeks the golden set is producing incredibly consistent
    results—consistent enough to be suspicious. The search model is normally updated
    daily by retraining the same model on searches and resulting clicks from the previous
    day. This helps keep the model updated with new preferences and new products.
    It also tends to produce a little instability in the results from the golden set
    of queries, though that instability is normally within reasonable bounds. But
    starting three weeks ago, *those* results became remarkably stable.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，搜索模型团队的一位成员注意到了一些有趣的事情：他们每天使用一个*黄金查询集*来测试新模型，并注意到在过去三周里，这个黄金查询集产生了极其一致的结果——足够引起怀疑。搜索模型通常通过重新训练前一天搜索和点击结果的模型来每日更新。这有助于保持模型对新偏好和新产品的更新。这也倾向于在黄金查询集的结果中产生一些不稳定性，尽管这种不稳定性通常在合理范围内。但是从三周前开始，*这些*结果变得异常稳定起来。
- en: 'Ariel goes to look at the trained model deployed in production. *It’s three
    weeks old, and has not been updated since that point.* This explains the stability
    of the golden queries. It also explains the drop-off in user click behavior: we’re
    probably showing fewer good results on new preferences and new products. Indefinitely,
    of course—if we keep the same, stale model, we’ll eventually be unable to correctly
    recommend anything new. So Ariel looks at the search model training system, which
    schedules the search model training every night. It has not completed a training
    run in over three weeks, which would definitely explain why there isn’t a new
    trained model in production.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Ariel 前往查看已部署到生产环境的训练模型。*这个模型已经三周没有更新过，自那时以来一直如此。* 这解释了黄金查询的稳定性。它也解释了用户点击行为的下降：我们可能在新偏好和新产品上显示较少的良好结果。当然，如果我们继续使用同样陈旧的模型，最终将无法正确推荐任何新内容。因此，Ariel
    查看了搜索模型训练系统，该系统每晚都安排搜索模型的训练。在过去三周内没有完成过一次训练运行，这肯定可以解释为何生产环境中没有新的训练模型。
- en: Note
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'We have a proximal cause for the outage, but at this point we don’t know the
    underlying cause, and there’s no obvious simple mitigation: without a new trained
    model in production, we cannot improve the situation. This is also a very rough
    proximal start of impact.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经找到了故障的近因，但目前我们还不知道根本原因，并且没有明显的简单缓解措施：没有新的训练模型投入使用，我们就无法改善情况。这也是影响起始相当严重的一次近因。
- en: The training system is distributed. A scheduler loads a set of processes to
    store the state of the model, and another set of processes to read the last day’s
    search logs and update the model with the new expressed preferences of the users.
    Ariel notes that all of the processes trying to read logs from the search system
    are spending most of their time waiting for those logs to be returned from the
    logging system.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 训练系统是分布式的。一个调度程序加载一组处理过程来存储模型的状态，另一组处理过程则读取昨天的搜索日志，并使用用户新表达的偏好来更新模型。Ariel 注意到，所有试图从搜索系统读取日志的处理过程，大部分时间都在等待这些日志从日志系统返回。
- en: The logging system accesses raw customer logs via a set of processes called
    *log feeders* that have permission to read the relevant parts of the logs. Looking
    at those log-feeder processes, Ariel notices a group of 10 of them and sees that
    each is crashing and exiting every few minutes. Diving into process crash logs,
    Ariel sees that the log feeders are running out of memory, and when they can’t
    allocate more memory, they crash. When they crash, a new log-feeder process is
    started on a new machine, and the training process retries its connection, reads
    a few bytes, and then that process runs out of memory and crashes again. This
    has been going on for three weeks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 日志系统通过一组称为*日志供应者*的进程访问原始客户日志，这些进程有权限读取日志的相关部分。在查看这些日志供应进程时，Ariel注意到其中有10个进程每隔几分钟就会崩溃并退出。深入研究进程崩溃日志时，Ariel发现日志供应者因为内存不足而崩溃。当它们无法分配更多内存时，它们会崩溃。崩溃后，新的日志供应进程会在新的机器上启动，训练过程会重新尝试连接，读取几个字节，然后该进程再次因为内存耗尽而崩溃。这种情况已经持续了三周。
- en: Ariel proposes that they try increasing the number of log-feeder processes from
    10 to 20\. Spreading the load from the training jobs around might prevent the
    jobs from crashing. They can also look at allocating more memory to the jobs if
    needed. The team agrees, Ariel makes the change, the log-feeder jobs stop crashing,
    and the search training run completes a few hours later.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Ariel建议将日志供应进程数量从10增加到20。在训练作业中分散负载可能会防止作业崩溃。如果需要，他们也可以考虑为作业分配更多内存。团队同意了这个建议，Ariel进行了更改，日志供应作业不再崩溃，并且搜索训练运行几小时后完成。
- en: Note
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The outage is mitigated as soon as the training run completes and the new trained
    model is put into production.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 训练运行完成并将新训练的模型投入生产后，中断得到了缓解。
- en: Ariel works with the team to double-check that the new trained model loads automatically
    into the serving system. The query golden set performs differently than the one
    from three weeks ago but performs acceptably well. Then they all wait a few hours
    to accumulate enough logs to generate the data they need to make sure that the
    updated trained model is really performing well for customers. Later, they analyze
    the logs and see that the click-through rate in the first five results is now
    back to where it should be.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Ariel与团队合作，再次确认新训练的模型是否能自动加载到服务系统中。查询黄金集的表现与三周前的不同，但表现仍然可接受。然后，他们等待几个小时以积累足够的日志来生成所需的数据，以确保更新的训练模型对客户的表现良好。随后，他们分析日志，发现前五个结果的点击率现在已经恢复到应有的水平。
- en: Note
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: At this point, the outage is resolved. Sometimes there is no obvious mitigation
    stage, and mitigation and resolution take place at the same time.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在此时，中断得到了解决。有时候没有明显的缓解阶段，缓解和解决同时进行。
- en: 'Ariel and the team work on a review of the incident, accumulating some post-outage
    work they’d like to perform, including the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Ariel和团队对事件进行了回顾，并积累了一些事后工作，包括以下内容：
- en: Monitor the age of the model in serving and alert if it’s over a certain threshold
    of hours old. “Age” here might be wall-clock age (literally, the timestamp on
    the file) or data age (how old the data is that the model is based on). Both of
    these are mechanically measurable.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控服务中模型的年龄，并在超过某个小时阈值时发出警报。“年龄”可以是墙上钟的年龄（字面上是文件的时间戳）或数据的年龄（模型基于的数据有多老）。这两者都可以通过机械手段进行测量。
- en: Determine our requirements for having a fresh model and then distribute the
    available time to the subcomponents of the training process. For example, if we
    need to get a model updated in production every 48 hours at the most, we might
    give ourselves 12 hours or so to troubleshoot problems and train a new model,
    so then we can allocate the remainder of the 36 hours to the log processing, log-feeding,
    training, evaluation, and copying to serving portions of the pipeline.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定我们对于必须有一个新鲜模型的需求，并将可用时间分配给训练过程的各个子组件。例如，如果我们最多每48小时需要在生产环境中更新一个模型，我们可能会给自己大约12小时来解决问题并训练一个新模型，然后我们可以将剩余的36小时分配给日志处理、日志供应、训练、评估和复制到服务流水线的部分。
- en: Monitor the golden query test and alert if it is unchanged as well as if it’s
    changed too much.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控黄金查询测试，并在它没有变化或变化太多时发出警报。
- en: Monitor the training system *training rate* and alert if it falls below a reasonable
    threshold such that we predict we will miss our deadline for training completion
    based on the allocated amount of time. Selecting what to monitor is difficult,
    and setting thresholds for those variables is even harder. This is covered briefly
    in [“ML Incident Management Principles”](#ml_incident_management_principles),
    and covered previously in [Chapter 9](ch09.xhtml#monitoring_and_observability_for_models).
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控训练系统的*训练速率*，并在其低于合理阈值时发出警报，以便我们预测基于分配的时间量我们将无法按时完成训练。选择监控内容是困难的，为这些变量设置阈值甚至更难。这在[“ML事件管理原则”](#ml_incident_management_principles)中简要涉及，并且在[第9章](ch09.xhtml#monitoring_and_observability_for_models)中已经涵盖。
- en: 'Finally, and most importantly: monitor the top-five-results click-through rate
    and alert if it falls below a certain threshold. This should catch any problem
    that affects the quality as perceived by users, but not caught by any of the other
    causes. Ideally, the metric for this should be available at least hourly so that
    we can use it while troubleshooting future problems, even if it’s stable on only
    a day-by-day basis.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，也是最重要的一点：监控前五个结果的点击率，并在其低于某个阈值时发出警报。这应该能够捕捉到任何影响用户感知质量但未被其他原因捕捉到的问题。理想情况下，这个指标应该至少每小时可用，这样即使只在每天基础上稳定也可以在未来解决问题时使用它。
- en: With those follow-up items scheduled, Ariel is ready for a break.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 随着这些后续项目的安排，艾瑞尔准备休息一下。
- en: Stages of ML incident response for story 1
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ML事件响应故事1的阶段
- en: 'This outage, although quite simple in cause, can help us start to see the way
    that ML incidents manifest somewhat differently for some phases of the incident
    response lifecycle:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这次停机的原因相当简单，但它可以帮助我们开始看到机器学习事件在某些阶段的响应生命周期中表现出略有不同的方式：
- en: Pre-incident
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 事前事件
- en: The training and serving system was a somewhat typical structure, with one system
    producing a trained model and periodically updating it, and another using that
    model to answer queries. This architecture can be very resilient, since the live
    customer-facing system is insulated from the learning system. When it fails, it
    is often because the model in serving is not updated. The underlying log data
    is also abstracted away in a clean fashion that protects the logs but still lets
    the training system learn on them. But this interface to the logs is precisely
    where the weakness in our system occurred.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 培训和服务系统是一个相当典型的结构，一个系统生成训练模型并定期更新，另一个系统使用该模型来回答查询。这种架构非常具有弹性，因为面向客户的实时系统与学习系统隔离开来。当它出现故障时，通常是因为服务中的模型没有更新。底层日志数据也以一种保护日志但仍允许训练系统从中学习的干净方式进行了抽象处理。但这种与日志的接口正是我们系统中弱点所在。
- en: Trigger
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 触发器
- en: Distributed systems often fail when they pass a particular threshold of scaling
    that sharply reduces performance, sometimes referred to as a *bottleneck*. In
    this case, we passed the threshold of performance of our log-feeder deployment
    and did not notice. The trigger was the simple growth of the data, corresponding
    growth of the training system requirements, and the business need to consume that
    data.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统在超过特定扩展阈值时通常会失败，从而显著降低性能，有时称为*瓶颈*。在这种情况下，我们超过了日志馈送部署性能的阈值，却没有注意到。触发器是数据的简单增长，对应于训练系统需求的增长，以及消费该数据的业务需求。
- en: Outage begins
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 停机开始
- en: The outage begins three weeks before we notice it. This is unfortunate, and
    why good monitoring is so important.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 停机开始三周后我们才注意到。这很不幸，这也是为什么良好的监控如此重要的原因。
- en: Detection
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 检测
- en: ML systems that are not well instrumented often manifest systems problems as
    only quality problems—they simply start performing less well and get gradually
    worse over time. Model quality changes are often the only end-to-end signal that
    something is wrong with the system infrastructure.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 未充分工具化的机器学习系统通常将系统问题表现为仅有质量问题——它们仅仅开始表现得不太好，并且随着时间的推移逐渐恶化。模型质量变化通常是系统基础设施出现问题的唯一端到端信号。
- en: Troubleshooting
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 故障排除
- en: ML troubleshooting often involves a broader set of teams than some other kinds
    of outages, precisely because they often manifest as publicly visible quality
    problems. Until the problem can be narrowed down, it’s prudent not to make assumptions
    about the kind of outage we’re experiencing—it could be a systems problem, a model
    problem, or just a drift in our ability to correctly predict the world.^([3](ch11.xhtml#ch01fn124))
    Sometimes it’s the world changing faster than we can keep up with—more on this
    in story 3\. Not all quality degradations are even outages. Future stories will
    show a yet broader cast of characters involved in troubleshooting.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习故障排除通常涉及比其他类型的故障更广泛的团队，这正是因为它们通常表现为公开可见的质量问题。在问题被缩小之前，最好不要对我们正在经历的故障类型进行假设——这可能是系统问题、模型问题，或者只是我们正确预测世界能力的漂移。^([3](ch11.xhtml#ch01fn124))
    有时候，问题是世界变化速度超过我们能跟上的速度——关于这一点，后续故事将详细介绍。并非所有的质量下降都是故障。未来的故事将展示更广泛的参与故障排除的人员阵容。
- en: Mitigation/resolution
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解/解决方案
- en: The fastest and least risky steps to mitigate the problem, in this case, involved
    training a new model and successfully deploying it to our production search serving
    system. For ML systems, especially those that train on lots of data or that produce
    large models, no such quick resolution might be available.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，缓解问题的最快、最低风险的步骤涉及训练一个新模型，并成功部署到我们的生产搜索服务系统中。对于机器学习系统，特别是那些在大量数据上进行训练或生成大型模型的系统来说，可能没有这样的快速解决方案。
- en: Follow-up
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 后续
- en: We can add a rich set of monitoring here, much of which is not easy to implement
    but will benefit us during future incidents.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这里添加丰富的监控内容，其中许多内容并不容易实施，但在未来的事件中将对我们有益。
- en: This first story shows a fairly simple ML-associated outage. We can see that
    outages can present as quality problems of models not quite doing what we expect
    or need them to do. We can also start to see the pattern of broad organizational
    coordination that is required in many cases for resolution. Finally, we can see
    that it is tempting to be ambitious in specifying the follow-up work. Keeping
    these three themes in mind, let’s consider another outage.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这个第一个故事展示了一个相当简单的与机器学习相关的故障。我们可以看到，故障可能表现为模型质量问题，未能完全符合我们的预期或需求。我们还可以开始看到，在许多情况下需要广泛的组织协调来解决问题的模式。最后，我们可以看到，对后续工作的规范是非常诱人的。在记住这三个主题的情况下，让我们考虑另一个故障。
- en: 'Story 2: Suddenly Useless Partners'
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故事2：突然无用的合作伙伴
- en: At YarnIt, we have two types of business. The first part of our business is
    a first-party store selling knitting and crocheting products. But we also have
    a marketplace for recommending products from other partners who sell them through
    our store. This is a way that we can make a wider variety of products available
    to our customers without having to invest more in inventory or marketing.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在YarnIt，我们有两种业务类型。我们的第一部分是直营店，销售针织和编织产品。但我们还有一个市场，推荐其他合作伙伴通过我们的商店销售的产品。这是一种可以向我们的客户提供更多种类产品的方式，而无需增加库存或营销投入。
- en: When and how to recommend these marketplace products is a little tricky. We
    need to incorporate them into our search results and discovery tools on the website
    as a baseline, but how should we make recommendations? The simplest approach would
    be to list every product in our product database, include all actions that touch
    them in our logs, and add them to our main prediction model. A notable constraint
    is that each of these partners requires that we separate their data from every
    other partner; otherwise, they won’t let us list their products.^([4](ch11.xhtml#ch01fn125))
    As a result, we’ll have to train a separate model per partner, and extract partner-specific
    data into isolated repositories, though we can still have a common feature store
    for shared data.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 何时以及如何推荐这些市场产品有点棘手。我们需要将它们作为基准纳入到我们网站上的搜索结果和发现工具中，但我们应该如何进行推荐呢？最简单的方法是列出我们产品数据库中的每个产品，包括所有涉及它们的操作在我们的日志中，然后将它们添加到我们的主预测模型中。一个显著的限制是，这些合作伙伴中的每一个都要求我们将他们的数据与其他合作伙伴的数据分开；否则，他们将不允许我们列出他们的产品。^([4](ch11.xhtml#ch01fn125))
    因此，我们将不得不为每个合作伙伴训练一个单独的模型，并将合作伙伴特定的数据提取到隔离的存储库中，尽管我们仍然可以为共享数据维护一个通用的特征存储。
- en: YarnIt is ambitious enough to plan for a potentially *very* large number of
    partners—somewhere between five thousand or five million—and so instead of a setup
    optimized for a few large models, we need a setup optimized for thousands of tiny
    models. As a result, we built a system that extracts historical data from each
    partner and puts it into a separate directory or small feature store. Then at
    the end of every day, we separate out the previous day’s deltas and add them to
    our stores just before starting training. Now our main models train quickly, and
    our smaller partner models train quickly as well. Best of all, we’re compliant
    with the access protection demanded by our partners.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: YarnIt雄心勃勃，计划为潜在的*非常*大量合作伙伴之间——大约在五千到五百万之间——设计一个设置，而不是为少数大型模型进行优化。因此，我们建立了一个系统，从每个合作伙伴中提取历史数据并将其放入单独的目录或小型特征存储中。然后，每天结束前，我们分离出前一天的增量并将其添加到我们的存储中，然后开始训练。现在，我们的主要模型训练速度很快，我们的较小合作伙伴模型也训练速度很快。最重要的是，我们符合合作伙伴要求的访问保护标准。
- en: Note
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The pre-incident is complete at this point. The stage is set, and the conditions
    for the outage have been set. It may be obvious by this point that several opportunities
    exist for things to go wrong.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 到这一点，预事故已经完成。舞台已经搭建好，停机的条件也已经设置好。到这时，可能已经很明显存在许多问题的机会。
- en: Sam, a production engineer at YarnIt, works on the partner training system.
    Sam is asked to produce a report for CrochetStuff, a partner, in advance of a
    business meeting. While preparing the report, Sam notices that the partner in
    question has zero recent conversions (sales) recorded in the ML training data
    but that the accounting system reports that it’s selling products every day. Sam
    produces a report and forwards it to colleagues who work on the data extraction
    and joining jobs for some advice. In the meantime, Sam leaves this fact off the
    report on data to the partner team and simply includes the sales data.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Sam是YarnIt的一名生产工程师，负责合作伙伴培训系统。在即将进行的业务会议前，Sam被要求为合作伙伴CrochetStuff制作报告。在准备报告时，Sam注意到所讨论的合作伙伴在机器学习训练数据中没有最近的转化记录，但会计系统报告称其每天都在销售产品。Sam制作了一份报告并转发给负责数据提取和连接工作的同事以寻求建议。与此同时，Sam在向合作伙伴团队的数据报告中没有提到这个事实，只包括了销售数据。
- en: Note
  id: totrans-129
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The detection happens here. No computer system detected the outage, which means
    that it may have been going on for an indefinite amount of time.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 检测发生在这里。没有计算机系统检测到停机情况，这意味着它可能已经持续了不确定的时间。
- en: Data discrepancies in counts like this happen all the time, so the data extraction
    team does not treat Sam’s report as a high priority. Sam is reporting a single
    discrepancy for a single partner, and the team files a bug and plans to get to
    it in the coming week or so.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样的计数数据不一致问题经常发生，因此数据提取团队不将Sam的报告视为高优先级。Sam报告了一个合作伙伴的单一差异，团队提交了一个bug，并计划在未来一周左右解决。
- en: Note
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The incident is unmanaged and continuing chaotically. It might be small, or
    it might not. No one has determined the extent of the impact of the data problem
    yet, and no one is responsible for coordinating a quick and focused response to
    it.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 事故未经管理，继续混乱进行。它可能很小，也可能不是。尚无人确定数据问题的影响程度，并且没有人负责协调快速和有针对性的应对措施。
- en: At the business meeting, CrochetStuff notes that its sales are down 40% week-on-week
    and continuing to drop daily. Their reports on page views, recommendations, and
    user inquiries are all down, even though when users *do* find the products, the
    rate at which they purchase continues to be high. CrochetStuff demands to know
    why YarnIt suddenly stopped recommending all of its products!
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在业务会议上，CrochetStuff指出其销售环比下降了40%，并且每天都在继续下降。尽管用户*找到*产品的速率依然很高，但他们的页面浏览量、推荐和用户查询量都在下降。CrochetStuff要求知道为什么YarnIt突然停止推荐其所有产品！
- en: Note
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: By this point, we have had internal detection, an internal partner advocate,
    customer reports, and a possible lead of what is happening. This is a lot of noise,
    but sometimes we don’t declare an incident until many people independently notice
    it.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们进行了内部检测、内部合作伙伴倡导、客户报告，并可能发现了正在发生的事情的线索。这些都是很多噪音，但有时我们直到多人独立注意到它之后才宣布事故。
- en: Sam declares an incident and starts working on the problem. The logs of the
    partner model training system clearly report that the partner models are successfully
    training every day, and there are no recent changes to either the binaries that
    carry out the training or the structure and features of the models themselves.
    Looking at the metrics coming from the models, Sam can see that the predicted
    value of every product in the CrochetStuff catalog has declined significantly
    every day for the past two weeks. Sam looks at other partners’ results and sees
    exactly the same drop.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Sam宣布了一个事件，并开始解决问题。合作模型训练系统的日志清楚地报告说，合作模型每天都在成功训练，并且最近没有对执行训练的二进制文件或模型结构和特性进行任何更改。通过模型生成的指标来看，Sam可以看到CrochetStuff目录中每个产品的预测值在过去两周内每天都显著下降。Sam查看其他合作伙伴的结果时，看到了完全相同的下降趋势。
- en: 'Sam brings in the ML engineers who built the model to troubleshoot what is
    happening. They double-check that nothing has changed and then do some aggregate
    checks on the underlying data. One of the things they notice is what Sam noticed
    originally: there are no sales for any partners in the last two weeks in the ML
    training data. The data all comes from our main logs system and is extracted every
    day to be joined with the historical data we have for each partner. The data extraction
    team resurrects Sam’s bug from a few days before and starts looking at it.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Sam找来建模的机器学习工程师们来排查发生了什么。他们再次确认没有任何改变，然后对底层数据进行了一些聚合检查。他们注意到的一件事与Sam最初注意到的一样：在过去两周内，机器学习训练数据中没有任何合作伙伴的销售数据。所有数据都来自我们的主日志系统，并且每天提取以与每个合作伙伴的历史数据进行连接。数据提取团队从几天前Sam的错误中恢复，并开始调查。
- en: Sam, who needs to find a fast mitigation for the problem, notes that the team
    stores older copies of trained models for as long as several months. Sam asks
    the ML engineers about the consequences of just loading an old model into serving
    for now. The team confirms that while the old trained model versions won’t have
    any information about new products or big changes in consumer behavior, they will
    have the expected recommendation behavior for all existing products. Since the
    scope of the outage is so significant, the partner team decides it is worth the
    risk to roll back the models. In consultation with the partner team, Sam rolls
    back all of the partner trained models to versions that were created two weeks
    earlier, since that seems to be before the impact of the outage began. The ML
    engineers do a quick check of aggregate metrics on the old models and confirm
    that recommendations should be back to where they were two weeks ago.^([5](ch11.xhtml#ch01fn126))
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Sam，需要快速缓解问题的人员，注意到团队保存了长达几个月的旧版本训练模型。Sam询问机器学习工程师只加载旧模型到服务中目前可能带来的后果。团队确认，虽然旧的训练模型版本不包含任何关于新产品或消费者行为大变化的信息，但它们对所有现有产品的推荐行为仍具有预期效果。由于故障的范围如此之大，合作团队决定冒这个风险回滚模型。在与合作团队磋商后，Sam将所有合作训练模型回滚到两周前创建的版本，因为这似乎是故障影响开始之前的时间点。机器学习工程师快速检查了旧模型的聚合指标，并确认推荐应该恢复到两周前的状态。^([5](ch11.xhtml#ch01fn126))
- en: Note
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: At this point, the outage is mitigated but not really resolved. Things are in
    a pretty unstable state—notably, we cannot build a new model with our accustomed
    process and have it work well—and we still need to figure out the best full resolution
    as well as how to avoid getting ourselves into this situation again.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，故障虽然得到了缓解，但并没有真正解决。情况非常不稳定，尤其是我们无法使用我们习惯的流程构建新模型，并使其良好运行。我们仍然需要找出最佳的完整解决方案，以及如何避免再次陷入这种情况。
- en: While Sam has been mitigating, the data extraction team has been investigating.
    It finds that while the extractions are working well, the process that merges
    extracted data into the existing data is consistently finding no merges possible
    for any partners. This appears to have started about two weeks ago. Further investigation
    reveals that two weeks ago, in order to facilitate other data analysis projects,
    the data management team changed the unique partner key, used to identify each
    partner in its log entries. This new unique key was included in the extracted
    data, and because it differed from previous partner identifiers, the newly extracted
    logs could not be merged with any data extracted prior to the key being added.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Sam 在减轻问题时，数据提取团队一直在进行调查。它发现，虽然提取工作正常，但将提取的数据合并到现有数据中的过程始终无法为任何合作伙伴找到可合并的内容。这一问题似乎始于大约两周前。进一步的调查揭示，两周前，为了促进其他数据分析项目，数据管理团队更改了用于在其日志条目中识别每个合作伙伴的唯一合作伙伴键。这个新的唯一键被包含在提取的数据中，因为它与以前的合作伙伴标识符不同，所以新提取的日志无法与添加键之前提取的任何数据合并。
- en: Note
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This is now a reasonable root cause for the outage.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这是停机的一个合理的根本原因。
- en: Sam requests that a single partner’s data be re-extracted and that a model be
    trained on the new data in order to quickly verify that the system will work correctly
    end to end. Once this is done, Sam and the team are able to verify that the newly
    extracted data contains the expected number of conversions and that the models
    are now, again, predicting that these products are good recommendations for many
    customers. Sam and the data extraction engineers do some quick estimations on
    how long it will take to re-extract all of the data, and Sam then consults with
    the ML engineers on how long it will take to retrain all of the models. They arrive
    at a collective estimate of 72 hours, during which they will continue to serve
    recommendations from the stale model versions that they restored from two weeks
    prior. After consulting with the retail product and business team, they all decide
    to carry out this approach. The partner team drafts some mail to partners to let
    them know about the problem and a timeline for resolution.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Sam 请求重新提取单个合作伙伴的数据，并在新数据上训练一个模型，以快速验证系统是否正确端到端地工作。一旦完成，Sam 和团队能够验证新提取的数据包含预期数量的转化，并且模型现在再次预测这些产品是许多客户的好推荐。Sam
    和数据提取工程师对重新提取所有数据需要多长时间进行了一些快速估算，然后Sam 与机器学习工程师商议重新训练所有模型需要多长时间。他们得出一个共同的估计为72小时，在此期间，他们将继续提供来自两周前恢复的陈旧模型版本的推荐。在与零售产品和业务团队商议后，他们决定执行这种方法。合作伙伴团队起草了一些邮件通知合作伙伴有关问题及解决时间表。
- en: Sam requests that all partner data be re-extracted and that all partner models
    be retrained, preferably from scratch, starting with the beginning of data we
    have. They monitor the process for three days, and once it is done, verify that
    the new models are recommending not only the older products but also newer products
    that didn’t exist two weeks prior. After careful checking, the new models are
    deemed to be good by the ML engineers and are put into production. Serving results
    are carefully checked, along with many folks doing live searches and browsing
    to verify that partner listings are actually showing up as expected. Finally,
    the outage is declared closed, and the partner team drafts an update to partners
    letting them know.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Sam 请求重新提取所有合作伙伴数据，并尽可能从头开始重新训练所有合作伙伴模型。他们监控这个过程三天，一旦完成，验证新模型不仅推荐旧产品，还推荐了在两周前不存在的新产品。经过仔细检查，机器学习工程师认为新模型是好的，并投入生产。服务结果经过仔细检查，许多人进行实时搜索和浏览以验证合作伙伴列表是否按预期显示。最终，停机宣布解决，合作伙伴团队起草了一份更新，通知合作伙伴们。
- en: Note
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: At this point, the outage is resolved.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，停机已经解决。
- en: Sam brings the team together to go over the outage and file some follow-up bugs
    so that they can avoid this kind of outage in the future and detect it more quickly
    than they did this time. The team considers rearchitecting the whole system so
    that they can eliminate the problem of having two copies of all of the data, with
    slightly different uses and constraints, but decides that they still don’t have
    a good idea about how to meet their performance goals for both systems if they
    are unified.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Sam召集团队一起讨论停机事件，并提出一些后续错误报告，以便他们能够避免类似的停机事件，并比这次更快速地检测到它。团队考虑重新架构整个系统，以消除所有数据两次拷贝的问题，具有稍有不同的用途和约束，但他们决定，如果统一，仍然没有很好地了解如何达到两个系统的性能目标。
- en: They do file a set of bugs related to monitoring the success of data extraction,
    data copying, and data merging. The biggest problem is that they don’t have a
    good source of truth for the question, how many lines of data should be merged?
    This failure happened for an entire class of logs, and the team was quickly able
    to add an alert for “log lines merged must be greater than zero.” But during the
    investigation, a series of less catastrophic failures were also found, and to
    catch those, we would need to know the expected number of logs per partner to
    be merged and then the actual number that were merged.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 他们确实提出了一组与监控数据提取成功、数据复制和数据合并相关的错误报告。最大的问题在于，他们没有一个关于“应该合并多少行数据”的可靠真实来源。这种失败发生在整个日志类别中，团队很快就能为“必须大于零的日志行合并”添加警报。但在调查过程中，还发现了一系列不太严重的失败，为了捕捉这些失败，我们需要知道每个合作伙伴预期合并的日志数量，以及实际合并的数量。
- en: The data extraction team settles on a strategy of storing the count of merged
    log lines by partner by day and comparing today’s successes to the trailing average
    of the last *n* days. This will work relatively well when partners are stable
    but will be noisy when they experience big changes in popularity.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 数据提取团队决定采用一种策略，按合作伙伴每天合并的日志行数进行存储，并将今天的成功与过去 *n* 天的滞后平均值进行比较。当合作伙伴稳定时，这种方法效果相对不错，但当他们的流行度发生较大变化时会产生噪音。
- en: Two years later, this alerting strategy is still unimplemented as a result of
    challenges in implementing it without unnecessary noise. The strategy may be a
    good idea but, given the dynamic retail environment, has proven unworkable, and
    the team still lacks good end-to-end rapid detection of this kind of log extraction
    and merging failure, except in the catastrophic case. However, a heuristic they
    did implement a few months in—a hook that triggers on any relevant change to the
    partner configurations and notifies an engineer to potentially expect breakage—has
    at least increased ongoing awareness of such a change as a potential trigger for
    outages.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 两年后，这种警报策略仍未实施，因为在实施过程中遇到了不必要的噪音挑战。这种策略可能是一个好主意，但考虑到动态的零售环境，已被证明行不通，而且团队仍然缺乏良好的端到端快速检测这类日志提取和合并故障的能力，除了在灾难性情况下。然而，他们在几个月前实施的一种启发式方法——通过触发任何合作伙伴配置变更并通知工程师潜在的故障——至少增加了对这种变化作为潜在触发器的持续意识。
- en: Stages of ML incident response for story 2
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ML事故响应故事2阶段
- en: 'Many of the characteristic stages that this incident went through are similar
    to those of any distributed systems incident. It has prominent differences though,
    and the best way to see those with some context and nuance is to walk through
    the partner training outage and look at the ML-salient features that occur during
    each section:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这次事故经历的许多特征阶段与任何分布式系统事故的相似之处很多。但是它有明显的不同之处，要看到这些特点，最好的方法是通过合作伙伴培训中断的过程，并查看在每个部分发生的与机器学习相关的特征：
- en: Pre-incident
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 事前事件
- en: Most of what went wrong was already latent in the structure of our system. We
    have a system with two authoritative sources for the data, one of which is an
    extracted version of the other, with incremental extracts being applied periodically.
    ML systems most commonly fail because of problems with data and metadata. We will
    dig into the tactics for observing and diagnosing outages across systems with
    coupled data and ML in [“ML Incident Management Principles”](#ml_incident_management_principles).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数问题在我们系统结构中已经潜在存在。我们的系统有两个数据的权威来源，其中一个是另一个的提取版本，定期应用增量提取。机器学习系统最常见的失败是由于数据和元数据的问题。我们将深入研究观察和诊断系统中耦合数据和机器学习中断的策略，参见[“机器学习事故管理原则”](#ml_incident_management_principles)。
- en: Trigger
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 触发器
- en: The data schema was changed. It was changed very far away from where we observed
    the problem, which obviously made it difficult to identify. It is important to
    think about this outage as a way of identifying the assumptions we have made about
    our data throughout the processing stack. If we can identify those assumptions
    and where they are implemented, we can avoid creating data processing systems
    that can be damaged by changes to those assumptions. In this case, it should have
    been impossible to change the schema of our main feature store without also modifying
    or at least notifying all downstream users of that feature store. Explicit data
    schema versioning is one way to achieve this result.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 数据架构已更改。这次更改距离我们观察到问题的地方很远，显然这使得识别变得困难。重要的是要将这次中断视为识别我们在整个处理堆栈中对数据所做的假设的一种方式。如果我们能够识别这些假设及其实施位置，我们就能避免创建会因为这些假设变化而受损的数据处理系统。在这种情况下，我们的主要特征存储架构不应该更改，除非也修改或至少通知所有下游用户这个特征存储的情况。显式的数据架构版本控制是实现这一结果的一种方式。
- en: Outage begins
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 中断开始
- en: The outage begins when one internal system processing data uses another internal
    system that processes data in a way that is no longer consistent with its structure.
    This is a common hazard for any large distributed pipeline system.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 中断始于一个内部系统处理数据的过程使用另一个内部系统处理数据的方式，而这种方式已不再与其结构一致。这是任何大型分布式管道系统的常见危险。
- en: Detection
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 检测
- en: 'ML systems quite commonly fail in ways that are detected first by end users.
    One challenge with this is that ML systems are often accused of failure, or at
    least not working as well as we might hope, even under normal operations, and
    so it may seem reasonable to disregard the complaints of users and customers.
    The primary method of noticing this particular outage is a common one: the recommendations
    system wasn’t making recommendations of the same quality as it used to. With ML
    system monitoring, keeping the high-level, end-to-end, coarse-grained picture
    in mind is particularly useful—with the central question being, have we substantially
    changed what the model is predicting over the past short while? These kinds of
    end-to-end quality metrics are completely independent of the implementation and
    will detect any kind of outage that substantially damages models. The challenge
    will be to filter that signal so that not too many false positives occur.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统很常见地以终端用户首先检测到的方式失败。其中一个挑战是，机器学习系统通常被指责失败，或者至少在正常运行时表现不佳，因此忽视用户和客户的投诉似乎是合理的。注意到这种特定中断的主要方法是一个常见的方法：推荐系统不再提供与以往相同质量的推荐。通过机器学习系统的监控，牢记高级别、端到端、粗粒度的整体情况特别有用——核心问题是，我们在过去的短时间内是否显著改变了模型的预测？这类端到端的质量指标完全独立于实现，将检测到任何严重损害模型的中断。挑战在于过滤该信号，以避免出现太多误报。
- en: Troubleshooting
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 故障排除
- en: 'Sam needs to work with multiple teams to understand the scope and potential
    causes of the outage. We have commercial and product staff (the partner team),
    ML engineers who build the model, data extraction engineers who get the data out
    of the feature store and logs store and ship it to our partner model training
    environment, and production engineers like Sam coordinating the whole effort.
    Troubleshooting ML outages really has to start not with the data but with the
    outside world: what is our model saying, and why is that wrong? There is *so*
    much data that starting by “just looking through the data” or even “doing aggregate
    analysis of the data” is likely to be a long and fruitless search. Start with
    the model’s changed or problematic behavior, and it will be much easier to work
    backward to why the model is now doing what it is doing.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Sam 需要与多个团队合作，以理解中断的范围和潜在原因。我们有商业和产品人员（合作伙伴团队）、构建模型的机器学习工程师、从特征存储和日志存储中提取数据并将其送至我们的合作伙伴模型训练环境的数据提取工程师，以及像
    Sam 这样协调整个工作的生产工程师。解决机器学习中断问题确实必须从外部世界开始，而不是从数据开始：我们的模型说了什么，为什么是错误的？有如此多的数据，仅仅“浏览数据”甚至“对数据进行聚合分析”可能会是一个漫长而毫无成果的搜索。从模型的变化或有问题的行为开始，倒推出现在模型为什么会这样做会更容易些。
- en: Mitigation
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解
- en: With some services, it is possible to simply restore an older version of the
    software while a fix is prepared. While this may inconvenience any users depending
    on new features, everyone else can continue unaffected.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些服务来说，可以在准备修复方案的同时简单地恢复软件的旧版本。虽然这可能会给依赖新功能的用户带来不便，但其他人可以继续不受影响。
- en: ML outages can only sometimes be mitigated by restoring an older version of
    the model, because their job is to help computer systems adapt to the world, and
    there’s no way to restore a snapshot of the world as it used to be.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习停机通常只能通过恢复模型的旧版本来部分缓解，因为它们的任务是帮助计算机系统适应世界，而没有办法恢复世界过去的快照。
- en: Additionally, quickly training up new models often requires more computing capacity
    than we have available. As was the case with our partner model outage, no cost-free
    quick mitigation exists. To determine which mitigation was the best option, the
    decision ultimately needed to be made by the product and business staff most familiar
    with our partners, users, and business. This level of escalation to business leaders
    happens sometimes for non-ML services but much more frequently for ML services.
    Most organizations that rely on ML to run important parts of their business will
    need to cultivate technical leaders who understand the business, and business
    leaders who understand the technology.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，快速培训新模型通常需要比我们现有的计算能力更多。正如我们合作伙伴模型停机的情况一样，没有无成本的快速缓解措施。确定最佳缓解选项需要最熟悉我们合作伙伴、用户和业务的产品和业务人员最终做出决定。对于非机器学习服务，这种升级到业务领导层的情况有时会发生，但对于机器学习服务则更为频繁。大多数依赖机器学习来运行业务重要部分的组织将需要培养既懂业务又懂技术的技术领导者。
- en: Resolution
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: Sam makes sure that the data in the partner training system is correct (at least
    in aggregate, and spot checks seem to confirm that it looks good). New models
    are trained. When we are ready to deploy them, there’s actually no simple way
    to determine whether the new models “fix” the problem. The world continues to
    change while we are working on resolving this problem. So some previously popular
    products may be less in vogue now. Some neglected products may have been discovered
    by our users. We can look at the aggregate metrics to see whether we are recommending
    partner products at closer to the rate that we did previously, but it won’t be
    identical. Sometimes people use a golden set of queries here to see if they can
    produce a “correct” set of recommendations for pre-canned results. This can increase
    our confidence somewhat but adds the new problem that we will want to continuously
    curate this golden set of queries to be representative of what our users search
    for. Once we do that, we will not necessarily have stable results over very long
    periods of time.^([6](ch11.xhtml#ch01fn127))
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Sam 确保合作伙伴培训系统中的数据是正确的（至少在总体上，抽查似乎确认它看起来不错）。新模型已经训练完成。当我们准备部署它们时，实际上没有简单的方法来确定新模型是否“修复”了问题。在我们努力解决这个问题的同时，世界继续变化。因此，一些先前受欢迎的产品现在可能不那么流行了。一些被忽视的产品可能被我们的用户发现了。我们可以查看总体指标，看看我们是否推荐合作伙伴产品的速率接近之前的水平，但这不会完全相同。有时人们会在这里使用一组黄金查询，以查看是否能生成一组“正确”的预置结果。这可能在一定程度上增加我们的信心，但也带来了一个新问题，即我们将希望不断地维护这组黄金查询，以代表我们用户搜索的内容。一旦我们做到了这一点，我们不一定会在非常长的时间段内得到稳定的结果。^([6](ch11.xhtml#ch01fn127))
- en: Follow-up
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 后续处理
- en: 'After-incident work is always difficult. For a start, the people with direct
    knowledge are tired, and may have been neglecting their other work for some time
    by this point. We have already paid the price of the outage, so we might as well
    get the value for it. While monitoring bugs are typically included in post-incident
    follow-up, it is incredibly common for them to languish (in some cases for years)
    for ML-based systems. The reason is relatively simple: it is extremely difficult
    to monitor real data and real models in a high-signal, low-noise way. Anything
    that is overly sensitive will alert all the time—the data is different! But anything
    that is overly broad will miss complete outages of subsets of our services. These
    problems exist for most distributed systems but are characteristic for ML systems.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 事后工作总是困难的。首先，有直接知识的人已经很累了，到这个时候可能已经忽略了他们的其他工作。我们已经为停机付出了代价，所以我们最好从中获得价值。尽管监控错误通常包含在事后跟进中，但对于基于机器学习的系统来说，这种错误往往会懒散下来（有时长达数年）。原因相对简单：以高信号低噪声方式监控真实数据和真实模型非常困难。任何过于敏感的东西都会一直警报——数据不同了！但是过于宽泛的东西会错过我们服务的子集的完全停机。这些问题存在于大多数分布式系统中，但对于机器学习系统来说是特征性的。
- en: While this outage was technically complex and somewhat subtle in its manifestation,
    many ML outages have very simple causes but still show up in difficult-to-correlate
    ways.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这次停机在技术上复杂，并且在表现上有些微妙，但许多机器学习停机都有非常简单的原因，但仍然以难以关联的方式显示出来。
- en: 'Story 3: Recommend You Find New Suppliers'
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '故事 3: 推荐您寻找新供应商'
- en: 'We have models for several aspects of our business at YarnIt. The recommendations
    model in particular has an important signal: purchases. Simply put, we recommend
    a product in every browsing context where users tend to purchase that product
    when it is offered to them. This is good for our users, who more quickly find
    products that they want to buy, and for YarnIt, which will presumably sell more
    products more quickly.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在 YarnIt，我们有几个业务方面的模型。特别是推荐模型具有重要的信号：购买。简单来说，我们在用户倾向于购买产品时，在每一个浏览上下文中推荐产品给他们。这对我们的用户来说是好事，因为他们更快地找到想购买的产品；对于
    YarnIt 来说，这意味着更快地销售更多产品。
- en: Gabi is a production engineer who works on the discovery modeling system. One
    unusually pleasant summer day, Gabi is working through configuration cleanups
    that have been lingering and addressing requests from other departments. Customer
    support staff sent a note that they have been tracking a theme in feedback on
    the website for the past couple of weeks, saying that the recommendations are
    “weird.” Subjective impressions like this by some customers are generally pretty
    hard to take any concrete action on, but Gabi files the request into a “pending
    follow-up” section for later follow-up.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Gabi 是一名工作在发现建模系统上的生产工程师。一个异常愉快的夏日，Gabi 在处理已经悬而未决的配置清理工作，并处理其他部门的请求。客户支持人员发送了一封通知，他们在过去几周内一直在网站上追踪到一个反馈主题，称推荐内容“奇怪”。一些客户的这种主观印象通常很难采取任何具体行动，但是
    Gabi 将该请求归档到“待跟进”部分，以便稍后跟进。
- en: Note
  id: totrans-177
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: No spoilers! We definitely cannot say whether incident detection has happened
    yet at this point.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 不要透露剧透！我们绝对不能说到目前为止是否已经发生了事件检测。
- en: Further in the incoming requests, Gabi spots an unusual problem report. The
    website payments team tells Gabi that Finance is reporting a big drop in revenue.
    Revenue is down 3% for the past month on the site. That might not seem like a
    big drop, but after further digging, the team finds that last week versus four
    weeks ago is down closer to 15%! The payments team has checked the payment-processing
    infrastructure, and found that customers are paying for carts successfully at
    the same rate they historically have. They note, though, that the carts have fewer
    average products than they used to, and in particular fewer people are purchasing
    products from recommendations than expected. This is why the payments team has
    contacted Gabi. Seeing numbers this big, Gabi declares an incident.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在后续的请求中，Gabi 发现了一个异常的问题报告。网站支付团队告诉 Gabi，财务部门报告收入大幅下降。网站上过去一个月的收入下降了 3%。这可能看起来不是很大的下降，但经过进一步的调查，团队发现相比四周前，上周的下降接近
    15%！支付团队已经检查了支付处理基础设施，并发现客户支付购物车的成功率与历史上相同。他们指出，尽管如此，购物车的平均产品数少于以往，并且特别是购买推荐产品的人数少于预期。这就是为什么支付团队联系了
    Gabi。看到如此大的数字，Gabi 宣布了一个事件。
- en: Note
  id: totrans-180
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Incident detected and declared.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 检测到并宣布了事件。
- en: 'Gabi asks the financial team to double-check the week-versus-four-weeks-ago
    comparison for the past several weeks, and asks for a more detailed timeline of
    revenue for the past several weeks. Finally, Gabi asks for any product, category,
    or partner breakdowns available. Gabi then asks the payments team to verify its
    numbers about recommendations added to carts as well as to provide any breakdowns
    it can. In particular: does the team see a particular type of cart that has fewer
    recommendations than others or that has changed more recently?'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Gaby 要求财务团队再次核实过去几周的本周与四周前的比较，并要求提供过去几周收入的更详细的时间表。最后，Gaby 要求提供任何可用的产品、类别或合作伙伴的分解情况。然后，Gaby
    要求支付团队验证关于添加到购物车的推荐的数字，并提供他们能提供的任何分解信息。特别是：团队是否看到某种特定类型的购物车比其他购物车少推荐或者最近发生了变化？
- en: Meanwhile, Gabi starts looking at aggregate metrics for the application, just
    trying to figure out some basic questions. Are we showing recommendations at all?
    Are we showing recommendations as often as we have in the past, and for all the
    queries and users and products that we did in the past, and in the same proportions
    across user subpopulations? Are we generating sales from recommendations at the
    same rate as we typically have? Is there anything else salient about the recommendations
    that is obviously different?
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，Gaby 开始查看应用程序的聚合指标，试图弄清楚一些基本问题。我们是否在显示推荐？我们是否像过去一样频繁地显示推荐，以及对于所有的查询、用户和产品，我们是否以过去的同样比例跨用户子群体生成销售？我们是否像通常一样从推荐中生成销售？推荐中是否有明显不同的显著之处？
- en: 'Gabi also starts doing the normal production investigation, focusing particular
    attention on what changed in the recommendations stack recently. The results are
    not promising for finding an obvious culprit: the recommendations models and binaries
    to train the models are unchanged in the last six weeks. The data for the model
    is updated daily, of course, so that’s something to look at. But the data schema
    in the feature store hasn’t changed in several months.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Gaby 还开始进行常规的生产调查，特别关注最近推荐堆栈中发生了什么变化。结果并不令人鼓舞，找不到明显的罪魁祸首：推荐模型和用于训练模型的二进制文件在过去六周内都没有改变。当然，模型的数据每天更新，这也是需要关注的一点。但是特征存储中的数据架构几个月来都没有变化。
- en: 'Gabi needs to continue troubleshooting but takes time to compose a quick message
    to the finance and payments teams that asked for help with this issue. Gabi confirms
    what is known so far: the recommendations system is running and producing results,
    and there are no recent changes to be found, but the quality of the results has
    not been verified. Gabi reminds them to inform their department heads if they
    have not already, which seems wise given the amount of money the company appears
    to be losing.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Gaby 需要继续故障排除，但却花时间撰写一条快速消息给财务和支付团队，请求帮助解决这个问题。Gaby 确认了到目前为止所知的情况：推荐系统正在运行并产生结果，但尚未验证结果的质量。考虑到公司似乎正在损失大量资金，Gaby
    提醒他们如果尚未通知部门负责人则需要通知他们，这似乎是明智的做法。
- en: No obvious software, modeling, or data updates correlate with the outage, so
    Gabi decides that it’s time to dig into the recommendations model itself. Gabi
    sends a quick message to Imani, who built the model, asking for help. As Gabi
    is explaining to Imani what they know so far (fewer products purchased, fewer
    recommendations purchased per checkout, no system changes to speak of), the note
    from customer support comes to mind. Customers complaining about “weird” recommendations,
    if the timeline matches up, certainly seems relevant.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 没有明显的软件、建模或数据更新与停机时间相关，因此 Gaby 决定深入研究推荐模型本身。Gaby 发送了一条快速消息给建模者 Imani，请求帮助。当
    Gaby 向 Imani 解释他们到目前为止所知道的情况（购买产品减少，每次结账购买的推荐减少，没有系统变更）时，客户支持的便签也跃入脑海。如果时间线符合，客户抱怨有关“奇怪”推荐的确显得相关。
- en: 'Customer support staff confirm that they started getting the first sporadic
    complaints just over three weeks ago but that they have been intensifying and
    became especially pointed in the last week. Imani thinks this may be worth investigating
    and asks Gabi to grab enough data to trend some basic metrics on the recommendations
    system: number of recommendations per browse page, average hourly delta between
    expected “value” of all recommendations (probability that a customer will purchase
    a recommended product times the purchase price), and the observed value (total
    value of recommended products ultimately purchased). Imani grabs a copy of recent
    customer queries and product results in order to use them as a repeatable test
    of the recommendation system. The recommendation system uses the query that a
    user made, the page that they are on, and their purchase history (if we know it)
    to make recommendations, so this is the information that Imani will need to query
    the recommendation model directly.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 客户支持人员确认他们在刚过去的三周左右开始收到第一批零星投诉，但最近一周情况变得尤为尖锐。Imani认为这可能值得调查，并请求Gabi收集足够的数据以追踪推荐系统的一些基本指标：每个浏览页面的推荐数量，预期的所有推荐产品的平均每小时差异（客户购买推荐产品的概率乘以购买价格的预期“价值”），以及观察到的价值（最终购买的所有推荐产品的总价值）。Imani获取了最近客户查询和产品结果的副本，以便将它们用作推荐系统的可重复测试。推荐系统使用用户的查询、所在页面以及他们的购买历史（如果我们知道的话）来进行推荐，因此这是Imani将需要直接查询推荐模型的信息。
- en: Note
  id: totrans-188
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Without more information, we have to worry that by doing this, Imani may have
    violated the privacy of YarnIt’s customers. Search queries may contain protected
    information like user IP addresses, and any collection of search queries contains
    the additional problem that when correlated with each other for a given user,
    they reveal even more private information.^([7](ch11.xhtml#ch01fn128)) Imani definitely
    should have consulted with privacy and data protection professionals at YarnIt,
    or better yet, not even had direct, unmonitored access to the queries to make
    this kind of a mistake.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 没有更多信息的情况下，我们必须担心Imani可能侵犯了YarnIt客户的隐私。搜索查询可能包含受保护的信息，如用户IP地址，而任何搜索查询的收集还有另一个问题，即在给定用户的情况下，它们相互关联时会透露更多私人信息。（参见第7页，第11章，第128页脚注）Imani肯定应该在YarnIt咨询隐私和数据保护专家之后，或者更好的做法是根本不应该直接无监控地访问这些查询，以避免这种错误。
- en: Imani extracts out about 100,000 queries and page views and sets up a test environment
    where they can be played against the recommendation model. After a test run through
    the system, Imani has recommendations for all of the results and has stored a
    copy of the whole run so that it can be compared to future runs if they need to
    modify or fix the model itself.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Imani提取了大约100,000个查询和页面浏览数据，并建立了一个测试环境，可以对推荐模型进行测试。在系统的测试运行结束后，Imani得到了所有结果的推荐，并存储了整个运行的副本，以便将来需要修改或修复模型时进行比较。
- en: Gabi comes back and reports something interesting. Just over three weeks ago,
    the number of recommendations per page dropped slowly. For one week, the difference
    between expected value and observed value of each recommendation declined only
    a bit. By two weeks ago, the recommendation count plateaued at just under 50%
    lower than it has been. But then the value of the recommendations began to drop
    significantly compared to the expected value. That decline continued through last
    week. Two weeks ago, the observed value of the recommendations hit a low value
    of 40% of their expected value. Even more strangely, though, the gap between the
    expected value and observed value of the recommendations started narrowing a week
    ago, but at the same time the number of recommendations shown began falling again,
    so that now we seem to be showing very few recommendations at all, but those that
    we do show seem to be relatively accurately valued. Something is definitely wrong,
    and it is starting to look like it’s the model, but no clear diagnosis is flowing
    from this set of facts. [Figure 11-1](#the_number_of_expected_and_shown_recomm)
    shows a graphical representation of this set of changes over time.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Gabi 回来报告了一些有趣的事情。三周多前，每页推荐的数量开始缓慢下降。一周内，每个推荐的预期值和观察到的值之间的差距只略有下降。两周前，推荐数量停留在比过去少了将近50%的水平。但是随后推荐的价值开始显著下降，相比预期值。这种下降持续到上周。两周前，推荐的观察值达到了预期值的40%的低点。更奇怪的是，推荐的预期值和观察到的值之间的差距在一周前开始缩小，但同时推荐显示的数量再次下降，现在我们似乎根本没有显示多少推荐，但显示的推荐似乎相对准确地被价值化了。显然出现了问题，看起来是模型的问题，但目前还没有清晰的诊断结果。[图 11-1](#the_number_of_expected_and_shown_recomm)
    展示了这些变化随时间的图形表示。
- en: '![The number of expected and shown recommendations as well as their average
    expected value as they change over the period of the incident](Images/reml_1101.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![期望和显示推荐的数量以及它们随事件期间变化的平均期望值](Images/reml_1101.png)'
- en: Figure 11-1\. The number of expected and shown recommendations as well as their
    average expected value as they change over the period of the incident
  id: totrans-193
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-1\. 期望和显示推荐的数量以及它们随事件期间变化的平均期望值
- en: Imani continues to build the QA environment to test hypotheses. On a hunch,
    Gabi and Imani grab another 100,000 queries and page views from a month ago (before
    there was any evidence of a problem) as well as a snapshot of a model from every
    week in the last six weeks. Since the model retrains daily, even though the configuration
    of the model is exactly the same day after day, each day the model has learned
    from the things the users did the preceding day. Imani plans to run the old and
    new queries against each of the models and see what can be learned.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Imani 继续构建 QA 环境来测试假设。基于直觉，Gabi 和 Imani 又拿出了一个月前（在出现问题之前）的另外 100,000 个查询和页面视图，以及过去六周每周的一个模型快照。虽然模型每天都进行重新训练，但即使模型的配置每天完全相同，模型每天都会根据用户前一天的行为进行学习。Imani
    计划运行旧和新的查询与每个模型进行对比，看看可以学到什么。
- en: 'Gabi pushes for a quick test first: today’s queries versus a month-old model.
    Here’s the thinking: if that works, there’s a quick mitigation (restore the old
    model to serving) while troubleshooting continues. Gabi is focused on solving
    the lost revenue problem as quickly as possible. Imani runs the tests, and the
    results are not that promising and difficult to evaluate. The old model makes
    different recommendations than the new model and does seem to make slightly more
    of them. But the old model still makes many fewer recommendations against today’s
    queries than it did against the queries a month ago.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Gabi 主张先进行快速测试：今天的查询与一个月前的模型进行对比。思路是：如果这个方法有效，可以快速减轻问题（恢复旧模型提供服务），同时继续进行故障排除。Gabi
    的焦点是尽快解决收入损失问题。Imani 运行了测试，结果并不太令人满意，也很难评估。旧模型与新模型做出了不同的推荐，而且似乎稍微多一些。但是，与一个月前的查询相比，旧模型对今天的查询仍然做出了更少的推荐。
- en: Without something quite a bit more concrete, Gabi isn’t comfortable that changing
    the model to an older one will help. It might even do more damage to our revenue
    than the current model. Gabi decides to leave the recommendation system in its
    current state. It’s time to send another note to the folks in finance and payments
    about the current status of the troubleshooting. The payments and finance contacts
    both report that their bosses want a lot more information about what’s going on.
    Gabi’s colleague Yao, who has been shadowing the investigation and is familiar
    with the recommendations system, is drafted to handle communications. Yao promptly
    sets up a shared document with the state as it is known so far and links to specific
    dashboards and reports for more information. Yao also sends out a broad notice
    to senior folks in the company, notifying them of the outage and the current status
    of the investigation.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 没有更具体的依据，Gabi 不确定将模型改为旧模型是否有帮助。这甚至可能比当前模型对我们的收入造成更大的损害。Gabi 决定将推荐系统保持当前状态。现在是向财务和支付部门发送另一封关于故障排除当前状态的通知。支付和财务联系人都报告说，他们的老板想要更多关于发生情况的信息。Gabi
    的同事 Yao 一直跟踪调查，并熟悉推荐系统，被选中负责沟通。Yao 迅速建立了一个包含到目前为止已知状态的共享文档，并链接到特定的仪表板和报告以获取更多信息。Yao
    还向公司高级管理人员广发通知，告知他们停机情况及调查的当前状态。
- en: Imani and Gabi finish running the full sweep of old and new queries against
    older and newer models. The results are different for each pair, but nothing broadly
    systematic stands out that might explain the differences, and the general metrics
    match the weird pattern described previously. Imani decides to forget the model
    for a second and focus instead on the queries and page views themselves. Imani
    wants to figure out how they have changed in the last month, thinking maybe the
    problem is with the model’s ability to handle a shift in user behavior rather
    than something being wrong with the model itself.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Imani 和 Gabi 对旧模型和新模型运行了所有新旧查询的完整检查。每对的结果都不同，但没有明显的广泛系统性问题可以解释这些差异，而且总体指标与之前描述的奇怪模式相匹配。Imani
    决定暂时放下模型，转而专注于查询和页面访问本身。Imani 想弄清楚他们在过去一个月里如何改变，也许问题在于模型处理用户行为转变的能力，而不是模型本身有问题。
- en: Imani spot-checks the queries, but there are 100,000 of them in each of two
    batches, and whatever might be substantially different about them is not exactly
    obvious. Gabi, meanwhile, produces two reports. The first looks exclusively at
    the search queries that customers used to get to the product pages they ended
    up on. Gabi tokenizes the search queries and just counts the appearances of each
    word. While that’s running, Gabi takes the product pages the customers ended up
    on and assigns each to a large category (yarn, pattern, needles, accessories,
    gear), and then to subcategories within those, according to the product ontology
    (built by another team). Gabi lines up the two pairs of reports and looks for
    the biggest differences between the user behavior four weeks ago and today.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Imani 抽查了这些查询，但每批有 10 万条，两批都有，而它们之间可能存在的显著差异并不明显。与此同时，Gabi 制作了两份报告。第一份报告专门研究了客户用于访问最终产品页面的搜索查询。Gabi
    对搜索查询进行了标记，并简单统计了每个单词出现的次数。在此期间，Gabi 将客户最终访问的产品页面分配到大类（纱线、图案、针、配件、装备）中，并根据产品本体论（由另一个团队建立）将其进一步分到子类中。Gabi
    对比了四周前和今天用户行为的最大差异。
- en: 'The results are shockingly obvious: compared to four weeks ago, users have
    increasingly been looking for very different products. In particular, they are
    now looking for lightweight yarns, patterns for vests and smaller items, and smaller-gauge
    needles. Imani and Gabi stare at the results, and the problem suddenly seems so
    obvious. What happened four weeks ago? It got very hot in the northern hemisphere,
    where the majority of YarnIt’s customers are based. The heat came earlier than
    usual and significantly decreased the interest most customers had in knitting
    with chunky, warm wool.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显而易见：与四周前相比，用户越来越多地寻找完全不同的产品。特别是，他们现在寻找轻量级纱线、背心和小件物品的图案，以及较小规格的针。Imani 和 Gabi
    盯着结果看，问题突然变得如此明显。四周前发生了什么？北半球的热浪来得比往常早，并显著减少了大多数 YarnIt 客户对用粗毛线编织的兴趣。
- en: Imani points out, however, that that doesn’t explain the decrease in recommendations,
    only the change in what the recommendations should be. This still leaves the question
    of why aren’t we just recommending good hemp and silk yarn instead of wool? Gabi
    walks through a few queries to the recommendation engine by hand, using a command-line
    tool built for troubleshooting like this, and notices something. The recommendation
    engine test instance is set to log many more details than the production instance.
    One of the things it’s logging at a pretty high rate is that many candidate recommendations
    are disqualified from being shown to users because they’re out of stock.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Imani指出，这并不能解释推荐减少，只是推荐内容的变化。这仍然让人困惑，为什么我们不推荐优质的大麻和丝绸纱线，而是推荐羊毛呢？Gabi手动执行了几个查询到推荐引擎，使用了一个专为这样的故障排除而构建的命令行工具，并注意到了一些情况。推荐引擎的测试实例设置为记录比生产实例更多的细节。其中一个高频记录的情况是，许多推荐候选产品因为缺货而被取消显示给用户。
- en: Yao gets an update from Imani and Gabi, updates some of the shared doc, and
    publishes some information to the increasingly large group of people waiting to
    find out how the company is going to fix this problem. Someone from the retail
    team sees the note about many recommendations being out of stock and mentions
    to Yao that YarnIt did lose several important suppliers recently. One of the biggest,
    KnitPicking, is a popular supplier of fashionable yarns, many of which happen
    to be lightweight. In fact, KnitPicking was one of the largest suppliers of those
    weights of yarn at those price points. Yao gets more details on the timing of
    the supply problems, adds it to the doc, and reports back to Gabi.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Yao从Imani和Gabi那里得到了最新的消息，更新了一些共享文档，并向越来越多等待公司解决问题的人群发布了一些信息。来自零售团队的某人看到了关于许多推荐产品缺货的说明，并提到YarnIt最近确实失去了几个重要的供应商。其中最大的一个，KnitPicking，是一家流行的时尚纱线供应商，其中许多产品恰好是轻巧的纱线。事实上，KnitPicking是这些重量级和价格点的主要供应商之一。Yao获取了关于供应问题时间安排的更多细节，将其添加到文档中，并向Gabi汇报了情况。
- en: Note
  id: totrans-202
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This is an interesting state for the incident to be in. We have a likely root
    cause but no obvious way to mitigate it or resolve it.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有趣的问题状态。我们有一个可能的根本原因，但没有明显的解决或减轻它的方法。
- en: Imani and Gabi have a solid hypothesis on the weird recommendations. The recommendations
    system is configured with a minimum threshold of expected value for each recommendation
    it shows so that it won’t show terrible recommendations when it doesn’t have any
    good ones. But it takes a while for a recommendation’s expected value to adjust,
    especially when it hasn’t been shown often recently. Imani concludes that the
    system quickly learned that few people wanted heavyweight wool yarns. But once
    those were understood to be poor recommendations, it took a while for the system
    to cycle through many other products until it finally concluded that we really
    don’t have very much stock in the products that our customers currently want to
    buy.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Imani和Gabi对异常推荐有了一个坚实的假设。推荐系统配置了对每个推荐产品显示的最低预期值阈值，这样在没有好的推荐产品时就不会显示糟糕的推荐。但是，一个推荐产品的预期值调整需要一段时间，特别是当最近它没有经常被显示时。Imani得出结论，系统很快学到了很少人想要重量级羊毛纱线。但一旦这些产品被认定为不良推荐，系统在最终确认我们当前客户真正想购买的产品库存非常有限之前，需要很长时间循环检查许多其他产品。
- en: Gabi, Imani, and Yao schedule a meeting with the heads of retail and finance
    to discuss what they have learned and ask for guidance on how to proceed. Oddly,
    the current state seems to be that the recommendations system is now moderately
    good for current circumstances. It recommends few products for most customers
    on most page views since we don’t have much of what most of our customers want
    right now. The loss of revenue was as much due to supply problems as it ever was
    due to the recommendations system. Presented with the facts as they are known,
    the head of retail asks the team to verify its findings to be certain but agrees
    that fixing the supply problem is the highest priority. The finance lead nods
    and goes off to sharply reduce projections for how much money we will make this
    quarter. There is no obvious change to the recommendations model that can improve
    the situation, given our supply shortfalls and the way that the weather has impacted
    our customers’ preferences.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: Gabi、Imani和Yao安排了一次与零售和财务负责人的会议，讨论他们所学到的内容，并寻求如何继续前进的指导。奇怪的是，目前的情况似乎是推荐系统现在在当前情况下表现得相当不错。由于我们目前没有大多数客户想要的产品，它对大多数客户的大多数页面浏览推荐很少产品。收入损失不仅是由于供应问题，也是由于推荐系统。在以已知的事实为基础的情况下，零售负责人要求团队核实其发现以确保准确，但同意解决供应问题是最优先的任务。财务主管点头同意，然后立即大幅减少本季度的盈利预期。鉴于我们的供应短缺以及天气对客户偏好的影响方式，很明显推荐模型没有明显的改变能够改善情况。
- en: Note
  id: totrans-206
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: At this point, the outage is probably over, since we’ve decided not to change
    the system or model.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，停机很可能已经结束，因为我们决定不改变系统或模型。
- en: 'The team gathers the next day to review what happened and what they can learn
    from it. Here are some of the proposed follow-up actions:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 第二天，团队齐聚一堂，回顾所发生的事情，并从中学习。以下是一些提议的后续行动：
- en: Monitor and graph the number of recommendations per page view, revenue per recommendation,
    and percentage gap between expected value of all recommendations per hour and
    the actual sales value.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控并绘制每页浏览的推荐数量、每个推荐的收入以及预期所有推荐每小时的预期价值与实际销售价值之间的百分比差距。
- en: 'Monitor and alert on high rates of candidate product recommendations unavailable
    (for whatever reason: out of stock, legal restrictions, etc.). We can also consider
    monitoring stock levels directly if we can find a high-signal way to do so, although
    ideally this would be the responsibility of a supply-chain or inventory management
    team. We should be careful here not to be overbroad in our monitoring of other
    teams’ work to avoid burdening our future selves with excessive alerting. We should
    think about monitoring user query behavior, in aggregate, directly as well so
    that we might be able to detect significant shifts in query topics and distribution.
    This kind of monitoring is generally good for graphing but not for alerting—it’s
    just too hard to get right. Finally, we can work more closely with the customer
    support team to get them tools to investigate user reports like these. If the
    support team had a query replicator/analyzer/logger, it may have been able to
    generate a considerably more detailed report than “customers say they get weird
    recommendations.” This kind of “empower another team to be more effective” effort
    often pays off much more than pure automation.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于候选产品推荐高失效率（无论出于何种原因：缺货、法律限制等），应进行监控和警报。如果可以找到高信号方式，我们还可以考虑直接监控库存水平，尽管最理想的情况是由供应链或库存管理团队负责。在这里，我们应当小心，避免对其他团队的工作进行过度监控，以免未来过多的警报负担我们自己。我们应该考虑直接监控用户查询行为的总体情况，这样我们可能能够检测到查询主题和分布的显著变化。这种监控通常适合绘图，但不适合警报，因为它很难实现正确。最后，我们可以更密切地与客户支持团队合作，为他们提供调查此类用户报告的工具。如果支持团队有一个查询复制器/分析器/记录器，可能会生成比“客户说他们得到奇怪推荐”更详细的报告。这种“增强另一个团队效率”的努力通常比纯自动化产生更大回报。
- en: Review ways to get the model to adjust more quickly. Taking so many days to
    converge on the right recommendation behavior isn’t reasonable. The overall stability
    of the model has been perceived to be of value, but in this case it ended up showing
    bad recommendations to users for many days and making it harder for the production
    team to troubleshoot problems with it. Imani wants to find a way to improve the
    responsiveness to new situations without making the model overly unstable.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查如何使模型更快地调整。花费如此多的时间才能收敛于正确的推荐行为是不合理的。总体上，模型的稳定性被认为具有价值，但在这种情况下，它最终向用户显示了糟糕的推荐，使生产团队更难以解决与其相关的问题。伊曼尼希望找到一种方法，在不使模型过于不稳定的情况下提高对新情况的响应能力。
- en: 'We should treat this as an opportunity to think about what the model should
    do when it doesn’t have any good recommendations. This is fundamentally a product
    and business problem rather than an ML engineering problem: we need to figure
    out the behavior we want the model to exhibit and the kinds of recommendations
    we think we should surface to users under these circumstances. At a high level,
    we would like to keep making money at a reasonable rate with good margins, even
    when we do not have the products that our customers want the most. Figuring out
    whether there’s a way to identify a product recommendation strategy to do that
    is a hard problem.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该把这视为一个思考模型在没有任何好的推荐时应该怎么做的机会。这从根本上来说是一个产品和业务问题，而不是 ML 工程问题：我们需要弄清楚我们希望模型展示的行为以及在这种情况下我们认为应该向用户展示的推荐类型。在高层次上，我们希望以合理的利润率继续赚钱，即使我们没有客户最想要的产品。弄清楚是否有一种方法来确定产品推荐策略来解决这个难题是一个棘手的问题。
- en: Finally, it’s clear that some exogenous data to the ML system should be always
    available to make troubleshooting situations like these easier. In particular,
    the production engineers should have revenue results in aggregate and broken down
    by product category in the product catalog, by geography, and by the original
    source of the user viewing the product (search result or recommendation or home
    page).
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，显然 ML 系统需要一些外生数据始终可用，以便更轻松地进行类似的故障排除。特别是，生产工程师应该在产品目录中按产品类别、地理位置和用户查看产品的原始来源（搜索结果、推荐或主页）的汇总和分解中始终有收入结果。
- en: Many of these follow-ups are quite ambitious and unlikely to be completed in
    any reasonable amount of time. Some of them, though, can be done fairly quickly
    and should make our system more resilient to problems like this in the future.
    As always, figuring out the right balance and understanding the trade-offs in
    implementing those is precisely the art of good follow-up, though we should favor
    the ones that make problems faster to troubleshoot.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 许多这些后续措施非常雄心勃勃，不太可能在任何合理的时间内完成。其中一些，但可以相对较快地完成，并且应该使我们的系统在未来更具抗干扰能力。正如往常一样，找到正确的平衡并理解实施这些措施的权衡是良好后续措施的本质，尽管我们应该偏爱那些使问题更容易排查的措施。
- en: Stages of ML incident response for story 3
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ML 事件响应阶段3
- en: 'Although this incident had a somewhat different trajectory from that of the
    previous two stories, we can see many of the same themes appear. Rather than repeat
    them, let’s try to focus on any additional lessons we can learn from this outage:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管此次事件与前两个案例的轨迹略有不同，但我们可以看到许多相同的主题出现。与其重复它们，让我们试着集中精力从这次中断中学到的任何额外教训：
- en: Pre-incident
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 事前准备
- en: No obvious significant failure in the architecture or implementation of our
    system led to this outage, which is interesting. We definitely could have made
    choices that would have made the outage progress differently, and more smoothly
    for our users, but in the end we cannot recommend products we don’t have, and
    sales were going to go down. There may be a model that could produce better recommendations
    under these circumstances (rapid change in demand combined with an inventory problem),
    but that falls more under the heading of continuous model improvement rather than
    incident avoidance.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们系统的架构或实施中没有明显的重大故障导致这次中断，这很有趣。我们确实可以做出不同选择，使中断进展不同，并且更顺利地为我们的用户服务，但最终我们不能推荐我们没有的产品，销售肯定会下降。在这种情况下可能会有一个模型能够在这些情况下产生更好的推荐（需求快速变化与库存问题结合），但这更多地属于持续模型改进而不是事故避免的范畴。
- en: Trigger
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 触发器
- en: The weather changed, and we lost a supplier. This is a tough combination of
    events to directly detect, but we can certainly try with some of the monitoring
    efforts that were picked.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 天气变化，并且我们失去了一个供应商。这是一种难以直接检测到的事件组合，但我们可以尝试使用一些选择的监控方法来进行检测。
- en: Outage begins
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 停机开始
- en: In some ways, there is no outage. That is what is most interesting about this
    incident. An outage can be understood to be a failing of the system such that
    it yields an incorrect result. It’s appropriate to describe the “weird recommendations”
    period as an outage, but one with only minimal costs since the main impact was
    probably to annoy our users a bit. But the loss in revenue wasn’t caused by the
    recommendations model nor was it preventable by it. Likewise, the outage won’t
    end until the weather changes or we source a new supply of lightweight yarns.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 从某些方面来看，这并不是停机。这是此次事件最有趣的地方。停机可以被理解为系统的失效，导致其产生错误结果。适当地描述“奇怪推荐”期间的时期可以作为停机的描述，但成本仅为最小，因为主要影响可能只是稍微让我们的用户感到恼火。但是收入损失并非由推荐模型造成，也无法通过它来预防。同样，直到天气改变或我们获取新的轻量级纱线供应之前，停机都不会结束。
- en: Detection
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 检测
- en: The earliest sign of the outage was the customer complaints about weird recommendations.
    That’s the kind of noisy signal that probably cannot be relied on, but as noted,
    we can get the support team better tools so that it can report problems in more
    detail. Other, less obvious, signals may have had a higher accuracy that we could
    use for detection, but even figuring them out is a data science problem.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 此次停机的最早迹象是关于奇怪推荐的客户投诉。这是一种可能不能依赖的嘈杂信号，但正如所指出的，我们可以为支持团队提供更好的工具，以便能够更详细地报告问题。其他不那么明显的信号可能具有更高的准确性，我们可以用于检测，但即使弄清楚它们也是一个数据科学问题。
- en: Troubleshooting
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 故障排除
- en: 'The process of investigating this outage includes some of the hallmarks of
    many ML-centric outage investigations: detailed probing at a particular model
    (or set of models or modeling infrastructure) coupled with broad investigation
    of changes in the world around us. The investigation might have proceeded more
    quickly if Sam had followed up on the detailed timeline of revenue from the finance
    team. With the breakdown of revenue changes by product, category, or partner,
    we should have been able to see a sharp shift in consumer behavior combined with
    a sharp rise and then drop in sales from KnitPicking (as our stock in its products
    ran low). It is sometimes difficult to remember that clarity about an outage might
    come from looking more broadly at the whole situation rather than more carefully
    at a single part of it.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 调查此次停机的过程包括许多以机器学习为中心的停机调查的特征：在特定模型（或一组模型或建模基础设施）上进行详细探索，同时广泛调查我们周围环境的变化。如果Sam对财务团队的详细收入时间表进行了跟进，调查可能会更快地进行下去。通过按产品、类别或合作伙伴细分的收入变化的详细数据，我们本应该能够看到消费者行为的急剧变化，以及KnitPicking销售的急剧上升和下降（因为我们的产品库存短缺）。有时候很难记住，关于停机的清晰度可能来自于更广泛地观察整个情况，而不是更仔细地观察其单个部分。
- en: Mitigation/resolution
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解/解决
- en: 'Some outages have no obvious mitigation. This is tremendously disappointing,
    but occasionally there’s no quick way to restore the system to whatever properties
    it previously had. Moreover, the only way to actually resolve the core outage,
    and get our revenue back on track, is to change what our users want or to fix
    the products that we have available to sell. One thing the team didn’t think about,
    probably in part because it was focused on troubleshooting the model and resolving
    the ML portion of the outage, was that there may have been other, non-ML ways
    of mitigating the outage: what if our system showed out-of-stock recommendations
    and invited customers to be notified when we had those (or similar) products available?
    In that case, we might have avoided some of the lost revenue by shifting it forward
    in time and also reduced the weird recommendations served to customers. Sometimes
    mitigations can be found outside of our system.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 有些停机没有明显的缓解措施。这非常令人失望，但偶尔没有快速恢复系统到先前状态的方法。而且，实际解决核心停机并让我们的收入恢复正轨的唯一方法是改变我们的用户需求或修复我们可供销售的产品。团队没有考虑的一件事，可能部分原因是因为它专注于排除模型和解决停机的机器学习部分，那就是可能有其他非机器学习方式来缓解停机：如果我们的系统显示缺货推荐并邀请客户在我们有这些（或类似）产品时通知他们呢？在这种情况下，我们可能通过将损失的收入向前移动并减少向客户提供的奇怪推荐，从而避免了一些损失。有时候，缓解措施可以在我们的系统之外找到。
- en: Follow-up
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 后续处理
- en: 'In many cases, follow-up from an ML-centric incident evolves into a phase that
    doesn’t resemble “fix the problem” so much as “improve the performance on the
    model.” Post-incident follow-up often devolves into longer-term projects, even
    for non-ML-related systems and outages. But the boundary between a “fix” and “ongoing
    model improvement” is particularly fuzzy for ML systems. One recommendation: first
    define your model improvement process clearly. Track efforts that are underway
    and define the metrics you plan to use to guide model quality improvement. Once
    an incident occurs, take input from the incident to add, update, or reprioritize
    existing model improvement work. For more on this, see [Chapter 5](ch05.xhtml#evaluating_model_validity_and_quality).'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，从以机器学习为中心的事故的后续发展成为一个阶段，这个阶段不再像“修复问题”那样，而更像是“改善模型性能”。事故后的跟进往往演变成长期项目，即使对于非机器学习相关的系统和故障也是如此。但对于机器学习系统来说，“修复”和“持续改进模型”之间的界限特别模糊。一个建议是：首先清晰定义您的模型改进流程。跟踪正在进行的工作，并定义计划用于指导模型质量改进的指标。一旦发生事故，从事故中获取输入以添加、更新或重新排列现有的模型改进工作。有关更多信息，请参见[第5章](ch05.xhtml#evaluating_model_validity_and_quality)。
- en: These three stories, however different in detail, demonstrate common patterns
    for ML incidents in their detection, troubleshooting, mitigation, resolution,
    and ultimately post-incident follow-up actions. Keeping these in mind, it is useful
    to take a broader view of what is happening to make these incidents somewhat different
    from other outages in distributed computing systems.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这三个故事在细节上有所不同，展示了机器学习事故在检测、故障排除、缓解、解决以及最终事故后跟进行动中的共同模式。记住这些对于理解这些事件如何在某种程度上与分布式计算系统中的其他故障有所不同是有用的。
- en: ML Incident Management Principles
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习事故管理原则
- en: While each of these stories is specific, many of their lessons remain useful
    across various events. In this section, we will back away from the immediacy of
    the stories and distill what they, and the rest of our experience with ML systems
    outages, can teach us in the long term. We also offer a specific list of recommendations
    for you to follow to get ready for and respond to incidents.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些故事各具特定性，但它们的许多教训在各种事件中仍然有用。在本节中，我们将远离这些故事的紧迫性，并概括它们以及我们在机器学习系统故障中的其余经验可以教给我们的东西。我们还为您提供了一份具体的建议清单，供您准备和应对事故使用。
- en: Guiding Principles
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指导原则
- en: 'Three overarching themes that appear across ML incidents are so common that
    we list them here as guiding principles:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 三个贯穿机器学习事故的主题如此常见，我们将它们列为指导原则：
- en: Public
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 公共
- en: ML outages are often detected first by end users, or at least at the very end
    of the pipeline, all the way out in serving or integrated into an application.
    This is partly true because ML model performance (quality) monitoring is difficult.
    Some kinds of quality outages are obvious to end users but not obvious to developers,
    decision makers, or SREs. Typical examples include anything that affects a small
    sample of users 100% of the time. Those users get terrible performance from our
    systems all the time, but unless we happen to look at a slice of just those users,
    aggregate metrics probably won’t show anything wrong.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的故障通常首先由最终用户检测到，或者至少在流水线的最末端，在服务中或集成到应用程序中。这在一定程度上是因为机器学习模型性能（质量）监控很困难。某些类型的质量故障对最终用户是明显的，但对开发人员、决策者或SREs并不明显。典型的例子包括任何影响小部分用户百分之百时间的情况。这些用户始终从我们的系统中获得糟糕的性能，但除非我们碰巧查看到这些用户的一小部分，否则聚合指标可能不会显示任何问题。
- en: Fuzzy
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊
- en: 'ML outages are less sharply defined in two dimensions: in impact and in time.
    With respect to time, determining the precise start and end of an ML incident
    is often difficult. Although there may well be a traceable originating event,
    establishing a definitive causal chain can be impractical. ML outages are also
    unclear in impact: it can be hard to see whether a particular condition of an
    ML system is a significant outage or just a model that is not yet as sophisticated
    or effective as we would like it to be. One way to think about this is that every
    model starts out very basic, doing only some portion of what we hope it can do
    one day. If our work is effective, the model gets better over time as we refine
    our understanding of how to model the world and improve the data the model uses
    to do so. But there may be no sharp transition between “bad” and “good” for models.
    There is often only “better” and “not quite as good.” The line between “broken”
    and “could be better” is not always easy to see.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）中断在两个方面不太明确：在影响和时间上。关于时间，确定ML事件的确切开始和结束通常很困难。虽然可能有可追溯的起始事件，但建立起明确的因果链可能是不切实际的。ML中断在影响上也不明确：很难看出ML系统的特定条件是重大中断，还是仅仅是模型尚未像我们希望的那样复杂或有效。一个思考方式是，每个模型最初都非常基础，只能完成我们希望它有朝一日能完成的部分工作。如果我们的工作有效，随着我们改进对建模世界的理解和改进模型使用的数据，模型会随着时间而变得更好。但是，模型之间可能没有“糟糕”和“好”的明显过渡。通常只有“更好”和“不太好”。“损坏”和“可以改进”的界限并不总是容易看到。
- en: Unbounded
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 无限制。
- en: ML outage troubleshooting and resolution involve a broad range of systems and
    portions of the organization. This is a consequence of the way that ML systems
    span more technical, product, and business arms within organizations than non-ML
    systems. This isn’t to say that ML outages are necessarily more costly or more
    important than other outages—only that understanding and fixing them usually involves
    broader organizational scope.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ML中断的故障排除和解决涉及广泛的系统和组织部分。这是ML系统跨越组织内技术、产品和业务领域的方式的结果，比非ML系统更广泛地涉及组织范围。这并不是说ML中断一定比其他中断更昂贵或更重要——只是理解和修复它们通常涉及更广泛的组织范围。
- en: With the three big principles in mind, the rest of this section is organized
    by role. As we have stated, many people working on ML systems play multiple roles.
    It is worth reading the principles for each role, whether you expect to do that
    work or not. By structuring the lessons by role, we can bring out the particular
    perspective and organizational placement particular to that role.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑这三大原则的基础上，本节的其余部分按角色组织。正如我们所述，许多在ML系统上工作的人扮演多种角色。无论你是否期望做这项工作，阅读每个角色的原则都是值得的。通过按角色结构化课程，我们可以突出特定于该角色的特定视角和组织安置。
- en: Model Developer or Data Scientist
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型开发者或数据科学家。
- en: People working at the beginning of the ML system pipeline sometimes don’t like
    to think about incidents. To some, that seems like the difficult “operations”
    work that they would rather avoid. If ML ends up mattering in an application or
    organization, however, the data and modeling staff will absolutely be involved
    in incident management in the end. They can do certain things to get ready for
    that.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在ML系统管道的早期工作的人有时不喜欢考虑事故。对一些人来说，这似乎是他们宁愿避免的困难的“运维”工作。然而，如果ML最终在应用或组织中很重要，数据和建模人员绝对会参与最终的事故管理。他们可以采取某些措施来为此做好准备。
- en: Preparation
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备工作。
- en: 'A few concrete steps, taken in advance, can significantly improve the ability
    of an organization to respond to an incident. Among these are the following:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 提前采取几个具体步骤可以显著提高组织应对事故的能力。其中包括以下几点：
- en: Organize and version all models and data
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 组织和版本化所有模型和数据。
- en: 'This is the most important step that data and modeling staff can take to get
    ready for forthcoming incidents. If you can, put all training data in a versioned
    feature store, with clear metadata spelling out where all the data came from and
    which code or teams are responsible for its creation and curation. That last part
    is often skipped: we will end up performing transformations on the data we put
    into the feature store, and it is critical that we track and version the code
    that performs those transformations. Additionally, if we can, we should store
    intermediate artifacts from all training runs in the metadata system as well.
    Finally, it is useful to store historical versions of the models in ready-to-serve
    format. As you saw, these can be terribly useful for quick mitigation in the case
    of a rapid and unexplained decline in model quality.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据和建模人员为准备未来事件所能采取的最重要步骤。如果可能的话，将所有训练数据放入一个版本化的特征存储中，并清楚地记录元数据，说明数据的来源以及负责其创建和管理的代码或团队。通常会忽略到最后这部分内容：我们最终会对放入特征存储的数据执行转换操作，因此跟踪和版本化执行这些转换的代码至关重要。此外，如果可能的话，我们还应该在元数据系统中存储所有训练运行的中间产物。最后，将模型的历史版本存储为可即时服务的格式是很有用的。正如你所见，这些可以在模型质量迅速且无法解释地下降时，对快速缓解非常有用。
- en: Specify an acceptable fallback
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 指定可接受的备用方案
- en: When we first start, the acceptable fallback might be “whatever we’re doing
    now” if we already have a heuristic that works well enough. In a recommendations
    case, this might be “just recommend the most popular products” with little or
    no personalization. The challenge is that as our model gets better, the gap between
    that and what we used to do may get so large that the old heuristic no longer
    counts as a fallback. For example, if our personalized recommendations are good
    enough, we may start attracting multiple (potentially very different) groups of
    users to our applications and sites.^([8](ch11.xhtml#ch01fn129)) If our fallback
    recommendation is “whatever is popular,” that might produce truly awful recommendations
    for every different subgroup using the site. If we become dependent on our modeling
    system, the next step is to save multiple copies of our model and periodically
    test falling back to them. This can be integrated into our experimentation process
    by having several versions of the model in use at any one time, with (for example)
    a primary, a new, and an old model.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始时，可接受的备用方案可能是“我们现在正在做的任何事情”，如果我们已经有一个足够好用的启发式方法。在推荐案例中，这可能是“只推荐最流行的产品”，几乎没有个性化。挑战在于，随着我们的模型变得更好，原有的启发式方法与我们所做的可能会有很大差距，以至于旧的启发式方法不再适用。例如，如果我们的个性化推荐足够好，我们可能会吸引多个（潜在上非常不同的）用户群体来使用我们的应用和网站。^([8](ch11.xhtml#ch01fn129))
    如果我们的备用推荐是“流行的任何东西”，那么对于使用网站的每个不同子群体，这可能会产生真正糟糕的推荐。如果我们依赖于我们的建模系统，下一步是保存多个模型副本，并定期测试是否可以回退到它们。通过在任何时候使用几个版本的模型（例如主要、新旧模型），可以将此过程集成到我们的实验过程中。
- en: Decide on useful metrics
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 决定有用的度量标准
- en: The final bit of preparation that is most useful is to think carefully about
    model quality and performance metrics. We need to know whether the model is working,
    and model developers will have a set of objective functions that they use to determine
    this. Ultimately, we want a set of metrics that detect when the model stops working
    well that are independent of how it is implemented. This turns out to be a more
    challenging task than it might seem, but the closer we can approximate this, the
    better. [Chapter 9](ch09.xhtml#monitoring_and_observability_for_models) addresses
    the topic of selecting these metrics in a little more detail.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 最有用的最后一部分准备工作是仔细考虑模型质量和性能指标。我们需要知道模型是否有效，而模型开发人员会使用一组客观函数来确定这一点。最终，我们希望有一组能够检测模型停止有效运行的指标，而这些指标与其实现方式无关。这实际上比看起来更具挑战性，但我们越接近这个目标，效果就越好。[第9章](ch09.xhtml#monitoring_and_observability_for_models)稍微详细地讨论了选择这些指标的主题。
- en: Incident handling
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事故处理
- en: 'Model developers and data scientists play an important role during incidents:
    they explain the models as they currently are built. They also generate and validate
    hypotheses about what might be causing the problems we are seeing.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件发生期间，模型开发人员和数据科学家扮演着重要角色：他们解释当前构建的模型。他们还产生并验证关于可能导致我们所见问题的假设。
- en: To play that role, model and data folks need to be reachable; they should be
    available off-hours on an organized schedule such as an on-call rotation or equivalent.
    They should not expect to be woken up frequently, but they might well be indispensable
    if they are.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 为了发挥这种作用，模型和数据的人员需要保持可接触性；他们应该按照值班轮换或等价的有组织时间表在非工作时间内可用。他们不应频繁被唤醒，但如果必要的话，他们可能是不可或缺的。
- en: Finally, during incident handling and triage, model and data staff may be called
    upon to do custom data analysis and even to generate variants of the current model
    to test hypotheses. They should be ready to do so, but also prepared to push back
    on any requests that require violating user privacy or other ethics principles.
    See [“The Ethical On-Call Engineer Manifesto”](#the_ethical_on_call_engineer_manifesto)
    for more detail on this idea.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在事件处理和分析期间，可能需要模型和数据人员进行定制数据分析，甚至生成当前模型的变体来测试假设。他们应该准备好这样做，但也应准备好拒绝任何违反用户隐私或其他伦理原则的请求。详见[“伦理值班工程师宣言”](#the_ethical_on_call_engineer_manifesto)以获取更多关于这个想法的详细信息。
- en: Continuous improvement
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持续改进
- en: 'Model and data staff should work to shorten the model quality evaluation loop
    as a valuable but not dominant priority. [Chapter 5](ch05.xhtml#evaluating_model_validity_and_quality)
    provides more details, but the idea here is similar to any troubleshooting: the
    shorter the delay between a change and an evaluation of that change, the faster
    we can resolve a problem. This approach will also pay notable benefits to the
    ongoing development of models, even when we’re not having an outage. To do this,
    we’ll have to justify the staffing and machine resources to get the training iterations,
    tools, and metrics required. It won’t be cheap, but if we’re investing in ML to
    create value, this is one of the best ways for this part of our team to deliver
    that value, with the least risk of multiday outages.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 模型和数据的工作人员应致力于缩短模型质量评估循环，作为一个重要但不主导的优先事项。[第 5 章](ch05.xhtml#evaluating_model_validity_and_quality)
    提供了更多细节，但这里的想法类似于任何故障排除：改变与评估之间的延迟越短，我们就能更快地解决问题。这种方法也将显著促进模型的持续发展，即使我们没有故障期间也是如此。为了做到这一点，我们必须为获取训练迭代、工具和所需的指标来证明人员配备和机器资源做好准备。这不会便宜，但如果我们投资于机器学习以创造价值，这是我们团队的这一部分提供该价值的最佳方式之一，风险最小的方式。
- en: Software Engineer
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 软件工程师
- en: Some, but not all, organizations have software engineers who implement the systems
    software to make ML work, glue the parts together, and move the data around. Whoever
    is playing this role can significantly improve the odds that incidents go better.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 一些组织有软件工程师负责实现系统软件以使机器学习工作，将各部分粘合在一起，并移动数据。扮演这一角色的人可以显著提高事故处理的成功率。
- en: Preparation
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备工作
- en: Data handling should be clean, with clear provenance and as few versions of
    the same data as possible. In particular, when there are multiple “current” copies
    of the same data, this can result in subtle errors detected only in drops in model
    quality or unexpected errors. Data versioning should be explicit, and data provenance
    should be clearly labeled and discoverable.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理应该干净利落，具有清晰的来源和尽可能少的数据版本。特别是，在存在多个“当前”副本的情况下，这可能导致仅在模型质量下降或意外错误中才能检测到的微妙错误。数据版本应明确，数据来源应清晰标记和可发现。
- en: It is helpful if model and binary rollouts are separate and separable. The binaries
    that do the inference in serving, for example, and the model that they are reading
    from, should be pushed to production independently, with quality evaluations conducted
    each time. This is because binaries can affect quality subtly, as can models.
    If the rollouts are coupled, troubleshooting can be much more difficult.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型和二进制部署分开且可分离，这将非常有帮助。例如，在服务中执行推理的二进制文件和它们所读取的模型应该独立地推送到生产环境中，并且每次都进行质量评估。这是因为二进制文件和模型都可能在微妙地影响质量。如果部署是耦合的，故障排除将会变得更加困难。
- en: Feature handling and use in serving and training should be as consistent as
    possible. Some of the most common and most basic errors are differences in feature
    use between training and serving (called *training-serving skew*). These include
    simple differences in quantization of a feature, or even a change in certain features’
    contents altogether (a feature that used to be income becomes zip code, and chaos
    ensues immediately, for example).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务和训练中的特征处理和使用应尽可能一致。一些最常见和最基本的错误之一是训练和服务之间特征使用的差异（称为*训练-服务偏差*）。这些包括特征量化的简单差异，甚至某些特征内容的改变（例如曾经是收入的特征变成了邮政编码，这会立即导致混乱）。
- en: Implement or develop tooling as much as possible (sometimes test development
    is done by specialist test engineers, but this is organizationally specific).
    We will want tooling for model rollout and model rollback and for binary rollout
    and rollback. We should have tools to show the versions of the data (reading from
    the metadata) in every environment, and tools for customer support staff or production
    engineers (SREs) to read data directly for troubleshooting purposes (with appropriate
    logging and audit trails to respect privacy and data integrity guarantees). Where
    possible, find tooling that exists for your framework and environment already,
    but plan to implement at least some. The more tooling that exists that works,
    the lower the burden on software engineers during incidents.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 尽可能地实现或开发工具（有时测试开发由专门的测试工程师完成，但这取决于组织）。我们将需要用于模型部署和回滚、二进制部署和回滚的工具。我们应该有工具显示每个环境中数据版本（从元数据中读取），以及为客户支持人员或生产工程师（SRE）直接读取数据以进行故障排除的工具（带有适当的日志记录和审计追踪以尊重隐私和数据完整性保证）。在可能的情况下，找到已存在于您的框架和环境中的工具，但计划至少实施一些。存在有效运行的工具越多，软件工程师在事故发生时的负担就越低。
- en: Incident handling
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事故处理
- en: 'Software engineers should be a point of escalation during incidents, but if
    they have done their jobs well, they should be alerted only rarely. Software failures
    will occur in the model servers, data synchronizers, data versioners, model learners,
    model training orchestration software, and feature store. But as our system gets
    more mature, we will be able to treat this as a few large systems that can be
    well managed: a data system (feature store), a data pipeline (training), an analytics
    system (model quality), and a serving system (serving). Each of these is only
    slightly harder for ML than for non-ML problems, and so software engineers who
    do this well may have very low production responsibilities.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 软件工程师在事故期间应作为升级点，但如果他们的工作做得好，他们应该很少接到警报。软件失败会发生在模型服务器、数据同步器、数据版本控制器、模型学习者、模型训练编排软件和特征存储中。但随着我们的系统变得更加成熟，我们将能够将其视为几个可以有效管理的大系统：一个数据系统（特征存储）、一个数据流水线（训练）、一个分析系统（模型质量）和一个服务系统（服务）。对于ML而言，每一个问题都只比非ML问题稍微难一点，因此做得好的软件工程师在生产方面的责任可能非常低。
- en: Continuous improvement
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持续改进
- en: Software engineers should work regularly with model developers, with SREs/production
    engineers, and with customer support in order to understand what is missing and
    how the software should be improved. Most common improvements will involve resilience
    to big shifts in data and thoughtful exporting of software state for more effective
    monitoring.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 软件工程师应定期与模型开发人员、SRE/生产工程师以及客户支持合作，以了解缺失的内容以及软件应该如何改进。最常见的改进将涉及对数据大变动的弹性和对软件状态的精心导出，以实现更有效的监控。
- en: ML SRE or Production Engineer
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML SRE或生产工程师
- en: ML systems are run by someone. Larger organizations may have dedicated teams
    of production engineers or SREs who take responsibility for managing these systems
    in production.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ML 系统由某人运行。较大的组织可能会有专门的生产工程师或SRE团队负责管理这些系统的生产环境。
- en: Preparation
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备工作
- en: Production teams should be staffed with sufficient spare time to handle incidents
    when they come up. Many production teams fill their plate with projects, ranging
    from automation to instrumentation. Project work like this is enjoyable and often
    results in lasting improvements in the system, but if it is high priority and
    deadline driven, it will always suffer during and after an incident. If we want
    to execute project work effectively, we need to have spare capacity.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 生产团队在处理突发事件时应有足够的空闲时间。许多生产团队的工作任务从自动化到仪表化项目不等。像这样的项目工作既令人愉快，又常常在系统中带来持久的改进，但如果它们被高优先级和截止日期驱动，那么在和之后的事件中它们总是会受到影响。如果我们希望有效地执行项目工作，我们需要有备用容量。
- en: We will also need training and practice. Once the system is mature, large incidents
    may happen infrequently. The only way that our on-call staff will gain fluency
    with the incident management process itself, but also with our troubleshooting
    tools and techniques, is to practice. Good documentation and tooling helps, but
    not if on-call staff can’t understand the docs or find the dashboards. Some systems
    are sufficiently dynamic as to provide their own, regular, opportunities for this
    practice (this is a polite way of noting that some of our systems are broken fairly
    often). In this case, teams should be sure to regularly share the incident management
    lead role when the opportunity arises. For systems where this is not the case,
    scheduling regular, intentional, small breakages during business hours is one
    good approach.^([9](ch11.xhtml#ch01fn130))
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要培训和实践。一旦系统成熟，大型事件可能不经常发生。我们值班人员熟悉处理事件管理过程本身以及我们的故障排除工具和技术的唯一方法是实践。良好的文档和工具可以帮助，但如果值班人员无法理解文档或找到仪表板，则没有用处。有些系统足够动态，以至于提供自己的定期实践机会（这是指出某些系统经常出现故障的委婉方式）。在这种情况下，团队应确保在机会出现时定期分享事件管理主导角色。对于那些情况不是这样的系统，安排在工作时间定期意图中断是一个不错的方法。^([9](ch11.xhtml#ch01fn130))
- en: Production teams should conduct regular architectural reviews of the system
    to think through the biggest likely weak spots and address them. These might be
    unnecessary data copies, manual procedures, single points of failure, or stateful
    systems that cannot easily be rolled back.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 生产团队应定期进行系统架构审查，以思考最可能的弱点并加以解决。这些可能是不必要的数据副本、手动过程、单点故障或不能轻易回滚的有状态系统。
- en: Setting up monitoring and dashboards is a topic unto itself and is covered more
    extensively in [Chapter 9](ch09.xhtml#monitoring_and_observability_for_models).
    For now, we should note that monitoring distributed throughput pipelines is extremely
    difficult. Since progress is not reducible to a single value (the oldest data
    we’re still reading, newest data we have read, how fast we’re training, how much
    data is left to read), we need to make decisions based on changes in data distribution
    in the pipeline.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 设置监控和仪表板是一个独立的话题，将在第9章更详细地讨论[《监控和模型可观察性》](ch09.xhtml#monitoring_and_observability_for_models)。目前我们应注意，监控分布式吞吐量管道非常困难。由于进展不能简化为单一值（我们仍在读取的最旧数据、我们已经读取的最新数据、我们的训练速度、剩余要读取的数据量），我们需要根据管道数据分布的变化来做出决策。
- en: We will need to set up SLOs and defend them. As noted, our systems will be behaving
    in complex ways with multiple dimensions of variable performance along the “somewhat
    better” and “somewhat worse” axis. To pick thresholds, the first thing we’ll need
    to do is define SLIs that we want to track. In ML, these are generally slices
    (subsets) of the data or model. Then we’ll pick a metric for how those are performing.
    Since these metrics will change over time, if our data is normally distributed,
    we can pick thresholds by their distance from the median.^([10](ch11.xhtml#ch01fn131))
    If we update that periodically but not too often, we will continue to be sensitive
    to large shifts while ignoring longer-term trends. This may miss outages that
    happen slowly over weeks or months, but it will not be overly sensitive.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要设置 SLO（服务水平目标）并捍卫它们。如前所述，我们的系统将以多维度、变化的表现方式行为复杂。要选择阈值，我们首先需要定义我们想要跟踪的 SLI（服务水平指标）。在机器学习中，这些通常是数据或模型的切片（子集）。然后我们会选择一个指标来衡量它们的表现。由于这些指标会随时间变化，如果我们的数据呈正态分布，我们可以通过它们与中位数的距离来选择阈值。^([10](ch11.xhtml#ch01fn131))
    如果我们定期更新它们但不频繁，我们将继续对大的变化保持敏感，同时忽略较长期的趋势。这可能会错过在几周或几个月内慢慢发生的停机事件，但不会过于敏感。
- en: Production engineering teams should educate themselves about the business that
    they are in. This seems ancillary but isn’t. ML systems that work make a difference
    for the organizations that deploy them. To successfully navigate incidents, SREs
    or production engineers should understand what matters to the business and how
    ML interacts with that. Does the ML system make predictions, avoid fraud, connect
    clients, recommend books, or reduce costs? How and why does it do that, and why
    does that matter to our organization? What are the specific objectives that our
    organization is trying to accomplish, and how are they measured? Or even more
    basically, how is our organization put together? Where is an organizational chart
    (for a sufficiently large organization)? Answering those questions ahead of time
    prepares a production engineer for the necessary work of prioritizing, troubleshooting,
    and mitigating ML outages.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 生产工程团队应当深入了解所处的业务环境。这看似次要，但却并非如此。工作正常的ML系统对于部署它们的组织至关重要。要成功处理事故，SRE或生产工程师应当了解业务的关键点以及ML如何与其互动。ML系统是否进行预测、避免欺诈、连接客户、推荐书籍或降低成本？它如何以及为何这么做，以及这对我们组织有何重要性？我们的组织正在尝试实现哪些具体目标，并如何进行衡量？甚至更基本的是，我们的组织是如何构建的？对这些问题的提前回答将为生产工程师在优先级确定、故障排查和减轻ML中断所需工作方面做好准备。
- en: Finally, we need as many objective criteria to trigger an incident as possible.
    The hardest stage of an incident is before it is declared. Often many people are
    concerned. There is pervasive and disconnected evidence that things are not going
    well. But until someone declares an incident and engages the formal machinery
    of incident management, we cannot manage the incident directly. The clearer the
    guidelines we determine in advance, the shorter that period of confusion.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要尽可能多的客观标准来触发事故。事故宣布前的最困难阶段往往涉及许多人的关注。存在广泛而不连贯的证据表明事情进展不顺。但在有人宣布事故并启动正式的事故管理机制之前，我们无法直接管理事故。我们提前确定的指导方针越清晰，混乱期间就越，混乱期间就越短。
- en: Incident handling
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事故处理
- en: Step back and look at the whole system. ML outages are seldom caused by the
    system or metric where they manifest. Poor revenue can be caused by missing data
    (on the other side of the whole system!). Crashes in serving can be caused by
    changes in model configuration in training or errors in the synchronization system
    connecting training to serving. And, as we’ve seen, changes in the world around
    us can themselves be a source of impact. This is a fairly different practice than
    production engineers normally employ, but it is required for ML systems outages.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 站在整个系统的角度回望。ML中断很少由其显现的系统或度量标准引起。收入下降可能是由于数据缺失（在整个系统的另一侧！）。在服务中的崩溃可能是由于训练中模型配置的变更或连接训练与服务之间同步系统中的错误引起的。正如我们所见，周围环境的变化本身也可能是影响源泉。这与生产工程师通常采用的实践有所不同，但对ML系统中断却是必要的。
- en: Be prepared to deal with product leaders and business decision makers. ML outages
    rarely stop at the technical team’s edge. If things are going wrong, they usually
    impact sales or customer satisfaction—the business. Extensive experience interacting
    with customers or business leaders is not a typical requirement for production
    engineers. ML production engineers tend to get over that preference quickly.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好与产品   与产品负责人和业务决策者打交道需有充分准备。机器学习（ML）中断很少仅限于技术团队的边缘。如果出现问题，通常会影响销售或客户满意度——即业务。对客户或业务领导进行广泛交流的经验并非生产工程师的典型要求。ML生产工程师往往会迅速克服这种偏好。
- en: The rest of incident handling is normal SRE/production incident handling, and
    most production engineers are good at it.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的事故处理与正常的SRE/生产事故处理相同，大多数生产工程师都擅长处理此类情况。
- en: Continuous improvement
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持续改进
- en: ML production engineers will collect many ideas about how the incident could
    have gone better. These ideas range from monitoring to rapidly detect the problem
    that we’re not yet doing to system rearchitectures that would avoid the whole
    outage in the first place. The role of the production engineer is to prioritize
    these ideas.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ML生产工程师将收集许多关于事件可能如何更好处理的想法。这些想法从监控到快速检测问题的方式到系统重新架构，以避免整个中断。生产工程师的角色是优先处理这些想法。
- en: 'Post-incident follow-up items have two dimensions of prioritization: value
    and cost/feasibility of implementation. We should prioritize work on items that
    are both valuable and easy to implement. Many follow-up items will fall into the
    category of “likely valuable but extremely difficult to implement.” These are
    a separate category that should be reviewed regularly with senior leads but not
    prioritized alongside other tactical work, since working on them in that setting
    will never make sense.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 事故后的跟进项目有两个优先级维度：价值和实施成本/可行性。我们应优先处理既有价值又易于实施的项目。许多跟进项目属于“可能有价值但极难实施”的类别。这些项目应定期与高级负责人审查，但不应与其他战术工作并列优先，因为在那种情况下处理它们永远没有意义。
- en: Product Manager or Business Leader
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 产品经理或业务领导人
- en: Business and product leaders often think that following and tracking incidents
    is not their problem, but rather one for the technical teams. Once you add ML
    to your environment in all but the most narrow ways, your awareness of it likely
    becomes critical. Business and product leaders can report on the real-world impact
    of ML problems, and can also suggest which causes are most likely and which mitigations
    are least costly. If ML systems matter, business and product leaders should and
    will care about them.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 业务和产品领导人经常认为跟踪和追踪事故不是他们的问题，而是技术团队的问题。一旦你在几乎所有方面都将机器学习引入你的环境中，你对它的意识可能就变得至关重要了。业务和产品领导人可以报告机器学习问题的真实影响，并建议哪些原因最有可能以及哪些减轻措施成本最低。如果机器学习系统很重要，业务和产品领导人应该并且将会关心它们。
- en: Preparation
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备工作
- en: To the extent possible, business and product leaders should educate themselves
    about the ML technologies that are being deployed in their organization and products,
    including, and especially, the need to responsibly use these technologies. Just
    as production engineers should educate themselves about the business, business
    leaders should educate themselves about the technology.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在可能的情况下，业务和产品领导人应该了解在他们的组织和产品中部署的机器学习技术，特别是负责任地使用这些技术的需求。正如生产工程师应该了解业务一样，业务领导人应该了解技术。
- en: 'We should know two critical things: first, how does our system work (what data
    does it use to make what predictions or classifications), and second, what are
    its limitations? There are many things that ML systems can do but also many they
    cannot (yet, perhaps). Knowing what we cannot do is as critical as knowing what
    we’re trying to do.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该了解两个关键事项：首先，我们的系统如何工作（它使用什么数据来做出什么预测或分类），其次，它的局限性是什么？机器学习系统可以做许多事情，但也有许多事情它们（或许还）做不到。了解我们做不到的事情和我们试图做什么一样重要。
- en: Business and product leaders who take a basic interest in the way ML works will
    be astoundingly more useful during a serious incident than those who do not. They
    will also be able to directly participate in the process of picking ML projects
    worth investing in.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 了解机器学习工作方式的业务和产品领导人，在严重事故中将比不了解的人更有用。他们还能直接参与挑选值得投资的机器学习项目的过程。
- en: Finally, business leaders should ensure that their organization has the capacity
    to handle incidents. This largely means that the organization is staffed to a
    level capable of managing these incidents, trained in incident management, and
    invested in the kind of spare time necessary to make space for incidents. If it
    has not, it is the job of the business leader to make space for these investments.
    Anything else creates longer, larger outages.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，业务领导人应确保其组织有能力处理事故。这在很大程度上意味着组织的人员配置到位，能够管理这些事件，接受过事故管理的培训，并投入必要的空闲时间来处理事故。如果没有这样做，业务领导人的工作就是为这些投资腾出空间。其他任何做法都会导致更长时间、更大规模的停机。
- en: Incident handling
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事件处理
- en: Business leaders rarely have an on-call rotation or other systematized way of
    reaching them urgently, but the alternative is “everyone is mostly on call most
    of the time.” Culturally, business leaders should consider formalizing these on-call
    rotations, if only to enable themselves to take a vacation with freedom. The alternative
    is to empower another rotation of on-call staff to make independent decisions
    that can have significant revenue consequences.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 业务领导人很少有值班轮班或其他系统化的方式紧急联系他们，但替代方案是“几乎每个人大部分时间都值班”。从文化上讲，业务领导人应考虑正式化这些值班轮班，即使只是为了让自己能自由地度假。另一种选择是授权另一组值班人员做出独立决策，这些决策可能会对收入产生重大影响。
- en: 'During the actual incident, the most common problem that business leaders will
    face is the desire to lead. For once, they are not the most valuable or knowledgeable
    person. They have the right to two things: first, to be informed, and second,
    to offer context of the incident’s impact on the business. They do not generally
    usefully participate directly in the handling of the incident; they’re simply
    too far removed from the technical systems to do so. Many business leaders should
    consider proxying their questions through someone else and stay off direct incident
    communications (chat, phone, Slack) as a way of avoiding their natural desire
    to take over.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际事故中，业务领导最常面临的问题是想要主导。这一次，他们不是最有价值或最有知识的人。他们有两项权利：首先，得到通知；其次，提供事件对业务影响的背景信息。他们通常无法直接有效参与事故处理；他们与技术系统的距离太远。许多业务领导应考虑通过其他人代理他们的问题，并避免直接参与事故通讯（聊天、电话、Slack等），以避免他们天生的接管欲望。
- en: Continuous improvement
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持续改进
- en: Business leaders should determine the prioritization of work after outages and
    should set standards for what completion of those items means. They can do that
    without having particular opinions about how, exactly, we improve. But, rather,
    they can advocate for general standards and approaches. For example, if we rank
    follow-up work items in priority order (Highest Priority through Nice to Have),
    we can prioritize work on the Highest Priority bugs ahead of the High Priority
    ones, and so on. And we can set guidelines that if all of the Highest Priority
    items are not done after a particular period of time, we have a review to figure
    out whether anything is blocking them and what we can do, if anything, to speed
    up implementation.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 事故后，业务领导应确定工作优先级，并设定完成这些任务的标准。他们可以在不对如何确切改进提出特定意见的情况下进行这些操作。相反，他们可以倡导通用的标准和方法。例如，如果我们按优先顺序排列后续工作项目（从最高优先级到优先但不急需），我们可以优先处理最高优先级的错误，然后是高优先级的错误，依此类推。我们可以制定指南，如果在特定时间段内未完成所有最高优先级项目，则进行审查，以查明是否有任何阻碍因素及我们能否采取措施加快实施。
- en: Similarly, product teams have a huge role in specifying, maintaining, and developing
    SLOs. SLOs should represent the conditions that will meet a customer’s needs and
    make them happy. If they do not, we should change them until they do. The people
    to own the definition and evolution of those values are principally the product
    management team.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，产品团队在指定、维护和开发服务水平目标（SLO）方面发挥重要作用。SLO应该代表满足客户需求并使客户满意的条件。如果不能满足，我们应该修改它们，直到达到目标。主要负责定义和演化这些价值的人是产品管理团队。
- en: Special Topics
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特别主题
- en: We haven’t yet addressed two important topics that show up during the handling
    of ML incidents. This section delves into those subjects.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还未解决在处理机器学习事故过程中出现的两个重要话题。本节深入探讨这些主题。
- en: Production Engineers and ML Engineering Versus Modeling
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生产工程师与机器学习工程师对比建模
- en: 'Given that many ML systems problems present as model quality problems, a minimum
    level of ML modeling skill and experience seems required by ML production engineers.
    Without knowing something about the structure and functioning of the model, it
    may be difficult for those engineers to effectively and independently troubleshoot
    problems and evaluate potential solutions. The converse problem also appears:
    if there is no robust production engineering group, we might well end up with
    modelers responsible for the production serving system indefinitely. While both
    of these outcomes may be unavoidable, they are not ideal.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于许多机器学习系统问题表现为模型质量问题，机器学习生产工程师似乎需要一定程度的机器学习建模技能和经验。如果这些工程师对模型的结构和功能一无所知，他们可能难以有效和独立地解决问题并评估潜在解决方案。反过来的问题也出现了：如果没有强大的生产工程团队，我们可能最终由建模人员负责永久的生产服务系统。尽管这两种结果可能是不可避免的，但并非理想情况。
- en: This is not completely wrong, but it’s also entirely situationally dependent.
    Specifically, in smaller organizations, it will be common to have the model developer,
    system developer, and production engineer be a single person or the same small
    team. This is somewhat analogous to the model in which the developer of a service
    is also responsible for the production deployment, reliability, and incident response
    for that service. In these cases, obviously expertise with the model is a required
    part of the job.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不完全错误，但完全取决于具体情况。特别是在较小的组织中，模型开发人员、系统开发人员和生产工程师往往是同一人或同一个小团队。这与开发人员负责服务的生产部署、可靠性和事件响应的模型类似。在这些情况下，显然对模型的专业知识是工作的必要部分。
- en: As the organization and services get larger, though, the requirement that production
    engineers be model developers vanishes entirely. In fact, most SREs doing production
    engineering on ML systems at large employers never or rarely train models on their
    own. That is simply not their expertise and is not a required, or even useful,
    expertise to do their jobs well.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着组织和服务的扩大，要求生产工程师成为模型开发人员的要求完全消失了。事实上，在大型雇主的 ML 系统上进行生产工程的大多数 SRE 从未或很少独自训练模型。那不是他们的专长，也不是他们工作良好所需的或甚至有用的专长。
- en: ML SREs or ML production engineers do need certain ML-related skills and knowledge
    to be effective. They need basic familiarity with what ML models are, how they
    are constructed, and above all, the flavor and structure of the interconnected
    systems that build them. The relationship of components and the flow of data through
    the system is more important than the details of the learning algorithm.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: ML SRE（机器学习可靠性工程师）或 ML 生产工程师确实需要一定的与机器学习相关的技能和知识才能发挥效力。他们需要基本了解什么是 ML 模型，它们如何构建，以及构建它们的相互连接系统的特点和结构。系统组件之间的关系以及数据在系统中的流动比学习算法的细节更为重要。
- en: Let’s say, for example, that we have a supervised learning system that uses
    TensorFlow jobs scheduled at a particular time of day to read all the data from
    a particular feature store or storage bucket and to produce a saved model. This
    is one completely reasonable way to build an ML training system. In this case,
    the ML production engineer needs to know something about what TensorFlow is and
    how it works, how the data is updated in the feature store, how the model training
    processes are scheduled, how they read the data, what a saved model file looks
    like, how big it is, and how to validate it. That engineer does not need to know
    how many layers the model has or how they are updated, although there’s nothing
    wrong with knowing that. They do not need to know how the original labels were
    generated (unless we plan to generate them again).
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有一个监督学习系统，使用 TensorFlow 作业在特定时间执行，从特定特征存储或存储桶中读取所有数据，并生成一个保存的模型。这是构建
    ML 训练系统的一个完全合理的方式。在这种情况下，ML 生产工程师需要了解 TensorFlow 是什么以及它的工作原理，数据如何在特征存储中更新，模型训练过程如何调度，如何读取数据，保存的模型文件的外观如何，大小如何，以及如何验证它。该工程师不需要知道模型有多少层或者它们如何更新，尽管了解这些也无妨。他们也不需要知道原始标签是如何生成的（除非我们计划重新生成它们）。
- en: On the other side of the same coin, suppose we have settled on a delivery pipeline
    in which an ML modeling engineer packages their model into a Docker container,
    annotates a few configuration details in an appropriate config system, and submits
    the model for deployment as a microservice running in Kubernetes. The ML modeling
    engineer may need to understand the implications of how the Docker container is
    built and how large the container is, how the configuration choices will affect
    the container (particularly if there are config errors), and how to follow the
    container to its deployment location and do some cursory log checking or system
    inspection to verify basic health checks. The ML modeling engineer probably does
    not, however, need to know about low-level Kubernetes choices like pod-disruption
    budget settings, DNS resolution of the container’s pod, or the network connectivity
    details between the Docker container registry and Kubernetes. While those details
    are important, especially in the case where infrastructure components are part
    of a failure, the ML modeling engineer won’t be well suited to address them and
    may need to rely on handing off those types of errors to an SRE specialist familiar
    with that part of the infrastructure.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，假设我们已经确定了一个交付管道，其中机器学习建模工程师将他们的模型打包到一个Docker容器中，用适当的配置系统注释一些配置细节，并将模型提交为在Kubernetes中运行的微服务。机器学习建模工程师可能需要理解Docker容器的构建方式及其大小，配置选择将如何影响容器（特别是如果存在配置错误），以及如何跟踪容器到其部署位置并进行一些简要的日志检查或系统检查以验证基本健康检查。然而，机器学习建模工程师可能并不需要了解像Pod中断预算设置、容器Pod的DNS解析或Docker容器注册表与Kubernetes之间的网络连接细节等低级Kubernetes选择。尽管这些细节很重要，特别是在基础设施组件是故障的一部分的情况下，但机器学习建模工程师可能不适合解决它们，可能需要依赖熟悉基础设施该部分的SRE专家来处理这些类型的错误。
- en: Detailed knowledge of model building can certainly be extremely helpful. But
    the biggest reliability problem that most organizations run into is not a lack
    of knowledge about ML. It is rather a lack of knowledge and experience building
    and productionizing distributed systems. The ML knowledge is a nice addition rather
    than the most important skill set.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 对模型构建的详细知识确实非常有帮助。但是，大多数组织遇到的最大可靠性问题并不是缺乏关于机器学习的知识，而是缺乏构建和产品化分布式系统的知识和经验。机器学习知识是一个很好的补充，而不是最重要的技能集。
- en: The Ethical On-Call Engineer Manifesto
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 《伦理值班工程师宣言》
- en: We’ve written a lot in this chapter about how performing incident response is
    different and more difficult when ML is involved. Another way in which ML incident
    response is hard is how to handle customer data when you’re on call and actively
    resolving a problem, a constraint we call *privacy-preserving incident management*.
    This is a difficult change for some to make, since today (and decades previous),
    on-call engineers are accustomed to having prompt and unmediated access to systems,
    configuration, and data in order to resolve problems. Sadly, for most organizations
    and in most circumstances, this access is absolutely required. We cannot easily
    remove it and still allow for fixing problems promptly.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经讨论了当涉及到机器学习时，如何执行事件响应不同且更加困难。机器学习事件响应变得困难的另一方面是在解决问题并处于待命状态时如何处理客户数据，我们称之为*隐私保护事件管理*的约束。对一些人来说，这是一个难以适应的改变，因为今天（以及几十年前），值班工程师习惯于及时且不受限地访问系统、配置和数据以解决问题。但遗憾的是，对于大多数组织和大多数情况，这种访问是绝对必要的。我们无法轻易移除它，同时又允许快速修复问题。
- en: On-call engineers, in the course of their response, troubleshooting, mitigation,
    and resolution of service outages, need to take *extra* care to ensure that their
    actions are ethical. In particular, they must respect the privacy rights of users,
    watch for and identify unfair systems, and prevent unethical uses of ML. This
    means carefully considering the implications of their actions—not something easy
    to do during a stressful shift—and consulting with a large and diverse group of
    skilled colleagues to help make thoughtful decisions.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在值班工程师响应、故障排除、缓解和解决服务中断的过程中，他们需要特别注意确保他们的行动是道德的。特别是，他们必须尊重用户的隐私权利，监视并识别不公平的系统，并防止机器学习的不道德使用。这意味着需要仔细考虑他们行动的影响——在紧张的值班期间并不容易做到，并且需要与大量和多样化的熟练同事咨询，以帮助做出周到的决策。
- en: 'To help us understand why this should be the case, let’s consider the four
    incident dimensions in which ethical considerations for ML can arise: the impact
    (severity and type), the cause (or contributing factors), the troubleshooting
    process itself, and the call to action.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们理解为什么这样做是必要的，让我们考虑机器学习伦理考虑的四个事件维度：影响（严重性和类型）、原因（或促成因素）、故障排除过程本身以及行动呼吁。
- en: Impact
  id: totrans-314
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 影响
- en: Model incidents with effects on fairness can wreak truly massive and immediate
    harm on our users, and of course reputational harm to our organization. It doesn’t
    matter whether the effect is obvious to production dashboards tracking high-level
    KPIs or not. Imagine a bank loan approval program that is accidentally biased.
    Although the data supplied in applications might omit details on the applicants’
    race, there are many ways the model could learn race categories from the data
    that is supplied and from other label data.^([11](ch11.xhtml#ch01fn132)) If the
    model then systematically discriminates against some races in approving loans,
    we might well issue just as many loans—and show about the same revenue numbers
    on a high-level dashboard—but the result is deeply unfair. Such a model in a user-facing
    production system could be bad for both our customers and our organization.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及公平性的模型事件可能对我们的用户造成巨大且即时的伤害，当然也会给我们的组织声誉造成损害。无论效果是否显而易见于跟踪高级别关键绩效指标的生产仪表板，这都无关紧要。想象一下一个银行贷款批准程序出现意外偏见。尽管申请中提供的数据可能省略了申请者种族的详细信息，但模型可能会从提供的数据以及其他标签数据中学习到种族类别。^([11](ch11.xhtml#ch01fn132))
    如果模型然后在批准贷款时系统性地对某些种族进行歧视，我们可能会批准同样数量的贷款，并在高级别仪表板上显示大致相同的收入数字，但结果是极不公平的。这样一个存在于用户面向生产系统中的模型对我们的客户和组织都可能是有害的。
- en: In ideal circumstances, no organization would employ ML without undergoing at
    least a cursory Responsible AI evaluation as part of the design of the system
    and the model.^([12](ch11.xhtml#ch01fn133)) This evaluation would provide clear
    guidelines for metrics and tools to be used in identifying and mitigating bias
    that might appear in the model.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想情况下，没有任何组织会在不经过至少粗略的负责人工智能评估的情况下使用机器学习作为系统和模型设计的一部分。^([12](ch11.xhtml#ch01fn133))
    这种评估将为在模型中可能出现的偏见的识别和缓解提供清晰的指导方针、指标和工具。
- en: Cause
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原因
- en: 'For any incident, the cause or contributing factors to the outage can have
    consequences for the ethically minded on-call engineer. What if the cause turns
    out to be a deliberate design decision that is actually hard to reverse? Or the
    model was developed without enough (or any) attention being paid to ethical and
    fairness concerns? What if the system will continue to fail in this unfair way
    without expensive refactoring? Insider threat is real,^([13](ch11.xhtml#ch01fn134))
    don’t forget, but we don’t need to imagine that malice aforethought took place
    for these kinds of things to happen: a homogeneous team, strongly focused on shipping
    product to the exclusion of all else, can enable it purely by accident. Of course,
    all of this is enhanced by the current lack of explainability of most ML systems.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何事件，导致或促成停机的原因可能对在岗的工程师产生伦理上的影响。如果原因竟然是一项难以逆转的刻意设计决策呢？或者模型在开发过程中根本没有或没有足够地关注伦理和公平性问题呢？如果系统会因为昂贵的重构而继续以这种不公平的方式失败呢？内部威胁是真实存在的^([13](ch11.xhtml#ch01fn134))，不要忘记，但我们并不需要想象有预谋的恶意才会发生这些事情：一个同质化团队，强烈专注于产品上线而排斥其他一切，可以纯粹因偶然而使其成为可能。当然，目前大多数机器学习系统缺乏可解释性，这一切都进一步加剧了问题。
- en: Troubleshooting
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 故障排除
- en: Ethics concerns (generally, privacy) often arise during the troubleshooting
    phase for incidents. As you saw in story 3, it is tempting—maybe sometimes even
    required—to look at raw user data while troubleshooting modeling problems. But
    doing so directly exposes private customer data. Depending on the nature of the
    data, it might have other ethical implications as well—consider, for example,
    a financial system that includes customer investment decisions in the raw data.
    If a staff member has access to that private information and uses it to direct
    their own personal investments, this is obviously unethical and in multiple jurisdictions
    would be seriously illegal.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在故障排除阶段经常会出现伦理问题（通常是隐私问题）。正如您在故事3中看到的那样，查看原始用户数据可能是诱人的——有时甚至是必要的——用于解决建模问题。但这样做直接暴露了私人客户数据。根据数据的性质，它可能还会涉及其他伦理问题——例如，一个包含客户投资决策的金融系统的原始数据。如果员工可以访问这些私人信息并将其用于自己的个人投资，显然是不道德的，并且在多个司法管辖区可能严重违法。
- en: Solutions and a call to action
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决方案和行动号召
- en: The good news is that a lot of these problems have solutions, and getting started
    can be reasonably cheap. On the one hand, we’ve already spoken about the generally
    underweighted role that diverse teams can play in ensuring an organization against
    bad outcomes. Fixing those generally involves fixing the process that produced
    them rather than mitigating a specific one-time harm.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是这些问题大多数都有解决方案，并且开始解决问题成本合理。一方面，我们已经谈论过多样化团队在确保组织免受不良后果方面扮演的普遍低估角色。解决这些问题通常涉及修复产生问题的过程，而不是仅仅减轻一次性的伤害。
- en: But a diversity of team members is not, by itself, a solution. Teams need to
    adopt the use of Responsible AI practices during the model and system design phase
    in order to create consistent monitoring of fairness metrics and to provide incident
    responders a framework to evaluate against. For deliberate or inadvertent access
    to customer data during incident management, restricting that access by default
    with justification, logging, and multiple people in charge over the data (to act
    as ethical checks on each other) is a reasonable balance of risk versus reward.
    Other mechanisms that are useful to avoid the construction of flawed models are
    outlined in [Chapter 6](ch06.xhtml#fairnesscomma_privacycomma_and_ethical).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，仅仅拥有多样化的团队成员并不能解决问题。团队需要在模型和系统设计阶段采用负责任的人工智能实践，以便创建对公平性指标进行一致监控并为事件响应者提供评估框架。在事件管理期间故意或无意地访问客户数据时，默认情况下限制访问，并通过理由、日志记录和多人负责来行使伦理检查，是风险与回报的合理平衡。其他有助于避免构建有缺陷模型的机制已在[第6章](ch06.xhtml#fairnesscomma_privacycomma_and_ethical)中概述。
- en: Finally, though it is not within our authority to declare it unilaterally—nor
    would we wish to—we strongly believe there is an argument for formalizing such
    a manifesto, and promoting it industry-wide. The time will come—if it is not already
    here—when an on-call engineer will discover something vital and worthy of public
    disclosure, and may be conflicted about what to do. Without a commonly understood
    definition of what a whistleblower is in the ML world, society will suffer.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，尽管我们无权单方面宣布它——也不愿意这样做——但我们坚信有理由正式化这样的宣言，并在整个行业推广。时间将会来临——如果它还没有到来的话——当一名值班工程师发现某些重要且值得公开披露的事情时，可能会对如何处理产生冲突。在机器学习领域没有一个普遍理解的告密者定义的情况下，社会将受到影响。
- en: Conclusion
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: An ML model is an interface between the world as it is and as it changes on
    the one hand, and a computer system on the other. The model is designed to represent
    the state of the world to the computer system and, through its use, allow the
    computer system to predict and ultimately modify the world. This is true in some
    sense of all computer systems but is true at a semantically higher and broader
    sense for ML systems.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型在某种程度上是世界现状及其变化与计算机系统之间的接口。该模型旨在将世界的状态表示给计算机系统，并通过其使用允许计算机系统预测并最终修改世界。在某种意义上，这适用于所有计算机系统，但对于机器学习系统而言，在语义上更高更广泛地适用。
- en: Think of tasks such as prediction or classification, whereby an ML model attempts
    to learn about a set of elements in the world in order to correctly predict or
    categorize future instances of those elements. The purpose of the prediction or
    classification always is, and has to be, changing the behavior of a computing
    system or an organization in response to the prediction or classification. For
    example, if an ML model determines that an attempted payment is fraud, based on
    characteristics of the transaction and previous transactions that our model has
    learned from, this fact is not merely silently noted in a ledger somewhere—instead,
    the model will usually reject the transaction after such a categorization is made.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下诸如预测或分类等任务，其中 ML 模型试图学习世界上一组元素，以便正确预测或分类未来的这些元素实例。预测或分类的目的始终是并且必须是，根据预测或分类改变计算系统或组织的行为。例如，如果一个
    ML 模型确定一笔支付是欺诈行为，基于交易的特征和我们的模型从先前交易中学到的信息，这个事实不仅仅会悄悄地记录在某个账本上 —— 相反，在做出这样的分类后，模型通常会拒绝该交易。
- en: 'ML failures specifically occur when a mismatch arises among three elements:
    the world itself and the salient facts about it, the ML system’s ability to represent
    the world, and the ability of the system as a whole to change the world appropriately.
    Failures can occur at each of those elements or, most commonly, in combination
    or at the intersections between them.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: ML 失败特别在于三个元素之间的不匹配：世界本身及其关键事实、ML 系统表示世界的能力，以及系统作为整体适当地改变世界的能力。这些元素的每一个或者通常是它们之间或交叉点处可能出现失败。
- en: ML incidents are just like incidents for other distributed systems, except for
    all of the ways that they are not. The stories here share several common themes
    that will help ML production engineers prepare to identify, troubleshoot, mitigate,
    and resolve issues in ML systems as they arise.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: ML 事件就像其他分布式系统的事件一样，除了它们不同的方面。这里的故事分享了几个共同的主题，将帮助 ML 生产工程师准备好在 ML 系统中识别、排查、减轻和解决问题。
- en: Of all of the observations about ML systems made in this chapter, the most significant
    is that ML models, when they work, matter for the whole organization. Model and
    data quality have to therefore be the mission of everyone in the organization.
    When an ML model goes bad, fixing it will sometimes require the whole organization
    as well. ML production engineers who hope to get their organizations ready to
    manage these kinds of outages would do well to make sure that the engineers understand
    the business, and the business and product leaders understand the technology.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中关于 ML 系统的所有观察中，最重要的是 ML 模型在工作时对整个组织都具有重要意义。因此，模型和数据质量必须成为组织的使命。当 ML 模型出现问题时，修复它有时也需要整个组织的参与。希望让他们的组织准备好管理这类中断的
    ML 生产工程师们应确保工程师理解业务，业务和产品领导者理解技术。
- en: ^([1](ch11.xhtml#ch01fn122-marker)) If you’re looking for detailed coverage
    of general incident management, you may consider instead reviewing [*Site Reliability
    Engineering*](https://oreil.ly/cpdFY) and the [PagerDuty incident response handbook](https://response.pagerduty.com).
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch11.xhtml#ch01fn122-marker)) 如果您正在寻找关于一般事故管理的详细覆盖，您可以考虑查阅[*Site Reliability
    Engineering*](https://oreil.ly/cpdFY)和[PagerDuty事故响应手册](https://response.pagerduty.com)。
- en: ^([2](ch11.xhtml#ch01fn123-marker)) See [Chapter 14](ch14.xhtml#practical_ml_org_implementation_example)
    of [*Site Reliability Engineering*](https://oreil.ly/cpdFY) for more details.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch11.xhtml#ch01fn123-marker)) 更多详细信息，请参阅[*Site Reliability Engineering*](https://oreil.ly/cpdFY)的[第14章](ch14.xhtml#practical_ml_org_implementation_example)。
- en: ^([3](ch11.xhtml#ch01fn124-marker)) This drift, as well as the contents of the
    golden set, are also key places where unfair bias can become a factor for our
    system. See [Chapter 6](ch06.xhtml#fairnesscomma_privacycomma_and_ethical) for
    a discussion of these topics at more length.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch11.xhtml#ch01fn124-marker)) 这种漂移，以及黄金集的内容，也是我们系统中不公平偏见可能成为因素的关键地方。详见[第6章](ch06.xhtml#fairnesscomma_privacycomma_and_ethical)，更详细地讨论这些主题。
- en: ^([4](ch11.xhtml#ch01fn125-marker)) This kind of restriction on data commingling
    is somewhat common. Companies are sensitive about their commercially valuable
    data (for example, who bought *X* after searching for *Y*) being used to benefit
    their competitors. In this case, these companies may even regard YarnIt as a competitor
    (although one who sends them significant business that they value).
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch11.xhtml#ch01fn125-marker)) 对数据混合的这种限制在某种程度上很常见。公司对他们的商业数据（例如谁在搜索了*Y*之后购买了*X*）被用于使他们的竞争对手受益非常敏感。在这种情况下，这些公司甚至可能把YarnIt视为竞争对手（尽管后者为他们带来了他们重视的大量业务）。
- en: ^([5](ch11.xhtml#ch01fn126-marker)) This is a risky way to test this hypothesis.
    It would have been better to roll out a single model first to validate that the
    old models performed better and didn’t have another catastrophic problem. But
    this is a defensible choice that people make during high-stakes outages.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch11.xhtml#ch01fn126-marker)) 这是测试这一假设的一种冒险方式。最好先推出一个单一模型来验证旧模型的表现更好，并且没有其他灾难性问题。但在高风险的故障期间，这是人们可以辩护的选择。
- en: ^([6](ch11.xhtml#ch01fn127-marker)) Incident response has a pair of useful concepts.
    *Recovery point objective* (*RPO*) is the point in time that we are able to restore
    the system to full functionality after recovering from the outage, ideally immediately
    prior to the outage. *Recovery time objective* (*RTO*) is how long it will take
    to restore the system to functionality from an outage. ML systems certainly have
    an RTO; retraining a model, copying an old version—these take time. But the problem
    is that most ML systems have no meaningful notion of an RPO. Occasionally, a system
    runs entirely in the “past” on preexisting inputs, but most of the time ML systems
    exist to adapt our responses to current changes in the world. So the only RPO
    that matters is “now” for ever-changing values of “now.” A model trained “a few
    minutes ago” might be good enough for “now” but might not. This significantly
    complicates thinking about resolution.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch11.xhtml#ch01fn127-marker)) 事件响应有一对有用的概念。*恢复点目标*（*RPO*）是我们能够在恢复故障后将系统恢复到全功能状态的时间点，理想情况下是故障前的即时。*恢复时间目标*（*RTO*）是从故障中恢复系统功能需要的时间。ML系统当然有一个RTO；重新训练模型、复制旧版本等需要时间。但问题在于，大多数ML系统没有一个有意义的RPO概念。偶尔，一个系统完全在“过去”上运行，基于预先存在的输入，但大多数时候ML系统存在是为了调整我们对世界当前变化的响应。因此，唯一重要的RPO是“现在”，对于不断变化的“现在”值。一个“几分钟前”训练的模型可能对“现在”来说足够好，但也可能不够。这显著复杂化了对解决方案的思考。
- en: ^([7](ch11.xhtml#ch01fn128-marker)) IP addresses are probably personal information
    or PII in many jurisdictions, so caution must be exercised. This is not always
    widely understood by systems engineers or operators, especially those who work
    in countries with looser legal governance frameworks. Additionally, search queries
    that can be correlated to the same user demonstrably reveal private information
    by means of the combination of the queries. Famously, see Wikipedia’s [“AOL search
    log release” page](https://oreil.ly/U2bCP) for context.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch11.xhtml#ch01fn128-marker)) 在许多司法管辖区中，IP地址可能被视为个人信息或PII，因此必须谨慎行事。这并不总是系统工程师或运营商广泛理解的，特别是在法律监管框架较为松散的国家工作的人。此外，可以与同一用户相关联的搜索查询通过组合查询表明展示私人信息。著名的例子，请参阅维基百科的["AOL搜索日志发布"页面](https://oreil.ly/U2bCP)了解背景。
- en: ^([8](ch11.xhtml#ch01fn129-marker)) Of course, these different recommendations
    might mean the model is picking up on proxies for unfair bias, and model designers
    and operators should use fairness evaluation tools to regularly look for this
    bias.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch11.xhtml#ch01fn129-marker)) 当然，这些不同的建议可能意味着模型正在捕捉到不公平偏见的代理，模型设计师和操作者应使用公平性评估工具定期查找这种偏见。
- en: ^([9](ch11.xhtml#ch01fn130-marker)) For much more on this topic, see [*Chaos
    Engineering*](https://oreil.ly/R38WM) by Casey Rosenthal and Nora Jones (O’Reilly,
    2020).
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch11.xhtml#ch01fn130-marker)) 关于这个主题的更多信息，请参阅凯西·罗森塔尔和诺拉·琼斯的[*《混沌工程》*](https://oreil.ly/R38WM)（O'Reilly，2020）。
- en: ^([10](ch11.xhtml#ch01fn131-marker)) The statistics covering this and techniques
    for setting thresholds are covered well in Mike Julian’s [*Practical Monitoring*](https://oreil.ly/xsRZZ)
    (O’Reilly, 2017), especially [Chapter 4](ch04.xhtml#feature_and_training_data).
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch11.xhtml#ch01fn131-marker)) 关于此及设置阈值技术的统计信息在迈克·朱利安的[*《实用监控》*](https://oreil.ly/xsRZZ)（O'Reilly，2017）中有很好的涵盖，特别是[第四章](ch04.xhtml#feature_and_training_data)。
- en: ^([11](ch11.xhtml#ch01fn132-marker)) Models can learn race from geographic factors
    in areas that have segregated housing, from family or first names in places where
    those are racially correlated, from educational history in places that have segregated
    education, and even from job titles or job industry. In a racially biased society,
    many signals correlate with race in a way that models can easily learn even without
    a race label in the model.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch11.xhtml#ch01fn132-marker)) 在那些有种族隔离住房的地区，模型可以从地理因素中学习种族信息，从那些与种族相关的家庭或名字中学习，还可以从有种族隔离教育的地方的教育历史中学习，甚至可以从职位名称或职业行业中学习。在一个种族偏见的社会中，许多信号与种族相关，模型可以轻松学习这些信号，即使模型中没有种族标签。
- en: ^([12](ch11.xhtml#ch01fn133-marker)) This topic is covered much more extensively
    in [Chapter 6](ch06.xhtml#fairnesscomma_privacycomma_and_ethical).
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch11.xhtml#ch01fn133-marker)) 这个主题在[第 6 章](ch06.xhtml#fairnesscomma_privacycomma_and_ethical)中有更详尽的探讨。
- en: '^([13](ch11.xhtml#ch01fn134-marker)) See, for example, [“Famous Twitter Accounts
    Hacked: Insider Threat or Social Engineering Attack?”](https://oreil.ly/lc6kp)
    by Clare O’Gara, though the incidents that make the papers are almost by definition
    a small subset of the ones that actually happen.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch11.xhtml#ch01fn134-marker)) 例如，参见[“著名的 Twitter 账户被黑客入侵：内部威胁还是社会工程攻击？”](https://oreil.ly/lc6kp)
    的 Clare O’Gara，尽管出现在报纸上的事件几乎可以被定义为实际发生事件的一个小子集。
