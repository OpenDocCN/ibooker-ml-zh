- en: Chapter 3\. Model Explainability and Interpretability
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章 模型可解释性与可解释性
- en: 'Making sense of a machine learning model can seem as hard as making sense of
    intelligence itself. Computer scientist Marvin Minsky famously [described “intelligence”
    as a suitcase word](https://oreil.ly/SgFAp): “a word that means nothing by itself,
    but holds a bunch of things inside that you have to unpack.” This becomes even
    more confusing when you see models with superhuman performance in some tasks (for
    example, playing Go or chess), but that fail epically in others (for example,
    mistaking a picture of a person on a bus for a pedestrian). Machine learning is
    great at creating functions that map to complex decision spaces. Problems arise
    when you want to understand why the model made a particular decision.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 理解机器学习模型可能看起来像是理解智能本身一样困难。计算机科学家马文·明斯基曾著名地将“智能”描述为[“一个手提箱词”](https://oreil.ly/SgFAp)：“一个本身并不代表任何东西，但内含一堆你必须解开的东西。”
    当你看到在某些任务中具有超人表现（例如，下围棋或国际象棋），但在其他任务中却惨败（例如，将公交车上的人物误认为行人），这一切变得更加混乱。机器学习擅长创建映射到复杂决策空间的函数。问题在于，当你想要理解模型为何做出特定决策时。
- en: Even worse, “interpretability”—the tool you want to use to pick apart a model—may
    count as a suitcase word itself.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，“可解释性”——你想要用来解析模型的工具——本身可能也算是一个手提箱词。
- en: Explainability Versus Interpretability
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释性与可解释性的区别
- en: '*Explainability* and *interpretability* are often used interchangeably when
    it comes to making sense of ML models and their outputs. For interpretability,
    there are at least a few non-math-heavy definitions you could use. AI researcher
    Tim Miller described it as “the degree to which human beings can understand the
    cause of a decision,”^([1](ch03.html#idm45621854762112)) while Kim et al. described
    it as “the degree to which a machine’s output can be consistently predicted.”^([2](ch03.html#idm45621854760192))'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*可解释性*和*可解释性*在解释ML模型及其输出时通常可以互换使用。对于可解释性，至少有几个非数学重的定义可供选择。AI研究员蒂姆·米勒将其描述为“人类能够理解决策原因的程度”，^([1](ch03.html#idm45621854762112))
    而金尚宇等人将其描述为“能够一致预测机器输出的程度”。^([2](ch03.html#idm45621854760192))'
- en: What these definitions have in common is that they focus on the decisions that
    a model makes. Contrast this with *explainability* (sometimes referred to as Xplainable
    AI or XAI.^([3](ch03.html#idm45621854755760))) While it’s often used in similar
    contexts, the term usually emphasizes the learned model internals, such as the
    weights of a neural network or the node splits of a tree.^([4](ch03.html#idm45621854753488))
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这些定义的共同点在于它们侧重于模型所做的决策。与*可解释性*（有时称为Xplainable AI或XAI。^([3](ch03.html#idm45621854755760))）相反。尽管它通常在类似的语境中使用，但该术语通常强调学习模型内部，如神经网络的权重或树的节点分裂。^([4](ch03.html#idm45621854753488))
- en: Even though this distinction hasn’t been formalized among researchers, we’ll
    use *interpretable* as referring to model outputs and *explainable* as referring
    to model internals throughout the rest of the book.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管研究人员尚未正式区分这一点，我们将在本书的其余部分中将*可解释性*指涉模型输出，*可解释性*指涉模型内部。
- en: The Need for Interpretable and Explainable Models
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对于需要可解释性和可解释性的模型的需求
- en: If you have a model that can make decisions on the test data with high enough
    accuracy, surely that’s enough to deploy it, right?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个能够在测试数据上以足够高准确率做出决策的模型，那么部署它肯定足够了，对吧？
- en: As Doshi-Velez and Kim point out,^([5](ch03.html#idm45621854740496)) getting
    an output decision from the ML model is not always the end. Consider the hypothetical
    case of using a neural network in oncology. The model can make decisions that
    could be life changing for patients. Said patients would be well within their
    legal rights to ask for more details from the doctor, and they probably won’t
    be satisfied with a response like “Trust me on this, we have a really good neural
    network.” How good that neural network is might be in doubt as well. After all,
    you would have to make sure that the computer vision model that looks at X-rays
    is actually looking at the body part in question, not looking in the corners for
    a text label mistakenly left in by a human radiologist.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 正如多希-韦勒兹和金所指出的那样，^([5](ch03.html#idm45621854740496)) 从ML模型获得输出决策并不总是终点。考虑使用神经网络在肿瘤学中的假设案例。该模型可以做出对患者可能具有生命变化意义的决策。这些患者在法律上有权要求医生提供更多细节，而他们可能不会对“请相信我，我们有一个非常好的神经网络”这样的回答满意。这个神经网络到底有多好可能也值得怀疑。毕竟，你需要确保检查X光的计算机视觉模型确实在观察所研究的身体部位，而不是在角落里寻找被人类放错的文本标签。
- en: Interpretability and explainability are important safeguards against this kind
    of ignorance.^([6](ch03.html#idm45621854738064)) This is especially important
    when a model is being used in a context that it hasn’t encountered before, which
    is extremely important when considering a model’s fairness, privacy, and robustness.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性和可解释性是防止这种无知的重要保障。^([6](ch03.html#idm45621854738064)) 特别是在模型被用于其以前未曾遇到的情境时，考虑模型的公平性、隐私性和鲁棒性尤为重要。
- en: '[Nick Bostrom has famously postulated](https://oreil.ly/H61nH) that interpretability
    is a safeguard against creating a super-intelligent AI with goals contrary to
    those of its human creators. If you can interpret an advanced AI model and reliably
    explain its decisions, you can also reverse engineer it to make sure it does what
    you want and does not try to harm you. All the more reason to recognize the importance
    of model interpretability and explainability.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[尼克·博斯特罗姆曾著名地提出过](https://oreil.ly/H61nH)，解释性是防止创造出具有与其人类创造者相悖目标的超智能人工智能的保障。如果您能解释一个先进的AI模型并可靠地解释其决策，那么您也可以反向工程它，确保它按照您的意愿行事，而不会试图伤害您。更加理由去认识模型的可解释性和可解释性的重要性。'
- en: If your project absolutely needs interpretability or explainability as a feature,
    you will need to weigh drops in interpretability against the importance of performance
    gains. Decision trees are much more intuitively explainable and interpretable
    than deep neural networks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的项目绝对需要可解释性或可解释性作为特征，您将需要权衡可解释性的降低与性能提升的重要性。决策树比深度神经网络更直观解释和可解释。
- en: That being said, the performance gains granted by deep neural networks are why
    they’ve become so much more popular than decision trees.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，深度神经网络带来的性能提升正是它们比决策树更受欢迎的原因。
- en: A Possible Trade-off Between Explainability and Privacy
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可能存在解释性和隐私之间的权衡
- en: In [Chapter 1](ch01.html#chapter1), we detailed a variety of ways in which the
    internal rules or even the training dataset of a model could be stolen. Most of
    these ways involve closely inspecting the model’s decision outputs for all logits.
    The goal was to train a model to imitate the target as closely as possible. These
    attacks assume the attacker has access to more detailed information about the
    model’s decisions beyond just the final output value.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](ch01.html#chapter1)中，我们详细讨论了模型的内部规则甚至训练数据集可能被窃取的各种方式。这些方式大多涉及紧密检查模型决策输出的所有对数函。目标是尽可能训练一个模型以模仿目标。这些攻击假设攻击者可以访问有关模型决策更详细信息，而不仅仅是最终输出值。
- en: These interpretability methods go far beyond just listing all the logits. They
    provide more insight into the internals of a model than logits ever could. It’s
    theoretically possible to create an attack mechanism based on them. For example,
    instead of training a model on a classification dataset, you could train the model
    on saliency maps taken from a model that already performed well. A determined
    attacker could create a loss function based on the KL divergence between the saliency
    maps of the two models for given inputs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这些解释性方法远不止于简单列出所有的逻辑回归值。它们提供的见解比逻辑回归值更能深入了解模型的内部。理论上可以基于它们创建一个攻击机制。例如，不是在分类数据集上训练模型，而是在已经表现良好的模型的显著性图上训练模型。一个决心坚定的攻击者可以基于两个模型的给定输入的显著性图之间的KL散度创建一个损失函数。
- en: As we noted in [Chapter 1](ch01.html#chapter1), the best hope for defending
    against such attacks is to limit the output rate of predictions. It’s also important
    to limit who can see the full extent of the output predictions at all. For example,
    think twice when it comes to exposing the logits to anyone other than your team.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第1章](ch01.html#chapter1)中所指出的，抵御这类攻击的最佳希望是限制预测的输出速率。同样重要的是要限制除了你的团队之外的任何人看到全部预测输出的程度。例如，在向任何人公开逻辑回归值时要三思而后行。
- en: While no privacy mechanism is truly perfect, limiting the audience to only those
    necessary can go a long way.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有真正完美的隐私机制，但将观众限制在必要的人群之内可以走得更远。
- en: Evaluating the Usefulness of Interpretation or Explanation Methods
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估解释或说明方法的实用性
- en: 'It might be overwhelming to choose which method to use. As the field has matured,
    more guidelines have emerged on how to evaluate an interpretability method. Doshi-Velez
    and Kim’s three-level framework is a good example of this.^([7](ch03.html#idm45621854718720))
    The three levels they outline are:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 选择使用哪种方法可能会让人不知所措。随着该领域的成熟，关于如何评估解释性方法的指导方针越来越多。Doshi-Velez 和 Kim 的三级框架就是一个很好的例子。^([7](ch03.html#idm45621854718720))
    他们概述的三个级别包括：
- en: '*Application-level evaluation (real task)*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*应用级评估（实际任务）*'
- en: If you put your model explanation into your product, will the user understand
    what it’s saying? A good example of this would be a product that detects worn-down
    joints in veterinary X-rays of animals. An AI can be trained on previous radiology
    images to predict whether or not an animal is sick. An interpretable model, by
    contrast, will be able to not only communicate to the radiologist what it’s predicting
    but highlight the parts of the X-ray that caused it to draw that conclusion. It’s
    worth comparing these kinds of model explanations to a human radiologist explaining
    a similar decision.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将你的模型解释放入产品中，用户能理解其含义吗？一个很好的例子是，产品可以检测动物的兽医X光中磨损的关节。通过先前的放射学图像对AI进行训练，以预测动物是否生病。相比之下，一个可解释的模型不仅能够向放射科医生解释其预测内容，还能突出显示导致其得出结论的X光部位。值得比较的是，这些模型解释与人类放射科医生解释类似决策的方式。
- en: '*Human-level evaluation (simple task)*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*人类级评估（简单任务）*'
- en: This is similar to the application-level evaluation but without a specific end
    user in mind. With this kind of evaluation, you should ask whether a random person
    (not necessarily a user or domain expert) would be able to understand the model’s
    decision. If domain experts are rare and/or expensive (like the veterinarians
    in the previous example), using the judgment of an average person as a baseline
    is a possible alternative. Ideally, one should ask which of the model’s explanations
    are easiest to understand.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这类似于应用级评估，但没有特定的最终用户考虑。通过这种评估，你应该询问一个随机的人（不一定是用户或领域专家）是否能够理解模型的决策。如果领域专家稀缺和/或昂贵（如前面例子中的兽医），使用普通人的判断作为基准是一个可能的替代方案。理想情况下，应该询问模型解释中哪些是最容易理解的。
- en: '*Function-level evaluation (proxy task)*'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*功能级评估（代理任务）*'
- en: A function-level evaluation doesn’t rely on human criticism as much as the previous
    evaluations. Instead, it relies on the properties of the model type in question.
    In fact, this is the kind of evaluation you would turn to after you’ve demonstrated
    that you can obtain human-understandable explanations. Some of these explanations
    may be better than others, possibly due to a single metric. For example, if you
    are relying on a decision tree or decision rules, deeper trees or deeper rule
    sets may be more complex and harder to interpret (even if they’re technically
    feasible). You might create a function that selects shallower trees or rule sets,
    on the condition that they retain a certain level of predictive power.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 函数级评估不像前几个评估那样依赖于人类批评，而是依赖于所讨论的模型类型的属性。实际上，在您已经展示出您可以获得人类理解的解释之后，这是您会转向的评估类型。其中一些解释可能比其他解释更好，这可能是由于单一度量标准。例如，如果您依赖于决策树或决策规则，更深的树或更深的规则集可能更复杂且更难解释（即使它们在技术上是可行的）。您可以创建一个函数，选择较浅的树或规则集，条件是它们保留一定水平的预测能力。
- en: With these approaches in mind, let’s consider what an explanation of a large
    language model might look like according to these definitions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些方法，让我们来看看根据这些定义，一个大型语言模型的解释可能是什么样子。
- en: Definitions and Categories
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义与分类
- en: Interpretability and explainability in machine learning are complex and nuanced
    topics. Solutions that work in one domain might not work in another. As such,
    we’re going to cover a few important terms that are often used by interpretability
    and explainability practitioners and researchers.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，可解释性和可解释性是复杂且微妙的主题。在一个领域有效的解决方案可能在另一个领域无效。因此，我们将讨论一些由可解释性和解释性从业者和研究人员经常使用的重要术语。
- en: “Black Box”
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “黑盒子”
- en: 'Machine learning models are often referred to as a *black box* (we touched
    upon this in [Chapter 1](ch01.html#chapter1)). This can be for one of two reasons:
    the details of the model might be proprietary and might be intentionally hidden,
    or the function behind the model is available for inspection, but it’s so complicated
    that no human could comprehend it. Usually when talking about black box models,
    we are referring to the second reason, although many of the techniques discussed
    in this chapter could easily apply to the first reason.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型通常被称为*黑盒子*（我们在[第一章](ch01.html#chapter1)已经涉及过）。这可能有两个原因：模型的细节可能是专有的，可能是故意隐藏的；或者模型背后的功能是可以检查的，但是它非常复杂，没有人类可以理解。通常在讨论黑盒子模型时，我们指的是第二个原因，尽管本章讨论的许多技术很容易适用于第一个原因。
- en: Global Versus Local Interpretability
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全局与局部的可解释性
- en: '*Global* interpretations of a model decision can be generalized to the entire
    model behavior. *Local* interpretations are restricted to the input-output pair
    in question. The scope of interpretability could even fall somewhere between these.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*全局*解释模型决策可以推广到整个模型行为。*局部*解释被限制在所讨论的输入-输出对上。可解释性的范围甚至可以介于这两者之间。'
- en: Model-Agnostic Versus Model-Specific Methods
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型无关与模型特定方法
- en: '*Model-agnostic* interpretability methods do not depend on what type of model
    you’re using: tree based, neural network based, or something else entirely. By
    their nature, these methods do not have access to the model’s internal information,
    such as architecture or weights. Model-agnostic methods are applied after training
    and typically function by looking at data input and output pairs. These agnostic
    methods usually work by analyzing feature input and output pairs. By definition,
    these methods cannot have access to model internals such as weights or structural
    information.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型无关*的解释方法不依赖于您使用的模型类型：基于树的、基于神经网络的，或者完全不同的其他类型。这些方法本质上不访问模型的内部信息，比如结构或权重。模型无关方法通常是在训练后应用，并且通常通过观察数据的输入和输出对来运作。这些无关方法通常通过分析特征的输入和输出对来工作。根据定义，这些方法无法访问模型的内部信息，比如权重或结构信息。'
- en: '*Model-specific* interpretation tools are limited to specific model classes.
    The interpretation of regression weights in a linear model is a model-specific
    interpretation, since by definition the interpretation of intrinsically interpretable
    models is always model-specific. Tools that only work for the interpretation of
    neural networks, for example, are model-specific. Model-agnostic tools, however,
    can be used on any machine learning model.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*特定模型*的解释工具仅限于特定的模型类别。线性模型中回归权重的解释是一种特定于模型的解释，因为按定义，内在可解释模型的解释始终是特定于模型的。例如，仅适用于神经网络解释的工具属于特定于模型的工具。然而，模型无关的工具可以用于任何机器学习模型。'
- en: Interpreting GPT-2
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解读 GPT-2
- en: 'The vast majority of large language models are ML models pre-trained on a large
    corpus of text and fine-tunable for others. These are made of large numbers of
    transformer layers. They can be classified according to the differences in their
    initial modeling task as well as how many encoder and decoder layers they’re made
    of. *Autoregressive models* are pre-trained on the classic language-modeling task:
    guess the next token having read all the previous ones. They correspond to the
    decoder of the original transformer model, and a mask is used on top of the full
    sentence so that the attention heads can only see what was before in the text,
    and not what’s after. While they can be fine-tuned to do many tasks, the most
    common one is text generation.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 绝大多数大型语言模型都是在大量文本语料库上预训练的 ML 模型，并且可以进行微调以用于其他任务。这些模型由大量的 Transformer 层组成。它们可以根据初始建模任务的不同以及编码器和解码器层数的多少进行分类。*自回归模型*是在经典的语言建模任务上进行预训练的：在阅读所有先前的标记后猜测下一个标记。它们对应于原始
    Transformer 模型的解码器，还使用了一个遮罩层来覆盖整个句子，以便注意力头只能看到文本中之前的内容，而不是之后的内容。虽然它们可以进行多种任务的微调，但最常见的是文本生成。
- en: The large GPT (Generative Pre-trained Transformer) class of models from OpenAI
    are some of the most famous examples of *autoregressive language models*. [GPT-2](https://oreil.ly/62C81),
    the successor to the first-generation GPT, scaled up the size of the network and
    the data it was trained on. What made GPT-2 unique was that it was able to generalize
    to a much larger set of tasks than its predecessor, to perform much better on
    them than linear scaling laws would have predicted. OpenAI did not release GPT-2
    to the public for some time, for fear that it could generate human-like text that
    could be used for nefarious purposes. After [learning more about its capabilities](https://oreil.ly/v2iZ3),
    OpenAI slowly rolled out GPT-2 to research partners, companies, beta testers,
    and eventually the general public.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 的大型 GPT（生成预训练 Transformer）模型类是一些最著名的*自回归语言模型*示例之一。[GPT-2](https://oreil.ly/62C81)，作为第一代
    GPT 的继任者，扩大了网络的规模和训练数据的范围。使 GPT-2 独特的是，它能够推广到比其前任预测的更大任务集合，并且在这些任务上表现比线性缩放法预测的要好得多。OpenAI
    曾有一段时间没有将 GPT-2 公开发布，因为担心它可能生成类似人类文本的内容，这可能被用于不良目的。在[更多了解其能力之后](https://oreil.ly/v2iZ3)，OpenAI
    逐渐向研究伙伴、公司、测试用户以及最终向公众发布了 GPT-2。
- en: Note
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You can find all the code associated with this tutorial in the notebook [*Chapter_3_Interpreting_GPT.ipynb*](https://oreil.ly/GjIDm).
    This was heavily inspired by the LessWrong post [Interpreting GPT, the Logit Lens](https://oreil.ly/w6fiB).
    Much of the code has been refactored and now uses PyTorch and HuggingFace instead
    of TensorFlow. See the original blog post for the TensorFlow version.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在笔记本 [*Chapter_3_Interpreting_GPT.ipynb*](https://oreil.ly/GjIDm) 中找到与本教程相关的所有代码。这篇笔记受到了
    LessWrong 文章 [Interpreting GPT, the Logit Lens](https://oreil.ly/w6fiB) 的启发。大部分代码已进行了重构，现在使用的是
    PyTorch 和 HuggingFace，而不是 TensorFlow。有关 TensorFlow 版本，请参阅原始博客文章。
- en: OpenAI released [GPT-3 in 2020](https://arxiv.org/abs/2005.14165), an even larger
    model than GPT-2, trained on more data and with even higher output quality. It’s
    even more difficult to tell whether or not GPT-3’s output was written by a human.^([8](ch03.html#idm45621854672480))
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 在 [2020 年发布了 GPT-3](https://arxiv.org/abs/2005.14165)，这是比 GPT-2 更大的模型，使用更多的数据进行训练，输出质量更高。很难判断
    GPT-3 的输出是否是人类写的。^([8](ch03.html#idm45621854672480))
- en: 'At the time of writing, GPT-3 is only available through an API. This is due
    not only to safety concerns but also to the size of the model: it is so big that
    just downloading, storing, and running it is a complex, time-consuming, and potentially
    expensive process.^([9](ch03.html#idm45621854668624)) However, it’s safe to assume
    that many of the techniques and principles we use to understand GPT-2 can also
    apply to a larger model like GPT-3. With that in mind, let’s explore how you can
    get more context on GPT-2’s decisions.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，GPT-3仅通过API可用。这不仅是出于安全考虑，还因为模型体积过大：仅下载、存储和运行它就是一个复杂、耗时且可能昂贵的过程。^([9](ch03.html#idm45621854668624))
    不过，可以放心地假设我们用来理解GPT-2的许多技术和原则也可以适用于像GPT-3这样更大的模型。考虑到这一点，让我们探讨如何获取更多关于GPT-2决策背景的上下文。
- en: Tip
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: If you are specifically working with HuggingFace Transformer models, the [exBERT
    tool](https://oreil.ly/zYlcl) serves a similar function as the logit lens. This
    open source tool enables users to explore the learned attention weights and contextual
    representations of HuggingFace Transformer models. Input a sentence, and exBERT
    will pass the tokenized input through the specified model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您特别使用HuggingFace Transformer模型工作，[exBERT工具](https://oreil.ly/zYlcl)提供与逻辑镜头类似的功能。这个开源工具使用户能够探索HuggingFace
    Transformer模型的学习注意权重和上下文表示。输入一个句子，exBERT将通过指定的模型传递标记化的输入。
- en: We’re going to be using GPT-2 as it’s available from HuggingFace. For the interpretability,
    we’re going to use the utilities package [transformer-utils](https://oreil.ly/xXHAF),
    written by [nostalgebraist](https://oreil.ly/YL6uc).^([10](ch03.html#idm45621854662512))
    Let’s look at the commented excerpt.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用GPT-2，因为它可以从HuggingFace获得。为了提高可解释性，我们将使用由[nostalgebraist](https://oreil.ly/YL6uc)编写的实用程序包[transformer-utils](https://oreil.ly/xXHAF)。^([10](ch03.html#idm45621854662512))
    让我们看看评论摘录。
- en: Warning
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Running this code has a high RAM requirement. If you are running in Google Colab,
    use the largest GPU available in Colab Pro and set the RAM to the highest setting.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码需要大量的RAM。如果您在Google Colab中运行，请使用Colab Pro提供的最大GPU，并将RAM设置为最高设置。
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You’re mainly interested in the `plot_logit_lens` function, which wraps the
    various metrics you can use to look at the model. This function is geared toward
    decoders and *autoregressive models* that rely on the decoder part of the original
    transformer and use an attention mask so that at each position, the model can
    only look at the tokens before the attention heads. The space of autoregressive
    models includes [Original GPT](https://oreil.ly/pE1Dq), [GPT-2](https://oreil.ly/wsppp),
    [CTRL](https://oreil.ly/fNSRE), [Transformer-XL](https://oreil.ly/DFEeb), [Reformer](https://oreil.ly/L8uyH),
    and [XLNet](https://oreil.ly/ipV8V) (though we’ll mainly focus on GPT and its
    successors). This class of models is distinct from encoders or autoencoding models,
    or seq-to-seq transformer models, which are in turn distinct from retrieval-based
    models and multi-modal models (for example, like CLIP, described in [“Deep Dive:
    Saliency Mapping with CLIP”](#deep-dive-saliency-mapping)). To feed data into
    the autoregressive model, you need to first tokenize the input text using GPT-2’s
    tokenizer.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您主要关注的是`plot_logit_lens`函数，它包装了您可以用来查看模型的各种度量标准。这个函数专为解码器和依赖原始变压器的解码器部分以及使用注意力掩码的自回归模型而设计，因此在每个位置，模型只能查看注意力头之前的标记。自回归模型的空间包括[原始GPT](https://oreil.ly/pE1Dq)，[GPT-2](https://oreil.ly/wsppp)，[CTRL](https://oreil.ly/fNSRE)，[Transformer-XL](https://oreil.ly/DFEeb)，[Reformer](https://oreil.ly/L8uyH)和[XLNet](https://oreil.ly/ipV8V)（尽管我们主要关注GPT及其后继者）。这一类模型与编码器或自编码模型、序列到序列变压器模型以及检索模型和多模态模型（例如如CLIP中描述的）有所不同。要将数据输入自回归模型，您需要首先使用GPT-2的标记器对输入文本进行标记化。
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this section, you create a selection of texts for the model to read from,
    then use the `plot_logit_lens` function to look at the model’s ability to predict
    the next word. Our main text comes from the now-famous 2015 paper [“Human-level
    control through deep reinforcement learning”](https://oreil.ly/n8uxk). Here is
    the abstract for that paper, along with a few strings about dogs:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您可以创建模型阅读的文本选集，然后使用`plot_logit_lens`函数查看模型预测下一个词的能力。我们的主要文本来自于现在著名的2015年论文[“通过深度强化学习实现人类水平控制”](https://oreil.ly/n8uxk)。以下是该论文的摘要，以及关于狗的几个字符串：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This package generates plots of the activity at each layer of the decoder, as
    shown in [Figure 3-1](#gpt-logit-lens-0). The decoder model, for each token it
    takes in at position *n* (displayed on the bottom of the plots, representing the
    inputs), tries to predict the token at position *n* + 1 (displayed at the top
    of the plots, representing the outputs). Various hidden layers are labeled on
    the side *y*-axis. Exactly what we’re measuring at each of these layers of the
    decoder model for each of the tokens depends on the arguments you pass to the
    `plot_logit_lens` function.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 该软件包生成解码器每一层活动的图表，如[图 3-1](#gpt-logit-lens-0)所示。解码器模型针对每个位置*n*的输入令牌（显示在图表底部，表示输入）尝试预测位置*n*
    + 1的令牌（显示在图表顶部，表示输出）。各隐藏层在*Y*轴侧面标记。对于解码器模型每个令牌的每个层，我们测量的内容完全取决于您传递给`plot_logit_lens`函数的参数。
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The output of this `plot_logit_lens` function is a table of the most likely
    seeming tokens at each layer for each output position ([Figure 3-1](#gpt-logit-lens-0)).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`plot_logit_lens`函数的输出是每个输出位置上每个层最可能的令牌的表格（见[图 3-1](#gpt-logit-lens-0)）。'
- en: '![ptml 0301](assets/ptml_0301.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0301](assets/ptml_0301.png)'
- en: Figure 3-1\. Looking at the logits of each layer leading into positions 75 through
    100
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. 查看进入第75到100位置的每个层的logits
- en: It’s nice to see the specific words, but you’d also want to know how close the
    model is to suggesting the correct token at each step.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 看到具体的词语很好，但您还想知道模型在每个步骤中建议正确令牌的接近程度。
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: And you get a table of ranks at each layer ([Figure 3-2](#gpt-logit-lens-1)).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 您将获得每个层的排名表格（见[图 3-2](#gpt-logit-lens-1)）。
- en: '![ptml 0302](assets/ptml_0302.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0302](assets/ptml_0302.png)'
- en: Figure 3-2\. Rank of the probabilities of the correct token of each layer leading
    into positions 75 through 100
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. 每个层的正确令牌概率的排名，领先于第75到100位置
- en: KL divergence is useful for determining how much the full distribution of probabilities
    at each layer diverges from the eventual final output.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: KL散度有助于确定每层概率完全分布与最终输出之间的差异程度。
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This divergence starts out high early on, but then drops closer to 0 as the
    inputs propagate through the network ([Figure 3-3](#gpt-logit-lens-2)).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分歧在早期很高，但随后随着输入通过网络传播，逐渐接近0（见[图 3-3](#gpt-logit-lens-2)）。
- en: '![ptml 0303](assets/ptml_0303.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0303](assets/ptml_0303.png)'
- en: Figure 3-3\. KL divergence of probabilities
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. 概率的KL散度
- en: If the preceding isn’t informative enough for you, you can also specify the
    inclusion of sub-blocks of the network.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前面的内容对您不够详细，您还可以指定包含网络子块。
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Using this, you can see just how far the rank of the correct output token has
    to climb to get past all the competing choices ([Figure 3-4](#gpt-logit-lens-3)).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此功能，您可以看到正确输出令牌的排名需要多大努力才能超过所有竞争选择（见[图 3-4](#gpt-logit-lens-3)）。
- en: '![ptml 0304](assets/ptml_0304.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0304](assets/ptml_0304.png)'
- en: Figure 3-4\. Ranks of a rare yet correct output token throughout sub-blocks
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. 稀有但正确输出令牌的排名，涵盖子块
- en: The `plot_logit_lens` utility has a lot of options for different levels of granularity.
    What does all of this look like if we switch to a more repetitive input?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`   `plot_logit_lens`实用程序具有许多不同粒度级别的选项。如果我们切换到更加重复的输入，所有这些会是什么样子？'
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This analysis of the repetitive inputs produces [Figure 3-5](#gpt-logit-lens-4).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对重复输入的这种分析生成了[图 3-5](#gpt-logit-lens-4)。
- en: '![ptml 0305](assets/ptml_0305.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0305](assets/ptml_0305.png)'
- en: Figure 3-5\. Analysis on a more repetitive set of inputs
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5\. 对更重复的输入进行分析
- en: So how does this all relate to the three-part framework?
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这一切如何与三部分框架相关联？
- en: If you wanted to do an application-level evaluation, could a machine learning
    engineer easily understand what’s going on? You would want to compare the explanation
    produced by the application-level evaluation to other ways of explaining the internals
    of the large language models. Most importantly, you would want to compare this
    to how the ML engineer’s colleagues might explain what’s going on within the model.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想进行应用级评估，机器学习工程师能否轻松理解正在发生的事情？您希望将应用级评估产生的解释与其他解释大型语言模型内部机制的方法进行比较。最重要的是，您希望将其与ML工程师的同事如何解释模型内部机制进行比较。
- en: If you wanted to evaluate this explanation in terms of a “human-level evaluation,”
    you’d expand your focus beyond just machine learning developers to ask whether
    a non-ML software engineer (or, better yet, a non-engineer) could understand what
    was going on in the model. This approach might involve making the explanation
    of the input-to-output framing much more explicit in the plot.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想从“人类水平评估”的角度来评价这个解释，你会把焦点从仅限于机器学习开发者扩展到询问非机器学习软件工程师（或者更好的是非工程师）是否能理解模型中正在发生的事情。这种方法可能涉及在图中更明确地解释从输入到输出的框架。
- en: You might look at a functional-level evaluation after you’ve gotten human feedback.
    Once you understand what kinds of explanations a human can start to understand,
    you want some kind of proxy metric with which to evaluate the explanations. For
    example, how early does the correct token appear in the diagram? We could compare
    this timing across other transformer models. You might also time how long it takes
    for your interpretability method to run. The various approaches to analyzing the
    layers of a GPT model were all much faster than a technique like SHapley Additive
    exPlanations (or SHAP, defined in [“Shapley and SHAP”](#shapley-shap-sect)) would
    have been for such a large set of inputs and outputs.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在得到人类反馈后进行功能级评估。一旦你了解了人类能够开始理解的解释类型，你就希望有某种代理指标来评估这些解释。例如，正确令牌在图表中出现的时间有多早？我们可以比较这种时间跨其他变压器模型。你还可以计时解释性方法的运行时间。分析GPT模型层次的各种方法比像SHapley
    Additive exPlanations（或简称SHAP，见[“Shapley and SHAP”](#shapley-shap-sect)）这样的技术对如此大量的输入和输出来说要快得多。
- en: Methods for Explaining Models and Interpreting Outputs
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释模型和解释输出的方法
- en: The field of model explainability and interpretability changes quickly. However,
    some methods have stood the test of time, even after decades of use.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可解释性和可解释性领域发展迅速。然而，一些方法即使经过数十年的使用仍经受住了时间的考验。
- en: Inherently Explainable Models
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本质上可解释的模型
- en: Some models are easy to explain because their individual parameters correspond
    to decision points that humans can easily understand, such as linear and logistic
    regression models, symbolic regression models, support vector machines, and decision
    trees.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一些模型易于解释，因为它们的各个参数对应于人类可以轻松理解的决策点，例如线性和逻辑回归模型、符号回归模型、支持向量机和决策树。
- en: Linear regression
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性回归
- en: '*Linear regression* (and by extension multilinear regression) is perhaps the
    simplest type of inherently explainable model. A linear regression model simply
    takes in a dataset of a dependent and independent variable. Given a dataset <math
    alttext="StartSet y Subscript i Baseline comma x Subscript i Baseline 1 Baseline
    comma ellipsis comma x Subscript i p Baseline EndSet Subscript i equals 1 Superscript
    n"><msubsup><mrow><mo>{</mo><msub><mi>y</mi> <mi>i</mi></msub> <mo>,</mo><msub><mi>x</mi>
    <mrow><mi>i</mi><mn>1</mn></mrow></msub> <mo>,</mo><mo>...</mo><mo>,</mo><msub><mi>x</mi>
    <mrow><mi>i</mi><mi>p</mi></mrow></msub> <mo>}</mo></mrow> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup></math> , with <math alttext="y"><mi>y</mi></math> representing
    the independent variable and <math alttext="x"><mi>x</mi></math> representing
    the dependent variable, the model is <math alttext="y Subscript i Baseline equals
    beta 0 plus beta 1 x Subscript i Baseline 1 Baseline plus ellipsis plus beta Subscript
    p Baseline x Subscript i p Baseline plus epsilon Subscript i Baseline equals bold
    x Subscript i Superscript upper T Baseline beta plus epsilon Subscript i"><mrow><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>=</mo> <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>β</mi>
    <mn>1</mn></msub> <msub><mi>x</mi> <mrow><mi>i</mi><mn>1</mn></mrow></msub> <mo>+</mo>
    <mo>...</mo> <mo>+</mo> <msub><mi>β</mi> <mi>p</mi></msub> <msub><mi>x</mi> <mrow><mi>i</mi><mi>p</mi></mrow></msub>
    <mo>+</mo> <msub><mi>ϵ</mi> <mi>i</mi></msub> <mo>=</mo> <msubsup><mi>𝐱</mi> <mrow><mi>i</mi></mrow>
    <mi>T</mi></msubsup> <mi>β</mi> <mo>+</mo> <msub><mi>ϵ</mi> <mi>i</mi></msub></mrow></math>
    , where <math alttext="i equals 1 comma ellipsis comma n"><mrow><mi>i</mi> <mo>=</mo>
    <mn>1</mn> <mo>,</mo> <mo>...</mo> <mo>,</mo> <mi>n</mi></mrow></math> .'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*线性回归*（以及多元线性回归）或许是最简单的固有可解释模型类型。线性回归模型只需输入一个依赖变量和一个独立变量的数据集。给定数据集 <math alttext="StartSet
    y Subscript i Baseline comma x Subscript i Baseline 1 Baseline comma ellipsis
    comma x Subscript i p Baseline EndSet Subscript i equals 1 Superscript n"><msubsup><mrow><mo>{</mo><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>,</mo><msub><mi>x</mi> <mrow><mi>i</mi><mn>1</mn></mrow></msub>
    <mo>,</mo><mo>...</mo><mo>,</mo><msub><mi>x</mi> <mrow><mi>i</mi><mi>p</mi></mrow></msub>
    <mo>}</mo></mrow> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup></math>
    ，其中 <math alttext="y"><mi>y</mi></math> 表示独立变量，<math alttext="x"><mi>x</mi></math>
    表示依赖变量，模型为 <math alttext="y Subscript i Baseline equals beta 0 plus beta 1 x Subscript
    i Baseline 1 Baseline plus ellipsis plus beta Subscript p Baseline x Subscript
    i p Baseline plus epsilon Subscript i Baseline equals bold x Subscript i Superscript
    upper T Baseline beta plus epsilon Subscript i"><mrow><msub><mi>y</mi> <mi>i</mi></msub>
    <mo>=</mo> <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mrow><mi>i</mi><mn>1</mn></mrow></msub> <mo>+</mo> <mo>...</mo>
    <mo>+</mo> <msub><mi>β</mi> <mi>p</mi></msub> <msub><mi>x</mi> <mrow><mi>i</mi><mi>p</mi></mrow></msub>
    <mo>+</mo> <msub><mi>ϵ</mi> <mi>i</mi></msub> <mo>=</mo> <msubsup><mi>𝐱</mi> <mrow><mi>i</mi></mrow>
    <mi>T</mi></msubsup> <mi>β</mi> <mo>+</mo> <msub><mi>ϵ</mi> <mi>i</mi></msub></mrow></math>
    ，其中 <math alttext="i equals 1 comma ellipsis comma n"><mrow><mi>i</mi> <mo>=</mo>
    <mn>1</mn> <mo>,</mo> <mo>...</mo> <mo>,</mo> <mi>n</mi></mrow></math> 。'
- en: 'Here the various beta terms describe the linear relationship, and epsilon represents
    a random error term. To see this in action, let’s look at a very simple linear
    regression example:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这里各个 beta 项描述了线性关系，而 epsilon 表示随机误差项。要看到这一点的实际效果，让我们看一个非常简单的线性回归示例：
- en: '[PRE8]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If you have a regression problem, it’s a best practice to first make sure the
    problem is adequately solvable with linear regression before moving onto more
    complex models. You might be surprised to see just how many problems are adequately
    solved by a linear regression model.^([11](ch03.html#idm45621848233456))
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个回归问题，在转向更复杂的模型之前，首先确保线性回归能够充分解决这个问题是最佳实践。你可能会惊讶地看到有多少问题可以通过线性回归模型充分解决。^([11](ch03.html#idm45621848233456))
- en: Tip
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'Do you want to speed up scikit-learn on (Intel) CPUs? With [scikit-learn-intelex](https://oreil.ly/YEwz1),
    you can get from 1.4 up to about 4,800× speedups by adding one line of code:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 想要在 (Intel) CPU 上加速 scikit-learn 吗？通过 [scikit-learn-intelex](https://oreil.ly/YEwz1)，只需添加一行代码，速度提高了大约
    1.4 至 4,800 倍：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Speaking of code, these intrinsically interpretable models can be explored more
    in the notebook [*Chapter_3_Intrinsically_Interpretable_Models.ipynb*](https://oreil.ly/IxnwJ).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到代码，这些固有可解释模型可以在笔记本 [*Chapter_3_Intrinsically_Interpretable_Models.ipynb*](https://oreil.ly/IxnwJ)
    中进一步探索。
- en: Logistic regression
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: '*Logistic regression* is a type of linear model that is used to predict the
    probability of a categorical variable. In other words, it is a binary classifier.
    The reason it’s referred to as “regression” is that it is a regression model for
    the *probability* of an event or variable. The value of this event or variable
    depends on whether or not a certain probability threshold has been met.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*逻辑回归*是一种线性模型，用于预测分类变量的概率。换句话说，它是一个二元分类器。之所以称为“回归”，是因为它是一个事件或变量概率的回归模型。该事件或变量的值取决于是否达到了某个概率阈值。'
- en: Logistic regression is also known in the literature as *logit regression*, *maximum-entropy
    classification (MaxEnt)*, or the *log-linear classifier*. In this model, the probabilities
    describing the possible outcomes of a single trial are modeled using a [logistic
    function](https://oreil.ly/yvTrp) <math alttext="f left-parenthesis x right-parenthesis
    equals StartFraction upper L Over 1 plus e Superscript minus k left-parenthesis
    x minus x 0 right-parenthesis Baseline EndFraction"><mrow><mi>f</mi> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mi>L</mi> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>k</mi><mo>(</mo><mi>x</mi><mo>-</mo><msub><mi>x</mi> <mn>0</mn></msub>
    <mo>)</mo></mrow></msup></mrow></mfrac></mrow></math> , where <math alttext="x
    0"><msub><mi>x</mi> <mn>0</mn></msub></math> is the <math alttext="x"><mi>x</mi></math>
    value of the sigmoid’s midpoint, <math alttext="upper L"><mi>L</mi></math> is
    the curve’s maximum value, and <math alttext="k"><mi>k</mi></math> is the logistic
    growth rate or steepness of the curve.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在文献中，逻辑回归也被称为*logit回归*、*最大熵分类（MaxEnt）*或*对数线性分类器*。在该模型中，通过一个[逻辑函数](https://oreil.ly/yvTrp)，来建模描述单次试验可能结果的概率，其中<math
    alttext="f left-parenthesis x right-parenthesis equals StartFraction upper L Over
    1 plus e Superscript minus k left-parenthesis x minus x 0 right-parenthesis Baseline
    EndFraction"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mfrac><mi>L</mi> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi> <mrow><mo>-</mo><mi>k</mi><mo>(</mo><mi>x</mi><mo>-</mo><msub><mi>x</mi>
    <mn>0</mn></msub> <mo>)</mo></mrow></msup></mrow></mfrac></mrow></math>，其中<math
    alttext="x 0"><msub><mi>x</mi> <mn>0</mn></msub></math>是S型函数中点的<math alttext="x"><mi>x</mi></math>值，<math
    alttext="upper L"><mi>L</mi></math>是曲线的最大值，<math alttext="k"><mi>k</mi></math>是逻辑增长率或曲线的陡峭度。
- en: In this code snippet, you can create a basic logistic regression model and then
    view the decision boundaries.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码片段中，您可以创建一个基本的逻辑回归模型，然后查看决策边界。
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Much like how linear regression is the simple first option for regression problems,
    logistic regression is the simple first option for classification problems. As
    you can see in the preceding code snippet, the logistic regression model is so
    simple to define that most of the code is used for the plotting.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 就像线性回归是回归问题的简单首选一样，逻辑回归是分类问题的简单首选。正如您在前面的代码片段中看到的那样，逻辑回归模型定义起来非常简单，大部分代码用于绘图。
- en: Linear models that describe their outputs as a weighted sum of the input variables
    are easy to implement and understand. The problem is that they depend on certain
    assumptions that often do not hold in the real world. For example, linear regression
    often assumes that the error epsilon follows a Gaussian distribution, but real-world
    phenomena can follow distributions that look nothing like a Gaussian. Some variables
    might interact while others might not. Among those that interact, some might have
    linear relationships, and some might have nonlinear relationships. Fortunately,
    there are a wide variety of nonlinear models that better fit the data and still
    provide interpretability.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 将它们的输出描述为输入变量加权和的线性模型易于实施和理解。问题在于它们依赖于通常在现实世界中不成立的某些假设。例如，线性回归通常假设误差ε遵循高斯分布，但现实世界的现象可能遵循看起来与高斯分布完全不同的分布。有些变量可能会互相作用，而另一些则可能不会。在相互作用的变量中，有些可能具有线性关系，而另一些可能具有非线性关系。幸运的是，有各种各样的非线性模型可以更好地拟合数据，同时仍然提供解释能力。
- en: Generalized linear model
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 广义线性模型
- en: If the target outcome *y*, given the features, does not follow a Gaussian distribution,
    then a *generalized linear model* (GLM) is a good choice. The main approach of
    GLMs is to keep the weighted sum of features, but allow non-Gaussian outcome distributions
    and connect the expected mean of this distribution to the weighted sum.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果给定特征时目标结果*y*不符合高斯分布，则广义线性模型（GLM）是一个不错的选择。GLM的主要方法是保持特征的加权和，但允许非高斯结果分布，并将此分布的期望均值与加权和相连接。
- en: <math alttext="g left-parenthesis upper E Subscript upper Y Baseline left-parenthesis
    y vertical-bar x right-parenthesis right-parenthesis equals beta 0 plus beta 1
    x 1 plus ellipsis beta Subscript p Baseline x Subscript p" display="block"><mrow><mi>g</mi>
    <mrow><mo>(</mo> <msub><mi>E</mi> <mi>Y</mi></msub> <mrow><mo>(</mo> <mi>y</mi>
    <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <msub><mi>β</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo> <mo>...</mo> <msub><mi>β</mi> <mi>p</mi></msub> <msub><mi>x</mi>
    <mi>p</mi></msub></mrow></math>
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="g left-parenthesis upper E Subscript upper Y Baseline left-parenthesis
    y vertical-bar x right-parenthesis right-parenthesis equals beta 0 plus beta 1
    x 1 plus ellipsis beta Subscript p Baseline x Subscript p" display="block"><mrow><mi>g</mi>
    <mrow><mo>(</mo> <msub><mi>E</mi> <mi>Y</mi></msub> <mrow><mo>(</mo> <mi>y</mi>
    <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <msub><mi>β</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo> <mo>...</mo> <msub><mi>β</mi> <mi>p</mi></msub> <msub><mi>x</mi>
    <mi>p</mi></msub></mrow></math>
- en: While GLMs can be used for Gaussian distributions, this approach can also be
    applied to Poisson, gamma, and inverse gamma distributions.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然GLMs可用于高斯分布，但这种方法也可应用于泊松、Gamma和反Gamma分布。
- en: For GLMs, you can turn to scikit-learn’s [generalized linear models](https://oreil.ly/lxOV8).
    Upon importing the TweedieRegressor, you can toggle the `power`, `alpha`, and
    `link` settings to adjust the complexity of your linear model.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于GLMs，你可以使用scikit-learn的[广义线性模型](https://oreil.ly/lxOV8)。在导入TweedieRegressor后，你可以调整`power`、`alpha`和`link`设置来调整线性模型的复杂性。
- en: '[PRE12]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The output is a series of coefficients (all the beta values) and an intercept
    (corresponding to the first beta).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一系列系数（所有beta值）和一个截距（对应于第一个beta）。
- en: Generalized additive models
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 广义可加模型
- en: 'If the true relationship between the features and *y* is not linear, then a
    *generalized additive model* (GAM) is a good choice. GAMs are basically GLMs that
    allow nonlinear relationships. The formula is very similar:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果特征与*y*之间的真实关系不是线性的，那么**广义可加模型**（GAM）是一个不错的选择。GAMs基本上是允许非线性关系的广义线性模型（GLMs）。其公式非常相似：
- en: <math alttext="g left-parenthesis upper E Subscript upper Y Baseline left-parenthesis
    y vertical-bar x right-parenthesis right-parenthesis equals beta 0 plus f 1 left-parenthesis
    x 1 right-parenthesis plus f 2 left-parenthesis x 2 right-parenthesis plus ellipsis
    plus f Subscript p Baseline left-parenthesis x Subscript p Baseline right-parenthesis"
    display="block"><mrow><mi>g</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mi>Y</mi></msub>
    <mrow><mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>f</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>+</mo>
    <msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>f</mi> <mi>p</mi></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>p</mi></msub> <mo>)</mo></mrow></mrow></math>
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="g left-parenthesis upper E Subscript upper Y Baseline left-parenthesis
    y vertical-bar x right-parenthesis right-parenthesis equals beta 0 plus f 1 left-parenthesis
    x 1 right-parenthesis plus f 2 left-parenthesis x 2 right-parenthesis plus ellipsis
    plus f Subscript p Baseline left-parenthesis x Subscript p Baseline right-parenthesis"
    display="block"><mrow><mi>g</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mi>Y</mi></msub>
    <mrow><mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>f</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>+</mo>
    <msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>f</mi> <mi>p</mi></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>p</mi></msub> <mo>)</mo></mrow></mrow></math>
- en: The only difference is that the linear terms <math alttext="beta Subscript p
    Baseline x Subscript p"><mrow><msub><mi>β</mi> <mi>p</mi></msub> <msub><mi>x</mi>
    <mi>p</mi></msub></mrow></math> have been replaced with more flexible <math alttext="f
    Subscript p Baseline left-parenthesis x Subscript p Baseline right-parenthesis"><mrow><msub><mi>f</mi>
    <mi>p</mi></msub> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>p</mi></msub> <mo>)</mo></mrow></mrow></math>
    functions (usually representing splines). It’s still a sum of features, but optional
    nonlinearity is now represented by the functions.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的区别是线性项<math alttext="beta Subscript p Baseline x Subscript p"><mrow><msub><mi>β</mi>
    <mi>p</mi></msub> <msub><mi>x</mi> <mi>p</mi></msub></mrow></math> 被更加灵活的<math
    alttext="f Subscript p Baseline left-parenthesis x Subscript p Baseline right-parenthesis"><mrow><msub><mi>f</mi>
    <mi>p</mi></msub> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>p</mi></msub> <mo>)</mo></mrow></mrow></math>
    函数（通常代表样条函数）取代。它仍然是特征的总和，但现在可选的非线性由这些函数表示。
- en: To use GAMs in Python, you can use [pyGAM](https://oreil.ly/eQwEd).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Python中使用GAMs，你可以使用[pyGAM](https://oreil.ly/eQwEd)。
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Generalized additive models plus interactions
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 广义可加模型加交互项
- en: If features interact, then you can either add up interactions manually or turn
    to *generalized additive models plus interactions* (GA2Ms).^([12](ch03.html#idm45621842768384))
    These capture much more complex interactions than regular GAMs do. Applying GA2Ms
    to a dataset is not that different from applying the GAMs.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果特征之间存在交互作用，那么你可以手动添加交互项，或者转向**广义可加模型加交互项**（GA2Ms）。^([12](ch03.html#idm45621842768384))
    这些模型捕捉的交互作用比普通的GAMs复杂得多。将GA2Ms应用到数据集上与应用GAMs并没有太大区别。
- en: '[PRE14]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Beyond exploring the data, you can also train the GA2M model, which manifests
    itself as the `ExplainableBoostingRegressor` class. If you’re working on a classification
    problem, you use the `ExplainableBoostingClassifier` class instead.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 除了探索数据外，你还可以训练GA2M模型，它表现为`ExplainableBoostingRegressor`类。如果你在解决分类问题，可以使用`ExplainableBoostingClassifier`类。
- en: '[PRE15]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: What’s the downside of using this approach? Although the pairwise interaction
    terms in GA2M increase accuracy greatly, the model is *extremely* time-consuming
    and CPU-hungry.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法的缺点是什么？虽然GA2M中的成对交互项极大地提高了准确性，但该模型的计算非常耗时和CPU密集。
- en: Symbolic regression
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 符号回归
- en: Many of the previously described methods can be thought of as ways to create
    large equations to serve as models. *Symbolic regression* (SR) takes this to the
    extreme, by iteratively changing components of a formula to better fit the data.
    SR seeks an accurate model of the data in the form of a (hopefully elegant) mathematical
    expression. SR is generally considered hard and is usually attempted using evolutionary
    algorithms. If you have tabular data or data that could theoretically be described
    using an equation, then symbolic regression is a good choice.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 先前描述的许多方法都可以视为创建大型方程作为模型的方式。*符号回归*（SR）将这一过程推向极致，通过迭代地改变公式的组成部分以更好地拟合数据。SR寻求以（希望是优雅的）数学表达式形式的数据准确模型。SR通常被认为是困难的，并且通常使用进化算法尝试。如果你有表格数据或者可以用方程描述的数据，那么符号回归是一个不错的选择。
- en: Suppose you have a two-dimensional dataset like the following.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个二维数据集，如下所示。
- en: '[PRE16]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This has created a dataset with 100 data points, with 5 features each. The relation
    to model is 2.5382 <math alttext="cosine left-parenthesis x 3 right-parenthesis
    plus x 0 squared minus 0.5"><mrow><mo form="prefix">cos</mo> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>3</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <msubsup><mi>x</mi>
    <mn>0</mn> <mn>2</mn></msubsup> <mo>-</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn></mrow></math>
    . Now, let’s create a [PySR](https://oreil.ly/GeV6M) model and train it. PySR’s
    main interface is in the style of scikit-learn.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集包含 100 个数据点，每个数据点有 5 个特征。与模型的关系是 2.5382 <math alttext="cosine left-parenthesis
    x 3 right-parenthesis plus x 0 squared minus 0.5"><mrow><mo form="prefix">cos</mo>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>)</mo></mrow> <mo>+</mo>
    <msubsup><mi>x</mi> <mn>0</mn> <mn>2</mn></msubsup> <mo>-</mo> <mn>0</mn> <mo>.</mo>
    <mn>5</mn></mrow></math> 。现在，让我们创建一个 [PySR](https://oreil.ly/GeV6M) 模型并进行训练。PySR
    的主要接口采用了类似 scikit-learn 的风格。
- en: '[PRE17]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This will set up the model for 40 iterations of the search code, which contains
    hundreds of thousands of mutations and equation evaluations. You can then fit
    the model to the data by running `model.fit(X, y)`. Internally, this launches
    a Julia process, which will do a multithreaded search for equations to fit the
    dataset.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这将设置模型为搜索代码的 40 次迭代，其中包含数十万次的变异和方程求解。然后，您可以通过运行 `model.fit(X, y)` 将模型拟合到数据上。在内部，这将启动一个
    Julia 进程，该进程将进行多线程搜索以适应数据集的方程式。
- en: Note
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you’re not familiar with the [Julia language](https://julialang.org), it’s
    incredibly useful for machine learning. Julia is a dynamic, general-purpose programming
    language capable of high-performance scientific computing with high-level code.
    It is known for being able to handle any kind of UTF-8 encoding like math symbols
    and emojis.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不熟悉 [Julia 语言](https://julialang.org)，它对机器学习非常有用。Julia 是一种动态的、通用的编程语言，能够进行高性能科学计算，支持高级代码中的
    UTF-8 编码，如数学符号和表情符号。
- en: If you want to learn more, O’Reilly has some great resources, such as [“Learning
    Julia”](https://oreil.ly/E58zY).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多，O’Reilly 有一些很棒的资源，比如 [“学习 Julia”](https://oreil.ly/E58zY)。
- en: Equations will be printed during training, and once you are satisfied, you may
    quit early by hitting `'q'` and then `\<enter\>`. After the model has been fit,
    you can run `model.predict(X)` to see the predictions on a given dataset. Run
    `print(model)` to print the learned equations.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式将在训练过程中打印出来，一旦您满意，可以通过按 `'q'` 然后 `\<enter\>` 来提前退出。模型拟合完成后，您可以运行 `model.predict(X)`
    来查看在给定数据集上的预测结果。运行 `print(model)` 可以打印出学习到的方程式。
- en: '[PRE18]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This arrow in the `pick` column indicates which equation is currently selected
    by your `model_selection` strategy for prediction (you may change `model_selection`
    after `.fit(X, y)` as well). `model.equations_` is a Pandas DataFrame containing
    all equations, including callable format (`lambda_format`), SymPy format (`sympy_format`,
    which you can also get with `model.sympy()`), and even JAX and PyTorch format
    (both of which are differentiable and that you can get with `model.jax()` and
    `model.pytorch()`).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个箭头在 `pick` 列中表示您的 `model_selection` 策略当前选择的方程式用于预测（您也可以在 `.fit(X, y)` 后更改
    `model_selection`）。`model.equations_` 是一个 Pandas DataFrame，包含所有方程式，包括可调用格式（`lambda_format`）、SymPy
    格式（`sympy_format`，您也可以通过 `model.sympy()` 获得）、以及 JAX 和 PyTorch 格式（这两者都是可微分的，可以通过
    `model.jax()` 和 `model.pytorch()` 获得）。
- en: Support vector machines
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 支持向量机
- en: A precursor to neural network methods, *support vector machines* (SVMs) are
    a set of supervised learning methods used for classification, regression, and
    outlier detection. SVMs are great for when you have high-dimensional data, with
    possibly more dimensions than samples in your dataset. SVMs are memory-efficient
    and can be customized with their kernel functions (though packages like sklearn
    already have some great ones). The main downside of SVMs is that regularization
    is crucial if you want to avoid overfitting. Unlike methods like logistic regression,
    SVMs do not provide probability estimates. You need to turn to methods like fivefold
    cross-validation to get those estimates, and doing so will likely undo any computing
    efficiency advantages from using SVMs.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 作为神经网络方法的前身，*支持向量机*（SVM）是一组用于分类、回归和异常检测的监督学习方法。SVM 在处理高维数据时效果显著，可能比数据集中的样本更多的维度还要多。SVM
    内存效率高，可以通过核函数进行定制化（虽然像 sklearn 这样的包已经具有了一些出色的核函数）。SVM 的主要缺点是如果要避免过拟合，正则化至关重要。与逻辑回归等方法不同，SVM
    不提供概率估计。您需要使用类似五折交叉验证的方法来获取这些估计，这样做可能会消除使用 SVM 的计算效率优势。
- en: To use SVMs, there are many methods, but the most popular is scikit-learn’s
    [support vector machine implementation](https://oreil.ly/5NYAF).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用SVM，有许多方法，但最流行的是scikit-learn的[支持向量机实现](https://oreil.ly/5NYAF)。
- en: '[PRE19]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Decision tree
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 决策树
- en: Like SVMs, *decision trees* excel at fitting to nonlinear relationships (though
    they can struggle with linear relationships). Where decision trees excel is in
    sorting data into distinct groups and providing intuitive visualizations.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于SVM，*决策树*在拟合非线性关系方面表现出色（尽管它们在处理线性关系时可能会遇到困难）。决策树擅长的是将数据分类为不同组，并提供直观的可视化。
- en: 'Like many other machine learning methods, scikit-learn has a variety of [decision
    tree variants available](https://oreil.ly/u81jy). It’s also worth talking about
    one of the more popular interpretable decision tree algorithms: [XGBoost](https://oreil.ly/EkTuq)
    (which also has a [scikit-learn-like API](https://oreil.ly/pz1qL)).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多其他机器学习方法类似，scikit-learn提供了多种[决策树变体](https://oreil.ly/u81jy)。还值得一提的是其中一种更受欢迎的可解释决策树算法：[XGBoost](https://oreil.ly/EkTuq)（它也具有类似于[scikit-learn的API](https://oreil.ly/pz1qL)）。
- en: '[PRE20]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Decision rules
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 决策规则
- en: A *decision rule* is a set of if-then statements that can be used to make a
    decision. If the conditions in the if-then statement are met, then the decision
    rule will be followed. Decision rules are often used in decision-making processes
    because they are easy to understand and can be applied quickly. When most people
    start out programming in languages like Python, it’s common for them to use if-then
    statements extensively. As such, this can be a very intuitive way of understanding
    the logic behind a decision.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*决策规则*是一组if-then语句，可用于做出决策。如果if-then语句中的条件得到满足，则会执行决策规则。决策规则通常用于决策过程中，因为它们易于理解并且可以快速应用。当大多数人开始使用像Python这样的编程语言时，他们通常会广泛使用if-then语句。因此，这可以成为理解决策逻辑的一种非常直观的方式。'
- en: 'Creating all these if-then statements for a dataset with a large number of
    features can be very time consuming. There are many algorithms for coming up with
    these rules. Here are three of the most popular:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个包含大量特征的数据集的if-then语句可能非常耗时。有许多算法可以生成这些规则。以下是其中三种最受欢迎的：
- en: '*OneR*'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '*OneR*'
- en: OneR learns rules based on a single feature. It’s one of the simplest and easiest-to-understand
    approaches. While other algorithms may produce more accurate rules, OneR is fast
    and easy enough to serve as a benchmark to compare other algorithms against. To
    leverage OneR in Python, you can use the `OneRClassifier` implementation in the
    [MLxtend library](https://oreil.ly/BDIoD).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: OneR基于单个特征学习规则。这是一种最简单且易于理解的方法之一。虽然其他算法可能生成更准确的规则，但OneR快速而简单，足以作为与其他算法进行比较的基准。要在Python中使用OneR，您可以使用[MLxtend库](https://oreil.ly/BDIoD)中的`OneRClassifier`实现。
- en: Note
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: OneR is a very simple algorithm that assumes the data is categorical. It will
    not work as well with continuous data. You probably don’t want to rely on it for
    complex NLP or computer vision tasks.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: OneR是一个非常简单的算法，假设数据是分类的。它在处理连续数据时效果不佳。您可能不希望依赖它来处理复杂的自然语言处理或计算机视觉任务。
- en: '*Sequential covering*'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '*顺序覆盖*'
- en: Sequential covering is an iterative method that adds new if-then rules, removes
    the data points that are explained by the new rules, and repeats the process for
    the remaining data points until all the data points are explained. For using decision
    rules generated via sequential covering, [Oracle’s Skater library](https://oreil.ly/LkiWk)
    has good implementations.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序覆盖是一种迭代方法，通过添加新的if-then规则，移除被新规则解释的数据点，并重复该过程，直到所有数据点都得到解释。使用顺序覆盖生成的决策规则时，[Oracle的Skater库](https://oreil.ly/LkiWk)有良好的实现。
- en: '*Bayesian rule lists*'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '*贝叶斯规则列表*'
- en: This approach involves bringing in various frequentist statistics about the
    data as a starting point. This prior knowledge about the patterns can then be
    used to create a decision list based on Bayesian statistics. Depending on the
    implementation, this may also have some overlap with sequential covering. For
    implementing decision rules via Bayesian rule lists, a tool like the [iModels](https://oreil.ly/yDK4M)
    package is a great choice; it has an interface similar to that of sklearn. It
    also contains implementation of specific decision rules algorithms like Friedman
    and Popescu’s RuleFit.^([13](ch03.html#idm45621841570432))
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法涉及引入关于数据的各种频率统计作为起点的先验知识。这些关于模式的先验知识可以用来基于贝叶斯统计创建决策列表。根据实现方式，这可能还与顺序覆盖有一些重叠。对于通过贝叶斯规则列表实现决策规则，像[iModels](https://oreil.ly/yDK4M)包这样的工具是一个很好的选择；它具有类似于sklearn的接口。它还包含特定决策规则算法的实现，如Friedman和Popescu的RuleFit。^([13](ch03.html#idm45621841570432))
- en: Beyond intrinsically interpretable models
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 超越内在可解释模型
- en: All of the models described thus far have some easy way to transform their parameters
    into human-understandable guides to their underlying decision making. However,
    for a lot of domains, you may want a model that predicts the patterns in the data
    well regardless of how easy to understand its parameters are. Since 2012, neural
    network–based methods have replaced a lot of the methods we’ve described here
    in many domains. Given how much neural networks can vary, there should be interpretability
    methods that aren’t specific to any one model.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，所有描述的模型都有一些简单的方法来将它们的参数转化为人类可理解的指导，以解释它们的基础决策。然而，在许多领域，您可能希望有一个预测数据模式的模型，而不管其参数的易理解程度如何。自2012年以来，基于神经网络的方法已经在许多领域取代了我们在这里描述的许多方法。考虑到神经网络的巨大变化，应该有一些不特定于任何一个模型的解释方法。
- en: Local Model-Agnostic Interpretability Methods
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本地模型无关解释方法
- en: As we’ve mentioned, local interpretability focuses on making sense of individual
    predictions. Many of the previously discussed models had built-in methods for
    interpreting local predictions, such as the terms in a decision tree or multiple
    linear regression. However, if we’re comparing multiple model types that include
    many different architectures of neural networks, using these intrinsic interpretability
    methods will be like comparing apples and oranges. This is why we’d ideally like
    to have a way to combine local interpretability with model-agnostic interpretability.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，本地可解释性侧重于理解个体预测的意义。许多先前讨论的模型都有内置的方法来解释局部预测，例如决策树中的项或多重线性回归。然而，如果我们比较包括许多不同神经网络架构的多个模型类型，使用这些内在可解释性方法将像是在比较苹果和橙子。这就是为什么我们理想地希望有一种方法来结合局部可解释性和模型无关的可解释性。
- en: Local interpretable model-agnostic explanation
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本地可解释模型无关解释
- en: 'A *local interpretable model-agnostic explanation* (LIME) explains a prediction
    by replacing the complex model with a locally interpretable surrogate model. You
    can apply this technique to image, text, and even tabular data. The general steps
    of this technique are as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*本地可解释模型无关解释*（LIME）通过用本地可解释的替代模型替换复杂模型来解释预测。您可以将此技术应用于图像、文本，甚至表格数据。此技术的一般步骤如下：
- en: Select a bunch of instances of outputs from the model you want to interpret.
    (This is *local*, because we’re only interpreting this limited set rather than
    the *global* set of all possible model outputs.)
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择模型输出的一堆实例来解释您想要解释的模型。（这是*局部*的，因为我们只解释这个有限集而不是所有可能的模型输出的*全局*集合。）
- en: Create a surrogate model that reproduces the behavior of the model you want
    to interpret on these instances. You will know nothing about the model internals,
    only what the outputs look like.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个替代模型，它复制您想要解释的模型在这些实例上的行为。您将不了解模型内部，只知道输出的外观。
- en: Create random perturbations of the input data and see how the surrogate model
    classifies them.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建输入数据的随机扰动，并查看替代模型如何对其进行分类。
- en: Use these classification boundaries to create a decision boundary that can be
    used to explain the model’s predictions.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这些分类边界创建一个决策边界，可用于解释模型的预测。
- en: 'If you want a more formal mathematical version of this, assume the input data
    is <math alttext="x"><mi>x</mi></math> . The complex model to be interpreted is
    <math alttext="f"><mi>f</mi></math> , the simple interpretable model is <math
    alttext="g"><mi>g</mi></math> (with <math alttext="g element-of upper G"><mrow><mi>g</mi>
    <mo>∈</mo> <mi>G</mi></mrow></math> indicating that it is in the set of sparse
    linear models, like the kind discussed previously), and <math alttext="pi Subscript
    x"><msub><mi>π</mi> <mi>x</mi></msub></math> is a proximity measure indicating
    the size of the local neighborhood of your data points <math alttext="x"><mi>x</mi></math>
    . From this, you would create a loss function <math alttext="script upper L"><mi>ℒ</mi></math>
    that minimizes the difference between the outputs of <math alttext="f"><mi>f</mi></math>
    and <math alttext="g"><mi>g</mi></math> to be within <math alttext="pi Subscript
    x"><msub><mi>π</mi> <mi>x</mi></msub></math> . Without any modification, this
    process would just make a complicated <math alttext="g"><mi>g</mi></math> nearly
    identical to <math alttext="f"><mi>f</mi></math> . This is why you add <math alttext="normal
    upper Omega left-parenthesis g right-parenthesis"><mrow><mi>Ω</mi> <mo>(</mo>
    <mi>g</mi> <mo>)</mo></mrow></math> , which is a regularizer that limits the complexity
    of your interpretable model <math alttext="g"><mi>g</mi></math> . This brings
    you to your general equation for training LIME:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要这个更正式的数学版本，假设输入数据为<math alttext="x"><mi>x</mi></math>。要解释的复杂模型是<math alttext="f"><mi>f</mi></math>，简单可解释模型是<math
    alttext="g"><mi>g</mi></math>（其中<math alttext="g element-of upper G"><mrow><mi>g</mi>
    <mo>∈</mo> <mi>G</mi></mrow></math>表明它属于稀疏线性模型的集合，如先前讨论的那种），而<math alttext="pi
    Subscript x"><msub><mi>π</mi> <mi>x</mi></msub></math>是一个指示您的数据点<math alttext="x"><mi>x</mi></math>局部邻域大小的接近度量。从这里，您将创建一个损失函数<math
    alttext="script upper L"><mi>ℒ</mi></math>，它将最小化<math alttext="f"><mi>f</mi></math>和<math
    alttext="g"><mi>g</mi></math>的输出之间的差异，使其在<math alttext="pi Subscript x"><msub><mi>π</mi>
    <mi>x</mi></msub></math>内。在不进行任何修改的情况下，这个过程将使复杂的<math alttext="g"><mi>g</mi></math>几乎与<math
    alttext="f"><mi>f</mi></math>相同。这就是为什么您要添加<math alttext="normal upper Omega left-parenthesis
    g right-parenthesis"><mrow><mi>Ω</mi> <mo>(</mo> <mi>g</mi> <mo>)</mo></mrow></math>，这是一个正则化项，限制您的可解释模型<math
    alttext="g"><mi>g</mi></math>的复杂性。这将带您到训练LIME的一般方程式。
- en: <math alttext="xi left-parenthesis x right-parenthesis equals arg min Underscript
    g element-of upper G Endscripts script upper L left-parenthesis f comma g comma
    pi Subscript x Baseline right-parenthesis plus normal upper Omega left-parenthesis
    g right-parenthesis" display="block"><mrow><mi>ξ</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <munder><mrow><mo form="prefix">arg</mo><mo form="prefix"
    movablelimits="true">min</mo></mrow> <mrow><mi>g</mi><mo>∈</mo><mi>G</mi></mrow></munder>
    <mi>ℒ</mi> <mrow><mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>g</mi> <mo>,</mo> <msub><mi>π</mi>
    <mi>x</mi></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>Ω</mi> <mrow><mo>(</mo> <mi>g</mi>
    <mo>)</mo></mrow></mrow></math>
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="xi left-parenthesis x right-parenthesis equals arg min Underscript
    g element-of upper G Endscripts script upper L left-parenthesis f comma g comma
    pi Subscript x Baseline right-parenthesis plus normal upper Omega left-parenthesis
    g right-parenthesis" display="block"><mrow><mi>ξ</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <munder><mrow><mo form="prefix">arg</mo><mo form="prefix"
    movablelimits="true">min</mo></mrow> <mrow><mi>g</mi><mo>∈</mo><mi>G</mi></mrow></munder>
    <mi>ℒ</mi> <mrow><mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>g</mi> <mo>,</mo> <msub><mi>π</mi>
    <mi>x</mi></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>Ω</mi> <mrow><mo>(</mo> <mi>g</mi>
    <mo>)</mo></mrow></mrow></math>
- en: 'The loss function is more specifically described as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数更具体地描述如下：
- en: "<math alttext=\"script upper L left-parenthesis f comma g comma pi Subscript\
    \ x Baseline right-parenthesis equals sigma-summation Underscript z comma z prime\
    \ element-of script upper Z Endscripts pi Subscript x Baseline left-parenthesis\
    \ z right-parenthesis left-parenthesis f left-parenthesis z right-parenthesis\
    \ minus g left-parenthesis z prime right-parenthesis right-parenthesis squared\"\
    \ display=\"block\"><mrow><mi>ℒ</mi> <mrow><mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>g</mi>\
    \ <mo>,</mo> <msub><mi>π</mi> <mi>x</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <munder><mo>∑</mo>\
    \ <mrow><mi>z</mi><mo>,</mo><mi>z</mi><mi>â</mi><mi>\x80</mi><mi>\x99</mi><mo>∈</mo><mi>\U0001D4B5\
    </mi></mrow></munder> <msub><mi>π</mi> <mi>x</mi></msub> <mrow><mo>(</mo> <mi>z</mi>\
    \ <mo>)</mo></mrow> <msup><mrow><mo>(</mo><mi>f</mi><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow><mo>-</mo><mi>g</mi><mrow><mo>(</mo><msup><mi>z</mi>\
    \ <mo>'</mo></msup> <mo>)</mo></mrow><mo>)</mo></mrow> <mn>2</mn></msup></mrow></math>"
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: "<math alttext=\"script upper L left-parenthesis f comma g comma pi Subscript\
    \ x Baseline right-parenthesis equals sigma-summation Underscript z comma z prime\
    \ element-of script upper Z Endscripts pi Subscript x Baseline left-parenthesis\
    \ z right-parenthesis left-parenthesis f left-parenthesis z right-parenthesis\
    \ minus g left-parenthesis z prime right-parenthesis right-parenthesis squared\"\
    \ display=\"block\"><mrow><mi>ℒ</mi> <mrow><mo>(</mo> <mi>f</mi> <mo>,</mo> <mi>g</mi>\
    \ <mo>,</mo> <msub><mi>π</mi> <mi>x</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <munder><mo>∑</mo>\
    \ <mrow><mi>z</mi><mo>,</mo><mi>z</mi><mi>â</mi><mi>\x80</mi><mi>\x99</mi><mo>∈</mo><mi>\U0001D4B5\
    </mi></mrow></munder> <msub><mi>π</mi> <mi>x</mi></msub> <mrow><mo>(</mo> <mi>z</mi>\
    \ <mo>)</mo></mrow> <msup><mrow><mo>(</mo><mi>f</mi><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow><mo>-</mo><mi>g</mi><mrow><mo>(</mo><msup><mi>z</mi>\
    \ <mo>'</mo></msup> <mo>)</mo></mrow><mo>)</mo></mrow> <mn>2</mn></msup></mrow></math>"
- en: Intuitively, an *explanation* is a local linear approximation of the model’s
    behavior. While the model may be very complex globally, it is easier to approximate
    it around the vicinity of a particular instance. While treating the model as a
    black box, you perturb the instance you want to explain and learn a sparse linear
    model around it, as an explanation.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，*解释*是模型行为的局部线性逼近。虽然模型在全局上可能非常复杂，但在特定实例的周围近似它会更容易。当将模型视为黑盒时，您扰动要解释的实例，并在其周围学习一个稀疏线性模型，作为解释。
- en: The the model’s decision function is nonlinear. The bright red cross is the
    instance being explained (let’s call it *X*). You sample instances around *X*,
    and weight them according to their proximity to *X* (weight here is indicated
    by size). You then learn a linear model (dashed line) that approximates the model
    well in the vicinity of *X*, but not necessarily globally.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的决策函数是非线性的。鲜红色的十字是被解释的实例（我们称之为*X*）。您对*X*周围的实例进行采样，并根据它们与*X*的接近程度进行加权（这里的权重由大小表示）。然后，您学习一个线性模型（虚线），在*X*附近很好地近似模型，但不一定在全局范围内。
- en: 'Deep dive example: LIME on Vision Transformer models'
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深入示例：LIME在视觉Transformer模型上的应用
- en: Numerous examples of LIME on CNN-based image classifiers exist. Since these
    are model-agnostic methods, it’s worth demonstrating this by running LIME on [Vision
    Transformer (ViT) models](https://oreil.ly/yfZ2E) for image classification.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多关于LIME在基于CNN的图像分类器上的示例。由于这些是与模型无关的方法，值得通过在[视觉Transformer (ViT)模型](https://oreil.ly/yfZ2E)上运行LIME来进行演示，用于图像分类。
- en: Note
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You can find all the code associated with this tutorial in the notebook [*Chapter_3_LIME_for_Transformers.ipynb*](https://oreil.ly/lwDoi).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在笔记本[*Chapter_3_LIME_for_Transformers.ipynb*](https://oreil.ly/lwDoi)中找到与本教程相关的所有代码。
- en: '[PRE21]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: For your NLP example, you can take a version of BERT fine-tuned for finance
    called finBERT. This is a BERT model that can do sentiment analysis on text data.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 对于您的NLP示例，您可以使用专门针对金融领域进行了微调的BERT版本，称为finBERT。这是一个BERT模型，可以对文本数据进行情感分析。
- en: '[PRE22]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: For the `LimeTextExplainer` class, you need to specify a predictor function
    that will take the input and feed it through the tokenizer and model.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`LimeTextExplainer`类，您需要指定一个预测函数，该函数将接受输入并通过分词器和模型进行处理。
- en: '[PRE23]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: For the actual text explainer, you feed in your sample sentence and the predictor
    function. For this demonstration, you’ll set LIME to take two thousand samples.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实际的文本解释器，您需要提供样本句子和预测函数。在这个演示中，您将设置 LIME 来采集两千个样本。
- en: '[PRE24]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In [Figure 3-6](#lime-text), next to the output logits, you can see a breakdown
    of which features tilted the balance in favor of one output category or another.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 3-6](#lime-text) 中，除了输出的对数之外，您还可以看到哪些特征倾向于支持某个输出类别或另一个。
- en: '![ptml 0306](assets/ptml_0306.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0306](assets/ptml_0306.png)'
- en: Figure 3-6\. LIME running on text inputs
  id: totrans-184
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-6\. LIME 在文本输入上运行
- en: LIME isn’t just for text classification; it can work for image models as well.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: LIME 不仅适用于文本分类，也适用于图像模型。
- en: '[PRE25]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We’re working with a PIL image at the start ([Figure 3-7](#lime-image-input)).
    As with any torchvision model, we’ll want to do some pre-processing. However,
    due to a quirk of the original LIME library, you need to add a workaround: the
    `LimeImageExplainer`.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从开始处理 PIL 图像（[图 3-7](#lime-image-input)）。与任何 torchvision 模型一样，我们需要进行一些预处理。然而，由于原始
    LIME 库的一个怪异之处，您需要添加一个解决方法：`LimeImageExplainer`。
- en: '[PRE26]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![ptml 0307](assets/ptml_0307.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0307](assets/ptml_0307.png)'
- en: Figure 3-7\. LIME image input
  id: totrans-190
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-7\. LIME 图像输入
- en: As with the text explainer, we’ll create a prediction function that takes a
    batch of images and outputs the predictions. You just need to make sure the function
    properly makes use of the numpy-PIL conversion function in addition to the encoding
    and model.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 与文本解释器一样，我们将创建一个预测函数，该函数接受一批图像并输出预测。您只需确保该函数正确地利用了 numpy-PIL 转换函数以及编码和模型。
- en: '[PRE27]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: From here, we can use the explainer to examine which parts of the image correspond
    to the top predicted class ([Figure 3-8](#lime-image-pos)).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以使用解释器来检查图像中与顶部预测类别对应的部分（[图 3-8](#lime-image-pos)）。
- en: '[PRE28]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![ptml 0308](assets/ptml_0308.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0308](assets/ptml_0308.png)'
- en: Figure 3-8\. Positive contributions highlighted by LIME
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-8\. LIME 高亮的正面贡献
- en: Or if we’re focusing on just the top class prediction, we can examine the explanation
    further to figure out which parts were in favor of the decision, and which parts
    counted against it ([Figure 3-9](#lime-image-neg)).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果我们只关注顶部类别的预测，我们可以进一步检查解释，以找出哪些部分支持决定，哪些部分反对它（[图 3-9](#lime-image-neg)）。
- en: '[PRE29]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![ptml 0309](assets/ptml_0309.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0309](assets/ptml_0309.png)'
- en: Figure 3-9\. Negative contributions highlighted by LIME
  id: totrans-200
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-9\. LIME 高亮的负面贡献
- en: These approaches aren’t the only way to do LIME on transformer models. An alternative
    to this approach to using LIME is described in the [Captum package](https://oreil.ly/p78Oh).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法不是在变换器模型上使用 LIME 的唯一方式。在 Captum 软件包中描述了使用 LIME 的另一种方法的替代方法。
- en: Shapley and SHAP
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 夏普利与 SHAP
- en: '[*SHapley Additive exPlanations* (SHAP)](https://oreil.ly/zbGHN) is an attribution
    method that fairly assigns the prediction to individual features. This is based
    on an idea called *Shapley value* from the domain of cooperative game theory.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[*SHapley Additive exPlanations* (SHAP)](https://oreil.ly/zbGHN) 是一种归因方法，公平地将预测分配给各个特征。这基于合作博弈论领域的
    *夏普利值* 的概念。'
- en: Suppose we have a group of four people who cooperate in a game together (also
    known as a “coalition”). The game could be a machine learning competition. After
    the game, they get a certain payout for their result, such as getting $10,000
    for winning first place. The central question is how that prize should be fairly
    distributed. In a machine learning competition, each coalition member likely contributed
    different parts, so splitting it perfectly evenly among all the members wouldn’t
    make sense.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一组四个人一起合作进行游戏（也称为“联盟”）。这个游戏可能是一个机器学习竞赛。比赛结束后，他们根据结果得到一定的奖励，比如赢得第一名可获得 10,000
    美元。中心问题是如何公平分配奖金。在机器学习竞赛中，每个联盟成员可能贡献了不同的部分，因此完全平均分配给所有成员是没有意义的。
- en: Lloyd Shapley came up with Shapley values in 1951. These tell us the average
    contribution of the player to the payout. The explainable AI value SHAP makes
    use of Shapley values to determine which features of an input instance contributed
    to a model decision (instead of players in a game).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 劳埃德·夏普利于 1951 年提出了夏普利值。这些值告诉我们玩家对奖励的平均贡献。可解释的 AI 值 SHAP 利用夏普利值来确定输入实例的哪些特征导致了模型决策（而不是游戏中的玩家）。
- en: The main intuition behind Shapley values is that they measure how the coalition
    would have played with or without a certain player. Suppose, in your machine learning
    competition, we remove player Alice, who happens to be a domain expert. Rather
    than coming in first, the team places second and gets a payout of only $3,000.
    You could stop here and assume Alice contributed to 70% of the payout, but it’s
    not that simple.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: Shapley 值的主要直觉是，它们衡量了如果没有某个玩家，联盟会如何发挥作用。假设在您的机器学习竞赛中，我们移除了域专家 Alice 玩家。团队原本可以排名第一，但最终排名第二，仅获得
    $3,000 的奖金。您可能会在这里停下来，假设 Alice 贡献了奖金的 70%，但事实并非如此简单。
- en: Players interact with each other, so we also need to take into account how the
    players perform when working together. Suppose the team also has Bob, who is a
    machine learning expert. Alice only achieves great results when working with Bob,
    so the contribution should be split between them. But we’re not finished, because
    we also need to consider subsets, such as a three-person subset that excludes
    Bob and only contains Alice and her teammates Carol and Dylan. The Shapley value
    is used for calculating the contribution of each player for each possible subset
    of the coalition and averaging over all these contributions (known as the player’s
    *marginal value*).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 玩家彼此之间存在互动，因此我们还需要考虑玩家在共同工作时的表现。假设团队还有机器学习专家 Bob。Alice 只有在与 Bob 合作时才能取得出色的结果，因此贡献应该在他们之间分配。但我们还没有结束，因为我们还需要考虑子集，例如一个三人子集，排除
    Bob，仅包含 Alice 和她的队友 Carol 和 Dylan。Shapley 值用于计算联盟的每个可能子集的每个玩家的贡献，并对所有这些贡献进行平均（被称为玩家的
    *边际价值*）。
- en: Let’s go back to the machine learning context. As mentioned earlier, we can
    frame the features in a data instance as players and the model output prediction
    as the payout. Shapley values tell us how this value is distributed among all
    the inputs. SHAP uses this method to create local explanations for individual
    predictions, but it can also be used for global interpretations by averaging values
    across an entire dataset passed into a model.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到机器学习的背景。正如前面提到的，我们可以将数据实例中的特征视为玩家，模型输出预测为奖金。Shapley 值告诉我们这个值如何在所有输入之间分配。SHAP
    使用这种方法为个别预测创建局部解释，但也可以通过对传入模型的整个数据集的平均值进行全局解释。
- en: "How do we actually calculate Shapley values? Consider the equation for getting\
    \ the Shapley value for a feature value <math alttext=\"i\"><mi>i</mi></math>\
    \ for your black-box model <math alttext=\"f\"><mi>f</mi></math> and your input\
    \ data instance <math alttext=\"x\"><mi>x</mi></math> (this would be a single\
    \ row in a tabular dataset). You iterate over all possible subsets of features\
    \ ( <math alttext=\"z prime\"><mrow><mi>z</mi> <mi>â</mi> <mi>\x80</mi> <mi>\x99\
    </mi></mrow></math> ) to make sure we account for all interactions between feature\
    \ values. Our sampling space is denoted with a ′ because for larger instances\
    \ like images, we don’t treat each pixel as a feature; instead we find a way to\
    \ summarize the image into larger features. You get the black box model output\
    \ both with the feature we’re interested in ( <math alttext=\"f Subscript x Baseline\
    \ left-parenthesis z prime right-parenthesis\"><mrow><msub><mi>f</mi> <mi>x</mi></msub>\
    \ <mrow><mo>(</mo> <msup><mi>z</mi> <mo>'</mo></msup> <mo>)</mo></mrow></mrow></math>\
    \ ) and without it ( <math alttext=\"f Subscript x Baseline left-parenthesis z\
    \ prime minus i right-parenthesis\"><mrow><msub><mi>f</mi> <mi>x</mi></msub> <mrow><mo>(</mo>\
    \ <mi>z</mi> <mi>â</mi> <mi>\x80</mi> <mi>\x99</mi> <mo>∖</mo> <mi>i</mi> <mo>)</mo></mrow></mrow></math>\
    \ ). Seeing both tells us how the feature contributed to the model output in this\
    \ subset."
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: "我们如何实际计算 Shapley 值呢？考虑以下方程，用于获取您的黑盒模型 <math alttext=\"f\"><mi>f</mi></math>\
    \ 和输入数据实例 <math alttext=\"x\"><mi>x</mi></math> 的特征值 <math alttext=\"i\"><mi>i</mi></math>\
    \ 的 Shapley 值（这将是表格数据集中的单行）。您需要迭代所有可能的特征子集（<math alttext=\"z prime\"><mrow><mi>z</mi>\
    \ <mi>â</mi> <mi>\x80</mi> <mi>\x99</mi></mrow></math>），以确保我们考虑了特征值之间的所有交互。我们将采样空间标记为\
    \ ′，因为对于像图像这样的更大实例，我们不会将每个像素视为特征；相反，我们找到一种方法来总结图像为更大的特征。您会获得包括我们感兴趣的特征的黑盒模型输出（<math\
    \ alttext=\"f Subscript x Baseline left-parenthesis z prime right-parenthesis\"\
    ><mrow><msub><mi>f</mi> <mi>x</mi></msub> <mrow><mo>(</mo> <msup><mi>z</mi> <mo>'</mo></msup>\
    \ <mo>)</mo></mrow></mrow></math>），以及没有这个特征的输出（<math alttext=\"f Subscript x Baseline\
    \ left-parenthesis z prime minus i right-parenthesis\"><mrow><msub><mi>f</mi>\
    \ <mi>x</mi></msub> <mrow><mo>(</mo> <mi>z</mi> <mi>â</mi> <mi>\x80</mi> <mi>\x99\
    </mi> <mo>∖</mo> <mi>i</mi> <mo>)</mo></mrow></mrow></math>）。观察这两者告诉我们特征在该子集中如何影响模型输出。"
- en: You then do this for each possible permutation of subsets of features, each
    of which is additionally weighted by how many players are in the coalition, or
    how many features we’re looking at in total for the data instance <math alttext="upper
    M"><mi>M</mi></math> . This allows us to tell if a feature adds a large change
    to the model’s decision even if we’re already taking into account a lot of other
    features. This also lets us more directly observe the effects of features in isolation
    in smaller coalitions.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你要对每个特征子集的可能排列进行这样的操作，而每个排列的权重又取决于联合体中的玩家数量，或者我们针对数据实例<math alttext="upper
    M"><mi>M</mi></math>总共查看的特征数量。这使我们能够判断一个特征是否对模型的决策产生了很大的改变，即使我们已经考虑了很多其他特征。这也使我们能够更直接地观察在较小联合体中孤立特征的影响。
- en: "<math alttext=\"phi Subscript i Baseline left-parenthesis f comma x right-parenthesis\
    \ equals sigma-summation Underscript z prime subset-of-or-equal-to x Superscript\
    \ prime Baseline Endscripts StartFraction StartAbsoluteValue z Superscript prime\
    \ Baseline EndAbsoluteValue factorial left-parenthesis upper M minus StartAbsoluteValue\
    \ z Superscript prime Baseline EndAbsoluteValue minus 1 right-parenthesis factorial\
    \ Over upper M factorial EndFraction left-parenthesis right-parenthesis f Subscript\
    \ x Baseline left-parenthesis z Superscript prime Baseline right-parenthesis minus\
    \ f Subscript x Baseline left-parenthesis z prime minus i right-parenthesis right-parenthesis\"\
    \ display=\"block\"><mrow><msub><mi>φ</mi> <mi>i</mi></msub> <mrow><mo>(</mo>\
    \ <mi>f</mi> <mo>,</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <munder><mo>∑</mo>\
    \ <mrow><mi>z</mi><mi>â</mi><mi>\x80</mi><mi>\x99</mi><mo>⊆</mo><msup><mi>x</mi>\
    \ <mo>'</mo></msup></mrow></munder> <mfrac><mrow><mfenced close=\"|\" open=\"\
    |\" separators=\"\"><mi>z</mi><mi>â</mi><mi>\x80</mi><mi>\x99</mi></mfenced><mo>!</mo><mrow><mo>(</mo><mi>M</mi><mo>-</mo><mfenced\
    \ close=\"|\" open=\"|\" separators=\"\"><mi>z</mi><mi>â</mi><mi>\x80</mi><mi>\x99\
    </mi></mfenced><mo>-</mo><mn>1</mn><mo>)</mo></mrow><mo>!</mo></mrow> <mrow><mi>M</mi><mo>!</mo></mrow></mfrac>\
    \ <mfenced close=\")\" open=\"(\" separators=\"\"><mrow><mo>)</mo></mrow> <msub><mi>f</mi>\
    \ <mi>x</mi></msub> <mrow><mo>(</mo> <msup><mi>z</mi> <mo>'</mo></msup> <mo>)</mo></mrow>\
    \ <mo>-</mo> <msub><mi>f</mi> <mi>x</mi></msub> <mrow><mo>(</mo> <mi>z</mi> <mi>â</mi>\
    \ <mi>\x80</mi> <mi>\x99</mi> <mo>∖</mo> <mi>i</mi> <mo>)</mo></mrow></mfenced></mrow></math>"
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: "<math alttext=\"phi Subscript i Baseline left-parenthesis f comma x right-parenthesis\
    \ equals sigma-summation Underscript z prime subset-of-or-equal-to x Superscript\
    \ prime Baseline Endscripts StartFraction StartAbsoluteValue z Superscript prime\
    \ Baseline EndAbsoluteValue factorial left-parenthesis upper M minus StartAbsoluteValue\
    \ z Superscript prime Baseline EndAbsoluteValue minus 1 right-parenthesis factorial\
    \ Over upper M factorial EndFraction left-parenthesis right-parenthesis f Subscript\
    \ x Baseline left-parenthesis z Superscript prime Baseline right-parenthesis minus\
    \ f Subscript x Baseline left-parenthesis z prime minus i right-parenthesis right-parenthesis\"\
    \ display=\"block\"><mrow><msub><mi>φ</mi> <mi>i</mi></msub> <mrow><mo>(</mo>\
    \ <mi>f</mi> <mo>,</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <munder><mo>∑</mo>\
    \ <mrow><mi>z</mi><mi>â</mi><mi>\x80</mi><mi>\x99</mi><mo>⊆</mo><msup><mi>x</mi>\
    \ <mo>'</mo></msup></mrow></munder> <mfrac><mrow><mfenced close=\"|\" open=\"\
    |\" separators=\"\"><mi>z</mi><mi>â</mi><mi>\x80</mi><mi>\x99</mi></mfenced><mo>!</mo><mrow><mo>(</mo><mi>M</mi><mo>-</mo><mfenced\
    \ close=\"|\" open=\"|\" separators=\"\"><mi>z</mi><mi>â</mi><mi>\x80</mi><mi>\x99\
    </mi></mfenced><mo>-</mo><mn>1</mn><mo>)</mo></mrow><mo>!</mo></mrow> <mrow><mi>M</mi><mo>!</mo></mrow></mfrac>\
    \ <mfenced close=\")\" open=\"(\" separators=\"\"><mrow><mo>)</mo></mrow> <msub><mi>f</mi>\
    \ <mi>x</mi></msub> <mrow><mo>(</mo> <msup><mi>z</mi> <mo>'</mo></msup> <mo>)</mo></mrow>\
    \ <mo>-</mo> <msub><mi>f</mi> <mi>x</mi></msub> <mrow><mo>(</mo> <mi>z</mi> <mi>â</mi>\
    \ <mi>\x80</mi> <mi>\x99</mi> <mo>∖</mo> <mi>i</mi> <mo>)</mo></mrow></mfenced></mrow></math>"
- en: 'This still leaves one question: how do we remove features from a model input
    if our model typically takes in a fixed input size? This is solved in SHAP by
    replacing the removed feature value with a random replacement from somewhere else
    in the training data. If we do this for all subsets, the relevance of the feature
    is basically sampled out. You completely shuffle the features until they’re random,
    and a completely random feature offers no predictive power.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然有一个问题：如果我们的模型通常接受固定大小的输入，我们如何从模型输入中移除特征？在SHAP中，通过用训练数据中其他位置的随机替换值替换已移除的特征值来解决这个问题。如果我们对所有子集都这样做，那么特征的相关性基本上会被采样掉。你完全打乱特征直到它们成为随机的，而完全随机的特征则不具有预测能力。
- en: 'However there’s still one barrier to using SHAP: computational complexity.
    Calculating all those subsets is expensive. For an instance with <math alttext="n"><mi>n</mi></math>
    features, we have <math alttext="2 Superscript n"><msup><mn>2</mn> <mi>n</mi></msup></math>
    subsets. For 10 features, we have <math alttext="2 Superscript 10 Baseline equals
    1 comma 024"><mrow><msup><mn>2</mn> <mn>10</mn></msup> <mo>=</mo> <mn>1</mn> <mo>,</mo>
    <mn>024</mn></mrow></math> subsets, and for 20 features, we have <math alttext="2
    Superscript 20 Baseline equals 1 comma 048 comma 576"><mrow><msup><mn>2</mn> <mn>20</mn></msup>
    <mo>=</mo> <mn>1</mn> <mo>,</mo> <mn>048</mn> <mo>,</mo> <mn>576</mn></mrow></math>
    subsets, and so on. One possible workaround is to calculate SHAP approximately
    instead of exactly. Kernel SHAP samples feature subsets and fits a linear regression
    model based on the samples. The variables are simply whether a feature is absent
    or present, with the output value being the prediction. The coefficients of this
    linear model can be interpreted as approximate Shapley values. This is similar
    to LIME, except we don’t care how close instances are to each other, only how
    much information they contain.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 但是使用SHAP仍然存在一个障碍：计算复杂度很高。计算所有这些子集是昂贵的。对于具有<math alttext="n"><mi>n</mi></math>个特征的实例，我们有<math
    alttext="2 Superscript n"><msup><mn>2</mn> <mi>n</mi></msup></math>个子集。对于10个特征，我们有<math
    alttext="2 Superscript 10 Baseline equals 1 comma 024"><mrow><msup><mn>2</mn>
    <mn>10</mn></msup> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mn>024</mn></mrow></math>个子集，对于20个特征，我们有<math
    alttext="2 Superscript 20 Baseline equals 1 comma 048 comma 576"><mrow><msup><mn>2</mn>
    <mn>20</mn></msup> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mn>048</mn> <mo>,</mo> <mn>576</mn></mrow></math>个子集，以此类推。一个可能的解决方案是近似计算SHAP，而不是精确计算。Kernel
    SHAP对特征子集进行采样，并根据这些样本拟合线性回归模型。变量只是一个特征是否存在或缺失，输出值是预测结果。这个线性模型的系数可以解释为近似的Shapley值。这类似于LIME，但我们不关心实例之间的接近程度，只关心它们包含的信息量。
- en: There are other approximations for SHAP, such as Tree SHAP and Deep SHAP for
    tree-based models and deep neural networks respectively. These techniques are
    not really model-agnostic anymore, but on the plus side, they can at least take
    advantage of the model internals to speed up calculation.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP的其他近似方法包括Tree SHAP和Deep SHAP，分别用于基于树的模型和深度神经网络。这些技术不再是真正的模型无关的，但好处在于它们至少可以利用模型内部加速计算。
- en: 'Deep dive example: SHAP on Vision Transformer models'
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度分析示例：SHAP 对视觉Transformer模型的应用
- en: SHAP can be used to explain predictions on many different data types, from tabular
    to image to language data.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP可用于解释多种不同类型数据的预测，从表格数据到图像和语言数据。
- en: Note
  id: totrans-217
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You can find all the code associated with this tutorial in the notebook [*Chapter_3_SHAP_for_Transformers.ipynb*](https://oreil.ly/D8D5E).
    Interactive versions of Figures [3-10](#shap-example-0) through [3-15](#zeroshot-shap-1)
    are available in the *Chapter_3_SHAP_for_Transformers.ipynb* notebook.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在笔记本[*Chapter_3_SHAP_for_Transformers.ipynb*](https://oreil.ly/D8D5E)中找到与本教程相关的所有代码。图[3-10](#shap-example-0)到图[3-15](#zeroshot-shap-1)的交互版本也可在*Chapter_3_SHAP_for_Transformers.ipynb*笔记本中找到。
- en: Consider the example of using SHAP for a large language model.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑使用SHAP分析大型语言模型的示例。
- en: '[PRE30]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: For your classification task, we’ll use the HuggingFace Transformers library.
    We’ll create a standard `TextClassificationPipeline` using your model (DistilBERT)
    and the associated tokenizer.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 对于您的分类任务，我们将使用HuggingFace Transformers库。我们将使用您的模型（DistilBERT）和相关的tokenizer创建一个标准的`TextClassificationPipeline`。
- en: This model is a fine-tuned version of `distilbert-base-uncased` on the sst-2-english
    dataset. Switching out this model name, even for other distilbert models fine-tuned
    on sst-2-english, can result in changes to the visualization and output labels.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型是`distilbert-base-uncased`在sst-2-english数据集上微调的版本。即使是对其他在sst-2-english上微调的distilbert模型来说，替换这个模型名称也可能会导致可视化和输出标签的变化。
- en: '[PRE31]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: With your DistilBERT model and its tokenizers imported, we can see how SHAP
    processes text classifications. Here is an example working with clearly positive
    text (see [Figure 3-10](#shap-example-0)).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您的DistilBERT模型及其导入的tokenizer，我们可以看到SHAP如何处理文本分类。以下是一个处理显然是积极文本的示例（参见[图 3-10](#shap-example-0)）。
- en: '[PRE32]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![ptml 0310](assets/ptml_0310.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0310](assets/ptml_0310.png)'
- en: Figure 3-10\. Using SHAP on an obviously positive example sentence
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-10\. 在一个明显积极的示例句子上使用SHAP。
- en: And here is an example working with neutral text with a negative bent ([Figure 3-11](#shap-example-1)).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 并且这是一个处理有消极倾向的中性文本的示例（参见[图 3-11](#shap-example-1)）。
- en: '[PRE34]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![ptml 0311](assets/ptml_0311.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0311](assets/ptml_0311.png)'
- en: Figure 3-11\. Using SHAP on an intentionally neutral review (that’s perceived
    as negative)
  id: totrans-233
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-11\. 在一个有意义上是中立评价（被认为是消极的）上使用SHAP。
- en: In this example, we again analyze neutral text but this time with a positive
    slant (see [Figure 3-12](#shap-example-2)).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们再次分析中性文本，但这次是带有积极倾向的（参见[图 3-12](#shap-example-2)）。
- en: '[PRE36]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![ptml 0312](assets/ptml_0312.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0312](assets/ptml_0312.png)'
- en: Figure 3-12\. Using SHAP on another intentionally neutral review (that’s perceived
    as positive)
  id: totrans-238
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-12\. 在另一个有意义上是中立评价（被认为是积极的）的文本上使用SHAP。
- en: Finally, here we use SHAP to analyze a longer and intentionally ambiguous text
    ([Figure 3-13](#shap-example-3)).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在这里我们使用SHAP来分析一个更长且故意模糊的文本（参见[图 3-13](#shap-example-3)）。
- en: '[PRE38]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '![ptml 0313](assets/ptml_0313.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0313](assets/ptml_0313.png)'
- en: Figure 3-13\. Using SHAP on a much longer review
  id: totrans-243
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-13\. 在一个更长的评论上使用SHAP。
- en: You can even extend SHAP to interpreting zero-shot classification tasks ([Figure 3-14](#zeroshot-shap-0)).^([14](ch03.html#idm45621840086784))
    The main difference between the previous approach (aside from the change in imports)
    is that we’ll create a custom class `MyZeroShotClassification​Pipeline` from the
    imported `ZeroShotClassificationPipeline` class.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 您甚至可以将SHAP扩展到解释零样本分类任务（参见[图 3-14](#zeroshot-shap-0)）。^([14](ch03.html#idm45621840086784))
    与之前的方法（除了导入更改外）的主要区别在于，我们将从导入的`ZeroShotClassificationPipeline`类创建一个自定义类`MyZeroShotClassification​Pipeline`。
- en: '[PRE40]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![ptml 0314](assets/ptml_0314.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0314](assets/ptml_0314.png)'
- en: Figure 3-14\. Using SHAP to interpret zero-shot text classification
  id: totrans-248
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-14\. 使用SHAP解释零样本文本分类。
- en: This example shows the application of SHAP to a completely neutral text (see
    [Figure 3-15](#zeroshot-shap-1)).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例展示了SHAP应用于完全中性文本的情况（参见[图 3-15](#zeroshot-shap-1)）。
- en: '[PRE42]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Now, like LIME, SHAP can be extended to image data.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，像LIME一样，SHAP可以扩展到图像数据。
- en: There are numerous examples of [SHAP on CNN-based image classifiers](https://oreil.ly/eV5ib).
    You could use the same approach in a vision example, but there’s a reason so many
    of the SHAP examples out there are demonstrated on simple datasets like MNIST.
    SHAP operates on all the features of the input data. For text, that’s every token.
    For images, that’s every pixel. Even if you’re just running SHAP on a simple image
    of a handwritten digit, it’s computationally expensive.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多关于[基于CNN的图像分类器上的SHAP示例](https://oreil.ly/eV5ib)。您可以在视觉示例中使用相同的方法，但SHAP示例大多数都是在简单数据集（如MNIST）上演示的原因是有道理的。SHAP操作输入数据的所有特征。对于文本来说，这是每个token。对于图像来说，这是每个像素。即使您只是在手写数字的简单图像上运行SHAP，计算成本也很高。
- en: If you want an interpretability method for a neural network processing image
    data, there are much better options. For example, we haven’t gone into *global*
    model-agnostic interpretability methods yet.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要一个用于神经网络处理图像数据的可解释性方法，还有更好的选择。例如，我们还没有介绍*全局*模型无关的可解释性方法。
- en: '![ptml 0315](assets/ptml_0315.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0315](assets/ptml_0315.png)'
- en: Figure 3-15\. Using SHAP zero-shot text classification on an intentionally neutral
    input
  id: totrans-256
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-15\. 在一个有意义上是中立输入上使用SHAP进行零样本文本分类。
- en: Global Model-Agnostic Interpretability Methods
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全局模型无关的可解释性方法
- en: As discussed before, local interpretability focuses on making sense of individual
    decisions. By contrast, global methods seek to make sense of the behavior of the
    whole model. The inherently interpretable methods we’ve discussed earlier offer
    global interpretations. However, those interpretation methods were all specific
    to the model type. Here, we want to examine the global behavior of a model in
    a way that is independent of the model type (model-agnostic).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，局部可解释性专注于理解个别决策。相比之下，全局方法旨在理解整个模型的行为。我们之前讨论的固有可解释方法提供了全局解释。然而，这些解释方法都是针对特定模型类型的。在这里，我们希望以与模型类型无关的方式检验模型的全局行为（模型无关）。
- en: Permutation feature importance
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 排列特征重要性
- en: Permutation feature importance refers to permuting parts of the input features
    to see which ones cause the biggest change to the output predictions when modified.
    This can be applied to images, text, and tabular data
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 排列特征重要性指的是排列输入特征的部分，以查看修改时对输出预测造成最大变化的特征。这可以应用于图像、文本和表格数据。
- en: One way permutation feature importance can be applied to vision is by testing
    occlusion sensitivity. This is how much the decision output changes when certain
    sections of an image are occluded by a square of arbitrary size.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 排列特征重要性可以应用于视觉的一种方式是测试遮挡敏感性。这是指当图像的某些部分被任意大小的正方形遮挡时，决策输出的变化程度。
- en: Global surrogate models
  id: totrans-262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全局替代模型
- en: This technique involves taking a model and creating another that behaves extremely
    similarly. The idea is that you can take a model that’s otherwise a black box,
    and create an intrinsically interpretable model that behaves almost exactly like
    it (this is the “surrogate” in this case).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术涉及使用一个模型创建另一个行为极其相似的模型。这个想法是，你可以拿一个原本是黑盒的模型，创建一个本质上可解释的模型，其行为几乎与原模型完全相同（在这种情况下就是“替代模型”）。
- en: The advantage of this approach is that one can make sense of the high-level
    behaviors of otherwise inscrutable models. The downside is that all the interpretations
    are of the surrogate, not the original model itself. While the decisions of the
    surrogate may be a close approximation, they are not the original model.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的优点在于可以理解原本晦涩难懂模型的高级行为。缺点是所有解释都是针对替代模型而非原始模型本身。虽然替代模型的决策可能是一个接近的近似，但它们不是原始模型。
- en: Prototypes and criticisms
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原型和批评
- en: Prototypes and criticisms are both example-based interpretability approaches.
    A *prototype* is a synthetic data point designed to be representative of all the
    data points that result in a certain decision. Criticisms do the opposite, in
    that they create a synthetic data point representing instances that result in
    incorrect decisions.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 原型和批评都是基于示例的可解释性方法。*原型* 是设计成代表导致某个决策的所有数据点的合成数据点。批评则相反，它们创建一个代表导致错误决策的实例的合成数据点。
- en: '*MMD-critic* is an example-based interpretability approach developed by Kim
    et al. that combines prototypes and criticisms in a single framework.^([15](ch03.html#idm45621839628720))
    At a high level, it can be summarized as follows:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '*MMD-critic* 是由Kim等人开发的基于示例的可解释性方法，将原型和批评结合在一个框架中。^([15](ch03.html#idm45621839628720))
    在高层次上，可以总结如下：'
- en: Select the number of prototypes and criticisms you want to find.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择要查找的原型和批评的数量。
- en: Find prototypes with greedy search.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用贪婪搜索找到原型。
- en: Prototypes are selected so that the distribution of the prototypes is close
    to the data distribution.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择原型以使原型分布接近数据分布。
- en: Find criticisms with greedy search.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用贪婪搜索找到批评。
- en: Points are selected as criticisms where the distribution of prototypes differs
    from the distribution of the data.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为批评选定的点是原型分布与数据分布不同的地方。
- en: Explaining Neural Networks
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解释神经网络
- en: There are a lot of challenges when it comes to interpreting neural networks.
    Put simply, neural networks are universal function approximators. The idea is
    that with enough parameters in an equation, you can do pretty much anything. For
    example, as the famous physicist von Neumann is quoted as saying, “With four parameters
    I can fit an elephant, and with five I can make him wiggle his trunk.”
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 解释神经网络存在许多挑战。简单地说，神经网络是通用函数逼近器。这个想法是，通过在一个方程中使用足够多的参数，你可以做几乎任何事情。例如，正如著名物理学家冯·诺伊曼所说，“用四个参数我可以拟合一只大象，用五个参数我可以让它摇动鼻子。”
- en: With a neural network, each neuron is essentially a parameter in a gargantuan
    equation. Some parameters might be useless in the end, but as long as the model
    predicts a pattern in the data well enough, we usually don’t care.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 对于神经网络而言，每个神经元本质上都是一个巨大方程中的参数。一些参数最终可能是无用的，但只要模型能够很好地预测数据模式，我们通常不会太在意。
- en: This is obviously a problem when it comes to interpreting exactly what the model
    is doing. True, depending on which framework you use, you can add a bunch of abstractions
    to the defining of the mode. In fact, [PyTorch supports named tensors](https://oreil.ly/jWzUD),
    which are a way to add semantic meaning to the dimensions of a tensor.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及准确解释模型正在做什么时，这显然是一个问题。确实，根据您使用的框架，您可以为模式的定义添加大量抽象。事实上，[PyTorch 支持命名张量](https://oreil.ly/jWzUD)，这是向张量的维度添加语义含义的一种方式。
- en: If you create a map of the model’s behavior without mapping out every single
    neuron, you might feel like you’re missing some information. However, if you make
    your map of the model’s weights too granular, you can no longer understand it.
    This problem is often solved by looking at larger patterns in a neural network’s
    activations and behaviors, but even this might not tell the whole story. For example,
    a few researchers demonstrated some popular interpretability methods on copies
    of a neural network. For these copies they randomized a subset of the neural network
    weights. Despite this, they found that these interpretability methods could not
    tell the networks apart as long as the output accuracies were the same.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您创建模型行为的地图而没有映射出每一个神经元，您可能会觉得自己错过了一些信息。然而，如果您将模型权重的地图制作得太细粒度，那么您就无法理解它了。这个问题通常通过查看神经网络激活和行为中的更大模式来解决，但即使这样也可能无法讲述整个故事。例如，一些研究人员对神经网络的副本上演示了一些流行的可解释性方法。对于这些副本，他们随机化了神经网络权重的子集。尽管如此，他们发现这些可解释性方法在输出准确性相同的情况下无法区分网络。
- en: While these interpretability methods are still being improved, they are often
    still better than not having any interpretability methods at all. What’s important
    is recognizing what these interpretations should and should not be used for.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些可解释性方法仍在不断改进中，它们通常仍然比完全没有任何可解释性方法要好。重要的是要认识到这些解释方法应该用于什么，不应该用于什么。
- en: Saliency Mapping
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 显著性映射
- en: A *saliency map* is an image that highlights the region on which a network’s
    activations or attention focuses first. The goal of a saliency map is to reflect
    the degree of importance of a pixel to the model. *Saliency mapping* is useful
    in that it can point to specific parts of the input (for example, pixels in an
    input image or tokens in input text) that it attributes to a decision.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '*显著性地图*是一个突出显示网络激活或关注的区域的图像。显著性地图的目标是反映像素对模型的重要性程度。*显著性映射*的用处在于它可以指出输入的特定部分（例如输入图像中的像素或输入文本中的标记），这些部分被归因于某个决策。'
- en: Since saliency mapping allows you to look at what would contribute to different
    decisions, this can serve as a way to provide counterfactual evidence. For example,
    in a binary text sentiment classification task, one could look at embeddings that
    would contribute to either a positive or negative sentiment.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 由于显著性映射允许您查看对不同决策有贡献的内容，这可以作为提供反事实证据的一种方式。例如，在二元文本情感分类任务中，可以查看会对积极或消极情感有所贡献的嵌入。
- en: Gradient-based approaches are much faster to compute than methods like LIME
    or SHAP.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 基于梯度的方法比像 LIME 或 SHAP 这样的方法计算速度快得多。
- en: 'Deep Dive: Saliency Mapping with CLIP'
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入探讨：CLIP 中的显著性映射
- en: '[CLIP (Contrastive Language-Image Pre-training)](https://oreil.ly/PQ4my) is
    a model from OpenAI created as a bridge between how text is represented as embeddings
    and how images are represented as embeddings. In practical terms, this means that
    it can be used to compare the concept represented by an input string such as `"An
    adorable kitten sitting in a basket"` and the concept represented by an actual
    photo of a kitten in a basket, providing a numerical score of how close the two
    are. The OpenAI implementation was also trained to act as a zero-shot image classifier.
    For example, it is capable of not just recognizing an ImageNet photograph of a
    banana as a banana but also recognizing bananas in corrupted and low-quality photographs,
    as well as drawings and artistic depictions of bananas.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '[CLIP（对比语言-图像预训练）](https://oreil.ly/PQ4my) 是 OpenAI 创建的一个模型，用作文本表示和图像表示之间的桥梁。在实际应用中，这意味着它可以用来比较输入字符串（例如`"一个可爱的小猫坐在篮子里"`）所代表的概念与实际猫咪照片所代表的概念之间的相似性得分。OpenAI
    的实现还经过训练，可以作为零样本图像分类器使用。例如，它不仅能够识别 ImageNet 中香蕉的照片，还能够识别损坏和低质量照片中以及画作中的香蕉。'
- en: Training a network to associate text embeddings with images allows the model
    to describe the content of an image in human-understandable terms, not just as
    one-hot encoded vectors representing a predetermined number of output categories.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 训练网络以将文本嵌入与图像关联允许模型以人类可理解的方式描述图像内容，而不仅仅是作为表示预定输出类别数量的独热编码向量。
- en: However, all these capabilities rely on human users trusting CLIP to *correctly*
    associate text embeddings with image embeddings. Given the enormous variety of
    possible image and text pairings, this is no simple task. Still, the concepts
    we’ve covered so far can offer some guidance.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，所有这些能力都依赖于人类用户信任 CLIP 能够*正确*关联文本嵌入和图像嵌入。考虑到可能的图像和文本配对的巨大多样性，这并不是一项简单的任务。尽管如此，我们迄今所涵盖的概念可以提供一些指导。
- en: Note
  id: totrans-287
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You can find the code associated with this tutorial in the notebooks [*Chapter_3_CLIP_Saliency_mapping_Part1.ipynb*](https://oreil.ly/6pmRx)
    and [*Chapter_3_CLIP_Saliency_mapping_Part2.ipynb*](https://oreil.ly/GBP7Q). This
    was heavily inspired by [`hila-chefer`’s `Transformer-MM-Explainability` project](https://oreil.ly/9iKQ7),
    and makes use of the Captum library.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在笔记本 [*Chapter_3_CLIP_Saliency_mapping_Part1.ipynb*](https://oreil.ly/6pmRx)
    和 [*Chapter_3_CLIP_Saliency_mapping_Part2.ipynb*](https://oreil.ly/GBP7Q) 中找到与本教程相关的代码。这些笔记本受到
    [`hila-chefer` 的 `Transformer-MM-Explainability` 项目](https://oreil.ly/9iKQ7) 的启发，并利用了
    Captum 库。
- en: Running this code has a high RAM requirement. If you are running this in Google
    Colab, you should use the largest GPU available in Colab Pro and set the RAM to
    the highest setting.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码需要大量 RAM。如果您在 Google Colab 中运行此代码，请使用 Colab Pro 中最大的 GPU，并将 RAM 设置为最高。
- en: For working with CLIP, you can download the code from the project’s [public
    repository](https://oreil.ly/Q1xgq). We will place the model in a subdirectory
    from which you can import the model.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 若要使用 CLIP，您可以从项目的 [公共存储库](https://oreil.ly/Q1xgq) 下载代码。我们将模型放在一个子目录中，您可以从中导入模型。
- en: '[PRE44]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Once we’ve set up your development environment, you can download the weights
    for the CLIP models. These weights are available directly from OpenAI.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们设置好您的开发环境，您可以下载 CLIP 模型的权重。这些权重可以直接从 OpenAI 获取。
- en: '[PRE45]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Before you test out CLIP with any inputs, you need to set up your pre-processing
    steps. While CLIP is a technically impressive model, it’s still important to not
    forget proper pre-processing. Since CLIP works with both text and images, you
    need to be able to pre-process both data types.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在您使用任何输入测试 CLIP 之前，您需要设置预处理步骤。虽然 CLIP 是一个技术上令人印象深刻的模型，但不要忘记正确的预处理步骤。由于 CLIP
    同时处理文本和图像，您需要能够预处理这两种数据类型。
- en: '[PRE47]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: For the text pre-processing, we’ll use a case-insensitive tokenizer.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文本预处理，我们将使用不区分大小写的分词器。
- en: For the image pre-processing, we’ll go through a standard pixel intensity normalization,^([16](ch03.html#idm45621839311008))
    image resizing, and center-cropping procedure.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像预处理，我们将进行标准的像素强度归一化，^([16](ch03.html#idm45621839311008)) 图像调整大小和中心裁剪的过程。
- en: We could create this pre-processing stage ourselves, but we don’t need to. As
    you saw earlier, we can load CLIP’s pre-processing module for the particular model
    we’re using. We can just inspect that pre-processing step to make sure it has
    all the correct stages.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以自己创建这个预处理阶段，但我们没有必要。正如您早些时候看到的，我们可以加载特定模型的 CLIP 预处理模块。我们只需检查该预处理步骤，以确保它具有所有正确的阶段。
- en: '[PRE49]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Once this is done, you will prepare the model to take in a set of example images
    and their text descriptions. We can test the model by measuring the cosine similarity
    between the features generated for the text and the features generated for the
    image.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成，您将准备模型来接收一组示例图像及其文本描述。我们可以通过测量生成的文本特征和图像特征之间的余弦相似度来测试模型。
- en: '[PRE51]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: As shown in [Figure 3-16](#clip-saliency-0), we have a wide variety of images,
    from the realistic to the abstract, from the clearly defined to the blurred and
    unclear.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图 3-16](#clip-saliency-0)所示，我们拥有各种各样的图像，从逼真的到抽象的，从清晰定义的到模糊不清的。
- en: '![ptml 0316](assets/ptml_0316.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0316](assets/ptml_0316.png)'
- en: Figure 3-16\. CLIP’s matching of words to images
  id: totrans-307
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-16\. CLIP 将单词与图像匹配
- en: '[PRE52]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Despite some of these images being potentially difficult to classify by a human,
    CLIP does a pretty good job of pairing them with their textual descriptions, as
    shown in [Figure 3-17](#clip-saliency-1).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些图像有些可能对人类来说难以分类，但是 CLIP 在将它们与其文本描述配对方面做得相当好，正如[图 3-17](#clip-saliency-1)所示。
- en: '![ptml 0317](assets/ptml_0317.png)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0317](assets/ptml_0317.png)'
- en: Figure 3-17\. Using CLIP to pair images with text descriptions
  id: totrans-311
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-17\. 使用 CLIP 将图像与文本描述配对
- en: We’ll then run these pairs through our text and image pre-processing steps,
    followed by the CLIP model itself.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将这些对通过我们的文本和图像预处理步骤，然后通过 CLIP 模型本身。
- en: '[PRE53]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: To compare these image features with the text features, you normalize them both
    and calculate the dot product of each pair of features.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 要比较这些图像特征和文本特征，您需要对它们进行归一化，并计算每对特征的点积。
- en: '[PRE54]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: As you can see in [Figure 3-18](#clip-saliency-2), CLIP is very good at identifying
    not just when text and an image are similar but, just as importantly, when they
    are very dissimilar.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在[图 3-18](#clip-saliency-2)中所见，CLIP 不仅在文本和图像相似时表现非常好，而且在它们非常不相似时同样重要。
- en: Now that we’ve validated that CLIP works on preselected images and text pairs,
    we can use it to generate classifications for images from completely different
    datasets. To make CLIP’s output behave like the logits to the softmax operation,
    you just take the cosine similarity multiplied by 100.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经验证了 CLIP 在预选图像和文本对上的工作效果，我们可以使用它来为来自完全不同数据集的图像生成分类。为了使 CLIP 的输出行为类似于 softmax
    操作的对数几率，只需将余弦相似度乘以 100。
- en: '![ptml 0318](assets/ptml_0318.png)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0318](assets/ptml_0318.png)'
- en: Figure 3-18\. Cosine similarity between text and image features
  id: totrans-319
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-18\. 文本与图像特征之间的余弦相似度
- en: '[PRE55]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Many of the interpretability techniques we’ve covered so far in this chapter
    have been demonstrated many times on models with a limited number of possible
    outputs. The problem is that models can sometimes be presented with inputs that
    are like nothing they’ve seen before. This is why combining interpretability methods
    like saliency mapping with CLIP’s zero-shot capabilities can be very powerful.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章中我们介绍的许多可解释性技术已经多次在具有有限可能输出的模型上进行了演示。问题在于，模型有时会被呈现出它们从未见过的输入。这就是为什么将显著性映射等可解释性方法与
    CLIP 的零样本能力结合在一起可能非常强大的原因。
- en: To do saliency mapping with CLIP, make sure CLIP has been set up using the previously
    described steps. We also want to download [Captum](https://captum.ai), a model
    interpretability tool kit for PyTorch.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 CLIP 进行显著性映射，请确保已按先前描述的步骤设置好 CLIP。我们还需要下载[Captum](https://captum.ai)，这是一个用于
    PyTorch 的模型可解释性工具包。
- en: For the saliency mapping, we’ll also want to select the layers from which we’ll
    take the activations. The final layers of the model are the final probabilities
    fed into the output layers. To get a sense for the logic happening between the
    input and output, you need to pick an intermediate layer.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 对于显著性映射，我们还需要选择我们将从中获取激活的层。模型的最终层是输入到输出层的最终概率。为了了解在输入和输出之间发生的逻辑，您需要选择一个中间层。
- en: '[PRE56]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: CLIP should be okay to inspect, but there are a few key changes that you need
    to make for it all to work. The existing implementation of CLIP doesn’t record
    attention in a way that’s easy to log, so we’re going to monkey-patch the model.
    *Monkey-patching* refers to the process of dynamically modifying a class or function
    after it’s been defined. It’s a quick way of patching an existing third-party
    codebase or library as a workaround for a bug or missing feature.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: CLIP 应该可以检查，但是您需要进行一些关键更改，以使其全部正常工作。现有的 CLIP 实现不会以易于记录的方式记录注意力，因此我们将对模型进行补丁。*Monkey-patching*
    指的是在定义后动态修改类或函数的过程。这是修补现有第三方代码库或库的快速方法，用于解决错误或缺少功能。
- en: Note
  id: totrans-326
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The full extent of the monkey-patching of OpenAI’s code can be found in the
    [accompanying notebook for this section](https://oreil.ly/oYXTi). These changes
    are geared toward the `'ViT-B/32'` and `'ViT-B/16'` models. Due to differences
    in architecture, these changes would not be compatible with the `'RN50'`, `'RN101'`,
    `'RN50x4'`, `'RN50x16'`, `'RN50x64'`, `'ViT-L/14'`, and `'ViT-L/14@336px'` CLIP
    models. OpenAI may change CLIP in the future to include these changes. For now,
    we’re going to accommodate the branch we’re working with.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 的代码的整体补丁的详细内容可以在[本节的附属笔记本](https://oreil.ly/oYXTi)找到。这些更改针对 'ViT-B/32'
    和 'ViT-B/16' 模型。由于架构的差异，这些更改不兼容 'RN50'、'RN101'、'RN50x4'、'RN50x16'、'RN50x64'、'ViT-L/14'
    和 'ViT-L/14@336px' CLIP 模型。OpenAI 可能会在未来的版本中包含这些更改。目前，我们将适配我们正在使用的分支。
- en: If you are unfamiliar with monkey-patching in Python, [here’s a tutorial](https://oreil.ly/ZblMe)
    on doing this in machine learning contexts.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对 Python 中的 monkey-patching 不熟悉，[这里有一个教程](https://oreil.ly/ZblMe)，适用于机器学习环境。
- en: From here, we’ll create a helper function that examines the attention blocks
    in both the image and text portions of CLIP.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，我们将创建一个帮助函数，检查 CLIP 图像和文本部分的注意力块。
- en: '[PRE57]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: There are two things we’re interested in. The first is what parts of the input
    text the model is focusing on. For this reason, we’ll define a function that overlays
    a heatmap over the characters in the text.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的有两件事。第一件是模型专注于输入文本的哪些部分。因此，我们将定义一个函数，在文本中的字符上叠加热图。
- en: '[PRE58]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The second thing we’re interested in is what parts of the input image the model
    is focusing on. For this reason we’ll define a function that overlays a heatmap
    over the pixels of the input image.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的第二件事是模型专注于输入图像的哪些部分。因此，我们将定义一个函数，在输入图像的像素上叠加热图。
- en: '[PRE59]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: With these helper functions, you can see where CLIP’s attention is focusing
    on in both the text and image portions of the input. See Figures [3-19](#clip-saliency-3)
    to [3-36](#clip-saliency-20) for examples of CLIP saliency; the odd-numbered figures
    show saliency on input text, and the even-numbered figures show saliency on an
    image with similar content.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些辅助函数，您可以看到 CLIP 在输入的文本和图像部分的注意力集中在哪里。请参阅图 [3-19](#clip-saliency-3) 到 [3-36](#clip-saliency-20)
    ，了解 CLIP 显著性的示例；奇数编号的图显示输入文本的显著性，偶数编号的图显示类似内容的图像上的显著性。
- en: '[PRE60]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '![ptml 0319](assets/ptml_0319.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0319](assets/ptml_0319.png)'
- en: Figure 3-19\. CLIP saliency on the input text, highlighting the *glasses* part
  id: totrans-338
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-19\. 在输入文本上的 CLIP 显著性，突出显示 *眼镜* 部分
- en: '![ptml 0320](assets/ptml_0320.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0320](assets/ptml_0320.png)'
- en: Figure 3-20\. CLIP image saliency on the input image, highlighting the glasses
  id: totrans-340
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-20\. 在输入图像上的 CLIP 图像显著性，突出显示眼镜
- en: '![ptml 0321](assets/ptml_0321.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0321](assets/ptml_0321.png)'
- en: Figure 3-21\. CLIP saliency on the input text, highlighting the *lipstick* part
  id: totrans-342
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-21\. 在输入文本上的 CLIP 显著性，突出显示 *口红* 部分
- en: '![ptml 0322](assets/ptml_0322.png)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0322](assets/ptml_0322.png)'
- en: Figure 3-22\. CLIP image saliency on the input image, highlighting the lips
  id: totrans-344
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-22\. 在输入图像上的 CLIP 图像显著性，突出显示嘴唇
- en: '![ptml 0323](assets/ptml_0323.png)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0323](assets/ptml_0323.png)'
- en: Figure 3-23\. CLIP text saliency on text describing a rocket on a launch pad
  id: totrans-346
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-23\. 在火箭发射台上描述火箭的文字上的 CLIP 文本显著性
- en: '![ptml 0324](assets/ptml_0324.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0324](assets/ptml_0324.png)'
- en: Figure 3-24\. CLIP image and text saliency on the input image, containing the
    Artemis rocket
  id: totrans-348
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-24\. 在包含阿尔忒弥斯火箭的输入图像上的 CLIP 图像和文本显著性
- en: '![ptml 0325](assets/ptml_0325.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0325](assets/ptml_0325.png)'
- en: Figure 3-25\. CLIP text saliency on text describing a zebra
  id: totrans-350
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-25\. 描述斑马的文本上的 CLIP 文本显著性
- en: '![ptml 0326](assets/ptml_0326.png)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0326](assets/ptml_0326.png)'
- en: Figure 3-26\. CLIP image and text saliency on the input image, containing both
    an elephant in the center but also two zebras toward the bottom near a watering
    hole
  id: totrans-352
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-26\. CLIP 图像和文本显著性分析结果显示了输入图像中的一只大象位于中心，但也有两只斑马在水坑附近的底部。
- en: '![ptml 0327](assets/ptml_0327.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0327](assets/ptml_0327.png)'
- en: Figure 3-27\. CLIP text saliency on text describing a zebra
  id: totrans-354
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-27\. CLIP 对描述斑马的文本的显著性分析。
- en: '![ptml 0328](assets/ptml_0328.png)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0328](assets/ptml_0328.png)'
- en: Figure 3-28\. CLIP image and text saliency on the input image, containing both
    an elephant in the center but also two zebras toward the bottom near a watering
    hole
  id: totrans-356
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-28\. CLIP 图像和文本显著性分析结果显示了输入图像中的一只大象位于中心，但也有两只斑马在水坑附近的底部。
- en: '![ptml 0329](assets/ptml_0329.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0329](assets/ptml_0329.png)'
- en: Figure 3-29\. CLIP text saliency on text describing an elephant
  id: totrans-358
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-29\. CLIP 对描述大象的文本的显著性分析。
- en: '![ptml 0330](assets/ptml_0330.png)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0330](assets/ptml_0330.png)'
- en: Figure 3-30\. CLIP image and text saliency on the input image, containing both
    an elephant in the center but also a zebra in the corner
  id: totrans-360
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-30\. CLIP 图像和文本显著性分析结果显示了输入图像中的一只大象位于中心，同时角落里还有一只斑马。
- en: '![ptml 0331](assets/ptml_0331.png)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0331](assets/ptml_0331.png)'
- en: Figure 3-31\. CLIP saliency on text describing a dog breed
  id: totrans-362
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-31\. CLIP 对描述狗品种的文本的显著性分析。
- en: '![ptml 0332](assets/ptml_0332.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0332](assets/ptml_0332.png)'
- en: Figure 3-32\. CLIP saliency example on image containing both a dog and cat,
    depending on whether the input text specifically mentioned the dog or the cat
  id: totrans-364
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-32\. CLIP 对包含狗和猫的图像的显著性分析示例，具体取决于输入文本是否明确提到了狗或猫。
- en: '![ptml 0333](assets/ptml_0333.png)'
  id: totrans-365
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0333](assets/ptml_0333.png)'
- en: Figure 3-33\. CLIP saliency on text describing a dog breed
  id: totrans-366
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-33\. CLIP 对描述狗品种的文本的显著性分析。
- en: '![ptml 0334](assets/ptml_0334.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0334](assets/ptml_0334.png)'
- en: Figure 3-34\. CLIP saliency example on image containing both a dog and cat,
    depending on whether the input text described the breed of the dog or the breed
    of the cat
  id: totrans-368
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-34\. CLIP 对包含狗和猫的图像的显著性分析示例，具体取决于输入文本描述的是狗的品种还是猫的品种。
- en: '![ptml 0335](assets/ptml_0335.png)'
  id: totrans-369
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0335](assets/ptml_0335.png)'
- en: Figure 3-35\. CLIP saliency on the text, showing higher attribution on the word
    astronaut
  id: totrans-370
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-35\. CLIP 对文本的显著性分析，显示了对单词“宇航员”更高的归因。
- en: '![ptml 0336](assets/ptml_0336.png)'
  id: totrans-371
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0336](assets/ptml_0336.png)'
- en: Figure 3-36\. CLIP saliency on the input image emphasizing the astronaut’s face,
    followed by similar pairs of text/image saliency pairs that emphasize the flag
    in the picture and then the astronaut suit
  id: totrans-372
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-36\. CLIP 对输入图像的显著性分析强调了宇航员的面部，接着是一系列类似的文本/图像显著性分析对，强调了图片中的国旗，然后是宇航服。
- en: The saliency maps make a convincing case that CLIP can correctly identify which
    part of the picture the text describes. This is even the case when the target
    class is in just a small portion of the image.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 显著性地图有力地证明了CLIP可以正确识别文本描述的图片部分。即使目标类别只占图像的一小部分，也是如此。
- en: It may be tempting to look at these results and assume we’ve created an ideal
    zero-shot object detection model. Still, CLIP is not perfect, and it’s important
    to consider the limitations and edge cases.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会让人惊讶的是，CLIP不仅从文本中进行了积极的归因，而且还给这个图像-文本对分配了很高的相似性分数（见图3-37和3-38）。
- en: Consider the following example of an image of random static paired with a text
    description.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下例子，一个随机静态图像与文本描述配对。
- en: '[PRE61]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: It might be surprising not only how much CLIP is making positive attributions
    from the text, but also how high of a similarity score it assigns to this image-text
    pair (see Figures [3-37](#clip-saliency-23) and [3-38](#clip-saliency-24)).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅CLIP从文本中进行了积极的归因，而且还给这个图像-文本对分配了很高的相似性分数（见图3-37和3-38）。
- en: '![ptml 0337](assets/ptml_0337.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0337](assets/ptml_0337.png)'
- en: Figure 3-37\. CLIP similarity score between text seemingly describing a dog
    and a random noise image
  id: totrans-379
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-37\. CLIP 对看似描述狗的文本和随机噪声图像之间的相似性分数。
- en: '![ptml 0338](assets/ptml_0338.png)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0338](assets/ptml_0338.png)'
- en: Figure 3-38\. CLIP saliency map on noise that looks nothing like a dog to a
    human
  id: totrans-381
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 3-38\. CLIP 对看起来与狗毫不相像的噪音的显著性分析图。
- en: For comparison, consider an input image of a dog that’s much clearer ([Figure 3-40](#clip-saliency-22)).
    This input image gets a very high CLIP similarity score (`27.890625`) because
    of that similarity ([Figure 3-39](#clip-saliency-21)). Still, that’s a lower CLIP
    similarity score than the random noise we previously fed into CLIP.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较，考虑一张更清晰的狗的输入图像（见图3-40）。由于这种相似性，这个输入图像得到了非常高的CLIP相似性分数（`27.890625`）（见图3-39）。但是，这个CLIP相似性分数比我们之前输入的随机噪声还要低。
- en: '![ptml 0339](assets/ptml_0339.png)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0339](assets/ptml_0339.png)'
- en: Figure 3-39\. CLIP similarity score on human-understandable image of a husky
  id: totrans-384
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-39\. CLIP在人类可理解的哈士奇图像上的相似性分数
- en: Anyone who’s able to see the image in [Figure 3-40](#clip-saliency-22) would
    agree that it’s a dog, and the saliency map shows that CLIP seems to focus on
    the dog’s face and mouth.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 能够看到[图 3-40](#clip-saliency-22)的任何人都会同意这是一只狗，显著性图显示CLIP似乎集中在狗的面部和嘴巴上。
- en: '![ptml 0340](assets/ptml_0340.png)'
  id: totrans-386
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0340](assets/ptml_0340.png)'
- en: Figure 3-40\. CLIP saliency map on human-understandable image of a husky
  id: totrans-387
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-40\. CLIP在人类可理解的哈士奇图像上的显著性图
- en: The focus of CLIP might be confusing, but if you look closely at [Figure 3-37](#clip-saliency-23),
    CLIP focuses much more on the `image of` part than on the dog in the human-legible
    part. Some part of this image is associated with CLIP’s understanding of `image
    of` enough to give it a higher CLIP similarity score than the seemingly perfect
    text-to-image match with the dog.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然关注CLIP可能会让人感到困惑，但如果你仔细看[图 3-37](#clip-saliency-23)，CLIP更加关注`image of`部分，而不是人类可读部分的狗。这张图片的某些部分与CLIP对`image
    of`的理解足够相关，从而使其获得比与狗看似完美的文本到图像匹配更高的CLIP相似性分数。
- en: It’s important to remember that while associating text with images is a task
    humans can do, CLIP does not see the world in the same way that biological brains
    do.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，虽然将文本与图像关联是人类能够完成的任务，但CLIP并不以与生物大脑相同的方式看待世界。
- en: Adversarial Counterfactual Examples
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对抗反事实例
- en: We recommend looking at [Chapter 5](ch05.html#chapter5) for more information
    on adversarial examples, but we will briefly cover a specific example here.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议查看[第5章](ch05.html#chapter5)以获取有关对抗样本的更多信息，但我们将在这里简要介绍一个具体的例子。
- en: '*Counterfactual explanations* (also known as *contrastive explanations*) are
    a powerful approach. The idea behind a counterfactual is to present a modified
    version of a data instance that leads to a different prediction. Usually, the
    counterfactual is the smallest of the input features that changes the model output
    to another (predefined) output.'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '*反事实解释*（也称为*对比解释*）是一种强大的方法。反事实背后的想法是提出数据实例的修改版本，导致不同的预测结果。通常，反事实是改变模型输出到另一个（预定义）输出的最小输入特征。'
- en: Counterfactuals first emerged in the field of psychology in the 1970s.^([17](ch03.html#idm45621836221104))
    The paper “Counterfactual Explanations Without Opening the Black Box” introduced
    the idea of using them in machine learning.^([18](ch03.html#idm45621836219968))
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 反事实首次出现在20世纪70年代的心理学领域。^([17](ch03.html#idm45621836221104)) “不打开黑盒的反事实解释”一文介绍了在机器学习中使用它们的概念。^([18](ch03.html#idm45621836219968))
- en: An adversarial example is an instance with small, intentional feature perturbations
    that cause a machine learning model to make a false prediction. When it comes
    to explainability and interpretability, adversarial examples can serve a similar
    role as counterfactual explanations. In fact, the processes for generating both
    are very similar to one another.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗性示例是指具有小的、有意的特征扰动的实例，这些扰动会导致机器学习模型做出错误的预测。在可解释性和解释性方面，对抗性示例可以起到与反事实解释类似的作用。事实上，生成两者的过程非常相似。
- en: "In both cases, you want to figure out <math alttext=\"x prime\"><mrow><mi>x</mi>\
    \ <mi>â</mi> <mi>\x80</mi> <mi>\x99</mi></mrow></math> , an adversarial example,\
    \ in an optimization problem:"
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，您都希望找到一个对抗性例子，即一个优化问题中的小型对抗性特征扰动：
- en: <math alttext="argmin Underscript x prime Endscripts d left-parenthesis x comma
    x prime right-parenthesis" display="block"><mrow><munder><mrow><mtext>argmin</mtext></mrow>
    <msup><mi>x</mi> <mo>'</mo></msup></munder> <mi>d</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <msup><mi>x</mi> <mo>'</mo></msup> <mo>)</mo></mrow></mrow></math>
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="argmin Underscript x prime Endscripts d left-parenthesis x comma
    x prime right-parenthesis" display="block"><mrow><munder><mrow><mtext>argmin</mtext></mrow>
    <msup><mi>x</mi> <mo>'</mo></msup></munder> <mi>d</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <msup><mi>x</mi> <mo>'</mo></msup> <mo>)</mo></mrow></mrow></math>
- en: "Here, feeding <math alttext=\"x prime\"><mrow><mi>x</mi> <mi>â</mi> <mi>\x80\
    </mi> <mi>\x99</mi></mrow></math> into your model ( <math alttext=\"f left-parenthesis\
    \ x prime right-parenthesis\"><mrow><mi>f</mi> <mo>(</mo> <msup><mi>x</mi> <mo>'</mo></msup>\
    \ <mo>)</mo></mrow></math> ) will lead to a predefined output <math alttext=\"\
    c\"><mi>c</mi></math> . In both cases, when you’re explaining a model (the counterfactual)\
    \ or attacking a model (the adversarial sample), you want to minimize the changes\
    \ to the input data."
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: "在这里，将<math alttext=\"x prime\"><mrow><mi>x</mi> <mi>â</mi> <mi>\x80</mi> <mi>\x99\
    </mi></mrow></math>输入到您的模型（<math alttext=\"f left-parenthesis x prime right-parenthesis\"\
    ><mrow><mi>f</mi> <mo>(</mo> <msup><mi>x</mi> <mo>'</mo></msup> <mo>)</mo></mrow></math>）将导致预定义的输出<math\
    \ alttext=\"c\"><mi>c</mi></math>。在这两种情况下，当您解释一个模型（反事实）或攻击一个模型（对抗性样本）时，您都希望最小化对输入数据的更改。"
- en: But beyond this general mathematical form, how do you calculate the adversarial
    example practically? The method depends on whether you have access to the model
    internals (the white-box approaches) or not (the black-box approaches).
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 但除了这种一般的数学形式之外，你如何实际计算对抗样本呢？这种方法取决于你是否能访问模型的内部（白盒方法）或不能（黑盒方法）。
- en: Overcome the Limitations of Interpretability with a Security Mindset
  id: totrans-399
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 克服可解释性的局限性需要安全意识。
- en: We’ve discussed a lot of packages and pointed out the limitations of interpretability
    as a field. So what is one supposed to do if these tools apparently tell us so
    little? Ultimately, you may never be able to understand every single aspect of
    a sufficiently complex model. The next best thing is to have a “security mindset”
    to overcome the limitations of interpretability.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了许多包并指出了解释性作为一个领域的局限性。那么，如果这些工具显然告诉我们如此少，我们应该怎么办呢？最终，你可能永远无法理解足够复杂模型的每一个方面。下一步最好的方法是具备“安全意识”，以克服可解释性的局限性。
- en: What is a security mindset? It’s the ability to spot potential or real flaws
    in the integrity of a program, system of programs, organization, or even person
    or group of people. An attacker might adopt a security mindset to exploit weaknesses,
    or a security practitioner might adopt it to better defend the system and patch
    those weaknesses. An individual can learn to have a security mindset. A security
    mindset can exist as intuition. It can even emerge as a culture resulting from
    the guidelines and procedures of a security-conscious organization. In a machine
    learning context, it’s an ability to challenge assumptions about the behaviors
    and/or safety of your model.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是安全意识？这是发现程序、系统集成、组织甚至个人或一群人的完整性中潜在或实际缺陷的能力。攻击者可能会采用安全意识来利用弱点，而安全从业者可能会采用它来更好地保卫系统并修补这些弱点。个人可以学会具备安全意识。安全意识可以存在于直觉中。它甚至可以作为安全意识的文化出现，由安全意识组织的指导方针和程序引发。在机器学习的背景下，它是挑战模型行为和/或安全性假设的能力。
- en: For example, in the previous tutorials, we’ve given examples of using large
    language models for tasks like classification. This seems like a straightforward
    task, until you start questioning the assumptions behind the setup. For example,
    what if we used abstract labels like `A` and `B` instead of concrete labels like
    `POSITIVE` and `NEGATIVE`? If we’re using full words, does the spelling or capitalization
    matter? [In at least one case](https://oreil.ly/ItNoi), the performance of a large
    language model on the SST evaluation benchmark jumped from 53% to 69% after the
    researchers just changed the output label “positive” to “Positive.” In the case
    of [sentiment analysis and COVID testing](https://oreil.ly/CtCYu) (where testing
    negative for COVID should be seen as a good thing), the underlying meaning behind
    the labels “positive” and “negative” changed.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在之前的教程中，我们举了使用大型语言模型进行分类等任务的例子。这似乎是一个直接的任务，直到你开始质疑设置背后的假设。例如，如果我们使用抽象标签像`A`和`B`而不是像`POSITIVE`和`NEGATIVE`这样的具体标签会怎么样？如果我们使用完整的单词，拼写或大写字母是否重要？[至少在一个案例中](https://oreil.ly/ItNoi)，研究人员仅仅将输出标签“positive”改为“Positive”，一个大型语言模型在SST评估基准上的性能从53%提升到了69%。在[情感分析和COVID测试](https://oreil.ly/CtCYu)的情况下（在这种情况下，COVID测试为阴性应被视为一件好事），标签“positive”和“negative”背后的含义发生了变化。
- en: 'Part of the “security mindset” also means recognizing that anthropomorphizing
    your AI system is incredibly dangerous. Consider the case of a Google engineer
    who [struck up a conversation with Google’s LaMDA conversational model, concluded
    it was sentient, kicked up a storm in the company, and got suspended from their
    job](https://oreil.ly/CtCYu). If one reads the publicly available snippets of
    the conversation, one could conclude it was a conversation between two people.
    However, there are two things that seemed absent from the conversation:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: “安全意识”的一部分也意味着要认识到将你的AI系统拟人化是极其危险的。考虑一个与谷歌的LaMDA对话模型开始对话、得出其有意识的结论的谷歌工程师的案例，并因此在公司内掀起轩然大波并被停职的情况。如果有人阅读这段公开可用的对话片段，可能会得出这是两个人之间的对话的结论。然而，从对话中缺少两件事情：
- en: The engineer in question aggressively doubting the sentience of the chatbot
    and seeing the result
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关工程师积极怀疑聊天机器人的智能性并看到结果
- en: All the other conversations that would have been less coherent
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有其他可能不那么连贯的对话
- en: The latter implies there’s a selection bias behind these claims of sentience.
    As for the former, considering counterfactuals is crucial when evaluating language
    models. After all, the chatbot is a Transformer model that was likely trained
    on datasets of human queries and responses in a chat room. The main goal of this
    training was to predict the most likely appropriate output response given a query.
    As such, this evidence of the chatbot’s “sentience” is indistinguishable from
    a chatbot guessing the next likely sentences in a science fiction story about
    a sentient AI. In fact, further research has demonstrated that what most people
    think of as “human-like” in the responses from a chatbot is often simply the use
    of the first person.^([19](ch03.html#idm45621836184512))
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 后者意味着这些声称有知觉能力背后存在选择偏差。至于前者，在评估语言模型时考虑对事实的反事实是至关重要的。毕竟，聊天机器人是一个Transformer模型，很可能是在聊天室中的人类查询和响应数据集上进行训练的。这种训练的主要目的是根据查询预测最可能的适当输出响应。因此，聊天机器人“有知觉”的证据与一个预测下一个可能句子的聊天室科幻故事中的聪明AI几乎是一样的。事实上，进一步的研究表明，大多数人认为聊天机器人响应中的“类人”特征通常仅仅是第一人称的使用。^([19](ch03.html#idm45621836184512))
- en: Limitations and Pitfalls of Explainable and Interpretable Methods
  id: totrans-407
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释性和解释性方法的局限性和缺陷
- en: Before diving into the exact methods for interpreting and explaining models,
    let’s take a look at some of the pitfalls of these methods.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究解释和说明模型的确切方法之前，让我们先看看这些方法的一些缺陷。
- en: First off, if you need to make high-stakes decisions, make sure to use inherently
    interpretable models. These are models such as decision trees that are more readily
    converted to output explanations (see [“Decision tree”](#decision-tree-ch3-sect)
    for more details).
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果您需要做出高风险的决策，请确保使用本质上可解释的模型。这些模型例如决策树更容易转换为输出解释（详见[“决策树”](#decision-tree-ch3-sect)）。
- en: Before choosing a method, you need to be absolutely clear about what you want
    out of it. Are you trying to understand the nature of the data procurement process?
    How a decision was made? How the model works on a fundamental level? Some tools
    might be appropriate for some of these goals but not others.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择方法之前，您需要非常清楚您希望从中得到什么。您是想理解数据采购过程的本质吗？决策是如何做出的？模型在基本层面上是如何工作的？有些工具可能对其中某些目标适合，但对其他目标则不适合。
- en: If your goal is to make sense of the data generation process, this is only possible
    if you know that your model already generalizes well to unseen data.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的目标是理解数据生成过程，那么只有在您知道您的模型已经很好地泛化到未见数据时才可能实现。
- en: Decision interpretability can be misleading. It highlights things like correlations,
    but doesn’t go into the level of causal detail that causal inference does (see
    [Chapter 7](ch07.html#chapter7)). Remember that correlation does not (always)
    imply causation.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 决策的可解释性可能会误导。它突出显示诸如相关性之类的事物，但并不深入到因果推断所涉及的详细层次（见[第7章](ch07.html#chapter7)）。请记住，相关性并不总是意味着因果关系。
- en: Warning
  id: totrans-413
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Spurious correlations can result in inaccurate interpretations even with advanced
    interpretability methods like saliency methods and attention-based methods.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 虚假的相关性可能会导致即使使用先进的可解释性方法如显著性方法和基于注意力的方法也会出现不准确的解释。
- en: Tools such as feature importance usually estimate mean values, but one should
    beware the error bars on those means and take stock of the confidence intervals.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如特征重要性之类的工具通常会估计平均值，但是应注意这些平均值的误差范围，并考虑置信区间。
- en: 'A lot of machine learning involves working with extremely high-dimensional
    spaces. There’s no way around it: high-dimensional data and feature spaces are
    hard to make sense of without grouping the data or features together first.'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 很多机器学习涉及处理极高维度的空间。高维度的数据和特征空间要想在未进行数据或特征分组的情况下理解是困难的。
- en: Even if you do find important features in those matrices, remember that this
    does not imply causality (we’ve said this before and we’ll say it again).
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您在这些矩阵中找到了重要的特征，也请记住这并不意味着因果关系（我们之前已经说过这一点，我们将再次说一遍）。
- en: Risks of Deceptive Interpretability
  id: totrans-418
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[误导性可解释性的风险](https://wiki.example.org/deceptive_interpretability_risks)'
- en: Even if you’re not anthropomorphizing your model or ML pipeline, you should
    always be wary of 100% believing your interpretability or explainability method.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您不将模型或ML流水线拟人化，您也应始终警惕对可解释性或解释性方法的100%信任。
- en: One of the big concerns in the AI safety field, which was a hypothetical scenario
    until it was recently realized, is a “deceptively misaligned mesa-optimizer.”^([20](ch03.html#idm45621836170272))
    In short, a machine learning model is trained in an environment in the hopes that
    it will behave similarly in the real world. To make sure its alignment in the
    test environment is the same as its alignment in the outside world, its creators
    resort to interpretability methods. However, it turns out the interpretability
    method itself shows one pattern to the human engineer, while corresponding to
    an unwanted behavior in the real world. This is one of those scenarios that was
    often discussed in the same breath as far-future AGI takeovers, until it was demonstrated
    in real life.^([21](ch03.html#idm45621836168112))
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI安全领域的一个重大关注点是“欺骗性不对齐的Mesa-优化器”，直到最近才成为一个假设情景。简而言之，一个机器学习模型在一个环境中训练，希望它在现实世界中表现相似。为了确保其在测试环境中的对齐性与其在外部世界中的对齐性相同，其创建者们采用了解释性方法。然而，事实证明，解释性方法本身向人类工程师展示了一种模式，而在现实世界中却对应着一种不希望的行为。这是过去经常与远期AGI接管讨论在一起的情景之一，直到它在现实生活中得到证明。^([21](ch03.html#idm45621836168112))
- en: While we’ve mainly avoided the topic of reinforcement learning in this chapter,
    a lot of the computer vision interpretability tools we’ve described previously
    apply here. In this case, the authors of [“Goal Misgeneralization in Deep Reinforcement
    Learning”](https://arxiv.org/abs/2105.14111v6) had a very simple reinforcement
    learning environment called CoinRun. In short, they demonstrated an RL agent that
    appeared to have very clear goals (namely, reaching the coin at the end of the
    level). However, when put in different environments, it instead was just going
    to the end of the level. This is obviously a much lower-stakes application of
    an AI than putting that model in a self-driving car, but it should still be a
    reminder to check all of your assumptions about an interpretability method.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在本章中我们主要避免了强化学习的话题，但我们之前描述的许多计算机视觉解释工具在这里同样适用。在这种情况下，《深度强化学习中的目标误概化》的作者们拥有一个非常简单的强化学习环境称为CoinRun。简而言之，他们展示了一个强化学习代理人，看似有非常明确的目标（即到达关卡末尾的硬币）。然而，当置于不同的环境中时，它实际上只是到达了关卡的末尾。显然，这比将该模型放入自动驾驶汽车中要低风险得多，但这仍然应该提醒您检查有关解释性方法的所有假设。
- en: If you really want a framework for how to think about the ML model you’re evaluating,
    at best it’s a LARPer acting out a role specified by humans without any true experience
    of the real world, and at worst it’s a sociopath focusing on achieving its specified
    objective function regardless of how much that goal clashes with the wants and
    needs of the humans around it.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您真的想要一个思考评估中的机器学习模型的框架，最好将其视为一种角色扮演者，按照人类指定的角色行事，没有真正体验到现实世界的经历；最糟糕的情况是，它是一个关注实现其指定目标函数的社会病态，而不管这个目标与其周围的人类的想法和需求有多大冲突。
- en: Of course, even if you’re incredibly mindful of every single parameter of your
    model, looking at the model alone is not enough. In the next chapter, we explore
    the various pitfalls involved in acquiring the training data that informs your
    machine learning model or pipeline’s representation of the world.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，即使您非常注意模型的每一个参数，仅仅看模型本身是不够的。在下一章中，我们将探讨获取训练数据的各种陷阱，这些数据决定了您的机器学习模型或流程对世界的表示。
- en: Conclusion
  id: totrans-424
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, you learned about the tools and techniques that help explain
    the predictions of an ML model. To that end, you need to choose a proper explainability
    technique (e.g., global or local; inherently explainable model or post hoc explanations),
    consider possible interactions with other aspects of trust (such as privacy),
    and be mindful of limitations of such methods.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了帮助解释机器学习模型预测的工具和技术。为此，您需要选择适当的解释技术（例如全局或局部；固有可解释模型或事后解释），考虑与信任的其他方面（如隐私）的可能交互作用，并注意这些方法的限制。
- en: '^([1](ch03.html#idm45621854762112-marker)) Tim Miller, [“Explanation in Artificial
    Intelligence: Insights from the Social Sciences”](https://oreil.ly/teIWN), *Artificial
    Intelligence* 267 (2019): 1–38.'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.html#idm45621854762112-marker)) Tim Miller，《人工智能中的解释：社会科学的启示》，*人工智能*
    267（2019）：1–38。
- en: ^([2](ch03.html#idm45621854760192-marker)) Been Kim et al., [“Examples Are Not
    Enough, Learn To Criticize! Criticism for Interpretability”](https://oreil.ly/deDPo),
    *Advances in Neural Information Processing Systems* 29 (2016).
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch03.html#idm45621854760192-marker)) Been Kim 等人的文章[“例子不足以，学会批判！可解释性的批评”](https://oreil.ly/deDPo)，《神经信息处理系统进展》第29卷（2016年）。
- en: ^([3](ch03.html#idm45621854755760-marker)) See this survey paper on [evaluation
    of XAI](https://arxiv.org/abs/2201.08164) and the [corresponding website](https://oreil.ly/FQSZe)
    with a curated categorization of XAI papers.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch03.html#idm45621854755760-marker)) 详见这篇关于[XAI评估](https://arxiv.org/abs/2201.08164)的综述论文和[相关网站](https://oreil.ly/FQSZe)，提供了XAI论文的精选分类。
- en: ^([4](ch03.html#idm45621854753488-marker)) Dr. Matt Turek, [“Explainable Artificial
    Intelligence (XAI)”](https://oreil.ly/6wkHq), *Defense Advanced Research Projects
    Agency (DARPA)*, 2016.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch03.html#idm45621854753488-marker)) Dr. Matt Turek 的文章[“可解释人工智能（XAI）”](https://oreil.ly/6wkHq)，发表于国防高级研究计划局（DARPA），2016年。
- en: ^([5](ch03.html#idm45621854740496-marker)) Finale Doshi-Velez and Been Kim,
    [“Towards a Rigorous Science of Interpretable Machine Learning”](https://arxiv.org/abs/1702.08608),
    *arXiv preprint* (2017).
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch03.html#idm45621854740496-marker)) Finale Doshi-Velez 和 Been Kim 的文章[“走向可解释机器学习的严格科学”](https://arxiv.org/abs/1702.08608)，arXiv预印本（2017年）。
- en: ^([6](ch03.html#idm45621854738064-marker)) Nirmal Sobha Kartha et al., [“Why
    Are You Weird? Infusing Interpretability in Isolation Forest for Anomaly Detection”](https://arxiv.org/abs/2112.06858),
    *arXiv preprint* (2021).
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch03.html#idm45621854738064-marker)) Nirmal Sobha Kartha 等人的文章[“为什么你如此奇怪？注入孤立森林的可解释性用于异常检测”](https://arxiv.org/abs/2112.06858)，arXiv预印本（2021年）。
- en: ^([7](ch03.html#idm45621854718720-marker)) Doshi-Velez and Kim, “Towards a Rigorous
    Science of Interpretable Machine Learning.”
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch03.html#idm45621854718720-marker)) Doshi-Velez 和 Kim 的文章[“走向可解释机器学习的严格科学”]。
- en: ^([8](ch03.html#idm45621854672480-marker)) The *New York Times* judged [GPT-3’s
    ability to write original prose](https://oreil.ly/l5Xdm) as having fluency comparable
    to human levels.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch03.html#idm45621854672480-marker)) *纽约时报* 评价[GPT-3的写作原创性](https://oreil.ly/l5Xdm)达到了与人类水平相媲美的流畅程度。
- en: ^([9](ch03.html#idm45621854668624-marker)) Also, [Microsoft announced on September
    22, 2020](https://oreil.ly/gjCEN), that it had licensed “exclusive” use of GPT-3’s
    underlying model.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch03.html#idm45621854668624-marker)) 此外，[Microsoft在2020年9月22日宣布](https://oreil.ly/gjCEN)，已经获得了GPT-3基础模型的“独家”使用许可。
- en: '^([10](ch03.html#idm45621854662512-marker)) nostalgebraist, [“Interpreting
    GPT: the Logit Lens”](https://oreil.ly/rZtju), *LessWrong* (blog), August 30,
    2020.'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch03.html#idm45621854662512-marker)) nostalgebraist 的文章[“解读GPT：对数几率透镜”](https://oreil.ly/rZtju)，*LessWrong*（博客），2020年8月30日。
- en: ^([11](ch03.html#idm45621848233456-marker)) If you want a more in-depth, intuitive
    explanation of Linear regression, check out [MLU Explain’s article](https://oreil.ly/dEfCL).
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch03.html#idm45621848233456-marker)) 如果你希望更深入、更直观地了解线性回归，请查看[MLU Explain的文章](https://oreil.ly/dEfCL)。
- en: '^([12](ch03.html#idm45621842768384-marker)) Yin Lou et al., [“Accurate Intelligible
    Models with Pairwise Interactions”](https://dl.acm.org/doi/abs/10.1145/2487575.2487579),
    *Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery
    and Data Mining*, (August 2013): 623–31.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch03.html#idm45621842768384-marker)) Yin Lou 等人的文章[“具有成对交互的准确可理解模型”](https://dl.acm.org/doi/abs/10.1145/2487575.2487579)，发表于第19届ACM
    SIGKDD国际数据挖掘与知识发现会议（2013年）：623–31。
- en: '^([13](ch03.html#idm45621841570432-marker)) Jerome H. Friedman and Bogdan E.
    Popescu, [“Predictive Learning via Rule Ensembles”](https://arxiv.org/abs/0811.1679),
    *The Annals of Applied Statistics*, 2, no. 3 (2008): 916–54.'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch03.html#idm45621841570432-marker)) Jerome H. Friedman 和 Bogdan E. Popescu
    的文章[“通过规则集的预测学习”](https://arxiv.org/abs/0811.1679)，发表于《应用统计年刊》第2卷第3期（2008年）：916–54。
- en: ^([14](ch03.html#idm45621840086784-marker)) “Zero-shot” in machine learning
    refers to a model being able to perform tasks it hasn’t previously been trained
    to do.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch03.html#idm45621840086784-marker)) 在机器学习中，“零样本学习”指的是模型能够执行其以前未经训练的任务。
- en: ^([15](ch03.html#idm45621839628720-marker)) Kim et al., “Examples Are Not Enough,
    Learn to Criticize! Criticism for Interpretability.”
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch03.html#idm45621839628720-marker)) Kim 等人的文章[“例子不足以，学会批判！可解释性的批评”]。
- en: ^([16](ch03.html#idm45621839311008-marker)) In this case, we’re using the pixel
    mean and standard deviation for ImageNet. This is pretty common for many tasks
    working with photographic input. Still, in many domains, it’s worth directly calculating
    the mean and standard deviation for your particular dataset.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch03.html#idm45621839311008-marker)) 在这种情况下，我们使用ImageNet的像素均值和标准差。这对许多处理摄影输入的任务来说很普遍。然而，在许多领域，直接计算你特定数据集的均值和标准差也是值得的。
- en: '^([17](ch03.html#idm45621836221104-marker)) David K. Lewis, *Counterfactuals*,
    (Cambridge: Harvard University Press, 1973).'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch03.html#idm45621836221104-marker)) David K. Lewis，《反事实》，（剑桥：哈佛大学出版社，1973年）。
- en: ^([18](ch03.html#idm45621836219968-marker)) Sandra Wachter et al., [“Counterfactual
    Explanations Without Opening the Black Box”](https://oreil.ly/kD6D9), *Harvard
    Journal of Law & Technology* 31, no. 2 (Spring 2017).
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch03.html#idm45621836219968-marker)) Sandra Wachter 等，《不打开黑匣子的反事实解释》，*哈佛法律与技术杂志*
    31卷，第2期（2017年春季）。
- en: ^([19](ch03.html#idm45621836184512-marker)) Maurice Jakesch et al., [“Human
    Heuristics for AI-Generated Language Are Flawed”](https://arxiv.org/abs/2206.07271),
    *arXiv preprint* (2022).
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch03.html#idm45621836184512-marker)) Maurice Jakesch 等，《AI生成语言的人类启发式存在缺陷》，*arXiv预印本*（2022年）。
- en: '^([20](ch03.html#idm45621836170272-marker)) Robert Miles, [“The OTHER AI Alignment
    Problem: Mesa-Optimizers and Inner Alignment”](https://youtu.be/bJLcIBixGj8),
    video, February 16, 2021.; Robert Miles, [“Deceptive Misaligned Mesa-Optimisers?
    It’s More Likely Than You Think…​”](https://youtu.be/IeWljQw3UgQ), video, May
    23, 2021.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](ch03.html#idm45621836170272-marker)) Robert Miles，《另一个AI对齐问题：Mesa优化器和内部对齐》，视频，2021年2月16日；Robert
    Miles，《欺骗性不对齐Mesa优化器？比你想象的更有可能……》，视频，2021年5月23日。
- en: ^([21](ch03.html#idm45621836168112-marker)) Robert Miles, [“We Were Right! Real
    Inner Misalignment”](https://youtu.be/zkbPdEHEyEI), video, October 10, 2021.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch03.html#idm45621836168112-marker)) Robert Miles，《我们是对的！真正的内部不对齐》，视频，2021年10月10日。
