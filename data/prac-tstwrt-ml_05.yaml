- en: Chapter 5\. Secure and Trustworthy Data Generation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 章。安全可信的数据生成
- en: Anyone who’s been in the machine learning space even a little bit understands
    the importance of data. Still, it’s underappreciated just how important data is.
    OpenAI published a paper on scaling laws of large language models in 2020 and
    concluded that scaling up the model size would be enough to get more capable ML
    models on a given dataset.^([1](ch05.html#idm45621834000368)) However, with their
    2022 Chinchilla network paper, DeepMind demonstrated that parameters alone don’t
    make the model.^([2](ch05.html#idm45621833998336)) DeepMind demonstrated that
    the dataset needs to scale with the size of the model. While the evidence for
    this scaling law is compelling, the issue is that many teams are much more constrained
    by data than they are by number of parameters.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 任何稍有涉足机器学习领域的人都明白数据的重要性。但是，人们往往低估了数据的重要性。OpenAI 在 2020 年发表了一篇关于大型语言模型扩展定律的论文，并得出结论：增加模型大小足以使给定数据集上的机器学习模型更加强大。^([1](ch05.html#idm45621834000368))
    然而，DeepMind 在其 2022 年的 Chinchilla 网络论文中展示了，单单增加参数并不能创造出优秀的模型。^([2](ch05.html#idm45621833998336))
    DeepMind 表明，数据集的规模需要与模型的大小相匹配。尽管这种扩展定律的证据具有说服力，但问题在于，许多团队更多受制于数据的限制，而不是参数的数量。
- en: One of the most common barriers on any machine learning project is simply getting
    sufficient training data for your machine learning models.^([3](ch05.html#idm45621833995200))
    Data acquisition can be very challenging because a large enough sample needs to
    be collected to be representative of the entire population of data. In some cases,
    the challenge might be getting any data at all to feed into the model. With these
    concerns in mind, it’s important to remember the common pitfalls of sourcing datasets.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何机器学习项目中，最常见的障碍之一就是为机器学习模型获取足够的训练数据。^([3](ch05.html#idm45621833995200)) 数据获取可能非常具有挑战性，因为必须收集足够大的样本，以代表整体数据的总体。在某些情况下，挑战可能在于根本无法获取任何数据来输入模型。考虑到这些问题，记住数据集来源的常见陷阱是非常重要的。
- en: In the book, we’ve already covered a few examples of failure cases for machine
    learning models. These include societal or non-societal biases (see [Chapter 2](ch02.html#chapter2)),
    focusing on the wrong features in data (see [Chapter 3](ch03.html#chapter3)),
    and failing to capture the full distribution of a phenomenon (see [Chapter 4](ch04.html#chapter4)).
    Many of the fixes for these might involve changes to how a machine learning model
    is trained, but more often than not, the biggest problem is with the data itself;
    it might contain bugs, contain biases (which are then reflected in the model),
    or not conform to privacy standards. This chapter delves into best practices in
    curating and maintaining datasets.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们已经涵盖了一些机器学习模型失败案例的示例。这些案例包括社会或非社会偏见（见[第 2 章](ch02.html#chapter2)）、关注错误的数据特征（见[第
    3 章](ch03.html#chapter3)）以及未能捕捉现象的完整分布（见[第 4 章](ch04.html#chapter4)）。许多这些问题的修复可能涉及如何训练机器学习模型的变化，但最大的问题往往出现在数据本身：它可能包含错误、包含偏见（随后反映在模型中）或不符合隐私标准。本章深入探讨了策划和维护数据集的最佳实践。
- en: Before we dive into best practices for both real-world and synthetic data acquisitions,
    let’s go into some concrete examples of what untrustworthy data acquisition might
    look like and what consequences might arise from it.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨现实世界和合成数据获取的最佳实践之前，让我们来看一些未经信任的数据获取可能的具体示例及其可能带来的后果。
- en: 'Case 1: Unsecured AWS Buckets'
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例 1：未加保护的 AWS 存储桶
- en: Amazon S3 has plenty of buckets containing all kinds of information, including
    images, videos, and text, all covering almost every conceivable domain and subject.
    When these buckets are being created, there’s usually some security settings that
    can be set up to to restrict access to only yourself or trusted users. A lot of
    people don’t set up these security measures, either because they’re in a hurry
    or they don’t know how to do it.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3 存储桶中包含各种信息，包括图像、视频和文本，涵盖几乎每一个可能的领域和主题。在创建这些存储桶时，通常可以设置一些安全设置，以限制访问仅限于您自己或受信任的用户。许多人不设置这些安全措施，可能是因为匆忙或不知道如何设置。
- en: A few people started to realize the extent of these unsecured AWS buckets. Much
    like people who scrape public GitHub repos for unsecured cryptocurrency private
    keys, some groups quickly built tools to scrape valuable datasets from these unsecured
    buckets. For example, [GrayHatWarfare](https://oreil.ly/q58ND) provides a webapp
    to search and browse public S3 buckets. Many often specialize in specific types
    of data. For example, in its early days [IntelPixel](https://oreil.ly/YYik3) combined
    such a scraper with its privacy tools to create anonymized medical data for creating
    medical imaging datasets for deep learning. IntelPixel is probably an unusually
    ethical outlier. Most companies with access to these unsecured buckets don’t bother
    to anonymize the data (and most of those that do only partially anonymize). Approaches
    like this lower the bar to acquire data, but they introduce new problems of data
    quality control, as well as legal, ethical, and public relations liabilities.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人开始意识到这些未安全配置的AWS存储桶的程度。就像有些人会从未安全配置的GitHub仓库中获取未安全的加密货币私钥一样，一些团体迅速开发了工具，从这些未安全的存储桶中获取有价值的数据集。例如，[GrayHatWarfare](https://oreil.ly/q58ND)
    提供了一个Web应用程序来搜索和浏览公共S3存储桶。许多人专门针对特定类型的数据。例如，在早期阶段，[IntelPixel](https://oreil.ly/YYik3)
    将这样一个抓取器与其隐私工具结合起来，用于创建医学成像数据集的匿名化医疗数据。IntelPixel可能是一个不寻常的道德异常值。大多数访问这些未安全配置的存储桶的公司都不费力进行数据匿名化（而那些进行匿名化的公司也仅仅是部分匿名化）。这样的方法降低了获取数据的门槛，但引入了数据质量控制、法律、伦理和公共关系责任的新问题。
- en: Note
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you’re an owner of one of these AWS S3 buckets and you spent a lot of time,
    money, and effort acquiring the data, you should definitely take the time to [secure
    access to your bucket and set up monitoring for it](https://oreil.ly/wrX3h) (or
    whatever data storage option you’re using on any cloud provider).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是这些AWS S3存储桶的所有者，并且花费了大量时间、金钱和精力获取数据，你应该绝对花时间来[确保访问您的存储桶并设置监控](https://oreil.ly/wrX3h)（或者您在任何云提供商上使用的数据存储选项）。
- en: 'Case 2: Clearview AI Scraping Photos from Social Media'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例2：Clearview AI从社交媒体上抓取照片
- en: Using a somewhat similar strategy to the S3 bucket case, Clearview AI built
    a facial recognition tool from publicly available photos. They created a scraper
    that paired public social media photos with names, then created a tool that purportedly
    could [identify anyone from their database of three billion pictures](https://clearview.ai).
    This tool was marketed to law enforcement agencies, though it was immediately
    clear that it had [enormous potential for abuse by stalkers](https://oreil.ly/c1gsc).
    This tool can recognize most Americans based on a photograph, regardless of whether
    that American’s photo has ever been in a criminal database. Privacy experts and
    the public were shocked by this. That’s why it shouldn’t come as a surprise when
    Clearview AI [faced a privacy violation lawsuit](https://oreil.ly/8lo6W) brought
    by groups including the American Civil Liberties Union, committing to end corporate
    customers’ access to its database of photos collected from the public web.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于S3存储桶案例的策略，Clearview AI从公开可用的照片中构建了面部识别工具。他们创建了一个抓取器，将公共社交媒体照片与姓名配对，然后创建了一款据称可以从他们的30亿张图片数据库中识别任何人的工具，[不论该美国人的照片是否曾出现在刑事数据库中](https://clearview.ai)。尽管该工具立即显露出可能被跟踪者滥用的[巨大潜力](https://oreil.ly/c1gsc)，但它被市场化为向执法机构推广。这个工具可以基于照片识别大多数美国人，而不管该美国人的照片是否曾被收录在刑事数据库中。隐私专家和公众对此感到震惊。因此，当Clearview
    AI面对包括美国公民自由联盟在内的团体提起的[隐私侵犯诉讼](https://oreil.ly/8lo6W)时，这也就不足为奇了，他们承诺终止企业客户对其从公共网络收集的照片数据库的访问。
- en: Note
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you’re one of the billions of people who have a social media profile, you
    should probably limit the availability of a lot of your information to yourself
    only or just close friends. An even better step would be to apply any of the various
    facial recognition–cloaking tools to your photos, such as [the SAND Lab’s Fawkes
    software](https://oreil.ly/ALncK).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是数十亿社交媒体用户之一，你可能应该限制大部分信息仅供自己或亲密朋友查看。更好的做法是应用各种面部识别伪装工具对你的照片进行处理，比如[SAND实验室的Fawkes软件](https://oreil.ly/ALncK)。
- en: 'Case 3: Improperly Stored Medical Data'
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例3：未正确存储的医疗数据
- en: It’s important to remember that improper data sourcing can also apply to how
    data is passed between internal teams. In 2020, security researchers found unprotected
    folders called “staging data” through the Cense AI website that exposed the personal
    and health information of more than 2.5 million patients. The security researchers
    suspected the data was being stored temporarily before being loaded into Cense
    AI’s data management system or AI.^([4](ch05.html#idm45621833967616))
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，不当的数据来源也可能适用于数据如何在内部团队之间传递。2020年，安全研究人员发现了称为“暂存数据”的未受保护文件夹，通过Cense AI网站公开了超过250万名患者的个人和健康信息。安全研究人员怀疑这些数据是在加载到Cense
    AI的数据管理系统或AI之前暂时存储的。
- en: All these cases involved some sort of usage of improperly sourced data. In two
    instances, users may have known their data storage was set to public, but underestimated
    the reach of the data. In the third case, the AI was sourcing data from what was
    supposed to be an internal system, but even temporary relaxing of the security
    standards introduced enormous liabilities.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些情况都涉及某种形式的非法获取数据的使用。在两个案例中，用户可能知道他们的数据存储设置为公共的，但低估了数据的影响力。在第三种情况下，AI正在从本应为内部系统的数据源获取数据，但是即使是暂时放松的安全标准也会引入巨大的法律责任。
- en: If you’re not too concerned about ethics, you should at least be aware that
    these approaches to data will burn bridges, erode customer trust, and generally
    be a public relations disaster. If you’re working on an engineering team that’s
    been tasked with putting together one of these unethical data acquisition projects,
    just know that you will likely be the first scapegoat if your project gets bad
    press.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对道德不太关心，至少要意识到这些对数据的处理方法将会烧毁桥梁，侵蚀客户信任，并且通常会成为公共关系灾难。如果您是一个被指定负责策划这类不道德数据获取项目的工程团队的一员，那么请知道，如果您的项目受到不利报道，您很可能会成为第一个替罪羊。
- en: Issues in Procuring Real-World Data
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获得现实世界数据的问题
- en: When it comes to evaluating your data acquisition efforts, there are a few aspects
    you’ll want to look at.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当评估您的数据获取工作时，您会希望查看几个方面。
- en: Using the Right Data for the Modeling Goal
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用正确的数据来达到建模目标
- en: Before data acquisition, you should first ask whether you have the correct data
    for the modeling goal. For example, if you’re acquiring cell-imaging data for
    a microscopy dataset, but you’re trying to look at protein folding (proteins being
    much smaller than cells), then the most wisely sampled, ethically acquired cell
    dataset won’t help you much with your protein-folding research.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据获取之前，您应首先询问是否拥有适合建模目标的正确数据。例如，如果您正在获取显微镜数据以获得细胞成像数据集，但您试图观察蛋白质折叠（蛋白质比细胞小得多），那么即使是最明智地取样的、在道德上获取的细胞数据集对您的蛋白质折叠研究也帮助不大。
- en: Consent
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 同意
- en: Put simply, do you have the permission of whoever produced the data to use it?
    This doesn’t just mean explaining what you’re going to do in a long and illegible
    “Terms and Conditions” document. Ideally, you should make sure your users are
    fully aware of what the data is being used for, or at least that you’re using
    it.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地说，您是否获得了数据的生产者的使用许可？这不仅意味着在冗长而难以理解的“条款和条件”文件中解释您将要做的事情。理想情况下，您应确保用户充分了解数据的使用目的，或者至少您正在使用该数据。
- en: 'Even if you do have the consent of the data owner, that consent might not be
    unlimited in terms of time or geography. For this reason, you should also have
    a data retention policy in place. The purpose of a data retention policy is to
    determine the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您已经得到了数据所有者的同意，这种同意可能在时间或地理范围上并不是无限制的。因此，您还应该制定一个数据保留政策。数据保留政策的目的是确定以下内容：
- en: How long you will store the data
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您将存储数据的时间有多长
- en: How you will store the data
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您将如何存储数据
- en: Where you will store the data
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您将存储数据的位置
- en: The format of the data
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的格式
- en: The medium for storing the data
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储数据的介质
- en: Who has authority over the data
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁对数据拥有权威
- en: What happens when an unauthorized entity accesses the data
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当未经授权的实体访问数据时会发生什么
- en: Depending on your industry (e.g., healthcare, defense, accounting), this might
    already be required for compliance. If it’s not, it’s still a best practice to
    have one in place.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您所在行业（例如医疗保健、国防、会计等），这可能已经是合规要求。即使不是，建议仍然制定一个最佳实践政策。
- en: After the Sarbanes–Oxley Act in 2002, corporate accountability was enforced
    through mechanisms like having an ethics officer and a dedicated code of ethics.
    Translating those so they apply to organizations using AI systems is one way to
    increase the responsibility of organizations developing this technology.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在2002年通过萨班斯-奥克斯利法案之后，企业通过设立伦理官员和专门的伦理准则等机制来强化企业责任。将这些准则翻译为适用于使用 AI 系统的组织是增加这些技术开发组织责任感的一种方式。
- en: PII, PHI, and Secrets
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PII、PHI 和 机密信息
- en: Even if you have the consent of the data owner or owners, you still need to
    make sure that you’re not using any data that contains personally identifiable
    information (PII). This can refer to a bunch of different information fields or
    combinations thereof. For example, a person’s name and date of birth together
    would be higher risk than either of those fields alone. The same applies to storing
    a person’s name alongside their address. Other fields are sensitive even on their
    own, such as phone numbers, email addresses, Social Security numbers, healthcare
    keywords, VINs, and device identifiers.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您已经得到数据所有者的同意，您仍然需要确保不使用包含个人身份信息（PII）的任何数据。这可能涉及一系列不同的信息字段或其组合。例如，一个人的姓名和出生日期合在一起的风险比这些字段单独使用更高。同样适用于将一个人的姓名与其地址一起存储。其他字段即使单独使用也是敏感的，例如电话号码、电子邮件地址、社会安全号码、医疗关键词、车辆识别号（VIN）和设备标识符。
- en: Depending on which country you’re in, this might be legally protected information.
    For example, in the US, protected health information (PHI) is protected by the
    Health Insurance Portability and Accountability Act (HIPAA). PHI is any information
    that describes a person’s medical history (e.g., mental or physical health conditions,
    tests and laboratory results, insurance information, and/or identifiable demographic
    information).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您所在的国家不同，这可能是受法律保护的信息。例如，在美国，受保护的健康信息（PHI）受《健康保险移植与责任法案》（HIPAA）保护。 PHI 是指描述一个人医疗历史的任何信息（例如，心理或身体健康状况、测试和实验室结果、保险信息和/或可识别的人口统计信息）。
- en: Still, even if you’re sure there is no legally defined PII or PHI in your data,
    you should still be careful about sensitive information. For example, if you’re
    working on a project that involves NLP tasks on codebases, you want to make sure
    that codebase has been cleared of any secrets.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您确信您的数据中没有法律上定义的 PII 或 PHI，您仍应注意敏感信息。例如，如果您正在处理涉及代码库的 NLP 项目，您需要确保代码库已经清除了任何机密信息。
- en: Proportionality and Sampling Techniques
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比例和抽样技术
- en: The relative frequency of samples in the dataset and the presence of outliers
    is something everyone should know about a dataset before using it. Whatever dataset
    you’re creating, you want to make sure that the relative frequencies of all the
    features match those of the entire real-world population. Due to the law of large
    numbers, this is often (though not always) synonymous with making sure your dataset
    is large enough.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用数据集之前，每个人都应该了解数据集中样本的相对频率以及是否存在异常值。无论您创建的是什么数据集，您都希望确保所有特征的相对频率与整个真实世界人口的相匹配。由于大数定律的存在，这通常（但并非总是）与确保您的数据集足够大是同义的。
- en: Undescribed Variation
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未描述的变异
- en: For your dataset, there might be data features that aren’t explained by any
    of the dependent variables that you’re interested in. If you don’t properly normalize
    or clean the data of some of these features, the model may waste computing time
    trying to figure out how they are relevant to the target variable. While it might
    be easy enough to ignore these in many other statistical tests, it can be hard
    to get machine learning models to ignore the features you’re not interested in.
    It’s also possible that you’ve simply made a mistake in your data-labeling process,
    and your model is looking for a pattern that doesn’t and shouldn’t exist. This
    in turn can lead to unintended proxies.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于您的数据集，可能存在未被任何感兴趣的因变量解释的数据特征。如果您不适当地对一些这些特征进行归一化或清理，模型可能会浪费计算时间来试图弄清楚它们与目标变量的相关性。虽然在许多其他统计测试中可能很容易忽略这些问题，但很难让机器学习模型忽略您不感兴趣的特征。还有可能是您在数据标记过程中犯了错误，您的模型正在寻找不存在且不应存在的模式。这反过来可能会导致意外的替代指标。
- en: Unintended Proxies
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 意外的替代指标
- en: This is an issue where a certain feature of the data is not recorded, but the
    model is able to use others as a proxy. For example, thanks to years of discriminatory
    housing policies in many cities, some machine learning models may unintentionally
    use a data feature like `postal_code` as a proxy for ethnicity or race. In another
    case, a machine learning model trained to detect COVID-19 in chest X-rays turned
    out to be [heavily trained on sick children who did not actually have COVID-19](https://oreil.ly/cTju4).
    As a result, the model mainly paid attention to whether patients were lying down
    (which was more likely to mean serious illness), which was the unintended proxy.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个数据的某个特征没有记录的问题，但模型能够使用其他特征作为代理。例如，由于许多城市历年来的歧视性住房政策，一些机器学习模型可能会无意中将像`postal_code`这样的数据特征作为种族或族裔的代理。另一个案例中，一个训练用于检测胸部X射线中COVID-19的机器学习模型，结果发现主要是[在实际没有COVID-19的患病儿童](https://oreil.ly/cTju4)进行了大量训练。因此，该模型主要关注患者是否躺下（这更可能意味着严重疾病），这是意外的代理。
- en: Failures of External Validity
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 外部效度的失败
- en: External validity refers to how much you can generalize your findings to other
    situations, people, settings, and measures. In other words, can you apply the
    conclusions from this model to other situations? There are plenty of scenarios
    in which external validity can be undermined. For example, if you have a medical
    dataset you’re trying to use to predict a mental illness, and that model performs
    really well, you may be tempted to apply it to people outside of the study. However,
    consider if you only had data from 20- to 29-year-olds. This model suddenly seems
    much less applicable to the general population. You can certainly replicate the
    model’s performance on new 20- to 29-year-olds, but if you’re claiming that the
    model can perform equally well on people outside that age range, this is a failure
    of validity. This heavily overlaps with a lot of the concepts described in [Chapter 2](ch02.html#chapter2).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 外部效度是指您能将研究结果推广到其他情境、人群、设置和测量程度的程度。换句话说，您能否将这个模型的结论应用到其他情况？有很多情况下，外部效度可能会受到损害。例如，如果您有一个医疗数据集，试图用它来预测某种精神疾病，并且该模型表现非常出色，您可能会想将其应用于研究之外的人群。然而，请考虑一下，如果您只有20到29岁年龄段的数据。这个模型突然对普通人群的适用性显得不那么可靠了。当然，您可以在新的20到29岁年龄段上复制模型的性能，但如果您声称该模型在超出该年龄段的人群中同样表现良好，那这就是效度失败了。这与[第二章](ch02.html#chapter2)中描述的许多概念有很大重叠。
- en: Data Integrity
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据完整性
- en: Do you understand where the data came from? Are there interpolated values mixed
    in with the real data? Have you kept track of which corrections are being made
    to the data? Have you made sure that there aren’t data instances present in both
    your training and test dataset? For example, getting a model to high accuracy
    on MNIST is a very easy task. However, before you celebrate getting your neural
    network to work, you should be aware that there [are a few mislabeled entries
    in the MNIST dataset](https://oreil.ly/cZE0N).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道数据的来源吗？在真实数据中是否混有插值数值？你有记录数据进行的哪些修正吗？你确定训练集和测试集中没有相同的数据实例吗？例如，在MNIST数据集中获得高准确率的模型是一件非常容易的事情。然而，在庆祝你的神经网络开始工作之前，你应该意识到MNIST数据集中[存在一些错误标记的条目](https://oreil.ly/cZE0N)。
- en: One of the easiest mistakes to make on a data science or machine learning project,
    especially prior to putting together a dedicated pipeline manager, is not properly
    tracking which data is in which split.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学或机器学习项目中，尤其是在组建专门的管道管理器之前，最容易犯的错误之一是没有正确跟踪哪些数据位于哪个拆分中。
- en: Splitting datasets into training, validation, and test sets is a common practice
    in machine learning. There’s also different ratios for how much data should be
    in each split, with some ratios being better for different dataset sizes than
    others. There’s also varying strategies for shuffling or stratifying the data.
    In some cases, such as when you’re working with time series data, you may want
    to make sure that the data is split by time.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集拆分为训练、验证和测试集是机器学习中的常见做法。每个拆分中应该有多少数据的比例也有所不同，有些比例适合不同的数据集大小。还有各种不同的洗牌或分层数据的策略。在某些情况下，例如当你处理时间序列数据时，你可能希望确保数据按时间分割。
- en: These are all important things to consider, but the problem we want to focus
    on here is far simpler. We want to make sure that when we’re testing our model
    on either the training or validation dataset that it’s not just scoring higher
    because it’s memorizing the data. We discussed various ways to test the robustness
    of a machine learning model in [Chapter 4](ch04.html#chapter4), but this is a
    very common source of non-robustness (even if it’s not the only source of problems
    for a particular model).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是需要考虑的重要事项，但我们要关注的问题要简单得多。我们希望确保在测试模型时，无论是在训练集还是验证集上，它都不仅仅是因为记住了数据而得分较高。我们在[第四章](ch04.html#chapter4)中讨论了测试机器学习模型鲁棒性的各种方法，但这是非鲁棒性的一个非常常见的来源（即使对于特定模型来说，这并不是唯一的问题来源）。
- en: Setting Reasonable Expectations
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设定合理的期望
- en: After putting in all the effort to acquire a dataset, you might expect the resulting
    model to suddenly be able to answer any question about the subject. It’s always
    important to manage expectations. After all, if you’re training a regression or
    classification model on a dataset, you should keep in mind that the main category
    of questions you’ll be able to answer are those directly related to the model
    type. Even then, some of the outputs may result from quirks or bottlenecks in
    the model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在努力获取数据集之后，您可能期望生成的模型突然能够回答关于主题的任何问题。管理期望总是很重要的。毕竟，如果您在数据集上训练回归或分类模型，您应该记住您能够回答的主要问题类别是直接与模型类型相关的。即便如此，一些输出可能是由于模型中的怪癖或瓶颈导致的。
- en: Tools for Addressing Data Collection Issues
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据收集问题的工具
- en: There are not many technical tools that can automatically help you collect a
    more trustworthy real-world dataset. Most of the existing tools can only really
    help after you’ve addressed some of the higher-level issues described previously.
    For dealing with higher-level issues, one of the best things to keep handy is
    a checklist. This is an area where sophisticated tools cannot compensate for human
    intent and intentional system design.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 并没有太多技术工具可以自动帮助您收集更可靠的真实世界数据集。大多数现有工具实际上只能在您解决了前述一些更高级别问题后才能真正帮上忙。在处理更高级别问题时，最好随时准备一个检查清单。这是一个领域，高级工具无法弥补人类意图和有意设计的地方。
- en: Once you’ve gone through your checklist, the other tools will actually be helpful.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您完成了检查清单，其他工具实际上会非常有帮助。
- en: Getting consent
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获得同意
- en: For getting consent, there are some design principles that can make you one
    of the stand-out good guys (at least compared to everyone else).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得同意，有一些设计原则可以使您成为突出的好人（至少与其他人相比是如此）。
- en: For “Terms and Conditions” pages, plenty of sites nowadays have a timer that
    only lets you select the *agree* option after a certain amount of time, or after
    you’ve scrolled all the way to the bottom, or both. A few other organizations
    go further by providing a text-to-speech option for the terms and conditions (and
    if you’re updating it, you can use automatic text-to-speech tools like Speechify
    or Resemble AI).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于“条款和条件”页面，如今有许多网站设置了一个计时器，只有在一定时间后或者在您完全滚动到底部后才能选择*同意*选项，或者两者兼而有之。其他一些组织则通过提供条款和条件的文本转语音选项进一步提升服务（如果您正在更新它，您可以使用像Speechify或Resemble
    AI这样的自动文本转语音工具）。
- en: For creating a data retention policy, [use Proofpoint’s guide](https://oreil.ly/JRu0n).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 创建数据保留政策，请参阅 [Proofpoint 指南](https://oreil.ly/JRu0n)。
- en: Identifying PHI, PII, and other sensitive data
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 辨识 PHI、PII 和其他敏感数据
- en: For identifying PHI, you can use [the Nightfall PHI/PII API](https://oreil.ly/PyPmF).
    AWS also has a [medical data API](https://oreil.ly/AMrNS) that can help you identify
    PHI.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对于识别 PHI，您可以使用 [Nightfall PHI/PII API](https://oreil.ly/PyPmF)。AWS 还有一个可以帮助您识别
    PHI 的 [医疗数据 API](https://oreil.ly/AMrNS)。
- en: For clearing secrets, you can also use [the Nightfall Secrets API](https://oreil.ly/6b7rU).
    Nightfall can scan for secrets for services such as AWS, Azure, Confluence, Confluent,
    Datadog, ElasticSearch, Facebook, GitHub, GitLab, Google API, JIRA, Nightfall,
    Okta, Paypal, Plaid, Salesforce, Slack, Square, Stripe, Twitter, Twilio, and Zapier.
    GitHub itself offers a [secret-scanning tool](https://oreil.ly/DTaJ5) (though
    given their past scandals with secrets, such as cryptocurrency private keys showing
    up in GitHub copilot autocompletions, we recommend exploring all of your options
    first).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要清除密钥，您还可以使用[Nightfall Secrets API](https://oreil.ly/6b7rU)。Nightfall可以扫描诸如AWS、Azure、Confluence、Confluent、Datadog、ElasticSearch、Facebook、GitHub、GitLab、Google
    API、JIRA、Nightfall、Okta、Paypal、Plaid、Salesforce、Slack、Square、Stripe、Twitter、Twilio和Zapier等服务的秘密。GitHub本身提供了[secret-scanning
    tool](https://oreil.ly/DTaJ5)（尽管鉴于他们过去在秘密方面的丑闻，比如加密货币私钥出现在GitHub copilot的自动完成中，我们建议先探索所有选项）。
- en: Proportionality and sampling techniques
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比例和抽样技术
- en: The right proportions of classes can be important. For example, if you’re training
    a classification model, you might want to make sure your data pipeline is more
    frequently sampling the minority class.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的类比例很重要。例如，如果您正在训练分类模型，您可能希望确保您的数据管道更频繁地对少数类进行抽样。
- en: Tracking unintended variation
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪意外变化
- en: For taking control of unintended variation, you can use tools like those discussed
    in [Chapter 4](ch04.html#chapter4) to identify unintended variation.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了控制意外变化，您可以使用像[第4章](ch04.html#chapter4)讨论的工具来识别意外变化。
- en: Tracking unintended proxies
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪意外代理
- en: Many of the tools discussed in [Chapter 3](ch03.html#chapter3) can also be used
    to track unintended proxies.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[第3章](ch03.html#chapter3)讨论的许多工具也可以用来跟踪意外代理。'
- en: Data integrity
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据完整性
- en: For areas like the life sciences, workflows that track data provenance are standard
    practice. Tools like [Insitro’s Redun](https://oreil.ly/IpfEz) are excellent for
    those domains. Not specific to biosciences are tools like [Airflow](https://oreil.ly/MAexk)
    and [Luigi](https://oreil.ly/hz0ld). I would also recommend checking out tools
    like [Flyte](https://oreil.ly/2h6mP) for managing your data pipelines. When it
    comes to tracking changes to the data, tools like [Data Version Control (DVC)](https://dvc.org)
    are also a good option. When those changes involve pre-processing steps and feature
    engineering, you can use a feature store like [Feathr](https://oreil.ly/gglaw)
    (created by LinkedIn) that offers interfaces for monitoring and tracking these
    steps.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生命科学等领域，跟踪数据来源的工作流是标准做法。像[Insitro’s Redun](https://oreil.ly/IpfEz)这样的工具非常适合这些领域。不特定于生物科学的工具还包括像[Airflow](https://oreil.ly/MAexk)和[Luigi](https://oreil.ly/hz0ld)这样的工具。我还建议查看像[Flyte](https://oreil.ly/2h6mP)这样的工具来管理您的数据管道。当涉及到跟踪数据变更时，像[Data
    Version Control (DVC)](https://dvc.org)这样的工具也是一个不错的选择。当这些变更涉及预处理步骤和特征工程时，您可以使用由LinkedIn创建的特征存储库[Feathr](https://oreil.ly/gglaw)，该存储库提供了用于监控和跟踪这些步骤的接口。
- en: Improperly organized splits
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 错误组织的拆分
- en: When you need to make sure your model is not reusing the same data instances
    in both your training and test data, you can use a tool like [did-it-spill](https://oreil.ly/fdPhQ).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当您需要确保您的模型在训练和测试数据中没有重复使用相同的数据实例时，您可以使用像[did-it-spill](https://oreil.ly/fdPhQ)这样的工具。
- en: Setting reasonable expectations
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设定合理的期望
- en: One of the most common failure modes in deploying machine learning products
    can stem from (1) not stating why you think generalization is possible and (2)
    not thinking carefully about the universe of your out-of-distribution cases. It’s
    hard to identify a software package that can help you set reasonable expectations.
    The best you can do is to keep a running tab on all the different failure cases
    that your model might encounter. When it comes to figuring out what questions
    your machine learning model or pipeline will answer, it’s also important to list
    the questions that it won’t answer.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 部署机器学习产品中最常见的故障模式之一可能源于（1）未说明为何认为泛化是可能的以及（2）未仔细思考您的超出分布案例的宇宙。很难找到一个能帮助您设定合理期望的软件包。您能做的最好的事情是持续跟踪您的模型可能遇到的所有不同故障案例。当您需要弄清楚您的机器学习模型或管道将回答的问题时，列出它不会回答的问题也很重要。
- en: All these issues with real-world data have led people to try to come up with
    approaches for synthetic training data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些真实世界数据的问题都导致人们试图提出合成训练数据的方法。
- en: Synthetically Generated Data
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成生成的数据
- en: Given all the challenges of sourcing real-world data, it may be tempting to
    search for ways of producing synthetic data. After all, machine learning models
    such as StyleGAN famously produce realistic faces of [people who do not actually
    exist](https://oreil.ly/ojmhw) (as well as [cats](https://oreil.ly/2THmG), [rental
    apartments](https://oreil.ly/BsBSX), and [vehicles](https://oreil.ly/utQEp) that
    do not exist in the real world. See [“This X does not exist”](https://oreil.ly/tS6sg)
    for more examples).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 面对获取真实世界数据的所有挑战，寻找生产合成数据的方法可能会很诱人。毕竟，像 StyleGAN 这样的机器学习模型以非真实存在的[人物](https://oreil.ly/ojmhw)（以及[猫](https://oreil.ly/2THmG)、[租房公寓](https://oreil.ly/BsBSX)和[车辆](https://oreil.ly/utQEp)）闻名。有关更多示例，请参阅[“This
    X does not exist”](https://oreil.ly/tS6sg)。
- en: 'These data generators do have a few shortcomings compared to real-world data.
    However, synthetic data is still incredibly useful for one crucial step of many
    machine learning pipelines: transfer learning. A model trained on high-quality
    synthetic data can be quickly trained on real-world data. This approach has a
    few advantages:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 与真实世界的数据相比，这些数据生成器确实存在一些缺点。然而，合成数据在许多机器学习流程中的一个关键步骤上仍然非常有用：迁移学习。在高质量合成数据上训练的模型可以快速地在真实数据上进行训练。这种方法有几个优点：
- en: Synthetic data can be made to have perfectly accurate labels. This even applies
    to detailed labels that might be cumbersome or expensive to acquire in real life.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成数据可以拥有完全准确的标签。这甚至适用于在现实生活中获取可能复杂或昂贵的详细标签。
- en: Synthetic environments can be easily tweaked to make changes to the model’s
    behavior, such as randomizing parts of the environment you want the model to ignore
    while keeping consistent the features you want the model to focus on.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以轻松调整合成环境，以改变模型的行为，例如随机化要忽略的环境部分，同时保持希望模型专注的特征的一致性。
- en: Synthetic data can be used as a proxy for sensitive real-world data, training
    a model on important patterns while leaving out those patterns that would be tied
    to specific individuals (see [Chapter 1](ch01.html#chapter1) for more on privacy).
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成数据可以作为敏感真实世界数据的代理，训练模型捕捉重要模式，同时排除与特定个体相关的模式（有关隐私详情，请参阅[第 1 章](ch01.html#chapter1)）。
- en: Synthetic data generators can quickly and cheaply produce however much data
    is needed once they’re built.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦建立起来，合成数据生成器可以快速、廉价地生成所需的大量数据。
- en: Of course, realizing these benefits is entirely contingent on having a *good
    enough* data generator. Creating generators that can produce realistic data is
    a non-trivial task. More importantly, it isn’t yet possible to exclusively use
    generators for training models that are then deployed to the real world without
    training on real data. We don’t live in an ideal world.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，实现这些好处完全依赖于具有足够*优质*的数据生成器。创建能够生成逼真数据的生成器是一项非平凡的任务。更重要的是，尚不能完全依赖生成器训练模型并将其部署到真实世界中，而不进行真实数据训练。我们并非生活在一个理想的世界中。
- en: Still, that doesn’t mean companies haven’t devoted tons of time and resources
    to creating sophisticated data simulation tools. For example, there’s NVIDIA Omniverse,
    a simulation, physics engine, and rendering tool. There’s also Pixar’s universal
    scene description technology to do accurate renderings. Physics simulators like
    MuJoCo have been used in reinforcement learning for years, and ever since DeepMind
    bought MuJoCo and made it open source, using it has been as easy as `pip install
    mujoco`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不意味着公司没有投入大量时间和资源来创建复杂的数据模拟工具。例如，有 NVIDIA Omniverse，一个仿真、物理引擎和渲染工具。还有 Pixar
    的通用场景描述技术，用于进行准确的渲染。物理模拟器如 MuJoCo 多年来一直在强化学习中使用，自从 DeepMind 购买 MuJoCo 并开源以来，使用它就像`pip
    install mujoco`一样简单。
- en: DALL·E, GPT-3, and Synthetic Data
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DALL·E、GPT-3 和合成数据
- en: If you’ve been paying attention to AI news, you may have concluded that AI generators
    have already gotten to the point where they can be used to generate realistic
    data. For example, the DALL·E project is an image generation AI that can create
    realistic images from just text. A few people tried using projects like [Craiyon
    (formerly known as DALL·E mini)](https://oreil.ly/f4ZAp) (and its compute-optimized
    forks for usage on a local machine)^([5](ch05.html#idm45621833814912)) to try
    creating image classifiers in under five minutes. For example, for an apple versus
    banana classifier, one could feed in a bunch of prompts to DALL·E mini like “Banana
    on table,” “Banana on random background,” “Apple on table,” and “Apple on random
    background.” One could then feed these images into a tool like Google’s [Teachable
    Machine](https://oreil.ly/lwdcd) and get a classifier that seems to work pretty
    well when it comes to classifying real-life apples and bananas. If you’ve read
    the previous chapters, you will be aware at this point that making a basic working
    ML model in a toy environment is easy, but making it robust in the real world
    is much harder. For example, the aforementioned classifier ends up failing in
    cases such as a yellow apple, or apples and bananas in different lighting, or
    items that don’t belong in either category.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你关注过人工智能的新闻，你可能会得出结论，AI生成器已经发展到可以用来生成逼真数据的程度。例如，DALL·E项目就是一个可以从文本生成逼真图像的图像生成AI。有些人尝试使用像[Craiyon（之前称为DALL·E迷你）](https://oreil.ly/f4ZAp)（及其适用于本地计算机的优化分支）^([5](ch05.html#idm45621833814912))来尝试在不到五分钟内创建图像分类器。例如，对于一个苹果与香蕉分类器，可以向DALL·E迷你输入一系列提示，如“桌上的香蕉”，“随机背景上的香蕉”，“桌上的苹果”和“随机背景上的苹果”。然后，可以将这些图像输入到像谷歌的[Teachable
    Machine](https://oreil.ly/lwdcd)这样的工具中，并得到一个在分类现实生活中的苹果和香蕉时似乎运作良好的分类器。如果你已经阅读了前几章，那么你现在应该意识到，在玩具环境中制作基本工作的ML模型很容易，但要在真实世界中使其稳健则更为困难。例如，前述分类器最终在黄色苹果或不同光照下的苹果和香蕉，或者不属于任何类别的物品的情况下失败了。
- en: Still, plenty of people will still be tempted by the synthetic data generators.
    Shortly after the release of DALL·E mini, people discovered that the program could
    create seemingly realistic biological research data ([Figure 5-1](#dalle-mini-images)).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，仍有许多人会被合成数据生成器所诱惑。在DALL·E迷你发布后不久，人们发现该程序可以创建看似逼真的生物研究数据（[图 5-1](#dalle-mini-images)）。
- en: '![ptml 0501](assets/ptml_0501.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0501](assets/ptml_0501.png)'
- en: Figure 5-1\. Fake microscopy images generated from the DALL·E mini model
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-1\. 从DALL·E迷你模型生成的假显微镜图像
- en: None of the images in [Figure 5-1](#dalle-mini-images) came from an actual laboratory
    or microscope. They were simply generated by a computer program. To a non-expert,
    these images might seem very realistic. However, if you wanted to use images like
    this to either fully train a machine learning model or validate a hypothesis in
    a scientific publication, you would quickly hit a wall. When generative models
    create images like this, they are essentially sampling from a probability distribution
    representing the likely properties of the image. This means you will often get
    stereotyped images, and the few images that are not stereotyped will just look
    incoherent. As such, this is an extremely poor choice of tool for making sense
    of a domain like cell biology, which is characterized by looking for all sorts
    of outliers.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-1](#dalle-mini-images)中的图像都不是来自实际实验室或显微镜。它们只是由计算机程序生成的。对于非专家来说，这些图像可能看起来非常逼真。然而，如果你想要使用这样的图像来完全训练一个机器学习模型或验证科学出版物中的假设，你会很快遇到困难。当生成模型创建这样的图像时，它们实际上是从代表图像可能属性的概率分布中进行采样。这意味着你经常会得到刻板化的图像，而那些不刻板的图像看起来只会让人感到不协调。因此，这是在像细胞生物学这样一个需要寻找各种离群点的领域中理解的极其糟糕的工具选择。'
- en: In addition to being practically useless as a sole source of training data or
    hypothesis validation, these images, if added to some sort of publication, would
    likely destroy any trust between the publisher and whoever submitted the images.
    This means that, when it comes to using synthetic data for either machine learning
    or science, these kinds of images are actually worse than useless.^([6](ch05.html#idm45621833808128))
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 除了作为唯一的训练数据来源或假设验证的实际无用外，如果将这些图像添加到某种出版物中，可能会破坏出版者与提交图像的人之间的任何信任。这意味着，当涉及使用合成数据进行机器学习或科学研究时，这些类型的图像实际上比无用还要糟糕。^([6](ch05.html#idm45621833808128))
- en: This is not to say that synthetic data never has *any* use. It’s just that using
    it correctly is usually far more nuanced and tricky than it might immediately
    seem. Shooting oneself in the foot with synthetic data is also extremely easy.
    Even in the best-case scenario, you will probably only be able to use the synthetic
    data for pre-training, rather than a full end-to-end model-training pipeline that
    can function in the real world.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着合成数据从不具有*任何*用途。只是要正确使用它通常比看起来要微妙和棘手得多。使用合成数据搞砸自己的脚也极为容易。即使在最好的情况下，您可能也只能将合成数据用于预训练，而不是一个可以在真实世界中运行的完整端到端模型训练流水线。
- en: Improving Pattern Recognition with Synthetic Data
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用合成数据改善模式识别
- en: If you cannot use synthetic data to fully train a model, then how useful can
    it be? Even if you’re not relying on synthetic data for the whole process, it
    can still be incredibly useful for improving the overall pattern recognition capabilities
    of a model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不能使用合成数据完全训练模型，那么它能有多大用处呢？即使您不依赖合成数据进行整个过程，它仍然可以极大地提升模型的整体模式识别能力。
- en: Process-driven synthetic data
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过程驱动的合成数据
- en: Process-driven synthetic data is a type of synthetic data that is generated
    by an explicitly defined algorithm. This may involve randomly selecting points
    from an equation or manifold that’s had some random noise added onto it. The upside
    of these approaches is that it’s easy to incorporate human domain knowledge into
    this data generation. The downside is that a poorly designed process can exacerbate
    blind spots and biases of the humans designing the process.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 过程驱动的合成数据是通过显式定义的算法生成的一种合成数据类型。这可能涉及从方程或流形中随机选择点，并对其添加一些随机噪声。这些方法的优势在于可以将人类领域知识轻松地整合到数据生成中。不利之处在于，设计不当的过程可能会加剧设计该过程的人类的盲点和偏见。
- en: Data-driven synthetic data
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据驱动的合成数据
- en: Data-driven synthetic data refers to synthetic data that has been produced by
    a generative model fit to or trained on some kind of real-world data. In this
    category you can find the various generative adversarial networks (GANs) and flow
    models that are used for producing synthetic data.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 数据驱动的合成数据指的是通过适应或训练于某种现实世界数据的生成模型生成的合成数据。在这一类别中，您可以找到各种生成对抗网络（GAN）和流模型，用于生成合成数据。
- en: The upside of this approach is that one can be more confident that the dataset
    is representative of real-life phenomena. The downside is that training a good
    generator depends on having access to a large and high-quality dataset, and if
    you already have such a good dataset, you probably don’t need this new generator
    in the first place. After all, if you’re trying to make a model that can discriminate
    between image classes produced from a GAN, why not just use the discriminator
    from the GAN itself? Conversely, if you don’t have enough data to reliably train
    a classifier or regressor, you should not expect turning the model into a generator
    to magically solve the data problem.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的优势在于可以更有信心地确保数据集代表真实生活现象。不利之处在于，训练一个良好的生成器取决于是否有大量且高质量的数据集，如果您已经拥有这样一个好的数据集，您可能根本不需要这个新的生成器。毕竟，如果您试图制作一个可以区分由GAN生成的图像类的模型，为什么不直接使用GAN本身的判别器呢？相反，如果您没有足够的数据来可靠地训练分类器或回归器，您不应期望将模型转化为生成器能够奇迹般地解决数据问题。
- en: 'Deep Dive: Pre-Training a Model with a Process-Driven Synthetic Dataset'
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入探讨：使用过程驱动的合成数据集预训练模型
- en: For an example of improving pattern recognition, let’s take a look at what happens
    when you pre-train a model on nothing but raw patterns.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以提高模式识别为例，让我们看看当您仅在原始模式上预训练模型时会发生什么。
- en: If you were to take a look at the activations of an image recognition network,
    you would see that collections of neurons in the earlier layers are typically
    more active when it comes to simple patterns based on one or two colors, and the
    intersection between them is oriented at an angle. The later layers are usually
    activated after combinations of the earlier neurons are activated in groups to
    form higher-level patterns, such as distinct shapes. Even later, the layers are
    recognizably activated in response to the presence of patterns corresponding to
    high-level concepts. When you run the full network, the pattern recognition progresses
    from edges, to textures, to patterns, to parts, and finally to objects.^([7](ch05.html#idm45621833777040))
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看图像识别网络的激活，你会发现早期层次中的神经元集合通常在处理基于一两种颜色的简单模式时更活跃，并且它们的交集呈角度取向。稍后的层次通常在早期神经元组合激活后被激活，形成更高级别的模式，例如独特的形状。甚至更晚一些，这些层次在响应于高级概念对应的模式存在时被明显激活。当你运行整个网络时，模式识别从边缘、纹理、图案、部件，最终到物体的过程逐步进行。^([7](ch05.html#idm45621833777040))
- en: If you train a model from scratch, your model needs to learn all of these patterns,
    both high level and low level. The motivation behind pre-training is that while
    the higher-level concepts close to the end may not be as useful due to the change
    in domain, training on a large dataset may mean less retraining has to happen
    on the earlier layers. For this reason, computer vision models are often pre-trained
    on such large and (relatively) diverse classification datasets as ImageNet.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从头开始训练一个模型，你的模型需要学习所有这些模式，包括高级和低级模式。预训练背后的动机在于，虽然接近末端的高级概念由于域的改变可能不那么有用，但在大型数据集上进行训练可能意味着早期层次上的重新训练减少。因此，计算机视觉模型通常会在像ImageNet这样的大型（相对）多样化的分类数据集上进行预训练。
- en: Suppose you wanted to do this kind of pre-training without training on ImageNet,
    or for that matter any other real-world data. You can do this by building a process-driven
    synthetic data generator that allows a model to train on a bunch of fractals.
    These are fractals that are completely abstract and don’t correspond to real-world
    objects. You can get results that are comparable to using a model pre-trained
    on a dataset like ImageNet.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想要进行这种类型的预训练，而不是在ImageNet或者任何其他真实世界的数据上进行训练。你可以通过构建一个基于过程驱动的合成数据生成器来实现这一点，使模型能够在一堆分形图上进行训练。这些分形图完全是抽象的，不对应于真实世界的物体。你可以得到与使用ImageNet这样的数据集预训练的模型相媲美的结果。
- en: Note
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You can find all the code associated with this tutorial in the notebook [*Chapter_5_Synthetic_Data_Fractals.ipynb*](https://oreil.ly/IQpwY).
    This was heavily inspired by the optimized fractal pre-training techniques described
    in “Improving Fractal Pre-Training,”^([8](ch05.html#idm45621833772464)) which
    improved upon the initial discovery by Kataoka et al. (2020) that synthetic fractals
    could be used in pre-training at all.^([9](ch05.html#idm45621833770640)) Much
    of the code has been refactored and uses PyTorch and HuggingFace.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在笔记本[*Chapter_5_Synthetic_Data_Fractals.ipynb*](https://oreil.ly/IQpwY)中找到与本教程相关的所有代码。这受到了“改进分形预训练”中优化的分形预训练技术的启发，^([8](ch05.html#idm45621833772464))
    该技术在2020年由片冈等人首次提出，表明合成分形可以用于预训练。^([9](ch05.html#idm45621833770640)) 很多代码已经进行了重构，并使用了PyTorch和HuggingFace。
- en: If you want to visualize the fractals being generated from the parameters, try
    out the [interactive in-browser visualizer](https://oreil.ly/goLSk) from “Improving
    Fractal Pre-Training.”
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要可视化从参数生成的分形图，请尝试来自“改进分形预训练”的[交互式浏览器可视化工具](https://oreil.ly/goLSk)。
- en: For the data generator, you will make heavy use of the Numba library for efficiently
    producing these shapes on a CPU. The script produces images that can either be
    stored in a dataset on disk, or produced from scratch for each iteration of the
    training data generator. Each of the output fractals will have a colored background,
    a numerical constant corresponding to the shape and type of the fractal, as well
    as one or multiple label types corresponding to all of these properties (see [Figure 5-2](#fractal-sample-image)).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据生成器，你将大量使用Numba库来在CPU上高效地生成这些形状。该脚本生成的图像可以存储在磁盘上的数据集中，也可以在每次训练数据生成器的迭代中从头生成。每个输出的分形图将具有有色背景，对应于分形的形状和类型的数值常数，以及与所有这些属性对应的一个或多个标签类型（见[图5-2](#fractal-sample-image)）。
- en: '![ptml 0502](assets/ptml_0502.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0502](assets/ptml_0502.png)'
- en: Figure 5-2\. Examples of output fractals
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-2\. 输出分形图示例
- en: Facial Recognition, Pose Detection, and Human-Centric Tasks
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人脸识别、姿势检测和以人为中心的任务
- en: Microsoft has shown that it’s possible to do high-performing facial recognition
    in the wild without (directly) using real data. Instead, Microsoft has built a
    vast dataset of synthetic faces by combining “a procedurally-generated parametric
    3D face model with a comprehensive library of hand-crafted assets to render training
    images with unprecedented realism and diversity.”^([10](ch05.html#idm45621833745440))
    This was achieved with the aptly named project “Fake It Till You Make It” ([Microsoft
    GitHub project page](https://oreil.ly/rUJPn), [dataset repo](https://oreil.ly/GYrPI),
    and [video presentation](https://youtu.be/wlOMpQe8luQ)).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 微软展示了在野外进行高效的人脸识别是可能的，而不需要（直接）使用真实数据。相反，微软通过结合“一个程序生成的参数化3D面部模型和一个全面的手工制作资产库来渲染训练图像，以实现前所未有的真实感和多样性。”^([10](ch05.html#idm45621833745440))
    这是通过名为“假装到成功”（[微软GitHub项目页面](https://oreil.ly/rUJPn)，[数据集库](https://oreil.ly/GYrPI)，以及[视频演示](https://youtu.be/wlOMpQe8luQ)）的项目成功实现的。
- en: 'For a long time, AI had two big resources: data and computation. Projects like
    this show that *data* is really just *computation* in a trench coat. Microsoft
    can use computers to generate vast amounts of data, changing the economics of
    AI development as a whole.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 长期以来，AI拥有两大资源：数据和计算力。像这样的项目表明，*数据*实际上只是*计算力*穿着风衣。微软可以利用计算机生成大量数据，从而改变整体AI开发的经济学。
- en: Going beyond faces to the whole body, [Unity has created a tool kit](https://oreil.ly/Mghmp)
    for generating synthetic human poses and body shapes. This tool kit, [PeopleSansPeople](https://oreil.ly/jawT9),
    allows the bounding boxes and pose key points of the labels to be generated directly
    from the human models.^([11](ch05.html#idm45621833737264)) The project page goes
    into detail about how this can create much larger training datasets than standard
    benchmarks like the [“Common Objects in Context” (COCO) dataset](https://oreil.ly/jfBfO)
    that’s a staple of image segmentation and object detection research (comparable
    to MNIST or CIFAR-10 in image classification). Not only that, but the project
    page also discusses how these synthetic datasets can produce a smoother distribution
    of bounding boxes (see [Figure 5-3](#peoplesanspeople-image)).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅仅局限于面部，[Unity已经创建了一个工具包](https://oreil.ly/Mghmp)，用于生成合成的人体姿势和身体形状。这个工具包，[PeopleSansPeople](https://oreil.ly/jawT9)，允许直接从人体模型生成标签的边界框和姿势关键点。^([11](ch05.html#idm45621833737264))
    该项目页面详细介绍了这如何创建比标准基准如[“常见上下文中的通用对象”（COCO数据集）](https://oreil.ly/jfBfO)（在图像分割和物体检测研究中与MNIST或CIFAR-10相媲美）更大的训练数据集。此外，项目页面还讨论了这些合成数据集如何产生更平滑的边界框分布（见[图5-3](#peoplesanspeople-image)）。
- en: '![ptml 0503](assets/ptml_0503.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![ptml 0503](assets/ptml_0503.png)'
- en: Figure 5-3\. Distribution of bounding boxes from COCO and “PeopleSansPeople,”
    taken from the Unity Technologies project page
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-3\. COCO和“PeopleSansPeople”中的边界框分布，取自Unity Technologies项目页面
- en: Object Recognition and Related Tasks
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 物体识别及相关任务
- en: There are an enormous variety of supervised learning tasks in computer vision
    that can be applied to the same images. The problem is that tasks like image classification,
    instance segmentation, depth mapping, optical flow, and many others require fundamentally
    different kinds of labels. If you could make at least semirealistic images or
    videos of objects, you could automatically generate the different label types
    for the input features since you would have control over both. For example, the
    package [Tex⁠tRecognitionDataGenerator](https://oreil.ly/TkY79) automatically
    generates images of text for optical character recognition (OCR) in various fonts
    and noise levels, all of which are paired with the correct labels every time the
    data is generated. In another example, Microsoft created a generator for virtual
    avatars that would automatically generate labels for over seven hundred key points
    on their faces.^([12](ch05.html#idm45621833710944)) Training on this synthetic
    dataset allowed a facial recognition system to identify those key points on real
    faces, as well as provide confidence estimates on each point when part of the
    person’s face was occluded.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉中有大量的监督学习任务可以应用于相同的图像。问题在于像图像分类、实例分割、深度映射、光流等任务需要基本不同类型的标签。如果能够制作至少半真实的图像或视频，您可以为输入特征自动生成不同类型的标签，因为您可以控制两者。例如，包括[Tex⁠tRecognitionDataGenerator](https://oreil.ly/TkY79)可以自动生成各种字体和噪声水平下的文本图像，用于光学字符识别（OCR），并每次生成数据时与正确的标签配对。另一个例子，微软创建了一个生成器用于虚拟头像，该生成器将为面部的七百多个关键点自动生成标签。^([12](ch05.html#idm45621833710944))
    在这个合成数据集上训练允许面部识别系统在真实面部上识别这些关键点，并在部分面部被遮挡时为每个点提供置信度估计。
- en: Google research produced a tool called [Kubric](https://oreil.ly/cGCg6).^([13](ch05.html#idm45621833707984))
    This is a data generation pipeline for creating semi-realistic synthetic multi-object
    videos with rich annotations such as instance segmentation masks, depth maps,
    and optical flow. [Assuming you have docker installed](https://oreil.ly/UPw0n),
    you can use Kubric to generate synthetic training video data. The result is a
    Pythonic interface for interacting with the renderer (which is Blender, an open
    source 3D renderer).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Google研究开发了一个名为[Kubric](https://oreil.ly/cGCg6)的工具。^([13](ch05.html#idm45621833707984))
    这是一个数据生成管道，用于创建具有丰富注释的半真实合成多对象视频，例如实例分割掩模、深度图和光流。[假设您已安装docker](https://oreil.ly/UPw0n)，您可以使用Kubric生成合成训练视频数据。结果是一个Python界面，用于与渲染器（Blender，一个开源3D渲染器）交互。
- en: '[PRE0]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code makes a scene with some extremely simple objects, but [more complex
    assets](https://oreil.ly/LAszb) can also be specified. You can find more examples
    in the notebook [*Chapter_5_Synthetic_Data_Blender.ipynb*](https://oreil.ly/ubaIR).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码创建了一个场景，其中包含一些极简单的对象，但也可以指定[更复杂的资产](https://oreil.ly/LAszb)。您可以在笔记本[*Chapter_5_Synthetic_Data_Blender.ipynb*](https://oreil.ly/ubaIR)中找到更多示例。
- en: If you’re looking for a much larger prepopulated dataset of synthetic objects,
    it might also be worth looking at [NVIDIA’s GET3D dataset](https://oreil.ly/VJ5Cu).
    This is a tool that, based on 2D images, constructs high-fidelity 3D shapes with
    textures and geometric details.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在寻找一个更大的预填充的合成对象数据集，也可以考虑查看[NVIDIA的GET3D数据集](https://oreil.ly/VJ5Cu)。这是一个工具，基于2D图像构建具有纹理和几何细节的高保真度3D形状。
- en: Object recognition might seem like a lower-stakes domain for synthetic data,
    but it still comes down to the question of how this model is being used in the
    real world. There’s a difference between deploying a trained model to a robot
    handling durable objects in a closed environment and deploying a trained model
    to an autonomous vehicle navigating a completely open world.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对象识别可能看起来是合成数据领域中风险较低的领域，但这仍然归结为这个模型在现实世界中如何使用的问题。部署训练好的模型来处理封闭环境中的耐用物体和部署训练好的模型来导航完全开放的世界之间存在差异。
- en: Environment Navigation
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 环境导航
- en: Using synthetic data to train agent models how to navigate an environment has
    been standard practice in reinforcement learning for years. Tools like [OpenAI
    Universe](https://oreil.ly/Ixd8x) (deprecated in favor of [OpenAI Retro](https://oreil.ly/LzPjs))
    and [Unity ML Agents](https://oreil.ly/lI2Wn) are staples of RL research.^([14](ch05.html#idm45621833384528))
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，在强化学习中，使用合成数据来训练代理模型如何导航环境已成为标准做法。像[OpenAI Universe](https://oreil.ly/Ixd8x)（已弃用，推荐使用[OpenAI
    Retro](https://oreil.ly/LzPjs)）和[Unity ML Agents](https://oreil.ly/lI2Wn)这样的工具是RL研究的基石。^([14](ch05.html#idm45621833384528))
- en: For simulating more realistic external environments, tools like [AirSim from
    Microsoft](https://oreil.ly/HznJp) offer more help.^([15](ch05.html#idm45621833381840))
    There have also been projects like [Driving in the Matrix](https://oreil.ly/UeFLb)
    that make use of open-world games like *Grand Theft Auto V* to create labeled
    computer vision data that would be relevant for instance segmentation.^([16](ch05.html#idm45621833378768))
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模拟更真实的外部环境，像[Microsoft的AirSim](https://oreil.ly/HznJp)这样的工具提供了更多的帮助。^([15](ch05.html#idm45621833381840))
    还有像[Driving in the Matrix](https://oreil.ly/UeFLb)这样的项目，利用开放世界游戏如*侠盗猎车手V*来创建适用于实例分割的标记计算机视觉数据。^([16](ch05.html#idm45621833378768))
- en: On [Tesla AI Day 2022](https://youtu.be/ODSJsviD_SU), Tesla described how it
    was using a virtual environment containing thousands of virtual cars to train
    its AI. This virtual environment, based on the Unreal engine, includes a virtual
    reconstruction of the streets of San Francisco. Such simulated environments allow
    Tesla engineers to constantly make tweaks to the training environment, randomize
    textures so the agents can recognize objects independently of textures, and even
    add unusual scenarios and circumstances that would be difficult to acquire training
    data for in the real world. Tesla has taken some of these principles from simulated
    driving environments to a massive scale (though the resulting [self-driving AI
    is still not perfect yet](https://oreil.ly/WTTKv)).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在[2022年特斯拉AI日](https://youtu.be/ODSJsviD_SU)上，特斯拉描述了它如何使用包含数千辆虚拟汽车的虚拟环境来训练其AI。这个基于虚幻引擎的虚拟环境包括了旧金山街道的虚拟重建。这种模拟环境使特斯拉工程师可以不断地调整训练环境，随机化纹理，使代理能够独立于纹理识别对象，甚至添加在现实世界中难以获取训练数据的不寻常场景和情况。特斯拉从模拟驾驶环境中采纳了一些原则，将其扩展到了一个大规模（尽管最终的[自动驾驶AI还不完美](https://oreil.ly/WTTKv)）。
- en: Perhaps one of the more promising developments in synthetic environments is
    environments that can be navigated by both humans and ML agents for the sake of
    comparison between the two. Created in Godot, [Generally Intelligent’s Avalon](https://oreil.ly/I4TzF)is
    one such environment. It can be navigated by reinforcement learning agents and
    by humans with VR headsets.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在合成环境中更具前景的发展之一可能是可以由人类和ML代理导航的环境，以便比较两者之间的差异。由Godot创建的[Generally Intelligent的Avalon](https://oreil.ly/I4TzF)就是这样的一个环境。它可以被强化学习代理和戴着VR头显的人类导航。
- en: Unity and Unreal Environments
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Unity和Unreal环境
- en: The tools discussed so far relate to readily available synthetic data tool kits.
    However, you may want to consider creating synthetic data unique to your own task.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止讨论的工具与现有的合成数据工具包相关。但是，您可能希望考虑创建与您自己任务相关的合成数据。
- en: Unity has been discussed in previous subsections. It is a cross-platform game
    engine for 2D and 3D experiences, made famous for smoothing out some of the more
    challenging aspects of game development. It was created in Copenhagen, Denmark,
    and released in 2005. Today it’s used in many popular games including the 2D *Among
    Us*, the 3D *Monument Valley*, augmented reality games like *Pokémon Go*, third-person
    shooters like *Escape from Tarkov*, and interactive simulations beyond the gaming
    industry. The engine itself is written in C++, but it allows developers to write
    code in C#. It also provides a graphical editor that you can use in lieu of writing
    code. Every object in a Unity environment can have a bunch of components such
    as a mesh (defining the shape of the object) and a mesh renderer (defining textures
    and how the lighting hits the object). There are also physics components such
    as rigid body dynamics and collisions to simulate how the object behaves in the
    real world. Game developers add more behaviors on top of these, such as an object
    losing hit points whenever it’s hit. If you’re interested in creating simulated
    training data for vision, the meshes, mesh renderers, and physics components will
    be the most valuable tools.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Unity已经在前面的小节中讨论过。它是一个跨平台的2D和3D游戏引擎，因其优化游戏开发中一些更具挑战性的方面而闻名。它于2005年在丹麦的哥本哈根创建并发布。如今，它被广泛应用于许多热门游戏，包括2D游戏*Among
    Us*，3D游戏*Monument Valley*，像*Pokémon Go*这样的增强现实游戏，以及像*Escape from Tarkov*这样的第三人称射击游戏，以及超越游戏行业的交互式模拟。该引擎本身用C++编写，但允许开发者使用C#编写代码。它还提供了一个图形化编辑器，您可以在其中进行编程而无需编写代码。在Unity环境中的每个对象都可以具有许多组件，例如网格（定义对象的形状）和网格渲染器（定义纹理及光照如何作用于对象）。还有物理组件，如刚体动力学和碰撞，以模拟对象在现实世界中的行为。游戏开发者在此基础上添加更多行为，例如每次被击中时对象失去生命值。如果您对创建视觉模拟训练数据感兴趣，网格、网格渲染器和物理组件将是最有价值的工具。
- en: As mentioned previously, Unity has tools for simulating data and environments
    such as [Unity ML Agents](https://oreil.ly/bKq7Q) and [PeopleSansPeople](https://oreil.ly/mBRxu).
    However, you don’t need to rely on these ML-specific tools; you can also generate
    synthetic computer vision data using scenes created with Unity Assets.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Unity具有用于模拟数据和环境的工具，例如[Unity ML Agents](https://oreil.ly/bKq7Q)和[PeopleSansPeople](https://oreil.ly/mBRxu)。但您不必依赖于这些专门的ML工具；您也可以使用用Unity资产创建的场景来生成合成计算机视觉数据。
- en: Unreal Engine is a close competitor of Unity when it comes to simulating realistic
    environments. MetaAI developed [UETorch](https://oreil.ly/USfzm), an [Unreal Engine
    4](https://oreil.ly/BYX1q) plug-in that adds support for embedded [Lua/Torch](http://torch.ch)
    scripts in the game engine loop and a set of Lua APIs for providing user input
    and taking screenshots and segmentation masks. While usable, UETorch has been
    archived for several years and is no longer maintained. For a more up-to-date
    tool kit, [UnrealCV](https://oreil.ly/Hb5eo) is another repo for generating synthetic
    scenes and images from Unreal Engine.^([17](ch05.html#idm45621833350640))
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Unreal Engine是Unity在模拟逼真环境方面的直接竞争对手。MetaAI开发了[UETorch](https://oreil.ly/USfzm)，这是一个[Unreal
    Engine 4](https://oreil.ly/BYX1q)插件，为游戏引擎循环中添加了嵌入式[Lua/Torch](http://torch.ch)脚本支持，并提供了一组Lua
    API，用于提供用户输入以及拍摄和分割蒙版。虽然可用，但UETorch已经存档多年且不再维护。对于更新的工具包，[UnrealCV](https://oreil.ly/Hb5eo)是另一个库，用于从Unreal
    Engine生成合成场景和图像。^([17](ch05.html#idm45621833350640))
- en: Limitations of Synthetic Data in Healthcare
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合成数据在医疗保健中的限制
- en: 'There are a variety of projects working on synthetic healthcare data. One of
    these is [DeepSynthBody](https://oreil.ly/y5RFK).^([18](ch05.html#idm45621833341888))
    DeepSynthBody is a collection of generative models (both conditional and unconditional)
    for producing realistic-looking healthcare data. The generative models fall into
    11 categories: cardiovascular, digestive, endocrine, integumentary, lymphatic,
    muscular, nervous, urinary, reproductive, respiratory, and skeletal.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多项目正在处理合成医疗保健数据。其中之一是[DeepSynthBody](https://oreil.ly/y5RFK)。^([18](ch05.html#idm45621833341888))
    DeepSynthBody是一组生成模型（条件和非条件的），用于生成看起来逼真的医疗保健数据。生成模型分为11类：心血管、消化系统、内分泌、皮肤、淋巴、肌肉、神经、泌尿、生殖、呼吸和骨骼。
- en: Synthetic data is generally easiest to correctly produce when it is easy for
    humans to have an intuition of the feature distribution. For data types like histology
    or cell biology, where human intuition is limited even in the best of times, this
    becomes much riskier and more challenging.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当人类在特征分布上的直觉受限时，合成数据通常最容易正确生成。对于组织学或细胞生物学等数据类型，在最佳情况下，即使对于人类的直觉来说，这也变得更加冒险和具有挑战性。
- en: '[PRE1]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The generator functions can generate DeepFake ECGs with 8-lead values (lead
    names from first column to eighth column: *I*,*II*,*V1*,*V2*,*V3*,*V4*,*V5*,*V6*)
    for 10 seconds (5,000 values per lead). This 8-leads format can be converted to
    a 12-leads format using the following equations:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 生成函数可以生成具有8个导联值的DeepFake心电图，每个导联的名称从第一列到第八列依次为*I*, *II*, *V1*, *V2*, *V3*, *V4*,
    *V5*, *V6*，持续10秒钟（每个导联5000个值）。这种8导联格式可以使用以下方程转换为12导联格式：
- en: <math><mrow><mtext>lead</mtext> <mtext>III</mtext> <mtext>value</mtext> <mo>=</mo>
    <mo>(</mo> <mtext>lead</mtext> <mtext>II</mtext> <mtext>value</mtext> <mo>)</mo>
    <mo>-</mo> <mo>(</mo> <mtext>lead</mtext> <mtext>I</mtext> <mtext>value</mtext>
    <mo>)</mo></mrow></math> <math><mrow><mtext>lead</mtext> <mtext>aVR</mtext> <mtext>value</mtext>
    <mo>=</mo> <mo>-</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>*</mo> <mo>(</mo> <mtext>lead</mtext>
    <mtext>I</mtext> <mtext>value</mtext> <mo>+</mo> <mtext>lead</mtext> <mtext>II</mtext>
    <mtext>value</mtext> <mo>)</mo></mrow></math> <math><mrow><mtext>lead</mtext>
    <mtext>aVL</mtext> <mtext>value</mtext> <mo>=</mo> <mtext>lead</mtext> <mtext>I</mtext>
    <mtext>value</mtext> <mo>-</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>*</mo> <mtext>lead</mtext>
    <mtext>II</mtext> <mtext>value</mtext></mrow></math> <math><mrow><mtext>lead</mtext>
    <mtext>aVF</mtext> <mtext>value</mtext> <mo>=</mo> <mtext>lead</mtext> <mtext>II</mtext>
    <mtext>value</mtext> <mo>-</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>*</mo> <mtext>lead</mtext>
    <mtext>I</mtext> <mtext>value</mtext></mrow></math>
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mtext>Ⅲ导联</mtext> <mtext>数值</mtext> <mo>=</mo> <mo>(</mo> <mtext>Ⅱ导联</mtext>
    <mtext>数值</mtext> <mo>)</mo> <mo>-</mo> <mo>(</mo> <mtext>Ⅰ导联</mtext> <mtext>数值</mtext>
    <mo>)</mo></mrow></math> <math><mrow><mtext>导联</mtext> <mtext>aVR</mtext> <mtext>数值</mtext>
    <mo>=</mo> <mo>-</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>*</mo> <mo>(</mo> <mtext>Ⅰ导联</mtext>
    <mtext>数值</mtext> <mo>+</mo> <mtext>Ⅱ导联</mtext> <mtext>数值</mtext> <mo>)</mo></mrow></math>
    <math><mrow><mtext>导联</mtext> <mtext>aVL</mtext> <mtext>数值</mtext> <mo>=</mo>
    <mtext>Ⅰ导联</mtext> <mtext>数值</mtext> <mo>-</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn>
    <mo>*</mo> <mtext>Ⅱ导联</mtext> <mtext>数值</mtext></mrow></math> <math><mrow><mtext>导联</mtext>
    <mtext>aVF</mtext> <mtext>数值</mtext> <mo>=</mo> <mtext>Ⅱ导联</mtext> <mtext>数值</mtext>
    <mo>-</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>*</mo> <mtext>Ⅰ导联</mtext> <mtext>数值</mtext></mrow></math>
- en: Beyond DeepSynthBody, there’s also the [Simulacrum](https://oreil.ly/M4XQ7)
    and [SHARED](https://oreil.ly/1oBU4) projects.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 除了DeepSynthBody外，还有[模拟](https://oreil.ly/M4XQ7)和[SHARED](https://oreil.ly/1oBU4)项目。
- en: One of the problems with healthcare data is that, while it’s relatively easy
    to produce data on healthy patients that doesn’t identify anyone, this is much
    harder to do for data representing actual pathologies. The distinguishing part
    of many healthcare datasets is their outliers (the sick people whose health data
    deviates from a healthy baseline), and as such many [doubt the usefulness of the
    approach as a privacy solution](https://arxiv.org/abs/2011.07018) (see [Chapter 1](ch01.html#chapter1)
    on k-anonymity).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗数据的一个问题在于，虽然相对容易生成不会识别任何人的健康患者数据，但对实际病理数据进行这样的处理要困难得多。许多医疗数据集的区分特点在于其异常值（健康基准之外的患病者），因此很多人[怀疑这种方法作为隐私解决方案的实用性](https://arxiv.org/abs/2011.07018)（参见[第1章](ch01.html#chapter1)关于k-匿名性）。
- en: Still, synthetic data has its merits simply because real-world healthcare data
    is too messy to be usable in many cases. Because many healthcare systems are designed
    around billing, decisions are made by hospital and insurance executives who are
    generally not technical experts. And there hasn’t been much incentive to clean
    up the system or work on a well-structured open protocol for interop the same
    way there is in domains like banking.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 人造数据有其优点，因为真实世界的医疗数据在很多情况下太混乱，无法使用。因为许多医疗系统是围绕账单设计的，决策由医院和保险公司的高管做出，他们通常不是技术专家。目前还没有太多的动力来清理系统或者像银行等领域那样制定良好结构化的开放协议进行互操作。
- en: Additionally, doctors and nurses are usually not concerned with programmatic
    recording of data, nor are they usually trained to be able to do that. They’re
    typically only thinking about recording the data for reading by another human.^([19](ch05.html#idm45621833184416))
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，医生和护士通常不关心数据的程序记录，他们通常也没有接受过这方面的培训。他们通常只考虑将数据记录下来，以便其他人类阅读。^([19](ch05.html#idm45621833184416))
- en: Limitations of Synthetic Data in NLP
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自然语言处理中合成数据的局限性
- en: Most of the examples so far have been related to image processing. Given the
    existence of large language models like GPT-3, it should be possible to generate
    synthetic data for sequential or text-based tasks.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，大多数示例都与图像处理有关。鉴于像 GPT-3 这样的大型语言模型的存在，应该可以为顺序或基于文本的任务生成合成数据。
- en: This, unfortunately, runs into the same problem as using GANs for synthetic
    data. If you have enough data to create a well-trained language generative model,
    then you probably don’t need the generative model itself to solve your data issue.
    If you use an off-the-shelf language model from an organization like [OpenAI](https://openai.com/api),
    [Cohere](https://cohere.ai), [Copy.ai](https://www.copy.ai), [ElutherAI](https://www.eleuther.ai),
    or [GooseAI](https://goose.ai), you need to be extremely diligent about checking
    for mistakes, biases, and other issues that wouldn’t be present in real-world
    data. If you’re using one of the non–open sourced language models that require
    paying to use an API, then trying to create a decent synthetic dataset might be
    more costly than just ethically sourcing real data.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这与使用 GAN 生成合成数据面临相同的问题。如果你有足够的数据来创建一个训练良好的语言生成模型，那么你可能根本不需要这个生成模型来解决你的数据问题。如果你使用像
    [OpenAI](https://openai.com/api), [Cohere](https://cohere.ai), [Copy.ai](https://www.copy.ai),
    [ElutherAI](https://www.eleuther.ai), 或 [GooseAI](https://goose.ai) 这样的组织提供的非开源语言模型来生成合成数据，你需要极度谨慎地检查错误、偏见和其他在真实数据中不存在的问题。如果你使用需要付费的
    API 的非开源语言模型，那么尝试创建一个体面的合成数据集可能比仅仅从伦理角度获取真实数据更加昂贵。
- en: Self-Supervised Learned Models Versus Giant Natural Datasets
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自监督学习模型与巨大的自然数据集之间的比较
- en: 'If you’re not in a position to make use of large synthetic datasets, but you’re
    also struggling with procuring enough labeled real-world data, there’s another
    avenue worth considering: self-supervised learned models.^([20](ch05.html#idm45621833169664))'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你无法使用大型合成数据集，但又苦于获取足够标记的真实世界数据，还有另一条值得考虑的途径：自监督学习的模型。^([20](ch05.html#idm45621833169664))
- en: Self-supervised learning works by trying to predict an unobserved or hidden
    part of the input. For example, in NLP, the words of a line are predicted using
    the remaining words in the sentence. It’s much easier to scale than supervised
    learning. It can automatically generate labels for training, and many self-supervised
    learning systems can be used in more contexts than they were trained in. The only
    downside is that self-supervised learning typically works best in cases where
    the underlying data is discrete (e.g., Google’s BERT predicting the integer tokens
    in text), but performs comparatively poorly on continuous data.^([21](ch05.html#idm45621833166912))
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习的工作原理是试图预测输入中未观察到或隐藏的部分。例如，在自然语言处理中，一行的单词可以使用句子中剩余的单词来预测。它比监督学习更容易扩展。它可以自动生成训练标签，而且许多自监督学习系统可以在比它们训练的更多上下文中使用。唯一的缺点是，自监督学习通常在基础数据为离散的情况下效果最佳（例如，Google
    的 BERT 预测文本中的整数标记），但在连续数据上表现相对较差。^([21](ch05.html#idm45621833166912))
- en: Note
  id: totrans-150
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Confusingly, the acronym SSL is used to refer to both self-supervised learning
    and semi-supervised learning. Semi-supervised learning is a technique in which
    you use a trained model to label new data, and then continue training on that
    new data.^([22](ch05.html#idm45621833164624)) While it can be a useful technique,
    it’s not the exact same as self-supervised learning. With both techniques, one
    should take care to stick to best practices.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆不已，SSL 这个首字母缩写同时用来指代自监督学习和半监督学习。半监督学习是一种技术，你可以使用训练好的模型来标记新数据，然后继续在这些新数据上训练。^([22](ch05.html#idm45621833164624))
    虽然这可以是一种有用的技术，但它与自监督学习并不完全相同。在使用这两种技术时，应注意遵循最佳实践。
- en: Repurposing Quality Control Metrics for Security Purposes
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将质量控制度量重新用于安全目的
- en: One of the main downsides of synthetic data is that not everyone is using it
    just to reduce their company’s training data budget. Deepfakes have been talked
    about as hypotheticals for a while now, but as this chapter has hopefully convinced
    you, deepfakes are already here. This is an enormous problem for the know-your-customer
    (KYC) industry. The silver lining is that many of the tools for testing the robustness
    of synthetic and adversarial data (discussed in this chapter and [Chapter 4](ch04.html#chapter4))
    can work on deepfakes. For a breakdown of synthetic data generation tools, see
    the [Appendix A](app01.html#appx).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据的主要缺点之一是，并非所有人都只是为了减少公司的训练数据预算而使用它。深度伪造技术长期以来一直被视为假设，但正如本章希望说服您的那样，深度伪造技术已经存在。这对了解您的客户（KYC）行业是一个巨大的问题。好消息是，许多用于测试合成和对抗数据鲁棒性的工具（本章和[第4章](ch04.html#chapter4)讨论过）也适用于深度伪造技术。关于合成数据生成工具的详细介绍，请参阅[附录A](app01.html#appx)。
- en: Conclusion
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: When it comes to acquiring data, whether it be real-world or synthetic, this
    is one of the crucial steps in making your ML pipeline trustworthy according to
    all the various standards described in the book so far. Acquiring real-world data
    that helps your model produce the outputs you want it to is full of hazards, but
    there are plenty of tools to make it easier if you know what to look for. Data-driven
    synthetic data might seem like a solution to some of the problems described with
    real-world data (e.g., privacy, availability, etc.), but it is not a panacea.
    Some of the problems with synthetic data can be fixed with a process-driven approach,
    but process-driven synthetic data is only as good as the assumptions you hard-code
    into your data generator. At the end of the day, your ability to get adequate
    training data will be determined by how well you can measure the distribution
    of features and labels, control for quality, and constantly double-check and triple-check
    your assumptions behind the domain.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到获取数据时，无论是真实世界的还是合成的，这是使您的ML流水线符合到目前为止书中描述的各种标准的关键步骤之一。获取有助于您的模型产生您希望的输出的真实世界数据充满了危险，但是如果您知道要寻找什么，有很多工具可以使其变得更容易。数据驱动的合成数据可能看起来是解决某些与真实世界数据相关的问题（例如隐私、可用性等）的解决方案，但它并非灵丹妙药。一些关于合成数据的问题可以通过过程驱动方法来解决，但是过程驱动的合成数据的质量取决于您在数据生成器中硬编码的假设的好坏。归根结底，您能否获得足够的训练数据将取决于您有多么好地能够衡量特征和标签的分布，控制质量，并始终再三检查您在该领域的假设。
- en: ^([1](ch05.html#idm45621834000368-marker)) Jared Kaplan et al., [“Scaling Laws
    for Neural Language Models”](https://arxiv.org/abs/2001.08361), *arXiv preprint*
    (2020).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch05.html#idm45621834000368-marker)) Jared Kaplan 等人，《神经语言模型的缩放法则》，*arXiv预印本*（2020年）。
- en: ^([2](ch05.html#idm45621833998336-marker)) Jordan Hoffmann et al., [An Empirical
    Analysis of Compute-Optimal Large Language Model Training](https://oreil.ly/QsoDW),
    *arXiv preprint* (2022).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch05.html#idm45621833998336-marker)) Jordan Hoffmann 等人，《大规模语言模型训练的计算优化实证分析》（2022年），[arXiv预印本](https://oreil.ly/QsoDW)。
- en: ^([3](ch05.html#idm45621833995200-marker)) Even with few-shot learning image
    and language models, figuring out the *best* few examples is difficult.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch05.html#idm45621833995200-marker)) 即使是少样本学习的图像和语言模型，找出*最佳*的几个示例也是困难的。
- en: ^([4](ch05.html#idm45621833967616-marker)) [“AI Company Exposed 2.5 Million
    Patient Records Over the Internet”](https://oreil.ly/V-GJu), *HIPAA Journal*,
    August 21, 2020.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch05.html#idm45621833967616-marker)) [“AI公司通过互联网泄露了250万患者记录”](https://oreil.ly/V-GJu)，*HIPAA
    Journal*，2020年8月21日。
- en: ^([5](ch05.html#idm45621833814912-marker)) [DALL·E mini stripped](https://oreil.ly/THa3U)
    to the bare essentials necessary for doing inference on a local machine.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch05.html#idm45621833814912-marker)) [DALL·E mini裸版](https://oreil.ly/THa3U)，仅包含在本地机器上执行推理所需的基本要素。
- en: ^([6](ch05.html#idm45621833808128-marker)) Sites like [Retraction Watch](https://retractionwatch.com)
    already keep track of papers that have been retracted for using fake data produced
    with generative models. Generative models may show up more often on such sites.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch05.html#idm45621833808128-marker)) 像[撤稿观察](https://retractionwatch.com)这样的网站已经在跟踪使用生成模型产生的假数据而撤销的论文。生成模型可能会更频繁地出现在这类网站上。
- en: ^([7](ch05.html#idm45621833777040-marker)) Chris Olah et al., [“Feature Visualization”](https://oreil.ly/0i6Ip),
    *Distill* (November 7, 2017).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch05.html#idm45621833777040-marker)) Chris Olah 等人，《特征可视化》，*Distill*（2017年11月7日）。
- en: ^([8](ch05.html#idm45621833772464-marker)) Connor Anderson and Ryan Farrell,
    [“Improving Fractal Pre-Training”](https://oreil.ly/7sNnO), *Proceedings of the
    IEEE/CVF Winter Conference on Applications of Computer Vision* (2022).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch05.html#idm45621833772464-marker)) Connor Anderson 和 Ryan Farrell，[“改进分形预训练”](https://oreil.ly/7sNnO)，*IEEE/CVF冬季计算机视觉应用会议论文集*
    (2022).
- en: ^([9](ch05.html#idm45621833770640-marker)) Hirokatsu Kataoka et al., [“Pre-Training
    Without Natural Images”](https://oreil.ly/rb9L1), *ACCV 2020* (2020).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch05.html#idm45621833770640-marker)) Hirokatsu Kataoka 等人，[“无自然图像的预训练”](https://oreil.ly/rb9L1)，*ACCV
    2020* (2020).
- en: '^([10](ch05.html#idm45621833745440-marker)) Erroll Wood et al., [“Fake It Till
    You Make It: Face Analysis in the Wild Using Synthetic Data Alone”](https://oreil.ly/8wxyh),
    *Proceedings of the IEEE/CVF International Conference on Computer Vision* (2021):
    3681–91.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '^([10](ch05.html#idm45621833745440-marker)) Erroll Wood 等人，[“虚假而为之：仅使用合成数据在野外进行面部分析”](https://oreil.ly/8wxyh)，*IEEE/CVF国际计算机视觉会议论文集*
    (2021): 3681–91。'
- en: '^([11](ch05.html#idm45621833737264-marker)) Salehe Erfanian Ebadi et al., [“PEOPLESANSPEOPLE:
    A Synthetic Data Generator for Human-Centric Computer Vision](https://arxiv.org/abs/2112.09290)“,
    *arXiv preprint* (2021).'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '^([11](ch05.html#idm45621833737264-marker)) Salehe Erfanian Ebadi 等人，[“PEOPLESANSPEOPLE:
    人类中心计算机视觉的合成数据生成器”](https://arxiv.org/abs/2112.09290)，*arXiv预印本* (2021).'
- en: ^([12](ch05.html#idm45621833710944-marker)) Erroll Wood et al., [“3D Face Reconstruction
    with Dense Landmarks”](https://oreil.ly/aa7nI), *Microsoft*, 2022.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch05.html#idm45621833710944-marker)) Erroll Wood 等人，[“带有密集标记的3D面部重建”](https://oreil.ly/aa7nI)，*Microsoft*，2022年.
- en: '^([13](ch05.html#idm45621833707984-marker)) Klaus Greff et al., [“Kubric: A
    Scalable Dataset Generator”](https://arxiv.org/abs/2203.03570), *Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (2022): 3749–61.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '^([13](ch05.html#idm45621833707984-marker)) Klaus Greff 等人，[“Kubric: A Scalable
    Dataset Generator”](https://arxiv.org/abs/2203.03570)，*IEEE/CVF计算机视觉与模式识别会议论文集*
    (2022): 3749–61.'
- en: '^([14](ch05.html#idm45621833384528-marker)) Arthur Juliani et al., [“Unity:
    A General Platform for Intelligent Agents”](https://arxiv.org/abs/1809.02627),
    *arXiv preprint* (2018).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch05.html#idm45621833384528-marker)) Arthur Juliani 等人，[“Unity：智能代理的通用平台”](https://arxiv.org/abs/1809.02627)，*arXiv预印本*
    (2018).
- en: '^([15](ch05.html#idm45621833381840-marker)) Shital Shah et al., [“AirSim: High-Fidelity
    Visual and Physical Simulation for Autonomous Vehicles”](https://arxiv.org/abs/1705.05065),
    *Field and Service Robotics Conference 2017 (FSR 2017)* (2017).'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch05.html#idm45621833381840-marker)) Shital Shah 等人，[“AirSim：用于自动驾驶车辆的高保真视觉和物理仿真”](https://arxiv.org/abs/1705.05065)，*Field
    and Service Robotics Conference 2017 (FSR 2017)* (2017).
- en: '^([16](ch05.html#idm45621833378768-marker)) Matthew Johnson-Roberson et al.,
    [“Driving in the Matrix: Can Virtual Worlds Replace Human-Generated Annotations
    for Real World Tasks?”](https://arxiv.org/abs/1610.01983), *International Conference
    on Robotics and Automation* (2017).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch05.html#idm45621833378768-marker)) Matthew Johnson-Roberson 等人，[“驾驶在矩阵中：虚拟世界能否替代真实世界任务的人工生成注释？”](https://arxiv.org/abs/1610.01983)，*国际机器人与自动化会议*
    (2017).
- en: '^([17](ch05.html#idm45621833350640-marker)) Weichao Qiu et al., [“UnrealCV:
    Virtual Worlds for Computer Vision”](https://dl.acm.org/doi/abs/10.1145/3123266.3129396),
    *ACM Multimedia Open Source Software Competition*, 2017.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch05.html#idm45621833350640-marker)) Weichao Qiu 等人，[“UnrealCV：计算机视觉的虚拟世界”](https://dl.acm.org/doi/abs/10.1145/3123266.3129396)，*ACM多媒体开源软件竞赛*，2017年.
- en: '^([18](ch05.html#idm45621833341888-marker)) Vajira Thambawita et al., [“DeepSynthBody:
    the Beginning of the End for Data Deficiency in Medicine”](https://oreil.ly/Bq5dW),
    *IEEE* (2021).'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch05.html#idm45621833341888-marker)) Vajira Thambawita 等人，[“DeepSynthBody：医学数据不足的终结开始”](https://oreil.ly/Bq5dW)，*IEEE*
    (2021).
- en: ^([19](ch05.html#idm45621833184416-marker)) Brian Kihoon Lee, [“Deep Learning
    on Electronic Medical Records Is Doomed to Fail”](https://oreil.ly/P9pbj), *moderndescartes.com*
    (blog), March 22, 2022.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch05.html#idm45621833184416-marker)) Brian Kihoon Lee，[“电子医疗记录上的深度学习注定失败”](https://oreil.ly/P9pbj)，*moderndescartes.com*
    (博客)，2022年3月22日.
- en: '^([20](ch05.html#idm45621833169664-marker)) Yuki M. Asano et al., [“PASS: An
    ImageNet Replacement for Self-Supervised Pre-Training Without Humans”](https://arxiv.org/abs/2109.13228),
    *arXiv preprint* (2021).'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '^([20](ch05.html#idm45621833169664-marker)) Yuki M. Asano 等人，[“PASS: 一种用于自监督预训练的ImageNet替代品，无需人类参与”](https://arxiv.org/abs/2109.13228)，*arXiv预印本*
    (2021).'
- en: ^([21](ch05.html#idm45621833166912-marker)) If you want to learn more, visit
    [GitHub](https://oreil.ly/mcteu) for a list of papers on self-supervised learning.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch05.html#idm45621833166912-marker)) 如果您想了解更多信息，请访问[GitHub](https://oreil.ly/mcteu)查看关于自监督学习的论文列表。
- en: ^([22](ch05.html#idm45621833164624-marker)) See Lilian Weng’s blog post [“Learning
    with not Enough Data Part 1”](https://oreil.ly/iN33C) for a great summary of how
    semi-supervised learning works.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch05.html#idm45621833164624-marker)) 查看 Lilian Weng 的博客文章 [“用不足的数据学习
    第一部分”](https://oreil.ly/iN33C)，了解半监督学习的精彩总结。
