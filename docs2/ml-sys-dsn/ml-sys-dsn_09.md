# 8 基准解决方案

### 本章涵盖

+   什么是基准？

+   恒定基准

+   模型基准和特征基准

+   各种深度学习基准

+   基准比较

> 一切都应该尽可能简单，但不能过于简单。—— 阿尔伯特·爱因斯坦

当我们开始思考我们未来机器学习（ML）系统的构建块时，它的核心部分，或者说核心组件，似乎是一个使用机器学习技术构建的模型。在某种程度上，这是如此真实，以至于我们甚至可能会认为：“这就是它：这是我应该花费大部分时间、精力和创造力的主要点。”

但在现实中，这可能会变成大多数机器学习项目陷入的陷阱，它们在从未达到生产阶段的情况下陷入困境。在机器学习系统的背景下，机器学习模型并不一定是最重要的东西，以及其设计文档。尽管诱惑很大，但你应该始终记住，花费大量时间、团队努力，更重要的是，金钱来构建一个酷、现代且复杂的 AI 模型，而这个模型却从未为用户和你的公司带来任何价值。在生产中的平庸模型通常比纸上的优秀模型要好。

这本书最初的一个版本标题是《有效的机器学习系统设计》，这与任何机器学习项目的首要目标相对应，即构建一个能够工作的系统；只有当它带来利润时，我们才会开始迭代改进它，逐渐增加其复杂性（如果需要）。在本章中，我们将讨论基准解决方案，这是使我们的系统生命化的第一步。我们将讨论为什么需要基准，以及构建它们的目的。我们将从恒定基准到复杂的专用模型，以及各种特征基准进行探讨。

## 8.1 基准：你是谁？

基准是系统中最简单（但可行！）的模型、特征集或其他任何东西的版本。在机器学习系统世界中，它是最小可行产品（MVP），从一开始就带来价值，而尚未深入复杂性。让我们通过概述可能同样适用于两者的关键目标来进一步阐述 MVP 类比：

+   *以最低的时间、成本和努力投入，降低产品的最大风险*。在产品的生命初期，市场是否需要它，产品将有哪些用例，经济是否会收敛等等，这些都还不清楚。在很大程度上，这些风险也特属于机器学习产品。从某种意义上说，基准（或 MVP）是测试产品核心假设的最简单方法。

+   *获取早期反馈*。这是将快速失败原则缩小到产品规模。如果你的机器学习系统的整个想法是错误的，你可以在早期阶段看到，重新思考整个计划，用新的知识重新编写设计文档，并重新开始。

+   *尽快带来用户价值*。每个公司都希望通过让客户满意来创造收入。如果我们可以通过基线尽早为顾客带来价值，然后在逐步生成可预测收入的同时更新它，为什么不这样做呢？这将使方程中的每个人都很满意。

这三个点构成了基线和 MVP 之间相似性的基础。然而，还有三个纯粹是基线特定的目标：

+   *一个检查组件是否正常工作的占位符*——基线就像烟雾测试。正如 Cem Kaner、James Bach 和 Brett Pettichord 在他们的《软件测试经验教训》一书中所说，“烟雾测试”这个短语来自电子硬件测试。你插入一块新板并打开电源。如果你看到板子上冒烟，就关掉电源。你不需要做更多的测试。

    首先，你需要检查系统是否工作，其次，它是否正确工作。要“编译”整个系统，你不需要一个强大的机器学习模型。你需要的是能够以所需格式预测某些东西的东西，可选地，基于某些东西。为什么不选择最简单可能的替代方案呢？

+   *一个用于比较的东西*——我们是否可以进一步思考我们对模型的投资在未来能带来多少回报？基线是一个“基线”。它是坐标平面的起点——我们在某些指标上将其与新模型进行比较。

    在工业界工作的时候，模型的性能并不是我们比较模型的唯一指标。其他方面还需要努力、可解释性、可维护性等等。我们将在第 8.5 节中讨论它们。

+   *一个回退答案*——与 MVP 不同，当我们继续进行其第二版和后续版本时，我们不会完全丢弃基线。当它与复杂的模型并行存在时，这是一种良好的实践。当这个主要模型在预测时出现问题时，系统会切换到基线响应。

那么，一个精心选择的基线有什么优势呢？简单性自动带来很多优点：它稳健，不易出现意外行为和过拟合（由于自由度较少），易于构建和维护，对计算资源的需求不是太高。因此，基线易于扩展。作为额外的奖励，从非机器学习同事的角度来看，简单的模型更容易解释，并使理解底层发生的事情变得更加容易。这有助于增加对我们机器学习产品的信任，这在风险很高时可能是关键的。然而，简单性本身并不是目标，而是一个有价值的属性。

如果我们将我们的机器学习系统比作乐高模型，基线就是一个尽可能快地组装其他所有模块的机会。尽管如此，我们仍然鼓励您通过设计使您的系统尽可能模块化（即，“正交”）。这将使后续的更新更加容易，包括过渡到更复杂的模型和功能（初始设计并不决定您未来更新系统速度的快慢）。初始系统应该是简单且灵活的，而不是微不足道的或受限的，并包含基线。

尽管基线提供了许多优势，而且不需要太多，但它们的使用频率并没有像应有的那样高。不幸的真相是，复杂性更受欢迎。Eugene Yan 有一篇出色的文章，我们强烈推荐阅读。它叫做“简单是一种优势，但遗憾的是复杂性更受欢迎”([`eugeneyan.com/writing/simplicity/`](https://eugeneyan.com/writing/simplicity/))，强调了很多人选择复杂性而不是简单的主要原因，包括：

+   复杂性表明了努力。

+   复杂性表明了精通。

+   复杂性表明了创新。

+   复杂性表明了更多功能。

这导致了复杂性偏差，我们过度赞扬并偏爱复杂的思想和系统，而不是更简单的解决方案。

当然，基线不是万能的灵丹妙药，在某些情况下，基线可能不是必需的，甚至是不相关的：

+   *准确性至关重要*。在许多情况下，几个百分点的错误甚至不会被注意到。但如果我们无法承受质量的下降——例如，在某些医疗应用中，如癌症检测或处理自动驾驶汽车时——基线将是一个糟糕的救命绳索。在这种情况下，明确切换到手动控制可能是一个更好的主意。

+   *确定性很高*。我们清楚地了解用户的需求（例如，基于竞争对手的经验），或者我们有实施相同系统的自身经验。在这种情况下，如果我们已经有了在实战中证明有效的计划，并且可以简单地复制粘贴系统，我们就不需要重新发明轮子，也不需要在逐步迭代上浪费时间。

+   *我们正在重建一个已经工作的系统*。假设我们已经有了一个基于深度语义相似性模型（DSSM）架构的工作搜索引擎。整个流程已经实现并经过测试。因此，当它持续为用户提供价值时，就是从速度和准确性方面进行优化的时候——例如，通过切换到基于 Transformer 的模型。这不是考虑基线的正确地方，因为旧版本实际上就是一个基线。

然而，我们相信，尽管在某些情况下，早期的高复杂性可以找到合理的理由，但它不能成为默认的解决方案，因为它会激励人们使事情变得不必要地复杂；它鼓励“没有发明在这里”的心态，人们宁愿从头开始构建，即使这样做可以节省时间和精力，也会浪费时间和资源，而且往往会导致较差的结果。

正因如此，我们相信基线解决方案是首先要做的事情，在需要和可能的地方进行逐步改进。

## 8.2 常数基线

基线的良好隐喻是建造一座桥梁：有时你不需要一支桥梁建筑工程师团队、巨大的预算、计划或数年时间去建造它。有时你只需要一个稳定固定的日志。基线就是那个允许你以最小规模连接组件并解决给定任务的日志——在基线的情况下，一个临时、原始、易于构建的解决方案（见图 8.1）。

在详细说明之前，我们想要传达的想法很简单：首先构建一个精简、可操作的机器学习系统，然后再对其进行改进。将可能的解决方案的复杂性视为一个连续体。根据努力-准确性权衡，在这个范围内选择一个合适的初始点，然后继续前进。除非必要，否则不要在建模上花费太多时间。

![figure](img/CH08_F01_Babushkin.png)

##### 图 8.1 在构建复杂模型之前，先从一个原始基线开始，这可能是你未来机器学习系统的最合适的基础。

记住这个类比，让我们从最斯巴达式的解决方案开始讨论，这些解决方案看起来像一根桥梁的木材。当我们开始寻找合适的基线时，我们经常问自己，“最直接解决这个问题的机器学习模型是什么？”或者“从哪里开始选择正确的机器学习模型？”但这些问题往往被证明是错误的。我们认为正确的问题可能是，“我们是否真的需要机器学习来解决这个问题？”

有时候我们甚至不需要机器学习来解决这个问题，或者至少我们不应该自己重新发明轮子，而可以使用第三方供应商。我们已经在第三章（第 3.2 节）讨论了这种替代方案。

但假设我们决定构建自己的模型。良好的建模始于没有任何模型：通过从解决方案空间中选择最简单、最懒惰的解决方案来尝试破解一个定义的指标。这将是我们问题的第一个近似。你可以争论说，一个常数基线本身就代表了一个模型。使用常数基线，我们通过一个常数来近似所有的依赖关系和交互作用。

为了立即给出我们正在谈论的内容，这里有一些你已经知道的例子：

+   对于回归任务，常量基线是最后可用值（例如，对于相应的用户或项目）的平均或中位数预测（在时间序列预测中，你可以取最后一天/周/月/年的值）。此外，这也可以是用户定义的某个常量，该常量最大化了指标。

+   对于分类任务，这将是通过主要类别进行预测（例如，在反欺诈问题中，我们可以假设根本不存在欺诈）或对正类概率的常量预测。

+   对于排序，这可以是文档的随机顺序，或者基于无关的数值属性（如文档 ID）或简单的启发式方法（如“包含在项目描述中的查询关键字数量”）的排序。

在某种程度上，常量基线就像泰勒级数的第一项或梯度提升中的第一个基估计器的均值预测器（见图 8.2）。它们都不依赖于变量 x；它们已经（虽然粗略地）与我们的问题相关——不多，也不少。

![figure](img/CH08_F02_Babushkin.png)

##### 图 8.2 常量基线就像泰勒级数的第一项——这是为更复杂模型奠定基础的简单近似。

### 8.2.1 我们为什么需要常量基线？

建立这样的基线有两个目标。

第一个目标是基准测试。对于随机预测，获取所选指标的一个基线值是有帮助的。一个简单的合理性检查是将你的模型与简单的经验法则进行比较。确实，如果你花了两周时间进行艰苦的机器学习建模，然后最终在 5 分钟内实现了最简单的基线，并且这个基线击败了你的模型，那将是一件令人难过的事情。这听起来很荒谬，但在现实生活中这种情况相当普遍。

关于这个案例，有一个来自 Valerii 的有趣故事。他非常幸运，能够与一位既是一个出色的人也是一个伟大的专家的工程师一起工作。有一次，她通过仅使用常量基线——或者，如她喜欢纠正他的那样，逐步常量——赢得了预测某些工厂时间序列的机器学习竞赛。举办机器学习竞赛通常是一个非常直接的过程。参与者有一个标记的数据集和一个未标记的数据集。他们的目标是使用标记的数据集构建一个模型，该模型将对未标记的数据集进行预测，这些预测与实际值（仅对组织者可用）最接近。现在想象一下其他参与者们的挫败感，他们已经为几个月来工程化了数十个特征，并调整了他们梯度提升模型的参数。

这个案例激发了我们寻找并从最简单的模型开始，这是我们希望鼓励每个人去做的事情。不过，不要局限于它们。这将从一开始就让你对指标和目标值有一个更恰当的理解，这样你就可以对给定数据可以做什么以及不能做什么有一个愿景。

恒定基线的第二个目标是提供一个万无一失的回退方案。如果你的真实机器学习模型在运行时无法进行预测，由于某些错误、遇到响应时间限制、没有历史数据来计算特征（即新用户和新物品的冷启动问题）——或者它简单地变得疯狂（这有时会发生）——你的机器学习服务至少应该返回一些内容。因此，在这种情况下，恒定基线就足够了。

同时，我们可以轻松想象出一些情况，其中恒定基线过于原始，毫无价值。因此，最简单的可用基线应该更复杂，表现为一组启发式规则/正则表达式或浅层模型。恒定基线通常适用于简单的回归/分类问题，尤其是在表格或小型文本数据上；然而，使用恒定基线构建聊天机器人或语音识别系统是不可能的。

## 8.3 模型基线和特征基线

如果我们进一步沿着复杂度尺度前进，我们的下一个停靠点是规则基础模型，尽管在大多数情况下，我们无法在恒定基线和规则基础基线之间划出一条清晰的界限，因为我们可以将后者定义为一组之上的恒定值。但还有一个众所周知且具有说明性的规则基础基线例子：仅使用正则表达式开始解决自然语言处理问题。

几年前，Arseny 在一家出租车聚合公司工作，他参与开发了一个预测最近车辆到达客户所需时间的服务。问题很明显：如果我们预测过高，客户可能会决定不去等待并寻找其他服务；如果我们预测过低，客户会等待比我们承诺的时间更长，这意味着我们让他们失望。

Arseny 的同事，当时是一名高级工程师，将其视为一个标准的回归任务，并从像“总是预测 5 分钟”或“如果区域等于‘曼哈顿’：返回 4”这样的模型开始。简而言之：这些类型的基线很难被硬核机器学习魔法打败，而且讽刺的是，后者甚至作为回退方案在一段时间内投入了生产。

“如果区域等于 X 则返回 Y”模型是规则基础基线的优秀例子。我们可以通过取某些类别或几个类别的平均值/中位数/众数来生成类似的模型——在我们的例子中，通过位置取中位数。

随着我们沿着进步的方向前进，我们的模型变得更加复杂，并且能够找到更多对象属性与标签之间的联系。

在一个机器学习问题中，典型的基线序列可能开始于以下内容：恒定基线、规则基础基线和线性模型（见图 8.3）。只有当这些基线不足以满足我们的任务时，我们才需要更复杂和专业的解决方案。

![figure](img/CH08_F03_Babushkin.png)

##### 图 8.3 设计模型早期阶段的典型基线序列

例如，在构建推荐系统时，我们从一个恒定的检索开始，然后尝试协同过滤（例如交替最小二乘法），因子分解机，如果需要的话，最后是深度学习（例如深度结构化语义模型）。

无论你面临什么问题，都要注意这个领域的简单方法。它们不一定比更复杂的方法表现差。

一个生动的例子可以在 Maurizio Ferrari Dacrema 等人撰写的论文“Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches”中找到，这篇论文获得了 2019 年 RecSys 最佳论文奖([`arxiv.org/abs/1907.06902`](https://arxiv.org/abs/1907.06902))。该论文因其揭示的令人印象深刻的数据而备受瞩目。研究小组检查了在过去几年顶级研究会议上展示的 18 个算法。在研究了这些算法之后，只有七个算法在合理的努力下可以重现。当发现其中七个算法中的六个通常可以使用相对简单的启发式方法（例如基于最近邻或图技术的方法）来超越时，事情变得更加有趣。唯一剩下的算法明显优于基线；然而，它并不能始终超越一个调优良好的非神经网络线性排名方法。

从已经提到的 Eugene Yan 文章中列出的非详尽例子包括以下内容：

+   在大多数情况下，基于树的模型（随机森林、梯度提升）在表格数据上优于深度神经网络，尤其是在小型/中型数据集（例如，小于 100 万）上([`arxiv.org/abs/2207.08815`](https://arxiv.org/abs/2207.08815))。

+   在组合图问题上，贪婪算法优于图神经网络([`arxiv.org/abs/2206.13211`](https://arxiv.org/abs/2206.13211))。

+   在多任务学习问题上，简单的平均通常不比复杂的优化器差([`arxiv.org/abs/2201.04122`](https://arxiv.org/abs/2201.04122))。

+   嵌入的乘积在项目推荐和检索中优于神经网络协同过滤([`arxiv.org/abs/2005.09683`](https://arxiv.org/abs/2005.09683))。

到目前为止，我们一直在谈论关注模型的基线。但特征呢？特征实际上是模型的一部分，有时甚至是模型最重要的部分。在经典机器学习中，我们必须手动构建特征，为基线选择特征是基于相同的原则；我们从一小组基本特征（最可能的是那些更容易计算的）开始。有两种方法可以添加新特征：

+   构建新特征，这是一个具有挑战性和耗时的工作，需要构建新的 ETL 管道

+   从已存在的特征派生新特征

我们需要尝试的基线特征序列应如下所示：原始的最小特征集，各种交互和计数器，然后是嵌入，接着是更复杂的东西（见图 8.4）。

![figure](img/CH08_F04_Babushkin.png)

##### 图 8.4 需要尝试的基线特征序列：从最简单到更复杂

从哪里开始的一组好的特征有哪些属性？答案是和模型完全一样，我们将在后面进一步讨论。

对于通常用深度学习方法解决的问题，可以使用简单的基线，通过浅层模型构建。正如我们回忆的那样，深度学习是表示学习的一部分，这意味着我们不是手工制作特征，而是将这项工作委托给神经网络。然而，对于一些像图像或文本分类这样的问题，你可以应用朴素的方法（基于规则或基于线性模型）。例如，在 BERT-like 架构出现之前，朴素贝叶斯在自然语言处理领域是一个非常强大的基线。对于计算机视觉，一些问题可以通过使用像素颜色的直方图（甚至只是均值/中值！）作为线性模型的特征来解决。话虽如此，对于大多数场景，从简单的深度学习模型开始——无论是在少量样本设置中的基础模型还是在训练好的模型——可能是一个更好的选择，因为这些模型已经在各种任务中证明了自己的能力。

阿尔谢尼曾经为候选人设计了一个带回家的练习题，其中他们得到了一个在简单图像数据集上解决异常检测问题的脚本。该脚本包含两个基线——一个使用神经网络，另一个使用颜色直方图——并且候选人被指示改进其中的任何一个以击败某些指标。这两个基线已经在一个相似的水平上表现，并且都实现得特别糟糕，因此候选人有改进的空间。大多数候选人更喜欢工作在更复杂的深度学习解决方案上，而只有其中经验最丰富的候选人注意到，只需对基于直方图的基线进行一行代码的更改，就可以达到所需的结果。

## 8.4 深度学习基线的多样性

当问题不是微不足道的，并且由于数据结构（这可以适用于大多数计算机视觉或语言处理问题）而建议使用深度学习时，基线的多样性略有不同。最常见的是重用预训练模型和训练/微调最简单的模型。

如果问题不是独特的，并且有一个在类似任务上训练过的模型，那么重用预训练模型是一种常见的做法。例如，如果我们想训练一个能够识别宠物品种的模型，我们可以重用在一个 ImageNet 数据集上训练过的模型。ImageNet 是一个包含 1,000 个类别的图像数据集，其中超过 100 个是狗的品种。所以，一旦你的目标是识别猫和狗，你就可以重用 ImageNet 数据集上训练过的模型，而无需重新训练。这对于许多通用问题（如语音识别、目标检测、文本分类、情感分析等）来说是一种常见的做法。

这种方法的稍微高级版本是重用预训练模型中的特征（也称为*嵌入*或*表示*）来训练一个简单的浅层模型。例如，你可以使用在 ImageNet 数据集上训练的预训练模型，并使用其最后骨干层（在最终分类层之前）的表示来训练一个简单的线性模型，该模型将图像分类到自定义的类别集合中。这种方法在数据集较小且最终任务或多或少是平凡的（例如，分类）时特别有用，因此从头开始训练大型模型不太可能奏效。这种方法也被称为迁移学习的一个特例。我们见过一些案例，其中这样的基线实际上是无敌的，而且没有花哨的模型能够超越它。

使用预训练模型的一个更具体的版本是使用能够实现零样本或少量样本性能（意味着它们需要没有或少量训练样本来提供结果）的预训练模型或第三方 API。一个这样的 API 的华丽例子是 GPT 家族，但有许多 API 可用于不同的任务——例如，所有主要云供应商都有一个长长的 AI 解决方案列表，例如计算机视觉领域的 Amazon Rekognition 或 Google Cloud Vision AI；关于它们的详细信息超出了本书的范围。

使用主要供应商的第三方 API 作为基线有一个很好的副作用：它是谈判中的筹码，例如向大型企业销售软件产品或向潜在投资者证明初创科技是可靠的。潜在客户可能不知道给定问题的好指标是什么（回忆第五章），但将你的技术与 AWS 解决方案进行比较，可以恰当地界定问题。Arseny 至少知道三家使用过这种方法的公司，吹嘘他们如何击败了 Amazon、Google 和 OpenAI 等替代方案。在所有三个案例中，公司的声明都是合法的，这是预期的，因为主要供应商旨在提供一刀切解决方案，而初创公司可以提供更专业的 ML 系统，只做一件事就做得很好。

最后，如果这些选项都不起作用，你可以尝试从头开始训练一个简单的模型。然而，建议避免使用最新的最先进模型，而使用更简单且经过时间考验的模型。最新的模型在训练过程中往往更加“反复无常”，而一些较老的“明星”模型已经被深入研究，稳定的训练方法已知。这类模型的流行例子是用于视觉的 ResNet 系列和用于自然语言处理的 BERT 系列。我们个人的经验法则是从至少 2 年前的模型开始，但这不是一条严格的规定。它取决于系统所需的创新水平，如第三章所述。

值得注意的是，在“在预训练模型之上训练浅层模型”和“从头开始训练模型”之间有多个微调的层次。选择合适的微调程度非常具体，可能需要进行一些实验。例如，当基于 BERT 训练文本分类模型时，你可以逐渐复杂化训练范围：

+   只训练最后一层。

+   使用低秩适应（[`arxiv.org/abs/2106.09685`](https://arxiv.org/abs/2106.09685)）等适配器方法训练一些块。

+   训练一些编码器块。

+   训练标准化层。

+   训练嵌入层。

+   训练完整模型。

+   训练完整模型 + 标准化器。

这种多样性导致了一个问题，“我们如何选择一个合适的基线？”

## 8.5 基线比较

让我们检查各种特征和模型基线，从最简单的开始。我们可以回答核心问题，即何时停止增加复杂性以及如何确定我们系统的合适基线。我们应该同时考虑多个因素；其中一些是

+   准确性

+   努力程度（主要是开发时间）

+   可解释性

+   计算时间

最基本的是模型准确度（或其他机器学习指标）与其所需努力之间的权衡。方程中的第一个组成部分是准确度。当你从恒定基线移动到基于规则的基线，从基于规则的基线到线性模型，或者从原始特征到它们的聚合和比率时，你已经开始感受到这些小变化对指标增加的影响。它是敏感的还是不敏感的？显著超越你的恒定基线有多难？投资更多时间尝试获得更高准确度是否合理？

在某种意义上，作为一个机器学习工程师，你通过从训练循环中获得“反馈”来进行反向传播，并使用其数据和解决方案空间中的准确度分布来更新你对问题的理解。

第二个组成部分是努力。通过“努力”，我们主要指的是时间和计算资源。没有机器学习项目有无限的预算和，因此，无限的时间。我们考虑实现一个新模型（或特征）、训练它、调试它和测试它所需的时间。你也应该注意可能出现的所有伴随的复杂性和陷阱，尤其是基础设施方面的。

让我们考察一个恒定的基线。实现它几乎不需要时间，但它提供的准确性最低。因此，我们将它在时间-准确性坐标中的（0，0）点进行映射（如图 8.5 所示）。

![figure](img/CH08_F05_Babushkin.png)

##### 图 8.5 简单的基线容易构建，但牺牲了最终系统指标（时间序列预测的示例）。

让我们看看线性模型。它需要更多的努力，但也很可能提供更好的准确性。我们可能会找到对应于右侧和高于上一个点的点，依此类推。另一方面，重要的是要理解，随着模型改进和演变（因此复杂性增加），成本-准确性比开始下降。这种效率下降的一个显著例子是前面提到的梯度提升。根据我们的估计和经验，梯度提升需要的输入比你在早期阶段使用的所有更简单的模型加在一起还要多，而准确性却没有显著提高。

我们应该估计尝试更复杂模型需要多长时间以及它可能提供多少额外的准确性。一旦我们了解下一步需要太多的努力而几乎没有任何显著的分数提升，我们就应该停止。这个“早期停止阈值”取决于具体的领域和问题。

但如果出了问题或者模型需要一些额外的变化呢？哪个模型更容易调试或更新？

+   在光谱的左侧，我们有具有精确形式解的线性回归。

+   右侧是一个具有复杂训练和推理管道的深度神经网络。

你更愿意面对哪一个？

维护，我们将在第十六章中更详细地讨论，包括调试实现的功能或模型所需的额外工作量。我们可以将维护视为更复杂基线所需的额外努力的一部分。

基线的另一个基本属性是计算时间。我们的模型及其特征的计算时间如何影响响应时间？我们的基线是否符合服务水平协议？它是解决方案空间的自然极限，尤其是在处理实时系统时吗？但即使没有实时需求，计算时间也决定了我们在未来更彻底的实验中迭代的速度。

最后，我们有可解释性。当处理任何 ML 系统的第一次迭代时，这个参数很重要，特别是对于其他队友。当我们处理敏感或医疗数据时，它也成为了一个安全问题，而不仅仅是模型预测的信任问题。一般的模式很简单：基线越简单，解释其工作原理就越容易。

我们将在第十一章中详细讨论这个话题。

## 8.6 设计文档：基线

只要基线可以成为您的设计文档的一部分，我们将为我们的虚构公司 Supermegaretail 和 PhotoStock，Inc.填补这个空白。

### 8.6.1 Supermegaretail 的基线

让我们从预测系统开始。在这里，季节性在选择预测模型时将是一个巨大的因素，所以我们不能不在我们的设计文档中考虑它。

#### 设计文档：Supermegaretail

#### V. 基线解决方案

#### i. 常量基线

作为 Supermegaretail 需求预测系统的常量基线，我们计划使用每个 SKU 每个杂货的前一天的实际值。考虑到数据有时会延迟出现，以及杂货销售存在强烈的每周季节性，我们将后退 1 整个星期，而不是后退 1 天。因此，我们对 2022 年 9 月 8 日特定商品的预测将是该商品在 2022 年 9 月 1 日的实际销售价值。

#### ii. 高级常量基线

第五章提到了 1.5 分位数、25 分位数、50 分位数、75 分位数、95 分位数和 99 分位数的分位数损失。我们可以使用我们的基线使用年度窗口来计算相同的值。

#### iii. 线性模型基线

我们将使用一组基本特征来使用具有分位数损失的线性回归；一开始，我们只能使用目标变量，但带有多个滞后和聚合，如总和/最小值/最大值/平均值/中位数或对应于过去 7/14/30/60/90/180 天或不同大小的滚动窗口的最后几个分位数。同样的魔法也可以用于其他动态数据，如销售日期之外的价格、收入、平均账单或独特客户的数量。

#### iv. 时间序列特定基线

![图](img/CH08_UN01_Babushkin.png)

自回归积分移动平均（ARIMA）和季节性 ARIMA（SARIMA）都是用于预测的自回归算法；后者考虑了任何季节性模式。

这两种方法都需要调整多个超参数以提供令人满意的准确性。为了避免这种情况，我们可能更喜欢一种最先进的预测程序，它可以直接使用，称为 Prophet ([`github.com/facebook/prophet`](https://github.com/facebook/prophet))。Prophet 的优点是它很稳健，不需要太多的预处理：异常值、缺失值、位移和趋势都会自动处理。

#### v. 特征基线

什么额外信息可以让一些基线和可能的未来模型受益？

我们将包括关于产品（品牌、类别）、商店（地理特征）和上下文（基于时间的特征、季节性、星期几）的额外静态信息——所有这些都有适合所选模型的预处理和编码。

适用于基线的特征还包括计数器和交互。例如包括

+   当前价格与平均价格之间的差异（绝对和相对）

+   渗透率：产品销售额与类别（1 级、2 级、3 级）销售额的比率，对于不同大小的滚动窗口

+   自上次购买以来的天数

+   独特客户数量

### 8.6.2 PhotoStock Inc.的基线

现在我们转向 PhotoStock Inc.的案例，在那里我们正在构建一个高级搜索引擎，旨在提供更好、更准确的结果，并最终增加销售额。

#### 设计文档：PhotoStock Inc.

#### V. 基线解决方案

我们建议对 PhotoStock Inc.搜索引擎问题中的基线模型采用三种方法。

#### i. 非机器学习解决方案作为基线

目前，PhotoStock Inc.为其搜索引擎使用的是一个简单的非机器学习解决方案。它是一个基于关键字的搜索引擎，使用 ElasticSearch 数据库，可以进行模糊搜索。它不需要任何训练，并且已经部署到生产环境中，因此它是一个很好的基线模型候选。

尽管如此，它有两个缺点：它不使用图像进行搜索，只使用元数据（例如，标签、描述等），并且将其嵌入到新的机器学习管道中进行比较并不太容易。然而，将其作为基线模型仍然非常有用，因为它将允许我们比较机器学习模型与非机器学习解决方案的性能。

#### ii. 简单的机器学习解决方案作为基线

沿用之前的例子，我们可以使用一个简单的机器学习模型作为基线。它将不会使用图像，而只使用元数据。这样的模型可以使用查询和元数据作为原始输入，使用朴素词频-逆文档频率（TF-IDF）向量器将它们转换为特征，然后使用简单的线性模型来预测相关性得分。除此之外，它易于实现和训练，其卓越的简单性有助于早期阶段的调试和理解问题。

#### iii. 预训练模型作为基线

最后，我们可以使用预训练模型作为基线。鉴于问题的起源，我们需要一个能够统一视觉和文本领域的解决方案，最著名的是 CLIP ([`openai.com/index/clip/`](https://openai.com/index/clip/))。CLIP 于 2021 年发布，并在各种任务中证明是有用的。还有几个 CLIP 的后续版本可用，如果需要，可以在未来的迭代中对其进行审查。

CLIP，简而言之，是一个图像编码器和文本编码器，经过训练以预测哪些图像与适当的文本描述配对。它在一个庞大的数据集上进行了训练，因此在各种任务上表现出合理的性能。CLIP 是开源的，并且根据 MIT 许可证分发，因此可以用于商业目的。

为了使它适用于我们的用例，我们可以从使用其输出作为一对查询（图像）的相关性分数开始。这种方法不使用元数据和文本描述，因此它可以与先前的某种方法结合使用，或者进一步发展以使用两个组件的分数——例如：

relevancy_score = distance(query, image) + distance(query, description)

这两个距离都可以使用 CLIP 来计算——一个使用文本和图像编码器，另一个仅使用文本编码器。

作为第一步，我们可能完全避免任何训练。至于下一步，我们可以在我们的数据集上开始微调模型或其组件。

## 摘要

+   将基线视为机器学习系统设计的一个基本点，因为它们有效地解决了技术、机器学习和产品相关的问题（连接组件、设置一个用于比较的指标，以及通过一个弱模型理解产品用户体验）。

+   尽管基线被认为像 ABC 一样简单，但识别从哪些特征和模型开始的能力，却被低估了。

+   随着你深入到你的项目，你的常见进展将倾向于以下进展：恒定基线，然后是规则基线，然后是线性模型，然后是更复杂的东西。

+   虽然从一开始就构建一个复杂的模型可能很有吸引力，但始终考虑从恒定的基线开始；这将节省你的资源和时间，并指出你是否以最低的成本朝着正确的方向前进。

+   当一个问题暗示了使用深度学习时，最常见的方法是重用预训练模型，训练/微调最简单的模型，或者如果前两种方法都不奏效，从头开始训练一个简单的模型。

+   在选择各种基线选项时，应将准确性、努力程度（主要是开发时间）、可解释性和计算时间视为关键因素，其中准确性与努力程度的权衡尤为重要。

+   随着模型的发展和复杂度的增加，准确性的成本不可避免地会降低。这尤其适用于转向梯度提升，实践表明，它需要的输入比所有之前的模型加起来还要多，而准确性的提升却并不显著。
